{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVF2_gqB0EDy",
        "outputId": "d30ab9fc-a12a-41d6-f66a-a1fd1c26307d"
      },
      "outputs": [],
      "source": [
        "# Install missing dependencies\n",
        "# !pip install -q torchinfo torchmetrics wandb\n",
        "# !pip install torch\n",
        "# !pip install torchvision\n",
        "# !pip install numpy\n",
        "# !pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGJAcU7dTxJ1"
      },
      "source": [
        "### Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bnVg3M4l0EyA"
      },
      "outputs": [],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import wandb\n",
        "import pickle\n",
        "\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import  random_split, DataLoader, Subset\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2mj0Wd-T73T"
      },
      "source": [
        "### Build the directory for checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQg3CXCtgB-5",
        "outputId": "7b5a2e28-b427-4b64-f013-8c1977e97423"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybM87poAtHnl"
      },
      "source": [
        "### Set device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FC7BMY9z0H3L",
        "outputId": "3a9750af-17c1-4e3c-f816-20ff79567d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QH26cxftUt3"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "knmNFhHg0CwT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define a class for handling CIFAR100 data\n",
        "class CIFAR100Data:\n",
        "    \"\"\"\n",
        "    A class used to represent the CIFAR100 dataset.\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    batch_size : int\n",
        "        the number of samples that will be propagated through the network simultaneously\n",
        "    original_train_set : torchvision.datasets.CIFAR100\n",
        "        the original training set downloaded from CIFAR100\n",
        "    original_test_set : torchvision.datasets.CIFAR100\n",
        "        the original test set downloaded from CIFAR100\n",
        "    train_set : torch.utils.data.Subset\n",
        "        the training set after splitting the original training set\n",
        "    validation_set : torch.utils.data.Subset\n",
        "        the validation set after splitting the original training set\n",
        "    test_set : torchvision.datasets.CIFAR100\n",
        "        the test set, same as the original test set\n",
        "    original_train_loader : torch.utils.data.DataLoader\n",
        "        data loader for the original training set\n",
        "    original_test_loader : torch.utils.data.DataLoader\n",
        "        data loader for the original test set\n",
        "    train_loader : torch.utils.data.DataLoader\n",
        "        data loader for the training set\n",
        "    validation_loader : torch.utils.data.DataLoader\n",
        "        data loader for the validation set\n",
        "    test_loader : torch.utils.data.DataLoader\n",
        "        data loader for the test set\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    compute_mean_std(loader)\n",
        "        Computes the mean and standard deviation of the images in the loader.\n",
        "    download_data()\n",
        "        Downloads the CIFAR100 dataset.\n",
        "    split_data(original_train_set, validation_ratio=0.2)\n",
        "        Splits the original training set into a training set and a validation set.\n",
        "    compute_statistics(train_set)\n",
        "        Computes the mean and standard deviation of the training set.\n",
        "    apply_transforms(train_mean, train_std, is_validation_set_available = False)\n",
        "        Defines and applies the transformations for the training set, validation set, and test set.\n",
        "    save_data(data_loader, data_set, file_name: str)\n",
        "        Saves the data loader to Google Drive.\n",
        "    load_data(file_name: str)\n",
        "        Loads the data loader from Google Drive.\n",
        "    create_and_save_data_loaders(train_set, test_set, validation_set=None)\n",
        "        Creates data loaders for the training, validation, and test sets and saves them to Google Drive.\n",
        "    prepare_data(validation_ratio = None)\n",
        "        Prepares the data by downloading it, splitting it, computing statistics, applying transforms, and creating and saving data loaders.\n",
        "    train_valid_test(validation_ratio=0.2)\n",
        "        Loads or prepares the data loaders for the training, validation, and test sets and returns them.\n",
        "    train_test()\n",
        "        Loads or prepares the data loaders for the original training and test sets and returns them.\n",
        "    iid_shards(num_shards=2)\n",
        "        Loads or prepares the data loaders for the shards of the original training set and returns them.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=64):\n",
        "        \"\"\"\n",
        "        Initialize the CIFAR100Data object with the given batch size.\n",
        "\n",
        "        Parameters:\n",
        "        batch_size (int): The size of the batches for the data loaders.\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.original_train_set = None\n",
        "        self.original_test_set = None\n",
        "        self.train_set = None\n",
        "        self.validation_set = None\n",
        "        self.test_set = None\n",
        "\n",
        "        self.original_train_loader = None\n",
        "        self.original_test_loader = None\n",
        "        self.train_loader = None\n",
        "        self.validation_loader = None\n",
        "        self.test_loader = None\n",
        "\n",
        "    def compute_mean_std(self, loader):\n",
        "        \"\"\"\n",
        "        Compute the mean and standard deviation of the images in the loader.\n",
        "\n",
        "        Parameters:\n",
        "        loader (DataLoader): The DataLoader object containing the image data.\n",
        "\n",
        "        Returns:\n",
        "        mean (Tensor): The mean of the images.\n",
        "        std (Tensor): The standard deviation of the images.\n",
        "        \"\"\"\n",
        "        channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "        for data, _ in loader:\n",
        "            channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "            channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "            num_batches += 1\n",
        "        mean = channels_sum / num_batches\n",
        "        std = torch.sqrt((channels_squared_sum / num_batches) - mean**2)\n",
        "        return mean, std\n",
        "\n",
        "    def download_data(self):\n",
        "        \"\"\"\n",
        "        Download the CIFAR100 dataset and store it in instance variables.\n",
        "        \"\"\"\n",
        "        self.original_train_set = CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "        self.original_test_set = CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    def split_data(self, original_train_set, validation_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Split the original training set into a training set and a validation set.\n",
        "\n",
        "        Parameters:\n",
        "        original_train_set (Dataset): The original training set.\n",
        "        validation_ratio (float): The ratio of the original training set to use for validation.\n",
        "\n",
        "        Returns:\n",
        "        train_set (Subset): The new training set.\n",
        "        validation_set (Subset): The new validation set.\n",
        "        \"\"\"\n",
        "        train_len = int(len(original_train_set) * (1 - validation_ratio))\n",
        "        val_len = len(original_train_set) - train_len\n",
        "        train_set, validation_set = random_split(original_train_set, [train_len, val_len])\n",
        "\n",
        "        return train_set, validation_set\n",
        "\n",
        "    def compute_statistics(self, train_set):\n",
        "        \"\"\"\n",
        "        Compute the mean and standard deviation of the train set.\n",
        "\n",
        "        Parameters:\n",
        "        train_set (Dataset/Subset): The training set.\n",
        "\n",
        "        Returns:\n",
        "        train_mean (Tensor): The mean of the training set.\n",
        "        train_std (Tensor): The standard deviation of the training set.\n",
        "        \"\"\"\n",
        "        trainloader_tmp = DataLoader(train_set, batch_size=self.batch_size, shuffle=True)\n",
        "        train_mean, train_std = self.compute_mean_std(trainloader_tmp)\n",
        "\n",
        "        return train_mean, train_std\n",
        "\n",
        "    def apply_transforms(self, train_mean, train_std, is_validation_set_available = False):\n",
        "        \"\"\"\n",
        "        Define the transformations for the training set, validation set, and test set\n",
        "        and apply them to the datasets.\n",
        "\n",
        "        Parameters:\n",
        "        train_mean (Tensor): The mean of the training set.\n",
        "        train_std (Tensor): The standard deviation of the training set.\n",
        "        is_validation_set_available (bool): Whether a validation set is available.\n",
        "        \"\"\"\n",
        "\n",
        "        # Transformations for the training set\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(train_mean.tolist(), train_std.tolist())\n",
        "        ])\n",
        "\n",
        "        # Transformations for the validation and test sets\n",
        "        test_val_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(train_mean.tolist(), train_std.tolist())\n",
        "        ])\n",
        "\n",
        "        # Apply the transformations to the datasets\n",
        "        if is_validation_set_available:\n",
        "            self.train_set.transform = train_transforms\n",
        "            self.validation_set.transform = test_val_transforms\n",
        "            self.test_set.transform = test_val_transforms\n",
        "        else:\n",
        "            self.original_train_set.transform = train_transforms\n",
        "            self.original_test_set.transform = test_val_transforms\n",
        "\n",
        "    def save_data(self, data_loader, file_name: str):\n",
        "        \"\"\"\n",
        "        Save the given data loader and data set to Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        data_loader (DataLoader): The data loader to save.\n",
        "        file_name (str): The name of the file to save the data loader and data set to.\n",
        "        \"\"\"\n",
        "        # Check if the directory exists, if not, create it\n",
        "        # if not os.path.exists('/content/gdrive/MyDrive/data/data_loaders/'):\n",
        "        #     os.makedirs('/content/gdrive/MyDrive/data/data_loaders/')\n",
        "\n",
        "        # Open each file in write-binary mode on Google Drive and dump (pickle) the data loader into it\n",
        "        # with open(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl', 'wb') as f:\n",
        "        #     pickle.dump(data_loader, f)\n",
        "        if not os.path.exists(f'./data/data_loaders/{self.batch_size}/'):\n",
        "            os.makedirs(f'./data/data_loaders/{self.batch_size}/')\n",
        "        \n",
        "        open(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl', 'wb').write(pickle.dumps(data_loader))\n",
        "\n",
        "    def load_data(self, file_name: str):\n",
        "        \"\"\"\n",
        "        Load a data loader from Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        file_name (str): The name of the file to load the data loader from.\n",
        "\n",
        "        Returns:\n",
        "        data_loader (DataLoader): The loaded data loader, or None if the file does not exist.\n",
        "        \"\"\"\n",
        "        # Check if the file exists\n",
        "        # if os.path.exists(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl'):\n",
        "        #     # If it exists, open the file in read-binary mode and load (unpickle) the data loader from it\n",
        "        #     with open(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl', 'rb') as f:\n",
        "        #         return pickle.load(f)\n",
        "        # else:\n",
        "        #     return None\n",
        "        if os.path.exists(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl'):\n",
        "            return pickle.loads(open(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl', 'rb').read())\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def create_and_save_data_loaders(self, train_set, test_set, train_name: str, test_name: str, validation_set=None):\n",
        "        \"\"\"\n",
        "        Create data loaders for the training, validation, and test sets and save them to Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        train_set (Subset): The training set.\n",
        "        test_set (Subset): The test set.\n",
        "        validation_set (Subset, optional): The validation set.\n",
        "\n",
        "        Returns:\n",
        "        train_loader (DataLoader): The data loader for the training set.\n",
        "        validation_loader (DataLoader): The data loader for the validation set, if it exists.\n",
        "        test_loader (DataLoader): The data loader for the test set.\n",
        "        \"\"\"\n",
        "        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True, num_workers =8)\n",
        "        test_loader = DataLoader(test_set, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "        # Save the newly created data loaders to Google Drive\n",
        "        self.save_data(train_loader, train_name)\n",
        "        self.save_data(test_loader, test_name)\n",
        "\n",
        "        if validation_set is not None:\n",
        "            validation_loader = DataLoader(validation_set, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
        "            self.save_data(validation_loader, 'validation')\n",
        "            return train_loader, validation_loader, test_loader\n",
        "\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    def prepare_data(self, validation_ratio = None):\n",
        "        \"\"\"\n",
        "        Prepare the data by downloading it, splitting it into training, validation, and test sets,\n",
        "        computing statistics, applying transformations, and creating and saving data loaders.\n",
        "\n",
        "        Parameters:\n",
        "        validation_ratio (float, optional): The ratio of the original training set to use for validation.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.download_data()\n",
        "        except IOError:\n",
        "            print(\"Error downloading data\")\n",
        "            return\n",
        "\n",
        "        if validation_ratio is not None:\n",
        "            self.train_set, self.validation_set = self.split_data(self.original_train_set, validation_ratio)\n",
        "            if self.validation_set is None:\n",
        "                print(\"Validation set is not available\")\n",
        "                return\n",
        "            self.test_set = self.original_test_set\n",
        "            train_mean, train_std = self.compute_statistics(self.train_set)\n",
        "            self.apply_transforms(train_mean, train_std, is_validation_set_available = True)\n",
        "\n",
        "            # Create and save data loaders\n",
        "            self.train_loader, self.validation_loader, self.test_loader = self.create_and_save_data_loaders(self.train_set, self.test_set, 'train', 'test', self.validation_set)\n",
        "\n",
        "        else:\n",
        "            train_mean, train_std = self.compute_statistics(self.original_train_set)\n",
        "            self.apply_transforms(train_mean, train_std)\n",
        "\n",
        "            # Create and save data loaders\n",
        "            self.original_train_loader, self.original_test_loader = self.create_and_save_data_loaders(self.original_train_set, self.original_test_set, 'original_train', 'original_test')\n",
        "\n",
        "    def train_valid_test(self, validation_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Load the training, validation, and test data loaders from Google Drive, or prepare the data if they do not exist.\n",
        "\n",
        "        Parameters:\n",
        "        validation_ratio (float): The ratio of the original training set to use for validation.\n",
        "\n",
        "        Returns:\n",
        "        train_loader (DataLoader): The data loader for the training set.\n",
        "        validation_loader (DataLoader): The data loader for the validation set.\n",
        "        test_loader (DataLoader): The data loader for the test set.\n",
        "        \"\"\"\n",
        "        self.train_loader = self.load_data('train')\n",
        "        self.validation_loader = self.load_data('validation')\n",
        "        self.test_loader = self.load_data('test')\n",
        "\n",
        "        if self.train_loader is None or self.validation_loader is None or self.test_loader is None:\n",
        "            self.prepare_data(validation_ratio)\n",
        "\n",
        "        # Return the data loaders\n",
        "        return self.train_loader, self.validation_loader, self.test_loader\n",
        "\n",
        "    def train_test(self):\n",
        "        \"\"\"\n",
        "        Load the original training and test data loaders from Google Drive, or prepare the data if they do not exist.\n",
        "\n",
        "        Returns:\n",
        "        original_train_loader (DataLoader): The data loader for the original training set.\n",
        "        original_test_loader (DataLoader): The data loader for the original test set.\n",
        "        \"\"\"\n",
        "        self.original_train_loader = self.load_data('original_train')\n",
        "        self.original_test_loader = self.load_data('original_test')\n",
        "\n",
        "        if self.original_train_loader is None or self.original_test_loader is None:\n",
        "            self.prepare_data()\n",
        "\n",
        "        # Return the data loaders\n",
        "        return self.original_train_loader, self.original_test_loader\n",
        "\n",
        "    def iid_shards(self, num_shards=2):\n",
        "        \"\"\"\n",
        "        Create or load independent and identically distributed (IID) shards of the original training set.\n",
        "\n",
        "        Parameters:\n",
        "        num_shards (int): The number of shards to create.\n",
        "\n",
        "        Returns:\n",
        "        shard_loaders (list of DataLoader): The data loaders for the shards.\n",
        "        \"\"\"\n",
        "        # Try to load the shard datasets and their corresponding data loaders from Google Drive\n",
        "        shard_loaders = []\n",
        "        for i in range(num_shards):\n",
        "            shard_loader = self.load_data(f'iid_sharding/{num_shards}_chunk_{i+1}')\n",
        "            if shard_loader is None:\n",
        "                break\n",
        "            shard_loaders.append(shard_loader)\n",
        "\n",
        "        # If all shard data loaders were successfully loaded, return them\n",
        "        if len(shard_loaders) == num_shards:\n",
        "            return shard_loaders\n",
        "\n",
        "        # If not all shard data loaders were successfully loaded, create them\n",
        "        if self.original_train_set is None:\n",
        "            self.download_data()\n",
        "            train_mean, train_std = self.compute_statistics(self.original_train_set)\n",
        "            self.apply_transforms(train_mean, train_std)\n",
        "\n",
        "        # Shuffle the indices\n",
        "        indices = torch.randperm(len(self.original_train_set))\n",
        "\n",
        "        # Split the indices into K chunks\n",
        "        shard_size = len(indices) // num_shards\n",
        "        shards = [indices[i*shard_size:(i+1)*shard_size] for i in range(num_shards)]\n",
        "\n",
        "        # Create subsets for each shard\n",
        "        shard_datasets = [Subset(self.original_train_set, shard) for shard in shards]\n",
        "\n",
        "        # Create data loaders for each shard\n",
        "        shard_loaders = [DataLoader(shard_dataset, batch_size=self.batch_size, shuffle=True) for shard_dataset in shard_datasets]\n",
        "\n",
        "        # Save each shard dataset and its corresponding data loader\n",
        "        for i, shard_loader in enumerate(shard_loaders):\n",
        "            self.save_data(shard_loader, f'iid_sharding_{num_shards}_chunk_{i+1}')\n",
        "\n",
        "        return shard_loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KE_ErnYB06JF"
      },
      "outputs": [],
      "source": [
        "data = CIFAR100Data()\n",
        "train_loader, validation_loader, test_loader = data.train_valid_test(validation_ratio=0.2)\n",
        "original_train_loader, original_test_loader = data.train_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fjzE9q4UOPU"
      },
      "source": [
        "### Define the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KaLfzyjo0Pzk"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=0) # 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=0) # 10x10\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 14x14 for conv1 and 5x5 for conv2\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(5 * 5 * 64, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 14x14\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 5x5\n",
        "        x = self.flatten(x) # Flatten\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-4HtbSQ20ea5"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEseiEKFt0mR"
      },
      "source": [
        "### Define some basic functions for train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JZNSgcBp0jEl"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, loss_fn, accumulation_steps=1, device=device, is_wandb=False):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    optimizer.zero_grad()  # Initialize gradients to zero at the start of each epoch\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # Gradient accumulation\n",
        "        if (i+1) % accumulation_steps == 0 or i+1 == len(dataloader):\n",
        "            optimizer.step()  # Update model parameters\n",
        "            optimizer.zero_grad()  # Reset gradients to zero\n",
        "\n",
        "    train_loss = running_loss / len(dataloader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "\n",
        "    if is_wandb:\n",
        "        wandb.log({\"Train Loss\": train_loss, \"Train Accuracy\": train_accuracy})\n",
        "\n",
        "    return train_loss, train_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m6dkKxXh0i7n"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, loss_fn, device = device, is_wandb= False):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            if is_wandb:\n",
        "              # Log the loss and accuracy values at each step\n",
        "              wandb.log({\n",
        "                  'Test Loss': test_loss / (batch_idx + 1),\n",
        "                  'Test Accuracy': 100 * correct / total\n",
        "              })\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ZD7Vge_wYwvX"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, epoch, batch_size, optimizer_name, hyperparameters):\n",
        "    # dir_path = f\"/content/gdrive/MyDrive/{optimizer_name}/{batch_size}/\"\n",
        "    dir_path = f\"./train/{optimizer_name}/{batch_size}/\"\n",
        "    for key, value in hyperparameters.items():\n",
        "        dir_path = os.path.join(dir_path, f\"{key}_{value}/\")\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "    path = os.path.join(dir_path, f\"epoch_{epoch:03}.pt\")\n",
        "    torch.save(state, path)\n",
        "\n",
        "    # Get list of all files\n",
        "    list_of_files = glob.glob(os.path.join(dir_path, f\"epoch_*.pt\"))\n",
        "    # Sort files by creation time\n",
        "    list_of_files.sort(key=os.path.getctime)\n",
        "    # If there are more than 2 files, delete the second last one\n",
        "    if len(list_of_files) > 1:\n",
        "        os.remove(list_of_files[-2])\n",
        "\n",
        "def load_checkpoint(optimizer_name, batch_size, hyperparameters):\n",
        "    # dir_path = f\"/content/gdrive/MyDrive/{optimizer_name}/{batch_size}/\"\n",
        "    dir_path = f\"./train/{optimizer_name}/{batch_size}/\"\n",
        "    for key, value in hyperparameters.items():\n",
        "        dir_path = os.path.join(dir_path, f\"{key}_{value}/\")\n",
        "    list_of_files = glob.glob(os.path.join(dir_path, f\"epoch_*.pt\")) # * means all if need specific format then *.csv\n",
        "    if not list_of_files:  # I'm using glob which can return an empty list\n",
        "        return None\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    if os.path.isfile(latest_file):\n",
        "        return torch.load(latest_file)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9Yjx-yZf-Sbz"
      },
      "outputs": [],
      "source": [
        "def run_training(\n",
        "    num_epochs,\n",
        "    model,\n",
        "    trainloader,\n",
        "    validationloader,\n",
        "    testloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    optimizer_name: str,\n",
        "    accumulation_steps=1,\n",
        "    hyperparameters=None,\n",
        "    is_wandb = False,\n",
        "    n_epochs_stop = None\n",
        "  ):\n",
        "\n",
        "  best_accuracy = 0\n",
        "  epochs_no_improve = 0\n",
        "  n_epochs_stop = n_epochs_stop  # number of epochs to wait before stopping\n",
        "\n",
        "  start_epoch = 0\n",
        "  run_id = None\n",
        "  run_name = None\n",
        "  # Load checkpoint if available\n",
        "  checkpoint = load_checkpoint(optimizer_name, trainloader.batch_size, hyperparameters)\n",
        "  if checkpoint is not None:\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      start_epoch = checkpoint['epoch'] + 1\n",
        "      run_id = checkpoint.get('wandb_run_id', None)\n",
        "      run_name = checkpoint.get('wandb_run_name', None)\n",
        "\n",
        "  else:\n",
        "    run_name = \" \".join([f\"{key}={value}\" for key, value in hyperparameters.items()])\n",
        "\n",
        "  if is_wandb:\n",
        "    # Initialize a wandb run with the given hyperparameters\n",
        "    wandb.init(id=run_id, name=run_name, project=f'cifar100-training-mldl2024-baseline-{optimizer_name}',\n",
        "                   config=hyperparameters if hyperparameters is not None else {},\n",
        "                   resume=\"allow\", reinit=True)\n",
        "\n",
        "  for epoch in range(start_epoch, num_epochs):\n",
        "      # Call the training function for each epoch\n",
        "      train_loss, train_acc = train(model, trainloader, optimizer, loss_fn, accumulation_steps, device, is_wandb=is_wandb)\n",
        "      print(f'[{epoch+1}/{num_epochs}]: Training Loss: {train_loss}, Training Accuracy: {train_acc}')\n",
        "      scheduler.step() # Update learning rate based on scheduler\n",
        "\n",
        "      # Save checkpoint\n",
        "      save_checkpoint({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'loss': criterion,\n",
        "                    'wandb_run_id': wandb.run.id if is_wandb else None,\n",
        "                    'wandb_run_name': wandb.run.name if is_wandb else None,\n",
        "                    }, epoch, trainloader.batch_size, optimizer_name, hyperparameters)\n",
        "\n",
        "      if validationloader is not None:\n",
        "        val_loss, val_acc = test(model, validationloader, criterion)\n",
        "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
        "\n",
        "\n",
        "        if n_epochs_stop is not None:\n",
        "          if val_acc > best_accuracy:\n",
        "                best_accuracy = val_acc\n",
        "                epochs_no_improve = 0\n",
        "          else:\n",
        "              epochs_no_improve += 1\n",
        "              if epochs_no_improve == n_epochs_stop:\n",
        "                  print('Early stopping!')\n",
        "                  break\n",
        "\n",
        "  print('*'*70)\n",
        "  test_loss, test_acc = test(model, testloader, criterion, is_wandb = is_wandb)\n",
        "  print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "  # Finish the wandb run after all epochs\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taX_5ElNuKxC"
      },
      "source": [
        "### Centeralised baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "8hxWmieIE7jF"
      },
      "outputs": [],
      "source": [
        "\n",
        "learning_rates = [1e-03, 1e-02]\n",
        "weight_decays = [1e-04, 1e-03, 4e-04]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8587c890f2a847e293a101405d64fc0d",
            "175043eb44e44b4f9aefaf51aae6fb10",
            "db36d0cc7691440a9792ac779e161e62",
            "c6a68af25a2847e98201847781419670",
            "71e710b571d142a3a08cd233590b7171",
            "2671c3bf3cfd49aa9ad6841c289068cc",
            "45bdcbbed9ae47ffb24bd2a962345eaa",
            "bcbeb5bacc824f3aacd20e50d38bb70a",
            "2991ead42a2a4637b2902ca26837d74b",
            "9e0bb90e33ec4e198857c255080ef6f0",
            "77790c4dcd124f73907619689fb8d37c",
            "1fef0782f0804736881f03c2e31c3d64",
            "3606009883cf4212b7e1ed6e4f182845",
            "39aecb8ffe0645fbadccf8b0f8ed2486",
            "13e7a0db2aa74e35b7d1948224358d76",
            "7064cd1e5d794c258dbeeb63a9ae9f9b",
            "5cf516644d1a4ebf82c7e9dfa13e560b",
            "36a546b812d6403cbf5ed693318a9744",
            "aed05a015df946c7bae33226c3a8ddc6",
            "d601ef3ebb6c4b688ac53a65979aa445",
            "e4a5f301338a4e5185c042a22684ed4a",
            "48c7de7682f242fd86a234d1607187f4",
            "403dcd5f10de42ddbb67c8108e3bc34c",
            "a1d013e4d3e942b6b362ab5ade6d1a80",
            "e851c69b66ca4e8a80779a69435b855f",
            "4b733fc6800e4a0ab36bba52ff84f1a5",
            "dcbb358118e644a2a75d44d8adb6747b",
            "829bba2a5bb947a0bcf121c527902255",
            "7e2cc873f917444c833e152f7c2555de",
            "49727de0590f41dca6addf3f4ffe33f2",
            "60957598b6c64ab0987d583b788dd674",
            "e4ad17a7648245069c70f2f3fb79105a",
            "431cf75dd1cc4840b14f678876f45bc9",
            "a5f3871113994f1eb993c126d793d147",
            "7903555c1e884408b70c9951ecae84ec",
            "2d65b320aaed40cd87b8f78c99c614e7",
            "346856a22f0e45b2be0c14aa7902261f",
            "397b6d4daaf04a1181413adc5e30db0c",
            "ac87babb2f2a4781ab863c3b8f613807",
            "b3970cfd36ed4450b7c8f958a6499dc4",
            "df97494c2f654ffbaceb9ca801ff3113",
            "e1e5353cb6a1427a8b0b9d91d6067ef7",
            "77c702b6d9c04f00b8e624f31a591f01",
            "8795a05c814c469083b31be62e79289f",
            "829eee71e4d74403a22941b15dfcf9bc",
            "ab0b891f55f648cdbace9bc4540c51c6",
            "e6d67121f0ab4daf96d0bdd2c433259b",
            "3ee2c346d4d74faa915ef8315e3303c8"
          ]
        },
        "id": "9rGKhc7FJB8u",
        "outputId": "9b4eddc5-dc51-4af2-fdbe-4ba3175d3642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240611_235508-gw8sn909</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">learning_rate=0.001 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10/150]: Training Loss: 3.7955315692901612, Training Accuracy: 12.3825\n",
            "Validation Loss: 3.7704276780413974, Validation Accuracy: 12.97\n",
            "[11/150]: Training Loss: 3.693796951675415, Training Accuracy: 14.2675\n",
            "Validation Loss: 3.6661312990127857, Validation Accuracy: 14.76\n",
            "[12/150]: Training Loss: 3.5919596023559572, Training Accuracy: 16.0125\n",
            "Validation Loss: 3.5912161389733575, Validation Accuracy: 16.26\n",
            "[13/150]: Training Loss: 3.5116733703613283, Training Accuracy: 17.3775\n",
            "Validation Loss: 3.5196323546634356, Validation Accuracy: 16.95\n",
            "[14/150]: Training Loss: 3.4402521675109865, Training Accuracy: 18.835\n",
            "Validation Loss: 3.4998342930131656, Validation Accuracy: 17.78\n",
            "[15/150]: Training Loss: 3.374294019317627, Training Accuracy: 19.835\n",
            "Validation Loss: 3.412280123704558, Validation Accuracy: 19.05\n",
            "[16/150]: Training Loss: 3.3126377914428713, Training Accuracy: 20.9225\n",
            "Validation Loss: 3.3567575497232425, Validation Accuracy: 20.21\n",
            "[17/150]: Training Loss: 3.264142190551758, Training Accuracy: 21.7475\n",
            "Validation Loss: 3.3158142976700122, Validation Accuracy: 20.54\n",
            "[18/150]: Training Loss: 3.212448757171631, Training Accuracy: 22.925\n",
            "Validation Loss: 3.288792388454364, Validation Accuracy: 21.5\n",
            "[19/150]: Training Loss: 3.16608261680603, Training Accuracy: 23.6325\n",
            "Validation Loss: 3.247776625262704, Validation Accuracy: 22.28\n",
            "[20/150]: Training Loss: 3.1185284183502198, Training Accuracy: 24.565\n",
            "Validation Loss: 3.2615917640127194, Validation Accuracy: 21.82\n",
            "[21/150]: Training Loss: 3.0692719429016115, Training Accuracy: 25.24\n",
            "Validation Loss: 3.188312981538712, Validation Accuracy: 23.06\n",
            "[22/150]: Training Loss: 3.0227535221099853, Training Accuracy: 26.3125\n",
            "Validation Loss: 3.189725389905796, Validation Accuracy: 23.3\n",
            "[23/150]: Training Loss: 2.9822758083343506, Training Accuracy: 26.9425\n",
            "Validation Loss: 3.1865678501736587, Validation Accuracy: 24.06\n",
            "[24/150]: Training Loss: 2.9383605140686035, Training Accuracy: 27.7575\n",
            "Validation Loss: 3.1210442075304163, Validation Accuracy: 25.28\n",
            "[25/150]: Training Loss: 2.8941220123291016, Training Accuracy: 28.8275\n",
            "Validation Loss: 3.0783458576080904, Validation Accuracy: 26.38\n",
            "[26/150]: Training Loss: 2.846640188598633, Training Accuracy: 29.6625\n",
            "Validation Loss: 3.0489486524253895, Validation Accuracy: 26.15\n",
            "[27/150]: Training Loss: 2.803463589859009, Training Accuracy: 30.53\n",
            "Validation Loss: 3.0650304320511546, Validation Accuracy: 26.3\n",
            "[28/150]: Training Loss: 2.7623793058395387, Training Accuracy: 31.4175\n",
            "Validation Loss: 3.016696295161156, Validation Accuracy: 27.16\n",
            "[29/150]: Training Loss: 2.724277519607544, Training Accuracy: 31.9075\n",
            "Validation Loss: 3.001434786304547, Validation Accuracy: 27.8\n",
            "[30/150]: Training Loss: 2.6789874454498293, Training Accuracy: 33.0275\n",
            "Validation Loss: 3.016883801502787, Validation Accuracy: 27.3\n",
            "[31/150]: Training Loss: 2.639483213806152, Training Accuracy: 33.66\n",
            "Validation Loss: 2.98876147361318, Validation Accuracy: 28.67\n",
            "[32/150]: Training Loss: 2.5927667430877683, Training Accuracy: 34.5325\n",
            "Validation Loss: 2.994789396881298, Validation Accuracy: 27.54\n",
            "[33/150]: Training Loss: 2.5531089670181273, Training Accuracy: 35.2525\n",
            "Validation Loss: 2.997880709399084, Validation Accuracy: 28.54\n",
            "[34/150]: Training Loss: 2.5080887552261353, Training Accuracy: 36.16\n",
            "Validation Loss: 2.9557720460709493, Validation Accuracy: 29.05\n",
            "[35/150]: Training Loss: 2.470765545463562, Training Accuracy: 37.03\n",
            "Validation Loss: 2.960252163516488, Validation Accuracy: 29.2\n",
            "[36/150]: Training Loss: 2.4253519346237185, Training Accuracy: 37.9225\n",
            "Validation Loss: 2.9324972644733016, Validation Accuracy: 29.32\n",
            "[37/150]: Training Loss: 2.3800090463638304, Training Accuracy: 39.06\n",
            "Validation Loss: 2.9341223923264037, Validation Accuracy: 30.21\n",
            "[38/150]: Training Loss: 2.3413858253479005, Training Accuracy: 39.57\n",
            "Validation Loss: 2.9640257130762575, Validation Accuracy: 29.88\n",
            "[39/150]: Training Loss: 2.301597819519043, Training Accuracy: 40.4175\n",
            "Validation Loss: 3.0218158800890493, Validation Accuracy: 28.21\n",
            "[40/150]: Training Loss: 2.2570854791641235, Training Accuracy: 41.3725\n",
            "Validation Loss: 3.0180870347721562, Validation Accuracy: 29.27\n",
            "[41/150]: Training Loss: 2.2198365371704103, Training Accuracy: 42.375\n",
            "Validation Loss: 2.938889775306556, Validation Accuracy: 30.41\n",
            "[42/150]: Training Loss: 2.1788083906173705, Training Accuracy: 43.24\n",
            "Validation Loss: 2.931537726882157, Validation Accuracy: 30.24\n",
            "[43/150]: Training Loss: 2.130757416725159, Training Accuracy: 44.2975\n",
            "Validation Loss: 2.935111481672639, Validation Accuracy: 30.94\n",
            "[44/150]: Training Loss: 2.0930950580596925, Training Accuracy: 45.0275\n",
            "Validation Loss: 2.9872301232283283, Validation Accuracy: 30.88\n",
            "[45/150]: Training Loss: 2.0451603315353393, Training Accuracy: 46.14\n",
            "Validation Loss: 2.9818537857881777, Validation Accuracy: 30.2\n",
            "[46/150]: Training Loss: 2.004084638786316, Training Accuracy: 47.0275\n",
            "Validation Loss: 2.995785168022107, Validation Accuracy: 30.23\n",
            "[47/150]: Training Loss: 1.9692718086242675, Training Accuracy: 47.845\n",
            "Validation Loss: 3.0542795536624396, Validation Accuracy: 30.14\n",
            "[48/150]: Training Loss: 1.9216952280044555, Training Accuracy: 48.8675\n",
            "Validation Loss: 2.9834766873888148, Validation Accuracy: 31.12\n",
            "[49/150]: Training Loss: 1.8784988208770752, Training Accuracy: 49.9625\n",
            "Validation Loss: 3.0277192516691365, Validation Accuracy: 31.11\n",
            "[50/150]: Training Loss: 1.8381427211761474, Training Accuracy: 50.9275\n",
            "Validation Loss: 3.062338437244391, Validation Accuracy: 31.08\n",
            "[51/150]: Training Loss: 1.7901163187026978, Training Accuracy: 52.055\n",
            "Validation Loss: 3.1062804225144114, Validation Accuracy: 30.8\n",
            "[52/150]: Training Loss: 1.7526374937057496, Training Accuracy: 52.695\n",
            "Validation Loss: 3.121828522651818, Validation Accuracy: 31.1\n",
            "[53/150]: Training Loss: 1.7035991048812866, Training Accuracy: 53.87\n",
            "Validation Loss: 3.1324675629852683, Validation Accuracy: 30.77\n",
            "[54/150]: Training Loss: 1.6695509649276734, Training Accuracy: 54.6\n",
            "Validation Loss: 3.1344476976212423, Validation Accuracy: 30.74\n",
            "[55/150]: Training Loss: 1.6191298002243042, Training Accuracy: 55.795\n",
            "Validation Loss: 3.2295576159361823, Validation Accuracy: 29.87\n",
            "[56/150]: Training Loss: 1.5762285459518433, Training Accuracy: 56.7875\n",
            "Validation Loss: 3.242111048121361, Validation Accuracy: 30.56\n",
            "[57/150]: Training Loss: 1.5393764123916627, Training Accuracy: 58.005\n",
            "Validation Loss: 3.303940733526922, Validation Accuracy: 29.53\n",
            "[58/150]: Training Loss: 1.4886947209358214, Training Accuracy: 59.32\n",
            "Validation Loss: 3.306815612088343, Validation Accuracy: 30.63\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 12.757227435992782, Test Accuracy: 12.53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██▁▂▂▂▂▁▁▁▁▂▂▂▃▃▃▃▃▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Test Loss</td><td>▁▄▆▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>Train Loss</td><td>██▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.53</td></tr><tr><td>Test Loss</td><td>12.75723</td></tr><tr><td>Train Accuracy</td><td>59.32</td></tr><tr><td>Train Loss</td><td>1.48869</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240611_235508-gw8sn909/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240611_235923-9i8aijvl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">learning_rate=0.001 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605354942321777, Training Accuracy: 1.0075\n",
            "Validation Loss: 4.604883777108162, Validation Accuracy: 0.9\n",
            "[2/150]: Training Loss: 4.602973918151855, Training Accuracy: 1.0475\n",
            "Validation Loss: 4.6016397293965525, Validation Accuracy: 0.9\n",
            "[3/150]: Training Loss: 4.596875128936768, Training Accuracy: 1.3425\n",
            "Validation Loss: 4.590152442834939, Validation Accuracy: 2.52\n",
            "[4/150]: Training Loss: 4.556022624969483, Training Accuracy: 2.9175\n",
            "Validation Loss: 4.472016604842653, Validation Accuracy: 3.55\n",
            "[5/150]: Training Loss: 4.280242394256592, Training Accuracy: 4.6625\n",
            "Validation Loss: 4.20257385673037, Validation Accuracy: 5.95\n",
            "[6/150]: Training Loss: 4.122820203781128, Training Accuracy: 6.5925\n",
            "Validation Loss: 4.098185727550725, Validation Accuracy: 6.72\n",
            "[7/150]: Training Loss: 4.0448949375152585, Training Accuracy: 7.655\n",
            "Validation Loss: 4.033748802865387, Validation Accuracy: 8.54\n",
            "[8/150]: Training Loss: 3.977578921508789, Training Accuracy: 9.06\n",
            "Validation Loss: 3.970679567118359, Validation Accuracy: 8.73\n",
            "[9/150]: Training Loss: 3.9144488010406495, Training Accuracy: 9.9875\n",
            "Validation Loss: 3.902484763200116, Validation Accuracy: 10.84\n",
            "[10/150]: Training Loss: 3.8504066452026366, Training Accuracy: 11.2025\n",
            "Validation Loss: 3.853308222096437, Validation Accuracy: 11.05\n",
            "[11/150]: Training Loss: 3.776761824798584, Training Accuracy: 12.605\n",
            "Validation Loss: 3.7683646602995076, Validation Accuracy: 13.16\n",
            "[12/150]: Training Loss: 3.6920017036437986, Training Accuracy: 14.09\n",
            "Validation Loss: 3.712872941023225, Validation Accuracy: 13.54\n",
            "[13/150]: Training Loss: 3.617317741394043, Training Accuracy: 15.2475\n",
            "Validation Loss: 3.619570322097487, Validation Accuracy: 14.95\n",
            "[14/150]: Training Loss: 3.5433271072387695, Training Accuracy: 16.7275\n",
            "Validation Loss: 3.5456171734317854, Validation Accuracy: 16.81\n",
            "[15/150]: Training Loss: 3.47977327041626, Training Accuracy: 17.6525\n",
            "Validation Loss: 3.503120666856219, Validation Accuracy: 17.12\n",
            "[16/150]: Training Loss: 3.4149503967285155, Training Accuracy: 18.85\n",
            "Validation Loss: 3.449874220380358, Validation Accuracy: 17.98\n",
            "[17/150]: Training Loss: 3.357447999191284, Training Accuracy: 20.3025\n",
            "Validation Loss: 3.3906334479143667, Validation Accuracy: 19.6\n",
            "[18/150]: Training Loss: 3.3055746353149416, Training Accuracy: 20.985\n",
            "Validation Loss: 3.34384480859064, Validation Accuracy: 20.15\n",
            "[19/150]: Training Loss: 3.249339769363403, Training Accuracy: 21.955\n",
            "Validation Loss: 3.3408105813773576, Validation Accuracy: 20.75\n",
            "[20/150]: Training Loss: 3.2052097175598147, Training Accuracy: 22.84\n",
            "Validation Loss: 3.3127595497544404, Validation Accuracy: 21.29\n",
            "[21/150]: Training Loss: 3.150541979598999, Training Accuracy: 23.8475\n",
            "Validation Loss: 3.267914258750381, Validation Accuracy: 22.13\n",
            "[22/150]: Training Loss: 3.1069109004974367, Training Accuracy: 24.64\n",
            "Validation Loss: 3.2093709350391557, Validation Accuracy: 23.03\n",
            "[23/150]: Training Loss: 3.0725105766296386, Training Accuracy: 25.155\n",
            "Validation Loss: 3.2081045861456805, Validation Accuracy: 23.23\n",
            "[24/150]: Training Loss: 3.0264828220367432, Training Accuracy: 26.165\n",
            "Validation Loss: 3.153175331225061, Validation Accuracy: 23.9\n",
            "[25/150]: Training Loss: 2.9784529972076417, Training Accuracy: 27.0575\n",
            "Validation Loss: 3.120233716478773, Validation Accuracy: 24.62\n",
            "[26/150]: Training Loss: 2.9407661106109617, Training Accuracy: 27.7025\n",
            "Validation Loss: 3.122152067293787, Validation Accuracy: 25.03\n",
            "[27/150]: Training Loss: 2.9034343135833742, Training Accuracy: 28.395\n",
            "Validation Loss: 3.062598638473802, Validation Accuracy: 25.75\n",
            "[28/150]: Training Loss: 2.859911437988281, Training Accuracy: 29.1425\n",
            "Validation Loss: 3.0851597072212558, Validation Accuracy: 26.24\n",
            "[29/150]: Training Loss: 2.825396254348755, Training Accuracy: 29.9575\n",
            "Validation Loss: 3.0798455939930713, Validation Accuracy: 25.39\n",
            "[30/150]: Training Loss: 2.783854722213745, Training Accuracy: 30.46\n",
            "Validation Loss: 2.994018077850342, Validation Accuracy: 27.4\n",
            "[31/150]: Training Loss: 2.7530001544952394, Training Accuracy: 31.445\n",
            "Validation Loss: 3.023551480785297, Validation Accuracy: 26.3\n",
            "[32/150]: Training Loss: 2.715887685775757, Training Accuracy: 31.8725\n",
            "Validation Loss: 2.966492583037941, Validation Accuracy: 27.56\n",
            "[33/150]: Training Loss: 2.673046026611328, Training Accuracy: 32.72\n",
            "Validation Loss: 2.9745204934648646, Validation Accuracy: 27.99\n",
            "[34/150]: Training Loss: 2.6407437208175657, Training Accuracy: 33.34\n",
            "Validation Loss: 2.942354439170497, Validation Accuracy: 29.0\n",
            "[35/150]: Training Loss: 2.5946556980133058, Training Accuracy: 34.7025\n",
            "Validation Loss: 2.930390673837844, Validation Accuracy: 28.88\n",
            "[36/150]: Training Loss: 2.560257712173462, Training Accuracy: 35.2025\n",
            "Validation Loss: 2.9051667292406607, Validation Accuracy: 29.88\n",
            "[37/150]: Training Loss: 2.5238379081726072, Training Accuracy: 35.76\n",
            "Validation Loss: 2.890098687190159, Validation Accuracy: 29.33\n",
            "[38/150]: Training Loss: 2.486947275352478, Training Accuracy: 36.69\n",
            "Validation Loss: 2.9050150206134577, Validation Accuracy: 29.6\n",
            "[39/150]: Training Loss: 2.452709559249878, Training Accuracy: 37.475\n",
            "Validation Loss: 2.8899250182376544, Validation Accuracy: 29.65\n",
            "[40/150]: Training Loss: 2.4208646841049193, Training Accuracy: 37.9575\n",
            "Validation Loss: 2.9285842643421924, Validation Accuracy: 29.49\n",
            "[41/150]: Training Loss: 2.3780534410476686, Training Accuracy: 38.925\n",
            "Validation Loss: 2.896095122501349, Validation Accuracy: 30.27\n",
            "[42/150]: Training Loss: 2.3445595056533812, Training Accuracy: 39.4975\n",
            "Validation Loss: 2.903249968389037, Validation Accuracy: 29.49\n",
            "[43/150]: Training Loss: 2.3128848968505857, Training Accuracy: 40.2375\n",
            "Validation Loss: 2.8930906854617366, Validation Accuracy: 30.18\n",
            "[44/150]: Training Loss: 2.275460436248779, Training Accuracy: 40.965\n",
            "Validation Loss: 2.847154028096776, Validation Accuracy: 30.73\n",
            "[45/150]: Training Loss: 2.2384806400299073, Training Accuracy: 41.705\n",
            "Validation Loss: 2.898577917912963, Validation Accuracy: 30.18\n",
            "[46/150]: Training Loss: 2.214237283706665, Training Accuracy: 42.415\n",
            "Validation Loss: 2.8367908441337053, Validation Accuracy: 31.94\n",
            "[47/150]: Training Loss: 2.174029080581665, Training Accuracy: 43.2825\n",
            "Validation Loss: 2.8599718254842577, Validation Accuracy: 31.4\n",
            "[48/150]: Training Loss: 2.134048504257202, Training Accuracy: 44.0225\n",
            "Validation Loss: 2.8570211207031444, Validation Accuracy: 31.32\n",
            "[49/150]: Training Loss: 2.1011022747039796, Training Accuracy: 44.7675\n",
            "Validation Loss: 2.876888126324696, Validation Accuracy: 31.24\n",
            "[50/150]: Training Loss: 2.066174629211426, Training Accuracy: 45.84\n",
            "Validation Loss: 2.873898560833779, Validation Accuracy: 31.01\n",
            "[51/150]: Training Loss: 2.0310755935668947, Training Accuracy: 46.2775\n",
            "Validation Loss: 2.8654664003165666, Validation Accuracy: 31.98\n",
            "[52/150]: Training Loss: 1.9909400806427002, Training Accuracy: 47.45\n",
            "Validation Loss: 2.8746210936528103, Validation Accuracy: 31.69\n",
            "[53/150]: Training Loss: 1.9579231163024902, Training Accuracy: 48.0525\n",
            "Validation Loss: 2.8748430902031576, Validation Accuracy: 31.57\n",
            "[54/150]: Training Loss: 1.9230639179229736, Training Accuracy: 48.785\n",
            "Validation Loss: 2.910501542364716, Validation Accuracy: 31.56\n",
            "[55/150]: Training Loss: 1.8876561931610107, Training Accuracy: 49.645\n",
            "Validation Loss: 2.8805068404811203, Validation Accuracy: 32.02\n",
            "[56/150]: Training Loss: 1.8495587772369384, Training Accuracy: 50.57\n",
            "Validation Loss: 2.9215301510634695, Validation Accuracy: 31.68\n",
            "[57/150]: Training Loss: 1.8102108228683471, Training Accuracy: 51.2975\n",
            "Validation Loss: 2.926473318391545, Validation Accuracy: 32.35\n",
            "[58/150]: Training Loss: 1.7818908670425415, Training Accuracy: 52.1325\n",
            "Validation Loss: 2.9246792929947, Validation Accuracy: 32.57\n",
            "[59/150]: Training Loss: 1.7456034435272216, Training Accuracy: 52.775\n",
            "Validation Loss: 2.984062427168439, Validation Accuracy: 31.53\n",
            "[60/150]: Training Loss: 1.706142727279663, Training Accuracy: 53.955\n",
            "Validation Loss: 2.9781496843714623, Validation Accuracy: 32.57\n",
            "[61/150]: Training Loss: 1.6744635740280152, Training Accuracy: 54.59\n",
            "Validation Loss: 3.0356672569444982, Validation Accuracy: 31.58\n",
            "[62/150]: Training Loss: 1.6349090488433837, Training Accuracy: 55.5975\n",
            "Validation Loss: 3.0081513763233354, Validation Accuracy: 32.09\n",
            "[63/150]: Training Loss: 1.6007863130569457, Training Accuracy: 56.41\n",
            "Validation Loss: 3.032350327558578, Validation Accuracy: 32.3\n",
            "[64/150]: Training Loss: 1.5609112140655517, Training Accuracy: 57.235\n",
            "Validation Loss: 3.077729872077893, Validation Accuracy: 31.42\n",
            "[65/150]: Training Loss: 1.5253083936691285, Training Accuracy: 58.1475\n",
            "Validation Loss: 3.0732312840261278, Validation Accuracy: 32.72\n",
            "[66/150]: Training Loss: 1.4928287380218506, Training Accuracy: 59.1925\n",
            "Validation Loss: 3.0616249688871346, Validation Accuracy: 31.97\n",
            "[67/150]: Training Loss: 1.4535140877723693, Training Accuracy: 60.1225\n",
            "Validation Loss: 3.124178699627044, Validation Accuracy: 32.15\n",
            "[68/150]: Training Loss: 1.4196137544631957, Training Accuracy: 60.7675\n",
            "Validation Loss: 3.2008153435530935, Validation Accuracy: 31.3\n",
            "[69/150]: Training Loss: 1.3877691086769104, Training Accuracy: 61.4575\n",
            "Validation Loss: 3.1977471834535054, Validation Accuracy: 31.22\n",
            "[70/150]: Training Loss: 1.3564362874031066, Training Accuracy: 62.2125\n",
            "Validation Loss: 3.2483551836317512, Validation Accuracy: 31.49\n",
            "[71/150]: Training Loss: 1.3180213891029358, Training Accuracy: 63.6275\n",
            "Validation Loss: 3.3253093616218323, Validation Accuracy: 31.54\n",
            "[72/150]: Training Loss: 1.2782609523773194, Training Accuracy: 64.6325\n",
            "Validation Loss: 3.300645703722717, Validation Accuracy: 32.03\n",
            "[73/150]: Training Loss: 1.2435202094078064, Training Accuracy: 65.5975\n",
            "Validation Loss: 3.340803805430224, Validation Accuracy: 31.19\n",
            "[74/150]: Training Loss: 1.2111891516685487, Training Accuracy: 66.105\n",
            "Validation Loss: 3.3482626076716526, Validation Accuracy: 31.98\n",
            "[75/150]: Training Loss: 1.1782402634620666, Training Accuracy: 67.3425\n",
            "Validation Loss: 3.442917116128715, Validation Accuracy: 31.68\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 15.762403002210483, Test Accuracy: 12.36\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▄█▂▁▂▁▂▂▁▁▁▂▂▂▂▂▃▂▃▂▂▃▃▃▃▃▃▄▄▃▄▄▃▃▄▃▃▃▄▃</td></tr><tr><td>Test Loss</td><td>▃▁▄▄▆▇▇█▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>███▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.36</td></tr><tr><td>Test Loss</td><td>15.7624</td></tr><tr><td>Train Accuracy</td><td>67.3425</td></tr><tr><td>Train Loss</td><td>1.17824</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240611_235923-9i8aijvl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_002202-8lcpcbs2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605505518341064, Training Accuracy: 1.0675\n",
            "Validation Loss: 4.60469646514601, Validation Accuracy: 0.9\n",
            "[2/150]: Training Loss: 4.603742761993408, Training Accuracy: 1.0775\n",
            "Validation Loss: 4.602513228252435, Validation Accuracy: 0.97\n",
            "[3/150]: Training Loss: 4.60020831451416, Training Accuracy: 1.42\n",
            "Validation Loss: 4.596951505940432, Validation Accuracy: 1.39\n",
            "[4/150]: Training Loss: 4.590583048248291, Training Accuracy: 1.345\n",
            "Validation Loss: 4.579934718502555, Validation Accuracy: 1.81\n",
            "[5/150]: Training Loss: 4.522595316314697, Training Accuracy: 2.9\n",
            "Validation Loss: 4.390095902096694, Validation Accuracy: 3.43\n",
            "[6/150]: Training Loss: 4.228593465805054, Training Accuracy: 5.2625\n",
            "Validation Loss: 4.173950313762495, Validation Accuracy: 5.48\n",
            "[7/150]: Training Loss: 4.1090137573242185, Training Accuracy: 6.88\n",
            "Validation Loss: 4.087003700292794, Validation Accuracy: 7.44\n",
            "[8/150]: Training Loss: 4.035317427825928, Training Accuracy: 8.06\n",
            "Validation Loss: 4.015521998618059, Validation Accuracy: 8.52\n",
            "[9/150]: Training Loss: 3.960421589279175, Training Accuracy: 9.445\n",
            "Validation Loss: 3.9580009849208175, Validation Accuracy: 9.3\n",
            "[10/150]: Training Loss: 3.8591443000793455, Training Accuracy: 11.34\n",
            "Validation Loss: 3.84393062105604, Validation Accuracy: 11.61\n",
            "[11/150]: Training Loss: 3.7639447425842287, Training Accuracy: 12.9725\n",
            "Validation Loss: 3.7741037219952625, Validation Accuracy: 12.76\n",
            "[12/150]: Training Loss: 3.6964004222869873, Training Accuracy: 14.225\n",
            "Validation Loss: 3.6935869903321477, Validation Accuracy: 14.02\n",
            "[13/150]: Training Loss: 3.6246248401641847, Training Accuracy: 15.4325\n",
            "Validation Loss: 3.6313245053503924, Validation Accuracy: 15.35\n",
            "[14/150]: Training Loss: 3.5586987380981445, Training Accuracy: 16.58\n",
            "Validation Loss: 3.570704687932494, Validation Accuracy: 16.63\n",
            "[15/150]: Training Loss: 3.492145662689209, Training Accuracy: 17.56\n",
            "Validation Loss: 3.5174384117126465, Validation Accuracy: 17.05\n",
            "[16/150]: Training Loss: 3.4223767150878905, Training Accuracy: 18.875\n",
            "Validation Loss: 3.4360159157188077, Validation Accuracy: 18.52\n",
            "[17/150]: Training Loss: 3.3623727890014647, Training Accuracy: 19.63\n",
            "Validation Loss: 3.3825773327213944, Validation Accuracy: 19.78\n",
            "[18/150]: Training Loss: 3.3074194034576414, Training Accuracy: 20.8975\n",
            "Validation Loss: 3.3404667316728336, Validation Accuracy: 20.19\n",
            "[19/150]: Training Loss: 3.251063732147217, Training Accuracy: 21.8975\n",
            "Validation Loss: 3.312105529627223, Validation Accuracy: 20.9\n",
            "[20/150]: Training Loss: 3.204967420578003, Training Accuracy: 22.7225\n",
            "Validation Loss: 3.2530917027953326, Validation Accuracy: 22.31\n",
            "[21/150]: Training Loss: 3.15532322807312, Training Accuracy: 23.64\n",
            "Validation Loss: 3.229210142876692, Validation Accuracy: 22.45\n",
            "[22/150]: Training Loss: 3.1103267768859864, Training Accuracy: 24.38\n",
            "Validation Loss: 3.213347544336015, Validation Accuracy: 23.38\n",
            "[23/150]: Training Loss: 3.0626929641723635, Training Accuracy: 25.55\n",
            "Validation Loss: 3.181753307391124, Validation Accuracy: 24.04\n",
            "[24/150]: Training Loss: 3.01508925819397, Training Accuracy: 26.1675\n",
            "Validation Loss: 3.159736381214895, Validation Accuracy: 24.07\n",
            "[25/150]: Training Loss: 2.977297193527222, Training Accuracy: 26.95\n",
            "Validation Loss: 3.139521881273598, Validation Accuracy: 24.65\n",
            "[26/150]: Training Loss: 2.9348321487426756, Training Accuracy: 27.76\n",
            "Validation Loss: 3.129030877617514, Validation Accuracy: 25.02\n",
            "[27/150]: Training Loss: 2.892203674316406, Training Accuracy: 28.71\n",
            "Validation Loss: 3.1089744279339055, Validation Accuracy: 24.88\n",
            "[28/150]: Training Loss: 2.8514965145111084, Training Accuracy: 29.41\n",
            "Validation Loss: 3.0390360476864373, Validation Accuracy: 26.37\n",
            "[29/150]: Training Loss: 2.8064930957794187, Training Accuracy: 30.3275\n",
            "Validation Loss: 3.0866621254356046, Validation Accuracy: 26.25\n",
            "[30/150]: Training Loss: 2.771508701324463, Training Accuracy: 30.8325\n",
            "Validation Loss: 3.034489528388734, Validation Accuracy: 26.79\n",
            "[31/150]: Training Loss: 2.726985428237915, Training Accuracy: 32.06\n",
            "Validation Loss: 2.994590279403006, Validation Accuracy: 27.49\n",
            "[32/150]: Training Loss: 2.693068378448486, Training Accuracy: 32.6375\n",
            "Validation Loss: 2.991791993949064, Validation Accuracy: 27.57\n",
            "[33/150]: Training Loss: 2.6538521224975584, Training Accuracy: 33.305\n",
            "Validation Loss: 2.9930253712234984, Validation Accuracy: 27.59\n",
            "[34/150]: Training Loss: 2.6168819108963013, Training Accuracy: 33.9675\n",
            "Validation Loss: 2.9458029012011875, Validation Accuracy: 28.63\n",
            "[35/150]: Training Loss: 2.5724296060562133, Training Accuracy: 34.885\n",
            "Validation Loss: 2.9706625437280936, Validation Accuracy: 28.37\n",
            "[36/150]: Training Loss: 2.532205513381958, Training Accuracy: 35.7275\n",
            "Validation Loss: 3.0205048026552626, Validation Accuracy: 27.62\n",
            "[37/150]: Training Loss: 2.501378486442566, Training Accuracy: 36.655\n",
            "Validation Loss: 2.9459367466580337, Validation Accuracy: 29.16\n",
            "[38/150]: Training Loss: 2.4599771045684813, Training Accuracy: 37.265\n",
            "Validation Loss: 2.9162613555883907, Validation Accuracy: 29.42\n",
            "[39/150]: Training Loss: 2.416532469558716, Training Accuracy: 38.265\n",
            "Validation Loss: 2.9226647676176327, Validation Accuracy: 29.71\n",
            "[40/150]: Training Loss: 2.377360425758362, Training Accuracy: 39.1\n",
            "Validation Loss: 2.912419487716286, Validation Accuracy: 30.24\n",
            "[41/150]: Training Loss: 2.3416698053359983, Training Accuracy: 39.7725\n",
            "Validation Loss: 2.9336505536061184, Validation Accuracy: 29.72\n",
            "[42/150]: Training Loss: 2.302257305908203, Training Accuracy: 40.6025\n",
            "Validation Loss: 2.9164519552971906, Validation Accuracy: 30.29\n",
            "[43/150]: Training Loss: 2.2648201442718507, Training Accuracy: 41.4425\n",
            "Validation Loss: 2.917926338068239, Validation Accuracy: 30.33\n",
            "[44/150]: Training Loss: 2.2238695373535156, Training Accuracy: 42.1875\n",
            "Validation Loss: 2.920909085091512, Validation Accuracy: 30.59\n",
            "[45/150]: Training Loss: 2.186175981903076, Training Accuracy: 43.1875\n",
            "Validation Loss: 2.979639395027404, Validation Accuracy: 29.65\n",
            "[46/150]: Training Loss: 2.1421424005508425, Training Accuracy: 44.26\n",
            "Validation Loss: 2.955421671745883, Validation Accuracy: 29.75\n",
            "[47/150]: Training Loss: 2.1072659519195556, Training Accuracy: 44.7325\n",
            "Validation Loss: 2.9603501687383957, Validation Accuracy: 30.38\n",
            "[48/150]: Training Loss: 2.0704134420394897, Training Accuracy: 45.5625\n",
            "Validation Loss: 2.9289260366160397, Validation Accuracy: 30.82\n",
            "[49/150]: Training Loss: 2.0253924531936645, Training Accuracy: 46.8725\n",
            "Validation Loss: 2.9537550051500845, Validation Accuracy: 30.64\n",
            "[50/150]: Training Loss: 1.9894214233398437, Training Accuracy: 47.5425\n",
            "Validation Loss: 2.992744015280608, Validation Accuracy: 30.54\n",
            "[51/150]: Training Loss: 1.9478775398254395, Training Accuracy: 48.1625\n",
            "Validation Loss: 3.0440484505550116, Validation Accuracy: 30.87\n",
            "[52/150]: Training Loss: 1.9146845523834228, Training Accuracy: 48.9825\n",
            "Validation Loss: 2.9890038989911414, Validation Accuracy: 31.24\n",
            "[53/150]: Training Loss: 1.8723485668182374, Training Accuracy: 50.01\n",
            "Validation Loss: 2.993290390937951, Validation Accuracy: 31.22\n",
            "[54/150]: Training Loss: 1.8348793195724487, Training Accuracy: 50.52\n",
            "Validation Loss: 3.0035920021640266, Validation Accuracy: 31.61\n",
            "[55/150]: Training Loss: 1.7904879375457763, Training Accuracy: 52.175\n",
            "Validation Loss: 3.0537699574877504, Validation Accuracy: 30.68\n",
            "[56/150]: Training Loss: 1.7518022777557374, Training Accuracy: 52.58\n",
            "Validation Loss: 3.0826165934277188, Validation Accuracy: 30.36\n",
            "[57/150]: Training Loss: 1.723713356781006, Training Accuracy: 53.2725\n",
            "Validation Loss: 3.0921939679771473, Validation Accuracy: 30.79\n",
            "[58/150]: Training Loss: 1.673542138671875, Training Accuracy: 54.7525\n",
            "Validation Loss: 3.114953031965122, Validation Accuracy: 30.97\n",
            "[59/150]: Training Loss: 1.6370127866744995, Training Accuracy: 55.3475\n",
            "Validation Loss: 3.1347598710637183, Validation Accuracy: 31.13\n",
            "[60/150]: Training Loss: 1.595728307723999, Training Accuracy: 56.3775\n",
            "Validation Loss: 3.211446317138186, Validation Accuracy: 30.86\n",
            "[61/150]: Training Loss: 1.5595929719924926, Training Accuracy: 57.445\n",
            "Validation Loss: 3.1916901260424573, Validation Accuracy: 31.69\n",
            "[62/150]: Training Loss: 1.5153404804229735, Training Accuracy: 58.605\n",
            "Validation Loss: 3.2764444821959087, Validation Accuracy: 30.21\n",
            "[63/150]: Training Loss: 1.4795546808242799, Training Accuracy: 59.165\n",
            "Validation Loss: 3.2651574581292024, Validation Accuracy: 31.32\n",
            "[64/150]: Training Loss: 1.443065357875824, Training Accuracy: 60.3525\n",
            "Validation Loss: 3.2850031807164477, Validation Accuracy: 30.88\n",
            "[65/150]: Training Loss: 1.3952457666397096, Training Accuracy: 61.3125\n",
            "Validation Loss: 3.334014499263399, Validation Accuracy: 30.51\n",
            "[66/150]: Training Loss: 1.3616252402305602, Training Accuracy: 62.2875\n",
            "Validation Loss: 3.3781587804199025, Validation Accuracy: 30.85\n",
            "[67/150]: Training Loss: 1.3209700021743775, Training Accuracy: 63.1475\n",
            "Validation Loss: 3.4392695958447304, Validation Accuracy: 30.92\n",
            "[68/150]: Training Loss: 1.2754105567932128, Training Accuracy: 64.4\n",
            "Validation Loss: 3.487312679837464, Validation Accuracy: 30.89\n",
            "[69/150]: Training Loss: 1.2461662047386168, Training Accuracy: 65.2125\n",
            "Validation Loss: 3.470762025019166, Validation Accuracy: 30.79\n",
            "[70/150]: Training Loss: 1.2068843828201294, Training Accuracy: 66.345\n",
            "Validation Loss: 3.5463279022532666, Validation Accuracy: 30.57\n",
            "[71/150]: Training Loss: 1.174416847038269, Training Accuracy: 66.87\n",
            "Validation Loss: 3.5970414428953914, Validation Accuracy: 30.5\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.28561769473325, Test Accuracy: 11.15\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▆▁▃▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▃▃▄▄▃▃▄▄▄▄▄▄</td></tr><tr><td>Test Loss</td><td>▂▁▅▄▆▆▆▇▇▆▆▇█▇██▇█████▇▇▇███████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>███▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>11.15</td></tr><tr><td>Test Loss</td><td>17.28562</td></tr><tr><td>Train Accuracy</td><td>66.87</td></tr><tr><td>Train Loss</td><td>1.17442</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_002202-8lcpcbs2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_002809-yufpefeq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">learning_rate=0.01 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.394053651046753, Training Accuracy: 3.235\n",
            "Validation Loss: 4.1179144488778086, Validation Accuracy: 6.51\n",
            "[2/150]: Training Loss: 3.940752759170532, Training Accuracy: 9.1825\n",
            "Validation Loss: 3.793641860318032, Validation Accuracy: 10.96\n",
            "[3/150]: Training Loss: 3.607163610458374, Training Accuracy: 14.85\n",
            "Validation Loss: 3.445422892357893, Validation Accuracy: 18.4\n",
            "[4/150]: Training Loss: 3.32619926071167, Training Accuracy: 19.315\n",
            "Validation Loss: 3.202780070578217, Validation Accuracy: 21.55\n",
            "[5/150]: Training Loss: 3.0974891372680666, Training Accuracy: 23.9725\n",
            "Validation Loss: 3.0388081802684033, Validation Accuracy: 24.97\n",
            "[6/150]: Training Loss: 2.901975968170166, Training Accuracy: 27.42\n",
            "Validation Loss: 3.0498315498327755, Validation Accuracy: 25.89\n",
            "[7/150]: Training Loss: 2.72861491394043, Training Accuracy: 31.1425\n",
            "Validation Loss: 2.817266490049423, Validation Accuracy: 30.26\n",
            "[8/150]: Training Loss: 2.565713974761963, Training Accuracy: 33.8575\n",
            "Validation Loss: 2.7873742094465124, Validation Accuracy: 30.1\n",
            "[9/150]: Training Loss: 2.394580401802063, Training Accuracy: 37.745\n",
            "Validation Loss: 2.714815883879449, Validation Accuracy: 32.43\n",
            "[10/150]: Training Loss: 2.2325665201187133, Training Accuracy: 41.275\n",
            "Validation Loss: 2.6796328748107716, Validation Accuracy: 33.37\n",
            "[11/150]: Training Loss: 2.0732334920883178, Training Accuracy: 44.825\n",
            "Validation Loss: 2.743416508291937, Validation Accuracy: 33.16\n",
            "[12/150]: Training Loss: 1.9020709432601928, Training Accuracy: 48.52\n",
            "Validation Loss: 2.761919692823082, Validation Accuracy: 34.09\n",
            "[13/150]: Training Loss: 1.723027162361145, Training Accuracy: 52.47\n",
            "Validation Loss: 2.781366317894808, Validation Accuracy: 33.87\n",
            "[14/150]: Training Loss: 1.5519161633491516, Training Accuracy: 56.5925\n",
            "Validation Loss: 2.8901124114443544, Validation Accuracy: 32.73\n",
            "[15/150]: Training Loss: 1.3848727501869202, Training Accuracy: 60.6225\n",
            "Validation Loss: 3.061296709024223, Validation Accuracy: 32.5\n",
            "[16/150]: Training Loss: 1.2385452840805053, Training Accuracy: 64.0375\n",
            "Validation Loss: 3.1685607524434474, Validation Accuracy: 33.0\n",
            "[17/150]: Training Loss: 1.0766600145339966, Training Accuracy: 68.1675\n",
            "Validation Loss: 3.470290554556877, Validation Accuracy: 32.52\n",
            "[18/150]: Training Loss: 0.953560617685318, Training Accuracy: 71.2375\n",
            "Validation Loss: 3.737919813508441, Validation Accuracy: 32.63\n",
            "[19/150]: Training Loss: 0.8452390188217163, Training Accuracy: 74.1975\n",
            "Validation Loss: 3.9338995074010956, Validation Accuracy: 32.13\n",
            "[20/150]: Training Loss: 0.7454726006031036, Training Accuracy: 76.935\n",
            "Validation Loss: 4.16999766325495, Validation Accuracy: 32.08\n",
            "[21/150]: Training Loss: 0.6607641342639923, Training Accuracy: 79.455\n",
            "Validation Loss: 4.340858131457287, Validation Accuracy: 31.19\n",
            "[22/150]: Training Loss: 0.5830736963987351, Training Accuracy: 81.7975\n",
            "Validation Loss: 4.7213960696177875, Validation Accuracy: 32.35\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 31.791706814128123, Test Accuracy: 14.4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▂▃█▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇███████</td></tr><tr><td>Test Loss</td><td>▁▅█▇█▇██▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇███▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▅▅▅▄▄▄▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>14.4</td></tr><tr><td>Test Loss</td><td>31.79171</td></tr><tr><td>Train Accuracy</td><td>81.7975</td></tr><tr><td>Train Loss</td><td>0.58307</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_002809-yufpefeq/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_003027-5ijvpyn3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.452998904800415, Training Accuracy: 2.615\n",
            "Validation Loss: 4.1346032179085315, Validation Accuracy: 5.28\n",
            "[2/150]: Training Loss: 3.9527258255004885, Training Accuracy: 8.88\n",
            "Validation Loss: 3.7435999432946465, Validation Accuracy: 11.55\n",
            "[3/150]: Training Loss: 3.6381911922454835, Training Accuracy: 14.3725\n",
            "Validation Loss: 3.50478922181828, Validation Accuracy: 15.58\n",
            "[4/150]: Training Loss: 3.3785652015686036, Training Accuracy: 18.865\n",
            "Validation Loss: 3.3451961089091697, Validation Accuracy: 19.0\n",
            "[5/150]: Training Loss: 3.17810930519104, Training Accuracy: 22.375\n",
            "Validation Loss: 3.1223374703887163, Validation Accuracy: 23.6\n",
            "[6/150]: Training Loss: 3.0013810291290284, Training Accuracy: 25.565\n",
            "Validation Loss: 3.015145599462424, Validation Accuracy: 25.56\n",
            "[7/150]: Training Loss: 2.8544215950012206, Training Accuracy: 28.7175\n",
            "Validation Loss: 2.917889818264421, Validation Accuracy: 28.04\n",
            "[8/150]: Training Loss: 2.6971351528167724, Training Accuracy: 31.3825\n",
            "Validation Loss: 2.8436176351680875, Validation Accuracy: 29.6\n",
            "[9/150]: Training Loss: 2.567851602554321, Training Accuracy: 34.1025\n",
            "Validation Loss: 2.748332465530201, Validation Accuracy: 31.45\n",
            "[10/150]: Training Loss: 2.422238304901123, Training Accuracy: 37.085\n",
            "Validation Loss: 2.7193879473740887, Validation Accuracy: 32.08\n",
            "[11/150]: Training Loss: 2.3000989530563354, Training Accuracy: 39.695\n",
            "Validation Loss: 2.736810536141608, Validation Accuracy: 32.35\n",
            "[12/150]: Training Loss: 2.170335920906067, Training Accuracy: 42.5\n",
            "Validation Loss: 2.668315727239961, Validation Accuracy: 34.0\n",
            "[13/150]: Training Loss: 2.037977534675598, Training Accuracy: 45.47\n",
            "Validation Loss: 2.6606684786498924, Validation Accuracy: 34.72\n",
            "[14/150]: Training Loss: 1.9109795570373536, Training Accuracy: 48.245\n",
            "Validation Loss: 2.677434118690005, Validation Accuracy: 34.85\n",
            "[15/150]: Training Loss: 1.7840767404556275, Training Accuracy: 50.9475\n",
            "Validation Loss: 2.6786925458604363, Validation Accuracy: 35.46\n",
            "[16/150]: Training Loss: 1.6501886499404907, Training Accuracy: 54.325\n",
            "Validation Loss: 2.749260063383989, Validation Accuracy: 34.73\n",
            "[17/150]: Training Loss: 1.5220398645401, Training Accuracy: 57.045\n",
            "Validation Loss: 2.9064030396710536, Validation Accuracy: 34.13\n",
            "[18/150]: Training Loss: 1.3921052120208741, Training Accuracy: 60.4275\n",
            "Validation Loss: 2.978949681968446, Validation Accuracy: 33.67\n",
            "[19/150]: Training Loss: 1.2853214281082153, Training Accuracy: 62.9225\n",
            "Validation Loss: 3.0623086941470006, Validation Accuracy: 33.54\n",
            "[20/150]: Training Loss: 1.1686985822677611, Training Accuracy: 65.5875\n",
            "Validation Loss: 3.099342126755198, Validation Accuracy: 34.34\n",
            "[21/150]: Training Loss: 1.0535273086547852, Training Accuracy: 68.77\n",
            "Validation Loss: 3.2730220791640554, Validation Accuracy: 32.71\n",
            "[22/150]: Training Loss: 0.9473227613449097, Training Accuracy: 71.6425\n",
            "Validation Loss: 3.5567993069909942, Validation Accuracy: 33.18\n",
            "[23/150]: Training Loss: 0.8736372189521789, Training Accuracy: 73.5275\n",
            "Validation Loss: 3.4931609501504592, Validation Accuracy: 33.71\n",
            "[24/150]: Training Loss: 0.7797131684780121, Training Accuracy: 76.18\n",
            "Validation Loss: 3.6084122536288703, Validation Accuracy: 31.79\n",
            "[25/150]: Training Loss: 0.72144877743721, Training Accuracy: 77.925\n",
            "Validation Loss: 3.6706639156220064, Validation Accuracy: 33.34\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.253872677019448, Test Accuracy: 18.45\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▄█▄▅▃▄▄▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>▁▂▆▄▃▅▆▇▇▆▆▇▇▇███▇▇▇██▇▇█▇██████████████</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▆▆▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>18.45</td></tr><tr><td>Test Loss</td><td>17.25387</td></tr><tr><td>Train Accuracy</td><td>77.925</td></tr><tr><td>Train Loss</td><td>0.72145</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_003027-5ijvpyn3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_003346-pvvd2my8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">learning_rate=0.01 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.436210793685913, Training Accuracy: 2.8025\n",
            "Validation Loss: 4.1512272403498365, Validation Accuracy: 5.38\n",
            "[2/150]: Training Loss: 3.943741687011719, Training Accuracy: 9.175\n",
            "Validation Loss: 3.791590502307673, Validation Accuracy: 11.54\n",
            "[3/150]: Training Loss: 3.6135140613555907, Training Accuracy: 14.57\n",
            "Validation Loss: 3.473675949558331, Validation Accuracy: 17.5\n",
            "[4/150]: Training Loss: 3.3465395004272462, Training Accuracy: 19.22\n",
            "Validation Loss: 3.3301091406755385, Validation Accuracy: 19.19\n",
            "[5/150]: Training Loss: 3.1310076709747316, Training Accuracy: 22.94\n",
            "Validation Loss: 3.0678081117617855, Validation Accuracy: 24.65\n",
            "[6/150]: Training Loss: 2.9402838905334474, Training Accuracy: 26.4875\n",
            "Validation Loss: 2.9766739310732313, Validation Accuracy: 25.68\n",
            "[7/150]: Training Loss: 2.7704892574310302, Training Accuracy: 29.855\n",
            "Validation Loss: 2.8771827342403924, Validation Accuracy: 28.79\n",
            "[8/150]: Training Loss: 2.6034393648147582, Training Accuracy: 33.84\n",
            "Validation Loss: 2.7646109807263515, Validation Accuracy: 31.02\n",
            "[9/150]: Training Loss: 2.436837389945984, Training Accuracy: 37.1175\n",
            "Validation Loss: 2.731329696193622, Validation Accuracy: 32.37\n",
            "[10/150]: Training Loss: 2.273189482879639, Training Accuracy: 40.3275\n",
            "Validation Loss: 2.663352646645467, Validation Accuracy: 33.62\n",
            "[11/150]: Training Loss: 2.1113974294662476, Training Accuracy: 44.0125\n",
            "Validation Loss: 2.70243866884025, Validation Accuracy: 33.48\n",
            "[12/150]: Training Loss: 1.9719651878356934, Training Accuracy: 46.755\n",
            "Validation Loss: 2.7540456124931385, Validation Accuracy: 34.46\n",
            "[13/150]: Training Loss: 1.8135078485488891, Training Accuracy: 50.6725\n",
            "Validation Loss: 2.7649777801173507, Validation Accuracy: 34.67\n",
            "[14/150]: Training Loss: 1.663066688156128, Training Accuracy: 53.855\n",
            "Validation Loss: 2.8507347205641924, Validation Accuracy: 34.61\n",
            "[15/150]: Training Loss: 1.5029290641784667, Training Accuracy: 57.7575\n",
            "Validation Loss: 2.961932021341506, Validation Accuracy: 33.61\n",
            "[16/150]: Training Loss: 1.3492597907066346, Training Accuracy: 61.345\n",
            "Validation Loss: 3.0608204777833, Validation Accuracy: 33.71\n",
            "[17/150]: Training Loss: 1.2147304633140563, Training Accuracy: 64.7325\n",
            "Validation Loss: 3.1523648325804694, Validation Accuracy: 33.57\n",
            "[18/150]: Training Loss: 1.0741954045295716, Training Accuracy: 68.3375\n",
            "Validation Loss: 3.4972750517972715, Validation Accuracy: 32.75\n",
            "[19/150]: Training Loss: 0.9752286433696746, Training Accuracy: 70.7775\n",
            "Validation Loss: 3.703600254787761, Validation Accuracy: 32.29\n",
            "[20/150]: Training Loss: 0.8703240002632141, Training Accuracy: 73.66\n",
            "Validation Loss: 3.6860399884023485, Validation Accuracy: 32.6\n",
            "[21/150]: Training Loss: 0.7578078193187714, Training Accuracy: 76.6025\n",
            "Validation Loss: 4.062916931832672, Validation Accuracy: 31.29\n",
            "[22/150]: Training Loss: 0.673084812450409, Training Accuracy: 79.0375\n",
            "Validation Loss: 4.114260547480006, Validation Accuracy: 31.62\n",
            "[23/150]: Training Loss: 0.6178978152275085, Training Accuracy: 80.77\n",
            "Validation Loss: 4.332119194565306, Validation Accuracy: 32.24\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 24.731220123874156, Test Accuracy: 17.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▆▁▅▆▇█▆▆▆▇▇▆▇▇▇▇▇████████▇██▇▇▇▇███████</td></tr><tr><td>Test Loss</td><td>▁▄▆▅▅▅▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>17.1</td></tr><tr><td>Test Loss</td><td>24.73122</td></tr><tr><td>Train Accuracy</td><td>80.77</td></tr><tr><td>Train Loss</td><td>0.6179</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_003346-pvvd2my8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "  for wd in weight_decays:\n",
        "\n",
        "    print('='*50)\n",
        "    print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "    print('='*50)\n",
        "\n",
        "    hyperparameters = {'learning_rate': lr,\n",
        "                       'weight_decay' : wd\n",
        "                       }\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(num_epochs, model, train_loader, validation_loader, test_loader, optimizer, scheduler, criterion, device, 'SGDM-HyperParameterTuning', hyperparameters=hyperparameters, is_wandb = True, n_epochs_stop = 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9dca98d1b8c402db8fa03f1354a051b",
            "3445c5fe76514de0b6b9cc31200c8544",
            "eafc1e77174c4758a3780b481d694ae0",
            "e6a773393e084de9a117fbbf43b7a59e",
            "b0748d32c99741d39b18512400e07f30",
            "dc43eb867d6b446cb0cb8e5debae57e7",
            "6c30f9a9e6c44d78ad39f43a5f11a6d0",
            "81500a36ef5e4a9e9b36aef01bee3697"
          ]
        },
        "id": "i9Q1MpZmVAUp",
        "outputId": "00a406f8-47bc-405c-d5e8-e10713b7f5fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_013938-4i9h8t3n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.089274020146226, Training Accuracy: 7.336\n",
            "Validation Loss: 3.675565988394865, Validation Accuracy: 11.94\n",
            "[2/150]: Training Loss: 3.4894355224526445, Training Accuracy: 16.328\n",
            "Validation Loss: 3.239326788361665, Validation Accuracy: 21.43\n",
            "[3/150]: Training Loss: 3.1558719864281852, Training Accuracy: 21.82\n",
            "Validation Loss: 2.9393957374961515, Validation Accuracy: 26.07\n",
            "[4/150]: Training Loss: 2.9186559430778485, Training Accuracy: 26.722\n",
            "Validation Loss: 2.7213429053118277, Validation Accuracy: 30.34\n",
            "[5/150]: Training Loss: 2.7546427048685604, Training Accuracy: 29.83\n",
            "Validation Loss: 2.6445619574018346, Validation Accuracy: 32.87\n",
            "[6/150]: Training Loss: 2.6314107673552334, Training Accuracy: 32.316\n",
            "Validation Loss: 2.463979342940507, Validation Accuracy: 35.97\n",
            "[7/150]: Training Loss: 2.525907842399519, Training Accuracy: 34.748\n",
            "Validation Loss: 2.402360181899587, Validation Accuracy: 37.43\n",
            "[8/150]: Training Loss: 2.4479937202790203, Training Accuracy: 36.512\n",
            "Validation Loss: 2.4091407804732112, Validation Accuracy: 36.77\n",
            "[9/150]: Training Loss: 2.3761757938453303, Training Accuracy: 37.836\n",
            "Validation Loss: 2.266651909062817, Validation Accuracy: 40.12\n",
            "[10/150]: Training Loss: 2.3189178927780114, Training Accuracy: 39.182\n",
            "Validation Loss: 2.248874021943208, Validation Accuracy: 40.42\n",
            "[11/150]: Training Loss: 2.2658593403104015, Training Accuracy: 40.134\n",
            "Validation Loss: 2.259856101054295, Validation Accuracy: 40.67\n",
            "[12/150]: Training Loss: 2.2226978584628583, Training Accuracy: 41.142\n",
            "Validation Loss: 2.1725807235499097, Validation Accuracy: 42.45\n",
            "[13/150]: Training Loss: 2.1647636545893483, Training Accuracy: 42.432\n",
            "Validation Loss: 2.1585155209158637, Validation Accuracy: 43.43\n",
            "[14/150]: Training Loss: 2.130936350206585, Training Accuracy: 43.382\n",
            "Validation Loss: 2.099344393250289, Validation Accuracy: 44.47\n",
            "[15/150]: Training Loss: 2.100127648514555, Training Accuracy: 44.078\n",
            "Validation Loss: 2.1766397307632834, Validation Accuracy: 43.16\n",
            "[16/150]: Training Loss: 2.0619241555633447, Training Accuracy: 44.864\n",
            "Validation Loss: 2.086525283042033, Validation Accuracy: 45.45\n",
            "[17/150]: Training Loss: 2.030578180042374, Training Accuracy: 45.488\n",
            "Validation Loss: 2.056034764666466, Validation Accuracy: 45.56\n",
            "[18/150]: Training Loss: 2.0153322762540538, Training Accuracy: 45.894\n",
            "Validation Loss: 2.0836284441553103, Validation Accuracy: 45.49\n",
            "[19/150]: Training Loss: 1.9813076870520707, Training Accuracy: 46.512\n",
            "Validation Loss: 2.123422172418825, Validation Accuracy: 44.8\n",
            "[20/150]: Training Loss: 1.9613309851692766, Training Accuracy: 47.156\n",
            "Validation Loss: 2.0666351356324117, Validation Accuracy: 45.67\n",
            "[21/150]: Training Loss: 1.9383105931379605, Training Accuracy: 47.68\n",
            "Validation Loss: 2.002842481728572, Validation Accuracy: 47.53\n",
            "[22/150]: Training Loss: 1.9150681045963942, Training Accuracy: 48.088\n",
            "Validation Loss: 2.0622900238462316, Validation Accuracy: 47.17\n",
            "[23/150]: Training Loss: 1.893286463854563, Training Accuracy: 48.534\n",
            "Validation Loss: 2.00721144600279, Validation Accuracy: 46.89\n",
            "[24/150]: Training Loss: 1.890704987908873, Training Accuracy: 48.7\n",
            "Validation Loss: 2.038584551993449, Validation Accuracy: 46.81\n",
            "[25/150]: Training Loss: 1.864747319989802, Training Accuracy: 49.254\n",
            "Validation Loss: 2.0571977568280166, Validation Accuracy: 46.35\n",
            "[26/150]: Training Loss: 1.851232278225062, Training Accuracy: 49.578\n",
            "Validation Loss: 2.067047737206623, Validation Accuracy: 45.89\n",
            "[27/150]: Training Loss: 1.8424793141882132, Training Accuracy: 49.854\n",
            "Validation Loss: 1.9625371656600077, Validation Accuracy: 48.1\n",
            "[28/150]: Training Loss: 1.8046449944186393, Training Accuracy: 50.832\n",
            "Validation Loss: 2.0106217762467207, Validation Accuracy: 47.7\n",
            "[29/150]: Training Loss: 1.8060023488900852, Training Accuracy: 50.666\n",
            "Validation Loss: 1.972709655002424, Validation Accuracy: 48.73\n",
            "[30/150]: Training Loss: 1.794560846770206, Training Accuracy: 50.516\n",
            "Validation Loss: 1.9357355255989512, Validation Accuracy: 49.77\n",
            "[31/150]: Training Loss: 1.7700339468848674, Training Accuracy: 51.572\n",
            "Validation Loss: 2.0069477284789845, Validation Accuracy: 47.09\n",
            "[32/150]: Training Loss: 1.760896964146353, Training Accuracy: 51.7\n",
            "Validation Loss: 1.9989952729765776, Validation Accuracy: 48.32\n",
            "[33/150]: Training Loss: 1.7410227035927346, Training Accuracy: 52.406\n",
            "Validation Loss: 1.912184556578375, Validation Accuracy: 50.02\n",
            "[34/150]: Training Loss: 1.7288355792269987, Training Accuracy: 52.308\n",
            "Validation Loss: 1.960264290973639, Validation Accuracy: 49.04\n",
            "[35/150]: Training Loss: 1.726897613929056, Training Accuracy: 52.332\n",
            "Validation Loss: 1.9354495113822305, Validation Accuracy: 49.72\n",
            "[36/150]: Training Loss: 1.7120373965529225, Training Accuracy: 52.802\n",
            "Validation Loss: 1.9664037690800467, Validation Accuracy: 48.71\n",
            "[37/150]: Training Loss: 1.693096386502161, Training Accuracy: 53.136\n",
            "Validation Loss: 2.0150347925295495, Validation Accuracy: 47.45\n",
            "[38/150]: Training Loss: 1.6896419387949093, Training Accuracy: 53.464\n",
            "Validation Loss: 1.8958269729735746, Validation Accuracy: 50.19\n",
            "[39/150]: Training Loss: 1.6746401542897724, Training Accuracy: 53.896\n",
            "Validation Loss: 1.8924665306783786, Validation Accuracy: 50.21\n",
            "[40/150]: Training Loss: 1.658155962481828, Training Accuracy: 54.248\n",
            "Validation Loss: 2.013761671485415, Validation Accuracy: 47.68\n",
            "[41/150]: Training Loss: 1.6497482628468663, Training Accuracy: 54.48\n",
            "Validation Loss: 1.9099182338471625, Validation Accuracy: 49.93\n",
            "[42/150]: Training Loss: 1.640857491423102, Training Accuracy: 54.522\n",
            "Validation Loss: 1.9500497716247656, Validation Accuracy: 48.99\n",
            "[43/150]: Training Loss: 1.627800954272375, Training Accuracy: 54.828\n",
            "Validation Loss: 1.8859608940258148, Validation Accuracy: 50.08\n",
            "[44/150]: Training Loss: 1.6115469687125261, Training Accuracy: 55.468\n",
            "Validation Loss: 1.8382089783431619, Validation Accuracy: 51.49\n",
            "[45/150]: Training Loss: 1.5990354193141088, Training Accuracy: 55.408\n",
            "Validation Loss: 1.9672614282863155, Validation Accuracy: 49.18\n",
            "[46/150]: Training Loss: 1.597626144090272, Training Accuracy: 55.548\n",
            "Validation Loss: 1.8989077024399095, Validation Accuracy: 50.63\n",
            "[47/150]: Training Loss: 1.583931565284729, Training Accuracy: 55.81\n",
            "Validation Loss: 1.9013854675232225, Validation Accuracy: 50.7\n",
            "[48/150]: Training Loss: 1.5654289053224237, Training Accuracy: 56.032\n",
            "Validation Loss: 1.9721670173535681, Validation Accuracy: 49.36\n",
            "[49/150]: Training Loss: 1.5542657918789808, Training Accuracy: 56.446\n",
            "Validation Loss: 1.9395824830243542, Validation Accuracy: 49.82\n",
            "[50/150]: Training Loss: 1.5429580295482255, Training Accuracy: 56.698\n",
            "Validation Loss: 1.9366691735140078, Validation Accuracy: 50.0\n",
            "[51/150]: Training Loss: 1.539840473086023, Training Accuracy: 56.68\n",
            "Validation Loss: 1.93095024452088, Validation Accuracy: 49.97\n",
            "[52/150]: Training Loss: 1.522039294928846, Training Accuracy: 57.282\n",
            "Validation Loss: 1.901054722488306, Validation Accuracy: 50.91\n",
            "[53/150]: Training Loss: 1.505999029597358, Training Accuracy: 57.376\n",
            "Validation Loss: 1.945236231870712, Validation Accuracy: 49.27\n",
            "[54/150]: Training Loss: 1.507185840469492, Training Accuracy: 57.802\n",
            "Validation Loss: 1.8845598515431592, Validation Accuracy: 50.54\n",
            "[55/150]: Training Loss: 1.4943511856486424, Training Accuracy: 57.754\n",
            "Validation Loss: 1.908029711170561, Validation Accuracy: 50.57\n",
            "[56/150]: Training Loss: 1.4784885358322613, Training Accuracy: 58.39\n",
            "Validation Loss: 1.9093056567914926, Validation Accuracy: 50.32\n",
            "[57/150]: Training Loss: 1.4689392635736929, Training Accuracy: 58.69\n",
            "Validation Loss: 1.9369963088612647, Validation Accuracy: 50.18\n",
            "[58/150]: Training Loss: 1.4634843205704409, Training Accuracy: 58.688\n",
            "Validation Loss: 1.9295313540537646, Validation Accuracy: 50.43\n",
            "[59/150]: Training Loss: 1.4444945978996393, Training Accuracy: 59.07\n",
            "Validation Loss: 1.8427119877687685, Validation Accuracy: 52.33\n",
            "[60/150]: Training Loss: 1.4354293743515258, Training Accuracy: 59.374\n",
            "Validation Loss: 1.910806885950125, Validation Accuracy: 50.94\n",
            "[61/150]: Training Loss: 1.4113788747269174, Training Accuracy: 59.82\n",
            "Validation Loss: 1.8786808958478793, Validation Accuracy: 51.43\n",
            "[62/150]: Training Loss: 1.4087011503898883, Training Accuracy: 59.934\n",
            "Validation Loss: 1.93228034608683, Validation Accuracy: 50.3\n",
            "[63/150]: Training Loss: 1.4004798267046203, Training Accuracy: 60.114\n",
            "Validation Loss: 1.862087261145282, Validation Accuracy: 51.42\n",
            "[64/150]: Training Loss: 1.3885550134627105, Training Accuracy: 60.078\n",
            "Validation Loss: 1.839821860289118, Validation Accuracy: 52.23\n",
            "[65/150]: Training Loss: 1.3659701371741721, Training Accuracy: 61.178\n",
            "Validation Loss: 1.8993338536305033, Validation Accuracy: 51.3\n",
            "[66/150]: Training Loss: 1.359891347720495, Training Accuracy: 61.062\n",
            "Validation Loss: 1.808910168659915, Validation Accuracy: 52.34\n",
            "[67/150]: Training Loss: 1.350066394376023, Training Accuracy: 61.206\n",
            "Validation Loss: 1.842593222666698, Validation Accuracy: 52.23\n",
            "[68/150]: Training Loss: 1.3413548037371672, Training Accuracy: 61.606\n",
            "Validation Loss: 1.8450721175807296, Validation Accuracy: 52.19\n",
            "[69/150]: Training Loss: 1.328629597907176, Training Accuracy: 61.842\n",
            "Validation Loss: 1.9130320769206735, Validation Accuracy: 51.75\n",
            "[70/150]: Training Loss: 1.308861137579774, Training Accuracy: 62.402\n",
            "Validation Loss: 1.8209870947394402, Validation Accuracy: 52.76\n",
            "[71/150]: Training Loss: 1.3000667644736101, Training Accuracy: 62.528\n",
            "Validation Loss: 1.8656981424161583, Validation Accuracy: 52.29\n",
            "[72/150]: Training Loss: 1.2866845129395994, Training Accuracy: 62.902\n",
            "Validation Loss: 1.8237224574301654, Validation Accuracy: 53.36\n",
            "[73/150]: Training Loss: 1.2716818537248675, Training Accuracy: 63.328\n",
            "Validation Loss: 1.872310409879988, Validation Accuracy: 52.51\n",
            "[74/150]: Training Loss: 1.2592318182253777, Training Accuracy: 63.678\n",
            "Validation Loss: 1.8924590835146085, Validation Accuracy: 52.18\n",
            "[75/150]: Training Loss: 1.2489444612694518, Training Accuracy: 63.924\n",
            "Validation Loss: 1.8441433739510311, Validation Accuracy: 53.18\n",
            "[76/150]: Training Loss: 1.2271763168637404, Training Accuracy: 64.204\n",
            "Validation Loss: 1.826472075881472, Validation Accuracy: 53.48\n",
            "[77/150]: Training Loss: 1.2162439644031817, Training Accuracy: 64.628\n",
            "Validation Loss: 1.7922283798266367, Validation Accuracy: 53.91\n",
            "[78/150]: Training Loss: 1.1974031528091187, Training Accuracy: 65.212\n",
            "Validation Loss: 1.854033857394176, Validation Accuracy: 52.77\n",
            "[79/150]: Training Loss: 1.1963484688945438, Training Accuracy: 65.298\n",
            "Validation Loss: 1.8417060686524507, Validation Accuracy: 53.83\n",
            "[80/150]: Training Loss: 1.170646650559457, Training Accuracy: 65.906\n",
            "Validation Loss: 1.8188444110238629, Validation Accuracy: 54.0\n",
            "[81/150]: Training Loss: 1.1599712444998114, Training Accuracy: 66.228\n",
            "Validation Loss: 1.832872725596094, Validation Accuracy: 53.93\n",
            "[82/150]: Training Loss: 1.1514770396987495, Training Accuracy: 66.602\n",
            "Validation Loss: 1.8412558204808813, Validation Accuracy: 53.79\n",
            "[83/150]: Training Loss: 1.1428028439621791, Training Accuracy: 66.712\n",
            "Validation Loss: 1.8457995410178119, Validation Accuracy: 53.19\n",
            "[84/150]: Training Loss: 1.1221959683901208, Training Accuracy: 67.186\n",
            "Validation Loss: 1.8420210499672374, Validation Accuracy: 53.69\n",
            "[85/150]: Training Loss: 1.1132261551859435, Training Accuracy: 67.302\n",
            "Validation Loss: 1.8613816719905587, Validation Accuracy: 53.54\n",
            "[86/150]: Training Loss: 1.095082609473592, Training Accuracy: 68.072\n",
            "Validation Loss: 1.8083385081048224, Validation Accuracy: 53.78\n",
            "[87/150]: Training Loss: 1.0820598827908412, Training Accuracy: 68.22\n",
            "Validation Loss: 1.8537752772592435, Validation Accuracy: 54.26\n",
            "[88/150]: Training Loss: 1.0588698522818973, Training Accuracy: 68.838\n",
            "Validation Loss: 1.8358791383208743, Validation Accuracy: 54.18\n",
            "[89/150]: Training Loss: 1.0537138239806876, Training Accuracy: 68.858\n",
            "Validation Loss: 1.9032178441430354, Validation Accuracy: 53.39\n",
            "[90/150]: Training Loss: 1.0420529545115693, Training Accuracy: 69.19\n",
            "Validation Loss: 1.8331271857972358, Validation Accuracy: 54.72\n",
            "[91/150]: Training Loss: 1.0190018734053883, Training Accuracy: 69.946\n",
            "Validation Loss: 1.81914554811587, Validation Accuracy: 54.61\n",
            "[92/150]: Training Loss: 1.0052901713744453, Training Accuracy: 70.376\n",
            "Validation Loss: 1.8224602520086204, Validation Accuracy: 54.54\n",
            "[93/150]: Training Loss: 0.9959899578100581, Training Accuracy: 70.576\n",
            "Validation Loss: 1.8335816890570769, Validation Accuracy: 54.66\n",
            "[94/150]: Training Loss: 0.9820676271034323, Training Accuracy: 70.882\n",
            "Validation Loss: 1.8163665267312603, Validation Accuracy: 55.18\n",
            "[95/150]: Training Loss: 0.9656730821675352, Training Accuracy: 71.258\n",
            "Validation Loss: 1.8308387478445745, Validation Accuracy: 54.6\n",
            "[96/150]: Training Loss: 0.9520570190666277, Training Accuracy: 71.578\n",
            "Validation Loss: 1.8336243507968393, Validation Accuracy: 55.03\n",
            "[97/150]: Training Loss: 0.938745556661235, Training Accuracy: 71.902\n",
            "Validation Loss: 1.8366246033625997, Validation Accuracy: 54.91\n",
            "[98/150]: Training Loss: 0.9180464198827134, Training Accuracy: 72.722\n",
            "Validation Loss: 1.8760136365890503, Validation Accuracy: 54.5\n",
            "[99/150]: Training Loss: 0.9068292014281768, Training Accuracy: 73.062\n",
            "Validation Loss: 1.7993891132864983, Validation Accuracy: 55.5\n",
            "[100/150]: Training Loss: 0.8922816610625942, Training Accuracy: 73.34\n",
            "Validation Loss: 1.8412930228907591, Validation Accuracy: 54.68\n",
            "[101/150]: Training Loss: 0.8739150777421034, Training Accuracy: 73.706\n",
            "Validation Loss: 1.8339118517128525, Validation Accuracy: 55.67\n",
            "[102/150]: Training Loss: 0.8564372022667199, Training Accuracy: 74.472\n",
            "Validation Loss: 1.831563648904205, Validation Accuracy: 54.7\n",
            "[103/150]: Training Loss: 0.8455693187463619, Training Accuracy: 74.832\n",
            "Validation Loss: 1.8586692977103458, Validation Accuracy: 55.09\n",
            "[104/150]: Training Loss: 0.8356970895815383, Training Accuracy: 74.91\n",
            "Validation Loss: 1.891693490326025, Validation Accuracy: 54.66\n",
            "[105/150]: Training Loss: 0.8192636847038708, Training Accuracy: 75.622\n",
            "Validation Loss: 1.836436649037015, Validation Accuracy: 55.18\n",
            "[106/150]: Training Loss: 0.8021497989783202, Training Accuracy: 75.904\n",
            "Validation Loss: 1.8664625199737064, Validation Accuracy: 55.06\n",
            "[107/150]: Training Loss: 0.7924835441438743, Training Accuracy: 76.238\n",
            "Validation Loss: 1.8400274932764138, Validation Accuracy: 56.23\n",
            "[108/150]: Training Loss: 0.7697334062031773, Training Accuracy: 76.922\n",
            "Validation Loss: 1.852326028665919, Validation Accuracy: 55.58\n",
            "[109/150]: Training Loss: 0.7663251587268337, Training Accuracy: 77.026\n",
            "Validation Loss: 1.851918256206877, Validation Accuracy: 55.79\n",
            "[110/150]: Training Loss: 0.7508895213113111, Training Accuracy: 77.64\n",
            "Validation Loss: 1.8553174369654077, Validation Accuracy: 55.56\n",
            "[111/150]: Training Loss: 0.7446020825973252, Training Accuracy: 77.658\n",
            "Validation Loss: 1.8480755607033992, Validation Accuracy: 55.4\n",
            "[112/150]: Training Loss: 0.7242154034278582, Training Accuracy: 78.302\n",
            "Validation Loss: 1.8599452805367245, Validation Accuracy: 55.63\n",
            "[113/150]: Training Loss: 0.710430224609497, Training Accuracy: 78.58\n",
            "Validation Loss: 1.853841427405169, Validation Accuracy: 55.72\n",
            "[114/150]: Training Loss: 0.6952832066418265, Training Accuracy: 79.15\n",
            "Validation Loss: 1.8361253859890494, Validation Accuracy: 56.53\n",
            "[115/150]: Training Loss: 0.6855566057631427, Training Accuracy: 79.384\n",
            "Validation Loss: 1.8501070935255404, Validation Accuracy: 55.8\n",
            "[116/150]: Training Loss: 0.670332043791366, Training Accuracy: 79.848\n",
            "Validation Loss: 1.871697852565984, Validation Accuracy: 55.87\n",
            "[117/150]: Training Loss: 0.659062210518076, Training Accuracy: 80.28\n",
            "Validation Loss: 1.8932185765284641, Validation Accuracy: 56.33\n",
            "[118/150]: Training Loss: 0.6481513134049027, Training Accuracy: 80.47\n",
            "Validation Loss: 1.8721413916083658, Validation Accuracy: 56.69\n",
            "[119/150]: Training Loss: 0.6378583989256178, Training Accuracy: 80.804\n",
            "Validation Loss: 1.8575806663294507, Validation Accuracy: 56.3\n",
            "[120/150]: Training Loss: 0.6237786744561646, Training Accuracy: 81.468\n",
            "Validation Loss: 1.8885631751103007, Validation Accuracy: 56.27\n",
            "[121/150]: Training Loss: 0.6136706139311157, Training Accuracy: 81.672\n",
            "Validation Loss: 1.8672110297877318, Validation Accuracy: 56.64\n",
            "[122/150]: Training Loss: 0.598588163380885, Training Accuracy: 82.084\n",
            "Validation Loss: 1.8859197356898314, Validation Accuracy: 56.85\n",
            "[123/150]: Training Loss: 0.5942039575494463, Training Accuracy: 82.472\n",
            "Validation Loss: 1.8791207416801696, Validation Accuracy: 56.65\n",
            "[124/150]: Training Loss: 0.5779005947625241, Training Accuracy: 82.892\n",
            "Validation Loss: 1.8723569349118858, Validation Accuracy: 56.69\n",
            "[125/150]: Training Loss: 0.5656420003689463, Training Accuracy: 83.386\n",
            "Validation Loss: 1.8776653800041052, Validation Accuracy: 56.51\n",
            "[126/150]: Training Loss: 0.5588299318423966, Training Accuracy: 83.53\n",
            "Validation Loss: 1.8926861441818772, Validation Accuracy: 56.77\n",
            "[127/150]: Training Loss: 0.5484652115065424, Training Accuracy: 83.916\n",
            "Validation Loss: 1.8761122143192657, Validation Accuracy: 56.82\n",
            "[128/150]: Training Loss: 0.5397156641230254, Training Accuracy: 84.144\n",
            "Validation Loss: 1.883816226272826, Validation Accuracy: 56.91\n",
            "[129/150]: Training Loss: 0.5299459375307688, Training Accuracy: 84.524\n",
            "Validation Loss: 1.885110402942463, Validation Accuracy: 56.93\n",
            "[130/150]: Training Loss: 0.5226550506203985, Training Accuracy: 84.69\n",
            "Validation Loss: 1.8858621705109906, Validation Accuracy: 57.03\n",
            "[131/150]: Training Loss: 0.5145904917622466, Training Accuracy: 85.08\n",
            "Validation Loss: 1.898423175902883, Validation Accuracy: 56.86\n",
            "[132/150]: Training Loss: 0.5080187612444239, Training Accuracy: 85.244\n",
            "Validation Loss: 1.8937967233597093, Validation Accuracy: 57.24\n",
            "[133/150]: Training Loss: 0.501667047438719, Training Accuracy: 85.274\n",
            "Validation Loss: 1.8932398701928983, Validation Accuracy: 56.88\n",
            "[134/150]: Training Loss: 0.49395688687977585, Training Accuracy: 85.592\n",
            "Validation Loss: 1.8888862345628679, Validation Accuracy: 57.11\n",
            "[135/150]: Training Loss: 0.48916787244474796, Training Accuracy: 85.884\n",
            "Validation Loss: 1.8910012594453849, Validation Accuracy: 57.08\n",
            "[136/150]: Training Loss: 0.48000375615894947, Training Accuracy: 86.098\n",
            "Validation Loss: 1.9055567767210067, Validation Accuracy: 56.92\n",
            "[137/150]: Training Loss: 0.48404536522029307, Training Accuracy: 86.152\n",
            "Validation Loss: 1.8957096717919513, Validation Accuracy: 57.23\n",
            "[138/150]: Training Loss: 0.4733923572637236, Training Accuracy: 86.464\n",
            "Validation Loss: 1.8970948966445438, Validation Accuracy: 57.23\n",
            "[139/150]: Training Loss: 0.4687954626424843, Training Accuracy: 86.406\n",
            "Validation Loss: 1.8926855910355878, Validation Accuracy: 57.49\n",
            "[140/150]: Training Loss: 0.4656825878126237, Training Accuracy: 86.552\n",
            "Validation Loss: 1.8944045935466791, Validation Accuracy: 57.25\n",
            "[141/150]: Training Loss: 0.46502622329365567, Training Accuracy: 86.75\n",
            "Validation Loss: 1.892073856797188, Validation Accuracy: 57.21\n",
            "[142/150]: Training Loss: 0.45881695900579245, Training Accuracy: 86.948\n",
            "Validation Loss: 1.8972379872753362, Validation Accuracy: 57.33\n",
            "[143/150]: Training Loss: 0.4567206385152419, Training Accuracy: 86.978\n",
            "Validation Loss: 1.8969501234163904, Validation Accuracy: 57.41\n",
            "[144/150]: Training Loss: 0.45361602742729895, Training Accuracy: 87.108\n",
            "Validation Loss: 1.8974497530870378, Validation Accuracy: 57.36\n",
            "[145/150]: Training Loss: 0.45476321409196807, Training Accuracy: 87.206\n",
            "Validation Loss: 1.9007372218332472, Validation Accuracy: 57.39\n",
            "[146/150]: Training Loss: 0.45061131850685304, Training Accuracy: 87.172\n",
            "Validation Loss: 1.8978507139120893, Validation Accuracy: 57.36\n",
            "[147/150]: Training Loss: 0.4471297430832063, Training Accuracy: 87.32\n",
            "Validation Loss: 1.8995944998066896, Validation Accuracy: 57.45\n",
            "[148/150]: Training Loss: 0.44544086216584494, Training Accuracy: 87.358\n",
            "Validation Loss: 1.8984677867524942, Validation Accuracy: 57.57\n",
            "[149/150]: Training Loss: 0.45087983754589733, Training Accuracy: 87.206\n",
            "Validation Loss: 1.8988231648305418, Validation Accuracy: 57.57\n",
            "[150/150]: Training Loss: 0.445312842879149, Training Accuracy: 87.314\n",
            "Validation Loss: 1.898690512985181, Validation Accuracy: 57.55\n",
            "**********************************************************************\n",
            "Test Loss: 1.898690512985181, Test Accuracy: 57.55\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▆█▄▃▄▃▂▁▂▂▂▂▁▁▁▁▂▂▂▁▁▁▁▂▁▂▁▂▂▂▂▁▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>█▁▄▅▅▅▆▇▅▆▅▄▅▅▅▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▄</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇███████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>57.55</td></tr><tr><td>Test Loss</td><td>1.89869</td></tr><tr><td>Train Accuracy</td><td>87.314</td></tr><tr><td>Train Loss</td><td>0.44531</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_013938-4i9h8t3n/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                  'weight_decay' : wd}\n",
        "\n",
        "# Load the model\n",
        "model_0 = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer_0 = torch.optim.SGD(model_0.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_0, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model_0, original_train_loader, original_test_loader, original_test_loader, optimizer_0, scheduler, criterion, device, optimizer_name='SGDM', hyperparameters=hyperparameters, is_wandb=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ba6f9560801c461a90a0fd2f8c20d918",
            "5055c91b4ed34c1baf249fa25948e84f",
            "1feabb0772134ace893d71cb905e9b12",
            "fb5f2e328dff44018f41180c2a2ec871",
            "33050a2d80c24235aecc36cb34e79684",
            "2bc1423c729a4faa9a184ae092eda8ad",
            "1b1acf7a1f5f43739e1fe0894ba48950",
            "0d710da02bfe4c8e80d205158d9d64c7",
            "d770fa4de3bd479886dbf8e1f6369543",
            "c20d73b37f6a497a8847e2fd20a98d16",
            "edd61f4569b54b869669aebf91420508",
            "a6ba8ab59be54b8ca096631627ee9713",
            "15a0bbd1e2b14cef8a2f9accf120c1ad",
            "e181391aa4424c04804ac665abd6f594",
            "f8ce66183b2543e7bf19b71d90d1c53e",
            "904f899f441149e9b707699a0ebf31b5",
            "f76ed5acf91a4edf92950dcb88356f23",
            "9387a738135842cf965db860499510f5",
            "33a438b911c04f1f96c67b4f7ba7477d",
            "35d90a90d5854bcaa2bc5f385cdad931",
            "5630d5fcb50a46f2887e0cce74a005a6",
            "fed90f96881140119ee97a0d2120b615",
            "ff7b6956e7e34db68cd38dee19c798f1",
            "d71c8b5d30df474ca6f30976d0a33c71",
            "cbe10db0bb8d45609a0f3d59a30c8f61",
            "07ff6351429c48c2b835305d3111af40",
            "ab580ef13b18428c994fc4f8b80885b6",
            "497de066b1964cd4b931476e0bd50c66",
            "c5de35a9063345b1a12e212718a02575",
            "e86e517239b54ca4a6767a300aa7e01d",
            "eb268a732bc74b2d81ec3c3a6ecd0362",
            "f2915a147a4246dba7984a90f23c34ae",
            "2f39d5f73c7647f1804e4212cb39924d",
            "6e7ede02663f4eb0927872bf17858f18",
            "a562d76741f74b10b8095be14da779d1",
            "f4e7759ba0f544d8a28a9922e06e890b",
            "0a9ee7dc8817456aab4af03cbfa4c6ed",
            "567cc1542f09433f8cc8b3a39237f198",
            "8dc245e02cac40f1b601fa42a0e6e77a",
            "1b093d744b374154afe2058e4a6de822",
            "4302f47b1ff043aca2523212b015e080",
            "371471be80ca47dbb005c853b7832f04",
            "e75a0d8ae24e462aa3075a813aad302d",
            "fd2cd8045a5c4387b98d080782289c48",
            "1574e69b88de479da2aadc2dfdd43261",
            "f523ae2aca8c46878f0a6ddc1f798ef5",
            "0b42ea1995bb410b99e653780dad3916",
            "f3ebd9b7bf7a4d24b54ab6673322f74b"
          ]
        },
        "id": "Toi1eWRqJuhK",
        "outputId": "bd028d6d-1e8d-4fff-bccf-88ed9aa1c4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:ymdv8k6d) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁</td></tr><tr><td>Train Loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>7.7625</td></tr><tr><td>Train Loss</td><td>4.01706</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.00095 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/ymdv8k6d' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/ymdv8k6d</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_034825-ymdv8k6d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:ymdv8k6d). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_034959-j16vayol</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">learning_rate=0.001 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.032126424407959, Training Accuracy: 7.645\n",
            "Validation Loss: 3.633875617555752, Validation Accuracy: 13.81\n",
            "[2/150]: Training Loss: 3.4117616390228274, Training Accuracy: 17.9375\n",
            "Validation Loss: 3.291252329091358, Validation Accuracy: 19.57\n",
            "[3/150]: Training Loss: 3.0980306770324706, Training Accuracy: 23.7325\n",
            "Validation Loss: 3.0133402590539045, Validation Accuracy: 25.49\n",
            "[4/150]: Training Loss: 2.875119793319702, Training Accuracy: 27.905\n",
            "Validation Loss: 2.9483105938905365, Validation Accuracy: 26.77\n",
            "[5/150]: Training Loss: 2.6911334384918213, Training Accuracy: 31.615\n",
            "Validation Loss: 2.851942961383018, Validation Accuracy: 28.77\n",
            "[6/150]: Training Loss: 2.5383362628936768, Training Accuracy: 34.6425\n",
            "Validation Loss: 2.8010447116414454, Validation Accuracy: 30.38\n",
            "[7/150]: Training Loss: 2.3951899276733397, Training Accuracy: 37.7375\n",
            "Validation Loss: 2.772052654035532, Validation Accuracy: 31.08\n",
            "[8/150]: Training Loss: 2.2677825828552245, Training Accuracy: 40.2175\n",
            "Validation Loss: 2.740394227823634, Validation Accuracy: 32.51\n",
            "[9/150]: Training Loss: 2.1415996942520144, Training Accuracy: 43.1725\n",
            "Validation Loss: 2.7748732961666813, Validation Accuracy: 31.82\n",
            "[10/150]: Training Loss: 2.016268748664856, Training Accuracy: 45.7725\n",
            "Validation Loss: 2.766294874203433, Validation Accuracy: 33.51\n",
            "[11/150]: Training Loss: 1.8994886245727538, Training Accuracy: 48.375\n",
            "Validation Loss: 2.840820978401573, Validation Accuracy: 32.8\n",
            "[12/150]: Training Loss: 1.7866277021408081, Training Accuracy: 51.045\n",
            "Validation Loss: 2.8579562796149283, Validation Accuracy: 32.9\n",
            "[13/150]: Training Loss: 1.6882859018325806, Training Accuracy: 53.12\n",
            "Validation Loss: 2.923183766899595, Validation Accuracy: 32.48\n",
            "[14/150]: Training Loss: 1.5779105269432068, Training Accuracy: 55.655\n",
            "Validation Loss: 3.072260461795102, Validation Accuracy: 32.29\n",
            "[15/150]: Training Loss: 1.478017513847351, Training Accuracy: 58.1575\n",
            "Validation Loss: 3.1435716137005265, Validation Accuracy: 32.08\n",
            "[16/150]: Training Loss: 1.3899440537452699, Training Accuracy: 59.9975\n",
            "Validation Loss: 3.176926696376436, Validation Accuracy: 31.97\n",
            "[17/150]: Training Loss: 1.3004323136329652, Training Accuracy: 62.3725\n",
            "Validation Loss: 3.3300343015391354, Validation Accuracy: 32.02\n",
            "[18/150]: Training Loss: 1.2033100715637206, Training Accuracy: 64.74\n",
            "Validation Loss: 3.478040464364799, Validation Accuracy: 31.7\n",
            "[19/150]: Training Loss: 1.1342673721313477, Training Accuracy: 66.51\n",
            "Validation Loss: 3.621978481863714, Validation Accuracy: 31.07\n",
            "[20/150]: Training Loss: 1.057302718448639, Training Accuracy: 68.56\n",
            "Validation Loss: 3.8245642261140667, Validation Accuracy: 31.16\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 198.79228443704594, Test Accuracy: 3.39\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▇▃▃▁▁▂▂▂▂▃▂▂▂▂▂▂▂▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▁▆▇▅████████▇█▇▇██▇█▇███▇███▇▇█▇███▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▅▅▅▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>3.39</td></tr><tr><td>Test Loss</td><td>198.79228</td></tr><tr><td>Train Accuracy</td><td>68.56</td></tr><tr><td>Train Loss</td><td>1.0573</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_034959-j16vayol/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035204-l4zoq5dd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">learning_rate=0.001 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.108658624267578, Training Accuracy: 6.6075\n",
            "Validation Loss: 3.7040131304674087, Validation Accuracy: 12.1\n",
            "[2/150]: Training Loss: 3.5060665573120118, Training Accuracy: 16.015\n",
            "Validation Loss: 3.3598362321306947, Validation Accuracy: 18.42\n",
            "[3/150]: Training Loss: 3.1865245040893555, Training Accuracy: 21.7275\n",
            "Validation Loss: 3.128495198146553, Validation Accuracy: 22.84\n",
            "[4/150]: Training Loss: 2.9679495239257814, Training Accuracy: 25.8525\n",
            "Validation Loss: 2.9615708293428846, Validation Accuracy: 26.83\n",
            "[5/150]: Training Loss: 2.797335900115967, Training Accuracy: 29.515\n",
            "Validation Loss: 2.9264626108157406, Validation Accuracy: 26.96\n",
            "[6/150]: Training Loss: 2.6617756172180176, Training Accuracy: 32.13\n",
            "Validation Loss: 2.8755724490827816, Validation Accuracy: 28.35\n",
            "[7/150]: Training Loss: 2.54268462638855, Training Accuracy: 34.435\n",
            "Validation Loss: 2.7718013547788, Validation Accuracy: 30.25\n",
            "[8/150]: Training Loss: 2.424749851608276, Training Accuracy: 37.1025\n",
            "Validation Loss: 2.7567353567500024, Validation Accuracy: 31.11\n",
            "[9/150]: Training Loss: 2.3229350467681886, Training Accuracy: 39.08\n",
            "Validation Loss: 2.7088757032042095, Validation Accuracy: 32.08\n",
            "[10/150]: Training Loss: 2.2215481660842897, Training Accuracy: 41.4275\n",
            "Validation Loss: 2.75471066821153, Validation Accuracy: 31.83\n",
            "[11/150]: Training Loss: 2.134213170814514, Training Accuracy: 43.25\n",
            "Validation Loss: 2.8348169676057853, Validation Accuracy: 31.64\n",
            "[12/150]: Training Loss: 2.051020913696289, Training Accuracy: 44.9475\n",
            "Validation Loss: 2.7630925406316282, Validation Accuracy: 32.98\n",
            "[13/150]: Training Loss: 1.960823282814026, Training Accuracy: 46.7775\n",
            "Validation Loss: 2.7420302629470825, Validation Accuracy: 33.4\n",
            "[14/150]: Training Loss: 1.8790180908203125, Training Accuracy: 48.855\n",
            "Validation Loss: 2.7926843044864142, Validation Accuracy: 33.79\n",
            "[15/150]: Training Loss: 1.80182436504364, Training Accuracy: 50.6875\n",
            "Validation Loss: 2.8919099911003356, Validation Accuracy: 33.19\n",
            "[16/150]: Training Loss: 1.727850655937195, Training Accuracy: 52.3025\n",
            "Validation Loss: 2.8964282950018623, Validation Accuracy: 33.5\n",
            "[17/150]: Training Loss: 1.6616035480499267, Training Accuracy: 53.85\n",
            "Validation Loss: 3.033423226350432, Validation Accuracy: 32.53\n",
            "[18/150]: Training Loss: 1.5868734314918518, Training Accuracy: 55.5\n",
            "Validation Loss: 3.032342692089688, Validation Accuracy: 33.04\n",
            "[19/150]: Training Loss: 1.5333876008987426, Training Accuracy: 56.7525\n",
            "Validation Loss: 3.079486154446936, Validation Accuracy: 32.97\n",
            "[20/150]: Training Loss: 1.4575365795135498, Training Accuracy: 58.77\n",
            "Validation Loss: 3.181258452166418, Validation Accuracy: 32.82\n",
            "[21/150]: Training Loss: 1.39640816450119, Training Accuracy: 60.14\n",
            "Validation Loss: 3.216413262543405, Validation Accuracy: 32.76\n",
            "[22/150]: Training Loss: 1.337559293270111, Training Accuracy: 61.5275\n",
            "Validation Loss: 3.3633130872325534, Validation Accuracy: 31.73\n",
            "[23/150]: Training Loss: 1.2836213255882263, Training Accuracy: 62.6875\n",
            "Validation Loss: 3.4558656868661286, Validation Accuracy: 32.33\n",
            "[24/150]: Training Loss: 1.2338986722946168, Training Accuracy: 64.2825\n",
            "Validation Loss: 3.4873077155678134, Validation Accuracy: 32.02\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 156.72609671817463, Test Accuracy: 3.33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▅▁▂▃▂▃▃▃▃▃▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Test Loss</td><td>▇▇▁▂▁▄▄▇█▆▃▄▅▆▅▅▆▆▆▆▅▇▇▆▆▇▆▆▅▆▆▆▅▆▅▅▆▆▅▅</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>3.33</td></tr><tr><td>Test Loss</td><td>156.7261</td></tr><tr><td>Train Accuracy</td><td>64.2825</td></tr><tr><td>Train Loss</td><td>1.2339</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035204-l4zoq5dd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035441-y4ask5ys</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.053023485183716, Training Accuracy: 7.3\n",
            "Validation Loss: 3.71551227873298, Validation Accuracy: 12.6\n",
            "[2/150]: Training Loss: 3.4803551902770997, Training Accuracy: 16.4825\n",
            "Validation Loss: 3.3104240119836894, Validation Accuracy: 19.6\n",
            "[3/150]: Training Loss: 3.1457452793121337, Training Accuracy: 22.71\n",
            "Validation Loss: 3.1647931253834134, Validation Accuracy: 22.36\n",
            "[4/150]: Training Loss: 2.9213612785339356, Training Accuracy: 26.8375\n",
            "Validation Loss: 2.967867093481076, Validation Accuracy: 26.13\n",
            "[5/150]: Training Loss: 2.7346919048309326, Training Accuracy: 30.745\n",
            "Validation Loss: 2.870804744161618, Validation Accuracy: 28.43\n",
            "[6/150]: Training Loss: 2.580346668434143, Training Accuracy: 33.8975\n",
            "Validation Loss: 2.813369401700937, Validation Accuracy: 29.97\n",
            "[7/150]: Training Loss: 2.4525743492126466, Training Accuracy: 36.445\n",
            "Validation Loss: 2.8111886962963517, Validation Accuracy: 31.76\n",
            "[8/150]: Training Loss: 2.3342738655090334, Training Accuracy: 38.8\n",
            "Validation Loss: 2.7751463211266096, Validation Accuracy: 31.29\n",
            "[9/150]: Training Loss: 2.230911629486084, Training Accuracy: 40.89\n",
            "Validation Loss: 2.733239137443008, Validation Accuracy: 32.32\n",
            "[10/150]: Training Loss: 2.127202660560608, Training Accuracy: 43.0575\n",
            "Validation Loss: 2.740311449500406, Validation Accuracy: 32.67\n",
            "[11/150]: Training Loss: 2.0320646129608155, Training Accuracy: 45.3025\n",
            "Validation Loss: 2.7493710031934606, Validation Accuracy: 33.28\n",
            "[12/150]: Training Loss: 1.9452043891906738, Training Accuracy: 47.2675\n",
            "Validation Loss: 2.776471818328663, Validation Accuracy: 33.2\n",
            "[13/150]: Training Loss: 1.8665077058792114, Training Accuracy: 49.035\n",
            "Validation Loss: 2.801089420440091, Validation Accuracy: 32.56\n",
            "[14/150]: Training Loss: 1.782764630126953, Training Accuracy: 50.66\n",
            "Validation Loss: 2.869801163673401, Validation Accuracy: 33.19\n",
            "[15/150]: Training Loss: 1.6995231729507447, Training Accuracy: 52.77\n",
            "Validation Loss: 3.0037558374890856, Validation Accuracy: 32.92\n",
            "[16/150]: Training Loss: 1.6300209772109986, Training Accuracy: 54.165\n",
            "Validation Loss: 2.9989138818850183, Validation Accuracy: 32.86\n",
            "[17/150]: Training Loss: 1.5460361848831177, Training Accuracy: 56.605\n",
            "Validation Loss: 3.0711293569795646, Validation Accuracy: 32.69\n",
            "[18/150]: Training Loss: 1.48129998254776, Training Accuracy: 57.9875\n",
            "Validation Loss: 3.1773584519222284, Validation Accuracy: 31.98\n",
            "[19/150]: Training Loss: 1.4184319323539734, Training Accuracy: 59.43\n",
            "Validation Loss: 3.278900881481778, Validation Accuracy: 31.73\n",
            "[20/150]: Training Loss: 1.3525760270118714, Training Accuracy: 60.9775\n",
            "Validation Loss: 3.3168472605905714, Validation Accuracy: 31.51\n",
            "[21/150]: Training Loss: 1.275265542125702, Training Accuracy: 63.035\n",
            "Validation Loss: 3.5034019506660994, Validation Accuracy: 31.12\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 67.07529235645464, Test Accuracy: 5.39\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▁▂▇▃▁▂▁▂▂▂▃▃▃▄▄▄▄▃▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄</td></tr><tr><td>Test Loss</td><td>▁█▅▃▃▃▃▄▅▄▃▂▂▃▃▂▄▄▄▄▃▃▃▃▃▃▃▃▃▂▃▃▃▃▃▃▃▂▂▂</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>5.39</td></tr><tr><td>Test Loss</td><td>67.07529</td></tr><tr><td>Train Accuracy</td><td>63.035</td></tr><tr><td>Train Loss</td><td>1.27527</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035441-y4ask5ys/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035656-za8h22vt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">learning_rate=0.01 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.622148120880127, Training Accuracy: 0.935\n",
            "Validation Loss: 4.609954472560032, Validation Accuracy: 0.99\n",
            "[2/150]: Training Loss: 4.609106838226318, Training Accuracy: 0.9475\n",
            "Validation Loss: 4.611106529357327, Validation Accuracy: 0.9\n",
            "[3/150]: Training Loss: 4.608888108062744, Training Accuracy: 0.9925\n",
            "Validation Loss: 4.608767968074531, Validation Accuracy: 0.84\n",
            "[4/150]: Training Loss: 4.608837638854981, Training Accuracy: 0.935\n",
            "Validation Loss: 4.610516976399027, Validation Accuracy: 0.89\n",
            "[5/150]: Training Loss: 4.608827792358398, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.610510003035236, Validation Accuracy: 0.9\n",
            "[6/150]: Training Loss: 4.608845700073243, Training Accuracy: 0.935\n",
            "Validation Loss: 4.609803257474474, Validation Accuracy: 0.83\n",
            "[7/150]: Training Loss: 4.608741146087646, Training Accuracy: 0.9625\n",
            "Validation Loss: 4.60897787665106, Validation Accuracy: 0.89\n",
            "[8/150]: Training Loss: 4.608720026397705, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.610442146374162, Validation Accuracy: 0.89\n",
            "[9/150]: Training Loss: 4.60900821762085, Training Accuracy: 1.005\n",
            "Validation Loss: 4.609640285467646, Validation Accuracy: 0.9\n",
            "[10/150]: Training Loss: 4.609175831604004, Training Accuracy: 0.9175\n",
            "Validation Loss: 4.609878120908312, Validation Accuracy: 0.95\n",
            "[11/150]: Training Loss: 4.609065142822265, Training Accuracy: 0.8625\n",
            "Validation Loss: 4.610616553361249, Validation Accuracy: 0.9\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 19.343990089027745, Test Accuracy: 1.01\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▃▃▆▆▆▆▇▇▇▇▇▇▇▇█▇▇▇██▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Test Loss</td><td>▅▄█▅▅▄▂▄▅▃▃▃▃▄▃▃▃▃▃▃▂▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>Train Accuracy</td><td>▅▅▇▅▇▅▆▇█▄▁</td></tr><tr><td>Train Loss</td><td>█▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.01</td></tr><tr><td>Test Loss</td><td>19.34399</td></tr><tr><td>Train Accuracy</td><td>0.8625</td></tr><tr><td>Train Loss</td><td>4.60907</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035656-za8h22vt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035822-1oq8f1cm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.625637398529053, Training Accuracy: 0.885\n",
            "Validation Loss: 4.60909015509733, Validation Accuracy: 1.06\n",
            "[2/150]: Training Loss: 4.608977200317383, Training Accuracy: 0.94\n",
            "Validation Loss: 4.609363568056921, Validation Accuracy: 0.92\n",
            "[3/150]: Training Loss: 4.608765270996094, Training Accuracy: 0.9275\n",
            "Validation Loss: 4.610460181145152, Validation Accuracy: 0.9\n",
            "[4/150]: Training Loss: 4.609055269622803, Training Accuracy: 0.855\n",
            "Validation Loss: 4.609649321076217, Validation Accuracy: 0.91\n",
            "[5/150]: Training Loss: 4.608893507385254, Training Accuracy: 0.965\n",
            "Validation Loss: 4.610334041012321, Validation Accuracy: 1.15\n",
            "[6/150]: Training Loss: 4.609225297546387, Training Accuracy: 1.0125\n",
            "Validation Loss: 4.608022522774472, Validation Accuracy: 1.16\n",
            "[7/150]: Training Loss: 4.609016616821289, Training Accuracy: 0.9875\n",
            "Validation Loss: 4.609603547746209, Validation Accuracy: 0.82\n",
            "[8/150]: Training Loss: 4.609039859008789, Training Accuracy: 1.0025\n",
            "Validation Loss: 4.608962860836345, Validation Accuracy: 0.88\n",
            "[9/150]: Training Loss: 4.608584417724609, Training Accuracy: 0.98\n",
            "Validation Loss: 4.609565239803047, Validation Accuracy: 0.92\n",
            "[10/150]: Training Loss: 4.609195093536377, Training Accuracy: 0.9675\n",
            "Validation Loss: 4.609652103132503, Validation Accuracy: 0.9\n",
            "[11/150]: Training Loss: 4.608826132202148, Training Accuracy: 0.975\n",
            "Validation Loss: 4.610933561993253, Validation Accuracy: 0.95\n",
            "[12/150]: Training Loss: 4.609026128387451, Training Accuracy: 1.0425\n",
            "Validation Loss: 4.609673776444356, Validation Accuracy: 0.81\n",
            "[13/150]: Training Loss: 4.60898267364502, Training Accuracy: 0.9275\n",
            "Validation Loss: 4.6093105510541585, Validation Accuracy: 0.89\n",
            "[14/150]: Training Loss: 4.608909271240234, Training Accuracy: 0.885\n",
            "Validation Loss: 4.610904125650977, Validation Accuracy: 0.82\n",
            "[15/150]: Training Loss: 4.609115404510498, Training Accuracy: 0.925\n",
            "Validation Loss: 4.609269661508548, Validation Accuracy: 0.9\n",
            "[16/150]: Training Loss: 4.608642578887939, Training Accuracy: 0.9875\n",
            "Validation Loss: 4.610215545459917, Validation Accuracy: 0.81\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 51.00807974748551, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▆▅▇▇███▇▇▇▆▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█</td></tr><tr><td>Test Loss</td><td>▁▇█▆▅▆▆▇█▇▇▇▇▇▇▇▇▇▇█▇█▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▂▄▄▁▅▇▆▇▆▅▅█▄▂▄▆</td></tr><tr><td>Train Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>51.00808</td></tr><tr><td>Train Accuracy</td><td>0.9875</td></tr><tr><td>Train Loss</td><td>4.60864</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035822-1oq8f1cm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_040031-bgr70v9g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">learning_rate=0.01 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.626314550018311, Training Accuracy: 0.9725\n",
            "Validation Loss: 4.610879454643103, Validation Accuracy: 0.88\n",
            "[2/150]: Training Loss: 4.609021481323242, Training Accuracy: 0.9225\n",
            "Validation Loss: 4.6096283493527945, Validation Accuracy: 1.0\n",
            "[3/150]: Training Loss: 4.608779692077637, Training Accuracy: 0.9575\n",
            "Validation Loss: 4.610723838684665, Validation Accuracy: 1.07\n",
            "[4/150]: Training Loss: 4.609119167327881, Training Accuracy: 0.9125\n",
            "Validation Loss: 4.60863508236636, Validation Accuracy: 0.89\n",
            "[5/150]: Training Loss: 4.608814185333252, Training Accuracy: 0.95\n",
            "Validation Loss: 4.611634175488903, Validation Accuracy: 0.93\n",
            "[6/150]: Training Loss: 4.6092648048400875, Training Accuracy: 0.8575\n",
            "Validation Loss: 4.610189516832874, Validation Accuracy: 0.92\n",
            "[7/150]: Training Loss: 4.6090187705993655, Training Accuracy: 1.005\n",
            "Validation Loss: 4.610130288798338, Validation Accuracy: 0.88\n",
            "[8/150]: Training Loss: 4.608886881256104, Training Accuracy: 1.01\n",
            "Validation Loss: 4.610127786162552, Validation Accuracy: 0.84\n",
            "[9/150]: Training Loss: 4.608884384155274, Training Accuracy: 1.0175\n",
            "Validation Loss: 4.610361232879056, Validation Accuracy: 0.95\n",
            "[10/150]: Training Loss: 4.60871681137085, Training Accuracy: 1.0025\n",
            "Validation Loss: 4.6113608263100785, Validation Accuracy: 1.03\n",
            "[11/150]: Training Loss: 4.608806131744385, Training Accuracy: 1.035\n",
            "Validation Loss: 4.609321922253651, Validation Accuracy: 0.94\n",
            "[12/150]: Training Loss: 4.6090567108154294, Training Accuracy: 0.9075\n",
            "Validation Loss: 4.6090145414801915, Validation Accuracy: 0.9\n",
            "[13/150]: Training Loss: 4.608706290435791, Training Accuracy: 0.9225\n",
            "Validation Loss: 4.609259438362851, Validation Accuracy: 0.82\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 7.142075587230123, Test Accuracy: 1.08\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▃█▃▁▁▁▃▄▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Test Loss</td><td>▁▅▇█▆▆▆▆▇▆▆▆▆▆▆▆▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▆▄▅▃▅▁▇▇▇▇█▃▄</td></tr><tr><td>Train Loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.08</td></tr><tr><td>Test Loss</td><td>7.14208</td></tr><tr><td>Train Accuracy</td><td>0.9225</td></tr><tr><td>Train Loss</td><td>4.60871</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_040031-bgr70v9g/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "  for wd in weight_decays:\n",
        "\n",
        "    print('='*50)\n",
        "    print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "    print('='*50)\n",
        "\n",
        "    hyperparameters = {'learning_rate': lr,\n",
        "                       'weight_decay' : wd\n",
        "                       }\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(num_epochs, model, train_loader, validation_loader, test_loader, optimizer, scheduler, criterion, device, 'AdamW-HyperParameterTuning', hyperparameters=hyperparameters, is_wandb = True, n_epochs_stop = 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63dd47b50bdc44e88edd97d14585f7ea",
            "5e0116dc735e4ad995a5b1a039c6a55a",
            "8cf1e952ed294ccdbc3bb2275b5d3efd",
            "7421027bfcb34262a1b99d297e49bf8e",
            "76dfea14213f4e66b269b901150c6cba",
            "d1e4a03094b94c34ac235ffbd0c7fa06",
            "c8e410ff55fc448bbe87c8975a552e88",
            "f49251ce876f4d9292a4179b48ebb22a"
          ]
        },
        "id": "dC9sTmuvEymk",
        "outputId": "66657750-ed1c-435f-c9e5-a2cc4271560e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:z7dx25wy) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/z7dx25wy' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/z7dx25wy</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_002941-z7dx25wy/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:z7dx25wy). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_003350-ulxra0pg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 3.863059723773576, Training Accuracy: 10.28\n",
            "Validation Loss: 3.371582930255088, Validation Accuracy: 17.92\n",
            "[2/150]: Training Loss: 3.2885083447941734, Training Accuracy: 19.766\n",
            "Validation Loss: 3.0681341438536434, Validation Accuracy: 23.43\n",
            "[3/150]: Training Loss: 3.0068617961595736, Training Accuracy: 25.216\n",
            "Validation Loss: 2.8509516169311135, Validation Accuracy: 28.09\n",
            "[4/150]: Training Loss: 2.8243453850221756, Training Accuracy: 28.812\n",
            "Validation Loss: 2.6608721253218923, Validation Accuracy: 31.85\n",
            "[5/150]: Training Loss: 2.7198512532826884, Training Accuracy: 30.66\n",
            "Validation Loss: 2.614684703243766, Validation Accuracy: 32.43\n",
            "[6/150]: Training Loss: 2.6302451995937415, Training Accuracy: 32.706\n",
            "Validation Loss: 2.523006957807359, Validation Accuracy: 35.09\n",
            "[7/150]: Training Loss: 2.5562818654053046, Training Accuracy: 34.01\n",
            "Validation Loss: 2.4693225895523265, Validation Accuracy: 36.29\n",
            "[8/150]: Training Loss: 2.503678919409242, Training Accuracy: 35.054\n",
            "Validation Loss: 2.4447873132244036, Validation Accuracy: 36.7\n",
            "[9/150]: Training Loss: 2.4561512488538346, Training Accuracy: 36.162\n",
            "Validation Loss: 2.41026672663962, Validation Accuracy: 37.97\n",
            "[10/150]: Training Loss: 2.4110919961234187, Training Accuracy: 37.32\n",
            "Validation Loss: 2.3787831933635055, Validation Accuracy: 37.75\n",
            "[11/150]: Training Loss: 2.374972592686753, Training Accuracy: 37.942\n",
            "Validation Loss: 2.419552489450783, Validation Accuracy: 38.02\n",
            "[12/150]: Training Loss: 2.341363592220999, Training Accuracy: 38.71\n",
            "Validation Loss: 2.353040744544594, Validation Accuracy: 39.18\n",
            "[13/150]: Training Loss: 2.3113136654314785, Training Accuracy: 39.284\n",
            "Validation Loss: 2.329031374044479, Validation Accuracy: 40.04\n",
            "[14/150]: Training Loss: 2.286358056928191, Training Accuracy: 39.702\n",
            "Validation Loss: 2.353606297711658, Validation Accuracy: 38.89\n",
            "[15/150]: Training Loss: 2.255754057251279, Training Accuracy: 40.382\n",
            "Validation Loss: 2.313938088477797, Validation Accuracy: 40.46\n",
            "[16/150]: Training Loss: 2.2417570858660256, Training Accuracy: 40.766\n",
            "Validation Loss: 2.245134223798278, Validation Accuracy: 41.86\n",
            "[17/150]: Training Loss: 2.229791578886759, Training Accuracy: 40.774\n",
            "Validation Loss: 2.2972328845103074, Validation Accuracy: 40.73\n",
            "[18/150]: Training Loss: 2.198040244981761, Training Accuracy: 41.792\n",
            "Validation Loss: 2.284319670337021, Validation Accuracy: 40.6\n",
            "[19/150]: Training Loss: 2.1809934542307157, Training Accuracy: 41.802\n",
            "Validation Loss: 2.2219127932931206, Validation Accuracy: 41.97\n",
            "[20/150]: Training Loss: 2.172169676827043, Training Accuracy: 41.862\n",
            "Validation Loss: 2.3093747029638596, Validation Accuracy: 40.82\n",
            "[21/150]: Training Loss: 2.1469304264353974, Training Accuracy: 42.644\n",
            "Validation Loss: 2.2553204001894422, Validation Accuracy: 41.67\n",
            "[22/150]: Training Loss: 2.1338748418156754, Training Accuracy: 43.018\n",
            "Validation Loss: 2.300890388002821, Validation Accuracy: 40.66\n",
            "[23/150]: Training Loss: 2.120842968259016, Training Accuracy: 43.254\n",
            "Validation Loss: 2.2334311372914892, Validation Accuracy: 41.97\n",
            "[24/150]: Training Loss: 2.0970673977261614, Training Accuracy: 43.616\n",
            "Validation Loss: 2.2538574728996132, Validation Accuracy: 42.09\n",
            "[25/150]: Training Loss: 2.0897668813500565, Training Accuracy: 43.946\n",
            "Validation Loss: 2.2414238969231866, Validation Accuracy: 41.72\n",
            "[26/150]: Training Loss: 2.0756560088423512, Training Accuracy: 44.038\n",
            "Validation Loss: 2.1973593523547907, Validation Accuracy: 43.01\n",
            "[27/150]: Training Loss: 2.057910572537376, Training Accuracy: 44.59\n",
            "Validation Loss: 2.2248903679999574, Validation Accuracy: 42.7\n",
            "[28/150]: Training Loss: 2.043146767274803, Training Accuracy: 45.032\n",
            "Validation Loss: 2.210173088274184, Validation Accuracy: 42.56\n",
            "[29/150]: Training Loss: 2.03314662345535, Training Accuracy: 45.244\n",
            "Validation Loss: 2.2085875697955966, Validation Accuracy: 42.59\n",
            "[30/150]: Training Loss: 2.028535710576245, Training Accuracy: 45.074\n",
            "Validation Loss: 2.2007097385491536, Validation Accuracy: 43.4\n",
            "[31/150]: Training Loss: 2.009151526576723, Training Accuracy: 45.862\n",
            "Validation Loss: 2.201018148926413, Validation Accuracy: 43.24\n",
            "[32/150]: Training Loss: 1.9960764486466527, Training Accuracy: 46.118\n",
            "Validation Loss: 2.207929955925911, Validation Accuracy: 43.19\n",
            "[33/150]: Training Loss: 1.988575564930811, Training Accuracy: 46.282\n",
            "Validation Loss: 2.2023386712286883, Validation Accuracy: 43.24\n",
            "[34/150]: Training Loss: 1.9779068563905213, Training Accuracy: 46.246\n",
            "Validation Loss: 2.1736220698447744, Validation Accuracy: 43.85\n",
            "[35/150]: Training Loss: 1.9696562569159681, Training Accuracy: 46.612\n",
            "Validation Loss: 2.2412819467532406, Validation Accuracy: 42.97\n",
            "[36/150]: Training Loss: 1.9518849866469499, Training Accuracy: 47.002\n",
            "Validation Loss: 2.142467891334728, Validation Accuracy: 44.48\n",
            "[37/150]: Training Loss: 1.942737179491526, Training Accuracy: 47.244\n",
            "Validation Loss: 2.1808249912444193, Validation Accuracy: 43.96\n",
            "[38/150]: Training Loss: 1.934893620441027, Training Accuracy: 47.278\n",
            "Validation Loss: 2.194337487220764, Validation Accuracy: 44.03\n",
            "[39/150]: Training Loss: 1.9254444508296449, Training Accuracy: 47.672\n",
            "Validation Loss: 2.1627620777506738, Validation Accuracy: 44.64\n",
            "[40/150]: Training Loss: 1.9116085487253525, Training Accuracy: 47.786\n",
            "Validation Loss: 2.143426476770146, Validation Accuracy: 44.69\n",
            "[41/150]: Training Loss: 1.8990542265155432, Training Accuracy: 48.106\n",
            "Validation Loss: 2.1570872994744854, Validation Accuracy: 44.18\n",
            "[42/150]: Training Loss: 1.8952381147448059, Training Accuracy: 48.148\n",
            "Validation Loss: 2.179479962701251, Validation Accuracy: 44.42\n",
            "[43/150]: Training Loss: 1.8831077039699116, Training Accuracy: 48.608\n",
            "Validation Loss: 2.14893990337469, Validation Accuracy: 44.65\n",
            "[44/150]: Training Loss: 1.8653588525169646, Training Accuracy: 49.024\n",
            "Validation Loss: 2.139679863954046, Validation Accuracy: 44.98\n",
            "[45/150]: Training Loss: 1.8571323093855778, Training Accuracy: 49.132\n",
            "Validation Loss: 2.1511670715489966, Validation Accuracy: 45.05\n",
            "[46/150]: Training Loss: 1.851196085248152, Training Accuracy: 49.268\n",
            "Validation Loss: 2.1228003342440176, Validation Accuracy: 45.15\n",
            "[47/150]: Training Loss: 1.8476994010188696, Training Accuracy: 49.152\n",
            "Validation Loss: 2.2052687976011045, Validation Accuracy: 44.33\n",
            "[48/150]: Training Loss: 1.834682262919443, Training Accuracy: 49.48\n",
            "Validation Loss: 2.167970584456328, Validation Accuracy: 44.5\n",
            "[49/150]: Training Loss: 1.8160154127403902, Training Accuracy: 50.016\n",
            "Validation Loss: 2.1706748312445963, Validation Accuracy: 44.33\n",
            "[50/150]: Training Loss: 1.8177930782823002, Training Accuracy: 49.864\n",
            "Validation Loss: 2.1794446357496224, Validation Accuracy: 44.96\n",
            "[51/150]: Training Loss: 1.8067406710913725, Training Accuracy: 50.086\n",
            "Validation Loss: 2.1342575109688338, Validation Accuracy: 45.96\n",
            "[52/150]: Training Loss: 1.7917756205019744, Training Accuracy: 50.474\n",
            "Validation Loss: 2.1779661793617686, Validation Accuracy: 45.2\n",
            "[53/150]: Training Loss: 1.7835827201528622, Training Accuracy: 50.574\n",
            "Validation Loss: 2.105961331136667, Validation Accuracy: 46.26\n",
            "[54/150]: Training Loss: 1.775593501527596, Training Accuracy: 50.768\n",
            "Validation Loss: 2.135809161860472, Validation Accuracy: 45.59\n",
            "[55/150]: Training Loss: 1.774858244087385, Training Accuracy: 50.898\n",
            "Validation Loss: 2.129430113324694, Validation Accuracy: 45.8\n",
            "[56/150]: Training Loss: 1.7574954881997364, Training Accuracy: 51.258\n",
            "Validation Loss: 2.1614714724243065, Validation Accuracy: 45.34\n",
            "[57/150]: Training Loss: 1.7551402684367832, Training Accuracy: 51.536\n",
            "Validation Loss: 2.116780410906312, Validation Accuracy: 45.57\n",
            "[58/150]: Training Loss: 1.7323481986284865, Training Accuracy: 51.87\n",
            "Validation Loss: 2.1469044146264435, Validation Accuracy: 46.29\n",
            "[59/150]: Training Loss: 1.731923724684264, Training Accuracy: 52.004\n",
            "Validation Loss: 2.103028847913074, Validation Accuracy: 46.36\n",
            "[60/150]: Training Loss: 1.7310465676400362, Training Accuracy: 52.0\n",
            "Validation Loss: 2.1536702441561753, Validation Accuracy: 45.7\n",
            "[61/150]: Training Loss: 1.7244189166656845, Training Accuracy: 51.944\n",
            "Validation Loss: 2.140022467655741, Validation Accuracy: 45.48\n",
            "[62/150]: Training Loss: 1.7049367572645397, Training Accuracy: 52.6\n",
            "Validation Loss: 2.1410929146845628, Validation Accuracy: 46.43\n",
            "[63/150]: Training Loss: 1.6979511242998226, Training Accuracy: 52.706\n",
            "Validation Loss: 2.159957699714952, Validation Accuracy: 45.77\n",
            "[64/150]: Training Loss: 1.6934019074110729, Training Accuracy: 52.83\n",
            "Validation Loss: 2.1361425302590535, Validation Accuracy: 46.59\n",
            "[65/150]: Training Loss: 1.6794907693058023, Training Accuracy: 53.024\n",
            "Validation Loss: 2.1693425915043827, Validation Accuracy: 46.15\n",
            "[66/150]: Training Loss: 1.6717879327056964, Training Accuracy: 53.454\n",
            "Validation Loss: 2.1304182694975737, Validation Accuracy: 46.71\n",
            "[67/150]: Training Loss: 1.6595926739828055, Training Accuracy: 53.614\n",
            "Validation Loss: 2.120200866346906, Validation Accuracy: 46.39\n",
            "[68/150]: Training Loss: 1.648870440395287, Training Accuracy: 54.184\n",
            "Validation Loss: 2.098656458459842, Validation Accuracy: 46.87\n",
            "[69/150]: Training Loss: 1.63317440499735, Training Accuracy: 53.856\n",
            "Validation Loss: 2.10397704163934, Validation Accuracy: 47.28\n",
            "[70/150]: Training Loss: 1.6387051284465644, Training Accuracy: 54.282\n",
            "Validation Loss: 2.0964533455052954, Validation Accuracy: 47.14\n",
            "[71/150]: Training Loss: 1.6188073368633495, Training Accuracy: 54.606\n",
            "Validation Loss: 2.12077300032233, Validation Accuracy: 46.67\n",
            "[72/150]: Training Loss: 1.6113011437608762, Training Accuracy: 54.874\n",
            "Validation Loss: 2.1084914108750166, Validation Accuracy: 47.47\n",
            "[73/150]: Training Loss: 1.6181168059253936, Training Accuracy: 54.584\n",
            "Validation Loss: 2.0926199581972353, Validation Accuracy: 47.8\n",
            "[74/150]: Training Loss: 1.6009672808525202, Training Accuracy: 55.14\n",
            "Validation Loss: 2.1137902524061265, Validation Accuracy: 47.2\n",
            "[75/150]: Training Loss: 1.5877168545942477, Training Accuracy: 55.52\n",
            "Validation Loss: 2.0988229885222807, Validation Accuracy: 47.29\n",
            "[76/150]: Training Loss: 1.5841481110933797, Training Accuracy: 55.536\n",
            "Validation Loss: 2.130301916675203, Validation Accuracy: 47.01\n",
            "[77/150]: Training Loss: 1.572215504810938, Training Accuracy: 55.894\n",
            "Validation Loss: 2.149995141727909, Validation Accuracy: 47.05\n",
            "[78/150]: Training Loss: 1.5624580438179738, Training Accuracy: 55.868\n",
            "Validation Loss: 2.111784276688934, Validation Accuracy: 47.42\n",
            "[79/150]: Training Loss: 1.5614525537051813, Training Accuracy: 55.984\n",
            "Validation Loss: 2.114105687019931, Validation Accuracy: 47.26\n",
            "[80/150]: Training Loss: 1.539920823577115, Training Accuracy: 56.65\n",
            "Validation Loss: 2.113597672456389, Validation Accuracy: 48.04\n",
            "[81/150]: Training Loss: 1.5321300439822398, Training Accuracy: 56.72\n",
            "Validation Loss: 2.115057561048277, Validation Accuracy: 47.52\n",
            "[82/150]: Training Loss: 1.5347046963394146, Training Accuracy: 56.472\n",
            "Validation Loss: 2.120380314292422, Validation Accuracy: 47.69\n",
            "[83/150]: Training Loss: 1.5234107173922118, Training Accuracy: 56.854\n",
            "Validation Loss: 2.117662426772391, Validation Accuracy: 47.66\n",
            "[84/150]: Training Loss: 1.5176254797469624, Training Accuracy: 57.066\n",
            "Validation Loss: 2.1148886255397916, Validation Accuracy: 47.15\n",
            "[85/150]: Training Loss: 1.5007459478610008, Training Accuracy: 57.452\n",
            "Validation Loss: 2.114618365931663, Validation Accuracy: 47.39\n",
            "[86/150]: Training Loss: 1.4968964526872806, Training Accuracy: 57.466\n",
            "Validation Loss: 2.1021699586491676, Validation Accuracy: 47.78\n",
            "[87/150]: Training Loss: 1.4844805052518235, Training Accuracy: 57.862\n",
            "Validation Loss: 2.1039314968570784, Validation Accuracy: 47.72\n",
            "[88/150]: Training Loss: 1.4738873809652255, Training Accuracy: 58.114\n",
            "Validation Loss: 2.097645890181232, Validation Accuracy: 48.24\n",
            "[89/150]: Training Loss: 1.483021430271056, Training Accuracy: 57.876\n",
            "Validation Loss: 2.108822873443555, Validation Accuracy: 47.97\n",
            "[90/150]: Training Loss: 1.4626602787343437, Training Accuracy: 58.702\n",
            "Validation Loss: 2.0972186729406856, Validation Accuracy: 47.88\n",
            "[91/150]: Training Loss: 1.4539960583152673, Training Accuracy: 58.564\n",
            "Validation Loss: 2.1077453277672933, Validation Accuracy: 48.02\n",
            "[92/150]: Training Loss: 1.4446301146236527, Training Accuracy: 58.7\n",
            "Validation Loss: 2.0844076651676446, Validation Accuracy: 48.44\n",
            "[93/150]: Training Loss: 1.4391108949471008, Training Accuracy: 59.026\n",
            "Validation Loss: 2.093005408147338, Validation Accuracy: 48.37\n",
            "[94/150]: Training Loss: 1.423930914581889, Training Accuracy: 59.616\n",
            "Validation Loss: 2.1331047563795833, Validation Accuracy: 47.89\n",
            "[95/150]: Training Loss: 1.41947230582347, Training Accuracy: 59.502\n",
            "Validation Loss: 2.1126899483856882, Validation Accuracy: 48.0\n",
            "[96/150]: Training Loss: 1.4149078359384366, Training Accuracy: 59.56\n",
            "Validation Loss: 2.0845493116196554, Validation Accuracy: 48.7\n",
            "[97/150]: Training Loss: 1.3990580768841308, Training Accuracy: 60.132\n",
            "Validation Loss: 2.1009285654991294, Validation Accuracy: 48.44\n",
            "[98/150]: Training Loss: 1.4016986463380896, Training Accuracy: 60.082\n",
            "Validation Loss: 2.1022102696121117, Validation Accuracy: 48.23\n",
            "[99/150]: Training Loss: 1.391786497572194, Training Accuracy: 60.44\n",
            "Validation Loss: 2.087019986407772, Validation Accuracy: 48.33\n",
            "[100/150]: Training Loss: 1.3808096985682807, Training Accuracy: 60.598\n",
            "Validation Loss: 2.1079373640619266, Validation Accuracy: 48.46\n",
            "[101/150]: Training Loss: 1.375501683377244, Training Accuracy: 60.572\n",
            "Validation Loss: 2.1078098131592866, Validation Accuracy: 48.82\n",
            "[102/150]: Training Loss: 1.3738657930470488, Training Accuracy: 60.484\n",
            "Validation Loss: 2.118699251466496, Validation Accuracy: 47.93\n",
            "[103/150]: Training Loss: 1.366849816973557, Training Accuracy: 60.848\n",
            "Validation Loss: 2.07916833564734, Validation Accuracy: 49.02\n",
            "[104/150]: Training Loss: 1.3610880574606874, Training Accuracy: 60.932\n",
            "Validation Loss: 2.087844172860407, Validation Accuracy: 48.91\n",
            "[105/150]: Training Loss: 1.34294292833799, Training Accuracy: 61.462\n",
            "Validation Loss: 2.1156119442289802, Validation Accuracy: 49.17\n",
            "[106/150]: Training Loss: 1.3525332610320557, Training Accuracy: 61.288\n",
            "Validation Loss: 2.0910707043994003, Validation Accuracy: 48.55\n",
            "[107/150]: Training Loss: 1.331598934538834, Training Accuracy: 61.91\n",
            "Validation Loss: 2.1001909211942347, Validation Accuracy: 49.0\n",
            "[108/150]: Training Loss: 1.3267096242179042, Training Accuracy: 61.816\n",
            "Validation Loss: 2.1083290622492505, Validation Accuracy: 48.74\n",
            "[109/150]: Training Loss: 1.3154139440230397, Training Accuracy: 62.34\n",
            "Validation Loss: 2.1171723535865734, Validation Accuracy: 49.04\n",
            "[110/150]: Training Loss: 1.3305041518662593, Training Accuracy: 61.83\n",
            "Validation Loss: 2.0921388515241586, Validation Accuracy: 49.21\n",
            "[111/150]: Training Loss: 1.3154786750483696, Training Accuracy: 61.994\n",
            "Validation Loss: 2.1219316781706112, Validation Accuracy: 48.77\n",
            "[112/150]: Training Loss: 1.3147668346876988, Training Accuracy: 61.946\n",
            "Validation Loss: 2.0896254671607046, Validation Accuracy: 48.89\n",
            "[113/150]: Training Loss: 1.3001932930915863, Training Accuracy: 62.724\n",
            "Validation Loss: 2.103232970662937, Validation Accuracy: 49.02\n",
            "[114/150]: Training Loss: 1.2976091802120209, Training Accuracy: 62.64\n",
            "Validation Loss: 2.089232644457726, Validation Accuracy: 48.88\n",
            "[115/150]: Training Loss: 1.2918279953015126, Training Accuracy: 62.894\n",
            "Validation Loss: 2.098377283971021, Validation Accuracy: 49.17\n",
            "[116/150]: Training Loss: 1.2901173764482483, Training Accuracy: 63.008\n",
            "Validation Loss: 2.096894028080497, Validation Accuracy: 49.39\n",
            "[117/150]: Training Loss: 1.275385139619603, Training Accuracy: 63.266\n",
            "Validation Loss: 2.1110763952230953, Validation Accuracy: 49.35\n",
            "[118/150]: Training Loss: 1.2755424442803462, Training Accuracy: 63.438\n",
            "Validation Loss: 2.1062107443050215, Validation Accuracy: 49.34\n",
            "[119/150]: Training Loss: 1.2707537008673333, Training Accuracy: 63.144\n",
            "Validation Loss: 2.094398064977804, Validation Accuracy: 49.44\n",
            "[120/150]: Training Loss: 1.2619870495613275, Training Accuracy: 63.662\n",
            "Validation Loss: 2.109912445590754, Validation Accuracy: 49.31\n",
            "[121/150]: Training Loss: 1.2651302716921053, Training Accuracy: 63.564\n",
            "Validation Loss: 2.1148870439286442, Validation Accuracy: 48.87\n",
            "[122/150]: Training Loss: 1.2517427335614744, Training Accuracy: 63.992\n",
            "Validation Loss: 2.111772822726304, Validation Accuracy: 49.14\n",
            "[123/150]: Training Loss: 1.2525572213522917, Training Accuracy: 63.8\n",
            "Validation Loss: 2.097744130784539, Validation Accuracy: 49.4\n",
            "[124/150]: Training Loss: 1.2481763019891041, Training Accuracy: 63.982\n",
            "Validation Loss: 2.110331610509544, Validation Accuracy: 49.5\n",
            "[125/150]: Training Loss: 1.242631159322646, Training Accuracy: 64.258\n",
            "Validation Loss: 2.113812481521801, Validation Accuracy: 49.25\n",
            "[126/150]: Training Loss: 1.2439294564144692, Training Accuracy: 64.134\n",
            "Validation Loss: 2.106003999710083, Validation Accuracy: 49.44\n",
            "[127/150]: Training Loss: 1.2376054860746768, Training Accuracy: 64.1\n",
            "Validation Loss: 2.1138451304405357, Validation Accuracy: 49.45\n",
            "[128/150]: Training Loss: 1.2359750416425184, Training Accuracy: 64.344\n",
            "Validation Loss: 2.0956578482488157, Validation Accuracy: 49.5\n",
            "[129/150]: Training Loss: 1.2426931114910205, Training Accuracy: 64.084\n",
            "Validation Loss: 2.102140469915548, Validation Accuracy: 49.39\n",
            "[130/150]: Training Loss: 1.2271092739099128, Training Accuracy: 64.588\n",
            "Validation Loss: 2.1065317156967844, Validation Accuracy: 49.55\n",
            "[131/150]: Training Loss: 1.2293265251552357, Training Accuracy: 64.606\n",
            "Validation Loss: 2.1087451816364458, Validation Accuracy: 49.71\n",
            "[132/150]: Training Loss: 1.2165279118606196, Training Accuracy: 64.626\n",
            "Validation Loss: 2.1100895678161815, Validation Accuracy: 49.58\n",
            "[133/150]: Training Loss: 1.2260109276112998, Training Accuracy: 64.716\n",
            "Validation Loss: 2.107479982315355, Validation Accuracy: 49.48\n",
            "[134/150]: Training Loss: 1.2170597407823938, Training Accuracy: 64.91\n",
            "Validation Loss: 2.109668661075033, Validation Accuracy: 49.21\n",
            "[135/150]: Training Loss: 1.2119625063655932, Training Accuracy: 64.864\n",
            "Validation Loss: 2.1121888259413897, Validation Accuracy: 49.6\n",
            "[136/150]: Training Loss: 1.2143927402508534, Training Accuracy: 64.752\n",
            "Validation Loss: 2.1146486792594765, Validation Accuracy: 49.42\n",
            "[137/150]: Training Loss: 1.20208662275768, Training Accuracy: 65.196\n",
            "Validation Loss: 2.1086552408850117, Validation Accuracy: 49.53\n",
            "[138/150]: Training Loss: 1.2066055967679719, Training Accuracy: 65.132\n",
            "Validation Loss: 2.106570492884156, Validation Accuracy: 49.36\n",
            "[139/150]: Training Loss: 1.2045007688767464, Training Accuracy: 65.206\n",
            "Validation Loss: 2.1134595893750525, Validation Accuracy: 49.61\n",
            "[140/150]: Training Loss: 1.209533206413469, Training Accuracy: 65.066\n",
            "Validation Loss: 2.111029122285782, Validation Accuracy: 49.59\n",
            "[141/150]: Training Loss: 1.2018247985321542, Training Accuracy: 64.974\n",
            "Validation Loss: 2.112992768834351, Validation Accuracy: 49.59\n",
            "[142/150]: Training Loss: 1.2081030414384955, Training Accuracy: 65.38\n",
            "Validation Loss: 2.1114872906618056, Validation Accuracy: 49.54\n",
            "[143/150]: Training Loss: 1.1987551257128606, Training Accuracy: 65.484\n",
            "Validation Loss: 2.11025989283422, Validation Accuracy: 49.53\n",
            "[144/150]: Training Loss: 1.204268764961711, Training Accuracy: 65.084\n",
            "Validation Loss: 2.1116166456489807, Validation Accuracy: 49.52\n",
            "[145/150]: Training Loss: 1.2022794322741917, Training Accuracy: 65.088\n",
            "Validation Loss: 2.1134905511406576, Validation Accuracy: 49.47\n",
            "[146/150]: Training Loss: 1.1945363251144623, Training Accuracy: 65.452\n",
            "Validation Loss: 2.1135922700736174, Validation Accuracy: 49.52\n",
            "[147/150]: Training Loss: 1.1900141044803287, Training Accuracy: 65.494\n",
            "Validation Loss: 2.113608984430884, Validation Accuracy: 49.49\n",
            "[148/150]: Training Loss: 1.2009751156467916, Training Accuracy: 65.298\n",
            "Validation Loss: 2.1133065656491907, Validation Accuracy: 49.47\n",
            "[149/150]: Training Loss: 1.2031257037464005, Training Accuracy: 65.434\n",
            "Validation Loss: 2.113412342253764, Validation Accuracy: 49.47\n",
            "[150/150]: Training Loss: 1.1963014528726983, Training Accuracy: 65.458\n",
            "Validation Loss: 2.113395432757724, Validation Accuracy: 49.47\n",
            "**********************************************************************\n",
            "Test Loss: 2.113395432757724, Test Accuracy: 49.47\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▅▃▂▁▂▁▁▂▁▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁</td></tr><tr><td>Test Loss</td><td>▁▃▆▃█▆▅▇▅▅▃▃▃▄▄▃▃▃▄▅▆▅▅▄▄▅▅▅▄▄▄▄▄▄▄▄▄▄▃▃</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇██████████</td></tr><tr><td>Train Loss</td><td>█▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>49.47</td></tr><tr><td>Test Loss</td><td>2.1134</td></tr><tr><td>Train Accuracy</td><td>65.458</td></tr><tr><td>Train Loss</td><td>1.1963</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_003350-ulxra0pg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1e-03\n",
        "wd = 4e-04\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model_1 = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer_1 = torch.optim.AdamW(model_1.parameters(), lr=lr, weight_decay=wd)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_1, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model_1, original_train_loader, original_test_loader, original_test_loader, optimizer_1, scheduler, criterion, device, optimizer_name='AdamW', hyperparameters=hyperparameters, is_wandb = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeMWj_f0sbQE"
      },
      "source": [
        "### **Large Batch Optimizers**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "WkZmVFG0q90m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "\n",
        "class LARS(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements LARS (Layer-wise Adaptive Rate Scaling).\n",
        "\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "        lr (float): learning rate (default: 1e-3)\n",
        "        momentum (float, optional): momentum factor (default: 0)\n",
        "        trust_coef (float, optional): LARS coefficient as used in the paper (default: 1e-3)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        dampening (float, optional): dampening for momentum (default: 0)\n",
        "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
        "        epsilon (float, optional): epsilon to prevent zero division (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            params,\n",
        "            lr: float = 1e-3,\n",
        "            momentum: float = 0,\n",
        "            trust_coef: float = 1e-3,\n",
        "            dampening: float = 0,\n",
        "            weight_decay: float = 0,\n",
        "            nesterov=False,\n",
        "            epsilon: float = 1e-9\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LARS optimizer.\n",
        "\n",
        "        Args:\n",
        "            params: iterable of parameters to optimize or dicts defining\n",
        "            lr: learning rate\n",
        "            momentum: momentum factor\n",
        "            trust_coef: LARS coefficient as used in the paper\n",
        "            weight_decay: weight decay (L2 penalty)\n",
        "            dampening: dampening for momentum\n",
        "            nesterov: enables Nesterov momentum\n",
        "            epsilon: epsilon to prevent zero division\n",
        "        \"\"\"\n",
        "\n",
        "        if lr <= 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(\n",
        "            lr=lr,\n",
        "            momentum=momentum,\n",
        "            trust_coef=trust_coef,\n",
        "            dampening=dampening,\n",
        "            weight_decay=weight_decay,\n",
        "            nesterov=nesterov,\n",
        "            epsilon=epsilon)\n",
        "\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(LARS, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        \"\"\"\n",
        "        Sets the state of the optimizer.\n",
        "\n",
        "        Args:\n",
        "            state: The state to set the optimizer to.\n",
        "        \"\"\"\n",
        "        super(LARS, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def _compute_local_lr(self, p, weight_decay, trust_coef, epsilon):\n",
        "        \"\"\"\n",
        "        Computes the local learning rate for a given parameter.\n",
        "\n",
        "        Args:\n",
        "            p: The parameter to compute the local learning rate for.\n",
        "            weight_decay: The weight decay factor.\n",
        "            trust_coef: The trust coefficient.\n",
        "            epsilon: A small constant for numerical stability.\n",
        "\n",
        "        Returns:\n",
        "            float: The computed local learning rate.\n",
        "        \"\"\"\n",
        "        w_norm = torch.norm(p.data)\n",
        "        g_norm = torch.norm(p.grad.data)\n",
        "        if w_norm * g_norm > 0:\n",
        "            return trust_coef * w_norm / (g_norm + weight_decay * w_norm + epsilon)\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def _update_params(self, p, d_p, local_lr, lr, momentum, buf,\n",
        "                       dampening, nesterov, weight_decay):\n",
        "        \"\"\"\n",
        "        Updates the parameters with the computed update.\n",
        "\n",
        "        Args:\n",
        "            p: The parameter to be updated.\n",
        "            d_p: The computed update for the parameter.\n",
        "            local_lr: The local learning rate.\n",
        "            lr: The global learning rate.\n",
        "            momentum: The momentum factor.\n",
        "            buf: The buffer for the momentum.\n",
        "            dampening: The dampening for the momentum.\n",
        "            nesterov: A flag indicating whether to use Nesterov momentum.\n",
        "            weight_decay: The weight decay factor.\n",
        "        \"\"\"\n",
        "        if weight_decay != 0:\n",
        "            d_p.add_(weight_decay, p.data)\n",
        "        if momentum != 0:\n",
        "            param_state = self.state[p]\n",
        "            if 'momentum_buffer' not in param_state:\n",
        "                buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "            else:\n",
        "                buf = param_state['momentum_buffer']\n",
        "            buf.mul_(momentum).add_(1 - dampening, d_p)\n",
        "            if nesterov:\n",
        "                d_p = d_p.add(momentum, buf)\n",
        "            else:\n",
        "                d_p = buf\n",
        "\n",
        "        p.data.add_(-local_lr * lr, d_p)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            trust_coef = group['trust_coef']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "            epsilon = group['epsilon']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                local_lr = self._compute_local_lr(p, weight_decay, trust_coef, epsilon)\n",
        "                self._update_params(p, p.grad.data, local_lr, group['lr'], momentum, None, dampening, nesterov, weight_decay)\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "k3ow7VNfs377"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from typing import Optional, Union, Callable, List\n",
        "\n",
        "class LAMB(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements LAMB (Layer-wise Adaptive Moments) optimizer.\n",
        "\n",
        "    Args:\n",
        "        params (iterable): Iterable of parameters to optimize or dicts defining parameter groups.\n",
        "        learning_rate (Union[float, Callable], optional): The learning rate. Default is 0.001.\n",
        "        beta_1 (float, optional): The exponential decay rate for the 1st moment estimates. Default is 0.9.\n",
        "        beta_2 (float, optional): The exponential decay rate for the 2nd moment estimates. Default is 0.999.\n",
        "        epsilon (float, optional): A small constant for numerical stability. Default is 1e-6.\n",
        "        weight_decay (float, optional): Weight decay. Default is 0.0.\n",
        "        exclude_from_weight_decay (Optional[List[str]], optional): List of regex patterns of variables excluded from weight decay. Variables whose name contain a substring matching the pattern will be excluded. Default is None.\n",
        "        exclude_from_layer_adaptation (Optional[List[str]], optional): List of regex patterns of variables excluded from layer adaptation. Variables whose name contain a substring matching the pattern will be excluded. Default is None.\n",
        "        name (str, optional): Optional name for the operations created when applying gradients. Defaults to \"LAMB\".\n",
        "        **kwargs: Keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip gradients by value, `decay` is included for backward compatibility to allow time inverse decay of learning rate. `lr` is included for backward compatibility, recommended to use `learning_rate` instead.\n",
        "\n",
        "    Note:\n",
        "        - If \"weight_decay_rate\" is found in kwargs, it will be renamed to \"weight_decay\", and will be deprecated in Addons 0.18.\n",
        "        - If exclude_from_layer_adaptation is None, it will be set to exclude_from_weight_decay.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr: Union[float, Callable] = 0.001,\n",
        "        beta_1: float = 0.9,\n",
        "        beta_2: float = 0.999,\n",
        "        epsilon: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        exclude_from_weight_decay: Optional[List[str]] = None,\n",
        "        exclude_from_layer_adaptation: Optional[List[str]] = None,\n",
        "        name: str = \"LAMB\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LAMB optimizer.\n",
        "        \"\"\"\n",
        "\n",
        "        if \"weight_decay_rate\" in kwargs:\n",
        "            warnings.warn(\n",
        "                \"weight_decay_rate has been renamed to weight_decay,\"\n",
        "                \"and will be deprecated in Addons 0.18.\",\n",
        "                DeprecationWarning,\n",
        "            )\n",
        "            weight_decay = kwargs[\"weight_decay_rate\"]\n",
        "            del kwargs[\"weight_decay_rate\"]\n",
        "\n",
        "        defaults = dict(\n",
        "            lr=lr,\n",
        "            betas=(beta_1, beta_2),\n",
        "            eps=epsilon,\n",
        "            weight_decay=weight_decay,\n",
        "            **kwargs)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "        # exclude_from_layer_adaptation is set to exclude_from_weight_decay if\n",
        "        # the arg is None.\n",
        "        if exclude_from_layer_adaptation:\n",
        "            self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "        else:\n",
        "            self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "    def _compute_update(self, p, grad, state, group):\n",
        "        \"\"\"\n",
        "        Computes the update for a given parameter.\n",
        "\n",
        "        Args:\n",
        "            p (Tensor): The parameter to be updated.\n",
        "            grad (Tensor): The gradient of the parameter.\n",
        "            state (dict): A dictionary containing information about the optimization state.\n",
        "            group (dict): A dictionary containing the optimization parameters.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The computed update for the parameter.\n",
        "        \"\"\"\n",
        "        # State initialization\n",
        "        if len(state) == 0:\n",
        "            state['step'] = 0\n",
        "            # Exponential moving average of gradient values\n",
        "            state['exp_avg'] = torch.zeros_like(p.data)\n",
        "            # Exponential moving average of squared gradient values\n",
        "            state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "        exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "        beta1, beta2 = group['betas']\n",
        "\n",
        "        state['step'] += 1\n",
        "\n",
        "        # Decay the first and second moment running average coefficient\n",
        "        exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "        exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "        denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "        update = exp_avg / denom\n",
        "\n",
        "        # LAMB layer-wise adaptation\n",
        "        r1 = p.data.pow(2).sum().sqrt()\n",
        "        r2 = update.pow(2).sum().sqrt()\n",
        "        r = torch.where(r1 == 0, torch.zeros_like(r1), r1 / r2)\n",
        "\n",
        "        return r * update\n",
        "\n",
        "    def _update_params(self, p, update, step_size, weight_decay):\n",
        "        \"\"\"\n",
        "        Updates the parameters with the computed update.\n",
        "\n",
        "        Args:\n",
        "            p (Tensor): The parameter to be updated.\n",
        "            update (Tensor): The computed update for the parameter.\n",
        "            step_size (float): The step size for the update.\n",
        "            weight_decay (float): The weight decay factor.\n",
        "        \"\"\"\n",
        "        if weight_decay != 0:\n",
        "            p.data.add_(-weight_decay * step_size, p.data)\n",
        "\n",
        "        p.data.add_(-step_size, update)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Args:\n",
        "            closure (callable, optional): A closure that reevaluates the model and returns the loss. Default is None.\n",
        "        \"\"\"\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('LAMB does not support sparse gradients.')\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                update = self._compute_update(p, grad, state, group)\n",
        "                self._update_params(p, update, group['lr'], group['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "dh421LdmM9XP"
      },
      "outputs": [],
      "source": [
        "learning_rates = [1e-02, 5e-02, 1e-01, 5e-01, 1, 1.5, 2]\n",
        "wd = 1e-03"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "30d70d57987c4349b55560e5d9626201",
            "36ac25551e574241bed4d7e5a4301d95",
            "6898349b9c754ca7be91bea29cabbba5",
            "623f947ef06c41569be7fcdda4141174",
            "d268f74266044451b230f20756bab2f6",
            "6896790e80d1450c821918c7ef41e42f",
            "a30700c8bfb449cda98a40d75828f3d3",
            "77beee57b67d4bad826f616e5483b87a",
            "c59ee0d8b9fb4694ada362115bf965a9",
            "ab62d64100a84b1faae744ee0f99501a",
            "6abbcbe71a314356ba04f8349d1fc127",
            "97c3921b8e454ccdb7b4db95d4440c64",
            "50b4ba3147b540abad020ae780353f27",
            "584e5a6aada04535b64c40c3ece566e8",
            "d3326a99729a416abca13d3122196e64",
            "1d534596e41340438fc8d083fff6aa8b",
            "19ed5f5d4f714246bbdf44513ecc50f0",
            "1f9d7ac8fa8a4bcdb76fe2b2cb443f66",
            "71c0cc303cfc44ba8d989d5f8feca119",
            "07dc9b3c563e4615bec4dbd3233bf4ba",
            "a3ccc0b32e9a4ceebd6045dff63e6621",
            "104402d4cba5477499593d972bc48e9d",
            "80fe0a51b14b4e548454d4f83215336c",
            "8e13a8bef6e14973912966984e83cd4c"
          ]
        },
        "id": "dzsCB_Q9NnCD",
        "outputId": "56d144bd-faa8-4df2-a19c-7cc15394622d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_022555-nh2g7isx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605613048553467, Training Accuracy: 1.0325\n",
            "Validation Loss: 4.605481047539195, Validation Accuracy: 1.01\n",
            "[2/150]: Training Loss: 4.603893094635009, Training Accuracy: 1.2825\n",
            "Validation Loss: 4.603514659176966, Validation Accuracy: 1.37\n",
            "[3/150]: Training Loss: 4.601452378845215, Training Accuracy: 1.7625\n",
            "Validation Loss: 4.600479241389378, Validation Accuracy: 1.96\n",
            "[4/150]: Training Loss: 4.597398109436035, Training Accuracy: 1.815\n",
            "Validation Loss: 4.595512341541849, Validation Accuracy: 1.41\n",
            "[5/150]: Training Loss: 4.590549831390381, Training Accuracy: 1.5175\n",
            "Validation Loss: 4.587287993947411, Validation Accuracy: 1.68\n",
            "[6/150]: Training Loss: 4.579249038696289, Training Accuracy: 1.93\n",
            "Validation Loss: 4.573939116897097, Validation Accuracy: 2.37\n",
            "[7/150]: Training Loss: 4.560530513763427, Training Accuracy: 2.69\n",
            "Validation Loss: 4.5522112117451465, Validation Accuracy: 2.64\n",
            "[8/150]: Training Loss: 4.5309873321533205, Training Accuracy: 2.92\n",
            "Validation Loss: 4.519049043108703, Validation Accuracy: 2.85\n",
            "[9/150]: Training Loss: 4.488997451782226, Training Accuracy: 2.9475\n",
            "Validation Loss: 4.475813519423175, Validation Accuracy: 3.12\n",
            "[10/150]: Training Loss: 4.439574425506592, Training Accuracy: 3.3375\n",
            "Validation Loss: 4.429785430811013, Validation Accuracy: 3.32\n",
            "[11/150]: Training Loss: 4.391272030639648, Training Accuracy: 3.61\n",
            "Validation Loss: 4.386288050633327, Validation Accuracy: 3.95\n",
            "[12/150]: Training Loss: 4.346567308807373, Training Accuracy: 4.215\n",
            "Validation Loss: 4.348948326839763, Validation Accuracy: 4.02\n",
            "[13/150]: Training Loss: 4.3075446601867675, Training Accuracy: 4.48\n",
            "Validation Loss: 4.312188755934406, Validation Accuracy: 4.38\n",
            "[14/150]: Training Loss: 4.274280471801758, Training Accuracy: 4.9575\n",
            "Validation Loss: 4.284171402074729, Validation Accuracy: 4.91\n",
            "[15/150]: Training Loss: 4.24782478981018, Training Accuracy: 5.3275\n",
            "Validation Loss: 4.261963683328811, Validation Accuracy: 5.05\n",
            "[16/150]: Training Loss: 4.226929823303223, Training Accuracy: 5.7425\n",
            "Validation Loss: 4.2434815540435205, Validation Accuracy: 5.46\n",
            "[17/150]: Training Loss: 4.210706592941285, Training Accuracy: 5.9375\n",
            "Validation Loss: 4.230875344792748, Validation Accuracy: 5.78\n",
            "[18/150]: Training Loss: 4.197167670059204, Training Accuracy: 6.23\n",
            "Validation Loss: 4.218225898256727, Validation Accuracy: 5.69\n",
            "[19/150]: Training Loss: 4.1860190193176265, Training Accuracy: 6.505\n",
            "Validation Loss: 4.208940963076937, Validation Accuracy: 5.86\n",
            "[20/150]: Training Loss: 4.175828193664551, Training Accuracy: 6.6025\n",
            "Validation Loss: 4.201019479970264, Validation Accuracy: 6.0\n",
            "[21/150]: Training Loss: 4.167100285339355, Training Accuracy: 6.8025\n",
            "Validation Loss: 4.1936384735593375, Validation Accuracy: 5.97\n",
            "[22/150]: Training Loss: 4.158846283340454, Training Accuracy: 6.92\n",
            "Validation Loss: 4.185141735016161, Validation Accuracy: 6.28\n",
            "[23/150]: Training Loss: 4.151738377380371, Training Accuracy: 7.0375\n",
            "Validation Loss: 4.178911400448745, Validation Accuracy: 6.83\n",
            "[24/150]: Training Loss: 4.144738430023193, Training Accuracy: 7.23\n",
            "Validation Loss: 4.172337419667821, Validation Accuracy: 6.52\n",
            "[25/150]: Training Loss: 4.1379581127166745, Training Accuracy: 7.265\n",
            "Validation Loss: 4.165943450988478, Validation Accuracy: 6.63\n",
            "[26/150]: Training Loss: 4.132068264770508, Training Accuracy: 7.4525\n",
            "Validation Loss: 4.160335552920202, Validation Accuracy: 7.0\n",
            "[27/150]: Training Loss: 4.126062253570557, Training Accuracy: 7.4725\n",
            "Validation Loss: 4.157630066962758, Validation Accuracy: 6.66\n",
            "[28/150]: Training Loss: 4.120529958724975, Training Accuracy: 7.52\n",
            "Validation Loss: 4.150649539983956, Validation Accuracy: 7.07\n",
            "[29/150]: Training Loss: 4.115550531768799, Training Accuracy: 7.6175\n",
            "Validation Loss: 4.145238416210102, Validation Accuracy: 7.01\n",
            "[30/150]: Training Loss: 4.109972083282471, Training Accuracy: 7.74\n",
            "Validation Loss: 4.140822541182208, Validation Accuracy: 6.87\n",
            "[31/150]: Training Loss: 4.1054605201721195, Training Accuracy: 7.7775\n",
            "Validation Loss: 4.135137576206475, Validation Accuracy: 7.26\n",
            "[32/150]: Training Loss: 4.100883611297608, Training Accuracy: 7.9175\n",
            "Validation Loss: 4.13245949623691, Validation Accuracy: 7.37\n",
            "[33/150]: Training Loss: 4.096106577682495, Training Accuracy: 7.965\n",
            "Validation Loss: 4.1272796597450405, Validation Accuracy: 7.21\n",
            "[34/150]: Training Loss: 4.092031303024292, Training Accuracy: 8.075\n",
            "Validation Loss: 4.1231977316983945, Validation Accuracy: 7.19\n",
            "[35/150]: Training Loss: 4.087661064910889, Training Accuracy: 8.0775\n",
            "Validation Loss: 4.119425037104612, Validation Accuracy: 7.42\n",
            "[36/150]: Training Loss: 4.083959820175171, Training Accuracy: 8.14\n",
            "Validation Loss: 4.117144297642313, Validation Accuracy: 7.43\n",
            "[37/150]: Training Loss: 4.079987169265747, Training Accuracy: 8.2575\n",
            "Validation Loss: 4.112940530108798, Validation Accuracy: 7.33\n",
            "[38/150]: Training Loss: 4.076256622695923, Training Accuracy: 8.275\n",
            "Validation Loss: 4.10887487071335, Validation Accuracy: 7.72\n",
            "[39/150]: Training Loss: 4.072722610473633, Training Accuracy: 8.2625\n",
            "Validation Loss: 4.1064621779569395, Validation Accuracy: 7.62\n",
            "[40/150]: Training Loss: 4.06919368019104, Training Accuracy: 8.4025\n",
            "Validation Loss: 4.102874081605559, Validation Accuracy: 7.77\n",
            "[41/150]: Training Loss: 4.065893580627441, Training Accuracy: 8.425\n",
            "Validation Loss: 4.101947505003328, Validation Accuracy: 7.99\n",
            "[42/150]: Training Loss: 4.062419548797608, Training Accuracy: 8.64\n",
            "Validation Loss: 4.096677272942416, Validation Accuracy: 7.69\n",
            "[43/150]: Training Loss: 4.059447618484497, Training Accuracy: 8.6025\n",
            "Validation Loss: 4.096899234565201, Validation Accuracy: 7.72\n",
            "[44/150]: Training Loss: 4.056013444137573, Training Accuracy: 8.5725\n",
            "Validation Loss: 4.091373089772121, Validation Accuracy: 7.88\n",
            "[45/150]: Training Loss: 4.053135622024536, Training Accuracy: 8.6275\n",
            "Validation Loss: 4.088051226488345, Validation Accuracy: 8.07\n",
            "[46/150]: Training Loss: 4.049987061309815, Training Accuracy: 8.63\n",
            "Validation Loss: 4.085329578180981, Validation Accuracy: 8.03\n",
            "[47/150]: Training Loss: 4.047172613143921, Training Accuracy: 8.7125\n",
            "Validation Loss: 4.082841596785625, Validation Accuracy: 7.78\n",
            "[48/150]: Training Loss: 4.0441587448120115, Training Accuracy: 8.745\n",
            "Validation Loss: 4.081506820241357, Validation Accuracy: 8.21\n",
            "[49/150]: Training Loss: 4.04135802230835, Training Accuracy: 8.82\n",
            "Validation Loss: 4.079341964357218, Validation Accuracy: 8.03\n",
            "[50/150]: Training Loss: 4.0387205871582035, Training Accuracy: 8.7775\n",
            "Validation Loss: 4.075337004509701, Validation Accuracy: 8.12\n",
            "[51/150]: Training Loss: 4.036031353759766, Training Accuracy: 8.9025\n",
            "Validation Loss: 4.074757421092623, Validation Accuracy: 8.17\n",
            "[52/150]: Training Loss: 4.033370276260376, Training Accuracy: 8.91\n",
            "Validation Loss: 4.071030196110914, Validation Accuracy: 8.29\n",
            "[53/150]: Training Loss: 4.031033205032348, Training Accuracy: 8.965\n",
            "Validation Loss: 4.069437462812776, Validation Accuracy: 8.36\n",
            "[54/150]: Training Loss: 4.028417000579834, Training Accuracy: 9.095\n",
            "Validation Loss: 4.067116659917649, Validation Accuracy: 8.11\n",
            "[55/150]: Training Loss: 4.0260539081573485, Training Accuracy: 9.045\n",
            "Validation Loss: 4.065322780305413, Validation Accuracy: 8.45\n",
            "[56/150]: Training Loss: 4.0235095344543454, Training Accuracy: 9.085\n",
            "Validation Loss: 4.064038521165301, Validation Accuracy: 8.38\n",
            "[57/150]: Training Loss: 4.02125683631897, Training Accuracy: 9.18\n",
            "Validation Loss: 4.0599597381178745, Validation Accuracy: 8.62\n",
            "[58/150]: Training Loss: 4.019049766159058, Training Accuracy: 9.2225\n",
            "Validation Loss: 4.058757024206174, Validation Accuracy: 8.53\n",
            "[59/150]: Training Loss: 4.016744113540649, Training Accuracy: 9.3325\n",
            "Validation Loss: 4.056453751910264, Validation Accuracy: 8.65\n",
            "[60/150]: Training Loss: 4.014383445358276, Training Accuracy: 9.33\n",
            "Validation Loss: 4.054738797959248, Validation Accuracy: 8.49\n",
            "[61/150]: Training Loss: 4.012673494720459, Training Accuracy: 9.4\n",
            "Validation Loss: 4.05312654015365, Validation Accuracy: 8.45\n",
            "[62/150]: Training Loss: 4.0104282833099365, Training Accuracy: 9.3375\n",
            "Validation Loss: 4.050798089640915, Validation Accuracy: 8.61\n",
            "[63/150]: Training Loss: 4.0085177280426025, Training Accuracy: 9.345\n",
            "Validation Loss: 4.047672698452215, Validation Accuracy: 9.08\n",
            "[64/150]: Training Loss: 4.007076532363891, Training Accuracy: 9.44\n",
            "Validation Loss: 4.047075613289122, Validation Accuracy: 8.55\n",
            "[65/150]: Training Loss: 4.004718017959595, Training Accuracy: 9.47\n",
            "Validation Loss: 4.044435259642874, Validation Accuracy: 8.66\n",
            "[66/150]: Training Loss: 4.002854734802246, Training Accuracy: 9.58\n",
            "Validation Loss: 4.043384468479521, Validation Accuracy: 8.68\n",
            "[67/150]: Training Loss: 4.000918030929565, Training Accuracy: 9.59\n",
            "Validation Loss: 4.042230905241268, Validation Accuracy: 8.87\n",
            "[68/150]: Training Loss: 3.9992192554473878, Training Accuracy: 9.5775\n",
            "Validation Loss: 4.040329585409468, Validation Accuracy: 8.83\n",
            "[69/150]: Training Loss: 3.9973626461029053, Training Accuracy: 9.615\n",
            "Validation Loss: 4.037929029221747, Validation Accuracy: 9.01\n",
            "[70/150]: Training Loss: 3.9957307056427003, Training Accuracy: 9.69\n",
            "Validation Loss: 4.037050957892351, Validation Accuracy: 8.67\n",
            "[71/150]: Training Loss: 3.9943285522460936, Training Accuracy: 9.7375\n",
            "Validation Loss: 4.0364253475407885, Validation Accuracy: 8.88\n",
            "[72/150]: Training Loss: 3.9925530368804933, Training Accuracy: 9.7025\n",
            "Validation Loss: 4.033815119676529, Validation Accuracy: 8.93\n",
            "[73/150]: Training Loss: 3.9908373458862303, Training Accuracy: 9.7625\n",
            "Validation Loss: 4.0321422671056855, Validation Accuracy: 8.97\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 4.837270994854581, Test Accuracy: 5.7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▇▂▂▂▂▂▁▁▁▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▁▁▇██▇▇█▇▇▆▇▇▇▇▆▇▇▇▇▆▆▆▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▃▃▄▄▄▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>████▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>5.7</td></tr><tr><td>Test Loss</td><td>4.83727</td></tr><tr><td>Train Accuracy</td><td>9.7625</td></tr><tr><td>Train Loss</td><td>3.99084</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_022555-nh2g7isx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.05 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_023355-cthymqs8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">learning_rate=0.05 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.600790646362305, Training Accuracy: 1.1675\n",
            "Validation Loss: 4.590667490746565, Validation Accuracy: 1.26\n",
            "[2/150]: Training Loss: 4.559383809661865, Training Accuracy: 2.1575\n",
            "Validation Loss: 4.506907958133965, Validation Accuracy: 2.54\n",
            "[3/150]: Training Loss: 4.4036731437683105, Training Accuracy: 3.8525\n",
            "Validation Loss: 4.321598778864381, Validation Accuracy: 4.84\n",
            "[4/150]: Training Loss: 4.246265041351318, Training Accuracy: 5.2175\n",
            "Validation Loss: 4.227905522486207, Validation Accuracy: 6.02\n",
            "[5/150]: Training Loss: 4.176178216934204, Training Accuracy: 6.1675\n",
            "Validation Loss: 4.179626170237353, Validation Accuracy: 6.38\n",
            "[6/150]: Training Loss: 4.135982835769654, Training Accuracy: 6.6675\n",
            "Validation Loss: 4.148335417364813, Validation Accuracy: 6.64\n",
            "[7/150]: Training Loss: 4.108450821304321, Training Accuracy: 7.2275\n",
            "Validation Loss: 4.130975275282648, Validation Accuracy: 6.89\n",
            "[8/150]: Training Loss: 4.0844139430999755, Training Accuracy: 7.6\n",
            "Validation Loss: 4.101699337078507, Validation Accuracy: 7.5\n",
            "[9/150]: Training Loss: 4.065156806564331, Training Accuracy: 7.93\n",
            "Validation Loss: 4.086441223788413, Validation Accuracy: 7.13\n",
            "[10/150]: Training Loss: 4.045691847991943, Training Accuracy: 8.4825\n",
            "Validation Loss: 4.07577043733779, Validation Accuracy: 8.03\n",
            "[11/150]: Training Loss: 4.029001393127442, Training Accuracy: 8.6075\n",
            "Validation Loss: 4.055504823186595, Validation Accuracy: 8.33\n",
            "[12/150]: Training Loss: 4.011618738937378, Training Accuracy: 9.0575\n",
            "Validation Loss: 4.039901239856793, Validation Accuracy: 8.48\n",
            "[13/150]: Training Loss: 3.9964084663391115, Training Accuracy: 9.2925\n",
            "Validation Loss: 4.02936831097694, Validation Accuracy: 8.91\n",
            "[14/150]: Training Loss: 3.9814702980041505, Training Accuracy: 9.4925\n",
            "Validation Loss: 4.011358877655807, Validation Accuracy: 9.08\n",
            "[15/150]: Training Loss: 3.967844100570679, Training Accuracy: 9.735\n",
            "Validation Loss: 4.00843292133064, Validation Accuracy: 9.01\n",
            "[16/150]: Training Loss: 3.9526515048980713, Training Accuracy: 10.11\n",
            "Validation Loss: 3.983490101091421, Validation Accuracy: 9.73\n",
            "[17/150]: Training Loss: 3.9376510147094725, Training Accuracy: 10.2675\n",
            "Validation Loss: 3.9689508137429597, Validation Accuracy: 9.61\n",
            "[18/150]: Training Loss: 3.9245626121520996, Training Accuracy: 10.52\n",
            "Validation Loss: 3.9620496361118973, Validation Accuracy: 9.98\n",
            "[19/150]: Training Loss: 3.910297552108765, Training Accuracy: 10.8175\n",
            "Validation Loss: 3.952874835129756, Validation Accuracy: 10.09\n",
            "[20/150]: Training Loss: 3.8983414665222167, Training Accuracy: 11.1225\n",
            "Validation Loss: 3.930051308528633, Validation Accuracy: 10.44\n",
            "[21/150]: Training Loss: 3.8838251056671145, Training Accuracy: 11.2975\n",
            "Validation Loss: 3.9188870700301637, Validation Accuracy: 10.53\n",
            "[22/150]: Training Loss: 3.870637998199463, Training Accuracy: 11.44\n",
            "Validation Loss: 3.903455512538837, Validation Accuracy: 10.81\n",
            "[23/150]: Training Loss: 3.857129457092285, Training Accuracy: 11.84\n",
            "Validation Loss: 3.8918681099156665, Validation Accuracy: 11.32\n",
            "[24/150]: Training Loss: 3.8432881324768067, Training Accuracy: 12.0075\n",
            "Validation Loss: 3.8916967568124177, Validation Accuracy: 11.36\n",
            "[25/150]: Training Loss: 3.829104020690918, Training Accuracy: 12.395\n",
            "Validation Loss: 3.874841636912838, Validation Accuracy: 11.71\n",
            "[26/150]: Training Loss: 3.814932382965088, Training Accuracy: 12.6375\n",
            "Validation Loss: 3.862990617752075, Validation Accuracy: 11.7\n",
            "[27/150]: Training Loss: 3.801380111312866, Training Accuracy: 12.8\n",
            "Validation Loss: 3.850984105638638, Validation Accuracy: 12.17\n",
            "[28/150]: Training Loss: 3.7865677406311034, Training Accuracy: 13.18\n",
            "Validation Loss: 3.830880017796899, Validation Accuracy: 12.18\n",
            "[29/150]: Training Loss: 3.7712997707366944, Training Accuracy: 13.4425\n",
            "Validation Loss: 3.816112823547072, Validation Accuracy: 12.61\n",
            "[30/150]: Training Loss: 3.7579914638519285, Training Accuracy: 13.83\n",
            "Validation Loss: 3.817626942494872, Validation Accuracy: 12.9\n",
            "[31/150]: Training Loss: 3.7429426765441893, Training Accuracy: 14.14\n",
            "Validation Loss: 3.795013807381794, Validation Accuracy: 12.82\n",
            "[32/150]: Training Loss: 3.7270426654815676, Training Accuracy: 14.46\n",
            "Validation Loss: 3.774455428882769, Validation Accuracy: 13.53\n",
            "[33/150]: Training Loss: 3.7124608081817625, Training Accuracy: 14.53\n",
            "Validation Loss: 3.7734299799439253, Validation Accuracy: 13.65\n",
            "[34/150]: Training Loss: 3.695247130584717, Training Accuracy: 15.0575\n",
            "Validation Loss: 3.749705171888801, Validation Accuracy: 14.01\n",
            "[35/150]: Training Loss: 3.679954329299927, Training Accuracy: 15.12\n",
            "Validation Loss: 3.7417220279669308, Validation Accuracy: 13.98\n",
            "[36/150]: Training Loss: 3.6635797924041746, Training Accuracy: 15.48\n",
            "Validation Loss: 3.7247597214522634, Validation Accuracy: 14.42\n",
            "[37/150]: Training Loss: 3.6480526805877687, Training Accuracy: 15.7375\n",
            "Validation Loss: 3.7059438805671254, Validation Accuracy: 14.5\n",
            "[38/150]: Training Loss: 3.6313486305236817, Training Accuracy: 16.3075\n",
            "Validation Loss: 3.6903846977622647, Validation Accuracy: 14.92\n",
            "[39/150]: Training Loss: 3.6153011852264405, Training Accuracy: 16.3475\n",
            "Validation Loss: 3.6778608826315327, Validation Accuracy: 14.79\n",
            "[40/150]: Training Loss: 3.60027672958374, Training Accuracy: 16.67\n",
            "Validation Loss: 3.6614270756958396, Validation Accuracy: 15.31\n",
            "[41/150]: Training Loss: 3.585800159072876, Training Accuracy: 16.7725\n",
            "Validation Loss: 3.655038889805982, Validation Accuracy: 15.05\n",
            "[42/150]: Training Loss: 3.5694461936950685, Training Accuracy: 17.0375\n",
            "Validation Loss: 3.636945672855256, Validation Accuracy: 15.93\n",
            "[43/150]: Training Loss: 3.5568551288604735, Training Accuracy: 17.3975\n",
            "Validation Loss: 3.627324414101376, Validation Accuracy: 16.21\n",
            "[44/150]: Training Loss: 3.5419315227508545, Training Accuracy: 17.7\n",
            "Validation Loss: 3.6199980754001886, Validation Accuracy: 16.01\n",
            "[45/150]: Training Loss: 3.529905016708374, Training Accuracy: 17.7675\n",
            "Validation Loss: 3.6078376861134913, Validation Accuracy: 16.36\n",
            "[46/150]: Training Loss: 3.5179548221588135, Training Accuracy: 18.195\n",
            "Validation Loss: 3.591066009679418, Validation Accuracy: 16.38\n",
            "[47/150]: Training Loss: 3.5055387844085693, Training Accuracy: 18.2875\n",
            "Validation Loss: 3.5880215836178726, Validation Accuracy: 16.91\n",
            "[48/150]: Training Loss: 3.4944853992462157, Training Accuracy: 18.445\n",
            "Validation Loss: 3.573359035382605, Validation Accuracy: 17.28\n",
            "[49/150]: Training Loss: 3.4836856788635253, Training Accuracy: 18.615\n",
            "Validation Loss: 3.5583009431316595, Validation Accuracy: 17.54\n",
            "[50/150]: Training Loss: 3.4725227031707764, Training Accuracy: 18.9225\n",
            "Validation Loss: 3.5552009609854145, Validation Accuracy: 17.27\n",
            "[51/150]: Training Loss: 3.461646089553833, Training Accuracy: 19.095\n",
            "Validation Loss: 3.5449378551191586, Validation Accuracy: 17.49\n",
            "[52/150]: Training Loss: 3.451679636383057, Training Accuracy: 19.2575\n",
            "Validation Loss: 3.5295108943987805, Validation Accuracy: 17.59\n",
            "[53/150]: Training Loss: 3.44256662979126, Training Accuracy: 19.475\n",
            "Validation Loss: 3.5264732868048796, Validation Accuracy: 17.73\n",
            "[54/150]: Training Loss: 3.4335047622680666, Training Accuracy: 19.5175\n",
            "Validation Loss: 3.521607499213735, Validation Accuracy: 17.96\n",
            "[55/150]: Training Loss: 3.425080271530151, Training Accuracy: 19.8125\n",
            "Validation Loss: 3.513597962203299, Validation Accuracy: 18.01\n",
            "[56/150]: Training Loss: 3.4155618144989015, Training Accuracy: 19.8425\n",
            "Validation Loss: 3.5052308413633115, Validation Accuracy: 18.2\n",
            "[57/150]: Training Loss: 3.4078545150756834, Training Accuracy: 20.0575\n",
            "Validation Loss: 3.498734108202017, Validation Accuracy: 18.36\n",
            "[58/150]: Training Loss: 3.399192015457153, Training Accuracy: 20.1425\n",
            "Validation Loss: 3.4935538814326, Validation Accuracy: 18.5\n",
            "[59/150]: Training Loss: 3.3918968856811524, Training Accuracy: 20.275\n",
            "Validation Loss: 3.4842984858591843, Validation Accuracy: 18.83\n",
            "[60/150]: Training Loss: 3.3846318199157714, Training Accuracy: 20.45\n",
            "Validation Loss: 3.475666542721402, Validation Accuracy: 18.75\n",
            "[61/150]: Training Loss: 3.378842526626587, Training Accuracy: 20.395\n",
            "Validation Loss: 3.47740289360095, Validation Accuracy: 18.53\n",
            "[62/150]: Training Loss: 3.369043716430664, Training Accuracy: 20.85\n",
            "Validation Loss: 3.469373791081131, Validation Accuracy: 18.88\n",
            "[63/150]: Training Loss: 3.363127135467529, Training Accuracy: 20.8125\n",
            "Validation Loss: 3.453160047531128, Validation Accuracy: 19.11\n",
            "[64/150]: Training Loss: 3.355681411361694, Training Accuracy: 21.0925\n",
            "Validation Loss: 3.466009464992839, Validation Accuracy: 19.12\n",
            "[65/150]: Training Loss: 3.3498121349334715, Training Accuracy: 21.1625\n",
            "Validation Loss: 3.4505164547331013, Validation Accuracy: 19.11\n",
            "[66/150]: Training Loss: 3.343057912063599, Training Accuracy: 21.225\n",
            "Validation Loss: 3.4455762957311737, Validation Accuracy: 19.05\n",
            "[67/150]: Training Loss: 3.3380538593292237, Training Accuracy: 21.2275\n",
            "Validation Loss: 3.448872314137258, Validation Accuracy: 18.99\n",
            "[68/150]: Training Loss: 3.3309446399688722, Training Accuracy: 21.4425\n",
            "Validation Loss: 3.434380317189891, Validation Accuracy: 19.65\n",
            "[69/150]: Training Loss: 3.325505153656006, Training Accuracy: 21.5125\n",
            "Validation Loss: 3.428423096419899, Validation Accuracy: 19.77\n",
            "[70/150]: Training Loss: 3.319794240951538, Training Accuracy: 21.7375\n",
            "Validation Loss: 3.4293241318623733, Validation Accuracy: 19.58\n",
            "[71/150]: Training Loss: 3.3128502590179445, Training Accuracy: 21.7775\n",
            "Validation Loss: 3.422350405128139, Validation Accuracy: 19.89\n",
            "[72/150]: Training Loss: 3.308202914047241, Training Accuracy: 21.9175\n",
            "Validation Loss: 3.4211007197191763, Validation Accuracy: 20.03\n",
            "[73/150]: Training Loss: 3.3036910511016844, Training Accuracy: 21.85\n",
            "Validation Loss: 3.412458062931231, Validation Accuracy: 19.99\n",
            "[74/150]: Training Loss: 3.2999632190704347, Training Accuracy: 22.05\n",
            "Validation Loss: 3.410503987294094, Validation Accuracy: 19.96\n",
            "[75/150]: Training Loss: 3.2934399642944334, Training Accuracy: 21.9825\n",
            "Validation Loss: 3.4070342604521735, Validation Accuracy: 20.1\n",
            "[76/150]: Training Loss: 3.288022666168213, Training Accuracy: 22.4075\n",
            "Validation Loss: 3.3981059220186465, Validation Accuracy: 20.33\n",
            "[77/150]: Training Loss: 3.283489876937866, Training Accuracy: 22.37\n",
            "Validation Loss: 3.403488172846995, Validation Accuracy: 20.14\n",
            "[78/150]: Training Loss: 3.279419002151489, Training Accuracy: 22.4725\n",
            "Validation Loss: 3.39810815434547, Validation Accuracy: 20.23\n",
            "[79/150]: Training Loss: 3.275748169708252, Training Accuracy: 22.3675\n",
            "Validation Loss: 3.3924497191313727, Validation Accuracy: 20.38\n",
            "[80/150]: Training Loss: 3.2700943855285645, Training Accuracy: 22.625\n",
            "Validation Loss: 3.394149239655513, Validation Accuracy: 20.3\n",
            "[81/150]: Training Loss: 3.266976011657715, Training Accuracy: 22.6325\n",
            "Validation Loss: 3.389360663237845, Validation Accuracy: 20.25\n",
            "[82/150]: Training Loss: 3.2631465213775637, Training Accuracy: 22.7725\n",
            "Validation Loss: 3.3781265529098023, Validation Accuracy: 20.61\n",
            "[83/150]: Training Loss: 3.2582495727539063, Training Accuracy: 22.885\n",
            "Validation Loss: 3.380337715148926, Validation Accuracy: 20.88\n",
            "[84/150]: Training Loss: 3.2537473976135254, Training Accuracy: 23.075\n",
            "Validation Loss: 3.3771434042863784, Validation Accuracy: 20.89\n",
            "[85/150]: Training Loss: 3.2507594604492187, Training Accuracy: 22.9875\n",
            "Validation Loss: 3.3780695936482426, Validation Accuracy: 20.92\n",
            "[86/150]: Training Loss: 3.246923331832886, Training Accuracy: 23.055\n",
            "Validation Loss: 3.3708357325025426, Validation Accuracy: 20.88\n",
            "[87/150]: Training Loss: 3.2429458431243896, Training Accuracy: 23.1625\n",
            "Validation Loss: 3.36568513493629, Validation Accuracy: 21.0\n",
            "[88/150]: Training Loss: 3.239496036148071, Training Accuracy: 23.09\n",
            "Validation Loss: 3.369001481183775, Validation Accuracy: 20.84\n",
            "[89/150]: Training Loss: 3.235803797531128, Training Accuracy: 23.2875\n",
            "Validation Loss: 3.362776779065466, Validation Accuracy: 21.19\n",
            "[90/150]: Training Loss: 3.2327476997375486, Training Accuracy: 23.39\n",
            "Validation Loss: 3.3616829556264696, Validation Accuracy: 21.16\n",
            "[91/150]: Training Loss: 3.229936269760132, Training Accuracy: 23.3875\n",
            "Validation Loss: 3.360888686149743, Validation Accuracy: 21.41\n",
            "[92/150]: Training Loss: 3.2263083686828615, Training Accuracy: 23.4225\n",
            "Validation Loss: 3.359251875786265, Validation Accuracy: 21.08\n",
            "[93/150]: Training Loss: 3.224231428909302, Training Accuracy: 23.5575\n",
            "Validation Loss: 3.3559617753241473, Validation Accuracy: 21.38\n",
            "[94/150]: Training Loss: 3.2209563293457033, Training Accuracy: 23.52\n",
            "Validation Loss: 3.3566071850479027, Validation Accuracy: 21.38\n",
            "[95/150]: Training Loss: 3.2181186485290527, Training Accuracy: 23.5925\n",
            "Validation Loss: 3.3525171613996956, Validation Accuracy: 21.11\n",
            "[96/150]: Training Loss: 3.2156093044281007, Training Accuracy: 23.6025\n",
            "Validation Loss: 3.3487717983828986, Validation Accuracy: 21.48\n",
            "[97/150]: Training Loss: 3.211993044281006, Training Accuracy: 23.67\n",
            "Validation Loss: 3.3509595333390934, Validation Accuracy: 21.34\n",
            "[98/150]: Training Loss: 3.2086189796447755, Training Accuracy: 23.7725\n",
            "Validation Loss: 3.35127718585312, Validation Accuracy: 21.49\n",
            "[99/150]: Training Loss: 3.2077421699523927, Training Accuracy: 23.7925\n",
            "Validation Loss: 3.345605060553095, Validation Accuracy: 21.5\n",
            "[100/150]: Training Loss: 3.2047137928009035, Training Accuracy: 23.7025\n",
            "Validation Loss: 3.3447778088271996, Validation Accuracy: 21.56\n",
            "[101/150]: Training Loss: 3.202946053314209, Training Accuracy: 23.8775\n",
            "Validation Loss: 3.342098644584607, Validation Accuracy: 21.49\n",
            "[102/150]: Training Loss: 3.2004322288513185, Training Accuracy: 23.8375\n",
            "Validation Loss: 3.343631648713616, Validation Accuracy: 21.61\n",
            "[103/150]: Training Loss: 3.1983728965759277, Training Accuracy: 23.9425\n",
            "Validation Loss: 3.3422155471364405, Validation Accuracy: 21.24\n",
            "[104/150]: Training Loss: 3.196205286026001, Training Accuracy: 23.9975\n",
            "Validation Loss: 3.3361381269564294, Validation Accuracy: 21.8\n",
            "[105/150]: Training Loss: 3.194296379852295, Training Accuracy: 23.9125\n",
            "Validation Loss: 3.3376316750884816, Validation Accuracy: 21.59\n",
            "[106/150]: Training Loss: 3.1917529289245605, Training Accuracy: 23.9425\n",
            "Validation Loss: 3.3328404289901634, Validation Accuracy: 21.83\n",
            "[107/150]: Training Loss: 3.1901755290985108, Training Accuracy: 24.06\n",
            "Validation Loss: 3.335774242498313, Validation Accuracy: 21.85\n",
            "[108/150]: Training Loss: 3.188256001663208, Training Accuracy: 24.01\n",
            "Validation Loss: 3.335664199416045, Validation Accuracy: 21.84\n",
            "[109/150]: Training Loss: 3.186541044998169, Training Accuracy: 24.1\n",
            "Validation Loss: 3.331627411447513, Validation Accuracy: 21.98\n",
            "[110/150]: Training Loss: 3.184773151397705, Training Accuracy: 24.0825\n",
            "Validation Loss: 3.3308697946512016, Validation Accuracy: 21.79\n",
            "[111/150]: Training Loss: 3.1835228912353517, Training Accuracy: 24.1275\n",
            "Validation Loss: 3.3312593797209917, Validation Accuracy: 21.68\n",
            "[112/150]: Training Loss: 3.181557007980347, Training Accuracy: 24.2275\n",
            "Validation Loss: 3.3289258191539983, Validation Accuracy: 21.87\n",
            "[113/150]: Training Loss: 3.180008267211914, Training Accuracy: 24.3675\n",
            "Validation Loss: 3.3277820234845397, Validation Accuracy: 21.73\n",
            "[114/150]: Training Loss: 3.1787550163269045, Training Accuracy: 24.2975\n",
            "Validation Loss: 3.326631183077575, Validation Accuracy: 21.95\n",
            "[115/150]: Training Loss: 3.177647034072876, Training Accuracy: 24.285\n",
            "Validation Loss: 3.3255794716488785, Validation Accuracy: 22.03\n",
            "[116/150]: Training Loss: 3.176307448196411, Training Accuracy: 24.385\n",
            "Validation Loss: 3.3254039242009448, Validation Accuracy: 21.9\n",
            "[117/150]: Training Loss: 3.175141114425659, Training Accuracy: 24.3075\n",
            "Validation Loss: 3.3223649164673628, Validation Accuracy: 22.03\n",
            "[118/150]: Training Loss: 3.173803305053711, Training Accuracy: 24.4125\n",
            "Validation Loss: 3.323437298938727, Validation Accuracy: 21.99\n",
            "[119/150]: Training Loss: 3.1727485507965087, Training Accuracy: 24.345\n",
            "Validation Loss: 3.3220133781433105, Validation Accuracy: 22.09\n",
            "[120/150]: Training Loss: 3.171308903121948, Training Accuracy: 24.475\n",
            "Validation Loss: 3.320924275999616, Validation Accuracy: 22.15\n",
            "[121/150]: Training Loss: 3.1707864654541016, Training Accuracy: 24.485\n",
            "Validation Loss: 3.3217681638754097, Validation Accuracy: 21.98\n",
            "[122/150]: Training Loss: 3.169487755203247, Training Accuracy: 24.5\n",
            "Validation Loss: 3.3205978354071357, Validation Accuracy: 22.2\n",
            "[123/150]: Training Loss: 3.1687754665374754, Training Accuracy: 24.4775\n",
            "Validation Loss: 3.3199286217902118, Validation Accuracy: 22.03\n",
            "[124/150]: Training Loss: 3.1677217502593993, Training Accuracy: 24.5225\n",
            "Validation Loss: 3.3194276329818044, Validation Accuracy: 22.2\n",
            "[125/150]: Training Loss: 3.1672953506469725, Training Accuracy: 24.53\n",
            "Validation Loss: 3.3200536381666828, Validation Accuracy: 22.05\n",
            "[126/150]: Training Loss: 3.166370540237427, Training Accuracy: 24.53\n",
            "Validation Loss: 3.3180840486174175, Validation Accuracy: 22.01\n",
            "[127/150]: Training Loss: 3.165336986541748, Training Accuracy: 24.565\n",
            "Validation Loss: 3.318746434655159, Validation Accuracy: 22.24\n",
            "[128/150]: Training Loss: 3.164968849182129, Training Accuracy: 24.535\n",
            "Validation Loss: 3.3186944214401732, Validation Accuracy: 22.05\n",
            "[129/150]: Training Loss: 3.1642740074157714, Training Accuracy: 24.5175\n",
            "Validation Loss: 3.3177084133123897, Validation Accuracy: 22.21\n",
            "[130/150]: Training Loss: 3.16352066116333, Training Accuracy: 24.655\n",
            "Validation Loss: 3.318562794642843, Validation Accuracy: 22.01\n",
            "[131/150]: Training Loss: 3.1630500473022463, Training Accuracy: 24.5975\n",
            "Validation Loss: 3.317300656798539, Validation Accuracy: 22.06\n",
            "[132/150]: Training Loss: 3.1626014945983885, Training Accuracy: 24.66\n",
            "Validation Loss: 3.317058933768303, Validation Accuracy: 22.16\n",
            "[133/150]: Training Loss: 3.161920825958252, Training Accuracy: 24.64\n",
            "Validation Loss: 3.3171579837799072, Validation Accuracy: 22.02\n",
            "[134/150]: Training Loss: 3.161545040512085, Training Accuracy: 24.6375\n",
            "Validation Loss: 3.316502076045723, Validation Accuracy: 22.18\n",
            "[135/150]: Training Loss: 3.1611102500915527, Training Accuracy: 24.585\n",
            "Validation Loss: 3.3166633107859615, Validation Accuracy: 22.06\n",
            "[136/150]: Training Loss: 3.160765283203125, Training Accuracy: 24.6325\n",
            "Validation Loss: 3.3164391669498126, Validation Accuracy: 22.14\n",
            "[137/150]: Training Loss: 3.160325936508179, Training Accuracy: 24.6675\n",
            "Validation Loss: 3.315987286294342, Validation Accuracy: 22.11\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 5.462109195198982, Test Accuracy: 10.88\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▆█▂▁▂▂▁▁▂▂▃▃▂▂▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▃▁▄▆▆▇██▇▇▆▇▇▇▇▇▇▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▃▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train Loss</td><td>█▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>10.88</td></tr><tr><td>Test Loss</td><td>5.46211</td></tr><tr><td>Train Accuracy</td><td>24.6675</td></tr><tr><td>Train Loss</td><td>3.16033</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.05 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_023355-cthymqs8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.1 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_024913-26wygp07</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">learning_rate=0.1 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.554393922424317, Training Accuracy: 2.2\n",
            "Validation Loss: 4.421840394378468, Validation Accuracy: 3.74\n",
            "[2/150]: Training Loss: 4.284681567382813, Training Accuracy: 4.52\n",
            "Validation Loss: 4.239770348664302, Validation Accuracy: 4.95\n",
            "[3/150]: Training Loss: 4.181965134429932, Training Accuracy: 5.585\n",
            "Validation Loss: 4.184003517126581, Validation Accuracy: 5.53\n",
            "[4/150]: Training Loss: 4.125413941192627, Training Accuracy: 6.6775\n",
            "Validation Loss: 4.123335443484556, Validation Accuracy: 6.52\n",
            "[5/150]: Training Loss: 4.084817845535278, Training Accuracy: 7.4525\n",
            "Validation Loss: 4.096477279237881, Validation Accuracy: 6.87\n",
            "[6/150]: Training Loss: 4.048351853179931, Training Accuracy: 8.1125\n",
            "Validation Loss: 4.069233142646255, Validation Accuracy: 7.8\n",
            "[7/150]: Training Loss: 4.018422792816162, Training Accuracy: 8.56\n",
            "Validation Loss: 4.0364193445558, Validation Accuracy: 8.44\n",
            "[8/150]: Training Loss: 3.989247378540039, Training Accuracy: 8.9625\n",
            "Validation Loss: 4.010960247865908, Validation Accuracy: 8.51\n",
            "[9/150]: Training Loss: 3.9593318000793456, Training Accuracy: 9.5725\n",
            "Validation Loss: 3.9864684988738626, Validation Accuracy: 8.73\n",
            "[10/150]: Training Loss: 3.935969552612305, Training Accuracy: 9.97\n",
            "Validation Loss: 3.959391053315181, Validation Accuracy: 9.43\n",
            "[11/150]: Training Loss: 3.910384812927246, Training Accuracy: 10.53\n",
            "Validation Loss: 3.9335520723063473, Validation Accuracy: 10.05\n",
            "[12/150]: Training Loss: 3.8837633472442628, Training Accuracy: 11.015\n",
            "Validation Loss: 3.9218593843423637, Validation Accuracy: 9.91\n",
            "[13/150]: Training Loss: 3.85968777885437, Training Accuracy: 11.265\n",
            "Validation Loss: 3.884523991566555, Validation Accuracy: 10.94\n",
            "[14/150]: Training Loss: 3.83401321182251, Training Accuracy: 12.19\n",
            "Validation Loss: 3.8702170302154153, Validation Accuracy: 11.29\n",
            "[15/150]: Training Loss: 3.8098957332611083, Training Accuracy: 12.6325\n",
            "Validation Loss: 3.840197701363047, Validation Accuracy: 11.62\n",
            "[16/150]: Training Loss: 3.7832756935119627, Training Accuracy: 13.2\n",
            "Validation Loss: 3.8233511766810326, Validation Accuracy: 12.45\n",
            "[17/150]: Training Loss: 3.755026846694946, Training Accuracy: 13.5\n",
            "Validation Loss: 3.7900661996975065, Validation Accuracy: 12.91\n",
            "[18/150]: Training Loss: 3.7291974296569825, Training Accuracy: 14.06\n",
            "Validation Loss: 3.7731176181963293, Validation Accuracy: 13.22\n",
            "[19/150]: Training Loss: 3.703822989273071, Training Accuracy: 14.6625\n",
            "Validation Loss: 3.742501725057128, Validation Accuracy: 13.6\n",
            "[20/150]: Training Loss: 3.676954047012329, Training Accuracy: 15.14\n",
            "Validation Loss: 3.718170521365609, Validation Accuracy: 14.24\n",
            "[21/150]: Training Loss: 3.6502103706359863, Training Accuracy: 15.59\n",
            "Validation Loss: 3.6871351967951296, Validation Accuracy: 14.81\n",
            "[22/150]: Training Loss: 3.622364068222046, Training Accuracy: 16.105\n",
            "Validation Loss: 3.67376760464565, Validation Accuracy: 14.79\n",
            "[23/150]: Training Loss: 3.5969187736511232, Training Accuracy: 16.585\n",
            "Validation Loss: 3.6408486214413007, Validation Accuracy: 15.59\n",
            "[24/150]: Training Loss: 3.568799534988403, Training Accuracy: 17.215\n",
            "Validation Loss: 3.6294803862359113, Validation Accuracy: 15.79\n",
            "[25/150]: Training Loss: 3.5421108798980714, Training Accuracy: 17.57\n",
            "Validation Loss: 3.598143538092352, Validation Accuracy: 16.37\n",
            "[26/150]: Training Loss: 3.5124191093444823, Training Accuracy: 18.205\n",
            "Validation Loss: 3.5703049495721317, Validation Accuracy: 16.98\n",
            "[27/150]: Training Loss: 3.484529112625122, Training Accuracy: 18.7275\n",
            "Validation Loss: 3.5376776236637384, Validation Accuracy: 17.48\n",
            "[28/150]: Training Loss: 3.455819899749756, Training Accuracy: 19.0425\n",
            "Validation Loss: 3.5291991643844898, Validation Accuracy: 17.68\n",
            "[29/150]: Training Loss: 3.4284223934173585, Training Accuracy: 19.5625\n",
            "Validation Loss: 3.4991380257211673, Validation Accuracy: 18.43\n",
            "[30/150]: Training Loss: 3.4028552402496337, Training Accuracy: 20.0525\n",
            "Validation Loss: 3.4806957472661497, Validation Accuracy: 18.35\n",
            "[31/150]: Training Loss: 3.376880758666992, Training Accuracy: 20.5925\n",
            "Validation Loss: 3.450026891793415, Validation Accuracy: 19.53\n",
            "[32/150]: Training Loss: 3.354429434585571, Training Accuracy: 21.165\n",
            "Validation Loss: 3.435450357995975, Validation Accuracy: 19.72\n",
            "[33/150]: Training Loss: 3.3340842437744143, Training Accuracy: 21.175\n",
            "Validation Loss: 3.418211444927629, Validation Accuracy: 19.67\n",
            "[34/150]: Training Loss: 3.314141171646118, Training Accuracy: 21.5925\n",
            "Validation Loss: 3.4085868847597935, Validation Accuracy: 20.29\n",
            "[35/150]: Training Loss: 3.2981444416046144, Training Accuracy: 21.85\n",
            "Validation Loss: 3.3930132495369882, Validation Accuracy: 20.07\n",
            "[36/150]: Training Loss: 3.280233634567261, Training Accuracy: 22.4375\n",
            "Validation Loss: 3.3805624132703063, Validation Accuracy: 20.71\n",
            "[37/150]: Training Loss: 3.2627798179626466, Training Accuracy: 22.555\n",
            "Validation Loss: 3.365730774630407, Validation Accuracy: 21.1\n",
            "[38/150]: Training Loss: 3.246723106765747, Training Accuracy: 22.8925\n",
            "Validation Loss: 3.3649645671722994, Validation Accuracy: 21.17\n",
            "[39/150]: Training Loss: 3.23333472366333, Training Accuracy: 23.1725\n",
            "Validation Loss: 3.340107489543356, Validation Accuracy: 21.48\n",
            "[40/150]: Training Loss: 3.2185105766296385, Training Accuracy: 23.425\n",
            "Validation Loss: 3.3351985269291387, Validation Accuracy: 21.9\n",
            "[41/150]: Training Loss: 3.2041201099395753, Training Accuracy: 23.65\n",
            "Validation Loss: 3.320353848159693, Validation Accuracy: 22.37\n",
            "[42/150]: Training Loss: 3.1920853351593017, Training Accuracy: 23.97\n",
            "Validation Loss: 3.3151075627393785, Validation Accuracy: 21.98\n",
            "[43/150]: Training Loss: 3.178889651107788, Training Accuracy: 24.015\n",
            "Validation Loss: 3.3039617690311114, Validation Accuracy: 22.11\n",
            "[44/150]: Training Loss: 3.164986518096924, Training Accuracy: 24.4275\n",
            "Validation Loss: 3.2982496850809473, Validation Accuracy: 22.16\n",
            "[45/150]: Training Loss: 3.1540319355010986, Training Accuracy: 24.705\n",
            "Validation Loss: 3.2881052099215755, Validation Accuracy: 22.49\n",
            "[46/150]: Training Loss: 3.1423869262695314, Training Accuracy: 24.745\n",
            "Validation Loss: 3.285053641932785, Validation Accuracy: 22.32\n",
            "[47/150]: Training Loss: 3.1313994647979735, Training Accuracy: 25.0425\n",
            "Validation Loss: 3.2773830009873506, Validation Accuracy: 22.64\n",
            "[48/150]: Training Loss: 3.1199681632995606, Training Accuracy: 25.2175\n",
            "Validation Loss: 3.2647413463349553, Validation Accuracy: 22.66\n",
            "[49/150]: Training Loss: 3.107323546600342, Training Accuracy: 25.5575\n",
            "Validation Loss: 3.277184949559011, Validation Accuracy: 22.72\n",
            "[50/150]: Training Loss: 3.0971016899108887, Training Accuracy: 25.77\n",
            "Validation Loss: 3.2499756160055755, Validation Accuracy: 22.69\n",
            "[51/150]: Training Loss: 3.0865638957977293, Training Accuracy: 25.915\n",
            "Validation Loss: 3.28796663102071, Validation Accuracy: 22.45\n",
            "[52/150]: Training Loss: 3.075482699203491, Training Accuracy: 26.0775\n",
            "Validation Loss: 3.256385016593204, Validation Accuracy: 22.97\n",
            "[53/150]: Training Loss: 3.0676188301086427, Training Accuracy: 26.045\n",
            "Validation Loss: 3.2297865843317313, Validation Accuracy: 23.53\n",
            "[54/150]: Training Loss: 3.0562880493164064, Training Accuracy: 26.5925\n",
            "Validation Loss: 3.2346752266974965, Validation Accuracy: 23.32\n",
            "[55/150]: Training Loss: 3.046115529251099, Training Accuracy: 26.525\n",
            "Validation Loss: 3.229158471344383, Validation Accuracy: 23.27\n",
            "[56/150]: Training Loss: 3.0363171295166014, Training Accuracy: 26.5875\n",
            "Validation Loss: 3.2251109287237667, Validation Accuracy: 23.85\n",
            "[57/150]: Training Loss: 3.0262594100952147, Training Accuracy: 26.96\n",
            "Validation Loss: 3.20999311793382, Validation Accuracy: 23.73\n",
            "[58/150]: Training Loss: 3.018730586242676, Training Accuracy: 26.925\n",
            "Validation Loss: 3.206504849111958, Validation Accuracy: 23.66\n",
            "[59/150]: Training Loss: 3.007856759262085, Training Accuracy: 27.315\n",
            "Validation Loss: 3.2090084021258507, Validation Accuracy: 24.02\n",
            "[60/150]: Training Loss: 3.0000602096557616, Training Accuracy: 27.39\n",
            "Validation Loss: 3.2029919001706846, Validation Accuracy: 23.96\n",
            "[61/150]: Training Loss: 2.9893322017669677, Training Accuracy: 27.6525\n",
            "Validation Loss: 3.207233451733923, Validation Accuracy: 23.61\n",
            "[62/150]: Training Loss: 2.9812552192687987, Training Accuracy: 27.855\n",
            "Validation Loss: 3.191280894978031, Validation Accuracy: 23.71\n",
            "[63/150]: Training Loss: 2.972245023727417, Training Accuracy: 27.83\n",
            "Validation Loss: 3.191427630224046, Validation Accuracy: 24.21\n",
            "[64/150]: Training Loss: 2.9653648654937745, Training Accuracy: 28.0175\n",
            "Validation Loss: 3.189020594214178, Validation Accuracy: 24.07\n",
            "[65/150]: Training Loss: 2.957701969909668, Training Accuracy: 28.245\n",
            "Validation Loss: 3.183226536793314, Validation Accuracy: 23.98\n",
            "[66/150]: Training Loss: 2.9480487686157226, Training Accuracy: 28.3725\n",
            "Validation Loss: 3.1869888670125586, Validation Accuracy: 24.08\n",
            "[67/150]: Training Loss: 2.9404784973144533, Training Accuracy: 28.5625\n",
            "Validation Loss: 3.1826100653144205, Validation Accuracy: 24.61\n",
            "[68/150]: Training Loss: 2.9308408599853517, Training Accuracy: 28.73\n",
            "Validation Loss: 3.1697433404861743, Validation Accuracy: 24.11\n",
            "[69/150]: Training Loss: 2.924504146194458, Training Accuracy: 28.735\n",
            "Validation Loss: 3.164285852650928, Validation Accuracy: 24.76\n",
            "[70/150]: Training Loss: 2.9181696743011476, Training Accuracy: 29.045\n",
            "Validation Loss: 3.1617295559804153, Validation Accuracy: 24.5\n",
            "[71/150]: Training Loss: 2.909669787979126, Training Accuracy: 28.97\n",
            "Validation Loss: 3.16842480222131, Validation Accuracy: 24.55\n",
            "[72/150]: Training Loss: 2.901284480667114, Training Accuracy: 29.165\n",
            "Validation Loss: 3.16541398710506, Validation Accuracy: 24.39\n",
            "[73/150]: Training Loss: 2.8958903297424317, Training Accuracy: 29.41\n",
            "Validation Loss: 3.156350550378204, Validation Accuracy: 24.81\n",
            "[74/150]: Training Loss: 2.8880927780151366, Training Accuracy: 29.51\n",
            "Validation Loss: 3.1484538536922186, Validation Accuracy: 24.79\n",
            "[75/150]: Training Loss: 2.8816709129333495, Training Accuracy: 29.6575\n",
            "Validation Loss: 3.1521760521421007, Validation Accuracy: 24.75\n",
            "[76/150]: Training Loss: 2.874811888885498, Training Accuracy: 29.6025\n",
            "Validation Loss: 3.1412497159022434, Validation Accuracy: 24.86\n",
            "[77/150]: Training Loss: 2.868447174453735, Training Accuracy: 29.75\n",
            "Validation Loss: 3.148860450003557, Validation Accuracy: 25.12\n",
            "[78/150]: Training Loss: 2.8620141311645506, Training Accuracy: 30.02\n",
            "Validation Loss: 3.1491585096735863, Validation Accuracy: 25.07\n",
            "[79/150]: Training Loss: 2.8542796688079832, Training Accuracy: 30.2175\n",
            "Validation Loss: 3.1315311428847585, Validation Accuracy: 25.26\n",
            "[80/150]: Training Loss: 2.8495312446594236, Training Accuracy: 30.2625\n",
            "Validation Loss: 3.1400332511610287, Validation Accuracy: 25.12\n",
            "[81/150]: Training Loss: 2.8422299156188964, Training Accuracy: 30.4475\n",
            "Validation Loss: 3.129277274866772, Validation Accuracy: 25.51\n",
            "[82/150]: Training Loss: 2.8352813999176028, Training Accuracy: 30.645\n",
            "Validation Loss: 3.1319479532302563, Validation Accuracy: 25.37\n",
            "[83/150]: Training Loss: 2.830805637359619, Training Accuracy: 30.595\n",
            "Validation Loss: 3.1387126217981813, Validation Accuracy: 25.34\n",
            "[84/150]: Training Loss: 2.824944213485718, Training Accuracy: 30.7875\n",
            "Validation Loss: 3.1277991054923673, Validation Accuracy: 25.58\n",
            "[85/150]: Training Loss: 2.8196789070129396, Training Accuracy: 31.02\n",
            "Validation Loss: 3.1215793433462737, Validation Accuracy: 25.59\n",
            "[86/150]: Training Loss: 2.814448028564453, Training Accuracy: 31.1025\n",
            "Validation Loss: 3.1227446027622103, Validation Accuracy: 25.41\n",
            "[87/150]: Training Loss: 2.8087932884216307, Training Accuracy: 31.3075\n",
            "Validation Loss: 3.123080830665151, Validation Accuracy: 25.3\n",
            "[88/150]: Training Loss: 2.8027573429107666, Training Accuracy: 31.35\n",
            "Validation Loss: 3.1130096623851995, Validation Accuracy: 25.94\n",
            "[89/150]: Training Loss: 2.7979101371765136, Training Accuracy: 31.195\n",
            "Validation Loss: 3.1245606795997376, Validation Accuracy: 25.59\n",
            "[90/150]: Training Loss: 2.79326137008667, Training Accuracy: 31.37\n",
            "Validation Loss: 3.1252101788854905, Validation Accuracy: 25.47\n",
            "[91/150]: Training Loss: 2.7884928009033203, Training Accuracy: 31.3925\n",
            "Validation Loss: 3.115745410797702, Validation Accuracy: 25.52\n",
            "[92/150]: Training Loss: 2.7844152694702147, Training Accuracy: 31.5825\n",
            "Validation Loss: 3.1132962870749696, Validation Accuracy: 25.67\n",
            "[93/150]: Training Loss: 2.7792159679412842, Training Accuracy: 31.665\n",
            "Validation Loss: 3.111494478906036, Validation Accuracy: 25.84\n",
            "[94/150]: Training Loss: 2.773549281311035, Training Accuracy: 31.6525\n",
            "Validation Loss: 3.1067730256706287, Validation Accuracy: 25.89\n",
            "[95/150]: Training Loss: 2.76964068031311, Training Accuracy: 31.895\n",
            "Validation Loss: 3.1083280220153227, Validation Accuracy: 25.78\n",
            "[96/150]: Training Loss: 2.7651722465515136, Training Accuracy: 31.8825\n",
            "Validation Loss: 3.1057740730844485, Validation Accuracy: 25.67\n",
            "[97/150]: Training Loss: 2.761124114608765, Training Accuracy: 32.1025\n",
            "Validation Loss: 3.1073889534944183, Validation Accuracy: 25.55\n",
            "[98/150]: Training Loss: 2.756427172470093, Training Accuracy: 32.1475\n",
            "Validation Loss: 3.1095221422280477, Validation Accuracy: 25.75\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 6.147166403995198, Test Accuracy: 12.53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▄█▆▄▅▃▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▅▁▆▆▇███▇▇▆▇█▇▇▇▇▇▇▇▇▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▃▃▃▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.53</td></tr><tr><td>Test Loss</td><td>6.14717</td></tr><tr><td>Train Accuracy</td><td>32.1475</td></tr><tr><td>Train Loss</td><td>2.75643</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.1 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_024913-26wygp07/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.5 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_030015-a8qnvlbp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">learning_rate=0.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.377298123168945, Training Accuracy: 3.2725\n",
            "Validation Loss: 4.2101050941807445, Validation Accuracy: 5.2\n",
            "[2/150]: Training Loss: 4.07323479423523, Training Accuracy: 7.05\n",
            "Validation Loss: 3.997956647994412, Validation Accuracy: 8.69\n",
            "[3/150]: Training Loss: 3.9166299026489257, Training Accuracy: 9.98\n",
            "Validation Loss: 3.8700176090191882, Validation Accuracy: 10.85\n",
            "[4/150]: Training Loss: 3.76255333404541, Training Accuracy: 12.6475\n",
            "Validation Loss: 3.7763638131937403, Validation Accuracy: 12.03\n",
            "[5/150]: Training Loss: 3.6385873168945313, Training Accuracy: 14.8\n",
            "Validation Loss: 3.5995885247637514, Validation Accuracy: 15.3\n",
            "[6/150]: Training Loss: 3.5313883621215822, Training Accuracy: 16.6625\n",
            "Validation Loss: 3.547201700271315, Validation Accuracy: 16.33\n",
            "[7/150]: Training Loss: 3.4311797870635985, Training Accuracy: 18.0425\n",
            "Validation Loss: 3.447270431336324, Validation Accuracy: 18.49\n",
            "[8/150]: Training Loss: 3.3406018447875976, Training Accuracy: 20.2325\n",
            "Validation Loss: 3.3745645914867426, Validation Accuracy: 19.81\n",
            "[9/150]: Training Loss: 3.2601512760162352, Training Accuracy: 21.73\n",
            "Validation Loss: 3.3083346163391307, Validation Accuracy: 21.21\n",
            "[10/150]: Training Loss: 3.190315942764282, Training Accuracy: 23.0925\n",
            "Validation Loss: 3.2459553244766917, Validation Accuracy: 22.4\n",
            "[11/150]: Training Loss: 3.120881378555298, Training Accuracy: 24.2625\n",
            "Validation Loss: 3.2441095774340782, Validation Accuracy: 22.07\n",
            "[12/150]: Training Loss: 3.065099639892578, Training Accuracy: 25.1825\n",
            "Validation Loss: 3.205546066259882, Validation Accuracy: 22.44\n",
            "[13/150]: Training Loss: 3.002047216796875, Training Accuracy: 26.4075\n",
            "Validation Loss: 3.1507282090035216, Validation Accuracy: 24.42\n",
            "[14/150]: Training Loss: 2.947496301269531, Training Accuracy: 27.6075\n",
            "Validation Loss: 3.1272822519776167, Validation Accuracy: 24.2\n",
            "[15/150]: Training Loss: 2.8929669227600097, Training Accuracy: 28.1625\n",
            "Validation Loss: 3.08642372052381, Validation Accuracy: 25.55\n",
            "[16/150]: Training Loss: 2.8405557304382323, Training Accuracy: 29.4725\n",
            "Validation Loss: 3.021532262206837, Validation Accuracy: 26.7\n",
            "[17/150]: Training Loss: 2.7890852066040037, Training Accuracy: 30.505\n",
            "Validation Loss: 3.042905480998337, Validation Accuracy: 26.24\n",
            "[18/150]: Training Loss: 2.74124369392395, Training Accuracy: 31.39\n",
            "Validation Loss: 2.9991517309929914, Validation Accuracy: 26.63\n",
            "[19/150]: Training Loss: 2.692549164581299, Training Accuracy: 32.36\n",
            "Validation Loss: 2.9798509998685994, Validation Accuracy: 27.88\n",
            "[20/150]: Training Loss: 2.6449439025878907, Training Accuracy: 33.1025\n",
            "Validation Loss: 3.0654538998937912, Validation Accuracy: 26.5\n",
            "[21/150]: Training Loss: 2.6013897836685183, Training Accuracy: 34.135\n",
            "Validation Loss: 2.937944315041706, Validation Accuracy: 29.27\n",
            "[22/150]: Training Loss: 2.5583987575531006, Training Accuracy: 35.0375\n",
            "Validation Loss: 2.965156334980278, Validation Accuracy: 28.48\n",
            "[23/150]: Training Loss: 2.5067957414627076, Training Accuracy: 36.145\n",
            "Validation Loss: 2.940655703757219, Validation Accuracy: 28.99\n",
            "[24/150]: Training Loss: 2.4618710725784303, Training Accuracy: 37.005\n",
            "Validation Loss: 2.9297352444594074, Validation Accuracy: 28.88\n",
            "[25/150]: Training Loss: 2.4159774208068847, Training Accuracy: 37.9375\n",
            "Validation Loss: 2.9579435579336373, Validation Accuracy: 28.85\n",
            "[26/150]: Training Loss: 2.3772740001678465, Training Accuracy: 38.8375\n",
            "Validation Loss: 2.892203370476984, Validation Accuracy: 29.97\n",
            "[27/150]: Training Loss: 2.331508861351013, Training Accuracy: 39.695\n",
            "Validation Loss: 2.902201515853785, Validation Accuracy: 29.95\n",
            "[28/150]: Training Loss: 2.292740362548828, Training Accuracy: 40.25\n",
            "Validation Loss: 2.884886794788822, Validation Accuracy: 30.54\n",
            "[29/150]: Training Loss: 2.246493480873108, Training Accuracy: 41.2375\n",
            "Validation Loss: 2.9104482884619647, Validation Accuracy: 30.14\n",
            "[30/150]: Training Loss: 2.203635430717468, Training Accuracy: 42.4475\n",
            "Validation Loss: 2.9059300164508213, Validation Accuracy: 31.3\n",
            "[31/150]: Training Loss: 2.1624910346984865, Training Accuracy: 43.2625\n",
            "Validation Loss: 2.884638991325524, Validation Accuracy: 31.26\n",
            "[32/150]: Training Loss: 2.122718844985962, Training Accuracy: 44.17\n",
            "Validation Loss: 2.9034518907024602, Validation Accuracy: 30.71\n",
            "[33/150]: Training Loss: 2.0803083070755006, Training Accuracy: 45.055\n",
            "Validation Loss: 2.8911248453103813, Validation Accuracy: 31.08\n",
            "[34/150]: Training Loss: 2.0393711433410644, Training Accuracy: 45.9575\n",
            "Validation Loss: 2.9181400818429934, Validation Accuracy: 31.06\n",
            "[35/150]: Training Loss: 2.001698533630371, Training Accuracy: 46.8225\n",
            "Validation Loss: 2.9216579084943053, Validation Accuracy: 30.6\n",
            "[36/150]: Training Loss: 1.9612565605163574, Training Accuracy: 47.845\n",
            "Validation Loss: 2.95554546945414, Validation Accuracy: 31.47\n",
            "[37/150]: Training Loss: 1.9143695009231567, Training Accuracy: 48.7825\n",
            "Validation Loss: 2.9769522748934993, Validation Accuracy: 30.95\n",
            "[38/150]: Training Loss: 1.8757219652175903, Training Accuracy: 49.6925\n",
            "Validation Loss: 2.954901927595685, Validation Accuracy: 31.79\n",
            "[39/150]: Training Loss: 1.8348310264587402, Training Accuracy: 50.46\n",
            "Validation Loss: 2.97764066374226, Validation Accuracy: 31.41\n",
            "[40/150]: Training Loss: 1.7973475383758546, Training Accuracy: 51.6725\n",
            "Validation Loss: 3.0162993069666966, Validation Accuracy: 31.12\n",
            "[41/150]: Training Loss: 1.7525395877838135, Training Accuracy: 52.525\n",
            "Validation Loss: 3.0236745138836514, Validation Accuracy: 30.91\n",
            "[42/150]: Training Loss: 1.7114470052719115, Training Accuracy: 53.885\n",
            "Validation Loss: 3.051269774224348, Validation Accuracy: 31.17\n",
            "[43/150]: Training Loss: 1.6800853149414063, Training Accuracy: 54.0875\n",
            "Validation Loss: 3.0829398237216243, Validation Accuracy: 31.28\n",
            "[44/150]: Training Loss: 1.636157625389099, Training Accuracy: 55.3375\n",
            "Validation Loss: 3.110968621673098, Validation Accuracy: 31.14\n",
            "[45/150]: Training Loss: 1.589929871749878, Training Accuracy: 56.7225\n",
            "Validation Loss: 3.142918248085459, Validation Accuracy: 31.26\n",
            "[46/150]: Training Loss: 1.5445106566429139, Training Accuracy: 57.9225\n",
            "Validation Loss: 3.1339099574240907, Validation Accuracy: 31.8\n",
            "[47/150]: Training Loss: 1.5067133940696715, Training Accuracy: 58.8375\n",
            "Validation Loss: 3.1682807533604325, Validation Accuracy: 31.84\n",
            "[48/150]: Training Loss: 1.4696476486206054, Training Accuracy: 59.655\n",
            "Validation Loss: 3.2345377184023523, Validation Accuracy: 30.89\n",
            "[49/150]: Training Loss: 1.4380368849754332, Training Accuracy: 60.32\n",
            "Validation Loss: 3.2836993484740047, Validation Accuracy: 31.58\n",
            "[50/150]: Training Loss: 1.3966082113265992, Training Accuracy: 61.33\n",
            "Validation Loss: 3.369933787424853, Validation Accuracy: 30.61\n",
            "[51/150]: Training Loss: 1.3530357138633728, Training Accuracy: 62.43\n",
            "Validation Loss: 3.357933571384211, Validation Accuracy: 31.19\n",
            "[52/150]: Training Loss: 1.31355241689682, Training Accuracy: 63.4325\n",
            "Validation Loss: 3.41107276138986, Validation Accuracy: 30.17\n",
            "[53/150]: Training Loss: 1.2827554839134216, Training Accuracy: 64.0425\n",
            "Validation Loss: 3.376580183673057, Validation Accuracy: 30.85\n",
            "[54/150]: Training Loss: 1.2412437489509582, Training Accuracy: 65.2825\n",
            "Validation Loss: 3.48424918332677, Validation Accuracy: 30.12\n",
            "[55/150]: Training Loss: 1.1999455925941467, Training Accuracy: 66.39\n",
            "Validation Loss: 3.4844332743602195, Validation Accuracy: 30.82\n",
            "[56/150]: Training Loss: 1.1624719073295593, Training Accuracy: 67.315\n",
            "Validation Loss: 3.535801676428242, Validation Accuracy: 30.86\n",
            "[57/150]: Training Loss: 1.1305819693565369, Training Accuracy: 67.9275\n",
            "Validation Loss: 3.6139490315868597, Validation Accuracy: 30.44\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 16.0335865749675, Test Accuracy: 13.22\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▄▂▂▂▁▂▁▁▁▁▁▁▂▂▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>█▁▅▄▄▅▆▇▅▄▃▄▅▄▅▅▄▅▄▅▅▄▄▄▄▄▄▄▄▅▅▅▅▅▄▅▅▅▄▄</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.22</td></tr><tr><td>Test Loss</td><td>16.03359</td></tr><tr><td>Train Accuracy</td><td>67.9275</td></tr><tr><td>Train Loss</td><td>1.13058</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_030015-a8qnvlbp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:1 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_030647-hgowk59s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">learning_rate=1 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.390103232955933, Training Accuracy: 2.935\n",
            "Validation Loss: 4.160131826522244, Validation Accuracy: 5.54\n",
            "[2/150]: Training Loss: 4.031327721786499, Training Accuracy: 7.5025\n",
            "Validation Loss: 3.9958771960750505, Validation Accuracy: 8.6\n",
            "[3/150]: Training Loss: 3.800543330383301, Training Accuracy: 11.665\n",
            "Validation Loss: 3.7379826664165328, Validation Accuracy: 12.06\n",
            "[4/150]: Training Loss: 3.6242603660583494, Training Accuracy: 14.345\n",
            "Validation Loss: 3.559469526740396, Validation Accuracy: 15.28\n",
            "[5/150]: Training Loss: 3.48455090675354, Training Accuracy: 16.9325\n",
            "Validation Loss: 3.491581111956554, Validation Accuracy: 16.56\n",
            "[6/150]: Training Loss: 3.3448009601593016, Training Accuracy: 19.435\n",
            "Validation Loss: 3.3586603653658726, Validation Accuracy: 19.41\n",
            "[7/150]: Training Loss: 3.229361641693115, Training Accuracy: 21.4375\n",
            "Validation Loss: 3.2139996130754995, Validation Accuracy: 21.78\n",
            "[8/150]: Training Loss: 3.1254781677246095, Training Accuracy: 23.4825\n",
            "Validation Loss: 3.168266389020689, Validation Accuracy: 22.86\n",
            "[9/150]: Training Loss: 3.0173661666870117, Training Accuracy: 25.6925\n",
            "Validation Loss: 3.1283769850518293, Validation Accuracy: 24.17\n",
            "[10/150]: Training Loss: 2.931245880126953, Training Accuracy: 26.99\n",
            "Validation Loss: 3.016676799506898, Validation Accuracy: 25.79\n",
            "[11/150]: Training Loss: 2.8445968715667727, Training Accuracy: 28.6675\n",
            "Validation Loss: 2.968725839238258, Validation Accuracy: 26.94\n",
            "[12/150]: Training Loss: 2.769311902618408, Training Accuracy: 30.345\n",
            "Validation Loss: 2.935349525160091, Validation Accuracy: 27.73\n",
            "[13/150]: Training Loss: 2.698523984146118, Training Accuracy: 31.47\n",
            "Validation Loss: 2.9356894462731233, Validation Accuracy: 28.11\n",
            "[14/150]: Training Loss: 2.6179113666534426, Training Accuracy: 33.2625\n",
            "Validation Loss: 2.8293940914664297, Validation Accuracy: 30.0\n",
            "[15/150]: Training Loss: 2.5539515073776244, Training Accuracy: 34.565\n",
            "Validation Loss: 2.8150154101620815, Validation Accuracy: 30.54\n",
            "[16/150]: Training Loss: 2.482784992599487, Training Accuracy: 36.2825\n",
            "Validation Loss: 2.801185814438352, Validation Accuracy: 30.73\n",
            "[17/150]: Training Loss: 2.416481968307495, Training Accuracy: 37.2175\n",
            "Validation Loss: 2.778297721200688, Validation Accuracy: 31.36\n",
            "[18/150]: Training Loss: 2.3516669242858885, Training Accuracy: 38.785\n",
            "Validation Loss: 2.803610542017943, Validation Accuracy: 31.44\n",
            "[19/150]: Training Loss: 2.2785828254699707, Training Accuracy: 40.36\n",
            "Validation Loss: 2.770737362515395, Validation Accuracy: 31.54\n",
            "[20/150]: Training Loss: 2.2117202407836913, Training Accuracy: 42.02\n",
            "Validation Loss: 2.751694551698721, Validation Accuracy: 32.2\n",
            "[21/150]: Training Loss: 2.1421232624053954, Training Accuracy: 43.1125\n",
            "Validation Loss: 2.7352929327897963, Validation Accuracy: 32.64\n",
            "[22/150]: Training Loss: 2.0760102186203, Training Accuracy: 44.805\n",
            "Validation Loss: 2.7648525397489023, Validation Accuracy: 32.85\n",
            "[23/150]: Training Loss: 2.0119320999145507, Training Accuracy: 46.1375\n",
            "Validation Loss: 2.7834541448362313, Validation Accuracy: 33.19\n",
            "[24/150]: Training Loss: 1.946039645767212, Training Accuracy: 47.555\n",
            "Validation Loss: 2.805889447023914, Validation Accuracy: 33.52\n",
            "[25/150]: Training Loss: 1.8788161462783814, Training Accuracy: 49.055\n",
            "Validation Loss: 2.7862223508251702, Validation Accuracy: 34.25\n",
            "[26/150]: Training Loss: 1.799899059486389, Training Accuracy: 50.915\n",
            "Validation Loss: 2.804932374863108, Validation Accuracy: 33.77\n",
            "[27/150]: Training Loss: 1.7454933450698853, Training Accuracy: 52.16\n",
            "Validation Loss: 2.861256376193587, Validation Accuracy: 33.83\n",
            "[28/150]: Training Loss: 1.6650921211242675, Training Accuracy: 53.9225\n",
            "Validation Loss: 2.877333830116661, Validation Accuracy: 34.25\n",
            "[29/150]: Training Loss: 1.6064131809234619, Training Accuracy: 55.555\n",
            "Validation Loss: 2.973996728089205, Validation Accuracy: 33.39\n",
            "[30/150]: Training Loss: 1.543812055683136, Training Accuracy: 56.7775\n",
            "Validation Loss: 2.943861024394916, Validation Accuracy: 34.15\n",
            "[31/150]: Training Loss: 1.4620859157562256, Training Accuracy: 58.88\n",
            "Validation Loss: 2.9692332015675342, Validation Accuracy: 33.88\n",
            "[32/150]: Training Loss: 1.4009520672798157, Training Accuracy: 60.3925\n",
            "Validation Loss: 3.024310210707841, Validation Accuracy: 33.42\n",
            "[33/150]: Training Loss: 1.3313846939086913, Training Accuracy: 62.155\n",
            "Validation Loss: 3.1067024993289047, Validation Accuracy: 33.18\n",
            "[34/150]: Training Loss: 1.2518226915359496, Training Accuracy: 64.225\n",
            "Validation Loss: 3.307321997964458, Validation Accuracy: 33.31\n",
            "[35/150]: Training Loss: 1.1938729809761048, Training Accuracy: 65.5075\n",
            "Validation Loss: 3.3076086089869214, Validation Accuracy: 32.76\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 18.36642926210051, Test Accuracy: 13.77\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▅▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▁▂▅▆▇▆▇█▇▇▇▇▇██▇███████▇▇███████████████</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.77</td></tr><tr><td>Test Loss</td><td>18.36643</td></tr><tr><td>Train Accuracy</td><td>65.5075</td></tr><tr><td>Train Loss</td><td>1.19387</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_030647-hgowk59s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:1.5 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_031055-hfm8dgbz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.426865048217773, Training Accuracy: 2.45\n",
            "Validation Loss: 4.219578746018136, Validation Accuracy: 4.19\n",
            "[2/150]: Training Loss: 4.060279036712647, Training Accuracy: 6.7225\n",
            "Validation Loss: 3.8940811293899635, Validation Accuracy: 9.43\n",
            "[3/150]: Training Loss: 3.7707011901855467, Training Accuracy: 11.6925\n",
            "Validation Loss: 3.8030508642743346, Validation Accuracy: 11.0\n",
            "[4/150]: Training Loss: 3.58028080368042, Training Accuracy: 15.05\n",
            "Validation Loss: 3.516739834645751, Validation Accuracy: 16.1\n",
            "[5/150]: Training Loss: 3.4152388591766356, Training Accuracy: 17.82\n",
            "Validation Loss: 3.411277610025588, Validation Accuracy: 17.62\n",
            "[6/150]: Training Loss: 3.2448327434539794, Training Accuracy: 20.7725\n",
            "Validation Loss: 3.2892891753251385, Validation Accuracy: 19.86\n",
            "[7/150]: Training Loss: 3.1129616333007815, Training Accuracy: 23.41\n",
            "Validation Loss: 3.155244686041668, Validation Accuracy: 22.75\n",
            "[8/150]: Training Loss: 2.9936462223052978, Training Accuracy: 25.73\n",
            "Validation Loss: 3.020396041262681, Validation Accuracy: 25.53\n",
            "[9/150]: Training Loss: 2.8851455352783204, Training Accuracy: 28.0475\n",
            "Validation Loss: 2.9794276216227535, Validation Accuracy: 26.31\n",
            "[10/150]: Training Loss: 2.7872766895294188, Training Accuracy: 29.955\n",
            "Validation Loss: 2.873067584007409, Validation Accuracy: 28.57\n",
            "[11/150]: Training Loss: 2.6929493949890135, Training Accuracy: 31.84\n",
            "Validation Loss: 2.8678578267431565, Validation Accuracy: 28.72\n",
            "[12/150]: Training Loss: 2.60749265499115, Training Accuracy: 33.46\n",
            "Validation Loss: 2.831394789325204, Validation Accuracy: 29.21\n",
            "[13/150]: Training Loss: 2.5269983169555665, Training Accuracy: 35.2325\n",
            "Validation Loss: 2.8061546094857963, Validation Accuracy: 29.73\n",
            "[14/150]: Training Loss: 2.430880810165405, Training Accuracy: 37.0475\n",
            "Validation Loss: 2.777110814288923, Validation Accuracy: 31.06\n",
            "[15/150]: Training Loss: 2.357077407836914, Training Accuracy: 38.8175\n",
            "Validation Loss: 2.7613005273661035, Validation Accuracy: 32.32\n",
            "[16/150]: Training Loss: 2.2730004482269286, Training Accuracy: 40.5\n",
            "Validation Loss: 2.7338021667140304, Validation Accuracy: 32.77\n",
            "[17/150]: Training Loss: 2.183533114242554, Training Accuracy: 42.27\n",
            "Validation Loss: 2.764839885341134, Validation Accuracy: 32.81\n",
            "[18/150]: Training Loss: 2.1031003602981566, Training Accuracy: 43.9825\n",
            "Validation Loss: 2.7428993381512394, Validation Accuracy: 32.82\n",
            "[19/150]: Training Loss: 2.0166405237197877, Training Accuracy: 46.195\n",
            "Validation Loss: 2.792896580544247, Validation Accuracy: 32.59\n",
            "[20/150]: Training Loss: 1.9404266941070556, Training Accuracy: 47.745\n",
            "Validation Loss: 2.742409686374057, Validation Accuracy: 34.58\n",
            "[21/150]: Training Loss: 1.8538161834716798, Training Accuracy: 49.4875\n",
            "Validation Loss: 2.809636064395783, Validation Accuracy: 33.93\n",
            "[22/150]: Training Loss: 1.768288578414917, Training Accuracy: 51.4775\n",
            "Validation Loss: 2.7697540058451855, Validation Accuracy: 34.68\n",
            "[23/150]: Training Loss: 1.684787001991272, Training Accuracy: 53.0825\n",
            "Validation Loss: 2.8915080067458425, Validation Accuracy: 33.94\n",
            "[24/150]: Training Loss: 1.6049392827987672, Training Accuracy: 55.145\n",
            "Validation Loss: 2.8930992533446878, Validation Accuracy: 33.94\n",
            "[25/150]: Training Loss: 1.511135014438629, Training Accuracy: 57.31\n",
            "Validation Loss: 2.9712191205115834, Validation Accuracy: 33.37\n",
            "[26/150]: Training Loss: 1.431588893699646, Training Accuracy: 59.12\n",
            "Validation Loss: 3.04860136311525, Validation Accuracy: 34.26\n",
            "[27/150]: Training Loss: 1.359563471508026, Training Accuracy: 60.8075\n",
            "Validation Loss: 3.205587582983029, Validation Accuracy: 33.21\n",
            "[28/150]: Training Loss: 1.2744348917961121, Training Accuracy: 63.0075\n",
            "Validation Loss: 3.1817259317750386, Validation Accuracy: 32.84\n",
            "[29/150]: Training Loss: 1.2077363389968871, Training Accuracy: 64.38\n",
            "Validation Loss: 3.2625666909916387, Validation Accuracy: 33.74\n",
            "[30/150]: Training Loss: 1.146615783405304, Training Accuracy: 66.3775\n",
            "Validation Loss: 3.439337396317986, Validation Accuracy: 32.76\n",
            "[31/150]: Training Loss: 1.0637209503173828, Training Accuracy: 68.4275\n",
            "Validation Loss: 3.464182601612844, Validation Accuracy: 32.3\n",
            "[32/150]: Training Loss: 1.0153738078117371, Training Accuracy: 69.42\n",
            "Validation Loss: 3.585658008125937, Validation Accuracy: 32.99\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 20.296875631733304, Test Accuracy: 15.72\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▆▁▄▃▄▄▄▄▄▄▄▄▄▄▅▅▄▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>Test Loss</td><td>▁▅▇▇▇▆▇██▇▇█████████████████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>15.72</td></tr><tr><td>Test Loss</td><td>20.29688</td></tr><tr><td>Train Accuracy</td><td>69.42</td></tr><tr><td>Train Loss</td><td>1.01537</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_031055-hfm8dgbz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:2 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_031444-ws7fqwm1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">learning_rate=2 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.6014143745422365, Training Accuracy: 0.98\n",
            "Validation Loss: 4.606205284215842, Validation Accuracy: 0.91\n",
            "[2/150]: Training Loss: 4.605726162719726, Training Accuracy: 0.93\n",
            "Validation Loss: 4.606422876856129, Validation Accuracy: 0.91\n",
            "[3/150]: Training Loss: 4.605443458557129, Training Accuracy: 0.9375\n",
            "Validation Loss: 4.606579792727331, Validation Accuracy: 0.82\n",
            "[4/150]: Training Loss: 4.6053140991210935, Training Accuracy: 1.015\n",
            "Validation Loss: 4.606754381945179, Validation Accuracy: 0.82\n",
            "[5/150]: Training Loss: 4.6052259376525875, Training Accuracy: 1.0275\n",
            "Validation Loss: 4.60688726765335, Validation Accuracy: 0.82\n",
            "[6/150]: Training Loss: 4.605191477966309, Training Accuracy: 1.0175\n",
            "Validation Loss: 4.607019655264107, Validation Accuracy: 0.82\n",
            "[7/150]: Training Loss: 4.6051658882141115, Training Accuracy: 1.015\n",
            "Validation Loss: 4.607097844409335, Validation Accuracy: 0.82\n",
            "[8/150]: Training Loss: 4.605149390411377, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.607179025176224, Validation Accuracy: 0.82\n",
            "[9/150]: Training Loss: 4.605146067810058, Training Accuracy: 0.9425\n",
            "Validation Loss: 4.6072455181437695, Validation Accuracy: 0.82\n",
            "[10/150]: Training Loss: 4.605130741882324, Training Accuracy: 1.02\n",
            "Validation Loss: 4.607305599625703, Validation Accuracy: 0.82\n",
            "[11/150]: Training Loss: 4.605136211395264, Training Accuracy: 0.9625\n",
            "Validation Loss: 4.607342504392005, Validation Accuracy: 0.82\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 4.605385412835771, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁▆███▆▇▇▇▇▇▇▇▇▆▇███▇████████████████████</td></tr><tr><td>Test Loss</td><td>█▅▁▁▃▃▅▄▄▄▄▄▄▄▄▅▅▅▅▅▆▅▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▅▅▅</td></tr><tr><td>Train Accuracy</td><td>▅▁▂▇█▇▇▄▂▇▃</td></tr><tr><td>Train Loss</td><td>▁██▇▇▇▇▇▇▇▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>4.60539</td></tr><tr><td>Train Accuracy</td><td>0.9625</td></tr><tr><td>Train Loss</td><td>4.60514</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=2 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_031444-ws7fqwm1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "\n",
        "  print('='*50)\n",
        "  print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {'learning_rate': lr,\n",
        "                      'weight_decay' : wd\n",
        "                      }\n",
        "  # Load the model\n",
        "  model = LeNet5().to(device)\n",
        "\n",
        "  # Optimizer and scheduler setup\n",
        "  optimizer = LARS(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "  # Training\n",
        "  run_training(num_epochs,\n",
        "                model,\n",
        "                train_loader,\n",
        "                validation_loader,\n",
        "                test_loader,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                criterion,\n",
        "                device,\n",
        "                'LARS-HyperParameterTuning',\n",
        "                hyperparameters=hyperparameters,\n",
        "                is_wandb = True,\n",
        "                n_epochs_stop = 10\n",
        "  )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2bd5fda76227433aa9332e6e48cd415b",
            "fd6480fe59104c7aa15d39bf6ea4a63b",
            "3cb7b5c42e844747ae133750b7d42882",
            "b81cc89707e44dedb51081d13a3ba424",
            "1d74e9350c2c4c61b2e95924ec133012",
            "a5758bfac16a4388a036005a15812d1d",
            "0fdaf43c468043139e5d72397b118371",
            "f63fffe56ff64f1eb2b6e8f14974f011"
          ]
        },
        "id": "czSHzFs7SQug",
        "outputId": "fc513f95-8814-4002-e0d6-2a2eedad7dd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_005802-t2cjgem5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1584951/4263216451.py:113: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1578.)\n",
            "  d_p.add_(weight_decay, p.data)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.004822687724667, Training Accuracy: 8.156\n",
            "Validation Loss: 3.6169370329304105, Validation Accuracy: 15.1\n",
            "[2/150]: Training Loss: 3.489779775099986, Training Accuracy: 16.288\n",
            "Validation Loss: 3.195649910884298, Validation Accuracy: 21.71\n",
            "[3/150]: Training Loss: 3.188335987003258, Training Accuracy: 21.346\n",
            "Validation Loss: 2.9737777011409685, Validation Accuracy: 26.15\n",
            "[4/150]: Training Loss: 3.0118914528576006, Training Accuracy: 24.982\n",
            "Validation Loss: 2.7995891707717995, Validation Accuracy: 29.11\n",
            "[5/150]: Training Loss: 2.8688232484071152, Training Accuracy: 28.08\n",
            "Validation Loss: 2.7174989600090464, Validation Accuracy: 30.23\n",
            "[6/150]: Training Loss: 2.7214920926276984, Training Accuracy: 30.662\n",
            "Validation Loss: 2.5305145515757763, Validation Accuracy: 34.82\n",
            "[7/150]: Training Loss: 2.6200312084858983, Training Accuracy: 32.576\n",
            "Validation Loss: 2.474041129373441, Validation Accuracy: 35.97\n",
            "[8/150]: Training Loss: 2.53857664821093, Training Accuracy: 34.358\n",
            "Validation Loss: 2.3864964094890913, Validation Accuracy: 37.73\n",
            "[9/150]: Training Loss: 2.460603771764604, Training Accuracy: 36.126\n",
            "Validation Loss: 2.3855689604570913, Validation Accuracy: 38.2\n",
            "[10/150]: Training Loss: 2.3902963816052507, Training Accuracy: 37.29\n",
            "Validation Loss: 2.301407885399594, Validation Accuracy: 40.45\n",
            "[11/150]: Training Loss: 2.3503475908733087, Training Accuracy: 38.624\n",
            "Validation Loss: 2.3037940666174435, Validation Accuracy: 39.96\n",
            "[12/150]: Training Loss: 2.303130599696313, Training Accuracy: 39.49\n",
            "Validation Loss: 2.2026211046109534, Validation Accuracy: 42.0\n",
            "[13/150]: Training Loss: 2.2486851939459895, Training Accuracy: 40.568\n",
            "Validation Loss: 2.212206517055536, Validation Accuracy: 42.21\n",
            "[14/150]: Training Loss: 2.203081512085312, Training Accuracy: 41.506\n",
            "Validation Loss: 2.1992271386893694, Validation Accuracy: 43.09\n",
            "[15/150]: Training Loss: 2.159660982963679, Training Accuracy: 42.428\n",
            "Validation Loss: 2.1746684677281958, Validation Accuracy: 43.09\n",
            "[16/150]: Training Loss: 2.1303664485511877, Training Accuracy: 43.166\n",
            "Validation Loss: 2.146143364298875, Validation Accuracy: 44.21\n",
            "[17/150]: Training Loss: 2.1123076631589925, Training Accuracy: 43.67\n",
            "Validation Loss: 2.1201481705258605, Validation Accuracy: 44.27\n",
            "[18/150]: Training Loss: 2.0810553551939748, Training Accuracy: 44.61\n",
            "Validation Loss: 2.0423277001472036, Validation Accuracy: 46.15\n",
            "[19/150]: Training Loss: 2.0513661890993338, Training Accuracy: 44.866\n",
            "Validation Loss: 2.091191877225402, Validation Accuracy: 44.81\n",
            "[20/150]: Training Loss: 2.018301057541157, Training Accuracy: 45.826\n",
            "Validation Loss: 2.1546491832490178, Validation Accuracy: 43.92\n",
            "[21/150]: Training Loss: 1.99891439834824, Training Accuracy: 46.082\n",
            "Validation Loss: 2.149173748720983, Validation Accuracy: 44.11\n",
            "[22/150]: Training Loss: 1.9834696277023276, Training Accuracy: 46.51\n",
            "Validation Loss: 2.0435469044241934, Validation Accuracy: 46.15\n",
            "[23/150]: Training Loss: 1.954583641970554, Training Accuracy: 46.984\n",
            "Validation Loss: 2.0593765806999937, Validation Accuracy: 46.4\n",
            "[24/150]: Training Loss: 1.9357828209772134, Training Accuracy: 47.47\n",
            "Validation Loss: 1.9959042148225625, Validation Accuracy: 47.77\n",
            "[25/150]: Training Loss: 1.9152823200311198, Training Accuracy: 48.11\n",
            "Validation Loss: 2.007097185037698, Validation Accuracy: 46.74\n",
            "[26/150]: Training Loss: 1.889640983870572, Training Accuracy: 48.486\n",
            "Validation Loss: 2.0237637371014636, Validation Accuracy: 46.53\n",
            "[27/150]: Training Loss: 1.8898505502954468, Training Accuracy: 48.75\n",
            "Validation Loss: 1.9383376062295998, Validation Accuracy: 48.79\n",
            "[28/150]: Training Loss: 1.8655293333865797, Training Accuracy: 49.182\n",
            "Validation Loss: 2.000895071181522, Validation Accuracy: 47.12\n",
            "[29/150]: Training Loss: 1.843536861564802, Training Accuracy: 49.576\n",
            "Validation Loss: 2.0557514102595627, Validation Accuracy: 46.42\n",
            "[30/150]: Training Loss: 1.8280195388037834, Training Accuracy: 49.938\n",
            "Validation Loss: 1.9708276941518115, Validation Accuracy: 48.17\n",
            "[31/150]: Training Loss: 1.8121484304632982, Training Accuracy: 50.256\n",
            "Validation Loss: 2.0148930929269, Validation Accuracy: 48.07\n",
            "[32/150]: Training Loss: 1.7905213011195287, Training Accuracy: 51.016\n",
            "Validation Loss: 1.9494955805456562, Validation Accuracy: 48.66\n",
            "[33/150]: Training Loss: 1.7819690168513667, Training Accuracy: 51.152\n",
            "Validation Loss: 1.9355155472542829, Validation Accuracy: 49.85\n",
            "[34/150]: Training Loss: 1.7735850943628784, Training Accuracy: 51.054\n",
            "Validation Loss: 1.9679190664534356, Validation Accuracy: 48.93\n",
            "[35/150]: Training Loss: 1.7615117981000934, Training Accuracy: 51.618\n",
            "Validation Loss: 2.019153520559809, Validation Accuracy: 47.96\n",
            "[36/150]: Training Loss: 1.7415476721875809, Training Accuracy: 51.984\n",
            "Validation Loss: 1.9617887530357214, Validation Accuracy: 48.72\n",
            "[37/150]: Training Loss: 1.7273670095007132, Training Accuracy: 52.228\n",
            "Validation Loss: 1.9595575993228111, Validation Accuracy: 49.25\n",
            "[38/150]: Training Loss: 1.7174837630423134, Training Accuracy: 52.45\n",
            "Validation Loss: 1.9162586555359469, Validation Accuracy: 50.15\n",
            "[39/150]: Training Loss: 1.6948718257877222, Training Accuracy: 53.104\n",
            "Validation Loss: 1.9148104600845628, Validation Accuracy: 50.11\n",
            "[40/150]: Training Loss: 1.6948116973537923, Training Accuracy: 53.164\n",
            "Validation Loss: 1.9015048544877653, Validation Accuracy: 50.46\n",
            "[41/150]: Training Loss: 1.669160524292675, Training Accuracy: 53.832\n",
            "Validation Loss: 1.9202428220943282, Validation Accuracy: 49.95\n",
            "[42/150]: Training Loss: 1.6587599679027372, Training Accuracy: 53.99\n",
            "Validation Loss: 1.9989394374713776, Validation Accuracy: 48.53\n",
            "[43/150]: Training Loss: 1.6486307676033596, Training Accuracy: 54.324\n",
            "Validation Loss: 1.9677664428759531, Validation Accuracy: 49.26\n",
            "[44/150]: Training Loss: 1.6284820756034168, Training Accuracy: 54.798\n",
            "Validation Loss: 1.917847274215358, Validation Accuracy: 50.53\n",
            "[45/150]: Training Loss: 1.6195188324774623, Training Accuracy: 54.902\n",
            "Validation Loss: 1.9071525859225327, Validation Accuracy: 50.67\n",
            "[46/150]: Training Loss: 1.6109208017206558, Training Accuracy: 54.96\n",
            "Validation Loss: 1.8967621220145257, Validation Accuracy: 51.23\n",
            "[47/150]: Training Loss: 1.602793920375502, Training Accuracy: 55.188\n",
            "Validation Loss: 1.8559222494720653, Validation Accuracy: 51.43\n",
            "[48/150]: Training Loss: 1.5858894056066528, Training Accuracy: 55.652\n",
            "Validation Loss: 1.9233948349193404, Validation Accuracy: 50.32\n",
            "[49/150]: Training Loss: 1.5650417865694637, Training Accuracy: 56.188\n",
            "Validation Loss: 1.9384330412384811, Validation Accuracy: 49.91\n",
            "[50/150]: Training Loss: 1.5663130182744291, Training Accuracy: 56.228\n",
            "Validation Loss: 1.8889641389725313, Validation Accuracy: 51.35\n",
            "[51/150]: Training Loss: 1.542809939445437, Training Accuracy: 56.846\n",
            "Validation Loss: 1.8398898855136459, Validation Accuracy: 51.84\n",
            "[52/150]: Training Loss: 1.5279571914002108, Training Accuracy: 57.064\n",
            "Validation Loss: 1.9208611204366015, Validation Accuracy: 50.34\n",
            "[53/150]: Training Loss: 1.510901224735143, Training Accuracy: 57.122\n",
            "Validation Loss: 1.9133090471765797, Validation Accuracy: 50.8\n",
            "[54/150]: Training Loss: 1.511483409596831, Training Accuracy: 57.642\n",
            "Validation Loss: 1.8751734176259132, Validation Accuracy: 51.71\n",
            "[55/150]: Training Loss: 1.4843521323960152, Training Accuracy: 58.136\n",
            "Validation Loss: 1.8774340836105832, Validation Accuracy: 51.56\n",
            "[56/150]: Training Loss: 1.4896384542403014, Training Accuracy: 57.742\n",
            "Validation Loss: 1.8484339972210537, Validation Accuracy: 52.7\n",
            "[57/150]: Training Loss: 1.4539345915207778, Training Accuracy: 58.774\n",
            "Validation Loss: 1.8711960125880636, Validation Accuracy: 50.9\n",
            "[58/150]: Training Loss: 1.4413522976591153, Training Accuracy: 59.254\n",
            "Validation Loss: 1.8433482806394055, Validation Accuracy: 52.14\n",
            "[59/150]: Training Loss: 1.435598407407551, Training Accuracy: 59.348\n",
            "Validation Loss: 1.842708926291982, Validation Accuracy: 52.32\n",
            "[60/150]: Training Loss: 1.415708273572995, Training Accuracy: 59.856\n",
            "Validation Loss: 1.8708495941891032, Validation Accuracy: 51.34\n",
            "[61/150]: Training Loss: 1.4131718484489508, Training Accuracy: 59.934\n",
            "Validation Loss: 1.8397565495436359, Validation Accuracy: 52.21\n",
            "[62/150]: Training Loss: 1.3917764421466672, Training Accuracy: 60.466\n",
            "Validation Loss: 1.8553483759521678, Validation Accuracy: 52.56\n",
            "[63/150]: Training Loss: 1.3845181973541485, Training Accuracy: 60.468\n",
            "Validation Loss: 1.8767407699755043, Validation Accuracy: 51.4\n",
            "[64/150]: Training Loss: 1.3718093946156904, Training Accuracy: 60.9\n",
            "Validation Loss: 1.833029270931414, Validation Accuracy: 53.34\n",
            "[65/150]: Training Loss: 1.3485638827771482, Training Accuracy: 61.372\n",
            "Validation Loss: 1.8435825352456159, Validation Accuracy: 52.78\n",
            "[66/150]: Training Loss: 1.3356790865778618, Training Accuracy: 61.914\n",
            "Validation Loss: 1.8920623299422537, Validation Accuracy: 52.03\n",
            "[67/150]: Training Loss: 1.3243823959242047, Training Accuracy: 61.984\n",
            "Validation Loss: 1.8541991725848739, Validation Accuracy: 53.25\n",
            "[68/150]: Training Loss: 1.3088703974128684, Training Accuracy: 62.324\n",
            "Validation Loss: 1.8384279855497323, Validation Accuracy: 52.97\n",
            "[69/150]: Training Loss: 1.2935843141487493, Training Accuracy: 62.726\n",
            "Validation Loss: 1.8648313618010017, Validation Accuracy: 52.35\n",
            "[70/150]: Training Loss: 1.2788333388240747, Training Accuracy: 63.162\n",
            "Validation Loss: 1.8200989673092107, Validation Accuracy: 53.57\n",
            "[71/150]: Training Loss: 1.275286832810058, Training Accuracy: 63.326\n",
            "Validation Loss: 1.8271277934122996, Validation Accuracy: 52.6\n",
            "[72/150]: Training Loss: 1.2548354720063222, Training Accuracy: 63.724\n",
            "Validation Loss: 1.832458599357848, Validation Accuracy: 53.43\n",
            "[73/150]: Training Loss: 1.2409771790589823, Training Accuracy: 64.15\n",
            "Validation Loss: 1.8489187993821066, Validation Accuracy: 53.54\n",
            "[74/150]: Training Loss: 1.2177538118703897, Training Accuracy: 64.682\n",
            "Validation Loss: 1.8377945020699957, Validation Accuracy: 53.86\n",
            "[75/150]: Training Loss: 1.2167601452764039, Training Accuracy: 64.92\n",
            "Validation Loss: 1.856788229031168, Validation Accuracy: 53.15\n",
            "[76/150]: Training Loss: 1.1967681403964987, Training Accuracy: 65.394\n",
            "Validation Loss: 1.8202834759548212, Validation Accuracy: 54.44\n",
            "[77/150]: Training Loss: 1.1781836492021371, Training Accuracy: 65.698\n",
            "Validation Loss: 1.8182067392738002, Validation Accuracy: 54.42\n",
            "[78/150]: Training Loss: 1.1718934528967913, Training Accuracy: 65.94\n",
            "Validation Loss: 1.8361693392893312, Validation Accuracy: 53.34\n",
            "[79/150]: Training Loss: 1.1540917455387847, Training Accuracy: 66.372\n",
            "Validation Loss: 1.8517911365837048, Validation Accuracy: 53.86\n",
            "[80/150]: Training Loss: 1.1260635425215182, Training Accuracy: 67.01\n",
            "Validation Loss: 1.8486420083197819, Validation Accuracy: 53.93\n",
            "[81/150]: Training Loss: 1.1187372058248886, Training Accuracy: 67.426\n",
            "Validation Loss: 1.822678742894701, Validation Accuracy: 54.82\n",
            "[82/150]: Training Loss: 1.1072917601184162, Training Accuracy: 67.646\n",
            "Validation Loss: 1.8640035948935587, Validation Accuracy: 53.57\n",
            "[83/150]: Training Loss: 1.082973983510376, Training Accuracy: 68.116\n",
            "Validation Loss: 1.867675439567323, Validation Accuracy: 53.9\n",
            "[84/150]: Training Loss: 1.0828096682915602, Training Accuracy: 68.366\n",
            "Validation Loss: 1.826197045244229, Validation Accuracy: 54.16\n",
            "[85/150]: Training Loss: 1.0598852286100997, Training Accuracy: 68.856\n",
            "Validation Loss: 1.8198747148938998, Validation Accuracy: 54.4\n",
            "[86/150]: Training Loss: 1.0407975543185572, Training Accuracy: 69.42\n",
            "Validation Loss: 1.8279076829837386, Validation Accuracy: 54.55\n",
            "[87/150]: Training Loss: 1.030418163827618, Training Accuracy: 69.804\n",
            "Validation Loss: 1.854318435784358, Validation Accuracy: 54.88\n",
            "[88/150]: Training Loss: 1.0299987217120807, Training Accuracy: 69.594\n",
            "Validation Loss: 1.8434015595988862, Validation Accuracy: 54.47\n",
            "[89/150]: Training Loss: 1.0026646399741892, Training Accuracy: 70.49\n",
            "Validation Loss: 1.8365007965428055, Validation Accuracy: 54.24\n",
            "[90/150]: Training Loss: 0.9944430979164055, Training Accuracy: 70.764\n",
            "Validation Loss: 1.845389035097353, Validation Accuracy: 54.42\n",
            "[91/150]: Training Loss: 0.9791042178945468, Training Accuracy: 70.958\n",
            "Validation Loss: 1.8592563897940764, Validation Accuracy: 54.71\n",
            "[92/150]: Training Loss: 0.9622275731371491, Training Accuracy: 71.348\n",
            "Validation Loss: 1.8250258181505143, Validation Accuracy: 55.29\n",
            "[93/150]: Training Loss: 0.9501752741349018, Training Accuracy: 71.708\n",
            "Validation Loss: 1.849954966526882, Validation Accuracy: 55.02\n",
            "[94/150]: Training Loss: 0.9297837285358278, Training Accuracy: 72.38\n",
            "Validation Loss: 1.8463909307103248, Validation Accuracy: 55.77\n",
            "[95/150]: Training Loss: 0.9163948694991944, Training Accuracy: 72.898\n",
            "Validation Loss: 1.8669461308011583, Validation Accuracy: 55.06\n",
            "[96/150]: Training Loss: 0.9114100606468938, Training Accuracy: 72.956\n",
            "Validation Loss: 1.8656909784693627, Validation Accuracy: 54.75\n",
            "[97/150]: Training Loss: 0.8974789249165284, Training Accuracy: 73.276\n",
            "Validation Loss: 1.834348332350421, Validation Accuracy: 55.01\n",
            "[98/150]: Training Loss: 0.8797091352360328, Training Accuracy: 73.696\n",
            "Validation Loss: 1.8680614483584264, Validation Accuracy: 55.11\n",
            "[99/150]: Training Loss: 0.8685366097085007, Training Accuracy: 74.026\n",
            "Validation Loss: 1.8696094318559975, Validation Accuracy: 55.43\n",
            "[100/150]: Training Loss: 0.8596895751745804, Training Accuracy: 74.396\n",
            "Validation Loss: 1.8580050965782944, Validation Accuracy: 55.31\n",
            "[101/150]: Training Loss: 0.8450928368531835, Training Accuracy: 74.934\n",
            "Validation Loss: 1.8560257132645626, Validation Accuracy: 55.71\n",
            "[102/150]: Training Loss: 0.834670692567935, Training Accuracy: 75.278\n",
            "Validation Loss: 1.8615986776959366, Validation Accuracy: 55.84\n",
            "[103/150]: Training Loss: 0.8168128573757303, Training Accuracy: 75.56\n",
            "Validation Loss: 1.8920900590100866, Validation Accuracy: 55.38\n",
            "[104/150]: Training Loss: 0.8022570627577165, Training Accuracy: 76.022\n",
            "Validation Loss: 1.9013077168707635, Validation Accuracy: 55.71\n",
            "[105/150]: Training Loss: 0.7898137537414766, Training Accuracy: 76.588\n",
            "Validation Loss: 1.8971044345266501, Validation Accuracy: 55.23\n",
            "[106/150]: Training Loss: 0.7799203321528252, Training Accuracy: 76.854\n",
            "Validation Loss: 1.8587115873956377, Validation Accuracy: 55.33\n",
            "[107/150]: Training Loss: 0.7687876791600377, Training Accuracy: 76.832\n",
            "Validation Loss: 1.9066706402286602, Validation Accuracy: 55.7\n",
            "[108/150]: Training Loss: 0.7502601898234823, Training Accuracy: 77.674\n",
            "Validation Loss: 1.891866291784177, Validation Accuracy: 56.06\n",
            "[109/150]: Training Loss: 0.7453718431236799, Training Accuracy: 77.84\n",
            "Validation Loss: 1.9089836011267012, Validation Accuracy: 55.88\n",
            "[110/150]: Training Loss: 0.7324799866322667, Training Accuracy: 78.2\n",
            "Validation Loss: 1.8889893972949616, Validation Accuracy: 55.7\n",
            "[111/150]: Training Loss: 0.716928729620736, Training Accuracy: 78.53\n",
            "Validation Loss: 1.9158697025791096, Validation Accuracy: 56.07\n",
            "[112/150]: Training Loss: 0.7084723916809882, Training Accuracy: 78.768\n",
            "Validation Loss: 1.9187719480247254, Validation Accuracy: 55.71\n",
            "[113/150]: Training Loss: 0.6928996008146754, Training Accuracy: 79.508\n",
            "Validation Loss: 1.9122050970223299, Validation Accuracy: 56.4\n",
            "[114/150]: Training Loss: 0.686598046775669, Training Accuracy: 79.428\n",
            "Validation Loss: 1.895180571990408, Validation Accuracy: 56.18\n",
            "[115/150]: Training Loss: 0.6837174600881079, Training Accuracy: 79.66\n",
            "Validation Loss: 1.9321321894408792, Validation Accuracy: 55.4\n",
            "[116/150]: Training Loss: 0.6646802525233735, Training Accuracy: 80.106\n",
            "Validation Loss: 1.9081798047776435, Validation Accuracy: 56.21\n",
            "[117/150]: Training Loss: 0.6522155370172638, Training Accuracy: 80.528\n",
            "Validation Loss: 1.9046855428416258, Validation Accuracy: 56.69\n",
            "[118/150]: Training Loss: 0.6456939719064766, Training Accuracy: 80.752\n",
            "Validation Loss: 1.9132253895899294, Validation Accuracy: 56.47\n",
            "[119/150]: Training Loss: 0.6339363064378729, Training Accuracy: 81.286\n",
            "Validation Loss: 1.914469665782467, Validation Accuracy: 56.51\n",
            "[120/150]: Training Loss: 0.6339401570351227, Training Accuracy: 81.134\n",
            "Validation Loss: 1.913045568830648, Validation Accuracy: 55.93\n",
            "[121/150]: Training Loss: 0.6202226441610804, Training Accuracy: 81.422\n",
            "Validation Loss: 1.9112963069016766, Validation Accuracy: 56.58\n",
            "[122/150]: Training Loss: 0.6146376765216403, Training Accuracy: 81.858\n",
            "Validation Loss: 1.916867652516456, Validation Accuracy: 56.28\n",
            "[123/150]: Training Loss: 0.6090771163363591, Training Accuracy: 81.96\n",
            "Validation Loss: 1.9238637059357515, Validation Accuracy: 56.33\n",
            "[124/150]: Training Loss: 0.5977434807497523, Training Accuracy: 82.352\n",
            "Validation Loss: 1.9187599549627607, Validation Accuracy: 56.09\n",
            "[125/150]: Training Loss: 0.5865007763933343, Training Accuracy: 82.728\n",
            "Validation Loss: 1.9290249192031326, Validation Accuracy: 55.85\n",
            "[126/150]: Training Loss: 0.5832711922390686, Training Accuracy: 82.85\n",
            "Validation Loss: 1.925058329560954, Validation Accuracy: 56.54\n",
            "[127/150]: Training Loss: 0.5710540865845692, Training Accuracy: 83.058\n",
            "Validation Loss: 1.9433572846613112, Validation Accuracy: 56.46\n",
            "[128/150]: Training Loss: 0.566251437987208, Training Accuracy: 83.328\n",
            "Validation Loss: 1.9474792632327718, Validation Accuracy: 56.24\n",
            "[129/150]: Training Loss: 0.5592512233787791, Training Accuracy: 83.606\n",
            "Validation Loss: 1.9336790825910628, Validation Accuracy: 56.49\n",
            "[130/150]: Training Loss: 0.5560948127675849, Training Accuracy: 83.726\n",
            "Validation Loss: 1.9358682472994373, Validation Accuracy: 56.75\n",
            "[131/150]: Training Loss: 0.5547005703191623, Training Accuracy: 83.68\n",
            "Validation Loss: 1.941912688647106, Validation Accuracy: 56.32\n",
            "[132/150]: Training Loss: 0.5438491536299591, Training Accuracy: 84.188\n",
            "Validation Loss: 1.9333096700868788, Validation Accuracy: 56.52\n",
            "[133/150]: Training Loss: 0.5359534242421465, Training Accuracy: 84.398\n",
            "Validation Loss: 1.9515662831106004, Validation Accuracy: 56.36\n",
            "[134/150]: Training Loss: 0.5345852662763937, Training Accuracy: 84.37\n",
            "Validation Loss: 1.939547040280263, Validation Accuracy: 56.31\n",
            "[135/150]: Training Loss: 0.5338244077266024, Training Accuracy: 84.354\n",
            "Validation Loss: 1.9529236646214867, Validation Accuracy: 56.4\n",
            "[136/150]: Training Loss: 0.5233329969751256, Training Accuracy: 84.792\n",
            "Validation Loss: 1.9439837556735726, Validation Accuracy: 56.43\n",
            "[137/150]: Training Loss: 0.519332280549247, Training Accuracy: 84.868\n",
            "Validation Loss: 1.9427648835880742, Validation Accuracy: 56.25\n",
            "[138/150]: Training Loss: 0.513342816468395, Training Accuracy: 85.202\n",
            "Validation Loss: 1.9522086123751987, Validation Accuracy: 56.69\n",
            "[139/150]: Training Loss: 0.5097889236515135, Training Accuracy: 85.132\n",
            "Validation Loss: 1.950890618904381, Validation Accuracy: 56.41\n",
            "[140/150]: Training Loss: 0.5080071812319329, Training Accuracy: 85.386\n",
            "Validation Loss: 1.9511753282729227, Validation Accuracy: 56.69\n",
            "[141/150]: Training Loss: 0.5083310039299528, Training Accuracy: 85.398\n",
            "Validation Loss: 1.9493300193434309, Validation Accuracy: 56.5\n",
            "[142/150]: Training Loss: 0.5110094372726157, Training Accuracy: 85.232\n",
            "Validation Loss: 1.9510933920076698, Validation Accuracy: 56.46\n",
            "[143/150]: Training Loss: 0.5043484553161179, Training Accuracy: 85.402\n",
            "Validation Loss: 1.9473720959797027, Validation Accuracy: 56.53\n",
            "[144/150]: Training Loss: 0.5001817758926346, Training Accuracy: 85.59\n",
            "Validation Loss: 1.9499852835752403, Validation Accuracy: 56.64\n",
            "[145/150]: Training Loss: 0.5050505888088584, Training Accuracy: 85.566\n",
            "Validation Loss: 1.9509570135432444, Validation Accuracy: 56.58\n",
            "[146/150]: Training Loss: 0.4944563165230824, Training Accuracy: 85.7\n",
            "Validation Loss: 1.9510046653686814, Validation Accuracy: 56.56\n",
            "[147/150]: Training Loss: 0.4947198845655717, Training Accuracy: 85.914\n",
            "Validation Loss: 1.9500796012817674, Validation Accuracy: 56.62\n",
            "[148/150]: Training Loss: 0.4965038236487857, Training Accuracy: 85.548\n",
            "Validation Loss: 1.9505202922092122, Validation Accuracy: 56.65\n",
            "[149/150]: Training Loss: 0.4984786443964905, Training Accuracy: 85.54\n",
            "Validation Loss: 1.94986033325742, Validation Accuracy: 56.62\n",
            "[150/150]: Training Loss: 0.498654707256333, Training Accuracy: 85.464\n",
            "Validation Loss: 1.9498052581860001, Validation Accuracy: 56.63\n",
            "**********************************************************************\n",
            "Test Loss: 1.9498052581860001, Test Accuracy: 56.63\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▆█▃▄▃▂▂▂▂▂▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Test Loss</td><td>▁▃▆▅██▇█▆▇▆▅▆▇█▇▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▇▇▇▆▆▇▆▆▆</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>56.63</td></tr><tr><td>Test Loss</td><td>1.94981</td></tr><tr><td>Train Accuracy</td><td>85.464</td></tr><tr><td>Train Loss</td><td>0.49865</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_005802-t2cjgem5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1.5\n",
        "wd = 1e-03\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer = LARS(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(\n",
        "    num_epochs,\n",
        "    model,\n",
        "    original_train_loader,\n",
        "    original_test_loader,\n",
        "    original_test_loader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    criterion,\n",
        "    device,\n",
        "    optimizer_name='LARS',\n",
        "    hyperparameters=hyperparameters,\n",
        "    is_wandb = True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81408f178c46447f90d36d1d18cdad82",
            "06d3de2006b14793bd57a5ca89d44e4a",
            "804c12a3f13840c7bdb2e6df69e62c10",
            "4a4cfb14c56e477cbfef5a652c05fabc",
            "68d86018628f420e8d7e516ba5827e35",
            "8877fd11846246f989e31835e5d3e7ae",
            "68ff4108835c462b929d0b5c78497555",
            "a63e1d987556448280ca217f17b60b49"
          ]
        },
        "id": "RFWHh4OL50WX",
        "outputId": "099a0039-9168-4d4e-84ec-4d6300dd3498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 512, Learning rate: 4.242640687119286, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:9hoyxk41) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/9hoyxk41' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/9hoyxk41</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_012745-9hoyxk41/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:9hoyxk41). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_012749-momu4e5u</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">batch_size=512 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.194531238808924, Training Accuracy: 5.802\n",
            "Validation Loss: 3.8219263911247254, Validation Accuracy: 11.06\n",
            "[2/150]: Training Loss: 3.737521487839368, Training Accuracy: 12.162\n",
            "Validation Loss: 3.5326468467712404, Validation Accuracy: 15.5\n",
            "[3/150]: Training Loss: 3.469568571265863, Training Accuracy: 16.654\n",
            "Validation Loss: 3.2325081706047056, Validation Accuracy: 21.14\n",
            "[4/150]: Training Loss: 3.2623822543085836, Training Accuracy: 20.338\n",
            "Validation Loss: 3.041664385795593, Validation Accuracy: 24.34\n",
            "[5/150]: Training Loss: 3.1202199824002324, Training Accuracy: 23.134\n",
            "Validation Loss: 2.9670259952545166, Validation Accuracy: 26.23\n",
            "[6/150]: Training Loss: 2.973516508024566, Training Accuracy: 25.864\n",
            "Validation Loss: 2.835892844200134, Validation Accuracy: 28.97\n",
            "[7/150]: Training Loss: 2.8618772808386357, Training Accuracy: 27.73\n",
            "Validation Loss: 2.731530475616455, Validation Accuracy: 31.08\n",
            "[8/150]: Training Loss: 2.7622045083921782, Training Accuracy: 29.856\n",
            "Validation Loss: 2.6019123077392576, Validation Accuracy: 33.01\n",
            "[9/150]: Training Loss: 2.719049726213728, Training Accuracy: 30.804\n",
            "Validation Loss: 2.6247976064682006, Validation Accuracy: 33.43\n",
            "[10/150]: Training Loss: 2.6084506000791277, Training Accuracy: 33.166\n",
            "Validation Loss: 2.4777934432029722, Validation Accuracy: 36.28\n",
            "[11/150]: Training Loss: 2.5361861233808556, Training Accuracy: 34.45\n",
            "Validation Loss: 2.3982665181159972, Validation Accuracy: 37.66\n",
            "[12/150]: Training Loss: 2.486152622164512, Training Accuracy: 35.61\n",
            "Validation Loss: 2.4073413372039796, Validation Accuracy: 37.69\n",
            "[13/150]: Training Loss: 2.419785971544227, Training Accuracy: 36.994\n",
            "Validation Loss: 2.3586077094078064, Validation Accuracy: 39.62\n",
            "[14/150]: Training Loss: 2.378681479668131, Training Accuracy: 37.686\n",
            "Validation Loss: 2.2874060750007628, Validation Accuracy: 40.44\n",
            "[15/150]: Training Loss: 2.3229291341742693, Training Accuracy: 39.04\n",
            "Validation Loss: 2.391434836387634, Validation Accuracy: 38.28\n",
            "[16/150]: Training Loss: 2.3006048445798912, Training Accuracy: 39.566\n",
            "Validation Loss: 2.233357620239258, Validation Accuracy: 40.92\n",
            "[17/150]: Training Loss: 2.270021514016755, Training Accuracy: 40.304\n",
            "Validation Loss: 2.2809773087501526, Validation Accuracy: 40.35\n",
            "[18/150]: Training Loss: 2.219994238444737, Training Accuracy: 41.128\n",
            "Validation Loss: 2.208327281475067, Validation Accuracy: 42.26\n",
            "[19/150]: Training Loss: 2.1639412665853697, Training Accuracy: 42.49\n",
            "Validation Loss: 2.1477415204048156, Validation Accuracy: 43.47\n",
            "[20/150]: Training Loss: 2.1379866052647025, Training Accuracy: 43.012\n",
            "Validation Loss: 2.202856254577637, Validation Accuracy: 42.27\n",
            "[21/150]: Training Loss: 2.139409989726787, Training Accuracy: 43.086\n",
            "Validation Loss: 2.1385614931583405, Validation Accuracy: 43.93\n",
            "[22/150]: Training Loss: 2.07097029564332, Training Accuracy: 44.974\n",
            "Validation Loss: 2.128925609588623, Validation Accuracy: 44.07\n",
            "[23/150]: Training Loss: 2.0605698106240253, Training Accuracy: 44.808\n",
            "Validation Loss: 2.15288764834404, Validation Accuracy: 44.03\n",
            "[24/150]: Training Loss: 2.0457090200210106, Training Accuracy: 45.174\n",
            "Validation Loss: 2.1201067209243774, Validation Accuracy: 44.63\n",
            "[25/150]: Training Loss: 2.0101604510326774, Training Accuracy: 45.978\n",
            "Validation Loss: 2.0930452048778534, Validation Accuracy: 45.37\n",
            "[26/150]: Training Loss: 1.9699756795046282, Training Accuracy: 46.9\n",
            "Validation Loss: 2.089737904071808, Validation Accuracy: 45.61\n",
            "[27/150]: Training Loss: 1.967079225851565, Training Accuracy: 47.01\n",
            "Validation Loss: 2.1089664578437803, Validation Accuracy: 44.55\n",
            "[28/150]: Training Loss: 1.9404766535272404, Training Accuracy: 47.568\n",
            "Validation Loss: 2.0624644994735717, Validation Accuracy: 45.57\n",
            "[29/150]: Training Loss: 1.928514483023663, Training Accuracy: 47.712\n",
            "Validation Loss: 2.0849966049194335, Validation Accuracy: 45.11\n",
            "[30/150]: Training Loss: 1.9005685375661265, Training Accuracy: 48.44\n",
            "Validation Loss: 2.015596163272858, Validation Accuracy: 46.79\n",
            "[31/150]: Training Loss: 1.868617719533492, Training Accuracy: 49.064\n",
            "Validation Loss: 2.044619733095169, Validation Accuracy: 45.67\n",
            "[32/150]: Training Loss: 1.8784857465296376, Training Accuracy: 48.794\n",
            "Validation Loss: 2.029283958673477, Validation Accuracy: 46.27\n",
            "[33/150]: Training Loss: 1.8382798968529215, Training Accuracy: 49.868\n",
            "Validation Loss: 1.9727658331394196, Validation Accuracy: 48.14\n",
            "[34/150]: Training Loss: 1.8194199094966965, Training Accuracy: 50.486\n",
            "Validation Loss: 1.9934200942516327, Validation Accuracy: 47.5\n",
            "[35/150]: Training Loss: 1.7988280094399745, Training Accuracy: 50.79\n",
            "Validation Loss: 2.0087626039981843, Validation Accuracy: 46.76\n",
            "[36/150]: Training Loss: 1.8009161900500863, Training Accuracy: 50.804\n",
            "Validation Loss: 1.9823269903659821, Validation Accuracy: 48.14\n",
            "[37/150]: Training Loss: 1.767955198579905, Training Accuracy: 51.498\n",
            "Validation Loss: 1.973670369386673, Validation Accuracy: 48.18\n",
            "[38/150]: Training Loss: 1.761318182458683, Training Accuracy: 51.526\n",
            "Validation Loss: 1.9882086098194123, Validation Accuracy: 47.85\n",
            "[39/150]: Training Loss: 1.7494291188765545, Training Accuracy: 52.066\n",
            "Validation Loss: 1.945462554693222, Validation Accuracy: 48.63\n",
            "[40/150]: Training Loss: 1.7158451688532927, Training Accuracy: 52.788\n",
            "Validation Loss: 1.9138611912727357, Validation Accuracy: 49.24\n",
            "[41/150]: Training Loss: 1.7024361783144426, Training Accuracy: 52.972\n",
            "Validation Loss: 1.9541066110134124, Validation Accuracy: 49.38\n",
            "[42/150]: Training Loss: 1.6934348527266054, Training Accuracy: 53.184\n",
            "Validation Loss: 1.9292299151420593, Validation Accuracy: 49.48\n",
            "[43/150]: Training Loss: 1.6734726489806662, Training Accuracy: 53.69\n",
            "Validation Loss: 1.9281952559947968, Validation Accuracy: 49.57\n",
            "[44/150]: Training Loss: 1.6466177933070125, Training Accuracy: 54.438\n",
            "Validation Loss: 1.92038534283638, Validation Accuracy: 49.7\n",
            "[45/150]: Training Loss: 1.6545339092916371, Training Accuracy: 54.198\n",
            "Validation Loss: 1.9556318461894988, Validation Accuracy: 49.26\n",
            "[46/150]: Training Loss: 1.619915745696243, Training Accuracy: 54.986\n",
            "Validation Loss: 1.899458384513855, Validation Accuracy: 50.32\n",
            "[47/150]: Training Loss: 1.6211930987786274, Training Accuracy: 54.738\n",
            "Validation Loss: 1.9299038767814636, Validation Accuracy: 49.14\n",
            "[48/150]: Training Loss: 1.5995109361045214, Training Accuracy: 55.258\n",
            "Validation Loss: 1.9302596151828766, Validation Accuracy: 49.32\n",
            "[49/150]: Training Loss: 1.5750943154704815, Training Accuracy: 55.898\n",
            "Validation Loss: 1.8993667602539062, Validation Accuracy: 49.91\n",
            "[50/150]: Training Loss: 1.5744633698950008, Training Accuracy: 55.76\n",
            "Validation Loss: 1.9295048713684082, Validation Accuracy: 50.3\n",
            "[51/150]: Training Loss: 1.5583884862004493, Training Accuracy: 56.348\n",
            "Validation Loss: 1.925916600227356, Validation Accuracy: 50.14\n",
            "[52/150]: Training Loss: 1.5439508910081825, Training Accuracy: 56.592\n",
            "Validation Loss: 1.8903591930866241, Validation Accuracy: 50.65\n",
            "[53/150]: Training Loss: 1.5187961057740815, Training Accuracy: 57.12\n",
            "Validation Loss: 1.893898105621338, Validation Accuracy: 51.28\n",
            "[54/150]: Training Loss: 1.500082329827912, Training Accuracy: 57.754\n",
            "Validation Loss: 1.8901280999183654, Validation Accuracy: 50.42\n",
            "[55/150]: Training Loss: 1.5054621915428006, Training Accuracy: 57.632\n",
            "Validation Loss: 1.890578955411911, Validation Accuracy: 51.07\n",
            "[56/150]: Training Loss: 1.4812841756003243, Training Accuracy: 57.986\n",
            "Validation Loss: 1.9068008363246918, Validation Accuracy: 51.44\n",
            "[57/150]: Training Loss: 1.4542514341218131, Training Accuracy: 58.654\n",
            "Validation Loss: 1.8665942788124084, Validation Accuracy: 51.26\n",
            "[58/150]: Training Loss: 1.4304890097404013, Training Accuracy: 59.206\n",
            "Validation Loss: 1.872557681798935, Validation Accuracy: 51.35\n",
            "[59/150]: Training Loss: 1.4232833567930727, Training Accuracy: 59.584\n",
            "Validation Loss: 1.9096780002117157, Validation Accuracy: 50.55\n",
            "[60/150]: Training Loss: 1.4309481491847915, Training Accuracy: 59.184\n",
            "Validation Loss: 1.8791188061237336, Validation Accuracy: 51.2\n",
            "[61/150]: Training Loss: 1.40531452334657, Training Accuracy: 59.96\n",
            "Validation Loss: 1.8862035810947417, Validation Accuracy: 51.85\n",
            "[62/150]: Training Loss: 1.3938273799662688, Training Accuracy: 60.274\n",
            "Validation Loss: 1.8729142725467682, Validation Accuracy: 51.37\n",
            "[63/150]: Training Loss: 1.3863425692733453, Training Accuracy: 60.462\n",
            "Validation Loss: 1.8725131154060364, Validation Accuracy: 52.01\n",
            "[64/150]: Training Loss: 1.366844469187211, Training Accuracy: 60.966\n",
            "Validation Loss: 1.8498412251472474, Validation Accuracy: 51.87\n",
            "[65/150]: Training Loss: 1.3531476259231567, Training Accuracy: 61.048\n",
            "Validation Loss: 1.8571744859218597, Validation Accuracy: 52.36\n",
            "[66/150]: Training Loss: 1.3398733954040372, Training Accuracy: 61.472\n",
            "Validation Loss: 1.869799542427063, Validation Accuracy: 52.02\n",
            "[67/150]: Training Loss: 1.3146201080205488, Training Accuracy: 62.184\n",
            "Validation Loss: 1.85557941198349, Validation Accuracy: 52.16\n",
            "[68/150]: Training Loss: 1.3349930096645743, Training Accuracy: 61.624\n",
            "Validation Loss: 1.899474561214447, Validation Accuracy: 51.8\n",
            "[69/150]: Training Loss: 1.2890492300597989, Training Accuracy: 63.07\n",
            "Validation Loss: 1.8615913569927216, Validation Accuracy: 52.55\n",
            "[70/150]: Training Loss: 1.281143541238746, Training Accuracy: 63.172\n",
            "Validation Loss: 1.8803191304206848, Validation Accuracy: 51.97\n",
            "[71/150]: Training Loss: 1.2725608847579177, Training Accuracy: 63.378\n",
            "Validation Loss: 1.859445983171463, Validation Accuracy: 52.42\n",
            "[72/150]: Training Loss: 1.2559378949963316, Training Accuracy: 63.878\n",
            "Validation Loss: 1.8568916201591492, Validation Accuracy: 52.05\n",
            "[73/150]: Training Loss: 1.236931935865052, Training Accuracy: 64.244\n",
            "Validation Loss: 1.8739505887031556, Validation Accuracy: 52.77\n",
            "[74/150]: Training Loss: 1.2173650824293798, Training Accuracy: 64.762\n",
            "Validation Loss: 1.8348273098468781, Validation Accuracy: 53.4\n",
            "[75/150]: Training Loss: 1.2067504488691991, Training Accuracy: 65.066\n",
            "Validation Loss: 1.8692607581615448, Validation Accuracy: 53.1\n",
            "[76/150]: Training Loss: 1.1903777292796545, Training Accuracy: 65.334\n",
            "Validation Loss: 1.8275393545627594, Validation Accuracy: 54.25\n",
            "[77/150]: Training Loss: 1.1792806843105628, Training Accuracy: 65.694\n",
            "Validation Loss: 1.8515967845916748, Validation Accuracy: 53.52\n",
            "[78/150]: Training Loss: 1.1699374263383904, Training Accuracy: 65.942\n",
            "Validation Loss: 1.8811356365680694, Validation Accuracy: 53.09\n",
            "[79/150]: Training Loss: 1.1490371531369734, Training Accuracy: 66.792\n",
            "Validation Loss: 1.8353333652019501, Validation Accuracy: 53.82\n",
            "[80/150]: Training Loss: 1.13668700383634, Training Accuracy: 66.562\n",
            "Validation Loss: 1.8432445168495177, Validation Accuracy: 53.57\n",
            "[81/150]: Training Loss: 1.1307378818794174, Training Accuracy: 67.21\n",
            "Validation Loss: 1.8481176435947417, Validation Accuracy: 53.14\n",
            "[82/150]: Training Loss: 1.113474543605532, Training Accuracy: 67.312\n",
            "Validation Loss: 1.8410939693450927, Validation Accuracy: 53.83\n",
            "[83/150]: Training Loss: 1.087531100122296, Training Accuracy: 68.23\n",
            "Validation Loss: 1.8605490565299987, Validation Accuracy: 54.45\n",
            "[84/150]: Training Loss: 1.0892518618885352, Training Accuracy: 68.016\n",
            "Validation Loss: 1.8244962751865388, Validation Accuracy: 54.28\n",
            "[85/150]: Training Loss: 1.0597951071602958, Training Accuracy: 68.916\n",
            "Validation Loss: 1.848558533191681, Validation Accuracy: 54.32\n",
            "[86/150]: Training Loss: 1.0610668713949165, Training Accuracy: 69.08\n",
            "Validation Loss: 1.834687203168869, Validation Accuracy: 54.36\n",
            "[87/150]: Training Loss: 1.029247879373784, Training Accuracy: 69.662\n",
            "Validation Loss: 1.8577094554901123, Validation Accuracy: 54.1\n",
            "[88/150]: Training Loss: 1.0305843438420976, Training Accuracy: 69.63\n",
            "Validation Loss: 1.88287433385849, Validation Accuracy: 53.74\n",
            "[89/150]: Training Loss: 1.0086117690923262, Training Accuracy: 70.346\n",
            "Validation Loss: 1.8663456857204437, Validation Accuracy: 53.54\n",
            "[90/150]: Training Loss: 0.9981355539390019, Training Accuracy: 70.802\n",
            "Validation Loss: 1.8623527228832244, Validation Accuracy: 53.93\n",
            "[91/150]: Training Loss: 0.986907957159743, Training Accuracy: 70.956\n",
            "Validation Loss: 1.8775681614875794, Validation Accuracy: 54.56\n",
            "[92/150]: Training Loss: 0.9677880217834395, Training Accuracy: 71.402\n",
            "Validation Loss: 1.886433583498001, Validation Accuracy: 54.06\n",
            "[93/150]: Training Loss: 0.9601449692735866, Training Accuracy: 71.714\n",
            "Validation Loss: 1.848057508468628, Validation Accuracy: 55.12\n",
            "[94/150]: Training Loss: 0.9483164567120221, Training Accuracy: 71.99\n",
            "Validation Loss: 1.8797329545021058, Validation Accuracy: 54.52\n",
            "[95/150]: Training Loss: 0.9349474110165421, Training Accuracy: 72.398\n",
            "Validation Loss: 1.8802269518375396, Validation Accuracy: 54.13\n",
            "[96/150]: Training Loss: 0.9153923319310558, Training Accuracy: 72.582\n",
            "Validation Loss: 1.8897387385368347, Validation Accuracy: 54.28\n",
            "[97/150]: Training Loss: 0.9160392132340646, Training Accuracy: 72.794\n",
            "Validation Loss: 1.9283715963363648, Validation Accuracy: 53.5\n",
            "[98/150]: Training Loss: 0.9007182382807439, Training Accuracy: 73.294\n",
            "Validation Loss: 1.8609421133995057, Validation Accuracy: 54.96\n",
            "[99/150]: Training Loss: 0.8783578246223683, Training Accuracy: 73.912\n",
            "Validation Loss: 1.8637104988098145, Validation Accuracy: 54.56\n",
            "[100/150]: Training Loss: 0.8765367439814976, Training Accuracy: 74.022\n",
            "Validation Loss: 1.8750475943088531, Validation Accuracy: 54.59\n",
            "[101/150]: Training Loss: 0.8546222393610039, Training Accuracy: 74.918\n",
            "Validation Loss: 1.8807278335094453, Validation Accuracy: 55.13\n",
            "[102/150]: Training Loss: 0.8389398102857628, Training Accuracy: 74.972\n",
            "Validation Loss: 1.8944664776325226, Validation Accuracy: 54.78\n",
            "[103/150]: Training Loss: 0.8364474201688961, Training Accuracy: 75.32\n",
            "Validation Loss: 1.8999429523944855, Validation Accuracy: 54.68\n",
            "[104/150]: Training Loss: 0.8233104719191181, Training Accuracy: 75.606\n",
            "Validation Loss: 1.9150757372379303, Validation Accuracy: 54.49\n",
            "[105/150]: Training Loss: 0.8071710479502775, Training Accuracy: 76.094\n",
            "Validation Loss: 1.8923523843288421, Validation Accuracy: 55.54\n",
            "[106/150]: Training Loss: 0.7909371567015745, Training Accuracy: 76.448\n",
            "Validation Loss: 1.883741980791092, Validation Accuracy: 54.92\n",
            "[107/150]: Training Loss: 0.7867257595062256, Training Accuracy: 76.748\n",
            "Validation Loss: 1.8950099110603333, Validation Accuracy: 55.47\n",
            "[108/150]: Training Loss: 0.7650761269793218, Training Accuracy: 77.31\n",
            "Validation Loss: 1.9024061024188996, Validation Accuracy: 54.91\n",
            "[109/150]: Training Loss: 0.7652728691393015, Training Accuracy: 77.178\n",
            "Validation Loss: 1.9312968671321868, Validation Accuracy: 54.57\n",
            "[110/150]: Training Loss: 0.7572217492424712, Training Accuracy: 77.548\n",
            "Validation Loss: 1.8906243860721588, Validation Accuracy: 55.71\n",
            "[111/150]: Training Loss: 0.738684381149253, Training Accuracy: 77.932\n",
            "Validation Loss: 1.945603609085083, Validation Accuracy: 55.18\n",
            "[112/150]: Training Loss: 0.7319968044757843, Training Accuracy: 78.382\n",
            "Validation Loss: 1.9286673545837403, Validation Accuracy: 55.27\n",
            "[113/150]: Training Loss: 0.7233879006638819, Training Accuracy: 78.482\n",
            "Validation Loss: 1.9232488691806793, Validation Accuracy: 55.58\n",
            "[114/150]: Training Loss: 0.7083694521261721, Training Accuracy: 78.814\n",
            "Validation Loss: 1.907062864303589, Validation Accuracy: 55.51\n",
            "[115/150]: Training Loss: 0.7031112666032753, Training Accuracy: 79.204\n",
            "Validation Loss: 1.9117585182189942, Validation Accuracy: 56.02\n",
            "[116/150]: Training Loss: 0.6852655745282465, Training Accuracy: 79.458\n",
            "Validation Loss: 1.9387612223625184, Validation Accuracy: 55.18\n",
            "[117/150]: Training Loss: 0.6826438423322172, Training Accuracy: 79.792\n",
            "Validation Loss: 1.923887985944748, Validation Accuracy: 55.49\n",
            "[118/150]: Training Loss: 0.6681522337757811, Training Accuracy: 80.242\n",
            "Validation Loss: 1.940861666202545, Validation Accuracy: 55.59\n",
            "[119/150]: Training Loss: 0.6691557758924912, Training Accuracy: 80.146\n",
            "Validation Loss: 1.953080016374588, Validation Accuracy: 55.29\n",
            "[120/150]: Training Loss: 0.6531465272514188, Training Accuracy: 80.714\n",
            "Validation Loss: 1.9404853343963624, Validation Accuracy: 55.54\n",
            "[121/150]: Training Loss: 0.6419856098233437, Training Accuracy: 81.21\n",
            "Validation Loss: 1.9526274442672729, Validation Accuracy: 56.17\n",
            "[122/150]: Training Loss: 0.6383003540793244, Training Accuracy: 81.27\n",
            "Validation Loss: 1.9685742020606996, Validation Accuracy: 55.67\n",
            "[123/150]: Training Loss: 0.6263646182357049, Training Accuracy: 81.396\n",
            "Validation Loss: 1.9449464201927185, Validation Accuracy: 56.05\n",
            "[124/150]: Training Loss: 0.62737323982375, Training Accuracy: 81.438\n",
            "Validation Loss: 1.9453241765499114, Validation Accuracy: 56.28\n",
            "[125/150]: Training Loss: 0.6171576502371807, Training Accuracy: 81.866\n",
            "Validation Loss: 1.9553956925868987, Validation Accuracy: 55.63\n",
            "[126/150]: Training Loss: 0.6041063827519514, Training Accuracy: 82.16\n",
            "Validation Loss: 1.9582968175411224, Validation Accuracy: 56.15\n",
            "[127/150]: Training Loss: 0.6006453934372687, Training Accuracy: 82.38\n",
            "Validation Loss: 1.9529106080532075, Validation Accuracy: 56.03\n",
            "[128/150]: Training Loss: 0.6008156434613832, Training Accuracy: 82.348\n",
            "Validation Loss: 1.9448323190212249, Validation Accuracy: 56.3\n",
            "[129/150]: Training Loss: 0.5887871582289131, Training Accuracy: 82.762\n",
            "Validation Loss: 1.9513534665107728, Validation Accuracy: 56.25\n",
            "[130/150]: Training Loss: 0.5888028677020755, Training Accuracy: 82.86\n",
            "Validation Loss: 1.9529175937175751, Validation Accuracy: 56.18\n",
            "[131/150]: Training Loss: 0.5761450562550097, Training Accuracy: 83.106\n",
            "Validation Loss: 1.9645096361637115, Validation Accuracy: 56.02\n",
            "[132/150]: Training Loss: 0.5727416809116092, Training Accuracy: 83.094\n",
            "Validation Loss: 1.963749361038208, Validation Accuracy: 56.38\n",
            "[133/150]: Training Loss: 0.5652356436666177, Training Accuracy: 83.672\n",
            "Validation Loss: 1.9716902256011963, Validation Accuracy: 56.28\n",
            "[134/150]: Training Loss: 0.5695076165150623, Training Accuracy: 83.448\n",
            "Validation Loss: 1.964329320192337, Validation Accuracy: 55.99\n",
            "[135/150]: Training Loss: 0.5608592775403237, Training Accuracy: 83.678\n",
            "Validation Loss: 1.9603359639644622, Validation Accuracy: 56.25\n",
            "[136/150]: Training Loss: 0.5542723040799705, Training Accuracy: 83.854\n",
            "Validation Loss: 1.9673468470573425, Validation Accuracy: 56.04\n",
            "[137/150]: Training Loss: 0.5495593383604166, Training Accuracy: 84.128\n",
            "Validation Loss: 1.9731853008270264, Validation Accuracy: 56.19\n",
            "[138/150]: Training Loss: 0.5444910410715609, Training Accuracy: 84.204\n",
            "Validation Loss: 1.9700454473495483, Validation Accuracy: 56.12\n",
            "[139/150]: Training Loss: 0.5433347140039716, Training Accuracy: 84.306\n",
            "Validation Loss: 1.9688788115978242, Validation Accuracy: 56.13\n",
            "[140/150]: Training Loss: 0.5362506448006144, Training Accuracy: 84.586\n",
            "Validation Loss: 1.966701751947403, Validation Accuracy: 56.24\n",
            "[141/150]: Training Loss: 0.5390761190531205, Training Accuracy: 84.338\n",
            "Validation Loss: 1.9651995241641997, Validation Accuracy: 56.21\n",
            "[142/150]: Training Loss: 0.5341207445884237, Training Accuracy: 84.41\n",
            "Validation Loss: 1.9675312757492065, Validation Accuracy: 56.34\n",
            "[143/150]: Training Loss: 0.5282508870776819, Training Accuracy: 84.872\n",
            "Validation Loss: 1.967752468585968, Validation Accuracy: 56.25\n",
            "[144/150]: Training Loss: 0.5355107656547001, Training Accuracy: 84.532\n",
            "Validation Loss: 1.967381328344345, Validation Accuracy: 56.19\n",
            "[145/150]: Training Loss: 0.5333734960580359, Training Accuracy: 84.51\n",
            "Validation Loss: 1.969217723608017, Validation Accuracy: 56.19\n",
            "[146/150]: Training Loss: 0.5298109002867524, Training Accuracy: 84.75\n",
            "Validation Loss: 1.9694741308689117, Validation Accuracy: 56.12\n",
            "[147/150]: Training Loss: 0.529324583253082, Training Accuracy: 84.722\n",
            "Validation Loss: 1.9707287430763245, Validation Accuracy: 56.17\n",
            "[148/150]: Training Loss: 0.5251490242627203, Training Accuracy: 84.936\n",
            "Validation Loss: 1.9699740409851074, Validation Accuracy: 56.26\n",
            "[149/150]: Training Loss: 0.5242341507454308, Training Accuracy: 84.942\n",
            "Validation Loss: 1.97024707198143, Validation Accuracy: 56.16\n",
            "[150/150]: Training Loss: 0.5341996495821038, Training Accuracy: 84.57\n",
            "Validation Loss: 1.9700913786888123, Validation Accuracy: 56.18\n",
            "**********************************************************************\n",
            "Test Loss: 1.9700913786888123, Test Accuracy: 56.18\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▆▁▅▄▅▃▆▄▃▃▅▅▅▅▅▆▆▆▆</td></tr><tr><td>Test Loss</td><td>▆▆█▄▃▃▄▂▂▃▂▃▃▂▃▃▁▂▁▁</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>56.18</td></tr><tr><td>Test Loss</td><td>1.97009</td></tr><tr><td>Train Accuracy</td><td>84.57</td></tr><tr><td>Train Loss</td><td>0.5342</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_012749-momu4e5u/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 1024, Learning rate: 6.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_014707-w80ujlhs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">batch_size=1024 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.271560571631607, Training Accuracy: 4.982\n",
            "Validation Loss: 3.9391962051391602, Validation Accuracy: 8.84\n",
            "[2/150]: Training Loss: 3.82728639914065, Training Accuracy: 10.948\n",
            "Validation Loss: 3.6827336311340333, Validation Accuracy: 13.37\n",
            "[3/150]: Training Loss: 3.6269987845907408, Training Accuracy: 14.39\n",
            "Validation Loss: 3.4175909042358397, Validation Accuracy: 18.27\n",
            "[4/150]: Training Loss: 3.4358463238696664, Training Accuracy: 17.696\n",
            "Validation Loss: 3.2815504550933836, Validation Accuracy: 20.38\n",
            "[5/150]: Training Loss: 3.3039202203555984, Training Accuracy: 19.798\n",
            "Validation Loss: 3.171510195732117, Validation Accuracy: 23.09\n",
            "[6/150]: Training Loss: 3.1788000671231016, Training Accuracy: 22.106\n",
            "Validation Loss: 3.083156633377075, Validation Accuracy: 24.25\n",
            "[7/150]: Training Loss: 3.0781905553778826, Training Accuracy: 24.04\n",
            "Validation Loss: 2.9470993995666506, Validation Accuracy: 26.99\n",
            "[8/150]: Training Loss: 2.9905799846259917, Training Accuracy: 25.462\n",
            "Validation Loss: 2.8303237915039063, Validation Accuracy: 29.04\n",
            "[9/150]: Training Loss: 2.8789747199233697, Training Accuracy: 28.024\n",
            "Validation Loss: 2.7251497507095337, Validation Accuracy: 31.63\n",
            "[10/150]: Training Loss: 2.752841701312941, Training Accuracy: 30.378\n",
            "Validation Loss: 2.6787135124206545, Validation Accuracy: 32.86\n",
            "[11/150]: Training Loss: 2.664300650966411, Training Accuracy: 32.018\n",
            "Validation Loss: 2.5810091733932494, Validation Accuracy: 34.34\n",
            "[12/150]: Training Loss: 2.6055227445096385, Training Accuracy: 33.34\n",
            "Validation Loss: 2.511804437637329, Validation Accuracy: 35.24\n",
            "[13/150]: Training Loss: 2.569062106463374, Training Accuracy: 34.12\n",
            "Validation Loss: 2.452015995979309, Validation Accuracy: 36.63\n",
            "[14/150]: Training Loss: 2.4965496793085213, Training Accuracy: 35.586\n",
            "Validation Loss: 2.353745174407959, Validation Accuracy: 38.35\n",
            "[15/150]: Training Loss: 2.4792360870205625, Training Accuracy: 35.788\n",
            "Validation Loss: 2.362164545059204, Validation Accuracy: 38.51\n",
            "[16/150]: Training Loss: 2.406777240792099, Training Accuracy: 37.498\n",
            "Validation Loss: 2.322283720970154, Validation Accuracy: 39.52\n",
            "[17/150]: Training Loss: 2.3524391651153564, Training Accuracy: 38.372\n",
            "Validation Loss: 2.2932183027267454, Validation Accuracy: 40.0\n",
            "[18/150]: Training Loss: 2.3162564647441006, Training Accuracy: 39.304\n",
            "Validation Loss: 2.390507221221924, Validation Accuracy: 38.54\n",
            "[19/150]: Training Loss: 2.3010421821049283, Training Accuracy: 39.48\n",
            "Validation Loss: 2.2039053201675416, Validation Accuracy: 42.83\n",
            "[20/150]: Training Loss: 2.2905601968570632, Training Accuracy: 40.014\n",
            "Validation Loss: 2.327000045776367, Validation Accuracy: 39.01\n",
            "[21/150]: Training Loss: 2.2232315151058897, Training Accuracy: 41.472\n",
            "Validation Loss: 2.1848330736160277, Validation Accuracy: 42.37\n",
            "[22/150]: Training Loss: 2.175964046497734, Training Accuracy: 42.316\n",
            "Validation Loss: 2.192854475975037, Validation Accuracy: 42.34\n",
            "[23/150]: Training Loss: 2.12663603315548, Training Accuracy: 43.39\n",
            "Validation Loss: 2.184653973579407, Validation Accuracy: 42.91\n",
            "[24/150]: Training Loss: 2.1151150294712613, Training Accuracy: 43.664\n",
            "Validation Loss: 2.1352186679840086, Validation Accuracy: 43.8\n",
            "[25/150]: Training Loss: 2.0990794507824644, Training Accuracy: 44.256\n",
            "Validation Loss: 2.088001215457916, Validation Accuracy: 44.67\n",
            "[26/150]: Training Loss: 2.0608093349301084, Training Accuracy: 44.852\n",
            "Validation Loss: 2.1832612276077272, Validation Accuracy: 42.92\n",
            "[27/150]: Training Loss: 2.0558675892499028, Training Accuracy: 45.23\n",
            "Validation Loss: 2.176005721092224, Validation Accuracy: 43.08\n",
            "[28/150]: Training Loss: 2.0222370770512796, Training Accuracy: 45.868\n",
            "Validation Loss: 2.1084380388259887, Validation Accuracy: 44.53\n",
            "[29/150]: Training Loss: 1.9681626996215509, Training Accuracy: 47.006\n",
            "Validation Loss: 2.07066353559494, Validation Accuracy: 45.38\n",
            "[30/150]: Training Loss: 1.9436734793137531, Training Accuracy: 47.268\n",
            "Validation Loss: 2.0732940912246702, Validation Accuracy: 45.56\n",
            "[31/150]: Training Loss: 1.9339864083698817, Training Accuracy: 48.042\n",
            "Validation Loss: 2.095534420013428, Validation Accuracy: 45.23\n",
            "[32/150]: Training Loss: 1.9033171717001467, Training Accuracy: 48.32\n",
            "Validation Loss: 2.111021065711975, Validation Accuracy: 45.35\n",
            "[33/150]: Training Loss: 1.904011852887212, Training Accuracy: 48.414\n",
            "Validation Loss: 2.050978398323059, Validation Accuracy: 46.52\n",
            "[34/150]: Training Loss: 1.8750450124545974, Training Accuracy: 48.976\n",
            "Validation Loss: 2.080773401260376, Validation Accuracy: 45.2\n",
            "[35/150]: Training Loss: 1.8805813740710824, Training Accuracy: 48.968\n",
            "Validation Loss: 2.036470913887024, Validation Accuracy: 46.34\n",
            "[36/150]: Training Loss: 1.851276424466347, Training Accuracy: 49.646\n",
            "Validation Loss: 2.1005828619003295, Validation Accuracy: 45.2\n",
            "[37/150]: Training Loss: 1.8493371909978438, Training Accuracy: 49.736\n",
            "Validation Loss: 2.003628730773926, Validation Accuracy: 46.62\n",
            "[38/150]: Training Loss: 1.7895233460835047, Training Accuracy: 50.876\n",
            "Validation Loss: 1.9916603326797486, Validation Accuracy: 47.91\n",
            "[39/150]: Training Loss: 1.783764887829216, Training Accuracy: 51.294\n",
            "Validation Loss: 2.066832160949707, Validation Accuracy: 45.61\n",
            "[40/150]: Training Loss: 1.7760933297021049, Training Accuracy: 51.504\n",
            "Validation Loss: 1.9901643991470337, Validation Accuracy: 47.5\n",
            "[41/150]: Training Loss: 1.7614454274274864, Training Accuracy: 51.798\n",
            "Validation Loss: 2.0182290196418764, Validation Accuracy: 47.1\n",
            "[42/150]: Training Loss: 1.7892101711156416, Training Accuracy: 51.024\n",
            "Validation Loss: 1.9716030478477478, Validation Accuracy: 48.76\n",
            "[43/150]: Training Loss: 1.7074257597631337, Training Accuracy: 52.916\n",
            "Validation Loss: 1.9718806385993957, Validation Accuracy: 48.61\n",
            "[44/150]: Training Loss: 1.714418238523055, Training Accuracy: 52.714\n",
            "Validation Loss: 2.0062466263771057, Validation Accuracy: 48.27\n",
            "[45/150]: Training Loss: 1.6869578483153362, Training Accuracy: 53.334\n",
            "Validation Loss: 1.95201518535614, Validation Accuracy: 49.06\n",
            "[46/150]: Training Loss: 1.6628945092765652, Training Accuracy: 53.922\n",
            "Validation Loss: 2.012867844104767, Validation Accuracy: 47.15\n",
            "[47/150]: Training Loss: 1.6412470778640436, Training Accuracy: 54.254\n",
            "Validation Loss: 1.923640739917755, Validation Accuracy: 49.27\n",
            "[48/150]: Training Loss: 1.6261077705694704, Training Accuracy: 55.032\n",
            "Validation Loss: 1.9601864099502564, Validation Accuracy: 48.98\n",
            "[49/150]: Training Loss: 1.6493362480280351, Training Accuracy: 54.152\n",
            "Validation Loss: 1.9593440890312195, Validation Accuracy: 48.65\n",
            "[50/150]: Training Loss: 1.612999371119908, Training Accuracy: 55.134\n",
            "Validation Loss: 1.9344399094581604, Validation Accuracy: 49.38\n",
            "[51/150]: Training Loss: 1.5939155281806479, Training Accuracy: 55.666\n",
            "Validation Loss: 1.9557547926902772, Validation Accuracy: 48.7\n",
            "[52/150]: Training Loss: 1.6124721181635955, Training Accuracy: 55.024\n",
            "Validation Loss: 1.9627613067626952, Validation Accuracy: 48.75\n",
            "[53/150]: Training Loss: 1.5704505808499394, Training Accuracy: 56.09\n",
            "Validation Loss: 1.9339674592018128, Validation Accuracy: 49.77\n",
            "[54/150]: Training Loss: 1.556705151285444, Training Accuracy: 56.304\n",
            "Validation Loss: 1.910308563709259, Validation Accuracy: 50.74\n",
            "[55/150]: Training Loss: 1.5271518887305746, Training Accuracy: 57.15\n",
            "Validation Loss: 1.8914035081863403, Validation Accuracy: 50.77\n",
            "[56/150]: Training Loss: 1.5157563102488616, Training Accuracy: 57.53\n",
            "Validation Loss: 1.8953699111938476, Validation Accuracy: 50.82\n",
            "[57/150]: Training Loss: 1.4868425179500968, Training Accuracy: 58.284\n",
            "Validation Loss: 1.960522997379303, Validation Accuracy: 49.2\n",
            "[58/150]: Training Loss: 1.5009924586938352, Training Accuracy: 57.544\n",
            "Validation Loss: 1.9257111549377441, Validation Accuracy: 50.88\n",
            "[59/150]: Training Loss: 1.4776659741693614, Training Accuracy: 58.214\n",
            "Validation Loss: 1.9358840227127074, Validation Accuracy: 50.04\n",
            "[60/150]: Training Loss: 1.4657867806298392, Training Accuracy: 58.49\n",
            "Validation Loss: 2.0199026823043824, Validation Accuracy: 48.59\n",
            "[61/150]: Training Loss: 1.4666189709488227, Training Accuracy: 58.868\n",
            "Validation Loss: 1.9441120982170106, Validation Accuracy: 49.79\n",
            "[62/150]: Training Loss: 1.4370595435706937, Training Accuracy: 59.142\n",
            "Validation Loss: 1.8950949430465698, Validation Accuracy: 51.17\n",
            "[63/150]: Training Loss: 1.4119965835493438, Training Accuracy: 59.966\n",
            "Validation Loss: 1.946419107913971, Validation Accuracy: 49.96\n",
            "[64/150]: Training Loss: 1.3992952692265412, Training Accuracy: 60.37\n",
            "Validation Loss: 1.929420042037964, Validation Accuracy: 50.74\n",
            "[65/150]: Training Loss: 1.3843509275086072, Training Accuracy: 60.93\n",
            "Validation Loss: 1.8808708190917969, Validation Accuracy: 51.52\n",
            "[66/150]: Training Loss: 1.3892741276293386, Training Accuracy: 60.538\n",
            "Validation Loss: 1.9178170323371888, Validation Accuracy: 51.05\n",
            "[67/150]: Training Loss: 1.3926233807388617, Training Accuracy: 60.324\n",
            "Validation Loss: 1.879079854488373, Validation Accuracy: 52.14\n",
            "[68/150]: Training Loss: 1.3284603332986638, Training Accuracy: 62.108\n",
            "Validation Loss: 1.8741150736808776, Validation Accuracy: 51.87\n",
            "[69/150]: Training Loss: 1.3297611377677139, Training Accuracy: 62.144\n",
            "Validation Loss: 1.8850895166397095, Validation Accuracy: 51.78\n",
            "[70/150]: Training Loss: 1.3190836857776254, Training Accuracy: 62.086\n",
            "Validation Loss: 1.8964969992637635, Validation Accuracy: 51.72\n",
            "[71/150]: Training Loss: 1.297834805079869, Training Accuracy: 63.002\n",
            "Validation Loss: 1.8922056078910827, Validation Accuracy: 51.94\n",
            "[72/150]: Training Loss: 1.3022558105235198, Training Accuracy: 62.866\n",
            "Validation Loss: 1.8891796469688416, Validation Accuracy: 52.07\n",
            "[73/150]: Training Loss: 1.2681196271156778, Training Accuracy: 63.622\n",
            "Validation Loss: 1.9051270723342895, Validation Accuracy: 52.41\n",
            "[74/150]: Training Loss: 1.2562547800492267, Training Accuracy: 64.092\n",
            "Validation Loss: 1.8912514567375183, Validation Accuracy: 52.28\n",
            "[75/150]: Training Loss: 1.2469108761573324, Training Accuracy: 64.088\n",
            "Validation Loss: 1.9140023827552795, Validation Accuracy: 52.11\n",
            "[76/150]: Training Loss: 1.2424099080416622, Training Accuracy: 64.206\n",
            "Validation Loss: 1.896690595149994, Validation Accuracy: 52.53\n",
            "[77/150]: Training Loss: 1.2172678052162638, Training Accuracy: 64.804\n",
            "Validation Loss: 1.8944836139678956, Validation Accuracy: 52.54\n",
            "[78/150]: Training Loss: 1.198543380717842, Training Accuracy: 65.358\n",
            "Validation Loss: 1.8942208647727967, Validation Accuracy: 52.32\n",
            "[79/150]: Training Loss: 1.198562699921277, Training Accuracy: 65.602\n",
            "Validation Loss: 1.8823209404945374, Validation Accuracy: 52.42\n",
            "[80/150]: Training Loss: 1.1809428224758225, Training Accuracy: 66.04\n",
            "Validation Loss: 1.8809239506721496, Validation Accuracy: 52.57\n",
            "[81/150]: Training Loss: 1.1573098119424314, Training Accuracy: 66.476\n",
            "Validation Loss: 1.904803991317749, Validation Accuracy: 52.64\n",
            "[82/150]: Training Loss: 1.1748385405053898, Training Accuracy: 65.876\n",
            "Validation Loss: 1.8975732803344727, Validation Accuracy: 52.68\n",
            "[83/150]: Training Loss: 1.1381618465696062, Training Accuracy: 67.06\n",
            "Validation Loss: 1.87950758934021, Validation Accuracy: 53.8\n",
            "[84/150]: Training Loss: 1.1169312851769584, Training Accuracy: 67.614\n",
            "Validation Loss: 1.9594017744064331, Validation Accuracy: 51.52\n",
            "[85/150]: Training Loss: 1.1326112601221825, Training Accuracy: 67.212\n",
            "Validation Loss: 1.9392709732055664, Validation Accuracy: 52.51\n",
            "[86/150]: Training Loss: 1.1153452299079116, Training Accuracy: 67.558\n",
            "Validation Loss: 1.8824020862579345, Validation Accuracy: 53.05\n",
            "[87/150]: Training Loss: 1.075961629955136, Training Accuracy: 68.556\n",
            "Validation Loss: 1.8995132923126221, Validation Accuracy: 53.22\n",
            "[88/150]: Training Loss: 1.0561599804430593, Training Accuracy: 69.222\n",
            "Validation Loss: 1.8934579133987426, Validation Accuracy: 53.25\n",
            "[89/150]: Training Loss: 1.0379744488365796, Training Accuracy: 69.548\n",
            "Validation Loss: 1.8907739281654359, Validation Accuracy: 54.05\n",
            "[90/150]: Training Loss: 1.0645462481343015, Training Accuracy: 69.002\n",
            "Validation Loss: 1.9286641478538513, Validation Accuracy: 52.38\n",
            "[91/150]: Training Loss: 1.0510404596523362, Training Accuracy: 69.392\n",
            "Validation Loss: 1.897424077987671, Validation Accuracy: 53.61\n",
            "[92/150]: Training Loss: 1.017185703832276, Training Accuracy: 70.506\n",
            "Validation Loss: 1.9066467523574828, Validation Accuracy: 53.56\n",
            "[93/150]: Training Loss: 0.9912244945156331, Training Accuracy: 70.89\n",
            "Validation Loss: 1.9277787804603577, Validation Accuracy: 53.53\n",
            "[94/150]: Training Loss: 1.0054571652898983, Training Accuracy: 70.53\n",
            "Validation Loss: 1.8809196829795838, Validation Accuracy: 54.1\n",
            "[95/150]: Training Loss: 0.9765667416611497, Training Accuracy: 71.32\n",
            "Validation Loss: 1.8944197297096252, Validation Accuracy: 53.48\n",
            "[96/150]: Training Loss: 0.9578249174721387, Training Accuracy: 71.926\n",
            "Validation Loss: 1.942376160621643, Validation Accuracy: 53.53\n",
            "[97/150]: Training Loss: 0.9575933753227701, Training Accuracy: 71.676\n",
            "Validation Loss: 1.8917027354240417, Validation Accuracy: 53.65\n",
            "[98/150]: Training Loss: 0.944321874453097, Training Accuracy: 72.258\n",
            "Validation Loss: 1.8984474778175353, Validation Accuracy: 54.22\n",
            "[99/150]: Training Loss: 0.9205025398001379, Training Accuracy: 72.942\n",
            "Validation Loss: 1.9325331091880797, Validation Accuracy: 54.27\n",
            "[100/150]: Training Loss: 0.9185542439927861, Training Accuracy: 72.924\n",
            "Validation Loss: 1.9163445711135865, Validation Accuracy: 54.26\n",
            "[101/150]: Training Loss: 0.8990846799344433, Training Accuracy: 73.314\n",
            "Validation Loss: 1.9365061402320862, Validation Accuracy: 54.02\n",
            "[102/150]: Training Loss: 0.8797871519108208, Training Accuracy: 74.004\n",
            "Validation Loss: 1.937075173854828, Validation Accuracy: 54.45\n",
            "[103/150]: Training Loss: 0.8798652291297913, Training Accuracy: 74.044\n",
            "Validation Loss: 1.9165674328804017, Validation Accuracy: 54.24\n",
            "[104/150]: Training Loss: 0.8599669252123151, Training Accuracy: 74.54\n",
            "Validation Loss: 1.9492801547050476, Validation Accuracy: 53.91\n",
            "[105/150]: Training Loss: 0.8473539729507602, Training Accuracy: 74.856\n",
            "Validation Loss: 1.9327858686447144, Validation Accuracy: 53.8\n",
            "[106/150]: Training Loss: 0.8454914895855651, Training Accuracy: 74.948\n",
            "Validation Loss: 1.918694531917572, Validation Accuracy: 54.58\n",
            "[107/150]: Training Loss: 0.8351617601453042, Training Accuracy: 75.38\n",
            "Validation Loss: 1.925265645980835, Validation Accuracy: 54.65\n",
            "[108/150]: Training Loss: 0.8257343720416633, Training Accuracy: 75.846\n",
            "Validation Loss: 1.9380712270736695, Validation Accuracy: 54.61\n",
            "[109/150]: Training Loss: 0.803754199524315, Training Accuracy: 76.216\n",
            "Validation Loss: 1.952760434150696, Validation Accuracy: 54.15\n",
            "[110/150]: Training Loss: 0.8017950021490758, Training Accuracy: 76.334\n",
            "Validation Loss: 1.938999843597412, Validation Accuracy: 54.87\n",
            "[111/150]: Training Loss: 0.7898118264821111, Training Accuracy: 76.776\n",
            "Validation Loss: 1.9549705505371093, Validation Accuracy: 54.67\n",
            "[112/150]: Training Loss: 0.7774463660862981, Training Accuracy: 76.952\n",
            "Validation Loss: 1.9725535273551942, Validation Accuracy: 54.17\n",
            "[113/150]: Training Loss: 0.7767588861134588, Training Accuracy: 76.824\n",
            "Validation Loss: 1.9652800679206848, Validation Accuracy: 54.49\n",
            "[114/150]: Training Loss: 0.7543022997525274, Training Accuracy: 77.61\n",
            "Validation Loss: 1.9479739904403686, Validation Accuracy: 54.85\n",
            "[115/150]: Training Loss: 0.7407014296979321, Training Accuracy: 78.064\n",
            "Validation Loss: 1.974105668067932, Validation Accuracy: 54.73\n",
            "[116/150]: Training Loss: 0.7379214763641357, Training Accuracy: 78.122\n",
            "Validation Loss: 1.9709696292877197, Validation Accuracy: 54.92\n",
            "[117/150]: Training Loss: 0.7280089295640284, Training Accuracy: 78.332\n",
            "Validation Loss: 1.9550812244415283, Validation Accuracy: 54.87\n",
            "[118/150]: Training Loss: 0.719780373330019, Training Accuracy: 78.916\n",
            "Validation Loss: 1.9715718150138855, Validation Accuracy: 54.88\n",
            "[119/150]: Training Loss: 0.7140980338563725, Training Accuracy: 78.938\n",
            "Validation Loss: 1.9744232773780823, Validation Accuracy: 54.88\n",
            "[120/150]: Training Loss: 0.7100381559255172, Training Accuracy: 79.112\n",
            "Validation Loss: 1.9600295305252076, Validation Accuracy: 55.01\n",
            "[121/150]: Training Loss: 0.695380872609664, Training Accuracy: 79.644\n",
            "Validation Loss: 1.9685936331748963, Validation Accuracy: 55.25\n",
            "[122/150]: Training Loss: 0.693044870483632, Training Accuracy: 79.566\n",
            "Validation Loss: 1.973974621295929, Validation Accuracy: 54.99\n",
            "[123/150]: Training Loss: 0.685412128360904, Training Accuracy: 79.762\n",
            "Validation Loss: 1.981511080265045, Validation Accuracy: 55.03\n",
            "[124/150]: Training Loss: 0.6729757055944326, Training Accuracy: 80.388\n",
            "Validation Loss: 1.9723920106887818, Validation Accuracy: 54.88\n",
            "[125/150]: Training Loss: 0.6728029567368177, Training Accuracy: 80.238\n",
            "Validation Loss: 1.972815704345703, Validation Accuracy: 55.06\n",
            "[126/150]: Training Loss: 0.6577607624384821, Training Accuracy: 80.906\n",
            "Validation Loss: 1.9941662311553956, Validation Accuracy: 55.01\n",
            "[127/150]: Training Loss: 0.6531734880135984, Training Accuracy: 80.798\n",
            "Validation Loss: 1.9830293536186219, Validation Accuracy: 55.29\n",
            "[128/150]: Training Loss: 0.6451807484334829, Training Accuracy: 80.998\n",
            "Validation Loss: 1.98456552028656, Validation Accuracy: 55.25\n",
            "[129/150]: Training Loss: 0.6361871045462939, Training Accuracy: 81.438\n",
            "Validation Loss: 1.991374099254608, Validation Accuracy: 55.33\n",
            "[130/150]: Training Loss: 0.6329771852006718, Training Accuracy: 81.326\n",
            "Validation Loss: 1.982979428768158, Validation Accuracy: 55.15\n",
            "[131/150]: Training Loss: 0.6337368731596031, Training Accuracy: 81.498\n",
            "Validation Loss: 1.9814332127571106, Validation Accuracy: 55.25\n",
            "[132/150]: Training Loss: 0.6237865613431347, Training Accuracy: 81.828\n",
            "Validation Loss: 1.9956311464309693, Validation Accuracy: 55.37\n",
            "[133/150]: Training Loss: 0.6184223087466493, Training Accuracy: 81.804\n",
            "Validation Loss: 1.997809612751007, Validation Accuracy: 55.31\n",
            "[134/150]: Training Loss: 0.6162658759525844, Training Accuracy: 82.05\n",
            "Validation Loss: 1.9944164514541627, Validation Accuracy: 55.37\n",
            "[135/150]: Training Loss: 0.6049274242654139, Training Accuracy: 82.308\n",
            "Validation Loss: 2.0007421493530275, Validation Accuracy: 55.18\n",
            "[136/150]: Training Loss: 0.6065428415123297, Training Accuracy: 82.346\n",
            "Validation Loss: 2.002026319503784, Validation Accuracy: 55.35\n",
            "[137/150]: Training Loss: 0.6054561515243686, Training Accuracy: 82.446\n",
            "Validation Loss: 2.0026141166687013, Validation Accuracy: 55.51\n",
            "[138/150]: Training Loss: 0.6016628170499996, Training Accuracy: 82.674\n",
            "Validation Loss: 1.9972286820411682, Validation Accuracy: 55.54\n",
            "[139/150]: Training Loss: 0.599141927397981, Training Accuracy: 82.822\n",
            "Validation Loss: 1.9984585762023925, Validation Accuracy: 55.21\n",
            "[140/150]: Training Loss: 0.5853999877462581, Training Accuracy: 82.924\n",
            "Validation Loss: 2.0003657698631288, Validation Accuracy: 55.39\n",
            "[141/150]: Training Loss: 0.5930902678139356, Training Accuracy: 82.696\n",
            "Validation Loss: 1.9994045495986938, Validation Accuracy: 55.54\n",
            "[142/150]: Training Loss: 0.5897825044028613, Training Accuracy: 83.098\n",
            "Validation Loss: 2.0004444122314453, Validation Accuracy: 55.4\n",
            "[143/150]: Training Loss: 0.5907509253949536, Training Accuracy: 82.836\n",
            "Validation Loss: 1.9981922507286072, Validation Accuracy: 55.3\n",
            "[144/150]: Training Loss: 0.5838782507546094, Training Accuracy: 83.046\n",
            "Validation Loss: 1.9986275434494019, Validation Accuracy: 55.59\n",
            "[145/150]: Training Loss: 0.5819402069461589, Training Accuracy: 83.02\n",
            "Validation Loss: 2.0001697182655334, Validation Accuracy: 55.45\n",
            "[146/150]: Training Loss: 0.5872244786243049, Training Accuracy: 82.898\n",
            "Validation Loss: 2.000009226799011, Validation Accuracy: 55.41\n",
            "[147/150]: Training Loss: 0.5821643848808444, Training Accuracy: 83.186\n",
            "Validation Loss: 2.0006944298744203, Validation Accuracy: 55.35\n",
            "[148/150]: Training Loss: 0.5849178761852031, Training Accuracy: 83.14\n",
            "Validation Loss: 2.000812566280365, Validation Accuracy: 55.33\n",
            "[149/150]: Training Loss: 0.5800890168365167, Training Accuracy: 83.304\n",
            "Validation Loss: 2.000700604915619, Validation Accuracy: 55.4\n",
            "[150/150]: Training Loss: 0.5826626444349483, Training Accuracy: 83.206\n",
            "Validation Loss: 2.000621163845062, Validation Accuracy: 55.35\n",
            "**********************************************************************\n",
            "Test Loss: 2.000621163845062, Test Accuracy: 55.35\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▁▁▃▂▂▅▄▃▄</td></tr><tr><td>Test Loss</td><td>█▂▂▁▄▄▃▄▃▂</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>55.35</td></tr><tr><td>Test Loss</td><td>2.00062</td></tr><tr><td>Train Accuracy</td><td>83.206</td></tr><tr><td>Train Loss</td><td>0.58266</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=1024 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_014707-w80ujlhs/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 2048, Learning rate: 8.485281374238571, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_022321-j8jszxxs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">batch_size=2048 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.36701738357544, Training Accuracy: 3.886\n",
            "Validation Loss: 4.163058471679688, Validation Accuracy: 5.67\n",
            "[2/150]: Training Loss: 4.113679485321045, Training Accuracy: 6.492\n",
            "Validation Loss: 3.9081267356872558, Validation Accuracy: 9.58\n",
            "[3/150]: Training Loss: 3.8604202461242676, Training Accuracy: 10.016\n",
            "Validation Loss: 3.6436347484588625, Validation Accuracy: 14.06\n",
            "[4/150]: Training Loss: 3.7227595615386964, Training Accuracy: 12.524\n",
            "Validation Loss: 3.58444561958313, Validation Accuracy: 15.49\n",
            "[5/150]: Training Loss: 3.5834127140045164, Training Accuracy: 14.702\n",
            "Validation Loss: 3.4575596332550047, Validation Accuracy: 17.38\n",
            "[6/150]: Training Loss: 3.4569161987304686, Training Accuracy: 16.904\n",
            "Validation Loss: 3.262946367263794, Validation Accuracy: 20.16\n",
            "[7/150]: Training Loss: 3.3158952045440673, Training Accuracy: 19.406\n",
            "Validation Loss: 3.2002731800079345, Validation Accuracy: 22.26\n",
            "[8/150]: Training Loss: 3.1832161426544188, Training Accuracy: 22.068\n",
            "Validation Loss: 3.0290011405944823, Validation Accuracy: 24.81\n",
            "[9/150]: Training Loss: 3.185646390914917, Training Accuracy: 21.936\n",
            "Validation Loss: 3.1018139362335204, Validation Accuracy: 24.11\n",
            "[10/150]: Training Loss: 3.0637048053741456, Training Accuracy: 23.926\n",
            "Validation Loss: 2.9448835372924806, Validation Accuracy: 26.91\n",
            "[11/150]: Training Loss: 2.951322078704834, Training Accuracy: 26.03\n",
            "Validation Loss: 2.8756459236145018, Validation Accuracy: 27.94\n",
            "[12/150]: Training Loss: 2.9279331874847414, Training Accuracy: 26.79\n",
            "Validation Loss: 2.9318973541259767, Validation Accuracy: 27.51\n",
            "[13/150]: Training Loss: 2.828905839920044, Training Accuracy: 28.722\n",
            "Validation Loss: 2.634994125366211, Validation Accuracy: 33.35\n",
            "[14/150]: Training Loss: 2.8078646850585938, Training Accuracy: 29.266\n",
            "Validation Loss: 2.7456551074981688, Validation Accuracy: 30.56\n",
            "[15/150]: Training Loss: 2.712659044265747, Training Accuracy: 30.836\n",
            "Validation Loss: 2.5297746658325195, Validation Accuracy: 34.77\n",
            "[16/150]: Training Loss: 2.651611213684082, Training Accuracy: 32.136\n",
            "Validation Loss: 2.547566270828247, Validation Accuracy: 34.69\n",
            "[17/150]: Training Loss: 2.599648675918579, Training Accuracy: 33.174\n",
            "Validation Loss: 2.5292351245880127, Validation Accuracy: 34.72\n",
            "[18/150]: Training Loss: 2.577428216934204, Training Accuracy: 33.64\n",
            "Validation Loss: 2.5313771247863768, Validation Accuracy: 35.11\n",
            "[19/150]: Training Loss: 2.575561113357544, Training Accuracy: 33.86\n",
            "Validation Loss: 2.50340313911438, Validation Accuracy: 36.18\n",
            "[20/150]: Training Loss: 2.617272434234619, Training Accuracy: 32.958\n",
            "Validation Loss: 2.601680040359497, Validation Accuracy: 34.74\n",
            "[21/150]: Training Loss: 2.503620433807373, Training Accuracy: 35.3\n",
            "Validation Loss: 2.3930795192718506, Validation Accuracy: 38.69\n",
            "[22/150]: Training Loss: 2.4627874088287354, Training Accuracy: 36.662\n",
            "Validation Loss: 2.669213056564331, Validation Accuracy: 33.56\n",
            "[23/150]: Training Loss: 2.548478717803955, Training Accuracy: 34.642\n",
            "Validation Loss: 2.3424915313720702, Validation Accuracy: 39.2\n",
            "[24/150]: Training Loss: 2.3940266799926757, Training Accuracy: 37.736\n",
            "Validation Loss: 2.3067100048065186, Validation Accuracy: 39.53\n",
            "[25/150]: Training Loss: 2.3650291538238526, Training Accuracy: 38.102\n",
            "Validation Loss: 2.4807125091552735, Validation Accuracy: 36.63\n",
            "[26/150]: Training Loss: 2.3525609493255617, Training Accuracy: 38.382\n",
            "Validation Loss: 2.3692517280578613, Validation Accuracy: 39.11\n",
            "[27/150]: Training Loss: 2.2789812183380125, Training Accuracy: 40.074\n",
            "Validation Loss: 2.2349360942840577, Validation Accuracy: 41.75\n",
            "[28/150]: Training Loss: 2.2222459888458252, Training Accuracy: 40.97\n",
            "Validation Loss: 2.19801549911499, Validation Accuracy: 42.61\n",
            "[29/150]: Training Loss: 2.214301881790161, Training Accuracy: 41.694\n",
            "Validation Loss: 2.605668783187866, Validation Accuracy: 35.32\n",
            "[30/150]: Training Loss: 2.338454341888428, Training Accuracy: 38.786\n",
            "Validation Loss: 2.288765287399292, Validation Accuracy: 40.36\n",
            "[31/150]: Training Loss: 2.201904296875, Training Accuracy: 41.99\n",
            "Validation Loss: 2.205613946914673, Validation Accuracy: 42.56\n",
            "[32/150]: Training Loss: 2.1113436079025267, Training Accuracy: 43.934\n",
            "Validation Loss: 2.321266937255859, Validation Accuracy: 41.03\n",
            "[33/150]: Training Loss: 2.1466791677474975, Training Accuracy: 43.006\n",
            "Validation Loss: 2.1349957466125487, Validation Accuracy: 43.8\n",
            "[34/150]: Training Loss: 2.1290991640090944, Training Accuracy: 43.29\n",
            "Validation Loss: 2.217708683013916, Validation Accuracy: 42.79\n",
            "[35/150]: Training Loss: 2.0663461446762086, Training Accuracy: 44.68\n",
            "Validation Loss: 2.3302943229675295, Validation Accuracy: 40.26\n",
            "[36/150]: Training Loss: 2.0297911977767944, Training Accuracy: 45.408\n",
            "Validation Loss: 2.21708025932312, Validation Accuracy: 43.36\n",
            "[37/150]: Training Loss: 2.0129797410964967, Training Accuracy: 45.814\n",
            "Validation Loss: 2.0887409687042235, Validation Accuracy: 45.25\n",
            "[38/150]: Training Loss: 1.937804069519043, Training Accuracy: 47.634\n",
            "Validation Loss: 2.0723501682281493, Validation Accuracy: 45.71\n",
            "[39/150]: Training Loss: 1.943020739555359, Training Accuracy: 47.708\n",
            "Validation Loss: 2.0943463325500487, Validation Accuracy: 44.8\n",
            "[40/150]: Training Loss: 1.9138334608078003, Training Accuracy: 48.346\n",
            "Validation Loss: 2.2366223335266113, Validation Accuracy: 42.21\n",
            "[41/150]: Training Loss: 1.9987104320526123, Training Accuracy: 46.376\n",
            "Validation Loss: 2.12234206199646, Validation Accuracy: 45.35\n",
            "[42/150]: Training Loss: 1.9329777145385743, Training Accuracy: 47.608\n",
            "Validation Loss: 2.097510814666748, Validation Accuracy: 45.23\n",
            "[43/150]: Training Loss: 1.9182713079452514, Training Accuracy: 47.922\n",
            "Validation Loss: 2.085854196548462, Validation Accuracy: 45.54\n",
            "[44/150]: Training Loss: 1.900009379386902, Training Accuracy: 48.732\n",
            "Validation Loss: 2.051387619972229, Validation Accuracy: 46.24\n",
            "[45/150]: Training Loss: 1.8408135080337524, Training Accuracy: 49.714\n",
            "Validation Loss: 2.0023281574249268, Validation Accuracy: 47.57\n",
            "[46/150]: Training Loss: 1.785364203453064, Training Accuracy: 51.326\n",
            "Validation Loss: 2.049905252456665, Validation Accuracy: 46.49\n",
            "[47/150]: Training Loss: 1.8102792501449585, Training Accuracy: 50.858\n",
            "Validation Loss: 2.0309868812561036, Validation Accuracy: 46.64\n",
            "[48/150]: Training Loss: 1.7956236791610718, Training Accuracy: 50.794\n",
            "Validation Loss: 2.0011850118637087, Validation Accuracy: 47.81\n",
            "[49/150]: Training Loss: 1.7439770412445068, Training Accuracy: 52.0\n",
            "Validation Loss: 1.9770531415939332, Validation Accuracy: 48.07\n",
            "[50/150]: Training Loss: 1.7183953332901, Training Accuracy: 52.358\n",
            "Validation Loss: 2.0561673641204834, Validation Accuracy: 46.4\n",
            "[51/150]: Training Loss: 1.717338604927063, Training Accuracy: 53.112\n",
            "Validation Loss: 1.9954840183258056, Validation Accuracy: 47.55\n",
            "[52/150]: Training Loss: 1.7013448238372804, Training Accuracy: 53.098\n",
            "Validation Loss: 2.0024028778076173, Validation Accuracy: 47.72\n",
            "[53/150]: Training Loss: 1.7069044065475465, Training Accuracy: 53.0\n",
            "Validation Loss: 2.08711462020874, Validation Accuracy: 45.49\n",
            "[54/150]: Training Loss: 1.6761716079711915, Training Accuracy: 53.252\n",
            "Validation Loss: 1.9557607173919678, Validation Accuracy: 49.03\n",
            "[55/150]: Training Loss: 1.6440558958053588, Training Accuracy: 54.564\n",
            "Validation Loss: 1.9891844987869263, Validation Accuracy: 48.39\n",
            "[56/150]: Training Loss: 1.6161942625045775, Training Accuracy: 54.926\n",
            "Validation Loss: 2.029493975639343, Validation Accuracy: 47.58\n",
            "[57/150]: Training Loss: 1.6047872447967528, Training Accuracy: 55.192\n",
            "Validation Loss: 1.967372179031372, Validation Accuracy: 48.91\n",
            "[58/150]: Training Loss: 1.713731393814087, Training Accuracy: 52.926\n",
            "Validation Loss: 2.0652761220932008, Validation Accuracy: 46.68\n",
            "[59/150]: Training Loss: 1.6507894086837769, Training Accuracy: 54.226\n",
            "Validation Loss: 1.9929080486297608, Validation Accuracy: 48.66\n",
            "[60/150]: Training Loss: 1.6021452569961547, Training Accuracy: 55.432\n",
            "Validation Loss: 1.9558722257614136, Validation Accuracy: 49.28\n",
            "[61/150]: Training Loss: 1.543088173866272, Training Accuracy: 56.656\n",
            "Validation Loss: 1.9447553634643555, Validation Accuracy: 49.2\n",
            "[62/150]: Training Loss: 1.5494691371917724, Training Accuracy: 56.864\n",
            "Validation Loss: 1.885341501235962, Validation Accuracy: 50.76\n",
            "[63/150]: Training Loss: 1.4937063312530519, Training Accuracy: 58.158\n",
            "Validation Loss: 1.9500130414962769, Validation Accuracy: 49.94\n",
            "[64/150]: Training Loss: 1.4539641427993775, Training Accuracy: 59.004\n",
            "Validation Loss: 1.9285942554473876, Validation Accuracy: 49.98\n",
            "[65/150]: Training Loss: 1.4972302389144898, Training Accuracy: 57.904\n",
            "Validation Loss: 1.9630061149597169, Validation Accuracy: 49.26\n",
            "[66/150]: Training Loss: 1.518665623664856, Training Accuracy: 57.152\n",
            "Validation Loss: 1.9333840608596802, Validation Accuracy: 50.24\n",
            "[67/150]: Training Loss: 1.5036478281021117, Training Accuracy: 57.512\n",
            "Validation Loss: 1.961331272125244, Validation Accuracy: 50.09\n",
            "[68/150]: Training Loss: 1.4539181280136109, Training Accuracy: 59.142\n",
            "Validation Loss: 1.9611144304275512, Validation Accuracy: 49.25\n",
            "[69/150]: Training Loss: 1.46078604221344, Training Accuracy: 58.794\n",
            "Validation Loss: 1.916247057914734, Validation Accuracy: 50.02\n",
            "[70/150]: Training Loss: 1.4112844705581664, Training Accuracy: 59.934\n",
            "Validation Loss: 1.8900265216827392, Validation Accuracy: 51.2\n",
            "[71/150]: Training Loss: 1.3915088891983032, Training Accuracy: 60.376\n",
            "Validation Loss: 1.9043931245803833, Validation Accuracy: 50.87\n",
            "[72/150]: Training Loss: 1.3921622323989868, Training Accuracy: 60.564\n",
            "Validation Loss: 1.9693795204162599, Validation Accuracy: 50.0\n",
            "[73/150]: Training Loss: 1.3862884998321534, Training Accuracy: 60.752\n",
            "Validation Loss: 1.9339972734451294, Validation Accuracy: 50.94\n",
            "[74/150]: Training Loss: 1.358318910598755, Training Accuracy: 61.528\n",
            "Validation Loss: 1.9029748439788818, Validation Accuracy: 51.01\n",
            "[75/150]: Training Loss: 1.3378327751159669, Training Accuracy: 61.9\n",
            "Validation Loss: 1.9114508390426637, Validation Accuracy: 51.04\n",
            "[76/150]: Training Loss: 1.307257251739502, Training Accuracy: 62.684\n",
            "Validation Loss: 1.897865653038025, Validation Accuracy: 51.33\n",
            "[77/150]: Training Loss: 1.307571873664856, Training Accuracy: 62.566\n",
            "Validation Loss: 1.9430776834487915, Validation Accuracy: 50.79\n",
            "[78/150]: Training Loss: 1.2927326250076294, Training Accuracy: 62.904\n",
            "Validation Loss: 1.910500168800354, Validation Accuracy: 52.01\n",
            "[79/150]: Training Loss: 1.2737730932235718, Training Accuracy: 63.4\n",
            "Validation Loss: 1.8831387996673583, Validation Accuracy: 52.08\n",
            "[80/150]: Training Loss: 1.254057068824768, Training Accuracy: 64.394\n",
            "Validation Loss: 1.8864023208618164, Validation Accuracy: 51.51\n",
            "[81/150]: Training Loss: 1.2196114826202393, Training Accuracy: 64.948\n",
            "Validation Loss: 1.9068121194839478, Validation Accuracy: 51.97\n",
            "[82/150]: Training Loss: 1.2375918960571288, Training Accuracy: 64.48\n",
            "Validation Loss: 1.9304296493530273, Validation Accuracy: 51.61\n",
            "[83/150]: Training Loss: 1.2156933164596557, Training Accuracy: 64.806\n",
            "Validation Loss: 1.9103889226913453, Validation Accuracy: 51.82\n",
            "[84/150]: Training Loss: 1.1918401718139648, Training Accuracy: 65.572\n",
            "Validation Loss: 1.9341503858566285, Validation Accuracy: 51.6\n",
            "[85/150]: Training Loss: 1.2064945554733277, Training Accuracy: 65.146\n",
            "Validation Loss: 1.9983864784240724, Validation Accuracy: 50.34\n",
            "[86/150]: Training Loss: 1.201401376724243, Training Accuracy: 65.426\n",
            "Validation Loss: 1.9176611185073853, Validation Accuracy: 51.45\n",
            "[87/150]: Training Loss: 1.1660136127471923, Training Accuracy: 66.176\n",
            "Validation Loss: 1.943800139427185, Validation Accuracy: 51.49\n",
            "[88/150]: Training Loss: 1.1312262058258056, Training Accuracy: 67.438\n",
            "Validation Loss: 1.9152551412582397, Validation Accuracy: 51.68\n",
            "[89/150]: Training Loss: 1.1454276323318482, Training Accuracy: 66.958\n",
            "Validation Loss: 1.9066155195236205, Validation Accuracy: 52.43\n",
            "[90/150]: Training Loss: 1.1536525392532349, Training Accuracy: 66.622\n",
            "Validation Loss: 1.912238073348999, Validation Accuracy: 51.99\n",
            "[91/150]: Training Loss: 1.1152591037750244, Training Accuracy: 67.662\n",
            "Validation Loss: 1.9254616022109985, Validation Accuracy: 52.11\n",
            "[92/150]: Training Loss: 1.0796469306945802, Training Accuracy: 68.538\n",
            "Validation Loss: 1.918501377105713, Validation Accuracy: 52.25\n",
            "[93/150]: Training Loss: 1.0836839008331298, Training Accuracy: 68.43\n",
            "Validation Loss: 1.9036231279373168, Validation Accuracy: 52.52\n",
            "[94/150]: Training Loss: 1.111613211631775, Training Accuracy: 67.66\n",
            "Validation Loss: 1.9749577283859252, Validation Accuracy: 51.0\n",
            "[95/150]: Training Loss: 1.1183206748962402, Training Accuracy: 67.53\n",
            "Validation Loss: 1.9319661378860473, Validation Accuracy: 52.53\n",
            "[96/150]: Training Loss: 1.0428566884994508, Training Accuracy: 69.502\n",
            "Validation Loss: 1.9246442794799805, Validation Accuracy: 52.17\n",
            "[97/150]: Training Loss: 1.029050705432892, Training Accuracy: 70.002\n",
            "Validation Loss: 1.9244839429855347, Validation Accuracy: 52.21\n",
            "[98/150]: Training Loss: 1.0212417674064636, Training Accuracy: 70.272\n",
            "Validation Loss: 1.9145327806472778, Validation Accuracy: 52.78\n",
            "[99/150]: Training Loss: 1.0124672603607179, Training Accuracy: 70.44\n",
            "Validation Loss: 1.9107223749160767, Validation Accuracy: 53.04\n",
            "[100/150]: Training Loss: 0.9880559778213501, Training Accuracy: 71.17\n",
            "Validation Loss: 1.9347419500350953, Validation Accuracy: 52.57\n",
            "[101/150]: Training Loss: 0.9812371230125427, Training Accuracy: 71.144\n",
            "Validation Loss: 1.9186458826065063, Validation Accuracy: 53.22\n",
            "[102/150]: Training Loss: 0.9656218528747559, Training Accuracy: 72.014\n",
            "Validation Loss: 1.9120693922042846, Validation Accuracy: 53.07\n",
            "[103/150]: Training Loss: 0.9567889213562012, Training Accuracy: 71.89\n",
            "Validation Loss: 1.9197413206100464, Validation Accuracy: 52.84\n",
            "[104/150]: Training Loss: 0.9529655456542969, Training Accuracy: 72.086\n",
            "Validation Loss: 1.9144711256027223, Validation Accuracy: 53.0\n",
            "[105/150]: Training Loss: 0.9852134394645691, Training Accuracy: 71.252\n",
            "Validation Loss: 1.9319961071014404, Validation Accuracy: 53.06\n",
            "[106/150]: Training Loss: 0.9273789191246032, Training Accuracy: 72.91\n",
            "Validation Loss: 1.9424444437026978, Validation Accuracy: 52.84\n",
            "[107/150]: Training Loss: 0.9234069514274598, Training Accuracy: 73.084\n",
            "Validation Loss: 1.9234145641326905, Validation Accuracy: 52.94\n",
            "[108/150]: Training Loss: 0.9229924130439758, Training Accuracy: 73.21\n",
            "Validation Loss: 1.9324826002120972, Validation Accuracy: 52.73\n",
            "[109/150]: Training Loss: 0.9058748340606689, Training Accuracy: 73.67\n",
            "Validation Loss: 1.9500421285629272, Validation Accuracy: 53.29\n",
            "[110/150]: Training Loss: 0.8911954641342164, Training Accuracy: 73.872\n",
            "Validation Loss: 1.941013789176941, Validation Accuracy: 53.28\n",
            "[111/150]: Training Loss: 0.8825567650794983, Training Accuracy: 74.012\n",
            "Validation Loss: 1.9361898183822632, Validation Accuracy: 53.09\n",
            "[112/150]: Training Loss: 0.8620765686035157, Training Accuracy: 74.656\n",
            "Validation Loss: 1.9341821908950805, Validation Accuracy: 53.36\n",
            "[113/150]: Training Loss: 0.8601221704483032, Training Accuracy: 74.8\n",
            "Validation Loss: 1.9615466117858886, Validation Accuracy: 53.34\n",
            "[114/150]: Training Loss: 0.8472113418579101, Training Accuracy: 75.216\n",
            "Validation Loss: 1.950052309036255, Validation Accuracy: 53.42\n",
            "[115/150]: Training Loss: 0.84150705575943, Training Accuracy: 75.34\n",
            "Validation Loss: 1.9719900608062744, Validation Accuracy: 53.33\n",
            "[116/150]: Training Loss: 0.8295826292037964, Training Accuracy: 75.764\n",
            "Validation Loss: 1.9504849910736084, Validation Accuracy: 53.65\n",
            "[117/150]: Training Loss: 0.8204774522781372, Training Accuracy: 76.024\n",
            "Validation Loss: 1.9509764194488526, Validation Accuracy: 54.02\n",
            "[118/150]: Training Loss: 0.8103749394416809, Training Accuracy: 76.418\n",
            "Validation Loss: 1.9664921760559082, Validation Accuracy: 53.3\n",
            "[119/150]: Training Loss: 0.8074698400497436, Training Accuracy: 76.44\n",
            "Validation Loss: 1.955758023262024, Validation Accuracy: 53.71\n",
            "[120/150]: Training Loss: 0.8068988251686097, Training Accuracy: 76.406\n",
            "Validation Loss: 1.9637468814849854, Validation Accuracy: 53.55\n",
            "[121/150]: Training Loss: 0.7903911852836609, Training Accuracy: 76.678\n",
            "Validation Loss: 1.9706329584121705, Validation Accuracy: 53.57\n",
            "[122/150]: Training Loss: 0.7799955105781555, Training Accuracy: 77.276\n",
            "Validation Loss: 1.976036286354065, Validation Accuracy: 53.7\n",
            "[123/150]: Training Loss: 0.7765986251831055, Training Accuracy: 77.324\n",
            "Validation Loss: 1.9730368375778198, Validation Accuracy: 53.3\n",
            "[124/150]: Training Loss: 0.7681253123283386, Training Accuracy: 77.54\n",
            "Validation Loss: 1.9741400957107544, Validation Accuracy: 53.63\n",
            "[125/150]: Training Loss: 0.7622663331031799, Training Accuracy: 77.518\n",
            "Validation Loss: 1.9705329179763793, Validation Accuracy: 54.09\n",
            "[126/150]: Training Loss: 0.7574337005615235, Training Accuracy: 78.034\n",
            "Validation Loss: 1.9730172395706176, Validation Accuracy: 53.71\n",
            "[127/150]: Training Loss: 0.7504327082633973, Training Accuracy: 78.258\n",
            "Validation Loss: 1.9689469575881957, Validation Accuracy: 53.87\n",
            "[128/150]: Training Loss: 0.7432142400741577, Training Accuracy: 78.082\n",
            "Validation Loss: 1.9787657976150512, Validation Accuracy: 53.54\n",
            "[129/150]: Training Loss: 0.7408276867866516, Training Accuracy: 78.396\n",
            "Validation Loss: 1.9802783012390137, Validation Accuracy: 53.89\n",
            "[130/150]: Training Loss: 0.7272537612915039, Training Accuracy: 78.856\n",
            "Validation Loss: 1.9677628517150878, Validation Accuracy: 53.76\n",
            "[131/150]: Training Loss: 0.7158604049682618, Training Accuracy: 78.946\n",
            "Validation Loss: 1.97785542011261, Validation Accuracy: 53.9\n",
            "[132/150]: Training Loss: 0.7163805866241455, Training Accuracy: 79.138\n",
            "Validation Loss: 1.976898455619812, Validation Accuracy: 53.7\n",
            "[133/150]: Training Loss: 0.721850438117981, Training Accuracy: 78.816\n",
            "Validation Loss: 1.9874832153320312, Validation Accuracy: 53.66\n",
            "[134/150]: Training Loss: 0.719142906665802, Training Accuracy: 79.046\n",
            "Validation Loss: 1.9858264207839966, Validation Accuracy: 53.92\n",
            "[135/150]: Training Loss: 0.7152685523033142, Training Accuracy: 79.11\n",
            "Validation Loss: 1.9745909452438355, Validation Accuracy: 53.99\n",
            "[136/150]: Training Loss: 0.7077970743179322, Training Accuracy: 79.564\n",
            "Validation Loss: 1.9791152715682983, Validation Accuracy: 53.54\n",
            "[137/150]: Training Loss: 0.7019647455215454, Training Accuracy: 79.626\n",
            "Validation Loss: 1.9777050018310547, Validation Accuracy: 54.06\n",
            "[138/150]: Training Loss: 0.6962298607826233, Training Accuracy: 79.744\n",
            "Validation Loss: 1.9783851623535156, Validation Accuracy: 53.9\n",
            "[139/150]: Training Loss: 0.6945947551727295, Training Accuracy: 79.802\n",
            "Validation Loss: 1.9834458827972412, Validation Accuracy: 53.84\n",
            "[140/150]: Training Loss: 0.6916244769096375, Training Accuracy: 79.876\n",
            "Validation Loss: 1.9782796621322631, Validation Accuracy: 54.08\n",
            "[141/150]: Training Loss: 0.686495201587677, Training Accuracy: 80.022\n",
            "Validation Loss: 1.9823485612869263, Validation Accuracy: 54.07\n",
            "[142/150]: Training Loss: 0.6907814073562623, Training Accuracy: 80.056\n",
            "Validation Loss: 1.9827837467193603, Validation Accuracy: 53.98\n",
            "[143/150]: Training Loss: 0.6871487998962402, Training Accuracy: 80.084\n",
            "Validation Loss: 1.9844423055648803, Validation Accuracy: 54.1\n",
            "[144/150]: Training Loss: 0.6854921150207519, Training Accuracy: 80.314\n",
            "Validation Loss: 1.9852968454360962, Validation Accuracy: 53.98\n",
            "[145/150]: Training Loss: 0.6804221367835999, Training Accuracy: 80.244\n",
            "Validation Loss: 1.9844240427017212, Validation Accuracy: 54.1\n",
            "[146/150]: Training Loss: 0.682576208114624, Training Accuracy: 80.136\n",
            "Validation Loss: 1.9841588735580444, Validation Accuracy: 54.07\n",
            "[147/150]: Training Loss: 0.6786355781555176, Training Accuracy: 80.254\n",
            "Validation Loss: 1.9839539051055908, Validation Accuracy: 54.12\n",
            "[148/150]: Training Loss: 0.6753697633743286, Training Accuracy: 80.27\n",
            "Validation Loss: 1.9842885971069335, Validation Accuracy: 54.16\n",
            "[149/150]: Training Loss: 0.6753653740882873, Training Accuracy: 80.488\n",
            "Validation Loss: 1.9842547655105591, Validation Accuracy: 54.12\n",
            "[150/150]: Training Loss: 0.6740122199058532, Training Accuracy: 80.532\n",
            "Validation Loss: 1.984296441078186, Validation Accuracy: 54.15\n",
            "**********************************************************************\n",
            "Test Loss: 1.984296441078186, Test Accuracy: 54.15\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁█▆▃▇</td></tr><tr><td>Test Loss</td><td>▆▄▆█▁</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▃▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▆▆▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>54.15</td></tr><tr><td>Test Loss</td><td>1.9843</td></tr><tr><td>Train Accuracy</td><td>80.532</td></tr><tr><td>Train Loss</td><td>0.67401</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=2048 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_022321-j8jszxxs/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 4096, Learning rate: 12.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_024410-fcrci1zx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">batch_size=4096 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.448218419001653, Training Accuracy: 3.104\n",
            "Validation Loss: 4.19553820292155, Validation Accuracy: 5.83\n",
            "[2/150]: Training Loss: 4.162900081047645, Training Accuracy: 5.992\n",
            "Validation Loss: 4.001244783401489, Validation Accuracy: 8.19\n",
            "[3/150]: Training Loss: 3.9526728116548977, Training Accuracy: 9.02\n",
            "Validation Loss: 3.849735975265503, Validation Accuracy: 10.99\n",
            "[4/150]: Training Loss: 3.9088880098783054, Training Accuracy: 9.748\n",
            "Validation Loss: 3.7720150152842202, Validation Accuracy: 11.82\n",
            "[5/150]: Training Loss: 3.7579474999354434, Training Accuracy: 11.674\n",
            "Validation Loss: 3.6346964836120605, Validation Accuracy: 13.58\n",
            "[6/150]: Training Loss: 3.8317384169651914, Training Accuracy: 10.848\n",
            "Validation Loss: 3.6928911209106445, Validation Accuracy: 13.8\n",
            "[7/150]: Training Loss: 3.6279670825371375, Training Accuracy: 13.764\n",
            "Validation Loss: 3.426232655843099, Validation Accuracy: 17.9\n",
            "[8/150]: Training Loss: 3.559702047934899, Training Accuracy: 15.198\n",
            "Validation Loss: 3.5184563795725503, Validation Accuracy: 15.74\n",
            "[9/150]: Training Loss: 3.619346306874202, Training Accuracy: 14.12\n",
            "Validation Loss: 3.4724766413370767, Validation Accuracy: 16.53\n",
            "[10/150]: Training Loss: 3.4825954070458045, Training Accuracy: 16.518\n",
            "Validation Loss: 3.491668939590454, Validation Accuracy: 17.05\n",
            "[11/150]: Training Loss: 3.5322888447688174, Training Accuracy: 15.738\n",
            "Validation Loss: 3.3563063939412436, Validation Accuracy: 18.53\n",
            "[12/150]: Training Loss: 3.381067386040321, Training Accuracy: 18.274\n",
            "Validation Loss: 3.371330420176188, Validation Accuracy: 18.51\n",
            "[13/150]: Training Loss: 3.3759262011601376, Training Accuracy: 18.364\n",
            "Validation Loss: 3.1718979676564536, Validation Accuracy: 22.38\n",
            "[14/150]: Training Loss: 3.24786586027879, Training Accuracy: 20.88\n",
            "Validation Loss: 3.149214585622152, Validation Accuracy: 22.67\n",
            "[15/150]: Training Loss: 3.155352940926185, Training Accuracy: 22.24\n",
            "Validation Loss: 2.999330917994181, Validation Accuracy: 25.44\n",
            "[16/150]: Training Loss: 2.9997272124657264, Training Accuracy: 25.252\n",
            "Validation Loss: 2.8626222610473633, Validation Accuracy: 28.18\n",
            "[17/150]: Training Loss: 2.952247326190655, Training Accuracy: 26.39\n",
            "Validation Loss: 3.0151708920796714, Validation Accuracy: 25.48\n",
            "[18/150]: Training Loss: 3.035908350577721, Training Accuracy: 24.716\n",
            "Validation Loss: 2.84928830464681, Validation Accuracy: 28.54\n",
            "[19/150]: Training Loss: 2.8744187355041504, Training Accuracy: 27.56\n",
            "Validation Loss: 2.732924222946167, Validation Accuracy: 30.87\n",
            "[20/150]: Training Loss: 2.7774770443256083, Training Accuracy: 29.672\n",
            "Validation Loss: 2.800260861714681, Validation Accuracy: 29.69\n",
            "[21/150]: Training Loss: 2.9696661142202525, Training Accuracy: 26.582\n",
            "Validation Loss: 3.213308095932007, Validation Accuracy: 22.23\n",
            "[22/150]: Training Loss: 3.2055968137887807, Training Accuracy: 22.87\n",
            "Validation Loss: 3.0360422134399414, Validation Accuracy: 25.56\n",
            "[23/150]: Training Loss: 3.0269867456876316, Training Accuracy: 25.102\n",
            "Validation Loss: 2.861661911010742, Validation Accuracy: 29.24\n",
            "[24/150]: Training Loss: 2.8519647121429443, Training Accuracy: 28.248\n",
            "Validation Loss: 2.682717482248942, Validation Accuracy: 31.6\n",
            "[25/150]: Training Loss: 2.705435276031494, Training Accuracy: 31.156\n",
            "Validation Loss: 2.509896198908488, Validation Accuracy: 35.11\n",
            "[26/150]: Training Loss: 2.613956708174485, Training Accuracy: 33.41\n",
            "Validation Loss: 2.505950371424357, Validation Accuracy: 34.77\n",
            "[27/150]: Training Loss: 3.002190589904785, Training Accuracy: 26.466\n",
            "Validation Loss: 2.775864839553833, Validation Accuracy: 29.88\n",
            "[28/150]: Training Loss: 2.742469017322247, Training Accuracy: 30.316\n",
            "Validation Loss: 2.589009443918864, Validation Accuracy: 33.99\n",
            "[29/150]: Training Loss: 2.8341226394359884, Training Accuracy: 29.282\n",
            "Validation Loss: 2.8079089323679605, Validation Accuracy: 29.56\n",
            "[30/150]: Training Loss: 2.745966214400071, Training Accuracy: 30.384\n",
            "Validation Loss: 2.5663379033406577, Validation Accuracy: 34.18\n",
            "[31/150]: Training Loss: 2.5754335476801944, Training Accuracy: 33.944\n",
            "Validation Loss: 2.4243160088857016, Validation Accuracy: 37.33\n",
            "[32/150]: Training Loss: 2.4728290117703953, Training Accuracy: 35.998\n",
            "Validation Loss: 2.4164366722106934, Validation Accuracy: 37.02\n",
            "[33/150]: Training Loss: 2.550288127018855, Training Accuracy: 34.558\n",
            "Validation Loss: 2.4929703871409097, Validation Accuracy: 35.7\n",
            "[34/150]: Training Loss: 2.5172606064723086, Training Accuracy: 35.468\n",
            "Validation Loss: 2.5022354125976562, Validation Accuracy: 35.92\n",
            "[35/150]: Training Loss: 2.5095452528733473, Training Accuracy: 35.052\n",
            "Validation Loss: 2.3538503646850586, Validation Accuracy: 38.43\n",
            "[36/150]: Training Loss: 2.595434335561899, Training Accuracy: 34.342\n",
            "Validation Loss: 2.7459415594736734, Validation Accuracy: 30.95\n",
            "[37/150]: Training Loss: 2.5996641562535214, Training Accuracy: 33.51\n",
            "Validation Loss: 2.4413878122965493, Validation Accuracy: 37.55\n",
            "[38/150]: Training Loss: 2.4308731005742, Training Accuracy: 36.788\n",
            "Validation Loss: 2.3517263730367026, Validation Accuracy: 38.8\n",
            "[39/150]: Training Loss: 2.3385920707996073, Training Accuracy: 39.318\n",
            "Validation Loss: 2.4507851600646973, Validation Accuracy: 37.58\n",
            "[40/150]: Training Loss: 2.4006691529200626, Training Accuracy: 37.842\n",
            "Validation Loss: 2.3381757736206055, Validation Accuracy: 39.0\n",
            "[41/150]: Training Loss: 2.4301048792325535, Training Accuracy: 36.898\n",
            "Validation Loss: 2.3649702866872153, Validation Accuracy: 38.64\n",
            "[42/150]: Training Loss: 2.282798070173997, Training Accuracy: 39.856\n",
            "Validation Loss: 2.2728551228841147, Validation Accuracy: 40.36\n",
            "[43/150]: Training Loss: 2.235896715751061, Training Accuracy: 40.962\n",
            "Validation Loss: 2.2269629637400308, Validation Accuracy: 41.47\n",
            "[44/150]: Training Loss: 2.277051045344426, Training Accuracy: 40.666\n",
            "Validation Loss: 2.393709977467855, Validation Accuracy: 38.68\n",
            "[45/150]: Training Loss: 2.266980061164269, Training Accuracy: 40.186\n",
            "Validation Loss: 2.260339101155599, Validation Accuracy: 41.24\n",
            "[46/150]: Training Loss: 2.2269545518434963, Training Accuracy: 41.5\n",
            "Validation Loss: 2.184856653213501, Validation Accuracy: 42.59\n",
            "[47/150]: Training Loss: 2.1506412762861986, Training Accuracy: 42.82\n",
            "Validation Loss: 2.151843468348185, Validation Accuracy: 43.6\n",
            "[48/150]: Training Loss: 2.0945023756760817, Training Accuracy: 45.142\n",
            "Validation Loss: 2.1851927439371743, Validation Accuracy: 42.94\n",
            "[49/150]: Training Loss: 2.368942279082078, Training Accuracy: 38.482\n",
            "Validation Loss: 2.311251401901245, Validation Accuracy: 39.8\n",
            "[50/150]: Training Loss: 2.1795968275803785, Training Accuracy: 42.274\n",
            "Validation Loss: 2.1368969281514487, Validation Accuracy: 43.53\n",
            "[51/150]: Training Loss: 2.287435614145719, Training Accuracy: 40.578\n",
            "Validation Loss: 2.3101561864217124, Validation Accuracy: 40.31\n",
            "[52/150]: Training Loss: 2.133154667340792, Training Accuracy: 43.412\n",
            "Validation Loss: 2.101039091746012, Validation Accuracy: 44.48\n",
            "[53/150]: Training Loss: 2.009332299232483, Training Accuracy: 46.076\n",
            "Validation Loss: 2.053215821584066, Validation Accuracy: 46.02\n",
            "[54/150]: Training Loss: 2.0092475414276123, Training Accuracy: 46.312\n",
            "Validation Loss: 2.068614880243937, Validation Accuracy: 45.15\n",
            "[55/150]: Training Loss: 2.0747447105554433, Training Accuracy: 44.708\n",
            "Validation Loss: 2.0757156213124595, Validation Accuracy: 45.38\n",
            "[56/150]: Training Loss: 2.0832339341823873, Training Accuracy: 44.52\n",
            "Validation Loss: 2.2822861671447754, Validation Accuracy: 40.59\n",
            "[57/150]: Training Loss: 2.035889350450956, Training Accuracy: 45.234\n",
            "Validation Loss: 2.077279488245646, Validation Accuracy: 45.32\n",
            "[58/150]: Training Loss: 1.9101605140245879, Training Accuracy: 48.098\n",
            "Validation Loss: 2.075277328491211, Validation Accuracy: 45.52\n",
            "[59/150]: Training Loss: 1.930518700526311, Training Accuracy: 47.694\n",
            "Validation Loss: 2.0554560820261636, Validation Accuracy: 45.94\n",
            "[60/150]: Training Loss: 1.9262570784642146, Training Accuracy: 47.71\n",
            "Validation Loss: 1.9856750170389812, Validation Accuracy: 46.93\n",
            "[61/150]: Training Loss: 1.8526782714403593, Training Accuracy: 49.478\n",
            "Validation Loss: 1.9915226300557454, Validation Accuracy: 46.83\n",
            "[62/150]: Training Loss: 1.8636801151128917, Training Accuracy: 49.23\n",
            "Validation Loss: 2.094877322514852, Validation Accuracy: 45.09\n",
            "[63/150]: Training Loss: 1.8440089867665217, Training Accuracy: 49.998\n",
            "Validation Loss: 1.9725687503814697, Validation Accuracy: 47.58\n",
            "[64/150]: Training Loss: 1.8951456546783447, Training Accuracy: 48.798\n",
            "Validation Loss: 2.079833189646403, Validation Accuracy: 45.33\n",
            "[65/150]: Training Loss: 1.9134588700074415, Training Accuracy: 48.274\n",
            "Validation Loss: 2.0578166246414185, Validation Accuracy: 45.69\n",
            "[66/150]: Training Loss: 1.850765347480774, Training Accuracy: 49.748\n",
            "Validation Loss: 2.0475390752156577, Validation Accuracy: 47.14\n",
            "[67/150]: Training Loss: 1.7821540557421172, Training Accuracy: 51.288\n",
            "Validation Loss: 1.9497700134913127, Validation Accuracy: 48.19\n",
            "[68/150]: Training Loss: 1.7319823136696448, Training Accuracy: 52.606\n",
            "Validation Loss: 2.018282691637675, Validation Accuracy: 47.2\n",
            "[69/150]: Training Loss: 1.7186179894667406, Training Accuracy: 52.626\n",
            "Validation Loss: 1.9749605258305867, Validation Accuracy: 48.19\n",
            "[70/150]: Training Loss: 1.6911903069569514, Training Accuracy: 53.452\n",
            "Validation Loss: 1.9826482931772869, Validation Accuracy: 47.74\n",
            "[71/150]: Training Loss: 1.660032529097337, Training Accuracy: 54.11\n",
            "Validation Loss: 1.908194661140442, Validation Accuracy: 49.51\n",
            "[72/150]: Training Loss: 1.6769285110326915, Training Accuracy: 53.518\n",
            "Validation Loss: 1.954678734143575, Validation Accuracy: 48.03\n",
            "[73/150]: Training Loss: 1.6593820590239305, Training Accuracy: 53.96\n",
            "Validation Loss: 1.9272022247314453, Validation Accuracy: 48.63\n",
            "[74/150]: Training Loss: 1.6419056562276988, Training Accuracy: 54.992\n",
            "Validation Loss: 1.992493987083435, Validation Accuracy: 47.79\n",
            "[75/150]: Training Loss: 1.6689472198486328, Training Accuracy: 53.936\n",
            "Validation Loss: 1.9214499394098918, Validation Accuracy: 49.0\n",
            "[76/150]: Training Loss: 1.6087861702992365, Training Accuracy: 55.276\n",
            "Validation Loss: 1.896010160446167, Validation Accuracy: 49.84\n",
            "[77/150]: Training Loss: 1.5652516438410833, Training Accuracy: 56.72\n",
            "Validation Loss: 1.873304804166158, Validation Accuracy: 51.03\n",
            "[78/150]: Training Loss: 1.6746907876088069, Training Accuracy: 54.032\n",
            "Validation Loss: 1.954778750737508, Validation Accuracy: 49.08\n",
            "[79/150]: Training Loss: 1.5788640517454882, Training Accuracy: 55.932\n",
            "Validation Loss: 1.9272086222966511, Validation Accuracy: 50.3\n",
            "[80/150]: Training Loss: 1.6021267634171705, Training Accuracy: 55.644\n",
            "Validation Loss: 2.1279262701670327, Validation Accuracy: 45.34\n",
            "[81/150]: Training Loss: 1.7035195552385771, Training Accuracy: 53.114\n",
            "Validation Loss: 1.9278326431910198, Validation Accuracy: 49.04\n",
            "[82/150]: Training Loss: 1.559159095470722, Training Accuracy: 56.4\n",
            "Validation Loss: 1.9029817183812459, Validation Accuracy: 49.79\n",
            "[83/150]: Training Loss: 1.5267010835500865, Training Accuracy: 57.53\n",
            "Validation Loss: 1.9380817810694377, Validation Accuracy: 48.88\n",
            "[84/150]: Training Loss: 1.5102592706680298, Training Accuracy: 57.916\n",
            "Validation Loss: 1.8722127676010132, Validation Accuracy: 51.08\n",
            "[85/150]: Training Loss: 1.4807829398375292, Training Accuracy: 58.592\n",
            "Validation Loss: 1.9032895962397258, Validation Accuracy: 49.92\n",
            "[86/150]: Training Loss: 1.4740843681188731, Training Accuracy: 58.914\n",
            "Validation Loss: 1.8672935565312703, Validation Accuracy: 50.45\n",
            "[87/150]: Training Loss: 1.515398117212149, Training Accuracy: 57.934\n",
            "Validation Loss: 1.9412325620651245, Validation Accuracy: 49.15\n",
            "[88/150]: Training Loss: 1.576969366807204, Training Accuracy: 55.868\n",
            "Validation Loss: 1.935785969098409, Validation Accuracy: 49.25\n",
            "[89/150]: Training Loss: 1.4918665610826933, Training Accuracy: 58.11\n",
            "Validation Loss: 1.8986582358678181, Validation Accuracy: 51.05\n",
            "[90/150]: Training Loss: 1.4492073059082031, Training Accuracy: 59.446\n",
            "Validation Loss: 1.8367600440979004, Validation Accuracy: 51.57\n",
            "[91/150]: Training Loss: 1.4048503912412202, Training Accuracy: 60.418\n",
            "Validation Loss: 1.837977687517802, Validation Accuracy: 51.68\n",
            "[92/150]: Training Loss: 1.3744991559248705, Training Accuracy: 61.112\n",
            "Validation Loss: 1.8420219818751018, Validation Accuracy: 51.77\n",
            "[93/150]: Training Loss: 1.420577076765207, Training Accuracy: 60.392\n",
            "Validation Loss: 1.8663844267527263, Validation Accuracy: 51.21\n",
            "[94/150]: Training Loss: 1.4505155269916241, Training Accuracy: 59.012\n",
            "Validation Loss: 1.8934478759765625, Validation Accuracy: 50.84\n",
            "[95/150]: Training Loss: 1.4003274349065928, Training Accuracy: 60.672\n",
            "Validation Loss: 1.8551263411839802, Validation Accuracy: 51.69\n",
            "[96/150]: Training Loss: 1.3484498354104848, Training Accuracy: 61.974\n",
            "Validation Loss: 1.8562318483988445, Validation Accuracy: 51.96\n",
            "[97/150]: Training Loss: 1.314302426118117, Training Accuracy: 62.828\n",
            "Validation Loss: 1.8313268423080444, Validation Accuracy: 52.72\n",
            "[98/150]: Training Loss: 1.2976581683525672, Training Accuracy: 63.268\n",
            "Validation Loss: 1.8362118005752563, Validation Accuracy: 52.11\n",
            "[99/150]: Training Loss: 1.317265354670011, Training Accuracy: 62.994\n",
            "Validation Loss: 1.8350664774576824, Validation Accuracy: 52.02\n",
            "[100/150]: Training Loss: 1.2960394254097571, Training Accuracy: 63.262\n",
            "Validation Loss: 1.800865610440572, Validation Accuracy: 53.11\n",
            "[101/150]: Training Loss: 1.298880622937129, Training Accuracy: 62.896\n",
            "Validation Loss: 1.883919596672058, Validation Accuracy: 51.53\n",
            "[102/150]: Training Loss: 1.2974212628144484, Training Accuracy: 62.852\n",
            "Validation Loss: 1.8424270550409954, Validation Accuracy: 52.02\n",
            "[103/150]: Training Loss: 1.256823787322411, Training Accuracy: 63.952\n",
            "Validation Loss: 1.8408455053965251, Validation Accuracy: 52.54\n",
            "[104/150]: Training Loss: 1.252828497153062, Training Accuracy: 64.42\n",
            "Validation Loss: 1.8253253698349, Validation Accuracy: 52.37\n",
            "[105/150]: Training Loss: 1.2491283691846407, Training Accuracy: 64.358\n",
            "Validation Loss: 1.8558521668116252, Validation Accuracy: 52.17\n",
            "[106/150]: Training Loss: 1.229967685846182, Training Accuracy: 64.958\n",
            "Validation Loss: 1.8309193849563599, Validation Accuracy: 52.71\n",
            "[107/150]: Training Loss: 1.2172498794702382, Training Accuracy: 65.282\n",
            "Validation Loss: 1.8394190073013306, Validation Accuracy: 52.48\n",
            "[108/150]: Training Loss: 1.207243589254526, Training Accuracy: 65.544\n",
            "Validation Loss: 1.82985524336497, Validation Accuracy: 52.3\n",
            "[109/150]: Training Loss: 1.1976150732774, Training Accuracy: 65.54\n",
            "Validation Loss: 1.8410567442576091, Validation Accuracy: 52.6\n",
            "[110/150]: Training Loss: 1.1797684522775502, Training Accuracy: 66.22\n",
            "Validation Loss: 1.828009049097697, Validation Accuracy: 53.27\n",
            "[111/150]: Training Loss: 1.1586786141762366, Training Accuracy: 66.72\n",
            "Validation Loss: 1.8170452117919922, Validation Accuracy: 53.66\n",
            "[112/150]: Training Loss: 1.171253332724938, Training Accuracy: 66.59\n",
            "Validation Loss: 1.8729171355565388, Validation Accuracy: 52.55\n",
            "[113/150]: Training Loss: 1.2010775346022387, Training Accuracy: 65.75\n",
            "Validation Loss: 1.8387389580408733, Validation Accuracy: 53.17\n",
            "[114/150]: Training Loss: 1.1887562825129583, Training Accuracy: 66.114\n",
            "Validation Loss: 1.8573131561279297, Validation Accuracy: 52.59\n",
            "[115/150]: Training Loss: 1.1683265062478871, Training Accuracy: 66.588\n",
            "Validation Loss: 1.8474773168563843, Validation Accuracy: 53.17\n",
            "[116/150]: Training Loss: 1.1644465373112605, Training Accuracy: 66.768\n",
            "Validation Loss: 1.8591439326604207, Validation Accuracy: 52.41\n",
            "[117/150]: Training Loss: 1.1479460184390728, Training Accuracy: 67.308\n",
            "Validation Loss: 1.8460925817489624, Validation Accuracy: 53.29\n",
            "[118/150]: Training Loss: 1.1312938928604126, Training Accuracy: 67.496\n",
            "Validation Loss: 1.8282337188720703, Validation Accuracy: 53.62\n",
            "[119/150]: Training Loss: 1.1176557632593007, Training Accuracy: 68.078\n",
            "Validation Loss: 1.8184215625127156, Validation Accuracy: 53.58\n",
            "[120/150]: Training Loss: 1.1109853432728694, Training Accuracy: 68.212\n",
            "Validation Loss: 1.8269612789154053, Validation Accuracy: 53.4\n",
            "[121/150]: Training Loss: 1.092060116621164, Training Accuracy: 68.912\n",
            "Validation Loss: 1.8181384801864624, Validation Accuracy: 53.59\n",
            "[122/150]: Training Loss: 1.0812291502952576, Training Accuracy: 69.18\n",
            "Validation Loss: 1.8252775271733601, Validation Accuracy: 53.6\n",
            "[123/150]: Training Loss: 1.0699465458209698, Training Accuracy: 69.43\n",
            "Validation Loss: 1.834611177444458, Validation Accuracy: 54.01\n",
            "[124/150]: Training Loss: 1.0735741762014537, Training Accuracy: 69.112\n",
            "Validation Loss: 1.8203496138254802, Validation Accuracy: 53.93\n",
            "[125/150]: Training Loss: 1.0661220917334924, Training Accuracy: 69.538\n",
            "Validation Loss: 1.828150749206543, Validation Accuracy: 53.85\n",
            "[126/150]: Training Loss: 1.059658169746399, Training Accuracy: 69.666\n",
            "Validation Loss: 1.8271387418111165, Validation Accuracy: 53.8\n",
            "[127/150]: Training Loss: 1.0502580862778883, Training Accuracy: 70.108\n",
            "Validation Loss: 1.824654181798299, Validation Accuracy: 53.91\n",
            "[128/150]: Training Loss: 1.045825692323538, Training Accuracy: 69.762\n",
            "Validation Loss: 1.828839858373006, Validation Accuracy: 54.18\n",
            "[129/150]: Training Loss: 1.041814657358023, Training Accuracy: 70.04\n",
            "Validation Loss: 1.8183866739273071, Validation Accuracy: 53.89\n",
            "[130/150]: Training Loss: 1.0349373588195214, Training Accuracy: 70.334\n",
            "Validation Loss: 1.817612926165263, Validation Accuracy: 54.08\n",
            "[131/150]: Training Loss: 1.0304582439936125, Training Accuracy: 70.738\n",
            "Validation Loss: 1.8261488676071167, Validation Accuracy: 54.44\n",
            "[132/150]: Training Loss: 1.0328317513832679, Training Accuracy: 70.262\n",
            "Validation Loss: 1.8170503377914429, Validation Accuracy: 54.11\n",
            "[133/150]: Training Loss: 1.0127528584920442, Training Accuracy: 71.006\n",
            "Validation Loss: 1.823221206665039, Validation Accuracy: 54.24\n",
            "[134/150]: Training Loss: 1.0145881175994873, Training Accuracy: 70.876\n",
            "Validation Loss: 1.8177992900212605, Validation Accuracy: 54.42\n",
            "[135/150]: Training Loss: 1.0154722057856047, Training Accuracy: 70.856\n",
            "Validation Loss: 1.8151982227961223, Validation Accuracy: 54.36\n",
            "[136/150]: Training Loss: 1.0053791770568261, Training Accuracy: 70.962\n",
            "Validation Loss: 1.815675139427185, Validation Accuracy: 54.52\n",
            "[137/150]: Training Loss: 1.0002271212064302, Training Accuracy: 71.094\n",
            "Validation Loss: 1.8183471361796062, Validation Accuracy: 54.62\n",
            "[138/150]: Training Loss: 1.003823459148407, Training Accuracy: 71.112\n",
            "Validation Loss: 1.8167388836542766, Validation Accuracy: 54.32\n",
            "[139/150]: Training Loss: 1.0023488723314726, Training Accuracy: 71.28\n",
            "Validation Loss: 1.8161654869715373, Validation Accuracy: 54.5\n",
            "[140/150]: Training Loss: 0.996692391542288, Training Accuracy: 71.326\n",
            "Validation Loss: 1.8168489535649617, Validation Accuracy: 54.36\n",
            "[141/150]: Training Loss: 0.9932475502674396, Training Accuracy: 71.382\n",
            "Validation Loss: 1.8148254950841267, Validation Accuracy: 54.41\n",
            "[142/150]: Training Loss: 0.9950209443385785, Training Accuracy: 71.754\n",
            "Validation Loss: 1.8171526590983074, Validation Accuracy: 54.22\n",
            "[143/150]: Training Loss: 0.9949191717001108, Training Accuracy: 71.676\n",
            "Validation Loss: 1.8166076342264812, Validation Accuracy: 54.39\n",
            "[144/150]: Training Loss: 0.9898046300961421, Training Accuracy: 71.61\n",
            "Validation Loss: 1.8168938557306926, Validation Accuracy: 54.34\n",
            "[145/150]: Training Loss: 0.9879593665783222, Training Accuracy: 71.72\n",
            "Validation Loss: 1.8167452017466228, Validation Accuracy: 54.36\n",
            "[146/150]: Training Loss: 0.9881623249787551, Training Accuracy: 71.81\n",
            "Validation Loss: 1.8165217638015747, Validation Accuracy: 54.38\n",
            "[147/150]: Training Loss: 0.9901151886353126, Training Accuracy: 71.69\n",
            "Validation Loss: 1.81660795211792, Validation Accuracy: 54.48\n",
            "[148/150]: Training Loss: 0.9835631480583777, Training Accuracy: 71.944\n",
            "Validation Loss: 1.8168546358744304, Validation Accuracy: 54.43\n",
            "[149/150]: Training Loss: 0.9820910050318792, Training Accuracy: 72.082\n",
            "Validation Loss: 1.8165034850438435, Validation Accuracy: 54.45\n",
            "[150/150]: Training Loss: 0.9884678217080923, Training Accuracy: 71.694\n",
            "Validation Loss: 1.8165420691172283, Validation Accuracy: 54.48\n",
            "**********************************************************************\n",
            "Test Loss: 1.8165420691172283, Test Accuracy: 54.48\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▂▁█</td></tr><tr><td>Test Loss</td><td>▇█▁</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▂▃▄▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇█████████</td></tr><tr><td>Train Loss</td><td>█▇▇▆▅▅▅▅▄▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>54.48</td></tr><tr><td>Test Loss</td><td>1.81654</td></tr><tr><td>Train Accuracy</td><td>71.694</td></tr><tr><td>Train Loss</td><td>0.98847</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=4096 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_024410-fcrci1zx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 8192, Learning rate: 16.970562748477143, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_030841-573n6uz6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">batch_size=8192 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.543815356034499, Training Accuracy: 1.934\n",
            "Validation Loss: 4.557299613952637, Validation Accuracy: 4.11\n",
            "[2/150]: Training Loss: 4.4831575613755446, Training Accuracy: 3.478\n",
            "Validation Loss: 4.407679557800293, Validation Accuracy: 3.73\n",
            "[3/150]: Training Loss: 4.383443318880522, Training Accuracy: 4.272\n",
            "Validation Loss: 4.315660317738851, Validation Accuracy: 4.56\n",
            "[4/150]: Training Loss: 4.753879473759578, Training Accuracy: 2.854\n",
            "Validation Loss: 4.617130438486735, Validation Accuracy: 1.55\n",
            "[5/150]: Training Loss: 4.834007776700533, Training Accuracy: 1.152\n",
            "Validation Loss: 4.623517354329427, Validation Accuracy: 1.21\n",
            "[6/150]: Training Loss: 4.748236729548528, Training Accuracy: 1.046\n",
            "Validation Loss: 4.616909344991048, Validation Accuracy: 1.0\n",
            "[7/150]: Training Loss: 4.6143631201524, Training Accuracy: 1.022\n",
            "Validation Loss: 4.6133114496866865, Validation Accuracy: 0.95\n",
            "[8/150]: Training Loss: 86586261001215.23, Training Accuracy: 1.076\n",
            "Validation Loss: 199153685277354.66, Validation Accuracy: 1.08\n",
            "[9/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[11/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[12/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[13/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[15/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[16/150]: Training Loss: inf, Training Accuracy: 1.004\n",
            "Validation Loss: inf, Validation Accuracy: 0.99\n",
            "[17/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[18/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[19/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[20/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[21/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[22/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[23/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[24/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[25/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[26/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[27/150]: Training Loss: inf, Training Accuracy: 0.998\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[28/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[29/150]: Training Loss: inf, Training Accuracy: 1.004\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[30/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[31/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[32/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[33/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3707833002946235e+34, Validation Accuracy: 1.04\n",
            "[34/150]: Training Loss: 7.178876870446214e+34, Training Accuracy: 1.03\n",
            "Validation Loss: 6.908918765509594e+34, Validation Accuracy: 1.04\n",
            "[35/150]: Training Loss: 7.0300555279696e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 6.850623178707614e+34, Validation Accuracy: 1.04\n",
            "[36/150]: Training Loss: 7.161850738321898e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 6.997600003222513e+34, Validation Accuracy: 1.04\n",
            "[37/150]: Training Loss: 7.295138713909261e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.183176128279674e+34, Validation Accuracy: 1.04\n",
            "[38/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.320277327395843e+34, Validation Accuracy: 1.04\n",
            "[39/150]: Training Loss: 7.652232993118385e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.385754947129741e+34, Validation Accuracy: 1.04\n",
            "[40/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.395794805907017e+34, Validation Accuracy: 1.04\n",
            "[41/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.389329127611166e+34, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: 7.64618030431646e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.36814170130946e+34, Validation Accuracy: 1.04\n",
            "[43/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.351131744934992e+34, Validation Accuracy: 1.04\n",
            "[44/150]: Training Loss: inf, Training Accuracy: 1.026\n",
            "Validation Loss: 7.339262375838323e+34, Validation Accuracy: 1.04\n",
            "[45/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.334463460011365e+34, Validation Accuracy: 1.04\n",
            "[46/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.33473861281743e+34, Validation Accuracy: 1.04\n",
            "[47/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.342335768309189e+34, Validation Accuracy: 1.04\n",
            "[48/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343183509648092e+34, Validation Accuracy: 1.04\n",
            "[49/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.353242350172637e+34, Validation Accuracy: 1.04\n",
            "[50/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.35132750451987e+34, Validation Accuracy: 1.04\n",
            "[51/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.338507727590375e+34, Validation Accuracy: 1.04\n",
            "[52/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.345233868470492e+34, Validation Accuracy: 1.04\n",
            "[53/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.35075210998961e+34, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.35572186154199e+34, Validation Accuracy: 1.04\n",
            "[55/150]: Training Loss: 7.620612957278016e+34, Training Accuracy: 1.026\n",
            "Validation Loss: 7.362447672304763e+34, Validation Accuracy: 1.04\n",
            "[56/150]: Training Loss: 7.605070410587243e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.363398575313606e+34, Validation Accuracy: 1.04\n",
            "[57/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3600082701926835e+34, Validation Accuracy: 1.04\n",
            "[58/150]: Training Loss: 7.453089464225746e+34, Training Accuracy: 1.02\n",
            "Validation Loss: 7.363201660318024e+34, Validation Accuracy: 1.04\n",
            "[59/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.36800305202506e+34, Validation Accuracy: 1.04\n",
            "[60/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.36741461785972e+34, Validation Accuracy: 1.04\n",
            "[61/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.367097540150991e+34, Validation Accuracy: 1.04\n",
            "[62/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.360266091838198e+34, Validation Accuracy: 1.04\n",
            "[63/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.357579927011621e+34, Validation Accuracy: 1.04\n",
            "[64/150]: Training Loss: inf, Training Accuracy: 1.002\n",
            "Validation Loss: 7.3600130568941685e+34, Validation Accuracy: 1.04\n",
            "[65/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.361191245694225e+34, Validation Accuracy: 1.04\n",
            "[66/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.358085336664993e+34, Validation Accuracy: 1.04\n",
            "[67/150]: Training Loss: 7.58769795997563e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343106922424328e+34, Validation Accuracy: 1.04\n",
            "[68/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.340167062419033e+34, Validation Accuracy: 1.04\n",
            "[69/150]: Training Loss: 7.539564832453689e+34, Training Accuracy: 1.01\n",
            "Validation Loss: 7.3399107263015645e+34, Validation Accuracy: 1.04\n",
            "[70/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.343239299479195e+34, Validation Accuracy: 1.04\n",
            "[71/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.344283460637665e+34, Validation Accuracy: 1.04\n",
            "[72/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3470638739659e+34, Validation Accuracy: 1.04\n",
            "[73/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.337876213111667e+34, Validation Accuracy: 1.04\n",
            "[74/150]: Training Loss: 7.520041527682127e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.339984672586578e+34, Validation Accuracy: 1.04\n",
            "[75/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.341706399593216e+34, Validation Accuracy: 1.04\n",
            "[76/150]: Training Loss: 7.50774223153243e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.344978357646383e+34, Validation Accuracy: 1.04\n",
            "[77/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.34611412636776e+34, Validation Accuracy: 1.04\n",
            "[78/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.34531260145699e+34, Validation Accuracy: 1.04\n",
            "[79/150]: Training Loss: 7.570326728258824e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.35118538900336e+34, Validation Accuracy: 1.04\n",
            "[80/150]: Training Loss: 7.392040813047783e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.351906530340912e+34, Validation Accuracy: 1.04\n",
            "[81/150]: Training Loss: 7.55008671334021e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.357009484241519e+34, Validation Accuracy: 1.04\n",
            "[82/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.355688354631593e+34, Validation Accuracy: 1.04\n",
            "[83/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.351709120169314e+34, Validation Accuracy: 1.04\n",
            "[84/150]: Training Loss: 7.518704819072938e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.352724726177544e+34, Validation Accuracy: 1.04\n",
            "[85/150]: Training Loss: 7.480363492538042e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.353025628136426e+34, Validation Accuracy: 1.04\n",
            "[86/150]: Training Loss: 7.609761708160119e+34, Training Accuracy: 1.02\n",
            "Validation Loss: 7.355622331162831e+34, Validation Accuracy: 1.04\n",
            "[87/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.351417956672074e+34, Validation Accuracy: 1.04\n",
            "[88/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.3432506885275565e+34, Validation Accuracy: 1.04\n",
            "[89/150]: Training Loss: 7.571858879032369e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.342947970923284e+34, Validation Accuracy: 1.04\n",
            "[90/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.341380243657533e+34, Validation Accuracy: 1.04\n",
            "[91/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3435405315554215e+34, Validation Accuracy: 1.04\n",
            "[92/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.347343978532122e+34, Validation Accuracy: 1.04\n",
            "[93/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.349835869301868e+34, Validation Accuracy: 1.04\n",
            "[94/150]: Training Loss: 7.553363102583877e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.350179851574117e+34, Validation Accuracy: 1.04\n",
            "[95/150]: Training Loss: 7.518843468357338e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.349381297719442e+34, Validation Accuracy: 1.04\n",
            "[96/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.350629966572401e+34, Validation Accuracy: 1.04\n",
            "[97/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.350986328245043e+34, Validation Accuracy: 1.04\n",
            "[98/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.349232414797383e+34, Validation Accuracy: 1.04\n",
            "[99/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3498634341000755e+34, Validation Accuracy: 1.04\n",
            "[100/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.346068900291658e+34, Validation Accuracy: 1.04\n",
            "[101/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343747350071318e+34, Validation Accuracy: 1.04\n",
            "[102/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.343838462458209e+34, Validation Accuracy: 1.04\n",
            "[103/150]: Training Loss: 7.587162712793105e+34, Training Accuracy: 1.036\n",
            "Validation Loss: 7.34444604342949e+34, Validation Accuracy: 1.04\n",
            "[104/150]: Training Loss: 7.563224723389138e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.3440896817568485e+34, Validation Accuracy: 1.04\n",
            "[105/150]: Training Loss: 7.502001541710868e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.343770788402729e+34, Validation Accuracy: 1.04\n",
            "[106/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.344186901314601e+34, Validation Accuracy: 1.04\n",
            "[107/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.347785180362123e+34, Validation Accuracy: 1.04\n",
            "[108/150]: Training Loss: 7.541743759284682e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.349218714927616e+34, Validation Accuracy: 1.04\n",
            "[109/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.350196357441308e+34, Validation Accuracy: 1.04\n",
            "[110/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.35085609695291e+34, Validation Accuracy: 1.04\n",
            "[111/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.3504860354105e+34, Validation Accuracy: 1.04\n",
            "[112/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: 7.350065630973159e+34, Validation Accuracy: 1.04\n",
            "[113/150]: Training Loss: 7.572177010577234e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.34878494073785e+34, Validation Accuracy: 1.04\n",
            "[114/150]: Training Loss: 7.602740036076367e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.345721781904642e+34, Validation Accuracy: 1.04\n",
            "[115/150]: Training Loss: 7.637903627666111e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.342419287997172e+34, Validation Accuracy: 1.04\n",
            "[116/150]: Training Loss: 7.578869428701e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.340205025913571e+34, Validation Accuracy: 1.04\n",
            "[117/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.33890419852029e+34, Validation Accuracy: 1.04\n",
            "[118/150]: Training Loss: 7.53878203535377e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3400515213487e+34, Validation Accuracy: 1.04\n",
            "[119/150]: Training Loss: 7.55180291722975e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.341673717976179e+34, Validation Accuracy: 1.04\n",
            "[120/150]: Training Loss: 7.52984426063198e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.341424314322931e+34, Validation Accuracy: 1.04\n",
            "[121/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.342221382649559e+34, Validation Accuracy: 1.04\n",
            "[122/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.341639550831095e+34, Validation Accuracy: 1.04\n",
            "[123/150]: Training Loss: 7.564221817432473e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.34171366217478e+34, Validation Accuracy: 1.04\n",
            "[124/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.341365883553077e+34, Validation Accuracy: 1.04\n",
            "[125/150]: Training Loss: 7.467476193914916e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.341843068173553e+34, Validation Accuracy: 1.04\n",
            "[126/150]: Training Loss: 7.557965611288089e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.34209494770688e+34, Validation Accuracy: 1.04\n",
            "[127/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.342893501561555e+34, Validation Accuracy: 1.04\n",
            "[128/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: 7.343795217086171e+34, Validation Accuracy: 1.04\n",
            "[129/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3440480869715285e+34, Validation Accuracy: 1.04\n",
            "[130/150]: Training Loss: inf, Training Accuracy: 1.026\n",
            "Validation Loss: 7.343806276017188e+34, Validation Accuracy: 1.04\n",
            "[131/150]: Training Loss: 7.511219776509865e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.343705425168654e+34, Validation Accuracy: 1.04\n",
            "[132/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343869988664544e+34, Validation Accuracy: 1.04\n",
            "[133/150]: Training Loss: 7.572846983726496e+34, Training Accuracy: 1.004\n",
            "Validation Loss: 7.34368512295201e+34, Validation Accuracy: 1.04\n",
            "[134/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3437027842299035e+34, Validation Accuracy: 1.04\n",
            "[135/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: 7.34337316206211e+34, Validation Accuracy: 1.04\n",
            "[136/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343067143284399e+34, Validation Accuracy: 1.04\n",
            "[137/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.343213385267707e+34, Validation Accuracy: 1.04\n",
            "[138/150]: Training Loss: 7.591718865404154e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343415086964774e+34, Validation Accuracy: 1.04\n",
            "[139/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.343418718255556e+34, Validation Accuracy: 1.04\n",
            "[140/150]: Training Loss: 7.5901811534230485e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343325625164602e+34, Validation Accuracy: 1.04\n",
            "[141/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343275777445687e+34, Validation Accuracy: 1.04\n",
            "[142/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: 7.3432812243818595e+34, Validation Accuracy: 1.04\n",
            "[143/150]: Training Loss: 7.521443789977704e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.343387192049222e+34, Validation Accuracy: 1.04\n",
            "[144/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343500752415492e+34, Validation Accuracy: 1.04\n",
            "[145/150]: Training Loss: 7.489635587251364e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.343563144593472e+34, Validation Accuracy: 1.04\n",
            "[146/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343603253850745e+34, Validation Accuracy: 1.04\n",
            "[147/150]: Training Loss: 7.537443193678667e+34, Training Accuracy: 1.026\n",
            "Validation Loss: 7.343630983707625e+34, Validation Accuracy: 1.04\n",
            "[148/150]: Training Loss: 7.421953062990879e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.343639566758564e+34, Validation Accuracy: 1.04\n",
            "[149/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343644683577394e+34, Validation Accuracy: 1.04\n",
            "[150/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.343644848636065e+34, Validation Accuracy: 1.04\n",
            "**********************************************************************\n",
            "Test Loss: 7.343644848636065e+34, Test Accuracy: 1.04\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▁██</td></tr><tr><td>Test Loss</td><td>█▅▁</td></tr><tr><td>Train Accuracy</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▁▁▁      █ █   █   ████    ██ ██ █  █   </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.04</td></tr><tr><td>Test Loss</td><td>7.343644848636065e+34</td></tr><tr><td>Train Accuracy</td><td>1.01</td></tr><tr><td>Train Loss</td><td>inf</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=8192 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_030841-573n6uz6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 16384, Learning rate: 24.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_033254-cneyt8y0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">batch_size=16384 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.5802256144010105, Training Accuracy: 1.524\n",
            "Validation Loss: 4.505903720855713, Validation Accuracy: 3.24\n",
            "[2/150]: Training Loss: 4.487952305720403, Training Accuracy: 2.782\n",
            "Validation Loss: 4.534458001454671, Validation Accuracy: 1.82\n",
            "[3/150]: Training Loss: 4.498784615443303, Training Accuracy: 2.232\n",
            "Validation Loss: 4.477282365163167, Validation Accuracy: 2.08\n",
            "[4/150]: Training Loss: 4.4941191306481, Training Accuracy: 2.178\n",
            "Validation Loss: 4.612959861755371, Validation Accuracy: 1.29\n",
            "[5/150]: Training Loss: 4.5912819642287035, Training Accuracy: 1.504\n",
            "Validation Loss: 5.598563989003499, Validation Accuracy: 2.19\n",
            "[6/150]: Training Loss: 5.028410141284649, Training Accuracy: 1.632\n",
            "Validation Loss: 7.806542873382568, Validation Accuracy: 1.07\n",
            "[7/150]: Training Loss: 14089.29747926272, Training Accuracy: 1.044\n",
            "Validation Loss: 7.282219409942627, Validation Accuracy: 0.93\n",
            "[8/150]: Training Loss: 461533512.8043683, Training Accuracy: 0.978\n",
            "Validation Loss: 145186464.0, Validation Accuracy: 0.98\n",
            "[9/150]: Training Loss: 1.1580541048823784e+29, Training Accuracy: 0.952\n",
            "Validation Loss: 2.748474842936338e+29, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: 2.8978003478935013e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484746540416787e+29, Validation Accuracy: 1.0\n",
            "[11/150]: Training Loss: 2.828666588105865e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748474402182133e+29, Validation Accuracy: 1.0\n",
            "[12/150]: Training Loss: 2.8943495766660634e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484738354981552e+29, Validation Accuracy: 1.0\n",
            "[13/150]: Training Loss: 2.848512485818888e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748472828059972e+29, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: 2.8171856724252214e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748468672377467e+29, Validation Accuracy: 1.0\n",
            "[15/150]: Training Loss: 2.9237725789099303e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484595424689335e+29, Validation Accuracy: 1.0\n",
            "[16/150]: Training Loss: 2.8024521069540443e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748430578621172e+29, Validation Accuracy: 1.0\n",
            "[17/150]: Training Loss: 2.818569224092193e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7483436870778873e+29, Validation Accuracy: 1.0\n",
            "[18/150]: Training Loss: 2.8163175416317275e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7480828865182598e+29, Validation Accuracy: 1.0\n",
            "[19/150]: Training Loss: 2.818046581630586e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7474053213752977e+29, Validation Accuracy: 1.0\n",
            "[20/150]: Training Loss: 2.8566013910414994e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7454263979594298e+29, Validation Accuracy: 1.0\n",
            "[21/150]: Training Loss: 2.8411686828451232e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7395975495271803e+29, Validation Accuracy: 1.0\n",
            "[22/150]: Training Loss: 2.8607326044228643e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.722675988156443e+29, Validation Accuracy: 1.0\n",
            "[23/150]: Training Loss: 2.7987878847615806e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.6741031117411477e+29, Validation Accuracy: 1.0\n",
            "[24/150]: Training Loss: 2.723279453314973e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.535316349808136e+29, Validation Accuracy: 1.0\n",
            "[25/150]: Training Loss: 2.573586814635347e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.1297902431238725e+29, Validation Accuracy: 1.0\n",
            "[26/150]: Training Loss: 2.051805262233517e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 1.0476803956799425e+29, Validation Accuracy: 1.0\n",
            "[27/150]: Training Loss: 8.450376531000046e+28, Training Accuracy: 1.0\n",
            "Validation Loss: 9.264404581011073e+18, Validation Accuracy: 1.0\n",
            "[28/150]: Training Loss: nan, Training Accuracy: 1.044\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[29/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[30/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[31/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[32/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[33/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[34/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[35/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[36/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[37/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[38/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[39/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[40/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[41/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[43/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[44/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[45/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[46/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[47/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[48/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[49/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[50/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[51/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[52/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[53/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[55/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[56/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[57/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[58/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[59/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[60/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[61/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[62/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[63/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[64/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[65/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[66/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[67/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[68/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[69/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[70/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[71/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[72/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[73/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[74/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[75/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[76/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[77/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[78/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[79/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[80/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[81/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[82/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[83/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[84/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[85/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[86/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[87/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[88/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[89/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[90/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[91/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[92/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[93/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[94/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[95/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[96/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[97/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[98/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[99/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[100/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[101/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[102/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[103/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[104/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[105/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[106/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[107/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[108/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[109/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[110/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[111/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[112/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[113/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[114/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[115/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[116/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[117/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[118/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[119/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[120/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[121/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[122/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[123/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[124/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[125/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[126/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[127/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[128/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[129/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[130/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[131/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[132/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[133/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[134/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[135/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[136/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[137/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[138/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[139/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[140/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[141/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[142/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[143/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[144/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[145/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[146/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[147/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[148/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[149/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[150/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "**********************************************************************\n",
            "Test Loss: nan, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▃▁</td></tr><tr><td>Train Accuracy</td><td>█▆▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▁▁▁████                                 </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>nan</td></tr><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Train Loss</td><td>nan</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=16384 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_033254-cneyt8y0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 32768, Learning rate: 33.941125496954285, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_035739-zqj7yms0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">batch_size=32768 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.600700745215783, Training Accuracy: 1.18\n",
            "Validation Loss: 4.5345486005147295, Validation Accuracy: 2.25\n",
            "[2/150]: Training Loss: 4.525542259216309, Training Accuracy: 2.194\n",
            "Validation Loss: 4.480770270029704, Validation Accuracy: 3.63\n",
            "[3/150]: Training Loss: 4.467245468726525, Training Accuracy: 3.348\n",
            "Validation Loss: 4.682004292805989, Validation Accuracy: 2.02\n",
            "[4/150]: Training Loss: 4.584587500645564, Training Accuracy: 2.316\n",
            "Validation Loss: 4.589324951171875, Validation Accuracy: 1.07\n",
            "[5/150]: Training Loss: 4.593533919407771, Training Accuracy: 1.128\n",
            "Validation Loss: 4.565906047821045, Validation Accuracy: 2.24\n",
            "[6/150]: Training Loss: 4.610266098609338, Training Accuracy: 1.65\n",
            "Validation Loss: 5.121236960093181, Validation Accuracy: 1.01\n",
            "[7/150]: Training Loss: 5.261244590465839, Training Accuracy: 1.226\n",
            "Validation Loss: 7.05544392267863, Validation Accuracy: 1.19\n",
            "[8/150]: Training Loss: 6.352289456587571, Training Accuracy: 1.176\n",
            "Validation Loss: 22.820095698038738, Validation Accuracy: 0.83\n",
            "[9/150]: Training Loss: 33.29087433448205, Training Accuracy: 0.906\n",
            "Validation Loss: 54.22376505533854, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: 35.99252113929162, Training Accuracy: 0.988\n",
            "Validation Loss: 69.11057027180989, Validation Accuracy: 0.95\n",
            "[11/150]: Training Loss: 76.55324378380409, Training Accuracy: 1.196\n",
            "Validation Loss: 7.983708381652832, Validation Accuracy: 1.06\n",
            "[12/150]: Training Loss: 58.39160236945519, Training Accuracy: 1.032\n",
            "Validation Loss: 164.86418660481772, Validation Accuracy: 0.92\n",
            "[13/150]: Training Loss: 131.58557803814227, Training Accuracy: 0.95\n",
            "Validation Loss: 281.80524190266925, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: 178.63248865421002, Training Accuracy: 0.962\n",
            "Validation Loss: 7817948401325397.0, Validation Accuracy: 1.39\n",
            "[15/150]: Training Loss: 4967409836682319.0, Training Accuracy: 1.34\n",
            "Validation Loss: 2.8247563537114726e+17, Validation Accuracy: 1.0\n",
            "[16/150]: Training Loss: 1.7259852552660077e+17, Training Accuracy: 0.982\n",
            "Validation Loss: 7061819945735509.0, Validation Accuracy: 0.96\n",
            "[17/150]: Training Loss: 7.113184439761936e+16, Training Accuracy: 0.924\n",
            "Validation Loss: 64496.6328125, Validation Accuracy: 1.0\n",
            "[18/150]: Training Loss: nan, Training Accuracy: 1.014\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[19/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[20/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[21/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[22/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[23/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[24/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[25/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[26/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[27/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[28/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[29/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[30/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[31/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[32/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[33/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[34/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[35/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[36/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[37/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[38/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[39/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[40/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[41/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[43/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[44/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[45/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[46/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[47/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[48/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[49/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[50/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[51/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[52/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[53/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[55/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[56/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[57/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[58/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[59/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[60/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[61/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[62/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[63/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[64/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[65/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[66/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[67/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[68/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[69/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[70/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[71/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[72/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[73/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[74/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[75/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[76/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[77/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[78/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[79/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[80/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[81/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[82/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[83/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[84/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[85/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[86/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[87/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[88/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[89/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[90/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[91/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[92/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[93/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[94/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[95/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[96/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[97/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[98/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[99/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[100/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[101/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[102/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[103/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[104/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[105/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[106/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[107/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[108/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[109/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[110/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[111/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[112/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[113/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[114/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[115/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[116/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[117/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[118/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[119/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[120/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[121/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[122/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[123/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[124/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[125/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[126/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[127/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[128/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[129/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[130/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[131/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[132/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[133/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[134/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[135/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[136/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[137/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[138/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[139/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[140/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[141/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[142/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[143/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[144/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[145/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[146/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[147/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[148/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[149/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[150/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "**********************************************************************\n",
            "Test Loss: nan, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▃▁</td></tr><tr><td>Train Accuracy</td><td>▇█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Train Loss</td><td>▁▁▁▁█                                   </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>nan</td></tr><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Train Loss</td><td>nan</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=32768 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_035739-zqj7yms0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# check the lr updates from paper 18\n",
        "\n",
        "num_epochs = 150\n",
        "lr = 1.5\n",
        "wd = 1e-03\n",
        "batch_sizes = [512, 1024, 2048, 4096, 8192, 16384 , 32768]\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "  # Root square scale-up of learning rate\n",
        "  k = (batch_size / 64.0) ** 0.5\n",
        "  print('='*50)\n",
        "  print(f'Batch size: {batch_size}, Learning rate: {lr*k}, Weight decay: {wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': lr*k,\n",
        "    'weight_decay' : wd\n",
        "  }\n",
        "  if batch_size <= 4096:\n",
        "  \n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= batch_size)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LARS(model.parameters(), lr= lr*k, weight_decay=wd, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LARS_Large_Batches',\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )\n",
        "  else:\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= 4096)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LARS(model.parameters(), lr= lr*k, weight_decay=wd, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    accumulation_steps = batch_size // 4096\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LARS_Large_Batches',\n",
        "        accumulation_steps=accumulation_steps,\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ftxikW3Lr2ya"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.0009 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_045009-kw5xm0f9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">learning_rate=0.0009 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.366185345458985, Training Accuracy: 3.775\n",
            "Validation Loss: 4.140061999582182, Validation Accuracy: 6.19\n",
            "[2/150]: Training Loss: 3.9872212955474855, Training Accuracy: 9.2825\n",
            "Validation Loss: 3.9175391182018693, Validation Accuracy: 10.13\n",
            "[3/150]: Training Loss: 3.7751855819702147, Training Accuracy: 12.73\n",
            "Validation Loss: 3.754828929901123, Validation Accuracy: 13.44\n",
            "[4/150]: Training Loss: 3.6031822479248046, Training Accuracy: 15.7675\n",
            "Validation Loss: 3.5609892857302525, Validation Accuracy: 16.33\n",
            "[5/150]: Training Loss: 3.4478089206695555, Training Accuracy: 18.66\n",
            "Validation Loss: 3.4119288389849816, Validation Accuracy: 19.45\n",
            "[6/150]: Training Loss: 3.3203197284698485, Training Accuracy: 20.7075\n",
            "Validation Loss: 3.349654642639646, Validation Accuracy: 20.47\n",
            "[7/150]: Training Loss: 3.20732957611084, Training Accuracy: 22.7475\n",
            "Validation Loss: 3.2386614349996967, Validation Accuracy: 22.79\n",
            "[8/150]: Training Loss: 3.115479539489746, Training Accuracy: 24.5875\n",
            "Validation Loss: 3.1584747019846726, Validation Accuracy: 24.53\n",
            "[9/150]: Training Loss: 3.0234272315979003, Training Accuracy: 26.28\n",
            "Validation Loss: 3.0975672788680737, Validation Accuracy: 24.97\n",
            "[10/150]: Training Loss: 2.9408509815216064, Training Accuracy: 27.665\n",
            "Validation Loss: 3.0618672537955507, Validation Accuracy: 25.33\n",
            "[11/150]: Training Loss: 2.862503829956055, Training Accuracy: 29.3325\n",
            "Validation Loss: 2.9638838965422027, Validation Accuracy: 27.41\n",
            "[12/150]: Training Loss: 2.790407749938965, Training Accuracy: 30.48\n",
            "Validation Loss: 2.937404105617742, Validation Accuracy: 28.32\n",
            "[13/150]: Training Loss: 2.724927402114868, Training Accuracy: 31.9425\n",
            "Validation Loss: 2.9041963838467932, Validation Accuracy: 28.5\n",
            "[14/150]: Training Loss: 2.659171875, Training Accuracy: 33.2275\n",
            "Validation Loss: 2.8527053769227044, Validation Accuracy: 29.6\n",
            "[15/150]: Training Loss: 2.604087335395813, Training Accuracy: 34.1075\n",
            "Validation Loss: 2.8513991179739593, Validation Accuracy: 30.15\n",
            "[16/150]: Training Loss: 2.5427039728164673, Training Accuracy: 35.57\n",
            "Validation Loss: 2.8172519510718668, Validation Accuracy: 30.73\n",
            "[17/150]: Training Loss: 2.4821195234298705, Training Accuracy: 36.73\n",
            "Validation Loss: 2.826693563704278, Validation Accuracy: 31.28\n",
            "[18/150]: Training Loss: 2.4249122804641723, Training Accuracy: 37.97\n",
            "Validation Loss: 2.78142261353268, Validation Accuracy: 32.01\n",
            "[19/150]: Training Loss: 2.366035011482239, Training Accuracy: 39.02\n",
            "Validation Loss: 2.7907780021618884, Validation Accuracy: 31.84\n",
            "[20/150]: Training Loss: 2.3027314464569093, Training Accuracy: 40.4925\n",
            "Validation Loss: 2.740103484718663, Validation Accuracy: 32.92\n",
            "[21/150]: Training Loss: 2.24520486240387, Training Accuracy: 41.56\n",
            "Validation Loss: 2.720843028111063, Validation Accuracy: 33.71\n",
            "[22/150]: Training Loss: 2.194983146095276, Training Accuracy: 42.9375\n",
            "Validation Loss: 2.7611854592705987, Validation Accuracy: 32.67\n",
            "[23/150]: Training Loss: 2.138135533905029, Training Accuracy: 44.1975\n",
            "Validation Loss: 2.7068749218230037, Validation Accuracy: 33.35\n",
            "[24/150]: Training Loss: 2.078735979270935, Training Accuracy: 45.3275\n",
            "Validation Loss: 2.6949741673317686, Validation Accuracy: 34.58\n",
            "[25/150]: Training Loss: 2.0237128454208375, Training Accuracy: 46.48\n",
            "Validation Loss: 2.700145792809262, Validation Accuracy: 33.95\n",
            "[26/150]: Training Loss: 1.9667144546508788, Training Accuracy: 47.8375\n",
            "Validation Loss: 2.749180986623096, Validation Accuracy: 34.02\n",
            "[27/150]: Training Loss: 1.9086554452896118, Training Accuracy: 49.35\n",
            "Validation Loss: 2.719582610828861, Validation Accuracy: 34.45\n",
            "[28/150]: Training Loss: 1.845149391746521, Training Accuracy: 50.64\n",
            "Validation Loss: 2.735584658422288, Validation Accuracy: 34.52\n",
            "[29/150]: Training Loss: 1.7947315074920653, Training Accuracy: 51.665\n",
            "Validation Loss: 2.7848551835224127, Validation Accuracy: 33.98\n",
            "[30/150]: Training Loss: 1.7361212677001954, Training Accuracy: 53.24\n",
            "Validation Loss: 2.7989868426778513, Validation Accuracy: 34.65\n",
            "[31/150]: Training Loss: 1.675447853088379, Training Accuracy: 54.63\n",
            "Validation Loss: 2.805454480420252, Validation Accuracy: 35.16\n",
            "[32/150]: Training Loss: 1.6181456073760987, Training Accuracy: 55.7275\n",
            "Validation Loss: 2.825571666097945, Validation Accuracy: 35.24\n",
            "[33/150]: Training Loss: 1.5572484771728516, Training Accuracy: 57.33\n",
            "Validation Loss: 2.895953078178843, Validation Accuracy: 34.87\n",
            "[34/150]: Training Loss: 1.493730352783203, Training Accuracy: 58.9\n",
            "Validation Loss: 2.8819164500874317, Validation Accuracy: 34.54\n",
            "[35/150]: Training Loss: 1.4407835181236268, Training Accuracy: 60.1325\n",
            "Validation Loss: 2.9298907556351583, Validation Accuracy: 35.13\n",
            "[36/150]: Training Loss: 1.378046295261383, Training Accuracy: 61.6725\n",
            "Validation Loss: 2.9877944615236514, Validation Accuracy: 34.88\n",
            "[37/150]: Training Loss: 1.3214307213783265, Training Accuracy: 63.3825\n",
            "Validation Loss: 3.01296287281498, Validation Accuracy: 34.97\n",
            "[38/150]: Training Loss: 1.2566315541267394, Training Accuracy: 64.46\n",
            "Validation Loss: 3.1075331208052908, Validation Accuracy: 34.96\n",
            "[39/150]: Training Loss: 1.2033088095664979, Training Accuracy: 66.1\n",
            "Validation Loss: 3.1721465040923684, Validation Accuracy: 34.01\n",
            "[40/150]: Training Loss: 1.1419879460334779, Training Accuracy: 67.7475\n",
            "Validation Loss: 3.260179937265481, Validation Accuracy: 34.51\n",
            "[41/150]: Training Loss: 1.0848600325584412, Training Accuracy: 69.2325\n",
            "Validation Loss: 3.281414782165722, Validation Accuracy: 34.07\n",
            "[42/150]: Training Loss: 1.0264957049369812, Training Accuracy: 70.73\n",
            "Validation Loss: 3.4151626255861514, Validation Accuracy: 34.15\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.67243060336751, Test Accuracy: 14.49\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▃█▁▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▂▃▃▃▃▃▃▃▂▃▃</td></tr><tr><td>Test Loss</td><td>▆▁▂▂▄▄▆█▇▇▆▇█▇▇▇▆▇▇▇▇▇▆▆▆▆▆▆▆▇▇▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>14.49</td></tr><tr><td>Test Loss</td><td>17.67243</td></tr><tr><td>Train Accuracy</td><td>70.73</td></tr><tr><td>Train Loss</td><td>1.0265</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0009 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_045009-kw5xm0f9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.00095 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_045608-cwudz2wj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">learning_rate=0.00095 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.36243955039978, Training Accuracy: 3.8475\n",
            "Validation Loss: 4.152171432592307, Validation Accuracy: 6.23\n",
            "[2/150]: Training Loss: 3.988539717102051, Training Accuracy: 9.035\n",
            "Validation Loss: 3.8899211443153914, Validation Accuracy: 10.42\n",
            "[3/150]: Training Loss: 3.784552033996582, Training Accuracy: 12.44\n",
            "Validation Loss: 3.716481655266634, Validation Accuracy: 13.63\n",
            "[4/150]: Training Loss: 3.6115343948364256, Training Accuracy: 15.38\n",
            "Validation Loss: 3.575136796684022, Validation Accuracy: 15.25\n",
            "[5/150]: Training Loss: 3.464410584640503, Training Accuracy: 18.1625\n",
            "Validation Loss: 3.448981456695848, Validation Accuracy: 17.92\n",
            "[6/150]: Training Loss: 3.340861389923096, Training Accuracy: 20.2875\n",
            "Validation Loss: 3.3443257702384024, Validation Accuracy: 19.79\n",
            "[7/150]: Training Loss: 3.240240854263306, Training Accuracy: 22.0975\n",
            "Validation Loss: 3.2861741910314866, Validation Accuracy: 21.07\n",
            "[8/150]: Training Loss: 3.1493673683166503, Training Accuracy: 23.8725\n",
            "Validation Loss: 3.1970221844448408, Validation Accuracy: 22.88\n",
            "[9/150]: Training Loss: 3.058048994064331, Training Accuracy: 25.4\n",
            "Validation Loss: 3.149918096080707, Validation Accuracy: 23.89\n",
            "[10/150]: Training Loss: 2.980970076370239, Training Accuracy: 26.93\n",
            "Validation Loss: 3.05195216008812, Validation Accuracy: 25.52\n",
            "[11/150]: Training Loss: 2.8978964962005613, Training Accuracy: 28.4275\n",
            "Validation Loss: 3.035321120243923, Validation Accuracy: 26.01\n",
            "[12/150]: Training Loss: 2.828321962738037, Training Accuracy: 29.7825\n",
            "Validation Loss: 3.033455335410537, Validation Accuracy: 26.14\n",
            "[13/150]: Training Loss: 2.764588646316528, Training Accuracy: 31.0525\n",
            "Validation Loss: 2.9178414527018357, Validation Accuracy: 28.5\n",
            "[14/150]: Training Loss: 2.6963481563568115, Training Accuracy: 32.6275\n",
            "Validation Loss: 2.8597835826266342, Validation Accuracy: 29.48\n",
            "[15/150]: Training Loss: 2.6279782932281495, Training Accuracy: 33.5125\n",
            "Validation Loss: 2.820923639710542, Validation Accuracy: 30.76\n",
            "[16/150]: Training Loss: 2.567752400970459, Training Accuracy: 35.0025\n",
            "Validation Loss: 2.8166574232137886, Validation Accuracy: 30.67\n",
            "[17/150]: Training Loss: 2.5122242719650267, Training Accuracy: 36.11\n",
            "Validation Loss: 2.77275866611748, Validation Accuracy: 31.51\n",
            "[18/150]: Training Loss: 2.448093600654602, Training Accuracy: 37.37\n",
            "Validation Loss: 2.7573567454222663, Validation Accuracy: 31.87\n",
            "[19/150]: Training Loss: 2.390553472328186, Training Accuracy: 38.6925\n",
            "Validation Loss: 2.779167422823086, Validation Accuracy: 31.58\n",
            "[20/150]: Training Loss: 2.329650112724304, Training Accuracy: 39.8\n",
            "Validation Loss: 2.7296412940237933, Validation Accuracy: 32.77\n",
            "[21/150]: Training Loss: 2.2680850820541383, Training Accuracy: 41.2075\n",
            "Validation Loss: 2.7711537537301423, Validation Accuracy: 32.31\n",
            "[22/150]: Training Loss: 2.205855764579773, Training Accuracy: 42.4775\n",
            "Validation Loss: 2.710599136959975, Validation Accuracy: 33.08\n",
            "[23/150]: Training Loss: 2.153862490653992, Training Accuracy: 43.845\n",
            "Validation Loss: 2.6846724543601845, Validation Accuracy: 34.22\n",
            "[24/150]: Training Loss: 2.0879069725036623, Training Accuracy: 45.07\n",
            "Validation Loss: 2.6652191763470885, Validation Accuracy: 34.62\n",
            "[25/150]: Training Loss: 2.027932558250427, Training Accuracy: 46.0825\n",
            "Validation Loss: 2.7143203483265674, Validation Accuracy: 34.04\n",
            "[26/150]: Training Loss: 1.9607762811660767, Training Accuracy: 47.975\n",
            "Validation Loss: 2.6897484147624606, Validation Accuracy: 34.96\n",
            "[27/150]: Training Loss: 1.9115407361984253, Training Accuracy: 48.8575\n",
            "Validation Loss: 2.7138490722437574, Validation Accuracy: 34.41\n",
            "[28/150]: Training Loss: 1.8502281684875488, Training Accuracy: 50.4525\n",
            "Validation Loss: 2.699836605673383, Validation Accuracy: 35.02\n",
            "[29/150]: Training Loss: 1.790220089149475, Training Accuracy: 51.585\n",
            "Validation Loss: 2.7410409693505353, Validation Accuracy: 34.77\n",
            "[30/150]: Training Loss: 1.7332203540802003, Training Accuracy: 53.0625\n",
            "Validation Loss: 2.6978999216845083, Validation Accuracy: 35.51\n",
            "[31/150]: Training Loss: 1.6659312999725342, Training Accuracy: 54.48\n",
            "Validation Loss: 2.7799882926758688, Validation Accuracy: 35.39\n",
            "[32/150]: Training Loss: 1.6054936313629151, Training Accuracy: 55.9275\n",
            "Validation Loss: 2.783534232218554, Validation Accuracy: 35.38\n",
            "[33/150]: Training Loss: 1.5524930331230165, Training Accuracy: 57.2425\n",
            "Validation Loss: 2.7876193948612094, Validation Accuracy: 35.43\n",
            "[34/150]: Training Loss: 1.4864114666938781, Training Accuracy: 58.62\n",
            "Validation Loss: 2.8515792378954066, Validation Accuracy: 34.97\n",
            "[35/150]: Training Loss: 1.4250763600349425, Training Accuracy: 60.31\n",
            "Validation Loss: 2.89135210453325, Validation Accuracy: 34.83\n",
            "[36/150]: Training Loss: 1.3677435276031493, Training Accuracy: 61.51\n",
            "Validation Loss: 2.919705820691054, Validation Accuracy: 36.01\n",
            "[37/150]: Training Loss: 1.3075296778678893, Training Accuracy: 63.435\n",
            "Validation Loss: 3.000214212259669, Validation Accuracy: 35.23\n",
            "[38/150]: Training Loss: 1.2455093726158142, Training Accuracy: 64.7925\n",
            "Validation Loss: 3.0685715766469386, Validation Accuracy: 34.47\n",
            "[39/150]: Training Loss: 1.1875538174629212, Training Accuracy: 66.195\n",
            "Validation Loss: 3.0860758040361342, Validation Accuracy: 35.17\n",
            "[40/150]: Training Loss: 1.1235356809616088, Training Accuracy: 67.92\n",
            "Validation Loss: 3.142808488979461, Validation Accuracy: 35.12\n",
            "[41/150]: Training Loss: 1.0638824738502501, Training Accuracy: 69.31\n",
            "Validation Loss: 3.2775286580346954, Validation Accuracy: 35.6\n",
            "[42/150]: Training Loss: 1.0043726112365723, Training Accuracy: 71.1\n",
            "Validation Loss: 3.332795017084498, Validation Accuracy: 34.53\n",
            "[43/150]: Training Loss: 0.9537097842216492, Training Accuracy: 72.4\n",
            "Validation Loss: 3.416984627960594, Validation Accuracy: 34.84\n",
            "[44/150]: Training Loss: 0.8938642192840576, Training Accuracy: 74.145\n",
            "Validation Loss: 3.5402958104564886, Validation Accuracy: 34.94\n",
            "[45/150]: Training Loss: 0.8376890470981598, Training Accuracy: 75.4875\n",
            "Validation Loss: 3.6570517561238285, Validation Accuracy: 34.43\n",
            "[46/150]: Training Loss: 0.7843643071174622, Training Accuracy: 76.875\n",
            "Validation Loss: 3.745219696858886, Validation Accuracy: 34.67\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 24.405659256467395, Test Accuracy: 13.44\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██▁▂▂▁▁▁▂▃▃▄▃▃▃▄▄▄▅▅▄▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>Test Loss</td><td>▄▁▄▇▆▇█▇▄▂▂▂▄▃▄▃▃▄▃▃▃▂▂▁▂▂▂▃▃▃▃▂▃▃▂▂▂▂▂▂</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>Train Loss</td><td>█▇▇▇▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.44</td></tr><tr><td>Test Loss</td><td>24.40566</td></tr><tr><td>Train Accuracy</td><td>76.875</td></tr><tr><td>Train Loss</td><td>0.78436</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.00095 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_045608-cwudz2wj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_050220-wgvfp3rx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.351185768127442, Training Accuracy: 3.94\n",
            "Validation Loss: 4.125218055810139, Validation Accuracy: 6.94\n",
            "[2/150]: Training Loss: 3.934326037979126, Training Accuracy: 9.675\n",
            "Validation Loss: 3.8352680054439863, Validation Accuracy: 11.53\n",
            "[3/150]: Training Loss: 3.6920593730926514, Training Accuracy: 14.25\n",
            "Validation Loss: 3.6194094821905636, Validation Accuracy: 15.04\n",
            "[4/150]: Training Loss: 3.5119912174224854, Training Accuracy: 17.235\n",
            "Validation Loss: 3.498675950773203, Validation Accuracy: 17.26\n",
            "[5/150]: Training Loss: 3.3595370391845703, Training Accuracy: 19.9025\n",
            "Validation Loss: 3.3320715184424334, Validation Accuracy: 20.65\n",
            "[6/150]: Training Loss: 3.2359037544250486, Training Accuracy: 22.135\n",
            "Validation Loss: 3.2282794827868226, Validation Accuracy: 21.83\n",
            "[7/150]: Training Loss: 3.1236792266845703, Training Accuracy: 24.1875\n",
            "Validation Loss: 3.1484436852157494, Validation Accuracy: 23.69\n",
            "[8/150]: Training Loss: 3.0264555549621583, Training Accuracy: 25.99\n",
            "Validation Loss: 3.0823915505864816, Validation Accuracy: 24.76\n",
            "[9/150]: Training Loss: 2.9406655250549316, Training Accuracy: 27.4325\n",
            "Validation Loss: 3.018990922126041, Validation Accuracy: 25.75\n",
            "[10/150]: Training Loss: 2.8602982753753663, Training Accuracy: 28.8825\n",
            "Validation Loss: 2.982261516486004, Validation Accuracy: 26.83\n",
            "[11/150]: Training Loss: 2.7865394050598145, Training Accuracy: 30.62\n",
            "Validation Loss: 2.881638531472273, Validation Accuracy: 28.86\n",
            "[12/150]: Training Loss: 2.713952407836914, Training Accuracy: 32.0525\n",
            "Validation Loss: 2.8773576226204063, Validation Accuracy: 28.51\n",
            "[13/150]: Training Loss: 2.6428218954086304, Training Accuracy: 33.4175\n",
            "Validation Loss: 2.852285245421586, Validation Accuracy: 29.44\n",
            "[14/150]: Training Loss: 2.5819866678237915, Training Accuracy: 34.2325\n",
            "Validation Loss: 2.8152025581165483, Validation Accuracy: 29.99\n",
            "[15/150]: Training Loss: 2.5168129930496215, Training Accuracy: 36.01\n",
            "Validation Loss: 2.7263220571408606, Validation Accuracy: 32.4\n",
            "[16/150]: Training Loss: 2.456671890640259, Training Accuracy: 37.025\n",
            "Validation Loss: 2.7360152697107596, Validation Accuracy: 31.89\n",
            "[17/150]: Training Loss: 2.394518960952759, Training Accuracy: 38.405\n",
            "Validation Loss: 2.693733840231683, Validation Accuracy: 33.43\n",
            "[18/150]: Training Loss: 2.329904039955139, Training Accuracy: 40.0125\n",
            "Validation Loss: 2.679514690569252, Validation Accuracy: 33.49\n",
            "[19/150]: Training Loss: 2.271217462730408, Training Accuracy: 41.0875\n",
            "Validation Loss: 2.7137394892941615, Validation Accuracy: 32.98\n",
            "[20/150]: Training Loss: 2.2047285720825194, Training Accuracy: 42.575\n",
            "Validation Loss: 2.6841572416815787, Validation Accuracy: 32.96\n",
            "[21/150]: Training Loss: 2.1471473873138427, Training Accuracy: 43.83\n",
            "Validation Loss: 2.6751675947456603, Validation Accuracy: 33.61\n",
            "[22/150]: Training Loss: 2.085570357322693, Training Accuracy: 45.055\n",
            "Validation Loss: 2.6481618797703153, Validation Accuracy: 34.55\n",
            "[23/150]: Training Loss: 2.0214510499954224, Training Accuracy: 46.6625\n",
            "Validation Loss: 2.638173457163914, Validation Accuracy: 35.26\n",
            "[24/150]: Training Loss: 1.9607698831558227, Training Accuracy: 48.02\n",
            "Validation Loss: 2.621039168849872, Validation Accuracy: 35.84\n",
            "[25/150]: Training Loss: 1.8981156831741333, Training Accuracy: 49.45\n",
            "Validation Loss: 2.62651793896013, Validation Accuracy: 36.22\n",
            "[26/150]: Training Loss: 1.8291910402297973, Training Accuracy: 51.235\n",
            "Validation Loss: 2.6563384396255394, Validation Accuracy: 35.62\n",
            "[27/150]: Training Loss: 1.7651165187835693, Training Accuracy: 52.31\n",
            "Validation Loss: 2.639584611935221, Validation Accuracy: 36.55\n",
            "[28/150]: Training Loss: 1.7005936141967772, Training Accuracy: 54.275\n",
            "Validation Loss: 2.7095768307424652, Validation Accuracy: 36.06\n",
            "[29/150]: Training Loss: 1.6383595853805542, Training Accuracy: 55.6225\n",
            "Validation Loss: 2.7259993150735355, Validation Accuracy: 35.64\n",
            "[30/150]: Training Loss: 1.5726151014328003, Training Accuracy: 57.1225\n",
            "Validation Loss: 2.7611397246646274, Validation Accuracy: 36.11\n",
            "[31/150]: Training Loss: 1.508023483467102, Training Accuracy: 58.3025\n",
            "Validation Loss: 2.7436208489594187, Validation Accuracy: 35.66\n",
            "[32/150]: Training Loss: 1.4352122190475465, Training Accuracy: 60.295\n",
            "Validation Loss: 2.8204059456564057, Validation Accuracy: 36.43\n",
            "[33/150]: Training Loss: 1.3806078368186951, Training Accuracy: 61.585\n",
            "Validation Loss: 2.876485233853577, Validation Accuracy: 34.85\n",
            "[34/150]: Training Loss: 1.3117412397384645, Training Accuracy: 63.325\n",
            "Validation Loss: 2.8764415660481544, Validation Accuracy: 36.16\n",
            "[35/150]: Training Loss: 1.2477456188201905, Training Accuracy: 64.815\n",
            "Validation Loss: 2.959255384032134, Validation Accuracy: 35.83\n",
            "[36/150]: Training Loss: 1.178989047718048, Training Accuracy: 66.845\n",
            "Validation Loss: 3.055402055667464, Validation Accuracy: 35.68\n",
            "[37/150]: Training Loss: 1.1195641567230226, Training Accuracy: 68.255\n",
            "Validation Loss: 3.092683092044417, Validation Accuracy: 35.74\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 19.867750665944094, Test Accuracy: 12.24\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>██▂▃▁▁▂▁▁▁▂▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃</td></tr><tr><td>Test Loss</td><td>▂▁▂▃▅▅▆▇▇▆▆▆█▇██▇█▇▇▇▇▇▇▇▇▇▇▇██▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.24</td></tr><tr><td>Test Loss</td><td>19.86775</td></tr><tr><td>Train Accuracy</td><td>68.255</td></tr><tr><td>Train Loss</td><td>1.11956</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_050220-wgvfp3rx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.0015 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_050736-gnfp4sxh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">learning_rate=0.0015 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.262849729156494, Training Accuracy: 4.9725\n",
            "Validation Loss: 3.9988777105975304, Validation Accuracy: 9.32\n",
            "[2/150]: Training Loss: 3.787733755874634, Training Accuracy: 12.5275\n",
            "Validation Loss: 3.666901140455987, Validation Accuracy: 14.13\n",
            "[3/150]: Training Loss: 3.5222632232666014, Training Accuracy: 16.975\n",
            "Validation Loss: 3.430799526773441, Validation Accuracy: 18.28\n",
            "[4/150]: Training Loss: 3.3261954177856445, Training Accuracy: 20.0275\n",
            "Validation Loss: 3.268884590476941, Validation Accuracy: 20.25\n",
            "[5/150]: Training Loss: 3.1651099575042725, Training Accuracy: 22.825\n",
            "Validation Loss: 3.140599861266507, Validation Accuracy: 23.63\n",
            "[6/150]: Training Loss: 3.0220409996032713, Training Accuracy: 25.57\n",
            "Validation Loss: 3.062152488975768, Validation Accuracy: 24.92\n",
            "[7/150]: Training Loss: 2.9046311878204345, Training Accuracy: 27.855\n",
            "Validation Loss: 2.9628464735237654, Validation Accuracy: 26.95\n",
            "[8/150]: Training Loss: 2.7910710647583006, Training Accuracy: 30.235\n",
            "Validation Loss: 2.8832454301749064, Validation Accuracy: 28.14\n",
            "[9/150]: Training Loss: 2.687530333709717, Training Accuracy: 32.2625\n",
            "Validation Loss: 2.8348786056421367, Validation Accuracy: 30.07\n",
            "[10/150]: Training Loss: 2.590290707015991, Training Accuracy: 34.1175\n",
            "Validation Loss: 2.7776184780582502, Validation Accuracy: 30.52\n",
            "[11/150]: Training Loss: 2.499223603057861, Training Accuracy: 36.12\n",
            "Validation Loss: 2.726046642680077, Validation Accuracy: 31.91\n",
            "[12/150]: Training Loss: 2.4020754039764403, Training Accuracy: 37.9725\n",
            "Validation Loss: 2.7060916757887337, Validation Accuracy: 32.51\n",
            "[13/150]: Training Loss: 2.302425242996216, Training Accuracy: 40.3075\n",
            "Validation Loss: 2.660059646436363, Validation Accuracy: 33.06\n",
            "[14/150]: Training Loss: 2.2182941759109496, Training Accuracy: 42.03\n",
            "Validation Loss: 2.647583461870813, Validation Accuracy: 34.15\n",
            "[15/150]: Training Loss: 2.1231776348114013, Training Accuracy: 43.9025\n",
            "Validation Loss: 2.6469775620539475, Validation Accuracy: 34.32\n",
            "[16/150]: Training Loss: 2.030972394180298, Training Accuracy: 45.9525\n",
            "Validation Loss: 2.7037209963342947, Validation Accuracy: 32.86\n",
            "[17/150]: Training Loss: 1.9431676984786987, Training Accuracy: 47.91\n",
            "Validation Loss: 2.5850457507333937, Validation Accuracy: 36.27\n",
            "[18/150]: Training Loss: 1.8313071418762208, Training Accuracy: 50.255\n",
            "Validation Loss: 2.699979861071155, Validation Accuracy: 35.5\n",
            "[19/150]: Training Loss: 1.7440621503829956, Training Accuracy: 52.4725\n",
            "Validation Loss: 2.661453550028953, Validation Accuracy: 35.96\n",
            "[20/150]: Training Loss: 1.637422308921814, Training Accuracy: 54.8325\n",
            "Validation Loss: 2.7208387426509977, Validation Accuracy: 35.5\n",
            "[21/150]: Training Loss: 1.5425473594665526, Training Accuracy: 57.03\n",
            "Validation Loss: 2.766743406368669, Validation Accuracy: 35.3\n",
            "[22/150]: Training Loss: 1.4425379981994628, Training Accuracy: 59.42\n",
            "Validation Loss: 2.7848968460301684, Validation Accuracy: 36.36\n",
            "[23/150]: Training Loss: 1.346246865272522, Training Accuracy: 61.82\n",
            "Validation Loss: 2.918702983552483, Validation Accuracy: 35.2\n",
            "[24/150]: Training Loss: 1.2415513612747193, Training Accuracy: 64.48\n",
            "Validation Loss: 3.0769596373199657, Validation Accuracy: 34.71\n",
            "[25/150]: Training Loss: 1.1484121152877809, Training Accuracy: 66.9425\n",
            "Validation Loss: 3.111480196570135, Validation Accuracy: 35.56\n",
            "[26/150]: Training Loss: 1.049374456501007, Training Accuracy: 69.2\n",
            "Validation Loss: 3.2441035076311437, Validation Accuracy: 35.12\n",
            "[27/150]: Training Loss: 0.9539197593688965, Training Accuracy: 71.64\n",
            "Validation Loss: 3.3398004808243673, Validation Accuracy: 34.83\n",
            "[28/150]: Training Loss: 0.8686957097053528, Training Accuracy: 73.885\n",
            "Validation Loss: 3.526861637261263, Validation Accuracy: 35.38\n",
            "[29/150]: Training Loss: 0.7777377708911896, Training Accuracy: 76.4\n",
            "Validation Loss: 3.74925019938475, Validation Accuracy: 34.95\n",
            "[30/150]: Training Loss: 0.6971015272140503, Training Accuracy: 78.4225\n",
            "Validation Loss: 3.921683767039305, Validation Accuracy: 34.49\n",
            "[31/150]: Training Loss: 0.6319020359992981, Training Accuracy: 80.37\n",
            "Validation Loss: 4.265976667404175, Validation Accuracy: 33.7\n",
            "[32/150]: Training Loss: 0.5592198015213012, Training Accuracy: 82.41\n",
            "Validation Loss: 4.3743809985507065, Validation Accuracy: 34.21\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 32.802743437943185, Test Accuracy: 15.7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▅█▂▅▄▂▁▁▁▁▂▃▃▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▄▄▄▄▄▄</td></tr><tr><td>Test Loss</td><td>▁▄▇▆▇▇███▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▇▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>15.7</td></tr><tr><td>Test Loss</td><td>32.80274</td></tr><tr><td>Train Accuracy</td><td>82.41</td></tr><tr><td>Train Loss</td><td>0.55922</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_050736-gnfp4sxh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.002 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_051217-y92gs5m0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">learning_rate=0.002 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.222224911499024, Training Accuracy: 5.3975\n",
            "Validation Loss: 3.937301506662065, Validation Accuracy: 9.22\n",
            "[2/150]: Training Loss: 3.7261308227539063, Training Accuracy: 13.09\n",
            "Validation Loss: 3.593827167134376, Validation Accuracy: 15.34\n",
            "[3/150]: Training Loss: 3.4419474758148194, Training Accuracy: 18.2775\n",
            "Validation Loss: 3.3379262875599465, Validation Accuracy: 19.89\n",
            "[4/150]: Training Loss: 3.242010182952881, Training Accuracy: 21.865\n",
            "Validation Loss: 3.2397833553848754, Validation Accuracy: 21.54\n",
            "[5/150]: Training Loss: 3.074250465774536, Training Accuracy: 24.8525\n",
            "Validation Loss: 3.2218855049959414, Validation Accuracy: 22.29\n",
            "[6/150]: Training Loss: 2.9360343181610107, Training Accuracy: 27.3175\n",
            "Validation Loss: 2.9865669110778033, Validation Accuracy: 26.78\n",
            "[7/150]: Training Loss: 2.801424619293213, Training Accuracy: 30.0175\n",
            "Validation Loss: 2.881270451150882, Validation Accuracy: 28.82\n",
            "[8/150]: Training Loss: 2.688298546409607, Training Accuracy: 32.05\n",
            "Validation Loss: 2.8182313017025113, Validation Accuracy: 30.07\n",
            "[9/150]: Training Loss: 2.5692677375793456, Training Accuracy: 34.84\n",
            "Validation Loss: 2.7818179950592623, Validation Accuracy: 30.94\n",
            "[10/150]: Training Loss: 2.454072025489807, Training Accuracy: 37.1425\n",
            "Validation Loss: 2.741547807766374, Validation Accuracy: 32.13\n",
            "[11/150]: Training Loss: 2.341491235733032, Training Accuracy: 39.3875\n",
            "Validation Loss: 2.735630521349087, Validation Accuracy: 32.51\n",
            "[12/150]: Training Loss: 2.2293454483032225, Training Accuracy: 41.4725\n",
            "Validation Loss: 2.690371492106444, Validation Accuracy: 33.37\n",
            "[13/150]: Training Loss: 2.1135470266342162, Training Accuracy: 43.935\n",
            "Validation Loss: 2.7198572918108312, Validation Accuracy: 34.01\n",
            "[14/150]: Training Loss: 1.9979984771728516, Training Accuracy: 46.1675\n",
            "Validation Loss: 2.7182075719165195, Validation Accuracy: 34.3\n",
            "[15/150]: Training Loss: 1.8890921760559083, Training Accuracy: 49.265\n",
            "Validation Loss: 2.7245476724235873, Validation Accuracy: 34.8\n",
            "[16/150]: Training Loss: 1.7773400522232055, Training Accuracy: 51.53\n",
            "Validation Loss: 2.749075835677469, Validation Accuracy: 34.12\n",
            "[17/150]: Training Loss: 1.676476739501953, Training Accuracy: 53.69\n",
            "Validation Loss: 2.8863297662917216, Validation Accuracy: 34.72\n",
            "[18/150]: Training Loss: 1.5655937635421753, Training Accuracy: 56.19\n",
            "Validation Loss: 2.8975180911410385, Validation Accuracy: 35.07\n",
            "[19/150]: Training Loss: 1.4489710484504699, Training Accuracy: 59.165\n",
            "Validation Loss: 2.9350054689273715, Validation Accuracy: 34.48\n",
            "[20/150]: Training Loss: 1.3497021337509156, Training Accuracy: 61.3125\n",
            "Validation Loss: 3.0767477864672426, Validation Accuracy: 34.78\n",
            "[21/150]: Training Loss: 1.2329449357032776, Training Accuracy: 64.19\n",
            "Validation Loss: 3.22720639113408, Validation Accuracy: 33.72\n",
            "[22/150]: Training Loss: 1.1406824831962585, Training Accuracy: 66.7375\n",
            "Validation Loss: 3.406786183642734, Validation Accuracy: 33.27\n",
            "[23/150]: Training Loss: 1.044043209552765, Training Accuracy: 69.1625\n",
            "Validation Loss: 3.664752894905722, Validation Accuracy: 32.75\n",
            "[24/150]: Training Loss: 0.9549756371498108, Training Accuracy: 71.1525\n",
            "Validation Loss: 3.7399451838936777, Validation Accuracy: 32.73\n",
            "[25/150]: Training Loss: 0.8772646800518036, Training Accuracy: 73.25\n",
            "Validation Loss: 3.9628275534149946, Validation Accuracy: 33.22\n",
            "[26/150]: Training Loss: 0.7976884460449218, Training Accuracy: 75.4625\n",
            "Validation Loss: 4.143224073823091, Validation Accuracy: 32.26\n",
            "[27/150]: Training Loss: 0.7417024869441986, Training Accuracy: 76.86\n",
            "Validation Loss: 4.497031521645321, Validation Accuracy: 32.38\n",
            "[28/150]: Training Loss: 0.682380113697052, Training Accuracy: 78.7575\n",
            "Validation Loss: 4.677568254956774, Validation Accuracy: 32.16\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 35.528370875461846, Test Accuracy: 11.85\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▅▁▂▁▁▁▂▁▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▁▂▂▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▁▃▆▅▆▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>Train Accuracy</td><td>▁▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>Train Loss</td><td>█▇▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>11.85</td></tr><tr><td>Test Loss</td><td>35.52837</td></tr><tr><td>Train Accuracy</td><td>78.7575</td></tr><tr><td>Train Loss</td><td>0.68238</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.002 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_051217-y92gs5m0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "learning_rates = [9e-04, 95e-05, 1e-03, 15e-04, 2e-03]\n",
        "wd = 4e-04\n",
        "for lr in learning_rates:\n",
        "\n",
        "  print('='*50)\n",
        "  print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {'learning_rate': lr,\n",
        "                      'weight_decay' : wd\n",
        "                      }\n",
        "  # Load the model\n",
        "  model = LeNet5().to(device)\n",
        "\n",
        "  # Optimizer and scheduler setup\n",
        "  optimizer = LAMB(model.parameters(), lr=lr, weight_decay=wd)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "  # Training\n",
        "  run_training(num_epochs,\n",
        "                model,\n",
        "                train_loader,\n",
        "                validation_loader,\n",
        "                test_loader,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                criterion,\n",
        "                device,\n",
        "                'LAMB-HyperParameterTuning',\n",
        "                hyperparameters=hyperparameters,\n",
        "                is_wandb = True,\n",
        "                n_epochs_stop = 10\n",
        "  )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90b585318084475b9543b3226230d373",
            "5f3a33bc6a334c9e8c5886caa5f015ca",
            "46c9d83bf8af443bb376ed4858ce35f7",
            "2402e482be7e484fa98ae3f60f68d95a",
            "e8040d3a83de41319a2a836def914b1b",
            "0b4b10bb8bff4d40afa8df981440fe43",
            "3b0b3657d30547d7abe702d6c1e7b7c4",
            "17ac4efa9cf148e5be69edbc5b0bdecf",
            "f5fd8db807e144578a2e20762d7369d0",
            "32c759d7fff64701a6ad61b38ac63187",
            "557cf2de74314915b7204d9055fa6987",
            "c5bb24dc0f56483b88a0efbfa2a1c8ee",
            "67aa8f8c2b244c9a9a3bb11caf491247",
            "09b762f5ba784066a9408ffcfdea5b2e",
            "6a345ff7386643eeb7a5b190d69d2e0e",
            "8f4783e2060a4295bb68036a4a7310d9",
            "aa6aa819c1fd4776ac47af588aaaaacd",
            "64224c777f01418e904dcd30ecd7c5ef",
            "c1dbd12595384bc6a0240aaeb16014dc",
            "6aa92cf922724ac08c45385ff8a58447",
            "99929754d3094d03a5f311177ac26cb3",
            "9ea517158b974c5da17899e3fea4fc3b",
            "bb2ee36dd3c04926b10b832928d7d0a0",
            "9d88657b39fd4b169d61b1b8d240e6ff"
          ]
        },
        "id": "7sUsHkiHgURG",
        "outputId": "3829f79a-3d06-48ee-fea5-a00c18f8744b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:uqgfhn52) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>▁▄▆▇█</td></tr><tr><td>Train Loss</td><td>█▅▃▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>22.668</td></tr><tr><td>Train Loss</td><td>3.18342</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015026019100214134 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/uqgfhn52' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/uqgfhn52</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_051725-uqgfhn52/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:uqgfhn52). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_052010-62vz5e00</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">learning_rate=0.0015 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.170614353226274, Training Accuracy: 6.554\n",
            "Validation Loss: 3.8419871087286883, Validation Accuracy: 11.55\n",
            "[2/150]: Training Loss: 3.73113738697813, Training Accuracy: 13.326\n",
            "Validation Loss: 3.5141605601948536, Validation Accuracy: 17.24\n",
            "[3/150]: Training Loss: 3.4963422099037853, Training Accuracy: 17.148\n",
            "Validation Loss: 3.329459586720558, Validation Accuracy: 21.14\n",
            "[4/150]: Training Loss: 3.32537763838268, Training Accuracy: 20.17\n",
            "Validation Loss: 3.1594036445496188, Validation Accuracy: 23.38\n",
            "[5/150]: Training Loss: 3.1821046982274948, Training Accuracy: 22.724\n",
            "Validation Loss: 3.024734082495331, Validation Accuracy: 25.42\n",
            "[6/150]: Training Loss: 3.0576654736648132, Training Accuracy: 24.838\n",
            "Validation Loss: 2.917888655024729, Validation Accuracy: 27.48\n",
            "[7/150]: Training Loss: 2.9461568444586166, Training Accuracy: 26.996\n",
            "Validation Loss: 2.8047209317517128, Validation Accuracy: 29.77\n",
            "[8/150]: Training Loss: 2.860208951298843, Training Accuracy: 28.704\n",
            "Validation Loss: 2.7236505541831826, Validation Accuracy: 30.98\n",
            "[9/150]: Training Loss: 2.7667418916512023, Training Accuracy: 30.53\n",
            "Validation Loss: 2.6368031137308496, Validation Accuracy: 33.13\n",
            "[10/150]: Training Loss: 2.6879202682343895, Training Accuracy: 31.998\n",
            "Validation Loss: 2.536134794259527, Validation Accuracy: 35.32\n",
            "[11/150]: Training Loss: 2.61040174458033, Training Accuracy: 33.4\n",
            "Validation Loss: 2.4932953764678567, Validation Accuracy: 36.12\n",
            "[12/150]: Training Loss: 2.546117087306879, Training Accuracy: 34.894\n",
            "Validation Loss: 2.4478625689342524, Validation Accuracy: 37.12\n",
            "[13/150]: Training Loss: 2.4885423736803975, Training Accuracy: 35.89\n",
            "Validation Loss: 2.4252931342762745, Validation Accuracy: 37.55\n",
            "[14/150]: Training Loss: 2.4414472836057852, Training Accuracy: 37.026\n",
            "Validation Loss: 2.3621389410298343, Validation Accuracy: 39.2\n",
            "[15/150]: Training Loss: 2.3877986550636, Training Accuracy: 37.84\n",
            "Validation Loss: 2.3034424402151896, Validation Accuracy: 40.21\n",
            "[16/150]: Training Loss: 2.3379326612138382, Training Accuracy: 39.018\n",
            "Validation Loss: 2.272260831419829, Validation Accuracy: 41.24\n",
            "[17/150]: Training Loss: 2.300395258247395, Training Accuracy: 39.968\n",
            "Validation Loss: 2.2585707120834644, Validation Accuracy: 40.6\n",
            "[18/150]: Training Loss: 2.254751528315532, Training Accuracy: 40.976\n",
            "Validation Loss: 2.2186143770339384, Validation Accuracy: 42.07\n",
            "[19/150]: Training Loss: 2.2090765830805843, Training Accuracy: 42.026\n",
            "Validation Loss: 2.1868586600965756, Validation Accuracy: 42.61\n",
            "[20/150]: Training Loss: 2.183374183562101, Training Accuracy: 42.532\n",
            "Validation Loss: 2.184412774007032, Validation Accuracy: 42.58\n",
            "[21/150]: Training Loss: 2.1446489868566507, Training Accuracy: 43.298\n",
            "Validation Loss: 2.144960983543639, Validation Accuracy: 43.98\n",
            "[22/150]: Training Loss: 2.1038296910198144, Training Accuracy: 44.234\n",
            "Validation Loss: 2.14452546493263, Validation Accuracy: 44.01\n",
            "[23/150]: Training Loss: 2.0707620507311026, Training Accuracy: 44.894\n",
            "Validation Loss: 2.098228795513226, Validation Accuracy: 45.23\n",
            "[24/150]: Training Loss: 2.043932166093451, Training Accuracy: 45.518\n",
            "Validation Loss: 2.0813077680624215, Validation Accuracy: 45.38\n",
            "[25/150]: Training Loss: 2.0066164360021994, Training Accuracy: 46.274\n",
            "Validation Loss: 2.075542102953431, Validation Accuracy: 45.85\n",
            "[26/150]: Training Loss: 1.9791695739302184, Training Accuracy: 46.988\n",
            "Validation Loss: 2.0774263060016995, Validation Accuracy: 45.28\n",
            "[27/150]: Training Loss: 1.948626570232079, Training Accuracy: 47.584\n",
            "Validation Loss: 2.0519798697939344, Validation Accuracy: 46.31\n",
            "[28/150]: Training Loss: 1.9167836584398508, Training Accuracy: 48.236\n",
            "Validation Loss: 2.0201504807563344, Validation Accuracy: 46.88\n",
            "[29/150]: Training Loss: 1.8909891124271676, Training Accuracy: 48.752\n",
            "Validation Loss: 2.040525470569635, Validation Accuracy: 46.57\n",
            "[30/150]: Training Loss: 1.8726914470153087, Training Accuracy: 49.618\n",
            "Validation Loss: 2.0113253760489687, Validation Accuracy: 47.44\n",
            "[31/150]: Training Loss: 1.8444365990131408, Training Accuracy: 50.096\n",
            "Validation Loss: 2.0178289990516225, Validation Accuracy: 47.23\n",
            "[32/150]: Training Loss: 1.8157384923047117, Training Accuracy: 50.462\n",
            "Validation Loss: 1.9997166759648901, Validation Accuracy: 47.55\n",
            "[33/150]: Training Loss: 1.7931588938474046, Training Accuracy: 51.29\n",
            "Validation Loss: 1.9950028824958073, Validation Accuracy: 47.93\n",
            "[34/150]: Training Loss: 1.770590110355631, Training Accuracy: 51.824\n",
            "Validation Loss: 1.993164770162789, Validation Accuracy: 48.12\n",
            "[35/150]: Training Loss: 1.7467985225607976, Training Accuracy: 52.03\n",
            "Validation Loss: 1.9869080242837311, Validation Accuracy: 47.9\n",
            "[36/150]: Training Loss: 1.7260596163742377, Training Accuracy: 52.556\n",
            "Validation Loss: 1.9724081488931255, Validation Accuracy: 48.61\n",
            "[37/150]: Training Loss: 1.7053224419998696, Training Accuracy: 53.142\n",
            "Validation Loss: 1.9826935643603087, Validation Accuracy: 48.29\n",
            "[38/150]: Training Loss: 1.67785135681367, Training Accuracy: 53.82\n",
            "Validation Loss: 1.9470138079041888, Validation Accuracy: 49.88\n",
            "[39/150]: Training Loss: 1.6623152171254463, Training Accuracy: 54.074\n",
            "Validation Loss: 1.9769204634769706, Validation Accuracy: 48.87\n",
            "[40/150]: Training Loss: 1.6364040380853522, Training Accuracy: 54.652\n",
            "Validation Loss: 1.9554897744184847, Validation Accuracy: 49.57\n",
            "[41/150]: Training Loss: 1.6296177715291758, Training Accuracy: 54.87\n",
            "Validation Loss: 1.9755018660976629, Validation Accuracy: 49.42\n",
            "[42/150]: Training Loss: 1.6172699540319955, Training Accuracy: 55.052\n",
            "Validation Loss: 1.9689236112460968, Validation Accuracy: 49.6\n",
            "[43/150]: Training Loss: 1.5901159763793506, Training Accuracy: 55.706\n",
            "Validation Loss: 1.9709602108426914, Validation Accuracy: 49.39\n",
            "[44/150]: Training Loss: 1.5688080241917954, Training Accuracy: 56.494\n",
            "Validation Loss: 1.944002225140857, Validation Accuracy: 50.24\n",
            "[45/150]: Training Loss: 1.5468424783490808, Training Accuracy: 57.02\n",
            "Validation Loss: 1.9809717410688947, Validation Accuracy: 49.68\n",
            "[46/150]: Training Loss: 1.5288271441331605, Training Accuracy: 57.372\n",
            "Validation Loss: 1.9420389149599016, Validation Accuracy: 50.41\n",
            "[47/150]: Training Loss: 1.527083154453341, Training Accuracy: 57.472\n",
            "Validation Loss: 1.9570772792123685, Validation Accuracy: 49.71\n",
            "[48/150]: Training Loss: 1.5049020071773578, Training Accuracy: 57.818\n",
            "Validation Loss: 1.954159548328181, Validation Accuracy: 50.38\n",
            "[49/150]: Training Loss: 1.48557850992893, Training Accuracy: 58.67\n",
            "Validation Loss: 1.934345255232161, Validation Accuracy: 50.33\n",
            "[50/150]: Training Loss: 1.461377340052134, Training Accuracy: 58.866\n",
            "Validation Loss: 1.9670750221629052, Validation Accuracy: 50.09\n",
            "[51/150]: Training Loss: 1.4531892761397545, Training Accuracy: 59.148\n",
            "Validation Loss: 1.9439144878630426, Validation Accuracy: 50.57\n",
            "[52/150]: Training Loss: 1.4365854823528348, Training Accuracy: 59.4\n",
            "Validation Loss: 1.9623823484797387, Validation Accuracy: 50.49\n",
            "[53/150]: Training Loss: 1.4231898410393453, Training Accuracy: 59.886\n",
            "Validation Loss: 1.9759472274476555, Validation Accuracy: 50.14\n",
            "[54/150]: Training Loss: 1.408926703664653, Training Accuracy: 60.114\n",
            "Validation Loss: 1.924273559242297, Validation Accuracy: 51.21\n",
            "[55/150]: Training Loss: 1.3876726690613095, Training Accuracy: 60.616\n",
            "Validation Loss: 1.9458329692767684, Validation Accuracy: 50.63\n",
            "[56/150]: Training Loss: 1.375196378478004, Training Accuracy: 61.12\n",
            "Validation Loss: 1.9410056468028172, Validation Accuracy: 51.4\n",
            "[57/150]: Training Loss: 1.3586041162081082, Training Accuracy: 61.634\n",
            "Validation Loss: 1.9649552509283563, Validation Accuracy: 50.61\n",
            "[58/150]: Training Loss: 1.3581253530271828, Training Accuracy: 61.412\n",
            "Validation Loss: 1.9388997919240576, Validation Accuracy: 51.27\n",
            "[59/150]: Training Loss: 1.3380669855400729, Training Accuracy: 61.932\n",
            "Validation Loss: 1.9778220661126884, Validation Accuracy: 50.91\n",
            "[60/150]: Training Loss: 1.3257979125622898, Training Accuracy: 62.056\n",
            "Validation Loss: 1.9304483665782175, Validation Accuracy: 51.44\n",
            "[61/150]: Training Loss: 1.316665162896866, Training Accuracy: 62.458\n",
            "Validation Loss: 1.9412351808730204, Validation Accuracy: 51.61\n",
            "[62/150]: Training Loss: 1.2979835793947625, Training Accuracy: 62.832\n",
            "Validation Loss: 1.9522758213577756, Validation Accuracy: 51.6\n",
            "[63/150]: Training Loss: 1.2900130991130838, Training Accuracy: 63.092\n",
            "Validation Loss: 1.9639577113898696, Validation Accuracy: 51.23\n",
            "[64/150]: Training Loss: 1.2804708784955847, Training Accuracy: 63.436\n",
            "Validation Loss: 1.9787959422275518, Validation Accuracy: 51.42\n",
            "[65/150]: Training Loss: 1.255796139959789, Training Accuracy: 63.948\n",
            "Validation Loss: 1.9797948439409778, Validation Accuracy: 51.63\n",
            "[66/150]: Training Loss: 1.25389591042343, Training Accuracy: 64.23\n",
            "Validation Loss: 1.97708031554131, Validation Accuracy: 52.19\n",
            "[67/150]: Training Loss: 1.2357215599330795, Training Accuracy: 64.366\n",
            "Validation Loss: 1.9641305322100402, Validation Accuracy: 52.22\n",
            "[68/150]: Training Loss: 1.2240538022402303, Training Accuracy: 64.862\n",
            "Validation Loss: 1.9815536661512534, Validation Accuracy: 51.47\n",
            "[69/150]: Training Loss: 1.2087419308969736, Training Accuracy: 65.136\n",
            "Validation Loss: 1.979879951021474, Validation Accuracy: 51.77\n",
            "[70/150]: Training Loss: 1.1984577734604516, Training Accuracy: 65.552\n",
            "Validation Loss: 2.005889118856685, Validation Accuracy: 51.82\n",
            "[71/150]: Training Loss: 1.184933677506264, Training Accuracy: 66.026\n",
            "Validation Loss: 1.9805337274150483, Validation Accuracy: 51.89\n",
            "[72/150]: Training Loss: 1.1769923466398282, Training Accuracy: 65.964\n",
            "Validation Loss: 2.0164508561419834, Validation Accuracy: 51.97\n",
            "[73/150]: Training Loss: 1.1639809905720488, Training Accuracy: 66.116\n",
            "Validation Loss: 2.0093113024523306, Validation Accuracy: 51.75\n",
            "[74/150]: Training Loss: 1.1529584921077085, Training Accuracy: 66.55\n",
            "Validation Loss: 2.017468781987573, Validation Accuracy: 51.53\n",
            "[75/150]: Training Loss: 1.1453676276347216, Training Accuracy: 66.758\n",
            "Validation Loss: 2.011715882902692, Validation Accuracy: 51.48\n",
            "[76/150]: Training Loss: 1.1254654065574832, Training Accuracy: 67.396\n",
            "Validation Loss: 2.0016076625532406, Validation Accuracy: 51.93\n",
            "[77/150]: Training Loss: 1.1255306048161537, Training Accuracy: 67.168\n",
            "Validation Loss: 2.037281950567938, Validation Accuracy: 51.54\n",
            "[78/150]: Training Loss: 1.107588133391212, Training Accuracy: 67.898\n",
            "Validation Loss: 2.0207215995545598, Validation Accuracy: 52.25\n",
            "[79/150]: Training Loss: 1.0974091778478354, Training Accuracy: 67.988\n",
            "Validation Loss: 2.0399385941256383, Validation Accuracy: 52.27\n",
            "[80/150]: Training Loss: 1.0841643994726489, Training Accuracy: 68.482\n",
            "Validation Loss: 2.0396120669735467, Validation Accuracy: 51.88\n",
            "[81/150]: Training Loss: 1.086065025128367, Training Accuracy: 68.472\n",
            "Validation Loss: 2.0602660406926634, Validation Accuracy: 52.23\n",
            "[82/150]: Training Loss: 1.068733287741766, Training Accuracy: 68.792\n",
            "Validation Loss: 2.038099098357425, Validation Accuracy: 52.32\n",
            "[83/150]: Training Loss: 1.0567113834116466, Training Accuracy: 69.072\n",
            "Validation Loss: 2.0566319333519907, Validation Accuracy: 52.0\n",
            "[84/150]: Training Loss: 1.0568410671123154, Training Accuracy: 69.164\n",
            "Validation Loss: 2.031417142054078, Validation Accuracy: 52.23\n",
            "[85/150]: Training Loss: 1.0462324290019471, Training Accuracy: 69.518\n",
            "Validation Loss: 2.039376434247205, Validation Accuracy: 52.34\n",
            "[86/150]: Training Loss: 1.0314530159353905, Training Accuracy: 69.866\n",
            "Validation Loss: 2.0698205103540115, Validation Accuracy: 52.02\n",
            "[87/150]: Training Loss: 1.0182559825956363, Training Accuracy: 70.136\n",
            "Validation Loss: 2.063336102825821, Validation Accuracy: 52.83\n",
            "[88/150]: Training Loss: 1.010449574350396, Training Accuracy: 70.25\n",
            "Validation Loss: 2.077486888618226, Validation Accuracy: 52.3\n",
            "[89/150]: Training Loss: 1.0035706778316547, Training Accuracy: 70.786\n",
            "Validation Loss: 2.095621291998845, Validation Accuracy: 52.44\n",
            "[90/150]: Training Loss: 0.9991849294251494, Training Accuracy: 70.812\n",
            "Validation Loss: 2.069785719464539, Validation Accuracy: 52.4\n",
            "[91/150]: Training Loss: 0.993351522995078, Training Accuracy: 70.858\n",
            "Validation Loss: 2.1024031069627993, Validation Accuracy: 52.29\n",
            "[92/150]: Training Loss: 0.9726321048215222, Training Accuracy: 71.618\n",
            "Validation Loss: 2.084312925672835, Validation Accuracy: 52.53\n",
            "[93/150]: Training Loss: 0.97342309279515, Training Accuracy: 71.502\n",
            "Validation Loss: 2.0946866744642803, Validation Accuracy: 52.66\n",
            "[94/150]: Training Loss: 0.963803626920866, Training Accuracy: 71.718\n",
            "Validation Loss: 2.110511908105984, Validation Accuracy: 52.0\n",
            "[95/150]: Training Loss: 0.9580129440635672, Training Accuracy: 71.984\n",
            "Validation Loss: 2.111149025570815, Validation Accuracy: 52.13\n",
            "[96/150]: Training Loss: 0.9513878270869365, Training Accuracy: 72.204\n",
            "Validation Loss: 2.1115560136782894, Validation Accuracy: 52.52\n",
            "[97/150]: Training Loss: 0.938226883673607, Training Accuracy: 72.542\n",
            "Validation Loss: 2.1242388023692333, Validation Accuracy: 52.65\n",
            "[98/150]: Training Loss: 0.938509788811969, Training Accuracy: 72.476\n",
            "Validation Loss: 2.1135271635784467, Validation Accuracy: 52.82\n",
            "[99/150]: Training Loss: 0.9283110121326983, Training Accuracy: 72.674\n",
            "Validation Loss: 2.125285923860635, Validation Accuracy: 52.06\n",
            "[100/150]: Training Loss: 0.9165082442790956, Training Accuracy: 73.184\n",
            "Validation Loss: 2.1202975777304096, Validation Accuracy: 52.38\n",
            "[101/150]: Training Loss: 0.9109463012584335, Training Accuracy: 72.998\n",
            "Validation Loss: 2.136450658937928, Validation Accuracy: 52.42\n",
            "[102/150]: Training Loss: 0.9098046744418571, Training Accuracy: 73.26\n",
            "Validation Loss: 2.1267288725846893, Validation Accuracy: 52.86\n",
            "[103/150]: Training Loss: 0.8908002294237961, Training Accuracy: 73.838\n",
            "Validation Loss: 2.125086438883642, Validation Accuracy: 52.34\n",
            "[104/150]: Training Loss: 0.8947355315432219, Training Accuracy: 73.496\n",
            "Validation Loss: 2.13778414771815, Validation Accuracy: 52.62\n",
            "[105/150]: Training Loss: 0.8788276913830692, Training Accuracy: 74.106\n",
            "Validation Loss: 2.153025217876313, Validation Accuracy: 52.42\n",
            "[106/150]: Training Loss: 0.8798901442524112, Training Accuracy: 74.082\n",
            "Validation Loss: 2.1569059441803367, Validation Accuracy: 52.12\n",
            "[107/150]: Training Loss: 0.8666944346388282, Training Accuracy: 74.51\n",
            "Validation Loss: 2.1608687851839004, Validation Accuracy: 52.57\n",
            "[108/150]: Training Loss: 0.863055142485882, Training Accuracy: 74.528\n",
            "Validation Loss: 2.152739950805713, Validation Accuracy: 52.64\n",
            "[109/150]: Training Loss: 0.8662346141874943, Training Accuracy: 74.474\n",
            "Validation Loss: 2.14941197823567, Validation Accuracy: 52.71\n",
            "[110/150]: Training Loss: 0.8472307874342365, Training Accuracy: 75.102\n",
            "Validation Loss: 2.1724644390640746, Validation Accuracy: 52.69\n",
            "[111/150]: Training Loss: 0.8462071400469221, Training Accuracy: 75.26\n",
            "Validation Loss: 2.166171987345264, Validation Accuracy: 52.5\n",
            "[112/150]: Training Loss: 0.8393054546221442, Training Accuracy: 75.156\n",
            "Validation Loss: 2.16822886315121, Validation Accuracy: 52.79\n",
            "[113/150]: Training Loss: 0.835232794132379, Training Accuracy: 75.426\n",
            "Validation Loss: 2.1755759412316, Validation Accuracy: 52.8\n",
            "[114/150]: Training Loss: 0.8176318519484357, Training Accuracy: 75.594\n",
            "Validation Loss: 2.1797922325741714, Validation Accuracy: 52.63\n",
            "[115/150]: Training Loss: 0.8166115129618998, Training Accuracy: 75.654\n",
            "Validation Loss: 2.1856938577761316, Validation Accuracy: 52.44\n",
            "[116/150]: Training Loss: 0.8185412460733252, Training Accuracy: 75.768\n",
            "Validation Loss: 2.178807595732865, Validation Accuracy: 52.51\n",
            "[117/150]: Training Loss: 0.819738648203023, Training Accuracy: 75.68\n",
            "Validation Loss: 2.196637267519714, Validation Accuracy: 52.53\n",
            "[118/150]: Training Loss: 0.8139445048463924, Training Accuracy: 76.114\n",
            "Validation Loss: 2.1727140124436395, Validation Accuracy: 52.14\n",
            "[119/150]: Training Loss: 0.804041659359432, Training Accuracy: 76.238\n",
            "Validation Loss: 2.189874280789855, Validation Accuracy: 52.54\n",
            "[120/150]: Training Loss: 0.8070289515473349, Training Accuracy: 75.962\n",
            "Validation Loss: 2.1908302922157725, Validation Accuracy: 52.74\n",
            "[121/150]: Training Loss: 0.7972686002626443, Training Accuracy: 76.462\n",
            "Validation Loss: 2.183206063167305, Validation Accuracy: 52.9\n",
            "[122/150]: Training Loss: 0.7931420375090426, Training Accuracy: 76.7\n",
            "Validation Loss: 2.1991693654637428, Validation Accuracy: 52.88\n",
            "[123/150]: Training Loss: 0.7942516611284002, Training Accuracy: 76.382\n",
            "Validation Loss: 2.1899024916302627, Validation Accuracy: 52.96\n",
            "[124/150]: Training Loss: 0.7901588624243236, Training Accuracy: 76.912\n",
            "Validation Loss: 2.1976229795225106, Validation Accuracy: 52.76\n",
            "[125/150]: Training Loss: 0.784064800881059, Training Accuracy: 76.852\n",
            "Validation Loss: 2.197301295152895, Validation Accuracy: 52.94\n",
            "[126/150]: Training Loss: 0.7810554346236427, Training Accuracy: 77.018\n",
            "Validation Loss: 2.1978831883448704, Validation Accuracy: 53.05\n",
            "[127/150]: Training Loss: 0.7694210947855659, Training Accuracy: 77.242\n",
            "Validation Loss: 2.2037578973041216, Validation Accuracy: 52.8\n",
            "[128/150]: Training Loss: 0.771505500425768, Training Accuracy: 77.276\n",
            "Validation Loss: 2.204603326548437, Validation Accuracy: 52.61\n",
            "[129/150]: Training Loss: 0.7755528422039183, Training Accuracy: 77.05\n",
            "Validation Loss: 2.2066474340523885, Validation Accuracy: 52.48\n",
            "[130/150]: Training Loss: 0.7633897851190299, Training Accuracy: 77.462\n",
            "Validation Loss: 2.20657627294018, Validation Accuracy: 52.87\n",
            "[131/150]: Training Loss: 0.7619557766734487, Training Accuracy: 77.74\n",
            "Validation Loss: 2.2119038287241746, Validation Accuracy: 52.87\n",
            "[132/150]: Training Loss: 0.7639070795015301, Training Accuracy: 77.628\n",
            "Validation Loss: 2.214540675946861, Validation Accuracy: 52.93\n",
            "[133/150]: Training Loss: 0.7627752876800039, Training Accuracy: 77.624\n",
            "Validation Loss: 2.2126305232382126, Validation Accuracy: 52.92\n",
            "[134/150]: Training Loss: 0.762916150681503, Training Accuracy: 77.468\n",
            "Validation Loss: 2.213455740813237, Validation Accuracy: 52.87\n",
            "[135/150]: Training Loss: 0.7556408758434798, Training Accuracy: 77.858\n",
            "Validation Loss: 2.2093218823147427, Validation Accuracy: 52.78\n",
            "[136/150]: Training Loss: 0.7546808309567249, Training Accuracy: 77.614\n",
            "Validation Loss: 2.215512813276546, Validation Accuracy: 52.82\n",
            "[137/150]: Training Loss: 0.7569507613130237, Training Accuracy: 77.856\n",
            "Validation Loss: 2.214977786799145, Validation Accuracy: 52.94\n",
            "[138/150]: Training Loss: 0.7538443226414873, Training Accuracy: 77.938\n",
            "Validation Loss: 2.215168529255375, Validation Accuracy: 52.96\n",
            "[139/150]: Training Loss: 0.7538767649084711, Training Accuracy: 77.666\n",
            "Validation Loss: 2.215025094664021, Validation Accuracy: 52.95\n",
            "[140/150]: Training Loss: 0.7476015420216123, Training Accuracy: 77.98\n",
            "Validation Loss: 2.2151690637989407, Validation Accuracy: 53.11\n",
            "[141/150]: Training Loss: 0.7429782649135346, Training Accuracy: 78.256\n",
            "Validation Loss: 2.214695118794775, Validation Accuracy: 52.91\n",
            "[142/150]: Training Loss: 0.7340887488077974, Training Accuracy: 78.538\n",
            "Validation Loss: 2.216404147968171, Validation Accuracy: 53.08\n",
            "[143/150]: Training Loss: 0.7499228092029576, Training Accuracy: 78.16\n",
            "Validation Loss: 2.216663356799229, Validation Accuracy: 52.99\n",
            "[144/150]: Training Loss: 0.739901978646398, Training Accuracy: 78.208\n",
            "Validation Loss: 2.216373413231722, Validation Accuracy: 53.03\n",
            "[145/150]: Training Loss: 0.7356343204560487, Training Accuracy: 78.332\n",
            "Validation Loss: 2.21599667087482, Validation Accuracy: 52.82\n",
            "[146/150]: Training Loss: 0.7417128108575216, Training Accuracy: 78.1\n",
            "Validation Loss: 2.216853774277268, Validation Accuracy: 53.06\n",
            "[147/150]: Training Loss: 0.7406589664385447, Training Accuracy: 78.444\n",
            "Validation Loss: 2.2168655562552675, Validation Accuracy: 52.95\n",
            "[148/150]: Training Loss: 0.7310213162694745, Training Accuracy: 78.62\n",
            "Validation Loss: 2.216719139913085, Validation Accuracy: 52.99\n",
            "[149/150]: Training Loss: 0.7304428781923431, Training Accuracy: 78.478\n",
            "Validation Loss: 2.216782635943905, Validation Accuracy: 53.01\n",
            "[150/150]: Training Loss: 0.7461780087493569, Training Accuracy: 78.148\n",
            "Validation Loss: 2.2168066478838586, Validation Accuracy: 53.01\n",
            "**********************************************************************\n",
            "Test Loss: 2.2168066478838586, Test Accuracy: 53.01\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▆█▁▁▁▂▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▂▂▂▂▂▂▂</td></tr><tr><td>Test Loss</td><td>▂▁█▆▇▅▆▇▄▅▅▅▅▅▆▅▅▅▅▆▆▆▅▅▅▅▆▆▅▅▅▅▅▅▄▅▅▅▄▄</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>53.01</td></tr><tr><td>Test Loss</td><td>2.21681</td></tr><tr><td>Train Accuracy</td><td>78.148</td></tr><tr><td>Train Loss</td><td>0.74618</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_052010-62vz5e00/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 4.8/(2**5 *1e02) # approximately 15e-04\n",
        "wd = 4e-04\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer = LAMB(model.parameters(), learning_rate=lr, weight_decay=wd)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model, original_train_loader, original_test_loader, original_test_loader, optimizer, scheduler, criterion, device, optimizer_name='LAMB', hyperparameters=hyperparameters, is_wandb = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 512\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_055120-629ppi9i</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/629ppi9i' target=\"_blank\">batch_size=512 learning_rate=0.0004242640687119285 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/629ppi9i' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/629ppi9i</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.548603617415136, Training Accuracy: 2.498\n",
            "Validation Loss: 4.416820383071899, Validation Accuracy: 4.51\n",
            "[2/150]: Training Loss: 4.243599555930313, Training Accuracy: 5.9\n",
            "Validation Loss: 4.063300430774689, Validation Accuracy: 8.11\n",
            "[3/150]: Training Loss: 4.025548063978857, Training Accuracy: 8.684\n",
            "Validation Loss: 3.9094903230667115, Validation Accuracy: 10.6\n",
            "[4/150]: Training Loss: 3.9005869870283165, Training Accuracy: 10.854\n",
            "Validation Loss: 3.7815954089164734, Validation Accuracy: 13.47\n",
            "[5/150]: Training Loss: 3.7978148922628288, Training Accuracy: 12.58\n",
            "Validation Loss: 3.688620662689209, Validation Accuracy: 14.4\n",
            "[6/150]: Training Loss: 3.708504837386462, Training Accuracy: 14.016\n",
            "Validation Loss: 3.5979228973388673, Validation Accuracy: 15.97\n",
            "[7/150]: Training Loss: 3.6287196242079442, Training Accuracy: 15.174\n",
            "Validation Loss: 3.5210944056510924, Validation Accuracy: 17.53\n",
            "[8/150]: Training Loss: 3.5536105267855587, Training Accuracy: 16.508\n",
            "Validation Loss: 3.4404045224189757, Validation Accuracy: 19.09\n",
            "[9/150]: Training Loss: 3.4805082763944353, Training Accuracy: 17.65\n",
            "Validation Loss: 3.376018834114075, Validation Accuracy: 19.85\n",
            "[10/150]: Training Loss: 3.4161258960256773, Training Accuracy: 18.91\n",
            "Validation Loss: 3.303411877155304, Validation Accuracy: 21.76\n",
            "[11/150]: Training Loss: 3.3596596231265945, Training Accuracy: 19.954\n",
            "Validation Loss: 3.2550312638282777, Validation Accuracy: 22.38\n",
            "[12/150]: Training Loss: 3.299455146400296, Training Accuracy: 20.792\n",
            "Validation Loss: 3.2068899393081667, Validation Accuracy: 23.12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Exception ignored in:     Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        self._shutdown_workers()Traceback (most recent call last):\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "    \n",
            "self._shutdown_workers()AssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():    : \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child processif w.is_alive():    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    AssertionError\n",
            ": assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
            "\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        if w.is_alive():\n",
            "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "if w.is_alive():AssertionError: can only test a child process\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionErrorTraceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            ":     can only test a child processself._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40><function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    \n",
            "self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionErrorAssertionError: : can only test a child processcan only test a child process\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[13/150]: Training Loss: 3.2494236060551236, Training Accuracy: 21.83\n",
            "Validation Loss: 3.150032651424408, Validation Accuracy: 24.52\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:     assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "AssertionError: can only test a child process\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    : can only test a child processself._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>can only test a child process\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    Exception ignored in: Exception ignored in: self._shutdown_workers()\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40><function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "Traceback (most recent call last):\n",
            "    Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        \n",
            "self._shutdown_workers()self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "            assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():if w.is_alive():Exception ignored in: \n",
            "\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>        \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "\n",
            "AssertionErrorAssertionError: assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            ": can only test a child process    can only test a child process\n",
            "AssertionErrorself._shutdown_workers()\n",
            "\n",
            ": \n",
            "can only test a child process\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[14/150]: Training Loss: 3.2080983264105662, Training Accuracy: 22.638\n",
            "Validation Loss: 3.109050440788269, Validation Accuracy: 24.66\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        self._shutdown_workers()self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "AssertionError: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40><function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "        self._shutdown_workers()  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "self._shutdown_workers()\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():        \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():if w.is_alive():    \n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'        \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError: \n",
            "can only test a child process\n",
            "\n",
            "AssertionErrorAssertionError: : can only test a child process\n",
            "can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15/150]: Training Loss: 3.1625750454104677, Training Accuracy: 23.334\n",
            "Validation Loss: 3.048142147064209, Validation Accuracy: 26.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "Exception ignored in:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "AssertionError: can only test a child process\n",
            "    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:         self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "    can only test a child processTraceback (most recent call last):\n",
            "if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "    if w.is_alive():AssertionError: \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child processException ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "\n",
            "Traceback (most recent call last):\n",
            "AssertionErrorException ignored in: :   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    \n",
            "\n",
            "self._shutdown_workers()\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        if w.is_alive():self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "AssertionError    : if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child process    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():    \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "AssertionError    : can only test a child process\n",
            "if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[16/150]: Training Loss: 3.1151485175502542, Training Accuracy: 24.318\n",
            "Validation Loss: 3.019995415210724, Validation Accuracy: 26.75\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child processException ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    \n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        if w.is_alive():\n",
            "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionErrorif w.is_alive():: \n",
            "can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionErrorException ignored in: Exception ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40><function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "can only test a child processTraceback (most recent call last):\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        self._shutdown_workers()Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        self._shutdown_workers()if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "\n",
            "AssertionError: AssertionErrorcan only test a child process: \n",
            "can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[17/150]: Training Loss: 3.074753547201351, Training Accuracy: 25.172\n",
            "Validation Loss: 2.9703970074653627, Validation Accuracy: 27.48\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[18/150]: Training Loss: 3.036428164462654, Training Accuracy: 25.832\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():    Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    \n",
            "\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "    if w.is_alive():self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    \n",
            "if w.is_alive():    \n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "self._shutdown_workers()  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    Exception ignored in: AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "\n",
            ":     if w.is_alive():can only test a child processAssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>: \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "\n",
            "        AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child processTraceback (most recent call last):\n",
            ": if w.is_alive():Exception ignored in: \n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "\n",
            "self._shutdown_workers()\n",
            "    : assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "    self._shutdown_workers()\n",
            "AssertionError: \n",
            "    can only test a child processif w.is_alive():\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: if w.is_alive():can only test a child process\n",
            "\n",
            "Exception ignored in:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "    Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError:     can only test a child processself._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 2.91401789188385, Validation Accuracy: 28.63\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        self._shutdown_workers()\n",
            "self._shutdown_workers()  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "AssertionError:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError\n",
            ": Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process    self._shutdown_workers()\n",
            "Exception ignored in: \n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: self._shutdown_workers()\n",
            "\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "can only test a child process\n",
            "    \n",
            "Traceback (most recent call last):\n",
            "if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    Exception ignored in: self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "AssertionError    if w.is_alive():: \n",
            "\n",
            "can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'    self._shutdown_workers()\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError\n",
            ": \n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    if w.is_alive():self._shutdown_workers()\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child processAssertionError: can only test a child process\n",
            "Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[19/150]: Training Loss: 2.9957546457952384, Training Accuracy: 26.22\n",
            "Validation Loss: 2.8862305998802187, Validation Accuracy: 29.03\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Exception ignored in: Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "AssertionError\n",
            ": can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "AssertionError\n",
            ": Traceback (most recent call last):\n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>can only test a child process\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Exception ignored in: Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Traceback (most recent call last):\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "self._shutdown_workers()AssertionError\n",
            ":     can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()\n",
            "    \n",
            "if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():Exception ignored in: \n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "AssertionError: AssertionError    can only test a child process: \n",
            "can only test a child process\n",
            "self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[20/150]: Training Loss: 2.9593982185636247, Training Accuracy: 27.09\n",
            "Validation Loss: 2.8584514379501345, Validation Accuracy: 29.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Exception ignored in: \n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "    if w.is_alive():\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            ":     can only test a child processif w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "AssertionError:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process    \n",
            "self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    self._shutdown_workers()\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():\n",
            "    self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        self._shutdown_workers()    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():    \n",
            "\n",
            "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():: can only test a child process\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "\n",
            "AssertionError    assert self._parent_pid == os.getpid(), 'can only test a child process': \n",
            "can only test a child processAssertionError\n",
            ": can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[21/150]: Training Loss: 2.9291597142511483, Training Accuracy: 27.756\n",
            "Validation Loss: 2.823378837108612, Validation Accuracy: 30.07\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "AssertionError: Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process    self._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in:     Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "\n",
            "AssertionErrorTraceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Traceback (most recent call last):\n",
            ":   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    can only test a child process    \n",
            "self._shutdown_workers()self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            ":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionErrorException ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>: \n",
            "Traceback (most recent call last):\n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Exception ignored in: \n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>self._shutdown_workers()Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        if w.is_alive():\n",
            "\n",
            "Traceback (most recent call last):\n",
            "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()    \n",
            "\n",
            "if w.is_alive():AssertionError: \n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "        if w.is_alive():\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            ":     assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
            "\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[22/150]: Training Loss: 2.900624696089297, Training Accuracy: 28.334\n",
            "Validation Loss: 2.791938865184784, Validation Accuracy: 31.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    if w.is_alive():self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "AssertionError\n",
            "Traceback (most recent call last):\n",
            ":   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "can only test a child process    self._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "AssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers(): \n",
            "can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "Exception ignored in:     if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in:     <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>assert self._parent_pid == os.getpid(), 'can only test a child process'Exception ignored in:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "AssertionError\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            ":     can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():        \n",
            "self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "\n",
            "self._shutdown_workers()\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'        \n",
            "if w.is_alive():AssertionError: \n",
            "if w.is_alive():can only test a child processException ignored in: \n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    Traceback (most recent call last):\n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    \n",
            "AssertionErrorself._shutdown_workers()\n",
            ":   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "AssertionErrorcan only test a child process    \n",
            "if w.is_alive():: can only test a child process\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[23/150]: Training Loss: 2.8752694835468215, Training Accuracy: 28.62\n",
            "Validation Loss: 2.7719114065170287, Validation Accuracy: 30.97\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40><function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "          File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        self._shutdown_workers()assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "    \n",
            "Exception ignored in:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "AssertionErrorException ignored in: : <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "can only test a child processTraceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    \n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "    self._shutdown_workers()\n",
            "\n",
            "if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "            if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'self._shutdown_workers()\n",
            "\n",
            "\n",
            "Exception ignored in: AssertionError\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>can only test a child process:     \n",
            "        Exception ignored in: Traceback (most recent call last):\n",
            "\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():\n",
            "\n",
            "Exception ignored in: \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'Traceback (most recent call last):\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "AssertionError\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    : can only test a child process    assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            "self._shutdown_workers()    \n",
            "Traceback (most recent call last):\n",
            ": \n",
            "AssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()can only test a child process: \n",
            "      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "can only test a child process\n",
            "    if w.is_alive():\n",
            "    self._shutdown_workers()\n",
            "\n",
            "if w.is_alive():  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            "AssertionError: : \n",
            "can only test a child processcan only test a child process\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[24/150]: Training Loss: 2.844754442876699, Training Accuracy: 29.358\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()Exception ignored in: \n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():Exception ignored in:     \n",
            "    Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>self._shutdown_workers()  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "self._shutdown_workers()    \n",
            "\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Traceback (most recent call last):\n",
            "\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "\n",
            "        Traceback (most recent call last):\n",
            "AssertionError  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "if w.is_alive():    \n",
            "\n",
            ": Exception ignored in:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():    can only test a child process  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():    \n",
            "\n",
            "\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionError\n",
            "if w.is_alive():    \n",
            "AssertionError\n",
            "self._shutdown_workers(): : \n",
            "AssertionErrorcan only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "Exception ignored in: \n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>    if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Traceback (most recent call last):\n",
            "\n",
            ": can only test a child process  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "can only test a child process    \n",
            "\n",
            "self._shutdown_workers()AssertionError:     \n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "if w.is_alive():\n",
            "\n",
            "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            ":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>AssertionError\n",
            "Traceback (most recent call last):\n",
            ":   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    can only test a child processself._shutdown_workers()\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Loss: 2.754125702381134, Validation Accuracy: 31.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    if w.is_alive():\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Exception ignored in: Exception ignored in: \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>Traceback (most recent call last):\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>\n",
            "\n",
            "\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "self._shutdown_workers()Traceback (most recent call last):\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "self._shutdown_workers()      File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "Exception ignored in:   File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        \n",
            "    <function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>if w.is_alive():    \n",
            "\n",
            "if w.is_alive():Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Exception ignored in:     \n",
            "<function _MultiProcessingDataLoaderIter.__del__ at 0x74777b725b40>assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "\n",
            "self._shutdown_workers()self._shutdown_workers()AssertionErrorTraceback (most recent call last):\n",
            "    \n",
            ": can only test a child processself._shutdown_workers()\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "self._shutdown_workers()\n",
            "\n",
            "\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "        self._shutdown_workers()        assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "if w.is_alive():\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "AssertionErrorif w.is_alive():        \n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            ": if w.is_alive():  File \"/home/ali/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
            "    \n",
            "can only test a child process\n",
            "      File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "if w.is_alive():\n",
            "\n",
            "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            ":   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    \n",
            "can only test a child processAssertionErrorAssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "can only test a child process\n",
            ": \n",
            "AssertionErrorcan only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "AssertionError: : can only test a child process\n",
            "can only test a child process\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[25/150]: Training Loss: 2.8207734166359413, Training Accuracy: 29.844\n",
            "Validation Loss: 2.705601465702057, Validation Accuracy: 32.25\n",
            "[26/150]: Training Loss: 2.794313367532224, Training Accuracy: 30.218\n",
            "Validation Loss: 2.687318742275238, Validation Accuracy: 32.36\n",
            "[27/150]: Training Loss: 2.7672535643285636, Training Accuracy: 31.0\n",
            "Validation Loss: 2.6692835092544556, Validation Accuracy: 33.62\n",
            "[28/150]: Training Loss: 2.7328374750760136, Training Accuracy: 31.594\n",
            "Validation Loss: 2.644136917591095, Validation Accuracy: 33.92\n",
            "[29/150]: Training Loss: 2.712839340677067, Training Accuracy: 32.242\n",
            "Validation Loss: 2.61125727891922, Validation Accuracy: 34.29\n",
            "[30/150]: Training Loss: 2.689220988020605, Training Accuracy: 32.716\n",
            "Validation Loss: 2.597063958644867, Validation Accuracy: 34.51\n",
            "[31/150]: Training Loss: 2.6592776678046404, Training Accuracy: 33.256\n",
            "Validation Loss: 2.5820674300193787, Validation Accuracy: 35.0\n",
            "[32/150]: Training Loss: 2.640095056319723, Training Accuracy: 33.314\n",
            "Validation Loss: 2.54053658246994, Validation Accuracy: 35.24\n",
            "[33/150]: Training Loss: 2.6196285121294918, Training Accuracy: 33.868\n",
            "Validation Loss: 2.5317852973937987, Validation Accuracy: 36.02\n",
            "[34/150]: Training Loss: 2.5938801741113466, Training Accuracy: 34.496\n",
            "Validation Loss: 2.5169005155563355, Validation Accuracy: 36.18\n",
            "[35/150]: Training Loss: 2.5702837875911166, Training Accuracy: 34.798\n",
            "Validation Loss: 2.4821427941322325, Validation Accuracy: 36.45\n",
            "[36/150]: Training Loss: 2.5516227970317917, Training Accuracy: 35.478\n",
            "Validation Loss: 2.4792662143707274, Validation Accuracy: 36.78\n",
            "[37/150]: Training Loss: 2.536287232321136, Training Accuracy: 35.748\n",
            "Validation Loss: 2.4615839600563048, Validation Accuracy: 36.91\n",
            "[38/150]: Training Loss: 2.518194748430836, Training Accuracy: 36.15\n",
            "Validation Loss: 2.4392840027809144, Validation Accuracy: 37.61\n",
            "[39/150]: Training Loss: 2.4998596444421883, Training Accuracy: 36.174\n",
            "Validation Loss: 2.4394460558891295, Validation Accuracy: 37.83\n",
            "[40/150]: Training Loss: 2.478595862583238, Training Accuracy: 36.792\n",
            "Validation Loss: 2.4048784017562865, Validation Accuracy: 38.4\n",
            "[41/150]: Training Loss: 2.4725446628064525, Training Accuracy: 36.98\n",
            "Validation Loss: 2.419749367237091, Validation Accuracy: 37.61\n",
            "[42/150]: Training Loss: 2.447700734041175, Training Accuracy: 37.712\n",
            "Validation Loss: 2.397221338748932, Validation Accuracy: 38.39\n",
            "[43/150]: Training Loss: 2.437787973150915, Training Accuracy: 37.604\n",
            "Validation Loss: 2.376715588569641, Validation Accuracy: 39.06\n",
            "[44/150]: Training Loss: 2.41146419486221, Training Accuracy: 38.236\n",
            "Validation Loss: 2.383975315093994, Validation Accuracy: 38.93\n",
            "[45/150]: Training Loss: 2.400857081218642, Training Accuracy: 38.53\n",
            "Validation Loss: 2.3536798119544984, Validation Accuracy: 39.75\n",
            "[46/150]: Training Loss: 2.3903429873135624, Training Accuracy: 38.942\n",
            "Validation Loss: 2.3401002407073976, Validation Accuracy: 39.98\n",
            "[47/150]: Training Loss: 2.3778630105816587, Training Accuracy: 38.864\n",
            "Validation Loss: 2.3238447666168214, Validation Accuracy: 40.35\n",
            "[48/150]: Training Loss: 2.3627792669802297, Training Accuracy: 39.344\n",
            "Validation Loss: 2.3337461233139036, Validation Accuracy: 40.21\n",
            "[49/150]: Training Loss: 2.341205180907736, Training Accuracy: 39.73\n",
            "Validation Loss: 2.31098872423172, Validation Accuracy: 40.22\n",
            "[50/150]: Training Loss: 2.334307079412499, Training Accuracy: 40.016\n",
            "Validation Loss: 2.315126097202301, Validation Accuracy: 40.58\n",
            "[51/150]: Training Loss: 2.3188869831513386, Training Accuracy: 40.006\n",
            "Validation Loss: 2.295890510082245, Validation Accuracy: 40.87\n",
            "[52/150]: Training Loss: 2.305944788212679, Training Accuracy: 40.576\n",
            "Validation Loss: 2.2844882011413574, Validation Accuracy: 41.3\n",
            "[53/150]: Training Loss: 2.3018058027539934, Training Accuracy: 40.752\n",
            "Validation Loss: 2.2773577690124513, Validation Accuracy: 41.28\n",
            "[54/150]: Training Loss: 2.2820585503870126, Training Accuracy: 41.126\n",
            "Validation Loss: 2.265846014022827, Validation Accuracy: 41.54\n",
            "[55/150]: Training Loss: 2.2734045617434444, Training Accuracy: 41.172\n",
            "Validation Loss: 2.2698575258255005, Validation Accuracy: 41.55\n",
            "[56/150]: Training Loss: 2.268057511777294, Training Accuracy: 41.382\n",
            "Validation Loss: 2.248699498176575, Validation Accuracy: 42.0\n",
            "[57/150]: Training Loss: 2.2563396935560265, Training Accuracy: 41.77\n",
            "Validation Loss: 2.242726683616638, Validation Accuracy: 41.71\n",
            "[58/150]: Training Loss: 2.2405153902209536, Training Accuracy: 41.894\n",
            "Validation Loss: 2.2411133885383605, Validation Accuracy: 42.32\n",
            "[59/150]: Training Loss: 2.233138741279135, Training Accuracy: 41.998\n",
            "Validation Loss: 2.2358715295791627, Validation Accuracy: 42.37\n",
            "[60/150]: Training Loss: 2.2201552464037526, Training Accuracy: 42.37\n",
            "Validation Loss: 2.2211275577545164, Validation Accuracy: 42.25\n",
            "[61/150]: Training Loss: 2.2125545107588476, Training Accuracy: 42.374\n",
            "Validation Loss: 2.22549809217453, Validation Accuracy: 42.04\n",
            "[62/150]: Training Loss: 2.2010000238613205, Training Accuracy: 42.592\n",
            "Validation Loss: 2.209044873714447, Validation Accuracy: 42.73\n",
            "[63/150]: Training Loss: 2.189410664597336, Training Accuracy: 43.022\n",
            "Validation Loss: 2.2072029948234557, Validation Accuracy: 43.21\n",
            "[64/150]: Training Loss: 2.181582011738602, Training Accuracy: 43.196\n",
            "Validation Loss: 2.211189329624176, Validation Accuracy: 42.98\n",
            "[65/150]: Training Loss: 2.17209978006324, Training Accuracy: 43.494\n",
            "Validation Loss: 2.1931957960128785, Validation Accuracy: 43.09\n",
            "[66/150]: Training Loss: 2.159282922744751, Training Accuracy: 43.83\n",
            "Validation Loss: 2.185472071170807, Validation Accuracy: 43.41\n",
            "[67/150]: Training Loss: 2.1514484091680877, Training Accuracy: 43.87\n",
            "Validation Loss: 2.1950502753257752, Validation Accuracy: 43.24\n",
            "[68/150]: Training Loss: 2.146765425497172, Training Accuracy: 43.912\n",
            "Validation Loss: 2.1978687405586244, Validation Accuracy: 42.73\n",
            "[69/150]: Training Loss: 2.1396148119653975, Training Accuracy: 44.17\n",
            "Validation Loss: 2.175988519191742, Validation Accuracy: 43.64\n",
            "[70/150]: Training Loss: 2.124094669916192, Training Accuracy: 44.388\n",
            "Validation Loss: 2.1625670552253724, Validation Accuracy: 44.15\n",
            "[71/150]: Training Loss: 2.118907108598826, Training Accuracy: 44.714\n",
            "Validation Loss: 2.1682013154029844, Validation Accuracy: 44.16\n",
            "[72/150]: Training Loss: 2.1218399077045675, Training Accuracy: 44.516\n",
            "Validation Loss: 2.1531296133995057, Validation Accuracy: 44.24\n",
            "[73/150]: Training Loss: 2.103327241479134, Training Accuracy: 44.822\n",
            "Validation Loss: 2.149845826625824, Validation Accuracy: 44.42\n",
            "[74/150]: Training Loss: 2.1007259342135214, Training Accuracy: 45.092\n",
            "Validation Loss: 2.149185609817505, Validation Accuracy: 44.29\n",
            "[75/150]: Training Loss: 2.0860105752944946, Training Accuracy: 45.244\n",
            "Validation Loss: 2.153393119573593, Validation Accuracy: 44.03\n",
            "[76/150]: Training Loss: 2.0842377008224022, Training Accuracy: 45.118\n",
            "Validation Loss: 2.1478596448898317, Validation Accuracy: 44.41\n",
            "[77/150]: Training Loss: 2.073838080678667, Training Accuracy: 45.74\n",
            "Validation Loss: 2.1420213758945463, Validation Accuracy: 44.47\n",
            "[78/150]: Training Loss: 2.064723936878905, Training Accuracy: 45.914\n",
            "Validation Loss: 2.1414406061172486, Validation Accuracy: 44.65\n",
            "[79/150]: Training Loss: 2.068708761614196, Training Accuracy: 45.76\n",
            "Validation Loss: 2.129684728384018, Validation Accuracy: 44.69\n",
            "[80/150]: Training Loss: 2.05464696640871, Training Accuracy: 45.966\n",
            "Validation Loss: 2.1296287894248964, Validation Accuracy: 44.82\n",
            "[81/150]: Training Loss: 2.048685365793656, Training Accuracy: 45.972\n",
            "Validation Loss: 2.1220090091228485, Validation Accuracy: 45.16\n",
            "[82/150]: Training Loss: 2.043823238538236, Training Accuracy: 46.17\n",
            "Validation Loss: 2.121674305200577, Validation Accuracy: 44.82\n",
            "[83/150]: Training Loss: 2.0398333644380373, Training Accuracy: 46.582\n",
            "Validation Loss: 2.1206820785999296, Validation Accuracy: 45.25\n",
            "[84/150]: Training Loss: 2.0399894969803944, Training Accuracy: 46.332\n",
            "Validation Loss: 2.117530012130737, Validation Accuracy: 45.12\n",
            "[85/150]: Training Loss: 2.020768941665182, Training Accuracy: 46.63\n",
            "Validation Loss: 2.116836541891098, Validation Accuracy: 45.3\n",
            "[86/150]: Training Loss: 2.0279355182939645, Training Accuracy: 46.574\n",
            "Validation Loss: 2.107444965839386, Validation Accuracy: 45.62\n",
            "[87/150]: Training Loss: 2.020287135425879, Training Accuracy: 46.76\n",
            "Validation Loss: 2.10392941236496, Validation Accuracy: 45.62\n",
            "[88/150]: Training Loss: 2.0118079963995488, Training Accuracy: 46.982\n",
            "Validation Loss: 2.10864252448082, Validation Accuracy: 45.04\n",
            "[89/150]: Training Loss: 2.0041175241373024, Training Accuracy: 47.0\n",
            "Validation Loss: 2.1043585777282714, Validation Accuracy: 45.51\n",
            "[90/150]: Training Loss: 1.997280935851895, Training Accuracy: 47.278\n",
            "Validation Loss: 2.090637058019638, Validation Accuracy: 45.85\n",
            "[91/150]: Training Loss: 1.9916248126905791, Training Accuracy: 47.574\n",
            "Validation Loss: 2.0972966492176055, Validation Accuracy: 45.5\n",
            "[92/150]: Training Loss: 1.9858960862062416, Training Accuracy: 47.498\n",
            "Validation Loss: 2.089981472492218, Validation Accuracy: 45.74\n",
            "[93/150]: Training Loss: 1.981804991255001, Training Accuracy: 47.632\n",
            "Validation Loss: 2.0950992584228514, Validation Accuracy: 45.79\n",
            "[94/150]: Training Loss: 1.9809188794116586, Training Accuracy: 47.736\n",
            "Validation Loss: 2.0917014718055724, Validation Accuracy: 45.81\n",
            "[95/150]: Training Loss: 1.9745077296179168, Training Accuracy: 48.028\n",
            "Validation Loss: 2.0903584539890288, Validation Accuracy: 45.82\n",
            "[96/150]: Training Loss: 1.9678826964631373, Training Accuracy: 48.062\n",
            "Validation Loss: 2.085793948173523, Validation Accuracy: 45.88\n",
            "[97/150]: Training Loss: 1.969686961903864, Training Accuracy: 47.974\n",
            "Validation Loss: 2.0842667639255525, Validation Accuracy: 45.94\n",
            "[98/150]: Training Loss: 1.967830895161142, Training Accuracy: 48.11\n",
            "Validation Loss: 2.0819462299346925, Validation Accuracy: 45.77\n",
            "[99/150]: Training Loss: 1.9539092487218428, Training Accuracy: 48.09\n",
            "Validation Loss: 2.0695468485355377, Validation Accuracy: 46.38\n",
            "[100/150]: Training Loss: 1.9470370752470834, Training Accuracy: 48.734\n",
            "Validation Loss: 2.080887311697006, Validation Accuracy: 46.05\n",
            "[101/150]: Training Loss: 1.9548694807655957, Training Accuracy: 48.234\n",
            "Validation Loss: 2.071767729520798, Validation Accuracy: 46.49\n",
            "[102/150]: Training Loss: 1.9464308716812913, Training Accuracy: 48.376\n",
            "Validation Loss: 2.0714339315891266, Validation Accuracy: 46.27\n",
            "[103/150]: Training Loss: 1.9454800291937224, Training Accuracy: 48.468\n",
            "Validation Loss: 2.069366031885147, Validation Accuracy: 46.16\n",
            "[104/150]: Training Loss: 1.9380488541661476, Training Accuracy: 48.806\n",
            "Validation Loss: 2.073972535133362, Validation Accuracy: 46.41\n",
            "[105/150]: Training Loss: 1.9342538422467757, Training Accuracy: 48.66\n",
            "Validation Loss: 2.068258821964264, Validation Accuracy: 46.17\n",
            "[106/150]: Training Loss: 1.937512426960225, Training Accuracy: 48.806\n",
            "Validation Loss: 2.065845030546188, Validation Accuracy: 46.3\n",
            "[107/150]: Training Loss: 1.930478497427337, Training Accuracy: 48.82\n",
            "Validation Loss: 2.0694516718387606, Validation Accuracy: 46.33\n",
            "[108/150]: Training Loss: 1.9285986253193446, Training Accuracy: 48.574\n",
            "Validation Loss: 2.0660508811473846, Validation Accuracy: 46.56\n",
            "[109/150]: Training Loss: 1.9226828570268593, Training Accuracy: 48.984\n",
            "Validation Loss: 2.065355122089386, Validation Accuracy: 46.38\n",
            "[110/150]: Training Loss: 1.9163579600197929, Training Accuracy: 49.164\n",
            "Validation Loss: 2.0628578305244445, Validation Accuracy: 46.46\n",
            "[111/150]: Training Loss: 1.9168027821852236, Training Accuracy: 49.252\n",
            "Validation Loss: 2.0593102276325226, Validation Accuracy: 46.63\n",
            "[112/150]: Training Loss: 1.9165059583527702, Training Accuracy: 49.328\n",
            "Validation Loss: 2.0612095296382904, Validation Accuracy: 46.65\n",
            "[113/150]: Training Loss: 1.9075169830906147, Training Accuracy: 49.53\n",
            "Validation Loss: 2.0582003355026246, Validation Accuracy: 46.64\n",
            "[114/150]: Training Loss: 1.9039872094076506, Training Accuracy: 49.556\n",
            "Validation Loss: 2.057022488117218, Validation Accuracy: 46.46\n",
            "[115/150]: Training Loss: 1.9039045523624032, Training Accuracy: 49.45\n",
            "Validation Loss: 2.058062309026718, Validation Accuracy: 46.66\n",
            "[116/150]: Training Loss: 1.9059245598559478, Training Accuracy: 49.46\n",
            "Validation Loss: 2.0549796164035796, Validation Accuracy: 46.98\n",
            "[117/150]: Training Loss: 1.909138171040282, Training Accuracy: 49.394\n",
            "Validation Loss: 2.0545377254486086, Validation Accuracy: 46.76\n",
            "[118/150]: Training Loss: 1.9025853884463408, Training Accuracy: 49.46\n",
            "Validation Loss: 2.0527754604816435, Validation Accuracy: 46.83\n",
            "[119/150]: Training Loss: 1.8941444937063723, Training Accuracy: 49.826\n",
            "Validation Loss: 2.055216532945633, Validation Accuracy: 46.61\n",
            "[120/150]: Training Loss: 1.8918506807210493, Training Accuracy: 49.522\n",
            "Validation Loss: 2.0529846370220186, Validation Accuracy: 46.66\n",
            "[121/150]: Training Loss: 1.8913645014470937, Training Accuracy: 49.806\n",
            "Validation Loss: 2.053318554162979, Validation Accuracy: 46.87\n",
            "[122/150]: Training Loss: 1.8967320079706154, Training Accuracy: 49.708\n",
            "Validation Loss: 2.0482302486896513, Validation Accuracy: 46.95\n",
            "[123/150]: Training Loss: 1.8930062055587769, Training Accuracy: 49.736\n",
            "Validation Loss: 2.0486309468746184, Validation Accuracy: 46.98\n",
            "[124/150]: Training Loss: 1.8859221606838459, Training Accuracy: 49.948\n",
            "Validation Loss: 2.047211617231369, Validation Accuracy: 46.98\n",
            "[125/150]: Training Loss: 1.8830693084366468, Training Accuracy: 50.07\n",
            "Validation Loss: 2.0473871648311617, Validation Accuracy: 46.98\n",
            "[126/150]: Training Loss: 1.8846859773811029, Training Accuracy: 50.09\n",
            "Validation Loss: 2.04728844165802, Validation Accuracy: 47.16\n",
            "[127/150]: Training Loss: 1.8857315279999558, Training Accuracy: 49.906\n",
            "Validation Loss: 2.046469569206238, Validation Accuracy: 47.04\n",
            "[128/150]: Training Loss: 1.8859595972664502, Training Accuracy: 49.9\n",
            "Validation Loss: 2.046849066019058, Validation Accuracy: 46.92\n",
            "[129/150]: Training Loss: 1.8825436745371138, Training Accuracy: 49.864\n",
            "Validation Loss: 2.048234748840332, Validation Accuracy: 46.97\n",
            "[130/150]: Training Loss: 1.8798605483405444, Training Accuracy: 49.902\n",
            "Validation Loss: 2.045301067829132, Validation Accuracy: 47.01\n",
            "[131/150]: Training Loss: 1.8820846980931807, Training Accuracy: 49.88\n",
            "Validation Loss: 2.0458612203598023, Validation Accuracy: 47.06\n",
            "[132/150]: Training Loss: 1.8795445658722703, Training Accuracy: 50.058\n",
            "Validation Loss: 2.0437388598918913, Validation Accuracy: 47.08\n",
            "[133/150]: Training Loss: 1.876546278291819, Training Accuracy: 50.138\n",
            "Validation Loss: 2.04643372297287, Validation Accuracy: 46.93\n",
            "[134/150]: Training Loss: 1.874571469365334, Training Accuracy: 50.216\n",
            "Validation Loss: 2.0444207012653353, Validation Accuracy: 46.99\n",
            "[135/150]: Training Loss: 1.878583361907881, Training Accuracy: 50.102\n",
            "Validation Loss: 2.043903875350952, Validation Accuracy: 47.0\n",
            "[136/150]: Training Loss: 1.8731432812554496, Training Accuracy: 50.264\n",
            "Validation Loss: 2.043297988176346, Validation Accuracy: 47.04\n",
            "[137/150]: Training Loss: 1.8719240147240308, Training Accuracy: 50.256\n",
            "Validation Loss: 2.044253832101822, Validation Accuracy: 46.85\n",
            "[138/150]: Training Loss: 1.8687705020515286, Training Accuracy: 50.026\n",
            "Validation Loss: 2.0435604214668275, Validation Accuracy: 47.0\n",
            "[139/150]: Training Loss: 1.8780759548654362, Training Accuracy: 50.126\n",
            "Validation Loss: 2.0427211821079254, Validation Accuracy: 47.05\n",
            "[140/150]: Training Loss: 1.8736839489061006, Training Accuracy: 50.238\n",
            "Validation Loss: 2.0425303280353546, Validation Accuracy: 47.02\n",
            "[141/150]: Training Loss: 1.8668698303553524, Training Accuracy: 50.304\n",
            "Validation Loss: 2.042210203409195, Validation Accuracy: 47.06\n",
            "[142/150]: Training Loss: 1.872799194588953, Training Accuracy: 50.112\n",
            "Validation Loss: 2.0424644231796263, Validation Accuracy: 46.97\n",
            "[143/150]: Training Loss: 1.8772344613561824, Training Accuracy: 50.41\n",
            "Validation Loss: 2.0423132359981535, Validation Accuracy: 47.03\n",
            "[144/150]: Training Loss: 1.8697663484787455, Training Accuracy: 50.348\n",
            "Validation Loss: 2.042390114068985, Validation Accuracy: 46.96\n",
            "[145/150]: Training Loss: 1.8656348148170783, Training Accuracy: 50.32\n",
            "Validation Loss: 2.0424346685409547, Validation Accuracy: 47.0\n",
            "[146/150]: Training Loss: 1.8737119424099824, Training Accuracy: 50.538\n",
            "Validation Loss: 2.0425304055213926, Validation Accuracy: 47.04\n",
            "[147/150]: Training Loss: 1.8692006566086594, Training Accuracy: 50.398\n",
            "Validation Loss: 2.0425583481788636, Validation Accuracy: 46.95\n",
            "[148/150]: Training Loss: 1.8687953511062934, Training Accuracy: 50.346\n",
            "Validation Loss: 2.042505383491516, Validation Accuracy: 46.94\n",
            "[149/150]: Training Loss: 1.871606239250728, Training Accuracy: 50.198\n",
            "Validation Loss: 2.042434561252594, Validation Accuracy: 46.95\n",
            "[150/150]: Training Loss: 1.866833773194527, Training Accuracy: 50.392\n",
            "Validation Loss: 2.0424169659614564, Validation Accuracy: 46.95\n",
            "**********************************************************************\n",
            "Test Loss: 2.0424169659614564, Test Accuracy: 46.95\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▂▁▂▅▃▅█▇▆▇▇█▇▆▅▇▆▆▇</td></tr><tr><td>Test Loss</td><td>▆█▄▂▁▂▂▁▁▃▂▂▂▂▃▄▃▃▃▂</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>46.95</td></tr><tr><td>Test Loss</td><td>2.04242</td></tr><tr><td>Train Accuracy</td><td>50.392</td></tr><tr><td>Train Loss</td><td>1.86683</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=0.0004242640687119285 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/629ppi9i' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/629ppi9i</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_055120-629ppi9i/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 1024\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_062343-f6zj2dy6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/f6zj2dy6' target=\"_blank\">batch_size=1024 learning_rate=0.0006 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/f6zj2dy6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/f6zj2dy6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.590637878495819, Training Accuracy: 1.992\n",
            "Validation Loss: 4.556918144226074, Validation Accuracy: 3.09\n",
            "[2/150]: Training Loss: 4.497767944725192, Training Accuracy: 3.494\n",
            "Validation Loss: 4.4074239253997805, Validation Accuracy: 4.76\n",
            "[3/150]: Training Loss: 4.326443146686165, Training Accuracy: 4.914\n",
            "Validation Loss: 4.206428670883179, Validation Accuracy: 6.39\n",
            "[4/150]: Training Loss: 4.1541692480749015, Training Accuracy: 7.096\n",
            "Validation Loss: 4.048169994354248, Validation Accuracy: 8.63\n",
            "[5/150]: Training Loss: 4.041794528766554, Training Accuracy: 8.766\n",
            "Validation Loss: 3.943867230415344, Validation Accuracy: 10.57\n",
            "[6/150]: Training Loss: 3.9511346038506954, Training Accuracy: 10.2\n",
            "Validation Loss: 3.8476075649261476, Validation Accuracy: 12.17\n",
            "[7/150]: Training Loss: 3.8759255409240723, Training Accuracy: 11.486\n",
            "Validation Loss: 3.772109270095825, Validation Accuracy: 13.26\n",
            "[8/150]: Training Loss: 3.8086607310236715, Training Accuracy: 12.306\n",
            "Validation Loss: 3.715940999984741, Validation Accuracy: 14.08\n",
            "[9/150]: Training Loss: 3.7540337260888546, Training Accuracy: 13.228\n",
            "Validation Loss: 3.6463849544525146, Validation Accuracy: 15.81\n",
            "[10/150]: Training Loss: 3.70257940097731, Training Accuracy: 14.254\n",
            "Validation Loss: 3.6008975744247436, Validation Accuracy: 16.58\n",
            "[11/150]: Training Loss: 3.6446368256393744, Training Accuracy: 15.076\n",
            "Validation Loss: 3.537614035606384, Validation Accuracy: 17.38\n",
            "[12/150]: Training Loss: 3.5920012045879752, Training Accuracy: 16.168\n",
            "Validation Loss: 3.498702359199524, Validation Accuracy: 17.75\n",
            "[13/150]: Training Loss: 3.5408709195195414, Training Accuracy: 16.708\n",
            "Validation Loss: 3.435236358642578, Validation Accuracy: 19.14\n",
            "[14/150]: Training Loss: 3.4937274747965286, Training Accuracy: 17.706\n",
            "Validation Loss: 3.388493609428406, Validation Accuracy: 19.67\n",
            "[15/150]: Training Loss: 3.452468677442901, Training Accuracy: 18.38\n",
            "Validation Loss: 3.3595022439956663, Validation Accuracy: 20.31\n",
            "[16/150]: Training Loss: 3.41387711252485, Training Accuracy: 19.108\n",
            "Validation Loss: 3.3140936374664305, Validation Accuracy: 21.56\n",
            "[17/150]: Training Loss: 3.3753939258808994, Training Accuracy: 19.74\n",
            "Validation Loss: 3.275451421737671, Validation Accuracy: 22.49\n",
            "[18/150]: Training Loss: 3.338460786002023, Training Accuracy: 20.488\n",
            "Validation Loss: 3.233375310897827, Validation Accuracy: 23.1\n",
            "[19/150]: Training Loss: 3.3114829841925175, Training Accuracy: 21.016\n",
            "Validation Loss: 3.2035989284515383, Validation Accuracy: 23.04\n",
            "[20/150]: Training Loss: 3.2761189499679877, Training Accuracy: 21.566\n",
            "Validation Loss: 3.177353930473328, Validation Accuracy: 24.2\n",
            "[21/150]: Training Loss: 3.239693442169501, Training Accuracy: 22.324\n",
            "Validation Loss: 3.143001365661621, Validation Accuracy: 25.15\n",
            "[22/150]: Training Loss: 3.2111696467107658, Training Accuracy: 22.926\n",
            "Validation Loss: 3.1071121215820314, Validation Accuracy: 25.41\n",
            "[23/150]: Training Loss: 3.1833992928874735, Training Accuracy: 23.484\n",
            "Validation Loss: 3.0789601802825928, Validation Accuracy: 26.25\n",
            "[24/150]: Training Loss: 3.1474135603223528, Training Accuracy: 23.748\n",
            "Validation Loss: 3.0431544542312623, Validation Accuracy: 26.72\n",
            "[25/150]: Training Loss: 3.126202072416033, Training Accuracy: 24.388\n",
            "Validation Loss: 3.025442361831665, Validation Accuracy: 26.62\n",
            "[26/150]: Training Loss: 3.0991044433749453, Training Accuracy: 24.718\n",
            "Validation Loss: 2.9974936485290526, Validation Accuracy: 27.13\n",
            "[27/150]: Training Loss: 3.073319736792117, Training Accuracy: 25.346\n",
            "Validation Loss: 2.9764548778533935, Validation Accuracy: 27.54\n",
            "[28/150]: Training Loss: 3.0423376754838594, Training Accuracy: 25.946\n",
            "Validation Loss: 2.9351656436920166, Validation Accuracy: 28.32\n",
            "[29/150]: Training Loss: 3.013648816517421, Training Accuracy: 26.418\n",
            "Validation Loss: 2.919317698478699, Validation Accuracy: 28.99\n",
            "[30/150]: Training Loss: 2.9954160281590054, Training Accuracy: 26.764\n",
            "Validation Loss: 2.892651009559631, Validation Accuracy: 29.48\n",
            "[31/150]: Training Loss: 2.967517526782289, Training Accuracy: 27.272\n",
            "Validation Loss: 2.863291382789612, Validation Accuracy: 29.98\n",
            "[32/150]: Training Loss: 2.9497327609938018, Training Accuracy: 27.71\n",
            "Validation Loss: 2.855112910270691, Validation Accuracy: 29.8\n",
            "[33/150]: Training Loss: 2.9298942429678783, Training Accuracy: 27.868\n",
            "Validation Loss: 2.8315301179885863, Validation Accuracy: 30.54\n",
            "[34/150]: Training Loss: 2.906733279325524, Training Accuracy: 28.366\n",
            "Validation Loss: 2.7987032413482664, Validation Accuracy: 31.06\n",
            "[35/150]: Training Loss: 2.891595748006081, Training Accuracy: 28.684\n",
            "Validation Loss: 2.7815486907958986, Validation Accuracy: 31.66\n",
            "[36/150]: Training Loss: 2.8660872663770403, Training Accuracy: 29.228\n",
            "Validation Loss: 2.76305890083313, Validation Accuracy: 31.86\n",
            "[37/150]: Training Loss: 2.8532854245633494, Training Accuracy: 29.276\n",
            "Validation Loss: 2.7485848903656005, Validation Accuracy: 32.31\n",
            "[38/150]: Training Loss: 2.8363813964688047, Training Accuracy: 29.626\n",
            "Validation Loss: 2.741732931137085, Validation Accuracy: 32.37\n",
            "[39/150]: Training Loss: 2.817852025129357, Training Accuracy: 30.356\n",
            "Validation Loss: 2.716148281097412, Validation Accuracy: 32.52\n",
            "[40/150]: Training Loss: 2.7965505123138428, Training Accuracy: 30.468\n",
            "Validation Loss: 2.6954785108566286, Validation Accuracy: 33.26\n",
            "[41/150]: Training Loss: 2.777193152174658, Training Accuracy: 30.91\n",
            "Validation Loss: 2.689286541938782, Validation Accuracy: 33.33\n",
            "[42/150]: Training Loss: 2.7633943460425554, Training Accuracy: 30.874\n",
            "Validation Loss: 2.6628729820251467, Validation Accuracy: 33.54\n",
            "[43/150]: Training Loss: 2.7435058331002993, Training Accuracy: 31.472\n",
            "Validation Loss: 2.6562008619308473, Validation Accuracy: 33.72\n",
            "[44/150]: Training Loss: 2.725325599008677, Training Accuracy: 31.994\n",
            "Validation Loss: 2.644929838180542, Validation Accuracy: 33.83\n",
            "[45/150]: Training Loss: 2.7060077579653994, Training Accuracy: 32.404\n",
            "Validation Loss: 2.6198429346084593, Validation Accuracy: 34.2\n",
            "[46/150]: Training Loss: 2.6917145592825755, Training Accuracy: 32.636\n",
            "Validation Loss: 2.60967857837677, Validation Accuracy: 34.5\n",
            "[47/150]: Training Loss: 2.683579221063731, Training Accuracy: 32.58\n",
            "Validation Loss: 2.5991793870925903, Validation Accuracy: 35.03\n",
            "[48/150]: Training Loss: 2.6728540683279234, Training Accuracy: 33.022\n",
            "Validation Loss: 2.59100227355957, Validation Accuracy: 35.07\n",
            "[49/150]: Training Loss: 2.6557982454494553, Training Accuracy: 33.11\n",
            "Validation Loss: 2.577105498313904, Validation Accuracy: 35.14\n",
            "[50/150]: Training Loss: 2.6382284748310947, Training Accuracy: 33.666\n",
            "Validation Loss: 2.55712034702301, Validation Accuracy: 35.52\n",
            "[51/150]: Training Loss: 2.6272740947956943, Training Accuracy: 33.998\n",
            "Validation Loss: 2.5471322298049928, Validation Accuracy: 35.88\n",
            "[52/150]: Training Loss: 2.618494077604644, Training Accuracy: 34.04\n",
            "Validation Loss: 2.5421458959579466, Validation Accuracy: 35.73\n",
            "[53/150]: Training Loss: 2.598925138006405, Training Accuracy: 34.508\n",
            "Validation Loss: 2.536887764930725, Validation Accuracy: 36.18\n",
            "[54/150]: Training Loss: 2.5985752806371574, Training Accuracy: 34.666\n",
            "Validation Loss: 2.516120505332947, Validation Accuracy: 36.52\n",
            "[55/150]: Training Loss: 2.580332104040652, Training Accuracy: 34.912\n",
            "Validation Loss: 2.510345458984375, Validation Accuracy: 36.59\n",
            "[56/150]: Training Loss: 2.569650562442079, Training Accuracy: 34.968\n",
            "Validation Loss: 2.498000979423523, Validation Accuracy: 37.16\n",
            "[57/150]: Training Loss: 2.5618990878669585, Training Accuracy: 35.18\n",
            "Validation Loss: 2.495281624794006, Validation Accuracy: 37.19\n",
            "[58/150]: Training Loss: 2.5537893236899865, Training Accuracy: 35.348\n",
            "Validation Loss: 2.484134078025818, Validation Accuracy: 36.73\n",
            "[59/150]: Training Loss: 2.54392485715905, Training Accuracy: 35.704\n",
            "Validation Loss: 2.4660497426986696, Validation Accuracy: 37.66\n",
            "[60/150]: Training Loss: 2.5297549744041596, Training Accuracy: 35.884\n",
            "Validation Loss: 2.457916569709778, Validation Accuracy: 37.36\n",
            "[61/150]: Training Loss: 2.515256760071735, Training Accuracy: 36.114\n",
            "Validation Loss: 2.45170681476593, Validation Accuracy: 37.98\n",
            "[62/150]: Training Loss: 2.511414012130426, Training Accuracy: 36.192\n",
            "Validation Loss: 2.4506330490112305, Validation Accuracy: 37.83\n",
            "[63/150]: Training Loss: 2.505029770792747, Training Accuracy: 36.422\n",
            "Validation Loss: 2.4473904848098753, Validation Accuracy: 37.55\n",
            "[64/150]: Training Loss: 2.4959285015962562, Training Accuracy: 36.62\n",
            "Validation Loss: 2.438623309135437, Validation Accuracy: 37.77\n",
            "[65/150]: Training Loss: 2.4828718146499322, Training Accuracy: 36.9\n",
            "Validation Loss: 2.4237023115158083, Validation Accuracy: 38.23\n",
            "[66/150]: Training Loss: 2.4754056638600876, Training Accuracy: 37.1\n",
            "Validation Loss: 2.425072741508484, Validation Accuracy: 38.56\n",
            "[67/150]: Training Loss: 2.4672083854675293, Training Accuracy: 37.082\n",
            "Validation Loss: 2.411469268798828, Validation Accuracy: 38.18\n",
            "[68/150]: Training Loss: 2.46198515502774, Training Accuracy: 37.322\n",
            "Validation Loss: 2.409951162338257, Validation Accuracy: 38.86\n",
            "[69/150]: Training Loss: 2.4538968436572017, Training Accuracy: 37.764\n",
            "Validation Loss: 2.391971492767334, Validation Accuracy: 39.04\n",
            "[70/150]: Training Loss: 2.4462242953631343, Training Accuracy: 37.57\n",
            "Validation Loss: 2.394611191749573, Validation Accuracy: 38.71\n",
            "[71/150]: Training Loss: 2.429029284691324, Training Accuracy: 38.192\n",
            "Validation Loss: 2.386702823638916, Validation Accuracy: 38.88\n",
            "[72/150]: Training Loss: 2.43276318238706, Training Accuracy: 38.076\n",
            "Validation Loss: 2.3796674728393556, Validation Accuracy: 39.05\n",
            "[73/150]: Training Loss: 2.4164321957802284, Training Accuracy: 38.248\n",
            "Validation Loss: 2.3743354082107544, Validation Accuracy: 39.5\n",
            "[74/150]: Training Loss: 2.4130708344128666, Training Accuracy: 38.542\n",
            "Validation Loss: 2.3728184700012207, Validation Accuracy: 39.15\n",
            "[75/150]: Training Loss: 2.40391899614918, Training Accuracy: 38.72\n",
            "Validation Loss: 2.368211817741394, Validation Accuracy: 39.47\n",
            "[76/150]: Training Loss: 2.403892604672179, Training Accuracy: 38.72\n",
            "Validation Loss: 2.36419997215271, Validation Accuracy: 39.67\n",
            "[77/150]: Training Loss: 2.3943562458972543, Training Accuracy: 38.7\n",
            "Validation Loss: 2.3529299974441527, Validation Accuracy: 39.95\n",
            "[78/150]: Training Loss: 2.3884038876514047, Training Accuracy: 38.924\n",
            "Validation Loss: 2.3554153442382812, Validation Accuracy: 39.74\n",
            "[79/150]: Training Loss: 2.3807718559187285, Training Accuracy: 39.234\n",
            "Validation Loss: 2.3478601932525636, Validation Accuracy: 40.07\n",
            "[80/150]: Training Loss: 2.3758340952347736, Training Accuracy: 39.184\n",
            "Validation Loss: 2.348959946632385, Validation Accuracy: 40.03\n",
            "[81/150]: Training Loss: 2.3717645577022006, Training Accuracy: 39.1\n",
            "Validation Loss: 2.3494511365890505, Validation Accuracy: 39.68\n",
            "[82/150]: Training Loss: 2.3643068829361273, Training Accuracy: 39.686\n",
            "Validation Loss: 2.3405634641647337, Validation Accuracy: 40.06\n",
            "[83/150]: Training Loss: 2.357988488917448, Training Accuracy: 39.656\n",
            "Validation Loss: 2.333068513870239, Validation Accuracy: 40.54\n",
            "[84/150]: Training Loss: 2.349589080226665, Training Accuracy: 39.642\n",
            "Validation Loss: 2.3267210960388183, Validation Accuracy: 40.56\n",
            "[85/150]: Training Loss: 2.352643222224956, Training Accuracy: 39.594\n",
            "Validation Loss: 2.3241426944732666, Validation Accuracy: 40.55\n",
            "[86/150]: Training Loss: 2.345696108681815, Training Accuracy: 39.898\n",
            "Validation Loss: 2.32454628944397, Validation Accuracy: 40.42\n",
            "[87/150]: Training Loss: 2.3424980786381937, Training Accuracy: 39.724\n",
            "Validation Loss: 2.3185175895690917, Validation Accuracy: 41.01\n",
            "[88/150]: Training Loss: 2.332790350427433, Training Accuracy: 40.048\n",
            "Validation Loss: 2.3108999013900755, Validation Accuracy: 40.55\n",
            "[89/150]: Training Loss: 2.330972437955895, Training Accuracy: 40.282\n",
            "Validation Loss: 2.3076040267944338, Validation Accuracy: 41.04\n",
            "[90/150]: Training Loss: 2.331948946933357, Training Accuracy: 40.192\n",
            "Validation Loss: 2.313597249984741, Validation Accuracy: 40.67\n",
            "[91/150]: Training Loss: 2.3177189340396804, Training Accuracy: 40.614\n",
            "Validation Loss: 2.299083137512207, Validation Accuracy: 41.06\n",
            "[92/150]: Training Loss: 2.3187544443169417, Training Accuracy: 40.588\n",
            "Validation Loss: 2.3093937158584597, Validation Accuracy: 40.62\n",
            "[93/150]: Training Loss: 2.315753240974582, Training Accuracy: 40.59\n",
            "Validation Loss: 2.301071882247925, Validation Accuracy: 40.89\n",
            "[94/150]: Training Loss: 2.3093836502153047, Training Accuracy: 40.56\n",
            "Validation Loss: 2.295303463935852, Validation Accuracy: 41.39\n",
            "[95/150]: Training Loss: 2.3023490857104867, Training Accuracy: 40.91\n",
            "Validation Loss: 2.2921106100082396, Validation Accuracy: 41.17\n",
            "[96/150]: Training Loss: 2.3010492422142805, Training Accuracy: 40.876\n",
            "Validation Loss: 2.288085961341858, Validation Accuracy: 41.53\n",
            "[97/150]: Training Loss: 2.2992364387122954, Training Accuracy: 40.828\n",
            "Validation Loss: 2.2836422443389894, Validation Accuracy: 41.39\n",
            "[98/150]: Training Loss: 2.2914001844367204, Training Accuracy: 40.912\n",
            "Validation Loss: 2.288723373413086, Validation Accuracy: 41.45\n",
            "[99/150]: Training Loss: 2.28923791282031, Training Accuracy: 40.894\n",
            "Validation Loss: 2.2835492134094237, Validation Accuracy: 41.2\n",
            "[100/150]: Training Loss: 2.2794596467699324, Training Accuracy: 41.38\n",
            "Validation Loss: 2.2830920219421387, Validation Accuracy: 41.37\n",
            "[101/150]: Training Loss: 2.2831326844740887, Training Accuracy: 41.274\n",
            "Validation Loss: 2.2774308919906616, Validation Accuracy: 41.62\n",
            "[102/150]: Training Loss: 2.2726087472876726, Training Accuracy: 41.388\n",
            "Validation Loss: 2.276098442077637, Validation Accuracy: 41.66\n",
            "[103/150]: Training Loss: 2.2764012667597555, Training Accuracy: 41.556\n",
            "Validation Loss: 2.273059129714966, Validation Accuracy: 41.71\n",
            "[104/150]: Training Loss: 2.279530860939804, Training Accuracy: 41.396\n",
            "Validation Loss: 2.278269386291504, Validation Accuracy: 41.41\n",
            "[105/150]: Training Loss: 2.2749376637595042, Training Accuracy: 41.318\n",
            "Validation Loss: 2.2714242458343508, Validation Accuracy: 41.7\n",
            "[106/150]: Training Loss: 2.272334692429523, Training Accuracy: 41.548\n",
            "Validation Loss: 2.2693742513656616, Validation Accuracy: 41.48\n",
            "[107/150]: Training Loss: 2.2710340947520975, Training Accuracy: 41.378\n",
            "Validation Loss: 2.2652126789093017, Validation Accuracy: 41.68\n",
            "[108/150]: Training Loss: 2.267277630007997, Training Accuracy: 41.48\n",
            "Validation Loss: 2.266073441505432, Validation Accuracy: 41.61\n",
            "[109/150]: Training Loss: 2.260799787482437, Training Accuracy: 41.708\n",
            "Validation Loss: 2.2654496908187864, Validation Accuracy: 41.56\n",
            "[110/150]: Training Loss: 2.252530964053407, Training Accuracy: 42.132\n",
            "Validation Loss: 2.262526035308838, Validation Accuracy: 41.9\n",
            "[111/150]: Training Loss: 2.247779924042371, Training Accuracy: 42.178\n",
            "Validation Loss: 2.2605021238327025, Validation Accuracy: 41.78\n",
            "[112/150]: Training Loss: 2.2522501166985958, Training Accuracy: 41.864\n",
            "Validation Loss: 2.2593064069747926, Validation Accuracy: 41.88\n",
            "[113/150]: Training Loss: 2.2499374710783666, Training Accuracy: 41.928\n",
            "Validation Loss: 2.258829665184021, Validation Accuracy: 41.93\n",
            "[114/150]: Training Loss: 2.248957716688818, Training Accuracy: 41.898\n",
            "Validation Loss: 2.2602357864379883, Validation Accuracy: 41.8\n",
            "[115/150]: Training Loss: 2.246997745669618, Training Accuracy: 41.86\n",
            "Validation Loss: 2.2563353538513184, Validation Accuracy: 42.0\n",
            "[116/150]: Training Loss: 2.2447169118998, Training Accuracy: 42.086\n",
            "Validation Loss: 2.2574153184890746, Validation Accuracy: 41.69\n",
            "[117/150]: Training Loss: 2.246363454935502, Training Accuracy: 42.22\n",
            "Validation Loss: 2.255693864822388, Validation Accuracy: 41.89\n",
            "[118/150]: Training Loss: 2.2424791735045764, Training Accuracy: 42.13\n",
            "Validation Loss: 2.252920937538147, Validation Accuracy: 42.03\n",
            "[119/150]: Training Loss: 2.2432011000964107, Training Accuracy: 42.372\n",
            "Validation Loss: 2.2506787538528443, Validation Accuracy: 42.28\n",
            "[120/150]: Training Loss: 2.234548028634519, Training Accuracy: 42.426\n",
            "Validation Loss: 2.2501566410064697, Validation Accuracy: 42.13\n",
            "[121/150]: Training Loss: 2.23581794330052, Training Accuracy: 42.216\n",
            "Validation Loss: 2.249624562263489, Validation Accuracy: 42.2\n",
            "[122/150]: Training Loss: 2.2365842984647166, Training Accuracy: 42.344\n",
            "Validation Loss: 2.247886800765991, Validation Accuracy: 42.05\n",
            "[123/150]: Training Loss: 2.231048199595237, Training Accuracy: 42.258\n",
            "Validation Loss: 2.2481226205825804, Validation Accuracy: 42.21\n",
            "[124/150]: Training Loss: 2.2342022195154305, Training Accuracy: 42.48\n",
            "Validation Loss: 2.2451326131820677, Validation Accuracy: 42.16\n",
            "[125/150]: Training Loss: 2.2329893014868913, Training Accuracy: 42.156\n",
            "Validation Loss: 2.245043420791626, Validation Accuracy: 41.96\n",
            "[126/150]: Training Loss: 2.2330193714219697, Training Accuracy: 42.418\n",
            "Validation Loss: 2.24723482131958, Validation Accuracy: 41.96\n",
            "[127/150]: Training Loss: 2.2315565907225317, Training Accuracy: 42.332\n",
            "Validation Loss: 2.243821716308594, Validation Accuracy: 42.12\n",
            "[128/150]: Training Loss: 2.2296993148570157, Training Accuracy: 42.408\n",
            "Validation Loss: 2.2438623905181885, Validation Accuracy: 42.41\n",
            "[129/150]: Training Loss: 2.2296536795947017, Training Accuracy: 42.246\n",
            "Validation Loss: 2.2415871381759644, Validation Accuracy: 42.21\n",
            "[130/150]: Training Loss: 2.2241466337320754, Training Accuracy: 42.568\n",
            "Validation Loss: 2.2422409534454344, Validation Accuracy: 42.26\n",
            "[131/150]: Training Loss: 2.224864049833648, Training Accuracy: 42.598\n",
            "Validation Loss: 2.242423963546753, Validation Accuracy: 42.3\n",
            "[132/150]: Training Loss: 2.2205117478662606, Training Accuracy: 42.862\n",
            "Validation Loss: 2.241534924507141, Validation Accuracy: 42.14\n",
            "[133/150]: Training Loss: 2.224643206109806, Training Accuracy: 42.348\n",
            "Validation Loss: 2.239711046218872, Validation Accuracy: 42.17\n",
            "[134/150]: Training Loss: 2.2237596852438792, Training Accuracy: 42.628\n",
            "Validation Loss: 2.2399126052856446, Validation Accuracy: 42.42\n",
            "[135/150]: Training Loss: 2.219805839110394, Training Accuracy: 42.732\n",
            "Validation Loss: 2.239424467086792, Validation Accuracy: 42.14\n",
            "[136/150]: Training Loss: 2.217083351952689, Training Accuracy: 42.914\n",
            "Validation Loss: 2.2403131246566774, Validation Accuracy: 42.3\n",
            "[137/150]: Training Loss: 2.2213853573312563, Training Accuracy: 42.754\n",
            "Validation Loss: 2.2398319244384766, Validation Accuracy: 42.29\n",
            "[138/150]: Training Loss: 2.221228784444381, Training Accuracy: 42.688\n",
            "Validation Loss: 2.2398473262786864, Validation Accuracy: 42.13\n",
            "[139/150]: Training Loss: 2.220663090141452, Training Accuracy: 42.662\n",
            "Validation Loss: 2.2387043714523314, Validation Accuracy: 42.44\n",
            "[140/150]: Training Loss: 2.2193756784711565, Training Accuracy: 42.598\n",
            "Validation Loss: 2.2392037868499757, Validation Accuracy: 42.31\n",
            "[141/150]: Training Loss: 2.221537142383809, Training Accuracy: 42.654\n",
            "Validation Loss: 2.239200401306152, Validation Accuracy: 42.3\n",
            "[142/150]: Training Loss: 2.218330042702811, Training Accuracy: 42.8\n",
            "Validation Loss: 2.238777184486389, Validation Accuracy: 42.33\n",
            "[143/150]: Training Loss: 2.2231140574630426, Training Accuracy: 42.71\n",
            "Validation Loss: 2.2391661167144776, Validation Accuracy: 42.33\n",
            "[144/150]: Training Loss: 2.2220610939726537, Training Accuracy: 42.734\n",
            "Validation Loss: 2.23895423412323, Validation Accuracy: 42.28\n",
            "[145/150]: Training Loss: 2.2202161526193422, Training Accuracy: 42.758\n",
            "Validation Loss: 2.2384191513061524, Validation Accuracy: 42.25\n",
            "[146/150]: Training Loss: 2.2149193578836868, Training Accuracy: 42.996\n",
            "Validation Loss: 2.2386470317840574, Validation Accuracy: 42.3\n",
            "[147/150]: Training Loss: 2.2156761033194408, Training Accuracy: 42.662\n",
            "Validation Loss: 2.238538146018982, Validation Accuracy: 42.33\n",
            "[148/150]: Training Loss: 2.2188694087826475, Training Accuracy: 42.722\n",
            "Validation Loss: 2.2385375022888185, Validation Accuracy: 42.29\n",
            "[149/150]: Training Loss: 2.2163160820396577, Training Accuracy: 42.762\n",
            "Validation Loss: 2.2385093688964846, Validation Accuracy: 42.29\n",
            "[150/150]: Training Loss: 2.2146115546323815, Training Accuracy: 42.764\n",
            "Validation Loss: 2.238506293296814, Validation Accuracy: 42.29\n",
            "**********************************************************************\n",
            "Test Loss: 2.238506293296814, Test Accuracy: 42.29\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▂▁▅▅▅▅▄▅▄</td></tr><tr><td>Test Loss</td><td>█▄▃▁▃▃▃▄▃▃</td></tr><tr><td>Train Accuracy</td><td>▁▂▃▃▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train Loss</td><td>█▇▆▅▅▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>42.29</td></tr><tr><td>Test Loss</td><td>2.23851</td></tr><tr><td>Train Accuracy</td><td>42.764</td></tr><tr><td>Train Loss</td><td>2.21461</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=1024 learning_rate=0.0006 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/f6zj2dy6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/f6zj2dy6</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_062343-f6zj2dy6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 2048\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_064235-a1i0qpqi</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/a1i0qpqi' target=\"_blank\">batch_size=2048 learning_rate=0.000848528137423857 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/a1i0qpqi' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/a1i0qpqi</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.600872554779053, Training Accuracy: 1.838\n",
            "Validation Loss: 4.590850925445556, Validation Accuracy: 2.55\n",
            "[2/150]: Training Loss: 4.576414985656738, Training Accuracy: 2.548\n",
            "Validation Loss: 4.55309419631958, Validation Accuracy: 3.25\n",
            "[3/150]: Training Loss: 4.526648464202881, Training Accuracy: 3.408\n",
            "Validation Loss: 4.485427379608154, Validation Accuracy: 3.88\n",
            "[4/150]: Training Loss: 4.446523704528809, Training Accuracy: 4.17\n",
            "Validation Loss: 4.387019348144531, Validation Accuracy: 4.51\n",
            "[5/150]: Training Loss: 4.341707801818847, Training Accuracy: 4.806\n",
            "Validation Loss: 4.268606185913086, Validation Accuracy: 5.42\n",
            "[6/150]: Training Loss: 4.231560764312744, Training Accuracy: 5.834\n",
            "Validation Loss: 4.15619592666626, Validation Accuracy: 7.32\n",
            "[7/150]: Training Loss: 4.137169361114502, Training Accuracy: 7.258\n",
            "Validation Loss: 4.07053050994873, Validation Accuracy: 8.52\n",
            "[8/150]: Training Loss: 4.06978271484375, Training Accuracy: 8.214\n",
            "Validation Loss: 4.007327079772949, Validation Accuracy: 9.55\n",
            "[9/150]: Training Loss: 4.020532312393189, Training Accuracy: 9.192\n",
            "Validation Loss: 3.956293058395386, Validation Accuracy: 10.21\n",
            "[10/150]: Training Loss: 3.9746204376220704, Training Accuracy: 9.782\n",
            "Validation Loss: 3.902535915374756, Validation Accuracy: 11.51\n",
            "[11/150]: Training Loss: 3.9225975704193115, Training Accuracy: 10.588\n",
            "Validation Loss: 3.855096530914307, Validation Accuracy: 12.19\n",
            "[12/150]: Training Loss: 3.8843927574157715, Training Accuracy: 11.236\n",
            "Validation Loss: 3.8128616333007814, Validation Accuracy: 12.95\n",
            "[13/150]: Training Loss: 3.844352321624756, Training Accuracy: 11.834\n",
            "Validation Loss: 3.772704267501831, Validation Accuracy: 13.43\n",
            "[14/150]: Training Loss: 3.8149378585815428, Training Accuracy: 12.34\n",
            "Validation Loss: 3.740799808502197, Validation Accuracy: 14.52\n",
            "[15/150]: Training Loss: 3.778950262069702, Training Accuracy: 13.05\n",
            "Validation Loss: 3.7088190078735352, Validation Accuracy: 14.52\n",
            "[16/150]: Training Loss: 3.7480258464813234, Training Accuracy: 13.598\n",
            "Validation Loss: 3.6764598369598387, Validation Accuracy: 15.3\n",
            "[17/150]: Training Loss: 3.715016832351685, Training Accuracy: 14.102\n",
            "Validation Loss: 3.638604497909546, Validation Accuracy: 15.81\n",
            "[18/150]: Training Loss: 3.6842565822601316, Training Accuracy: 14.456\n",
            "Validation Loss: 3.598477506637573, Validation Accuracy: 16.36\n",
            "[19/150]: Training Loss: 3.6509159278869627, Training Accuracy: 15.14\n",
            "Validation Loss: 3.5720494270324705, Validation Accuracy: 17.0\n",
            "[20/150]: Training Loss: 3.6177934551239015, Training Accuracy: 15.678\n",
            "Validation Loss: 3.5425681114196776, Validation Accuracy: 17.62\n",
            "[21/150]: Training Loss: 3.582935447692871, Training Accuracy: 16.268\n",
            "Validation Loss: 3.50300612449646, Validation Accuracy: 18.33\n",
            "[22/150]: Training Loss: 3.550090913772583, Training Accuracy: 16.796\n",
            "Validation Loss: 3.473466396331787, Validation Accuracy: 19.04\n",
            "[23/150]: Training Loss: 3.5188063907623293, Training Accuracy: 17.128\n",
            "Validation Loss: 3.4353472232818603, Validation Accuracy: 19.68\n",
            "[24/150]: Training Loss: 3.495486888885498, Training Accuracy: 17.544\n",
            "Validation Loss: 3.414610576629639, Validation Accuracy: 19.64\n",
            "[25/150]: Training Loss: 3.46710319519043, Training Accuracy: 18.09\n",
            "Validation Loss: 3.380483055114746, Validation Accuracy: 20.42\n",
            "[26/150]: Training Loss: 3.4414588356018068, Training Accuracy: 18.524\n",
            "Validation Loss: 3.3567835807800295, Validation Accuracy: 20.4\n",
            "[27/150]: Training Loss: 3.415497074127197, Training Accuracy: 19.006\n",
            "Validation Loss: 3.336991882324219, Validation Accuracy: 21.37\n",
            "[28/150]: Training Loss: 3.400643033981323, Training Accuracy: 19.35\n",
            "Validation Loss: 3.315301847457886, Validation Accuracy: 21.36\n",
            "[29/150]: Training Loss: 3.3807515335083007, Training Accuracy: 19.672\n",
            "Validation Loss: 3.294951343536377, Validation Accuracy: 22.07\n",
            "[30/150]: Training Loss: 3.3530473613739016, Training Accuracy: 20.312\n",
            "Validation Loss: 3.270126295089722, Validation Accuracy: 22.23\n",
            "[31/150]: Training Loss: 3.3403017330169678, Training Accuracy: 20.354\n",
            "Validation Loss: 3.258027935028076, Validation Accuracy: 22.94\n",
            "[32/150]: Training Loss: 3.3205006408691404, Training Accuracy: 20.864\n",
            "Validation Loss: 3.225876235961914, Validation Accuracy: 23.57\n",
            "[33/150]: Training Loss: 3.3009582996368407, Training Accuracy: 21.156\n",
            "Validation Loss: 3.214678192138672, Validation Accuracy: 23.22\n",
            "[34/150]: Training Loss: 3.2803742408752443, Training Accuracy: 21.664\n",
            "Validation Loss: 3.193393039703369, Validation Accuracy: 23.96\n",
            "[35/150]: Training Loss: 3.261015605926514, Training Accuracy: 21.874\n",
            "Validation Loss: 3.178829050064087, Validation Accuracy: 24.36\n",
            "[36/150]: Training Loss: 3.248182525634766, Training Accuracy: 22.066\n",
            "Validation Loss: 3.1585222244262696, Validation Accuracy: 24.66\n",
            "[37/150]: Training Loss: 3.228750743865967, Training Accuracy: 22.64\n",
            "Validation Loss: 3.1375529289245607, Validation Accuracy: 25.22\n",
            "[38/150]: Training Loss: 3.2122406196594238, Training Accuracy: 22.746\n",
            "Validation Loss: 3.130802774429321, Validation Accuracy: 25.21\n",
            "[39/150]: Training Loss: 3.200315999984741, Training Accuracy: 23.118\n",
            "Validation Loss: 3.1034634590148924, Validation Accuracy: 25.76\n",
            "[40/150]: Training Loss: 3.179281768798828, Training Accuracy: 23.47\n",
            "Validation Loss: 3.0890458106994627, Validation Accuracy: 25.99\n",
            "[41/150]: Training Loss: 3.158253240585327, Training Accuracy: 23.802\n",
            "Validation Loss: 3.0687211990356444, Validation Accuracy: 26.33\n",
            "[42/150]: Training Loss: 3.146801538467407, Training Accuracy: 23.958\n",
            "Validation Loss: 3.055481195449829, Validation Accuracy: 26.63\n",
            "[43/150]: Training Loss: 3.1272859001159667, Training Accuracy: 24.326\n",
            "Validation Loss: 3.0511748790740967, Validation Accuracy: 26.8\n",
            "[44/150]: Training Loss: 3.117414894104004, Training Accuracy: 24.57\n",
            "Validation Loss: 3.0245641231536866, Validation Accuracy: 27.07\n",
            "[45/150]: Training Loss: 3.1020038509368897, Training Accuracy: 24.842\n",
            "Validation Loss: 3.008786678314209, Validation Accuracy: 27.39\n",
            "[46/150]: Training Loss: 3.0855378246307374, Training Accuracy: 25.254\n",
            "Validation Loss: 2.991756868362427, Validation Accuracy: 27.8\n",
            "[47/150]: Training Loss: 3.070243549346924, Training Accuracy: 25.452\n",
            "Validation Loss: 2.9793407917022705, Validation Accuracy: 28.28\n",
            "[48/150]: Training Loss: 3.0512985134124757, Training Accuracy: 25.744\n",
            "Validation Loss: 2.9645009517669676, Validation Accuracy: 27.98\n",
            "[49/150]: Training Loss: 3.037804851531982, Training Accuracy: 26.15\n",
            "Validation Loss: 2.94492564201355, Validation Accuracy: 28.53\n",
            "[50/150]: Training Loss: 3.02706787109375, Training Accuracy: 26.23\n",
            "Validation Loss: 2.933021306991577, Validation Accuracy: 28.91\n",
            "[51/150]: Training Loss: 3.0107177543640136, Training Accuracy: 26.506\n",
            "Validation Loss: 2.9290098667144777, Validation Accuracy: 28.84\n",
            "[52/150]: Training Loss: 2.9924880027770997, Training Accuracy: 27.032\n",
            "Validation Loss: 2.895456838607788, Validation Accuracy: 29.47\n",
            "[53/150]: Training Loss: 2.975731897354126, Training Accuracy: 27.272\n",
            "Validation Loss: 2.8865129470825197, Validation Accuracy: 29.5\n",
            "[54/150]: Training Loss: 2.9595889949798586, Training Accuracy: 27.632\n",
            "Validation Loss: 2.8671710014343263, Validation Accuracy: 30.08\n",
            "[55/150]: Training Loss: 2.945874729156494, Training Accuracy: 27.87\n",
            "Validation Loss: 2.8572846412658692, Validation Accuracy: 29.75\n",
            "[56/150]: Training Loss: 2.9351212215423583, Training Accuracy: 28.054\n",
            "Validation Loss: 2.8465723991394043, Validation Accuracy: 30.33\n",
            "[57/150]: Training Loss: 2.924895992279053, Training Accuracy: 28.296\n",
            "Validation Loss: 2.8296555995941164, Validation Accuracy: 30.55\n",
            "[58/150]: Training Loss: 2.910297574996948, Training Accuracy: 28.604\n",
            "Validation Loss: 2.826309061050415, Validation Accuracy: 30.86\n",
            "[59/150]: Training Loss: 2.8968456172943116, Training Accuracy: 28.5\n",
            "Validation Loss: 2.8103396892547607, Validation Accuracy: 30.74\n",
            "[60/150]: Training Loss: 2.8862410736083985, Training Accuracy: 29.156\n",
            "Validation Loss: 2.7891706466674804, Validation Accuracy: 31.45\n",
            "[61/150]: Training Loss: 2.8698458766937254, Training Accuracy: 28.992\n",
            "Validation Loss: 2.7788822650909424, Validation Accuracy: 31.5\n",
            "[62/150]: Training Loss: 2.8539681434631348, Training Accuracy: 29.33\n",
            "Validation Loss: 2.7650059700012206, Validation Accuracy: 32.31\n",
            "[63/150]: Training Loss: 2.84574893951416, Training Accuracy: 29.738\n",
            "Validation Loss: 2.7536985874176025, Validation Accuracy: 31.89\n",
            "[64/150]: Training Loss: 2.83269907951355, Training Accuracy: 29.984\n",
            "Validation Loss: 2.7471179485321047, Validation Accuracy: 31.71\n",
            "[65/150]: Training Loss: 2.8287733936309816, Training Accuracy: 29.936\n",
            "Validation Loss: 2.7425480842590333, Validation Accuracy: 32.37\n",
            "[66/150]: Training Loss: 2.8126729583740233, Training Accuracy: 30.256\n",
            "Validation Loss: 2.7356860637664795, Validation Accuracy: 32.08\n",
            "[67/150]: Training Loss: 2.79921669960022, Training Accuracy: 30.562\n",
            "Validation Loss: 2.71913685798645, Validation Accuracy: 32.48\n",
            "[68/150]: Training Loss: 2.796040153503418, Training Accuracy: 30.588\n",
            "Validation Loss: 2.70328369140625, Validation Accuracy: 33.07\n",
            "[69/150]: Training Loss: 2.784684944152832, Training Accuracy: 30.966\n",
            "Validation Loss: 2.6998016357421877, Validation Accuracy: 33.13\n",
            "[70/150]: Training Loss: 2.771635856628418, Training Accuracy: 30.944\n",
            "Validation Loss: 2.6886127948760987, Validation Accuracy: 33.05\n",
            "[71/150]: Training Loss: 2.768005828857422, Training Accuracy: 31.358\n",
            "Validation Loss: 2.6832919120788574, Validation Accuracy: 33.2\n",
            "[72/150]: Training Loss: 2.765062837600708, Training Accuracy: 31.252\n",
            "Validation Loss: 2.680223321914673, Validation Accuracy: 33.55\n",
            "[73/150]: Training Loss: 2.7503418922424316, Training Accuracy: 31.848\n",
            "Validation Loss: 2.670897054672241, Validation Accuracy: 33.25\n",
            "[74/150]: Training Loss: 2.740241832733154, Training Accuracy: 31.89\n",
            "Validation Loss: 2.6575933933258056, Validation Accuracy: 34.25\n",
            "[75/150]: Training Loss: 2.734506778717041, Training Accuracy: 31.896\n",
            "Validation Loss: 2.6604311943054197, Validation Accuracy: 33.96\n",
            "[76/150]: Training Loss: 2.7318229484558105, Training Accuracy: 32.09\n",
            "Validation Loss: 2.6528788089752195, Validation Accuracy: 33.73\n",
            "[77/150]: Training Loss: 2.7181160259246826, Training Accuracy: 32.278\n",
            "Validation Loss: 2.636572074890137, Validation Accuracy: 34.29\n",
            "[78/150]: Training Loss: 2.712002992630005, Training Accuracy: 32.138\n",
            "Validation Loss: 2.6339709758758545, Validation Accuracy: 34.11\n",
            "[79/150]: Training Loss: 2.708227500915527, Training Accuracy: 32.512\n",
            "Validation Loss: 2.632725191116333, Validation Accuracy: 34.27\n",
            "[80/150]: Training Loss: 2.6961685180664063, Training Accuracy: 32.58\n",
            "Validation Loss: 2.620032548904419, Validation Accuracy: 34.63\n",
            "[81/150]: Training Loss: 2.6996922492980957, Training Accuracy: 32.57\n",
            "Validation Loss: 2.622188997268677, Validation Accuracy: 34.46\n",
            "[82/150]: Training Loss: 2.687695999145508, Training Accuracy: 32.668\n",
            "Validation Loss: 2.6097755432128906, Validation Accuracy: 34.63\n",
            "[83/150]: Training Loss: 2.686816120147705, Training Accuracy: 33.0\n",
            "Validation Loss: 2.604731035232544, Validation Accuracy: 34.86\n",
            "[84/150]: Training Loss: 2.6810986232757568, Training Accuracy: 33.088\n",
            "Validation Loss: 2.60227370262146, Validation Accuracy: 34.58\n",
            "[85/150]: Training Loss: 2.667298593521118, Training Accuracy: 33.026\n",
            "Validation Loss: 2.5953265190124513, Validation Accuracy: 35.33\n",
            "[86/150]: Training Loss: 2.6712794971466063, Training Accuracy: 33.128\n",
            "Validation Loss: 2.595105266571045, Validation Accuracy: 35.11\n",
            "[87/150]: Training Loss: 2.6611053371429443, Training Accuracy: 33.468\n",
            "Validation Loss: 2.585465097427368, Validation Accuracy: 35.32\n",
            "[88/150]: Training Loss: 2.663666458129883, Training Accuracy: 33.35\n",
            "Validation Loss: 2.583946704864502, Validation Accuracy: 35.27\n",
            "[89/150]: Training Loss: 2.65557580947876, Training Accuracy: 33.416\n",
            "Validation Loss: 2.5775884628295898, Validation Accuracy: 35.09\n",
            "[90/150]: Training Loss: 2.645936164855957, Training Accuracy: 33.65\n",
            "Validation Loss: 2.575248098373413, Validation Accuracy: 35.32\n",
            "[91/150]: Training Loss: 2.641429653167725, Training Accuracy: 33.728\n",
            "Validation Loss: 2.5739793300628664, Validation Accuracy: 35.32\n",
            "[92/150]: Training Loss: 2.6367671966552733, Training Accuracy: 34.026\n",
            "Validation Loss: 2.5660872936248778, Validation Accuracy: 35.58\n",
            "[93/150]: Training Loss: 2.633252477645874, Training Accuracy: 33.894\n",
            "Validation Loss: 2.5642282962799072, Validation Accuracy: 35.44\n",
            "[94/150]: Training Loss: 2.6317241191864014, Training Accuracy: 34.138\n",
            "Validation Loss: 2.5631762504577638, Validation Accuracy: 35.39\n",
            "[95/150]: Training Loss: 2.6283755111694336, Training Accuracy: 34.238\n",
            "Validation Loss: 2.5549296855926515, Validation Accuracy: 35.99\n",
            "[96/150]: Training Loss: 2.6233442878723143, Training Accuracy: 34.092\n",
            "Validation Loss: 2.553958368301392, Validation Accuracy: 35.83\n",
            "[97/150]: Training Loss: 2.6188401126861574, Training Accuracy: 34.434\n",
            "Validation Loss: 2.5522915363311767, Validation Accuracy: 35.83\n",
            "[98/150]: Training Loss: 2.615722646713257, Training Accuracy: 34.306\n",
            "Validation Loss: 2.545611763000488, Validation Accuracy: 35.99\n",
            "[99/150]: Training Loss: 2.6122173404693605, Training Accuracy: 34.594\n",
            "Validation Loss: 2.5498822689056397, Validation Accuracy: 35.71\n",
            "[100/150]: Training Loss: 2.610180253982544, Training Accuracy: 34.442\n",
            "Validation Loss: 2.5442173004150392, Validation Accuracy: 36.31\n",
            "[101/150]: Training Loss: 2.6088740062713622, Training Accuracy: 34.904\n",
            "Validation Loss: 2.5409452438354494, Validation Accuracy: 36.03\n",
            "[102/150]: Training Loss: 2.6049435424804686, Training Accuracy: 34.646\n",
            "Validation Loss: 2.535108757019043, Validation Accuracy: 36.2\n",
            "[103/150]: Training Loss: 2.6048165130615235, Training Accuracy: 34.616\n",
            "Validation Loss: 2.534243869781494, Validation Accuracy: 36.2\n",
            "[104/150]: Training Loss: 2.599171781539917, Training Accuracy: 34.738\n",
            "Validation Loss: 2.533633089065552, Validation Accuracy: 36.05\n",
            "[105/150]: Training Loss: 2.597423791885376, Training Accuracy: 34.898\n",
            "Validation Loss: 2.529845094680786, Validation Accuracy: 36.45\n",
            "[106/150]: Training Loss: 2.596056480407715, Training Accuracy: 34.702\n",
            "Validation Loss: 2.5281211376190185, Validation Accuracy: 36.5\n",
            "[107/150]: Training Loss: 2.5845062160491943, Training Accuracy: 34.948\n",
            "Validation Loss: 2.5248257160186767, Validation Accuracy: 36.49\n",
            "[108/150]: Training Loss: 2.585829973220825, Training Accuracy: 35.074\n",
            "Validation Loss: 2.5224894523620605, Validation Accuracy: 36.49\n",
            "[109/150]: Training Loss: 2.5839975357055662, Training Accuracy: 35.16\n",
            "Validation Loss: 2.521509790420532, Validation Accuracy: 36.46\n",
            "[110/150]: Training Loss: 2.5794923305511475, Training Accuracy: 35.162\n",
            "Validation Loss: 2.5190929412841796, Validation Accuracy: 36.59\n",
            "[111/150]: Training Loss: 2.5758457374572754, Training Accuracy: 35.06\n",
            "Validation Loss: 2.51663761138916, Validation Accuracy: 36.37\n",
            "[112/150]: Training Loss: 2.576828861236572, Training Accuracy: 35.066\n",
            "Validation Loss: 2.5163278102874758, Validation Accuracy: 36.8\n",
            "[113/150]: Training Loss: 2.577974252700806, Training Accuracy: 35.126\n",
            "Validation Loss: 2.5136294841766356, Validation Accuracy: 36.77\n",
            "[114/150]: Training Loss: 2.5744064903259276, Training Accuracy: 35.212\n",
            "Validation Loss: 2.5124191284179687, Validation Accuracy: 36.53\n",
            "[115/150]: Training Loss: 2.5719550609588624, Training Accuracy: 35.18\n",
            "Validation Loss: 2.5119277000427247, Validation Accuracy: 36.54\n",
            "[116/150]: Training Loss: 2.5702946758270264, Training Accuracy: 35.3\n",
            "Validation Loss: 2.5109957695007323, Validation Accuracy: 36.92\n",
            "[117/150]: Training Loss: 2.570598087310791, Training Accuracy: 35.416\n",
            "Validation Loss: 2.507699728012085, Validation Accuracy: 36.88\n",
            "[118/150]: Training Loss: 2.5662026691436766, Training Accuracy: 35.434\n",
            "Validation Loss: 2.5102144718170165, Validation Accuracy: 36.76\n",
            "[119/150]: Training Loss: 2.5664295768737793, Training Accuracy: 35.47\n",
            "Validation Loss: 2.505918836593628, Validation Accuracy: 37.02\n",
            "[120/150]: Training Loss: 2.5633824253082276, Training Accuracy: 35.706\n",
            "Validation Loss: 2.503660488128662, Validation Accuracy: 36.85\n",
            "[121/150]: Training Loss: 2.56352068901062, Training Accuracy: 35.61\n",
            "Validation Loss: 2.502376890182495, Validation Accuracy: 37.07\n",
            "[122/150]: Training Loss: 2.5649334526062013, Training Accuracy: 35.482\n",
            "Validation Loss: 2.501589870452881, Validation Accuracy: 37.12\n",
            "[123/150]: Training Loss: 2.5551751327514647, Training Accuracy: 35.73\n",
            "Validation Loss: 2.5013341903686523, Validation Accuracy: 37.0\n",
            "[124/150]: Training Loss: 2.556901903152466, Training Accuracy: 35.526\n",
            "Validation Loss: 2.498872900009155, Validation Accuracy: 37.13\n",
            "[125/150]: Training Loss: 2.56141544342041, Training Accuracy: 35.398\n",
            "Validation Loss: 2.499050569534302, Validation Accuracy: 37.08\n",
            "[126/150]: Training Loss: 2.559230995178223, Training Accuracy: 35.614\n",
            "Validation Loss: 2.4986857414245605, Validation Accuracy: 36.93\n",
            "[127/150]: Training Loss: 2.5585966968536376, Training Accuracy: 35.736\n",
            "Validation Loss: 2.497245264053345, Validation Accuracy: 37.23\n",
            "[128/150]: Training Loss: 2.5579049968719483, Training Accuracy: 35.618\n",
            "Validation Loss: 2.4982468605041506, Validation Accuracy: 37.21\n",
            "[129/150]: Training Loss: 2.555950794219971, Training Accuracy: 35.748\n",
            "Validation Loss: 2.4955115795135496, Validation Accuracy: 37.22\n",
            "[130/150]: Training Loss: 2.5558400917053223, Training Accuracy: 35.628\n",
            "Validation Loss: 2.4957788944244386, Validation Accuracy: 36.97\n",
            "[131/150]: Training Loss: 2.549605436325073, Training Accuracy: 35.862\n",
            "Validation Loss: 2.494734859466553, Validation Accuracy: 37.41\n",
            "[132/150]: Training Loss: 2.5500775146484376, Training Accuracy: 35.77\n",
            "Validation Loss: 2.4960716724395753, Validation Accuracy: 37.08\n",
            "[133/150]: Training Loss: 2.5564523792266844, Training Accuracy: 35.596\n",
            "Validation Loss: 2.4939414501190185, Validation Accuracy: 37.17\n",
            "[134/150]: Training Loss: 2.5449225997924803, Training Accuracy: 35.882\n",
            "Validation Loss: 2.494381046295166, Validation Accuracy: 37.25\n",
            "[135/150]: Training Loss: 2.5483498573303223, Training Accuracy: 35.88\n",
            "Validation Loss: 2.493652677536011, Validation Accuracy: 37.19\n",
            "[136/150]: Training Loss: 2.5493384170532227, Training Accuracy: 35.934\n",
            "Validation Loss: 2.4934218406677244, Validation Accuracy: 37.27\n",
            "[137/150]: Training Loss: 2.54675745010376, Training Accuracy: 35.884\n",
            "Validation Loss: 2.4932618618011473, Validation Accuracy: 37.3\n",
            "[138/150]: Training Loss: 2.551592617034912, Training Accuracy: 35.658\n",
            "Validation Loss: 2.4930295944213867, Validation Accuracy: 37.26\n",
            "[139/150]: Training Loss: 2.5556958293914795, Training Accuracy: 35.616\n",
            "Validation Loss: 2.4928393840789793, Validation Accuracy: 37.32\n",
            "[140/150]: Training Loss: 2.5497092247009276, Training Accuracy: 35.746\n",
            "Validation Loss: 2.4923996925354004, Validation Accuracy: 37.19\n",
            "[141/150]: Training Loss: 2.5460032653808593, Training Accuracy: 36.058\n",
            "Validation Loss: 2.4924858093261717, Validation Accuracy: 37.35\n",
            "[142/150]: Training Loss: 2.5488867378234863, Training Accuracy: 35.844\n",
            "Validation Loss: 2.4925445079803468, Validation Accuracy: 37.29\n",
            "[143/150]: Training Loss: 2.5511161518096923, Training Accuracy: 35.83\n",
            "Validation Loss: 2.492031478881836, Validation Accuracy: 37.22\n",
            "[144/150]: Training Loss: 2.5504028892517088, Training Accuracy: 35.788\n",
            "Validation Loss: 2.4918816089630127, Validation Accuracy: 37.21\n",
            "[145/150]: Training Loss: 2.547076606750488, Training Accuracy: 35.668\n",
            "Validation Loss: 2.4918155670166016, Validation Accuracy: 37.23\n",
            "[146/150]: Training Loss: 2.542300052642822, Training Accuracy: 36.08\n",
            "Validation Loss: 2.4920117378234865, Validation Accuracy: 37.23\n",
            "[147/150]: Training Loss: 2.5489714622497557, Training Accuracy: 35.678\n",
            "Validation Loss: 2.4920287132263184, Validation Accuracy: 37.23\n",
            "[148/150]: Training Loss: 2.5497193813323973, Training Accuracy: 35.596\n",
            "Validation Loss: 2.4920116424560548, Validation Accuracy: 37.23\n",
            "[149/150]: Training Loss: 2.5469696426391604, Training Accuracy: 35.88\n",
            "Validation Loss: 2.4920021057128907, Validation Accuracy: 37.23\n",
            "[150/150]: Training Loss: 2.5485261821746827, Training Accuracy: 35.498\n",
            "Validation Loss: 2.491995668411255, Validation Accuracy: 37.22\n",
            "**********************************************************************\n",
            "Test Loss: 2.491995668411255, Test Accuracy: 37.22\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>▃█▆▁▂</td></tr><tr><td>Test Loss</td><td>█▁▃▆▃</td></tr><tr><td>Train Accuracy</td><td>▁▁▂▃▃▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇████████████████</td></tr><tr><td>Train Loss</td><td>██▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>37.22</td></tr><tr><td>Test Loss</td><td>2.492</td></tr><tr><td>Train Accuracy</td><td>35.498</td></tr><tr><td>Train Loss</td><td>2.54853</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=2048 learning_rate=0.000848528137423857 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/a1i0qpqi' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/a1i0qpqi</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_064235-a1i0qpqi/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 4096\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_070246-j81b4d42</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j81b4d42' target=\"_blank\">batch_size=4096 learning_rate=0.0012 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j81b4d42' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j81b4d42</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.603197281177227, Training Accuracy: 1.246\n",
            "Validation Loss: 4.599034945170085, Validation Accuracy: 2.16\n",
            "[2/150]: Training Loss: 4.594296822181115, Training Accuracy: 2.678\n",
            "Validation Loss: 4.58727502822876, Validation Accuracy: 3.46\n",
            "[3/150]: Training Loss: 4.580152915074275, Training Accuracy: 3.29\n",
            "Validation Loss: 4.5680915514628095, Validation Accuracy: 3.75\n",
            "[4/150]: Training Loss: 4.55770389850323, Training Accuracy: 3.57\n",
            "Validation Loss: 4.539859771728516, Validation Accuracy: 4.09\n",
            "[5/150]: Training Loss: 4.526640048393836, Training Accuracy: 3.846\n",
            "Validation Loss: 4.5020168622334795, Validation Accuracy: 4.4\n",
            "[6/150]: Training Loss: 4.4863302157475395, Training Accuracy: 4.116\n",
            "Validation Loss: 4.454424858093262, Validation Accuracy: 4.5\n",
            "[7/150]: Training Loss: 4.436847613408015, Training Accuracy: 4.154\n",
            "Validation Loss: 4.398792107899983, Validation Accuracy: 4.51\n",
            "[8/150]: Training Loss: 4.382756233215332, Training Accuracy: 4.368\n",
            "Validation Loss: 4.336817264556885, Validation Accuracy: 5.07\n",
            "[9/150]: Training Loss: 4.320116079770601, Training Accuracy: 5.092\n",
            "Validation Loss: 4.271851857503255, Validation Accuracy: 5.91\n",
            "[10/150]: Training Loss: 4.2579911672152, Training Accuracy: 5.896\n",
            "Validation Loss: 4.20835542678833, Validation Accuracy: 6.72\n",
            "[11/150]: Training Loss: 4.2017460236182576, Training Accuracy: 6.778\n",
            "Validation Loss: 4.149452845255534, Validation Accuracy: 7.6\n",
            "[12/150]: Training Loss: 4.147615909576416, Training Accuracy: 7.544\n",
            "Validation Loss: 4.097760200500488, Validation Accuracy: 8.45\n",
            "[13/150]: Training Loss: 4.109276514786941, Training Accuracy: 7.878\n",
            "Validation Loss: 4.055920441945394, Validation Accuracy: 8.81\n",
            "[14/150]: Training Loss: 4.069469965421236, Training Accuracy: 8.186\n",
            "Validation Loss: 4.02240784962972, Validation Accuracy: 9.43\n",
            "[15/150]: Training Loss: 4.0482294376079855, Training Accuracy: 8.564\n",
            "Validation Loss: 3.9910717010498047, Validation Accuracy: 9.75\n",
            "[16/150]: Training Loss: 4.014009714126587, Training Accuracy: 8.978\n",
            "Validation Loss: 3.961193005243937, Validation Accuracy: 10.36\n",
            "[17/150]: Training Loss: 3.9931728656475363, Training Accuracy: 9.682\n",
            "Validation Loss: 3.9339873790740967, Validation Accuracy: 10.79\n",
            "[18/150]: Training Loss: 3.967302780884963, Training Accuracy: 9.836\n",
            "Validation Loss: 3.9086116949717202, Validation Accuracy: 11.43\n",
            "[19/150]: Training Loss: 3.945032779987042, Training Accuracy: 10.19\n",
            "Validation Loss: 3.882365862528483, Validation Accuracy: 11.76\n",
            "[20/150]: Training Loss: 3.9207697831667385, Training Accuracy: 10.68\n",
            "Validation Loss: 3.8563054402669272, Validation Accuracy: 12.18\n",
            "[21/150]: Training Loss: 3.895809503702017, Training Accuracy: 11.034\n",
            "Validation Loss: 3.8310407797495523, Validation Accuracy: 12.46\n",
            "[22/150]: Training Loss: 3.87269454735976, Training Accuracy: 11.518\n",
            "Validation Loss: 3.808952808380127, Validation Accuracy: 12.48\n",
            "[23/150]: Training Loss: 3.8534568639901967, Training Accuracy: 11.846\n",
            "Validation Loss: 3.782241185506185, Validation Accuracy: 13.07\n",
            "[24/150]: Training Loss: 3.829915010012113, Training Accuracy: 12.048\n",
            "Validation Loss: 3.760414203008016, Validation Accuracy: 13.69\n",
            "[25/150]: Training Loss: 3.8085157687847433, Training Accuracy: 12.546\n",
            "Validation Loss: 3.7369075616200766, Validation Accuracy: 14.06\n",
            "[26/150]: Training Loss: 3.7978774034059963, Training Accuracy: 12.83\n",
            "Validation Loss: 3.7192533810933432, Validation Accuracy: 14.28\n",
            "[27/150]: Training Loss: 3.7712434438558726, Training Accuracy: 13.502\n",
            "Validation Loss: 3.7015438079833984, Validation Accuracy: 14.49\n",
            "[28/150]: Training Loss: 3.757168146280142, Training Accuracy: 13.28\n",
            "Validation Loss: 3.682270367940267, Validation Accuracy: 14.62\n",
            "[29/150]: Training Loss: 3.739195860349215, Training Accuracy: 13.572\n",
            "Validation Loss: 3.6604272524515786, Validation Accuracy: 15.51\n",
            "[30/150]: Training Loss: 3.7192102945767918, Training Accuracy: 14.206\n",
            "Validation Loss: 3.6448915004730225, Validation Accuracy: 15.47\n",
            "[31/150]: Training Loss: 3.7009674035585842, Training Accuracy: 14.666\n",
            "Validation Loss: 3.6245458920796714, Validation Accuracy: 16.05\n",
            "[32/150]: Training Loss: 3.685235757094163, Training Accuracy: 14.604\n",
            "Validation Loss: 3.604191780090332, Validation Accuracy: 16.37\n",
            "[33/150]: Training Loss: 3.6659323068765493, Training Accuracy: 15.21\n",
            "Validation Loss: 3.5856331984202066, Validation Accuracy: 16.73\n",
            "[34/150]: Training Loss: 3.650921583175659, Training Accuracy: 15.322\n",
            "Validation Loss: 3.5731921195983887, Validation Accuracy: 16.91\n",
            "[35/150]: Training Loss: 3.638433786538931, Training Accuracy: 15.394\n",
            "Validation Loss: 3.5550003051757812, Validation Accuracy: 17.2\n",
            "[36/150]: Training Loss: 3.615772980910081, Training Accuracy: 15.728\n",
            "Validation Loss: 3.5329747994740806, Validation Accuracy: 17.79\n",
            "[37/150]: Training Loss: 3.6038941786839414, Training Accuracy: 16.05\n",
            "Validation Loss: 3.516122579574585, Validation Accuracy: 17.6\n",
            "[38/150]: Training Loss: 3.584128581560575, Training Accuracy: 16.3\n",
            "Validation Loss: 3.501359542210897, Validation Accuracy: 17.71\n",
            "[39/150]: Training Loss: 3.5705398779649, Training Accuracy: 16.562\n",
            "Validation Loss: 3.4867658615112305, Validation Accuracy: 17.99\n",
            "[40/150]: Training Loss: 3.5499917543851414, Training Accuracy: 16.898\n",
            "Validation Loss: 3.4654527505238852, Validation Accuracy: 18.27\n",
            "[41/150]: Training Loss: 3.5377132709209738, Training Accuracy: 17.152\n",
            "Validation Loss: 3.448629140853882, Validation Accuracy: 18.51\n",
            "[42/150]: Training Loss: 3.520086728609525, Training Accuracy: 17.36\n",
            "Validation Loss: 3.4321948687235513, Validation Accuracy: 19.02\n",
            "[43/150]: Training Loss: 3.5058687833639293, Training Accuracy: 17.682\n",
            "Validation Loss: 3.4222156206766763, Validation Accuracy: 19.32\n",
            "[44/150]: Training Loss: 3.4854386219611535, Training Accuracy: 17.882\n",
            "Validation Loss: 3.4029709498087564, Validation Accuracy: 19.43\n",
            "[45/150]: Training Loss: 3.4765561543978176, Training Accuracy: 18.026\n",
            "Validation Loss: 3.391355276107788, Validation Accuracy: 19.92\n",
            "[46/150]: Training Loss: 3.459314914850088, Training Accuracy: 18.246\n",
            "Validation Loss: 3.373873710632324, Validation Accuracy: 20.06\n",
            "[47/150]: Training Loss: 3.445302651478694, Training Accuracy: 18.344\n",
            "Validation Loss: 3.358146905899048, Validation Accuracy: 20.38\n",
            "[48/150]: Training Loss: 3.437425136566162, Training Accuracy: 18.682\n",
            "Validation Loss: 3.348493973414103, Validation Accuracy: 20.42\n",
            "[49/150]: Training Loss: 3.428378838759202, Training Accuracy: 18.738\n",
            "Validation Loss: 3.337660074234009, Validation Accuracy: 20.87\n",
            "[50/150]: Training Loss: 3.4082561823037953, Training Accuracy: 19.196\n",
            "Validation Loss: 3.323828379313151, Validation Accuracy: 21.05\n",
            "[51/150]: Training Loss: 3.394208926420945, Training Accuracy: 19.342\n",
            "Validation Loss: 3.3132495880126953, Validation Accuracy: 21.3\n",
            "[52/150]: Training Loss: 3.3845279766963077, Training Accuracy: 19.668\n",
            "Validation Loss: 3.2969996134440103, Validation Accuracy: 21.48\n",
            "[53/150]: Training Loss: 3.3752853136796217, Training Accuracy: 19.65\n",
            "Validation Loss: 3.283722718556722, Validation Accuracy: 22.01\n",
            "[54/150]: Training Loss: 3.3559417174412656, Training Accuracy: 20.118\n",
            "Validation Loss: 3.273935556411743, Validation Accuracy: 22.21\n",
            "[55/150]: Training Loss: 3.3527236534998965, Training Accuracy: 20.182\n",
            "Validation Loss: 3.2600110371907554, Validation Accuracy: 22.21\n",
            "[56/150]: Training Loss: 3.33942435337947, Training Accuracy: 20.32\n",
            "Validation Loss: 3.2532562414805093, Validation Accuracy: 22.54\n",
            "[57/150]: Training Loss: 3.3295783813183126, Training Accuracy: 20.47\n",
            "Validation Loss: 3.241544167200724, Validation Accuracy: 22.6\n",
            "[58/150]: Training Loss: 3.3188119484828067, Training Accuracy: 20.912\n",
            "Validation Loss: 3.2292733987172446, Validation Accuracy: 22.89\n",
            "[59/150]: Training Loss: 3.3085557314065785, Training Accuracy: 20.83\n",
            "Validation Loss: 3.2252915700276694, Validation Accuracy: 23.05\n",
            "[60/150]: Training Loss: 3.301169615525466, Training Accuracy: 21.142\n",
            "Validation Loss: 3.211410919825236, Validation Accuracy: 23.25\n",
            "[61/150]: Training Loss: 3.2943123487325816, Training Accuracy: 21.44\n",
            "Validation Loss: 3.2039496898651123, Validation Accuracy: 23.12\n",
            "[62/150]: Training Loss: 3.2789928362919736, Training Accuracy: 21.606\n",
            "Validation Loss: 3.191706339518229, Validation Accuracy: 23.63\n",
            "[63/150]: Training Loss: 3.271783847075242, Training Accuracy: 21.548\n",
            "Validation Loss: 3.183237632115682, Validation Accuracy: 23.84\n",
            "[64/150]: Training Loss: 3.267558996494, Training Accuracy: 21.776\n",
            "Validation Loss: 3.1755964756011963, Validation Accuracy: 23.78\n",
            "[65/150]: Training Loss: 3.2593024327204776, Training Accuracy: 21.928\n",
            "Validation Loss: 3.1660290559132895, Validation Accuracy: 24.0\n",
            "[66/150]: Training Loss: 3.245825639137855, Training Accuracy: 22.07\n",
            "Validation Loss: 3.154296080271403, Validation Accuracy: 23.95\n",
            "[67/150]: Training Loss: 3.2345091563004713, Training Accuracy: 22.202\n",
            "Validation Loss: 3.1482552687327066, Validation Accuracy: 24.37\n",
            "[68/150]: Training Loss: 3.2364803827725925, Training Accuracy: 22.468\n",
            "Validation Loss: 3.1444711685180664, Validation Accuracy: 24.36\n",
            "[69/150]: Training Loss: 3.2277981501359205, Training Accuracy: 22.69\n",
            "Validation Loss: 3.13324769337972, Validation Accuracy: 24.42\n",
            "[70/150]: Training Loss: 3.2204189667334924, Training Accuracy: 22.912\n",
            "Validation Loss: 3.1285581588745117, Validation Accuracy: 24.63\n",
            "[71/150]: Training Loss: 3.212432549549983, Training Accuracy: 22.806\n",
            "Validation Loss: 3.1225887139638266, Validation Accuracy: 24.19\n",
            "[72/150]: Training Loss: 3.2032233018141527, Training Accuracy: 22.884\n",
            "Validation Loss: 3.1134212811787925, Validation Accuracy: 24.9\n",
            "[73/150]: Training Loss: 3.197613184268658, Training Accuracy: 23.006\n",
            "Validation Loss: 3.1070095698038735, Validation Accuracy: 24.96\n",
            "[74/150]: Training Loss: 3.1896161299485426, Training Accuracy: 23.14\n",
            "Validation Loss: 3.103363116582235, Validation Accuracy: 24.66\n",
            "[75/150]: Training Loss: 3.1869239256932187, Training Accuracy: 23.35\n",
            "Validation Loss: 3.0950690110524497, Validation Accuracy: 25.11\n",
            "[76/150]: Training Loss: 3.1853491159585805, Training Accuracy: 23.316\n",
            "Validation Loss: 3.083833853403727, Validation Accuracy: 25.17\n",
            "[77/150]: Training Loss: 3.174022527841421, Training Accuracy: 23.79\n",
            "Validation Loss: 3.077226718266805, Validation Accuracy: 25.58\n",
            "[78/150]: Training Loss: 3.168999726955707, Training Accuracy: 23.912\n",
            "Validation Loss: 3.0722909768422446, Validation Accuracy: 25.47\n",
            "[79/150]: Training Loss: 3.1615905394920936, Training Accuracy: 23.708\n",
            "Validation Loss: 3.069349686304728, Validation Accuracy: 25.58\n",
            "[80/150]: Training Loss: 3.151583139712994, Training Accuracy: 24.078\n",
            "Validation Loss: 3.0607732137044272, Validation Accuracy: 25.63\n",
            "[81/150]: Training Loss: 3.149446652485774, Training Accuracy: 23.998\n",
            "Validation Loss: 3.057941754659017, Validation Accuracy: 25.81\n",
            "[82/150]: Training Loss: 3.145682463279137, Training Accuracy: 24.14\n",
            "Validation Loss: 3.0518407026926675, Validation Accuracy: 25.83\n",
            "[83/150]: Training Loss: 3.143723029356736, Training Accuracy: 24.192\n",
            "Validation Loss: 3.0451351006825766, Validation Accuracy: 25.97\n",
            "[84/150]: Training Loss: 3.1309727888840895, Training Accuracy: 24.412\n",
            "Validation Loss: 3.0412493546803794, Validation Accuracy: 26.02\n",
            "[85/150]: Training Loss: 3.13380243228032, Training Accuracy: 24.424\n",
            "Validation Loss: 3.0333561102549234, Validation Accuracy: 26.26\n",
            "[86/150]: Training Loss: 3.122998604407677, Training Accuracy: 24.482\n",
            "Validation Loss: 3.027780214945475, Validation Accuracy: 26.34\n",
            "[87/150]: Training Loss: 3.1258247999044566, Training Accuracy: 24.628\n",
            "Validation Loss: 3.0237667560577393, Validation Accuracy: 26.32\n",
            "[88/150]: Training Loss: 3.111476237957294, Training Accuracy: 24.682\n",
            "Validation Loss: 3.0223042170206704, Validation Accuracy: 26.43\n",
            "[89/150]: Training Loss: 3.120484553850614, Training Accuracy: 24.518\n",
            "Validation Loss: 3.0167242685953775, Validation Accuracy: 26.77\n",
            "[90/150]: Training Loss: 3.10716673044058, Training Accuracy: 24.886\n",
            "Validation Loss: 3.0143421490987143, Validation Accuracy: 26.59\n",
            "[91/150]: Training Loss: 3.096709581521841, Training Accuracy: 25.004\n",
            "Validation Loss: 3.0087748368581138, Validation Accuracy: 26.56\n",
            "[92/150]: Training Loss: 3.1066546073326697, Training Accuracy: 24.99\n",
            "Validation Loss: 3.005091905593872, Validation Accuracy: 26.95\n",
            "[93/150]: Training Loss: 3.090373185964731, Training Accuracy: 25.092\n",
            "Validation Loss: 3.000840902328491, Validation Accuracy: 27.03\n",
            "[94/150]: Training Loss: 3.0964173537034254, Training Accuracy: 25.044\n",
            "Validation Loss: 2.997614860534668, Validation Accuracy: 26.97\n",
            "[95/150]: Training Loss: 3.084940341802744, Training Accuracy: 25.148\n",
            "Validation Loss: 2.9952355225880942, Validation Accuracy: 26.87\n",
            "[96/150]: Training Loss: 3.09445228943458, Training Accuracy: 25.232\n",
            "Validation Loss: 2.9892234007517495, Validation Accuracy: 26.98\n",
            "[97/150]: Training Loss: 3.0830492606529822, Training Accuracy: 25.54\n",
            "Validation Loss: 2.9863297939300537, Validation Accuracy: 27.35\n",
            "[98/150]: Training Loss: 3.069628440416776, Training Accuracy: 25.52\n",
            "Validation Loss: 2.9870328108469644, Validation Accuracy: 27.45\n",
            "[99/150]: Training Loss: 3.0752683602846584, Training Accuracy: 25.444\n",
            "Validation Loss: 2.9794111251831055, Validation Accuracy: 27.24\n",
            "[100/150]: Training Loss: 3.069608578315148, Training Accuracy: 25.602\n",
            "Validation Loss: 2.977992057800293, Validation Accuracy: 27.51\n",
            "[101/150]: Training Loss: 3.0671214507176328, Training Accuracy: 25.66\n",
            "Validation Loss: 2.9746710459391275, Validation Accuracy: 27.32\n",
            "[102/150]: Training Loss: 3.0730385780334473, Training Accuracy: 25.788\n",
            "Validation Loss: 2.9698847929636636, Validation Accuracy: 27.54\n",
            "[103/150]: Training Loss: 3.054584264755249, Training Accuracy: 25.852\n",
            "Validation Loss: 2.967825253804525, Validation Accuracy: 27.85\n",
            "[104/150]: Training Loss: 3.06634913958036, Training Accuracy: 25.634\n",
            "Validation Loss: 2.965172370274862, Validation Accuracy: 27.64\n",
            "[105/150]: Training Loss: 3.0517038382016697, Training Accuracy: 26.048\n",
            "Validation Loss: 2.9605621496836343, Validation Accuracy: 27.68\n",
            "[106/150]: Training Loss: 3.0615938810201793, Training Accuracy: 25.86\n",
            "Validation Loss: 2.9625186920166016, Validation Accuracy: 27.67\n",
            "[107/150]: Training Loss: 3.0499529104966383, Training Accuracy: 26.146\n",
            "Validation Loss: 2.9583574136098227, Validation Accuracy: 27.73\n",
            "[108/150]: Training Loss: 3.0448730908907375, Training Accuracy: 25.872\n",
            "Validation Loss: 2.95459246635437, Validation Accuracy: 27.94\n",
            "[109/150]: Training Loss: 3.0504057774176965, Training Accuracy: 25.964\n",
            "Validation Loss: 2.953615427017212, Validation Accuracy: 27.92\n",
            "[110/150]: Training Loss: 3.0516765851240892, Training Accuracy: 25.97\n",
            "Validation Loss: 2.9511011441548667, Validation Accuracy: 27.82\n",
            "[111/150]: Training Loss: 3.0474912019876332, Training Accuracy: 26.346\n",
            "Validation Loss: 2.9493021965026855, Validation Accuracy: 27.93\n",
            "[112/150]: Training Loss: 3.047640800476074, Training Accuracy: 26.166\n",
            "Validation Loss: 2.9490411281585693, Validation Accuracy: 28.1\n",
            "[113/150]: Training Loss: 3.0393428068894606, Training Accuracy: 26.168\n",
            "Validation Loss: 2.9449055989583335, Validation Accuracy: 28.15\n",
            "[114/150]: Training Loss: 3.0394653173593373, Training Accuracy: 26.22\n",
            "Validation Loss: 2.9426263173421225, Validation Accuracy: 28.19\n",
            "[115/150]: Training Loss: 3.0380828013786902, Training Accuracy: 26.418\n",
            "Validation Loss: 2.9426259199778237, Validation Accuracy: 28.35\n",
            "[116/150]: Training Loss: 3.028611715023334, Training Accuracy: 26.422\n",
            "Validation Loss: 2.9393649101257324, Validation Accuracy: 28.0\n",
            "[117/150]: Training Loss: 3.030808155353253, Training Accuracy: 26.422\n",
            "Validation Loss: 2.9383947054545083, Validation Accuracy: 28.26\n",
            "[118/150]: Training Loss: 3.0299956798553467, Training Accuracy: 26.366\n",
            "Validation Loss: 2.937206586201986, Validation Accuracy: 28.37\n",
            "[119/150]: Training Loss: 3.029345255631667, Training Accuracy: 26.258\n",
            "Validation Loss: 2.9358492692311606, Validation Accuracy: 28.28\n",
            "[120/150]: Training Loss: 3.027382172071017, Training Accuracy: 26.33\n",
            "Validation Loss: 2.934878349304199, Validation Accuracy: 28.35\n",
            "[121/150]: Training Loss: 3.0247208155118503, Training Accuracy: 26.736\n",
            "Validation Loss: 2.934181054433187, Validation Accuracy: 28.29\n",
            "[122/150]: Training Loss: 3.0200733771690955, Training Accuracy: 26.62\n",
            "Validation Loss: 2.932123899459839, Validation Accuracy: 28.54\n",
            "[123/150]: Training Loss: 3.0223946754749003, Training Accuracy: 26.398\n",
            "Validation Loss: 2.9316653410593667, Validation Accuracy: 28.46\n",
            "[124/150]: Training Loss: 3.0208843304560733, Training Accuracy: 26.57\n",
            "Validation Loss: 2.9322214126586914, Validation Accuracy: 28.39\n",
            "[125/150]: Training Loss: 3.020762535241934, Training Accuracy: 26.512\n",
            "Validation Loss: 2.929534435272217, Validation Accuracy: 28.53\n",
            "[126/150]: Training Loss: 3.010956544142503, Training Accuracy: 26.498\n",
            "Validation Loss: 2.9289840857187905, Validation Accuracy: 28.49\n",
            "[127/150]: Training Loss: 3.0190560817718506, Training Accuracy: 26.902\n",
            "Validation Loss: 2.9280758698781333, Validation Accuracy: 28.4\n",
            "[128/150]: Training Loss: 3.016689117138202, Training Accuracy: 26.766\n",
            "Validation Loss: 2.9267163276672363, Validation Accuracy: 28.58\n",
            "[129/150]: Training Loss: 3.013255009284386, Training Accuracy: 26.838\n",
            "Validation Loss: 2.926602840423584, Validation Accuracy: 28.63\n",
            "[130/150]: Training Loss: 3.008544298318716, Training Accuracy: 26.784\n",
            "Validation Loss: 2.925427039464315, Validation Accuracy: 28.64\n",
            "[131/150]: Training Loss: 3.0117177046262302, Training Accuracy: 26.518\n",
            "Validation Loss: 2.925293207168579, Validation Accuracy: 28.49\n",
            "[132/150]: Training Loss: 3.0137419517223654, Training Accuracy: 26.672\n",
            "Validation Loss: 2.9240074157714844, Validation Accuracy: 28.62\n",
            "[133/150]: Training Loss: 3.0168117743272047, Training Accuracy: 26.534\n",
            "Validation Loss: 2.9242477416992188, Validation Accuracy: 28.53\n",
            "[134/150]: Training Loss: 3.0148205206944394, Training Accuracy: 26.644\n",
            "Validation Loss: 2.9236361980438232, Validation Accuracy: 28.59\n",
            "[135/150]: Training Loss: 3.0078163146972656, Training Accuracy: 26.776\n",
            "Validation Loss: 2.922917683919271, Validation Accuracy: 28.69\n",
            "[136/150]: Training Loss: 3.0173892241257887, Training Accuracy: 26.794\n",
            "Validation Loss: 2.922706445058187, Validation Accuracy: 28.62\n",
            "[137/150]: Training Loss: 3.0146707388070912, Training Accuracy: 26.676\n",
            "Validation Loss: 2.922335624694824, Validation Accuracy: 28.61\n",
            "[138/150]: Training Loss: 3.010614743599525, Training Accuracy: 26.824\n",
            "Validation Loss: 2.921966473261515, Validation Accuracy: 28.58\n",
            "[139/150]: Training Loss: 3.014005239193256, Training Accuracy: 26.566\n",
            "Validation Loss: 2.921886603037516, Validation Accuracy: 28.76\n",
            "[140/150]: Training Loss: 3.0139314211331882, Training Accuracy: 26.826\n",
            "Validation Loss: 2.921703894933065, Validation Accuracy: 28.65\n",
            "[141/150]: Training Loss: 3.0081347135397105, Training Accuracy: 26.866\n",
            "Validation Loss: 2.921877384185791, Validation Accuracy: 28.66\n",
            "[142/150]: Training Loss: 3.010774318988507, Training Accuracy: 27.064\n",
            "Validation Loss: 2.921614408493042, Validation Accuracy: 28.72\n",
            "[143/150]: Training Loss: 3.0070647643162656, Training Accuracy: 26.66\n",
            "Validation Loss: 2.9214425086975098, Validation Accuracy: 28.62\n",
            "[144/150]: Training Loss: 3.010379406122061, Training Accuracy: 26.672\n",
            "Validation Loss: 2.9214176336924234, Validation Accuracy: 28.66\n",
            "[145/150]: Training Loss: 3.0113004721128025, Training Accuracy: 26.766\n",
            "Validation Loss: 2.9213058948516846, Validation Accuracy: 28.66\n",
            "[146/150]: Training Loss: 3.016514778137207, Training Accuracy: 26.868\n",
            "Validation Loss: 2.921256939570109, Validation Accuracy: 28.67\n",
            "[147/150]: Training Loss: 3.013971310395461, Training Accuracy: 26.528\n",
            "Validation Loss: 2.921257495880127, Validation Accuracy: 28.66\n",
            "[148/150]: Training Loss: 3.0143010432903585, Training Accuracy: 26.594\n",
            "Validation Loss: 2.9212076663970947, Validation Accuracy: 28.67\n",
            "[149/150]: Training Loss: 3.01210671204787, Training Accuracy: 26.668\n",
            "Validation Loss: 2.921198527018229, Validation Accuracy: 28.68\n",
            "[150/150]: Training Loss: 3.010485594089215, Training Accuracy: 27.018\n",
            "Validation Loss: 2.921196937561035, Validation Accuracy: 28.68\n",
            "**********************************************************************\n",
            "Test Loss: 2.921196937561035, Test Accuracy: 28.68\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>█▁▃</td></tr><tr><td>Test Loss</td><td>▁█▂</td></tr><tr><td>Train Accuracy</td><td>▁▁▁▂▃▃▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>Train Loss</td><td>██▇▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>28.68</td></tr><tr><td>Test Loss</td><td>2.9212</td></tr><tr><td>Train Accuracy</td><td>27.018</td></tr><tr><td>Train Loss</td><td>3.01049</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=4096 learning_rate=0.0012 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j81b4d42' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j81b4d42</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_070246-j81b4d42/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 8192\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_072517-j7f6j52c</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j7f6j52c' target=\"_blank\">batch_size=8192 learning_rate=0.001697056274847714 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j7f6j52c' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches/runs/j7f6j52c</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605092797960554, Training Accuracy: 1.07\n",
            "Validation Loss: 4.604321002960205, Validation Accuracy: 1.5\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.53 GiB. GPU ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[33], line 58\u001b[0m\n\u001b[1;32m     54\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mCosineAnnealingLR(optimizer, T_max\u001b[38;5;241m=\u001b[39mnum_epochs)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 58\u001b[0m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_train_loader_large_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_test_loader_large_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43moriginal_test_loader_large_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLAMB_Large_Batches\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_wandb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     72\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[22], line 46\u001b[0m, in \u001b[0;36mrun_training\u001b[0;34m(num_epochs, model, trainloader, validationloader, testloader, optimizer, scheduler, loss_fn, device, optimizer_name, accumulation_steps, hyperparameters, is_wandb, n_epochs_stop)\u001b[0m\n\u001b[1;32m     40\u001b[0m   wandb\u001b[38;5;241m.\u001b[39minit(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mrun_id, name\u001b[38;5;241m=\u001b[39mrun_name, project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcifar100-training-mldl2024-baseline-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimizer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     41\u001b[0m                  config\u001b[38;5;241m=\u001b[39mhyperparameters \u001b[38;5;28;01mif\u001b[39;00m hyperparameters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {},\n\u001b[1;32m     42\u001b[0m                  resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow\u001b[39m\u001b[38;5;124m\"\u001b[39m, reinit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Call the training function for each epoch\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_wandb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_wandb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     48\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Update learning rate based on scheduler\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[19], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, loss_fn, accumulation_steps, device, is_wandb)\u001b[0m\n\u001b[1;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(outputs, targets)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Backpropagation\u001b[39;00m\n\u001b[1;32m     16\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     17\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Repos/University/MLDL/Project/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.53 GiB. GPU "
          ]
        }
      ],
      "source": [
        "# check the lr updates from paper 18\n",
        "\n",
        "num_epochs = 150\n",
        "wd = 1e-04\n",
        "batch_sizes = [512, 1024, 2048, 4096, 8192, 16384 , 32768]\n",
        "learning_rates = [4.8/(2**i * 10**3) for i in reversed([x * 0.5 for x in range(0, 8)])]\n",
        "\n",
        "for i, batch_size in enumerate(batch_sizes):\n",
        "  print('='*50)\n",
        "  print(f'Batch size: {batch_size}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rates[i],\n",
        "    'weight_decay' : wd\n",
        "  }\n",
        "\n",
        "  if batch_size <= 4096:\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= batch_size)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LAMB(model.parameters(), learning_rate=learning_rates[i], weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LAMB_Large_Batches',\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )\n",
        "  else:\n",
        "    accumulation_steps = batch_size // 4096\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= batch_size)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LAMB(model.parameters(), learning_rate=learning_rates[i], weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LAMB_Large_Batches',\n",
        "        accumulation_steps=accumulation_steps,\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GXZaFXruZI_"
      },
      "source": [
        "### Local SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hRd9SL7iRiKl"
      },
      "outputs": [],
      "source": [
        "# Initialize a model and save its initial parameters\n",
        "initial_model = LeNet5()\n",
        "initial_state_dict = initial_model.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "I8hvzRbQW32s"
      },
      "outputs": [],
      "source": [
        "def synchronize(models):\n",
        "  for params in zip(*[model.parameters() for model in models]):\n",
        "    param_avg = torch.mean(torch.stack([param.data for param in params]), dim=0)\n",
        "    for param in params:\n",
        "      param.data = param_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "def local_SGD(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs):\n",
        "  total_start_time = time.time()\n",
        "\n",
        "  iterations = num_epochs // j\n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  models = [LeNet5().to(device) for _ in range(k)]\n",
        "  for model in models:\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "  #Initialize optimizers for each chunk\n",
        "  optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in models]\n",
        "  # Initialize a scheduler for each optimizer\n",
        "  schedulers = [torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations) for optimizer in optimizers]\n",
        "\n",
        "  for local_step in range(j):\n",
        "    for i, shard_loader in enumerate(shard_loaders):\n",
        "      train_start_time = time.time()\n",
        "      for epoch in range(iterations):\n",
        "        train_loss, train_accuracy = train(models[i], shard_loader, optimizers[i], loss_fn, device = device,  is_wandb=False)\n",
        "        schedulers[i].step()\n",
        "        print(f'Worker {i+1}, [{epoch+1:02}/{iterations}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {i+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "    synchronize(models)\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(models[0],original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Local Step {local_step+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "    \n",
        "\n",
        "  total_end_time = time.time()\n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for local_SGD: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.346933830, Training Accuracy: 4.204\n",
            "Worker 1, [02/37]: Training Loss: 3.870251820, Training Accuracy: 9.920\n",
            "Worker 1, [03/37]: Training Loss: 3.620391471, Training Accuracy: 13.928\n",
            "Worker 1, [04/37]: Training Loss: 3.406734371, Training Accuracy: 17.604\n",
            "Worker 1, [05/37]: Training Loss: 3.227851952, Training Accuracy: 20.680\n",
            "Worker 1, [06/37]: Training Loss: 3.081411375, Training Accuracy: 23.228\n",
            "Worker 1, [07/37]: Training Loss: 2.959613263, Training Accuracy: 25.768\n",
            "Worker 1, [08/37]: Training Loss: 2.835409520, Training Accuracy: 28.272\n",
            "Worker 1, [09/37]: Training Loss: 2.730215076, Training Accuracy: 30.212\n",
            "Worker 1, [10/37]: Training Loss: 2.635933402, Training Accuracy: 32.068\n",
            "Worker 1, [11/37]: Training Loss: 2.558617586, Training Accuracy: 34.012\n",
            "Worker 1, [12/37]: Training Loss: 2.475335482, Training Accuracy: 35.736\n",
            "Worker 1, [13/37]: Training Loss: 2.412462376, Training Accuracy: 37.100\n",
            "Worker 1, [14/37]: Training Loss: 2.337459444, Training Accuracy: 38.556\n",
            "Worker 1, [15/37]: Training Loss: 2.269182216, Training Accuracy: 40.132\n",
            "Worker 1, [16/37]: Training Loss: 2.209659675, Training Accuracy: 40.984\n",
            "Worker 1, [17/37]: Training Loss: 2.141477864, Training Accuracy: 42.572\n",
            "Worker 1, [18/37]: Training Loss: 2.067792155, Training Accuracy: 44.336\n",
            "Worker 1, [19/37]: Training Loss: 2.009028203, Training Accuracy: 45.624\n",
            "Worker 1, [20/37]: Training Loss: 1.950112686, Training Accuracy: 47.068\n",
            "Worker 1, [21/37]: Training Loss: 1.896399751, Training Accuracy: 48.304\n",
            "Worker 1, [22/37]: Training Loss: 1.817495881, Training Accuracy: 49.948\n",
            "Worker 1, [23/37]: Training Loss: 1.768419051, Training Accuracy: 51.460\n",
            "Worker 1, [24/37]: Training Loss: 1.714421099, Training Accuracy: 52.856\n",
            "Worker 1, [25/37]: Training Loss: 1.665269002, Training Accuracy: 53.524\n",
            "Worker 1, [26/37]: Training Loss: 1.602849198, Training Accuracy: 55.372\n",
            "Worker 1, [27/37]: Training Loss: 1.547299752, Training Accuracy: 56.504\n",
            "Worker 1, [28/37]: Training Loss: 1.491854038, Training Accuracy: 58.004\n",
            "Worker 1, [29/37]: Training Loss: 1.450439511, Training Accuracy: 59.172\n",
            "Worker 1, [30/37]: Training Loss: 1.413344342, Training Accuracy: 60.248\n",
            "Worker 1, [31/37]: Training Loss: 1.366656476, Training Accuracy: 61.400\n",
            "Worker 1, [32/37]: Training Loss: 1.331591014, Training Accuracy: 62.608\n",
            "Worker 1, [33/37]: Training Loss: 1.298676502, Training Accuracy: 63.468\n",
            "Worker 1, [34/37]: Training Loss: 1.276548143, Training Accuracy: 64.212\n",
            "Worker 1, [35/37]: Training Loss: 1.264215830, Training Accuracy: 64.308\n",
            "Worker 1, [36/37]: Training Loss: 1.253760742, Training Accuracy: 65.132\n",
            "Worker 1, [37/37]: Training Loss: 1.243993438, Training Accuracy: 65.052\n",
            "Time taken for training worker 1: 0:06:57.772261\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.335953256, Training Accuracy: 4.240\n",
            "Worker 2, [02/37]: Training Loss: 3.854078326, Training Accuracy: 10.436\n",
            "Worker 2, [03/37]: Training Loss: 3.580992210, Training Accuracy: 14.624\n",
            "Worker 2, [04/37]: Training Loss: 3.394571095, Training Accuracy: 18.052\n",
            "Worker 2, [05/37]: Training Loss: 3.231371858, Training Accuracy: 20.596\n",
            "Worker 2, [06/37]: Training Loss: 3.094290311, Training Accuracy: 23.520\n",
            "Worker 2, [07/37]: Training Loss: 2.956371501, Training Accuracy: 26.064\n",
            "Worker 2, [08/37]: Training Loss: 2.859478649, Training Accuracy: 27.744\n",
            "Worker 2, [09/37]: Training Loss: 2.746913511, Training Accuracy: 30.148\n",
            "Worker 2, [10/37]: Training Loss: 2.655629774, Training Accuracy: 32.036\n",
            "Worker 2, [11/37]: Training Loss: 2.581525729, Training Accuracy: 33.252\n",
            "Worker 2, [12/37]: Training Loss: 2.504083479, Training Accuracy: 34.716\n",
            "Worker 2, [13/37]: Training Loss: 2.421066763, Training Accuracy: 36.264\n",
            "Worker 2, [14/37]: Training Loss: 2.364145285, Training Accuracy: 37.708\n",
            "Worker 2, [15/37]: Training Loss: 2.291295568, Training Accuracy: 39.472\n",
            "Worker 2, [16/37]: Training Loss: 2.213315791, Training Accuracy: 40.916\n",
            "Worker 2, [17/37]: Training Loss: 2.172058371, Training Accuracy: 41.972\n",
            "Worker 2, [18/37]: Training Loss: 2.093776642, Training Accuracy: 43.644\n",
            "Worker 2, [19/37]: Training Loss: 2.026818507, Training Accuracy: 45.136\n",
            "Worker 2, [20/37]: Training Loss: 1.963965373, Training Accuracy: 46.600\n",
            "Worker 2, [21/37]: Training Loss: 1.911598911, Training Accuracy: 47.936\n",
            "Worker 2, [22/37]: Training Loss: 1.843257026, Training Accuracy: 49.436\n",
            "Worker 2, [23/37]: Training Loss: 1.785788538, Training Accuracy: 50.672\n",
            "Worker 2, [24/37]: Training Loss: 1.721950444, Training Accuracy: 52.116\n",
            "Worker 2, [25/37]: Training Loss: 1.678197159, Training Accuracy: 53.416\n",
            "Worker 2, [26/37]: Training Loss: 1.608235446, Training Accuracy: 55.052\n",
            "Worker 2, [27/37]: Training Loss: 1.557964069, Training Accuracy: 56.084\n",
            "Worker 2, [28/37]: Training Loss: 1.513678363, Training Accuracy: 57.664\n",
            "Worker 2, [29/37]: Training Loss: 1.463810800, Training Accuracy: 58.824\n",
            "Worker 2, [30/37]: Training Loss: 1.414017477, Training Accuracy: 60.036\n",
            "Worker 2, [31/37]: Training Loss: 1.387273318, Training Accuracy: 60.892\n",
            "Worker 2, [32/37]: Training Loss: 1.345971551, Training Accuracy: 61.960\n",
            "Worker 2, [33/37]: Training Loss: 1.316278005, Training Accuracy: 62.836\n",
            "Worker 2, [34/37]: Training Loss: 1.282244003, Training Accuracy: 63.824\n",
            "Worker 2, [35/37]: Training Loss: 1.263773558, Training Accuracy: 64.368\n",
            "Worker 2, [36/37]: Training Loss: 1.255194416, Training Accuracy: 64.336\n",
            "Worker 2, [37/37]: Training Loss: 1.246473845, Training Accuracy: 64.876\n",
            "Time taken for training worker 2: 0:07:03.735111\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.008125\n",
            "Local Step 01: Test Loss: 2.475470090, Test Accuracy: 36.310\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.432788741, Training Accuracy: 37.336\n",
            "Worker 1, [02/37]: Training Loss: 2.397832296, Training Accuracy: 38.344\n",
            "Worker 1, [03/37]: Training Loss: 2.285190594, Training Accuracy: 40.336\n",
            "Worker 1, [04/37]: Training Loss: 2.173438736, Training Accuracy: 42.252\n",
            "Worker 1, [05/37]: Training Loss: 2.099721456, Training Accuracy: 43.732\n",
            "Worker 1, [06/37]: Training Loss: 2.045842317, Training Accuracy: 44.876\n",
            "Worker 1, [07/37]: Training Loss: 2.005463145, Training Accuracy: 45.848\n",
            "Worker 1, [08/37]: Training Loss: 1.966942744, Training Accuracy: 46.608\n",
            "Worker 1, [09/37]: Training Loss: 1.943709526, Training Accuracy: 46.964\n",
            "Worker 1, [10/37]: Training Loss: 1.912984545, Training Accuracy: 48.032\n",
            "Worker 1, [11/37]: Training Loss: 1.884547610, Training Accuracy: 48.760\n",
            "Worker 1, [12/37]: Training Loss: 1.881149195, Training Accuracy: 48.724\n",
            "Worker 1, [13/37]: Training Loss: 1.856925401, Training Accuracy: 49.188\n",
            "Worker 1, [14/37]: Training Loss: 1.846666015, Training Accuracy: 49.444\n",
            "Worker 1, [15/37]: Training Loss: 1.836862628, Training Accuracy: 49.496\n",
            "Worker 1, [16/37]: Training Loss: 1.838099764, Training Accuracy: 49.092\n",
            "Worker 1, [17/37]: Training Loss: 1.828173239, Training Accuracy: 49.452\n",
            "Worker 1, [18/37]: Training Loss: 1.843572313, Training Accuracy: 49.408\n",
            "Worker 1, [19/37]: Training Loss: 1.822528102, Training Accuracy: 49.744\n",
            "Worker 1, [20/37]: Training Loss: 1.837240307, Training Accuracy: 49.460\n",
            "Worker 1, [21/37]: Training Loss: 1.830850442, Training Accuracy: 49.464\n",
            "Worker 1, [22/37]: Training Loss: 1.835888606, Training Accuracy: 49.140\n",
            "Worker 1, [23/37]: Training Loss: 1.815421275, Training Accuracy: 49.856\n",
            "Worker 1, [24/37]: Training Loss: 1.815408384, Training Accuracy: 49.384\n",
            "Worker 1, [25/37]: Training Loss: 1.825419417, Training Accuracy: 49.304\n",
            "Worker 1, [26/37]: Training Loss: 1.816687108, Training Accuracy: 50.020\n",
            "Worker 1, [27/37]: Training Loss: 1.825883023, Training Accuracy: 49.524\n",
            "Worker 1, [28/37]: Training Loss: 1.836849593, Training Accuracy: 49.848\n",
            "Worker 1, [29/37]: Training Loss: 1.800945607, Training Accuracy: 50.068\n",
            "Worker 1, [30/37]: Training Loss: 1.814302412, Training Accuracy: 49.944\n",
            "Worker 1, [31/37]: Training Loss: 1.817894403, Training Accuracy: 49.848\n",
            "Worker 1, [32/37]: Training Loss: 1.805135403, Training Accuracy: 50.260\n",
            "Worker 1, [33/37]: Training Loss: 1.790641870, Training Accuracy: 50.412\n",
            "Worker 1, [34/37]: Training Loss: 1.782956526, Training Accuracy: 50.372\n",
            "Worker 1, [35/37]: Training Loss: 1.769122681, Training Accuracy: 50.844\n",
            "Worker 1, [36/37]: Training Loss: 1.764171895, Training Accuracy: 50.900\n",
            "Worker 1, [37/37]: Training Loss: 1.766541025, Training Accuracy: 51.084\n",
            "Time taken for training worker 1: 0:06:50.256426\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.519054159, Training Accuracy: 38.524\n",
            "Worker 2, [02/37]: Training Loss: 2.464511711, Training Accuracy: 39.244\n",
            "Worker 2, [03/37]: Training Loss: 2.346797820, Training Accuracy: 41.216\n",
            "Worker 2, [04/37]: Training Loss: 2.279160099, Training Accuracy: 42.232\n",
            "Worker 2, [05/37]: Training Loss: 2.214430965, Training Accuracy: 43.620\n",
            "Worker 2, [06/37]: Training Loss: 2.152280229, Training Accuracy: 44.420\n",
            "Worker 2, [07/37]: Training Loss: 2.091944866, Training Accuracy: 45.864\n",
            "Worker 2, [08/37]: Training Loss: 2.035726429, Training Accuracy: 46.332\n",
            "Worker 2, [09/37]: Training Loss: 1.986140339, Training Accuracy: 47.804\n",
            "Worker 2, [10/37]: Training Loss: 1.925920213, Training Accuracy: 49.076\n",
            "Worker 2, [11/37]: Training Loss: 1.892236698, Training Accuracy: 49.428\n",
            "Worker 2, [12/37]: Training Loss: 1.842991268, Training Accuracy: 50.672\n",
            "Worker 2, [13/37]: Training Loss: 1.810747559, Training Accuracy: 51.188\n",
            "Worker 2, [14/37]: Training Loss: 1.781936263, Training Accuracy: 51.768\n",
            "Worker 2, [15/37]: Training Loss: 1.745121771, Training Accuracy: 52.244\n",
            "Worker 2, [16/37]: Training Loss: 1.727969273, Training Accuracy: 52.804\n",
            "Worker 2, [17/37]: Training Loss: 1.712914819, Training Accuracy: 53.104\n",
            "Worker 2, [18/37]: Training Loss: 1.701883606, Training Accuracy: 53.236\n",
            "Worker 2, [19/37]: Training Loss: 1.682427594, Training Accuracy: 53.968\n",
            "Worker 2, [20/37]: Training Loss: 1.671909727, Training Accuracy: 53.668\n",
            "Worker 2, [21/37]: Training Loss: 1.657730270, Training Accuracy: 53.876\n",
            "Worker 2, [22/37]: Training Loss: 1.675440448, Training Accuracy: 53.516\n",
            "Worker 2, [23/37]: Training Loss: 1.680264741, Training Accuracy: 53.164\n",
            "Worker 2, [24/37]: Training Loss: 1.668475804, Training Accuracy: 53.496\n",
            "Worker 2, [25/37]: Training Loss: 1.680219520, Training Accuracy: 53.900\n",
            "Worker 2, [26/37]: Training Loss: 1.657749396, Training Accuracy: 53.804\n",
            "Worker 2, [27/37]: Training Loss: 1.669926161, Training Accuracy: 53.276\n",
            "Worker 2, [28/37]: Training Loss: 1.681128841, Training Accuracy: 53.264\n",
            "Worker 2, [29/37]: Training Loss: 1.685092350, Training Accuracy: 53.240\n",
            "Worker 2, [30/37]: Training Loss: 1.695062655, Training Accuracy: 52.820\n",
            "Worker 2, [31/37]: Training Loss: 1.692605947, Training Accuracy: 52.968\n",
            "Worker 2, [32/37]: Training Loss: 1.704485581, Training Accuracy: 52.540\n",
            "Worker 2, [33/37]: Training Loss: 1.686156026, Training Accuracy: 52.952\n",
            "Worker 2, [34/37]: Training Loss: 1.695342046, Training Accuracy: 52.872\n",
            "Worker 2, [35/37]: Training Loss: 1.681966687, Training Accuracy: 53.012\n",
            "Worker 2, [36/37]: Training Loss: 1.662629045, Training Accuracy: 53.704\n",
            "Worker 2, [37/37]: Training Loss: 1.658543284, Training Accuracy: 53.756\n",
            "Time taken for training worker 2: 0:06:53.449373\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000592\n",
            "Local Step 02: Test Loss: 2.220306408, Test Accuracy: 44.000\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.232138074, Training Accuracy: 41.952\n",
            "Worker 1, [02/37]: Training Loss: 2.025541508, Training Accuracy: 45.920\n",
            "Worker 1, [03/37]: Training Loss: 1.917550284, Training Accuracy: 48.428\n",
            "Worker 1, [04/37]: Training Loss: 1.836218607, Training Accuracy: 49.844\n",
            "Worker 1, [05/37]: Training Loss: 1.789788568, Training Accuracy: 51.220\n",
            "Worker 1, [06/37]: Training Loss: 1.738754175, Training Accuracy: 52.088\n",
            "Worker 1, [07/37]: Training Loss: 1.683552034, Training Accuracy: 53.544\n",
            "Worker 1, [08/37]: Training Loss: 1.647031574, Training Accuracy: 54.176\n",
            "Worker 1, [09/37]: Training Loss: 1.606996179, Training Accuracy: 55.144\n",
            "Worker 1, [10/37]: Training Loss: 1.556789461, Training Accuracy: 55.960\n",
            "Worker 1, [11/37]: Training Loss: 1.510191279, Training Accuracy: 57.356\n",
            "Worker 1, [12/37]: Training Loss: 1.461284335, Training Accuracy: 58.512\n",
            "Worker 1, [13/37]: Training Loss: 1.417520674, Training Accuracy: 59.640\n",
            "Worker 1, [14/37]: Training Loss: 1.373465790, Training Accuracy: 60.412\n",
            "Worker 1, [15/37]: Training Loss: 1.321234496, Training Accuracy: 61.896\n",
            "Worker 1, [16/37]: Training Loss: 1.268260773, Training Accuracy: 63.396\n",
            "Worker 1, [17/37]: Training Loss: 1.227871743, Training Accuracy: 64.260\n",
            "Worker 1, [18/37]: Training Loss: 1.171755397, Training Accuracy: 65.500\n",
            "Worker 1, [19/37]: Training Loss: 1.117122418, Training Accuracy: 67.052\n",
            "Worker 1, [20/37]: Training Loss: 1.070369393, Training Accuracy: 68.560\n",
            "Worker 1, [21/37]: Training Loss: 1.002571877, Training Accuracy: 70.688\n",
            "Worker 1, [22/37]: Training Loss: 0.962227234, Training Accuracy: 71.472\n",
            "Worker 1, [23/37]: Training Loss: 0.915835659, Training Accuracy: 72.708\n",
            "Worker 1, [24/37]: Training Loss: 0.831296125, Training Accuracy: 75.296\n",
            "Worker 1, [25/37]: Training Loss: 0.803009839, Training Accuracy: 76.180\n",
            "Worker 1, [26/37]: Training Loss: 0.753290513, Training Accuracy: 77.512\n",
            "Worker 1, [27/37]: Training Loss: 0.722711525, Training Accuracy: 78.396\n",
            "Worker 1, [28/37]: Training Loss: 0.674268994, Training Accuracy: 79.944\n",
            "Worker 1, [29/37]: Training Loss: 0.634840521, Training Accuracy: 81.536\n",
            "Worker 1, [30/37]: Training Loss: 0.610157425, Training Accuracy: 81.904\n",
            "Worker 1, [31/37]: Training Loss: 0.571642991, Training Accuracy: 83.172\n",
            "Worker 1, [32/37]: Training Loss: 0.543937358, Training Accuracy: 83.948\n",
            "Worker 1, [33/37]: Training Loss: 0.536759709, Training Accuracy: 84.160\n",
            "Worker 1, [34/37]: Training Loss: 0.507790954, Training Accuracy: 85.236\n",
            "Worker 1, [35/37]: Training Loss: 0.492949661, Training Accuracy: 85.560\n",
            "Worker 1, [36/37]: Training Loss: 0.498092185, Training Accuracy: 85.652\n",
            "Worker 1, [37/37]: Training Loss: 0.481761846, Training Accuracy: 86.096\n",
            "Time taken for training worker 1: 0:06:53.736414\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.300083916, Training Accuracy: 41.308\n",
            "Worker 2, [02/37]: Training Loss: 1.996313827, Training Accuracy: 46.720\n",
            "Worker 2, [03/37]: Training Loss: 1.909187501, Training Accuracy: 48.600\n",
            "Worker 2, [04/37]: Training Loss: 1.824105219, Training Accuracy: 50.564\n",
            "Worker 2, [05/37]: Training Loss: 1.774564381, Training Accuracy: 51.440\n",
            "Worker 2, [06/37]: Training Loss: 1.707546422, Training Accuracy: 52.732\n",
            "Worker 2, [07/37]: Training Loss: 1.667779175, Training Accuracy: 53.952\n",
            "Worker 2, [08/37]: Training Loss: 1.634289013, Training Accuracy: 54.680\n",
            "Worker 2, [09/37]: Training Loss: 1.559580896, Training Accuracy: 56.480\n",
            "Worker 2, [10/37]: Training Loss: 1.517654250, Training Accuracy: 57.368\n",
            "Worker 2, [11/37]: Training Loss: 1.498040622, Training Accuracy: 57.864\n",
            "Worker 2, [12/37]: Training Loss: 1.425619020, Training Accuracy: 59.520\n",
            "Worker 2, [13/37]: Training Loss: 1.378430978, Training Accuracy: 60.396\n",
            "Worker 2, [14/37]: Training Loss: 1.341570542, Training Accuracy: 61.504\n",
            "Worker 2, [15/37]: Training Loss: 1.286219667, Training Accuracy: 62.868\n",
            "Worker 2, [16/37]: Training Loss: 1.257303183, Training Accuracy: 63.292\n",
            "Worker 2, [17/37]: Training Loss: 1.188436686, Training Accuracy: 65.404\n",
            "Worker 2, [18/37]: Training Loss: 1.139369673, Training Accuracy: 66.948\n",
            "Worker 2, [19/37]: Training Loss: 1.103571170, Training Accuracy: 67.600\n",
            "Worker 2, [20/37]: Training Loss: 1.039885713, Training Accuracy: 69.032\n",
            "Worker 2, [21/37]: Training Loss: 0.973318069, Training Accuracy: 71.440\n",
            "Worker 2, [22/37]: Training Loss: 0.929057169, Training Accuracy: 72.440\n",
            "Worker 2, [23/37]: Training Loss: 0.881451676, Training Accuracy: 73.896\n",
            "Worker 2, [24/37]: Training Loss: 0.830103540, Training Accuracy: 75.216\n",
            "Worker 2, [25/37]: Training Loss: 0.779896965, Training Accuracy: 76.768\n",
            "Worker 2, [26/37]: Training Loss: 0.738071151, Training Accuracy: 77.820\n",
            "Worker 2, [27/37]: Training Loss: 0.690932537, Training Accuracy: 79.568\n",
            "Worker 2, [28/37]: Training Loss: 0.642877583, Training Accuracy: 80.740\n",
            "Worker 2, [29/37]: Training Loss: 0.606967472, Training Accuracy: 82.248\n",
            "Worker 2, [30/37]: Training Loss: 0.574448963, Training Accuracy: 83.048\n",
            "Worker 2, [31/37]: Training Loss: 0.551925309, Training Accuracy: 83.800\n",
            "Worker 2, [32/37]: Training Loss: 0.528277208, Training Accuracy: 84.672\n",
            "Worker 2, [33/37]: Training Loss: 0.505987910, Training Accuracy: 85.320\n",
            "Worker 2, [34/37]: Training Loss: 0.495906272, Training Accuracy: 85.604\n",
            "Worker 2, [35/37]: Training Loss: 0.486601857, Training Accuracy: 86.040\n",
            "Worker 2, [36/37]: Training Loss: 0.471102916, Training Accuracy: 86.452\n",
            "Worker 2, [37/37]: Training Loss: 0.465594389, Training Accuracy: 86.800\n",
            "Time taken for training worker 2: 0:06:53.769529\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000632\n",
            "Local Step 03: Test Loss: 2.177777495, Test Accuracy: 52.580\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 1.995879439, Training Accuracy: 53.544\n",
            "Worker 1, [02/37]: Training Loss: 1.976348170, Training Accuracy: 53.176\n",
            "Worker 1, [03/37]: Training Loss: 1.893017505, Training Accuracy: 53.428\n",
            "Worker 1, [04/37]: Training Loss: 1.797419237, Training Accuracy: 53.772\n",
            "Worker 1, [05/37]: Training Loss: 1.713399713, Training Accuracy: 54.540\n",
            "Worker 1, [06/37]: Training Loss: 1.646399273, Training Accuracy: 55.796\n",
            "Worker 1, [07/37]: Training Loss: 1.575528552, Training Accuracy: 57.052\n",
            "Worker 1, [08/37]: Training Loss: 1.510918859, Training Accuracy: 58.212\n",
            "Worker 1, [09/37]: Training Loss: 1.465158349, Training Accuracy: 59.636\n",
            "Worker 1, [10/37]: Training Loss: 1.412229668, Training Accuracy: 60.776\n",
            "Worker 1, [11/37]: Training Loss: 1.364635725, Training Accuracy: 61.516\n",
            "Worker 1, [12/37]: Training Loss: 1.330431786, Training Accuracy: 61.940\n",
            "Worker 1, [13/37]: Training Loss: 1.290413091, Training Accuracy: 62.868\n",
            "Worker 1, [14/37]: Training Loss: 1.277946119, Training Accuracy: 63.248\n",
            "Worker 1, [15/37]: Training Loss: 1.259801941, Training Accuracy: 63.760\n",
            "Worker 1, [16/37]: Training Loss: 1.245313214, Training Accuracy: 64.000\n",
            "Worker 1, [17/37]: Training Loss: 1.225334429, Training Accuracy: 64.600\n",
            "Worker 1, [18/37]: Training Loss: 1.223382260, Training Accuracy: 64.156\n",
            "Worker 1, [19/37]: Training Loss: 1.236630912, Training Accuracy: 63.852\n",
            "Worker 1, [20/37]: Training Loss: 1.244410053, Training Accuracy: 63.800\n",
            "Worker 1, [21/37]: Training Loss: 1.263831700, Training Accuracy: 63.032\n",
            "Worker 1, [22/37]: Training Loss: 1.268534193, Training Accuracy: 62.908\n",
            "Worker 1, [23/37]: Training Loss: 1.286226573, Training Accuracy: 62.724\n",
            "Worker 1, [24/37]: Training Loss: 1.300755958, Training Accuracy: 62.340\n",
            "Worker 1, [25/37]: Training Loss: 1.322366198, Training Accuracy: 61.592\n",
            "Worker 1, [26/37]: Training Loss: 1.340680673, Training Accuracy: 61.108\n",
            "Worker 1, [27/37]: Training Loss: 1.358587034, Training Accuracy: 60.676\n",
            "Worker 1, [28/37]: Training Loss: 1.368885356, Training Accuracy: 60.580\n",
            "Worker 1, [29/37]: Training Loss: 1.397896638, Training Accuracy: 59.736\n",
            "Worker 1, [30/37]: Training Loss: 1.406910694, Training Accuracy: 60.040\n",
            "Worker 1, [31/37]: Training Loss: 1.430322038, Training Accuracy: 59.188\n",
            "Worker 1, [32/37]: Training Loss: 1.420877836, Training Accuracy: 59.528\n",
            "Worker 1, [33/37]: Training Loss: 1.414822780, Training Accuracy: 59.532\n",
            "Worker 1, [34/37]: Training Loss: 1.449606277, Training Accuracy: 58.776\n",
            "Worker 1, [35/37]: Training Loss: 1.451875314, Training Accuracy: 58.808\n",
            "Worker 1, [36/37]: Training Loss: 1.440347400, Training Accuracy: 59.100\n",
            "Worker 1, [37/37]: Training Loss: 1.411020159, Training Accuracy: 59.656\n",
            "Time taken for training worker 1: 0:06:54.447096\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.234784379, Training Accuracy: 44.084\n",
            "Worker 2, [02/37]: Training Loss: 2.157724431, Training Accuracy: 45.540\n",
            "Worker 2, [03/37]: Training Loss: 2.043437094, Training Accuracy: 47.124\n",
            "Worker 2, [04/37]: Training Loss: 1.969147407, Training Accuracy: 48.436\n",
            "Worker 2, [05/37]: Training Loss: 1.890242082, Training Accuracy: 49.936\n",
            "Worker 2, [06/37]: Training Loss: 1.807356592, Training Accuracy: 51.588\n",
            "Worker 2, [07/37]: Training Loss: 1.746580710, Training Accuracy: 52.840\n",
            "Worker 2, [08/37]: Training Loss: 1.680701076, Training Accuracy: 54.076\n",
            "Worker 2, [09/37]: Training Loss: 1.620727047, Training Accuracy: 55.652\n",
            "Worker 2, [10/37]: Training Loss: 1.550798339, Training Accuracy: 57.092\n",
            "Worker 2, [11/37]: Training Loss: 1.492585851, Training Accuracy: 58.464\n",
            "Worker 2, [12/37]: Training Loss: 1.444365308, Training Accuracy: 59.548\n",
            "Worker 2, [13/37]: Training Loss: 1.399252554, Training Accuracy: 60.784\n",
            "Worker 2, [14/37]: Training Loss: 1.355841165, Training Accuracy: 61.488\n",
            "Worker 2, [15/37]: Training Loss: 1.326303658, Training Accuracy: 62.484\n",
            "Worker 2, [16/37]: Training Loss: 1.300703871, Training Accuracy: 62.632\n",
            "Worker 2, [17/37]: Training Loss: 1.283999723, Training Accuracy: 62.808\n",
            "Worker 2, [18/37]: Training Loss: 1.265017437, Training Accuracy: 63.372\n",
            "Worker 2, [19/37]: Training Loss: 1.263370981, Training Accuracy: 63.180\n",
            "Worker 2, [20/37]: Training Loss: 1.259681551, Training Accuracy: 63.304\n",
            "Worker 2, [21/37]: Training Loss: 1.253722583, Training Accuracy: 63.432\n",
            "Worker 2, [22/37]: Training Loss: 1.257866571, Training Accuracy: 63.296\n",
            "Worker 2, [23/37]: Training Loss: 1.294187003, Training Accuracy: 62.648\n",
            "Worker 2, [24/37]: Training Loss: 1.307518342, Training Accuracy: 62.036\n",
            "Worker 2, [25/37]: Training Loss: 1.320251226, Training Accuracy: 61.756\n",
            "Worker 2, [26/37]: Training Loss: 1.345732882, Training Accuracy: 61.376\n",
            "Worker 2, [27/37]: Training Loss: 1.356533367, Training Accuracy: 60.796\n",
            "Worker 2, [28/37]: Training Loss: 1.354936567, Training Accuracy: 60.900\n",
            "Worker 2, [29/37]: Training Loss: 1.368638985, Training Accuracy: 60.848\n",
            "Worker 2, [30/37]: Training Loss: 1.391623963, Training Accuracy: 59.948\n",
            "Worker 2, [31/37]: Training Loss: 1.415299975, Training Accuracy: 59.452\n",
            "Worker 2, [32/37]: Training Loss: 1.417448115, Training Accuracy: 59.548\n",
            "Worker 2, [33/37]: Training Loss: 1.412226058, Training Accuracy: 60.064\n",
            "Worker 2, [34/37]: Training Loss: 1.445539606, Training Accuracy: 58.816\n",
            "Worker 2, [35/37]: Training Loss: 1.439179679, Training Accuracy: 58.792\n",
            "Worker 2, [36/37]: Training Loss: 1.436506317, Training Accuracy: 58.920\n",
            "Worker 2, [37/37]: Training Loss: 1.436755303, Training Accuracy: 59.020\n",
            "Time taken for training worker 2: 0:06:52.087729\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000621\n",
            "Local Step 04: Test Loss: 2.342789429, Test Accuracy: 45.670\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:55:25.102544\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.338301897, Training Accuracy: 4.108\n",
            "Worker 1, [02/18]: Training Loss: 3.862834174, Training Accuracy: 10.288\n",
            "Worker 1, [03/18]: Training Loss: 3.600455180, Training Accuracy: 14.396\n",
            "Worker 1, [04/18]: Training Loss: 3.399528824, Training Accuracy: 17.952\n",
            "Worker 1, [05/18]: Training Loss: 3.234376220, Training Accuracy: 20.548\n",
            "Worker 1, [06/18]: Training Loss: 3.087027595, Training Accuracy: 23.416\n",
            "Worker 1, [07/18]: Training Loss: 2.938923636, Training Accuracy: 25.844\n",
            "Worker 1, [08/18]: Training Loss: 2.811550189, Training Accuracy: 28.692\n",
            "Worker 1, [09/18]: Training Loss: 2.689318790, Training Accuracy: 31.180\n",
            "Worker 1, [10/18]: Training Loss: 2.567540699, Training Accuracy: 33.724\n",
            "Worker 1, [11/18]: Training Loss: 2.461736338, Training Accuracy: 35.808\n",
            "Worker 1, [12/18]: Training Loss: 2.358124382, Training Accuracy: 38.068\n",
            "Worker 1, [13/18]: Training Loss: 2.281230642, Training Accuracy: 39.924\n",
            "Worker 1, [14/18]: Training Loss: 2.185359363, Training Accuracy: 42.108\n",
            "Worker 1, [15/18]: Training Loss: 2.122683774, Training Accuracy: 43.488\n",
            "Worker 1, [16/18]: Training Loss: 2.059311180, Training Accuracy: 45.036\n",
            "Worker 1, [17/18]: Training Loss: 2.019495797, Training Accuracy: 46.100\n",
            "Worker 1, [18/18]: Training Loss: 1.993708049, Training Accuracy: 46.300\n",
            "Time taken for training worker 1: 0:03:21.275807\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.336734639, Training Accuracy: 4.324\n",
            "Worker 2, [02/18]: Training Loss: 3.862239201, Training Accuracy: 10.080\n",
            "Worker 2, [03/18]: Training Loss: 3.584167899, Training Accuracy: 14.476\n",
            "Worker 2, [04/18]: Training Loss: 3.377457039, Training Accuracy: 18.008\n",
            "Worker 2, [05/18]: Training Loss: 3.211479768, Training Accuracy: 21.212\n",
            "Worker 2, [06/18]: Training Loss: 3.061199552, Training Accuracy: 23.660\n",
            "Worker 2, [07/18]: Training Loss: 2.936250804, Training Accuracy: 26.132\n",
            "Worker 2, [08/18]: Training Loss: 2.804558142, Training Accuracy: 28.916\n",
            "Worker 2, [09/18]: Training Loss: 2.699370915, Training Accuracy: 30.796\n",
            "Worker 2, [10/18]: Training Loss: 2.576616593, Training Accuracy: 33.560\n",
            "Worker 2, [11/18]: Training Loss: 2.483090511, Training Accuracy: 35.588\n",
            "Worker 2, [12/18]: Training Loss: 2.374028146, Training Accuracy: 37.892\n",
            "Worker 2, [13/18]: Training Loss: 2.290047073, Training Accuracy: 39.660\n",
            "Worker 2, [14/18]: Training Loss: 2.204776195, Training Accuracy: 41.628\n",
            "Worker 2, [15/18]: Training Loss: 2.140650791, Training Accuracy: 43.288\n",
            "Worker 2, [16/18]: Training Loss: 2.077959366, Training Accuracy: 44.732\n",
            "Worker 2, [17/18]: Training Loss: 2.036505906, Training Accuracy: 45.444\n",
            "Worker 2, [18/18]: Training Loss: 2.009141309, Training Accuracy: 46.108\n",
            "Time taken for training worker 2: 0:03:25.059120\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000634\n",
            "Local Step 01: Test Loss: 2.536911123, Test Accuracy: 36.410\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.569438610, Training Accuracy: 35.676\n",
            "Worker 1, [02/18]: Training Loss: 2.478426702, Training Accuracy: 36.800\n",
            "Worker 1, [03/18]: Training Loss: 2.397758641, Training Accuracy: 37.512\n",
            "Worker 1, [04/18]: Training Loss: 2.357331813, Training Accuracy: 38.444\n",
            "Worker 1, [05/18]: Training Loss: 2.345081577, Training Accuracy: 38.488\n",
            "Worker 1, [06/18]: Training Loss: 2.343726906, Training Accuracy: 38.748\n",
            "Worker 1, [07/18]: Training Loss: 2.335712040, Training Accuracy: 38.424\n",
            "Worker 1, [08/18]: Training Loss: 2.345955180, Training Accuracy: 38.376\n",
            "Worker 1, [09/18]: Training Loss: 2.349006448, Training Accuracy: 38.216\n",
            "Worker 1, [10/18]: Training Loss: 2.339278302, Training Accuracy: 38.572\n",
            "Worker 1, [11/18]: Training Loss: 2.349341417, Training Accuracy: 38.136\n",
            "Worker 1, [12/18]: Training Loss: 2.332644062, Training Accuracy: 38.768\n",
            "Worker 1, [13/18]: Training Loss: 2.337496821, Training Accuracy: 38.880\n",
            "Worker 1, [14/18]: Training Loss: 2.313742583, Training Accuracy: 38.964\n",
            "Worker 1, [15/18]: Training Loss: 2.305455011, Training Accuracy: 39.024\n",
            "Worker 1, [16/18]: Training Loss: 2.275613385, Training Accuracy: 39.628\n",
            "Worker 1, [17/18]: Training Loss: 2.248121076, Training Accuracy: 40.232\n",
            "Worker 1, [18/18]: Training Loss: 2.210120511, Training Accuracy: 41.240\n",
            "Time taken for training worker 1: 0:03:21.445741\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.643174575, Training Accuracy: 34.032\n",
            "Worker 2, [02/18]: Training Loss: 2.475583891, Training Accuracy: 36.468\n",
            "Worker 2, [03/18]: Training Loss: 2.343632218, Training Accuracy: 39.524\n",
            "Worker 2, [04/18]: Training Loss: 2.252938516, Training Accuracy: 41.880\n",
            "Worker 2, [05/18]: Training Loss: 2.189806531, Training Accuracy: 42.752\n",
            "Worker 2, [06/18]: Training Loss: 2.138592061, Training Accuracy: 43.604\n",
            "Worker 2, [07/18]: Training Loss: 2.104939317, Training Accuracy: 44.676\n",
            "Worker 2, [08/18]: Training Loss: 2.081271741, Training Accuracy: 44.704\n",
            "Worker 2, [09/18]: Training Loss: 2.065335101, Training Accuracy: 44.832\n",
            "Worker 2, [10/18]: Training Loss: 2.049649607, Training Accuracy: 45.368\n",
            "Worker 2, [11/18]: Training Loss: 2.055194336, Training Accuracy: 45.152\n",
            "Worker 2, [12/18]: Training Loss: 2.071378900, Training Accuracy: 44.188\n",
            "Worker 2, [13/18]: Training Loss: 2.057529122, Training Accuracy: 44.580\n",
            "Worker 2, [14/18]: Training Loss: 2.061281877, Training Accuracy: 44.284\n",
            "Worker 2, [15/18]: Training Loss: 2.038535348, Training Accuracy: 44.944\n",
            "Worker 2, [16/18]: Training Loss: 2.056727594, Training Accuracy: 44.640\n",
            "Worker 2, [17/18]: Training Loss: 2.024253113, Training Accuracy: 45.444\n",
            "Worker 2, [18/18]: Training Loss: 2.007856947, Training Accuracy: 45.760\n",
            "Time taken for training worker 2: 0:03:22.445950\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000574\n",
            "Local Step 02: Test Loss: 2.260357195, Test Accuracy: 42.260\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.292651087, Training Accuracy: 40.320\n",
            "Worker 1, [02/18]: Training Loss: 2.159746803, Training Accuracy: 42.856\n",
            "Worker 1, [03/18]: Training Loss: 2.056022542, Training Accuracy: 44.856\n",
            "Worker 1, [04/18]: Training Loss: 1.992366273, Training Accuracy: 46.468\n",
            "Worker 1, [05/18]: Training Loss: 1.909835748, Training Accuracy: 48.336\n",
            "Worker 1, [06/18]: Training Loss: 1.842113892, Training Accuracy: 49.660\n",
            "Worker 1, [07/18]: Training Loss: 1.747178890, Training Accuracy: 52.292\n",
            "Worker 1, [08/18]: Training Loss: 1.661197432, Training Accuracy: 53.992\n",
            "Worker 1, [09/18]: Training Loss: 1.585869667, Training Accuracy: 55.744\n",
            "Worker 1, [10/18]: Training Loss: 1.508764199, Training Accuracy: 57.664\n",
            "Worker 1, [11/18]: Training Loss: 1.430879871, Training Accuracy: 59.716\n",
            "Worker 1, [12/18]: Training Loss: 1.326536743, Training Accuracy: 62.240\n",
            "Worker 1, [13/18]: Training Loss: 1.235498653, Training Accuracy: 64.656\n",
            "Worker 1, [14/18]: Training Loss: 1.172650597, Training Accuracy: 66.256\n",
            "Worker 1, [15/18]: Training Loss: 1.103726614, Training Accuracy: 68.136\n",
            "Worker 1, [16/18]: Training Loss: 1.049048170, Training Accuracy: 69.792\n",
            "Worker 1, [17/18]: Training Loss: 1.011386361, Training Accuracy: 71.112\n",
            "Worker 1, [18/18]: Training Loss: 0.981390766, Training Accuracy: 71.912\n",
            "Time taken for training worker 1: 0:03:19.717703\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.226945246, Training Accuracy: 41.868\n",
            "Worker 2, [02/18]: Training Loss: 2.062027182, Training Accuracy: 45.092\n",
            "Worker 2, [03/18]: Training Loss: 1.959348098, Training Accuracy: 47.124\n",
            "Worker 2, [04/18]: Training Loss: 1.893435905, Training Accuracy: 48.436\n",
            "Worker 2, [05/18]: Training Loss: 1.819453678, Training Accuracy: 50.000\n",
            "Worker 2, [06/18]: Training Loss: 1.739438706, Training Accuracy: 52.316\n",
            "Worker 2, [07/18]: Training Loss: 1.669845255, Training Accuracy: 53.904\n",
            "Worker 2, [08/18]: Training Loss: 1.591476493, Training Accuracy: 55.632\n",
            "Worker 2, [09/18]: Training Loss: 1.497490103, Training Accuracy: 57.840\n",
            "Worker 2, [10/18]: Training Loss: 1.407760799, Training Accuracy: 59.888\n",
            "Worker 2, [11/18]: Training Loss: 1.307702877, Training Accuracy: 62.248\n",
            "Worker 2, [12/18]: Training Loss: 1.242377972, Training Accuracy: 64.224\n",
            "Worker 2, [13/18]: Training Loss: 1.146132363, Training Accuracy: 67.192\n",
            "Worker 2, [14/18]: Training Loss: 1.071695577, Training Accuracy: 68.920\n",
            "Worker 2, [15/18]: Training Loss: 1.001646107, Training Accuracy: 70.984\n",
            "Worker 2, [16/18]: Training Loss: 0.946267288, Training Accuracy: 72.616\n",
            "Worker 2, [17/18]: Training Loss: 0.909222500, Training Accuracy: 73.688\n",
            "Worker 2, [18/18]: Training Loss: 0.895398385, Training Accuracy: 73.988\n",
            "Time taken for training worker 2: 0:03:24.410596\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000692\n",
            "Local Step 03: Test Loss: 1.892761729, Test Accuracy: 53.330\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 1.798199827, Training Accuracy: 53.452\n",
            "Worker 1, [02/18]: Training Loss: 1.749336429, Training Accuracy: 53.844\n",
            "Worker 1, [03/18]: Training Loss: 1.700445751, Training Accuracy: 54.256\n",
            "Worker 1, [04/18]: Training Loss: 1.643638015, Training Accuracy: 55.080\n",
            "Worker 1, [05/18]: Training Loss: 1.602402079, Training Accuracy: 55.800\n",
            "Worker 1, [06/18]: Training Loss: 1.545323150, Training Accuracy: 57.276\n",
            "Worker 1, [07/18]: Training Loss: 1.525966041, Training Accuracy: 57.204\n",
            "Worker 1, [08/18]: Training Loss: 1.515791746, Training Accuracy: 57.768\n",
            "Worker 1, [09/18]: Training Loss: 1.516894459, Training Accuracy: 57.488\n",
            "Worker 1, [10/18]: Training Loss: 1.527001230, Training Accuracy: 57.148\n",
            "Worker 1, [11/18]: Training Loss: 1.551609060, Training Accuracy: 56.412\n",
            "Worker 1, [12/18]: Training Loss: 1.572950869, Training Accuracy: 55.940\n",
            "Worker 1, [13/18]: Training Loss: 1.607249368, Training Accuracy: 54.760\n",
            "Worker 1, [14/18]: Training Loss: 1.657604429, Training Accuracy: 53.788\n",
            "Worker 1, [15/18]: Training Loss: 1.638196724, Training Accuracy: 54.172\n",
            "Worker 1, [16/18]: Training Loss: 1.664451373, Training Accuracy: 53.676\n",
            "Worker 1, [17/18]: Training Loss: 1.686820500, Training Accuracy: 52.984\n",
            "Worker 1, [18/18]: Training Loss: 1.681404465, Training Accuracy: 53.152\n",
            "Time taken for training worker 1: 0:03:22.309430\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.089785022, Training Accuracy: 45.312\n",
            "Worker 2, [02/18]: Training Loss: 1.966470639, Training Accuracy: 47.828\n",
            "Worker 2, [03/18]: Training Loss: 1.846406251, Training Accuracy: 50.504\n",
            "Worker 2, [04/18]: Training Loss: 1.752002242, Training Accuracy: 52.604\n",
            "Worker 2, [05/18]: Training Loss: 1.666097539, Training Accuracy: 54.428\n",
            "Worker 2, [06/18]: Training Loss: 1.601247922, Training Accuracy: 55.756\n",
            "Worker 2, [07/18]: Training Loss: 1.549472080, Training Accuracy: 56.804\n",
            "Worker 2, [08/18]: Training Loss: 1.502100658, Training Accuracy: 57.696\n",
            "Worker 2, [09/18]: Training Loss: 1.485401095, Training Accuracy: 58.152\n",
            "Worker 2, [10/18]: Training Loss: 1.471815590, Training Accuracy: 58.668\n",
            "Worker 2, [11/18]: Training Loss: 1.509580302, Training Accuracy: 57.200\n",
            "Worker 2, [12/18]: Training Loss: 1.518867386, Training Accuracy: 56.936\n",
            "Worker 2, [13/18]: Training Loss: 1.567558061, Training Accuracy: 55.808\n",
            "Worker 2, [14/18]: Training Loss: 1.575198059, Training Accuracy: 55.996\n",
            "Worker 2, [15/18]: Training Loss: 1.622425739, Training Accuracy: 54.296\n",
            "Worker 2, [16/18]: Training Loss: 1.616854398, Training Accuracy: 54.244\n",
            "Worker 2, [17/18]: Training Loss: 1.646051357, Training Accuracy: 54.256\n",
            "Worker 2, [18/18]: Training Loss: 1.642312684, Training Accuracy: 54.252\n",
            "Time taken for training worker 2: 0:03:19.510667\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000627\n",
            "Local Step 04: Test Loss: 2.155854350, Test Accuracy: 45.610\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.033856947, Training Accuracy: 46.080\n",
            "Worker 1, [02/18]: Training Loss: 1.866818183, Training Accuracy: 49.304\n",
            "Worker 1, [03/18]: Training Loss: 1.757091980, Training Accuracy: 51.644\n",
            "Worker 1, [04/18]: Training Loss: 1.683379064, Training Accuracy: 53.648\n",
            "Worker 1, [05/18]: Training Loss: 1.610882398, Training Accuracy: 54.688\n",
            "Worker 1, [06/18]: Training Loss: 1.551354516, Training Accuracy: 56.496\n",
            "Worker 1, [07/18]: Training Loss: 1.454040480, Training Accuracy: 58.596\n",
            "Worker 1, [08/18]: Training Loss: 1.379472123, Training Accuracy: 60.568\n",
            "Worker 1, [09/18]: Training Loss: 1.312543087, Training Accuracy: 62.492\n",
            "Worker 1, [10/18]: Training Loss: 1.209694292, Training Accuracy: 65.048\n",
            "Worker 1, [11/18]: Training Loss: 1.108566065, Training Accuracy: 67.636\n",
            "Worker 1, [12/18]: Training Loss: 1.025759354, Training Accuracy: 70.276\n",
            "Worker 1, [13/18]: Training Loss: 0.948344230, Training Accuracy: 72.192\n",
            "Worker 1, [14/18]: Training Loss: 0.867002715, Training Accuracy: 74.636\n",
            "Worker 1, [15/18]: Training Loss: 0.801270670, Training Accuracy: 76.744\n",
            "Worker 1, [16/18]: Training Loss: 0.753219323, Training Accuracy: 78.048\n",
            "Worker 1, [17/18]: Training Loss: 0.731996635, Training Accuracy: 78.332\n",
            "Worker 1, [18/18]: Training Loss: 0.702871990, Training Accuracy: 79.480\n",
            "Time taken for training worker 1: 0:03:24.064386\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.055341850, Training Accuracy: 45.552\n",
            "Worker 2, [02/18]: Training Loss: 1.831551989, Training Accuracy: 50.048\n",
            "Worker 2, [03/18]: Training Loss: 1.760335522, Training Accuracy: 52.048\n",
            "Worker 2, [04/18]: Training Loss: 1.675499031, Training Accuracy: 53.720\n",
            "Worker 2, [05/18]: Training Loss: 1.604085508, Training Accuracy: 55.764\n",
            "Worker 2, [06/18]: Training Loss: 1.524035948, Training Accuracy: 56.880\n",
            "Worker 2, [07/18]: Training Loss: 1.445901475, Training Accuracy: 58.796\n",
            "Worker 2, [08/18]: Training Loss: 1.366747075, Training Accuracy: 60.852\n",
            "Worker 2, [09/18]: Training Loss: 1.282870235, Training Accuracy: 63.372\n",
            "Worker 2, [10/18]: Training Loss: 1.187704135, Training Accuracy: 65.272\n",
            "Worker 2, [11/18]: Training Loss: 1.091111663, Training Accuracy: 67.980\n",
            "Worker 2, [12/18]: Training Loss: 1.006866988, Training Accuracy: 70.568\n",
            "Worker 2, [13/18]: Training Loss: 0.920770435, Training Accuracy: 72.912\n",
            "Worker 2, [14/18]: Training Loss: 0.852196517, Training Accuracy: 74.932\n",
            "Worker 2, [15/18]: Training Loss: 0.774572092, Training Accuracy: 77.204\n",
            "Worker 2, [16/18]: Training Loss: 0.725008072, Training Accuracy: 78.696\n",
            "Worker 2, [17/18]: Training Loss: 0.702434186, Training Accuracy: 79.636\n",
            "Worker 2, [18/18]: Training Loss: 0.689186696, Training Accuracy: 80.064\n",
            "Time taken for training worker 2: 0:03:19.753718\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000558\n",
            "Local Step 05: Test Loss: 1.923860023, Test Accuracy: 54.010\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 1.656514448, Training Accuracy: 56.640\n",
            "Worker 1, [02/18]: Training Loss: 1.614295915, Training Accuracy: 57.300\n",
            "Worker 1, [03/18]: Training Loss: 1.547406258, Training Accuracy: 58.120\n",
            "Worker 1, [04/18]: Training Loss: 1.488781116, Training Accuracy: 58.724\n",
            "Worker 1, [05/18]: Training Loss: 1.425352841, Training Accuracy: 60.136\n",
            "Worker 1, [06/18]: Training Loss: 1.374105666, Training Accuracy: 61.252\n",
            "Worker 1, [07/18]: Training Loss: 1.343565793, Training Accuracy: 61.836\n",
            "Worker 1, [08/18]: Training Loss: 1.313146506, Training Accuracy: 62.664\n",
            "Worker 1, [09/18]: Training Loss: 1.321445943, Training Accuracy: 62.300\n",
            "Worker 1, [10/18]: Training Loss: 1.344920136, Training Accuracy: 61.524\n",
            "Worker 1, [11/18]: Training Loss: 1.360573885, Training Accuracy: 60.844\n",
            "Worker 1, [12/18]: Training Loss: 1.385475160, Training Accuracy: 60.424\n",
            "Worker 1, [13/18]: Training Loss: 1.438701774, Training Accuracy: 59.132\n",
            "Worker 1, [14/18]: Training Loss: 1.487838290, Training Accuracy: 57.276\n",
            "Worker 1, [15/18]: Training Loss: 1.495411437, Training Accuracy: 57.740\n",
            "Worker 1, [16/18]: Training Loss: 1.518390086, Training Accuracy: 57.088\n",
            "Worker 1, [17/18]: Training Loss: 1.521843397, Training Accuracy: 57.032\n",
            "Worker 1, [18/18]: Training Loss: 1.556051914, Training Accuracy: 56.116\n",
            "Time taken for training worker 1: 0:03:24.341788\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.067388490, Training Accuracy: 45.564\n",
            "Worker 2, [02/18]: Training Loss: 1.902729126, Training Accuracy: 48.752\n",
            "Worker 2, [03/18]: Training Loss: 1.752272461, Training Accuracy: 52.780\n",
            "Worker 2, [04/18]: Training Loss: 1.653907949, Training Accuracy: 54.556\n",
            "Worker 2, [05/18]: Training Loss: 1.554520908, Training Accuracy: 56.684\n",
            "Worker 2, [06/18]: Training Loss: 1.476486673, Training Accuracy: 59.196\n",
            "Worker 2, [07/18]: Training Loss: 1.423403814, Training Accuracy: 59.732\n",
            "Worker 2, [08/18]: Training Loss: 1.361222320, Training Accuracy: 61.404\n",
            "Worker 2, [09/18]: Training Loss: 1.353473345, Training Accuracy: 61.488\n",
            "Worker 2, [10/18]: Training Loss: 1.344493654, Training Accuracy: 61.720\n",
            "Worker 2, [11/18]: Training Loss: 1.367951128, Training Accuracy: 60.988\n",
            "Worker 2, [12/18]: Training Loss: 1.376382552, Training Accuracy: 60.340\n",
            "Worker 2, [13/18]: Training Loss: 1.417972773, Training Accuracy: 59.320\n",
            "Worker 2, [14/18]: Training Loss: 1.444918746, Training Accuracy: 58.496\n",
            "Worker 2, [15/18]: Training Loss: 1.493864209, Training Accuracy: 58.000\n",
            "Worker 2, [16/18]: Training Loss: 1.523767189, Training Accuracy: 56.952\n",
            "Worker 2, [17/18]: Training Loss: 1.514010445, Training Accuracy: 57.116\n",
            "Worker 2, [18/18]: Training Loss: 1.522673655, Training Accuracy: 56.728\n",
            "Time taken for training worker 2: 0:03:20.285396\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000690\n",
            "Local Step 06: Test Loss: 2.165618887, Test Accuracy: 46.350\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 1.988457619, Training Accuracy: 47.284\n",
            "Worker 1, [02/18]: Training Loss: 1.761960334, Training Accuracy: 51.480\n",
            "Worker 1, [03/18]: Training Loss: 1.666756002, Training Accuracy: 53.524\n",
            "Worker 1, [04/18]: Training Loss: 1.603448532, Training Accuracy: 55.056\n",
            "Worker 1, [05/18]: Training Loss: 1.534656858, Training Accuracy: 56.888\n",
            "Worker 1, [06/18]: Training Loss: 1.444318163, Training Accuracy: 58.828\n",
            "Worker 1, [07/18]: Training Loss: 1.350190330, Training Accuracy: 61.568\n",
            "Worker 1, [08/18]: Training Loss: 1.271952945, Training Accuracy: 63.332\n",
            "Worker 1, [09/18]: Training Loss: 1.189010972, Training Accuracy: 65.304\n",
            "Worker 1, [10/18]: Training Loss: 1.098527775, Training Accuracy: 67.620\n",
            "Worker 1, [11/18]: Training Loss: 0.990394279, Training Accuracy: 70.876\n",
            "Worker 1, [12/18]: Training Loss: 0.923567646, Training Accuracy: 72.688\n",
            "Worker 1, [13/18]: Training Loss: 0.836020769, Training Accuracy: 75.416\n",
            "Worker 1, [14/18]: Training Loss: 0.760699750, Training Accuracy: 77.704\n",
            "Worker 1, [15/18]: Training Loss: 0.707213378, Training Accuracy: 79.048\n",
            "Worker 1, [16/18]: Training Loss: 0.660927107, Training Accuracy: 80.576\n",
            "Worker 1, [17/18]: Training Loss: 0.622835134, Training Accuracy: 81.692\n",
            "Worker 1, [18/18]: Training Loss: 0.604581241, Training Accuracy: 82.276\n",
            "Time taken for training worker 1: 0:03:21.930064\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 1.982542000, Training Accuracy: 47.284\n",
            "Worker 2, [02/18]: Training Loss: 1.792331019, Training Accuracy: 51.092\n",
            "Worker 2, [03/18]: Training Loss: 1.675472236, Training Accuracy: 53.200\n",
            "Worker 2, [04/18]: Training Loss: 1.587579643, Training Accuracy: 55.616\n",
            "Worker 2, [05/18]: Training Loss: 1.514520932, Training Accuracy: 57.196\n",
            "Worker 2, [06/18]: Training Loss: 1.434316154, Training Accuracy: 59.320\n",
            "Worker 2, [07/18]: Training Loss: 1.351746300, Training Accuracy: 61.376\n",
            "Worker 2, [08/18]: Training Loss: 1.269890132, Training Accuracy: 63.088\n",
            "Worker 2, [09/18]: Training Loss: 1.195957380, Training Accuracy: 65.384\n",
            "Worker 2, [10/18]: Training Loss: 1.094762754, Training Accuracy: 68.104\n",
            "Worker 2, [11/18]: Training Loss: 0.993254209, Training Accuracy: 70.812\n",
            "Worker 2, [12/18]: Training Loss: 0.900606376, Training Accuracy: 73.312\n",
            "Worker 2, [13/18]: Training Loss: 0.820031007, Training Accuracy: 75.848\n",
            "Worker 2, [14/18]: Training Loss: 0.754376591, Training Accuracy: 77.560\n",
            "Worker 2, [15/18]: Training Loss: 0.690829189, Training Accuracy: 79.544\n",
            "Worker 2, [16/18]: Training Loss: 0.647476331, Training Accuracy: 80.964\n",
            "Worker 2, [17/18]: Training Loss: 0.615184367, Training Accuracy: 82.108\n",
            "Worker 2, [18/18]: Training Loss: 0.596116880, Training Accuracy: 82.776\n",
            "Time taken for training worker 2: 0:03:17.921157\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000956\n",
            "Local Step 07: Test Loss: 1.931419570, Test Accuracy: 54.830\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 1.606947782, Training Accuracy: 58.332\n",
            "Worker 1, [02/18]: Training Loss: 1.555736713, Training Accuracy: 58.628\n",
            "Worker 1, [03/18]: Training Loss: 1.494072741, Training Accuracy: 59.020\n",
            "Worker 1, [04/18]: Training Loss: 1.418070025, Training Accuracy: 60.296\n",
            "Worker 1, [05/18]: Training Loss: 1.345032023, Training Accuracy: 61.720\n",
            "Worker 1, [06/18]: Training Loss: 1.298447141, Training Accuracy: 63.160\n",
            "Worker 1, [07/18]: Training Loss: 1.268123288, Training Accuracy: 63.544\n",
            "Worker 1, [08/18]: Training Loss: 1.239914948, Training Accuracy: 64.340\n",
            "Worker 1, [09/18]: Training Loss: 1.224644571, Training Accuracy: 64.416\n",
            "Worker 1, [10/18]: Training Loss: 1.264671528, Training Accuracy: 63.552\n",
            "Worker 1, [11/18]: Training Loss: 1.261320044, Training Accuracy: 63.540\n",
            "Worker 1, [12/18]: Training Loss: 1.309733057, Training Accuracy: 62.348\n",
            "Worker 1, [13/18]: Training Loss: 1.338533244, Training Accuracy: 61.480\n",
            "Worker 1, [14/18]: Training Loss: 1.394321041, Training Accuracy: 59.884\n",
            "Worker 1, [15/18]: Training Loss: 1.429972866, Training Accuracy: 58.996\n",
            "Worker 1, [16/18]: Training Loss: 1.474819107, Training Accuracy: 58.216\n",
            "Worker 1, [17/18]: Training Loss: 1.486631979, Training Accuracy: 57.872\n",
            "Worker 1, [18/18]: Training Loss: 1.475980571, Training Accuracy: 58.024\n",
            "Time taken for training worker 1: 0:03:16.899037\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 1.986411485, Training Accuracy: 47.592\n",
            "Worker 2, [02/18]: Training Loss: 1.842648368, Training Accuracy: 50.392\n",
            "Worker 2, [03/18]: Training Loss: 1.683388495, Training Accuracy: 54.032\n",
            "Worker 2, [04/18]: Training Loss: 1.581119142, Training Accuracy: 56.416\n",
            "Worker 2, [05/18]: Training Loss: 1.502963774, Training Accuracy: 58.220\n",
            "Worker 2, [06/18]: Training Loss: 1.421872181, Training Accuracy: 59.780\n",
            "Worker 2, [07/18]: Training Loss: 1.337474458, Training Accuracy: 62.004\n",
            "Worker 2, [08/18]: Training Loss: 1.308756537, Training Accuracy: 62.336\n",
            "Worker 2, [09/18]: Training Loss: 1.274928376, Training Accuracy: 63.244\n",
            "Worker 2, [10/18]: Training Loss: 1.284666575, Training Accuracy: 63.404\n",
            "Worker 2, [11/18]: Training Loss: 1.276442490, Training Accuracy: 63.276\n",
            "Worker 2, [12/18]: Training Loss: 1.320245545, Training Accuracy: 62.140\n",
            "Worker 2, [13/18]: Training Loss: 1.348027577, Training Accuracy: 61.204\n",
            "Worker 2, [14/18]: Training Loss: 1.382638066, Training Accuracy: 60.288\n",
            "Worker 2, [15/18]: Training Loss: 1.429839045, Training Accuracy: 59.108\n",
            "Worker 2, [16/18]: Training Loss: 1.445283758, Training Accuracy: 58.784\n",
            "Worker 2, [17/18]: Training Loss: 1.468263806, Training Accuracy: 58.672\n",
            "Worker 2, [18/18]: Training Loss: 1.469743130, Training Accuracy: 58.096\n",
            "Time taken for training worker 2: 0:03:15.113823\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000548\n",
            "Local Step 08: Test Loss: 2.132922392, Test Accuracy: 47.610\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:53:43.400276\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:16\n",
            "==================================================\n",
            "Worker 1, [01/9]: Training Loss: 4.331258162, Training Accuracy: 4.180\n",
            "Worker 1, [02/9]: Training Loss: 3.879224973, Training Accuracy: 9.716\n",
            "Worker 1, [03/9]: Training Loss: 3.605423959, Training Accuracy: 14.284\n",
            "Worker 1, [04/9]: Training Loss: 3.382780384, Training Accuracy: 18.008\n",
            "Worker 1, [05/9]: Training Loss: 3.192702473, Training Accuracy: 21.644\n",
            "Worker 1, [06/9]: Training Loss: 3.028310171, Training Accuracy: 24.344\n",
            "Worker 1, [07/9]: Training Loss: 2.863311910, Training Accuracy: 27.600\n",
            "Worker 1, [08/9]: Training Loss: 2.731471755, Training Accuracy: 30.424\n",
            "Worker 1, [09/9]: Training Loss: 2.648512939, Training Accuracy: 32.116\n",
            "Time taken for training worker 1: 0:01:37.088195\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 4.337453484, Training Accuracy: 4.200\n",
            "Worker 2, [02/9]: Training Loss: 3.881464337, Training Accuracy: 10.000\n",
            "Worker 2, [03/9]: Training Loss: 3.598077446, Training Accuracy: 14.688\n",
            "Worker 2, [04/9]: Training Loss: 3.383342150, Training Accuracy: 18.144\n",
            "Worker 2, [05/9]: Training Loss: 3.191937876, Training Accuracy: 21.632\n",
            "Worker 2, [06/9]: Training Loss: 3.033232584, Training Accuracy: 24.528\n",
            "Worker 2, [07/9]: Training Loss: 2.881496465, Training Accuracy: 27.936\n",
            "Worker 2, [08/9]: Training Loss: 2.768884253, Training Accuracy: 29.912\n",
            "Worker 2, [09/9]: Training Loss: 2.692637219, Training Accuracy: 31.712\n",
            "Time taken for training worker 2: 0:01:33.895517\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000692\n",
            "Local Step 01: Test Loss: 2.863732481, Test Accuracy: 29.380\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.928259168, Training Accuracy: 27.876\n",
            "Worker 1, [02/9]: Training Loss: 2.847660615, Training Accuracy: 28.596\n",
            "Worker 1, [03/9]: Training Loss: 2.824548246, Training Accuracy: 28.712\n",
            "Worker 1, [04/9]: Training Loss: 2.837341042, Training Accuracy: 28.016\n",
            "Worker 1, [05/9]: Training Loss: 2.841210933, Training Accuracy: 28.052\n",
            "Worker 1, [06/9]: Training Loss: 2.836823809, Training Accuracy: 28.156\n",
            "Worker 1, [07/9]: Training Loss: 2.803213232, Training Accuracy: 28.972\n",
            "Worker 1, [08/9]: Training Loss: 2.770300491, Training Accuracy: 29.536\n",
            "Worker 1, [09/9]: Training Loss: 2.712724468, Training Accuracy: 30.672\n",
            "Time taken for training worker 1: 0:01:39.042630\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.774833576, Training Accuracy: 29.704\n",
            "Worker 2, [02/9]: Training Loss: 2.613975177, Training Accuracy: 33.480\n",
            "Worker 2, [03/9]: Training Loss: 2.517207162, Training Accuracy: 35.452\n",
            "Worker 2, [04/9]: Training Loss: 2.468718158, Training Accuracy: 36.308\n",
            "Worker 2, [05/9]: Training Loss: 2.474413583, Training Accuracy: 36.064\n",
            "Worker 2, [06/9]: Training Loss: 2.488613384, Training Accuracy: 35.676\n",
            "Worker 2, [07/9]: Training Loss: 2.506361137, Training Accuracy: 35.252\n",
            "Worker 2, [08/9]: Training Loss: 2.482359909, Training Accuracy: 35.504\n",
            "Worker 2, [09/9]: Training Loss: 2.450172183, Training Accuracy: 36.320\n",
            "Time taken for training worker 2: 0:01:37.601605\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000706\n",
            "Local Step 02: Test Loss: 2.531620492, Test Accuracy: 35.370\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.559430642, Training Accuracy: 33.936\n",
            "Worker 1, [02/9]: Training Loss: 2.433174911, Training Accuracy: 36.708\n",
            "Worker 1, [03/9]: Training Loss: 2.325357565, Training Accuracy: 38.836\n",
            "Worker 1, [04/9]: Training Loss: 2.195921039, Training Accuracy: 41.780\n",
            "Worker 1, [05/9]: Training Loss: 2.073887211, Training Accuracy: 44.468\n",
            "Worker 1, [06/9]: Training Loss: 1.942312006, Training Accuracy: 47.752\n",
            "Worker 1, [07/9]: Training Loss: 1.796766283, Training Accuracy: 50.664\n",
            "Worker 1, [08/9]: Training Loss: 1.680089586, Training Accuracy: 53.880\n",
            "Worker 1, [09/9]: Training Loss: 1.597588727, Training Accuracy: 55.756\n",
            "Time taken for training worker 1: 0:01:37.852000\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.422076096, Training Accuracy: 37.460\n",
            "Worker 2, [02/9]: Training Loss: 2.289689493, Training Accuracy: 39.908\n",
            "Worker 2, [03/9]: Training Loss: 2.186770099, Training Accuracy: 41.868\n",
            "Worker 2, [04/9]: Training Loss: 2.047996442, Training Accuracy: 44.644\n",
            "Worker 2, [05/9]: Training Loss: 1.925006098, Training Accuracy: 47.640\n",
            "Worker 2, [06/9]: Training Loss: 1.783035034, Training Accuracy: 51.028\n",
            "Worker 2, [07/9]: Training Loss: 1.644513726, Training Accuracy: 54.492\n",
            "Worker 2, [08/9]: Training Loss: 1.531824474, Training Accuracy: 57.140\n",
            "Worker 2, [09/9]: Training Loss: 1.444553078, Training Accuracy: 59.656\n",
            "Time taken for training worker 2: 0:01:34.503072\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000536\n",
            "Local Step 03: Test Loss: 1.909235360, Test Accuracy: 49.790\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.896713415, Training Accuracy: 49.484\n",
            "Worker 1, [02/9]: Training Loss: 1.883896873, Training Accuracy: 49.512\n",
            "Worker 1, [03/9]: Training Loss: 1.862027227, Training Accuracy: 49.980\n",
            "Worker 1, [04/9]: Training Loss: 1.857027269, Training Accuracy: 49.780\n",
            "Worker 1, [05/9]: Training Loss: 1.879697374, Training Accuracy: 48.868\n",
            "Worker 1, [06/9]: Training Loss: 1.927587054, Training Accuracy: 47.696\n",
            "Worker 1, [07/9]: Training Loss: 1.965495714, Training Accuracy: 46.988\n",
            "Worker 1, [08/9]: Training Loss: 2.010332192, Training Accuracy: 45.924\n",
            "Worker 1, [09/9]: Training Loss: 2.014419035, Training Accuracy: 45.660\n",
            "Time taken for training worker 1: 0:01:43.539090\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.219610523, Training Accuracy: 42.144\n",
            "Worker 2, [02/9]: Training Loss: 1.992569017, Training Accuracy: 46.776\n",
            "Worker 2, [03/9]: Training Loss: 1.871457202, Training Accuracy: 49.440\n",
            "Worker 2, [04/9]: Training Loss: 1.809200049, Training Accuracy: 50.452\n",
            "Worker 2, [05/9]: Training Loss: 1.804406007, Training Accuracy: 50.872\n",
            "Worker 2, [06/9]: Training Loss: 1.840106928, Training Accuracy: 49.700\n",
            "Worker 2, [07/9]: Training Loss: 1.877243443, Training Accuracy: 48.632\n",
            "Worker 2, [08/9]: Training Loss: 1.915869412, Training Accuracy: 48.008\n",
            "Worker 2, [09/9]: Training Loss: 1.962784954, Training Accuracy: 47.052\n",
            "Time taken for training worker 2: 0:01:40.123689\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000604\n",
            "Local Step 04: Test Loss: 2.206938151, Test Accuracy: 43.050\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.160919200, Training Accuracy: 42.828\n",
            "Worker 1, [02/9]: Training Loss: 2.030984518, Training Accuracy: 45.612\n",
            "Worker 1, [03/9]: Training Loss: 1.918762886, Training Accuracy: 48.044\n",
            "Worker 1, [04/9]: Training Loss: 1.791807645, Training Accuracy: 50.632\n",
            "Worker 1, [05/9]: Training Loss: 1.663162606, Training Accuracy: 53.968\n",
            "Worker 1, [06/9]: Training Loss: 1.510409055, Training Accuracy: 57.792\n",
            "Worker 1, [07/9]: Training Loss: 1.369208245, Training Accuracy: 61.364\n",
            "Worker 1, [08/9]: Training Loss: 1.249726333, Training Accuracy: 64.752\n",
            "Worker 1, [09/9]: Training Loss: 1.177457424, Training Accuracy: 66.808\n",
            "Time taken for training worker 1: 0:01:37.863779\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.103952440, Training Accuracy: 43.944\n",
            "Worker 2, [02/9]: Training Loss: 1.980744775, Training Accuracy: 46.832\n",
            "Worker 2, [03/9]: Training Loss: 1.876726879, Training Accuracy: 48.852\n",
            "Worker 2, [04/9]: Training Loss: 1.751875727, Training Accuracy: 51.736\n",
            "Worker 2, [05/9]: Training Loss: 1.609425462, Training Accuracy: 55.076\n",
            "Worker 2, [06/9]: Training Loss: 1.444614009, Training Accuracy: 59.176\n",
            "Worker 2, [07/9]: Training Loss: 1.309424439, Training Accuracy: 62.412\n",
            "Worker 2, [08/9]: Training Loss: 1.201872895, Training Accuracy: 65.816\n",
            "Worker 2, [09/9]: Training Loss: 1.119217759, Training Accuracy: 67.888\n",
            "Time taken for training worker 2: 0:01:37.498845\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000618\n",
            "Local Step 05: Test Loss: 1.851623490, Test Accuracy: 52.530\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.680769645, Training Accuracy: 54.704\n",
            "Worker 1, [02/9]: Training Loss: 1.634636603, Training Accuracy: 55.436\n",
            "Worker 1, [03/9]: Training Loss: 1.599540853, Training Accuracy: 56.012\n",
            "Worker 1, [04/9]: Training Loss: 1.593483184, Training Accuracy: 55.916\n",
            "Worker 1, [05/9]: Training Loss: 1.595202080, Training Accuracy: 55.620\n",
            "Worker 1, [06/9]: Training Loss: 1.640188331, Training Accuracy: 54.756\n",
            "Worker 1, [07/9]: Training Loss: 1.701278118, Training Accuracy: 52.932\n",
            "Worker 1, [08/9]: Training Loss: 1.770202006, Training Accuracy: 51.224\n",
            "Worker 1, [09/9]: Training Loss: 1.799856608, Training Accuracy: 50.552\n",
            "Time taken for training worker 1: 0:01:39.745372\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.030824286, Training Accuracy: 46.460\n",
            "Worker 2, [02/9]: Training Loss: 1.796544528, Training Accuracy: 50.976\n",
            "Worker 2, [03/9]: Training Loss: 1.667833500, Training Accuracy: 54.028\n",
            "Worker 2, [04/9]: Training Loss: 1.597815648, Training Accuracy: 55.704\n",
            "Worker 2, [05/9]: Training Loss: 1.572243351, Training Accuracy: 56.468\n",
            "Worker 2, [06/9]: Training Loss: 1.607474568, Training Accuracy: 55.200\n",
            "Worker 2, [07/9]: Training Loss: 1.668656332, Training Accuracy: 53.752\n",
            "Worker 2, [08/9]: Training Loss: 1.737443353, Training Accuracy: 51.916\n",
            "Worker 2, [09/9]: Training Loss: 1.766873066, Training Accuracy: 51.264\n",
            "Time taken for training worker 2: 0:01:41.108700\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000586\n",
            "Local Step 06: Test Loss: 2.199762981, Test Accuracy: 44.850\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.010879992, Training Accuracy: 46.088\n",
            "Worker 1, [02/9]: Training Loss: 1.871608740, Training Accuracy: 49.112\n",
            "Worker 1, [03/9]: Training Loss: 1.750311499, Training Accuracy: 51.784\n",
            "Worker 1, [04/9]: Training Loss: 1.624286287, Training Accuracy: 54.752\n",
            "Worker 1, [05/9]: Training Loss: 1.472360437, Training Accuracy: 58.608\n",
            "Worker 1, [06/9]: Training Loss: 1.334262796, Training Accuracy: 62.052\n",
            "Worker 1, [07/9]: Training Loss: 1.184321855, Training Accuracy: 65.976\n",
            "Worker 1, [08/9]: Training Loss: 1.075434258, Training Accuracy: 68.932\n",
            "Worker 1, [09/9]: Training Loss: 0.988469751, Training Accuracy: 71.508\n",
            "Time taken for training worker 1: 0:01:37.225657\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.974796155, Training Accuracy: 46.636\n",
            "Worker 2, [02/9]: Training Loss: 1.847496071, Training Accuracy: 49.708\n",
            "Worker 2, [03/9]: Training Loss: 1.725470143, Training Accuracy: 52.500\n",
            "Worker 2, [04/9]: Training Loss: 1.598850674, Training Accuracy: 55.672\n",
            "Worker 2, [05/9]: Training Loss: 1.475702756, Training Accuracy: 58.308\n",
            "Worker 2, [06/9]: Training Loss: 1.312109318, Training Accuracy: 62.572\n",
            "Worker 2, [07/9]: Training Loss: 1.173079465, Training Accuracy: 66.072\n",
            "Worker 2, [08/9]: Training Loss: 1.050814929, Training Accuracy: 69.712\n",
            "Worker 2, [09/9]: Training Loss: 0.971919452, Training Accuracy: 71.756\n",
            "Time taken for training worker 2: 0:01:36.298767\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 07: Test Loss: 1.844509944, Test Accuracy: 53.970\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.548237679, Training Accuracy: 57.868\n",
            "Worker 1, [02/9]: Training Loss: 1.513897244, Training Accuracy: 58.248\n",
            "Worker 1, [03/9]: Training Loss: 1.469510639, Training Accuracy: 59.176\n",
            "Worker 1, [04/9]: Training Loss: 1.440788821, Training Accuracy: 59.540\n",
            "Worker 1, [05/9]: Training Loss: 1.470182478, Training Accuracy: 58.880\n",
            "Worker 1, [06/9]: Training Loss: 1.502721791, Training Accuracy: 57.536\n",
            "Worker 1, [07/9]: Training Loss: 1.571185929, Training Accuracy: 55.880\n",
            "Worker 1, [08/9]: Training Loss: 1.639050612, Training Accuracy: 54.376\n",
            "Worker 1, [09/9]: Training Loss: 1.671893028, Training Accuracy: 53.380\n",
            "Time taken for training worker 1: 0:01:38.205409\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.935304374, Training Accuracy: 48.296\n",
            "Worker 2, [02/9]: Training Loss: 1.690934256, Training Accuracy: 53.352\n",
            "Worker 2, [03/9]: Training Loss: 1.554314487, Training Accuracy: 56.704\n",
            "Worker 2, [04/9]: Training Loss: 1.476858615, Training Accuracy: 58.616\n",
            "Worker 2, [05/9]: Training Loss: 1.470984513, Training Accuracy: 58.476\n",
            "Worker 2, [06/9]: Training Loss: 1.489068938, Training Accuracy: 57.804\n",
            "Worker 2, [07/9]: Training Loss: 1.556183987, Training Accuracy: 56.120\n",
            "Worker 2, [08/9]: Training Loss: 1.617340825, Training Accuracy: 54.552\n",
            "Worker 2, [09/9]: Training Loss: 1.662179473, Training Accuracy: 53.832\n",
            "Time taken for training worker 2: 0:01:36.754628\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000606\n",
            "Local Step 08: Test Loss: 2.144220903, Test Accuracy: 46.690\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.938846254, Training Accuracy: 47.756\n",
            "Worker 1, [02/9]: Training Loss: 1.780019795, Training Accuracy: 51.200\n",
            "Worker 1, [03/9]: Training Loss: 1.642375049, Training Accuracy: 54.420\n",
            "Worker 1, [04/9]: Training Loss: 1.535020120, Training Accuracy: 56.884\n",
            "Worker 1, [05/9]: Training Loss: 1.398048077, Training Accuracy: 60.268\n",
            "Worker 1, [06/9]: Training Loss: 1.223654094, Training Accuracy: 64.948\n",
            "Worker 1, [07/9]: Training Loss: 1.089170064, Training Accuracy: 68.564\n",
            "Worker 1, [08/9]: Training Loss: 0.968166002, Training Accuracy: 71.828\n",
            "Worker 1, [09/9]: Training Loss: 0.894824079, Training Accuracy: 74.004\n",
            "Time taken for training worker 1: 0:01:43.841196\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.924143718, Training Accuracy: 47.980\n",
            "Worker 2, [02/9]: Training Loss: 1.767701033, Training Accuracy: 50.896\n",
            "Worker 2, [03/9]: Training Loss: 1.647668148, Training Accuracy: 54.212\n",
            "Worker 2, [04/9]: Training Loss: 1.513858411, Training Accuracy: 57.384\n",
            "Worker 2, [05/9]: Training Loss: 1.384338850, Training Accuracy: 60.484\n",
            "Worker 2, [06/9]: Training Loss: 1.212355838, Training Accuracy: 64.984\n",
            "Worker 2, [07/9]: Training Loss: 1.068967514, Training Accuracy: 69.104\n",
            "Worker 2, [08/9]: Training Loss: 0.954942542, Training Accuracy: 72.252\n",
            "Worker 2, [09/9]: Training Loss: 0.881268272, Training Accuracy: 74.456\n",
            "Time taken for training worker 2: 0:01:38.791513\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000550\n",
            "Local Step 09: Test Loss: 1.822768778, Test Accuracy: 55.410\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.473676163, Training Accuracy: 59.704\n",
            "Worker 1, [02/9]: Training Loss: 1.430590278, Training Accuracy: 60.296\n",
            "Worker 1, [03/9]: Training Loss: 1.383135933, Training Accuracy: 61.064\n",
            "Worker 1, [04/9]: Training Loss: 1.350303032, Training Accuracy: 62.052\n",
            "Worker 1, [05/9]: Training Loss: 1.369416322, Training Accuracy: 61.136\n",
            "Worker 1, [06/9]: Training Loss: 1.426471629, Training Accuracy: 59.464\n",
            "Worker 1, [07/9]: Training Loss: 1.496903128, Training Accuracy: 57.568\n",
            "Worker 1, [08/9]: Training Loss: 1.560343488, Training Accuracy: 55.992\n",
            "Worker 1, [09/9]: Training Loss: 1.640096385, Training Accuracy: 54.108\n",
            "Time taken for training worker 1: 0:01:38.379356\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.896586530, Training Accuracy: 48.856\n",
            "Worker 2, [02/9]: Training Loss: 1.642463262, Training Accuracy: 54.508\n",
            "Worker 2, [03/9]: Training Loss: 1.495237710, Training Accuracy: 57.760\n",
            "Worker 2, [04/9]: Training Loss: 1.400325143, Training Accuracy: 60.612\n",
            "Worker 2, [05/9]: Training Loss: 1.389091055, Training Accuracy: 60.368\n",
            "Worker 2, [06/9]: Training Loss: 1.419044674, Training Accuracy: 59.700\n",
            "Worker 2, [07/9]: Training Loss: 1.491974661, Training Accuracy: 57.388\n",
            "Worker 2, [08/9]: Training Loss: 1.544628769, Training Accuracy: 56.768\n",
            "Worker 2, [09/9]: Training Loss: 1.600745687, Training Accuracy: 55.012\n",
            "Time taken for training worker 2: 0:01:36.942271\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000563\n",
            "Local Step 10: Test Loss: 2.092466505, Test Accuracy: 46.640\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.867450327, Training Accuracy: 49.172\n",
            "Worker 1, [02/9]: Training Loss: 1.722962595, Training Accuracy: 52.336\n",
            "Worker 1, [03/9]: Training Loss: 1.609478798, Training Accuracy: 55.096\n",
            "Worker 1, [04/9]: Training Loss: 1.466709459, Training Accuracy: 58.768\n",
            "Worker 1, [05/9]: Training Loss: 1.316631173, Training Accuracy: 62.424\n",
            "Worker 1, [06/9]: Training Loss: 1.164095522, Training Accuracy: 66.120\n",
            "Worker 1, [07/9]: Training Loss: 1.017853892, Training Accuracy: 70.436\n",
            "Worker 1, [08/9]: Training Loss: 0.898019586, Training Accuracy: 73.796\n",
            "Worker 1, [09/9]: Training Loss: 0.826475953, Training Accuracy: 76.172\n",
            "Time taken for training worker 1: 0:01:36.763983\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.868697829, Training Accuracy: 49.224\n",
            "Worker 2, [02/9]: Training Loss: 1.698841214, Training Accuracy: 52.904\n",
            "Worker 2, [03/9]: Training Loss: 1.588551082, Training Accuracy: 55.756\n",
            "Worker 2, [04/9]: Training Loss: 1.471454419, Training Accuracy: 58.292\n",
            "Worker 2, [05/9]: Training Loss: 1.304230658, Training Accuracy: 62.716\n",
            "Worker 2, [06/9]: Training Loss: 1.158706278, Training Accuracy: 66.592\n",
            "Worker 2, [07/9]: Training Loss: 1.020894859, Training Accuracy: 70.600\n",
            "Worker 2, [08/9]: Training Loss: 0.895294671, Training Accuracy: 74.036\n",
            "Worker 2, [09/9]: Training Loss: 0.816826024, Training Accuracy: 76.096\n",
            "Time taken for training worker 2: 0:01:38.833861\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000605\n",
            "Local Step 11: Test Loss: 1.849310359, Test Accuracy: 54.600\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.434525405, Training Accuracy: 60.304\n",
            "Worker 1, [02/9]: Training Loss: 1.381600032, Training Accuracy: 61.136\n",
            "Worker 1, [03/9]: Training Loss: 1.345009440, Training Accuracy: 61.952\n",
            "Worker 1, [04/9]: Training Loss: 1.312604953, Training Accuracy: 62.424\n",
            "Worker 1, [05/9]: Training Loss: 1.320775728, Training Accuracy: 62.136\n",
            "Worker 1, [06/9]: Training Loss: 1.378313157, Training Accuracy: 60.824\n",
            "Worker 1, [07/9]: Training Loss: 1.447440599, Training Accuracy: 58.624\n",
            "Worker 1, [08/9]: Training Loss: 1.543417409, Training Accuracy: 56.356\n",
            "Worker 1, [09/9]: Training Loss: 1.574221901, Training Accuracy: 55.988\n",
            "Time taken for training worker 1: 0:01:37.205166\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.892147686, Training Accuracy: 49.076\n",
            "Worker 2, [02/9]: Training Loss: 1.600374488, Training Accuracy: 55.720\n",
            "Worker 2, [03/9]: Training Loss: 1.448039321, Training Accuracy: 58.920\n",
            "Worker 2, [04/9]: Training Loss: 1.352082748, Training Accuracy: 61.580\n",
            "Worker 2, [05/9]: Training Loss: 1.326746211, Training Accuracy: 62.108\n",
            "Worker 2, [06/9]: Training Loss: 1.361298176, Training Accuracy: 61.232\n",
            "Worker 2, [07/9]: Training Loss: 1.419706924, Training Accuracy: 59.224\n",
            "Worker 2, [08/9]: Training Loss: 1.512846164, Training Accuracy: 57.460\n",
            "Worker 2, [09/9]: Training Loss: 1.547286319, Training Accuracy: 56.664\n",
            "Time taken for training worker 2: 0:01:39.775961\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000618\n",
            "Local Step 12: Test Loss: 2.084076831, Test Accuracy: 47.480\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.838515742, Training Accuracy: 49.960\n",
            "Worker 1, [02/9]: Training Loss: 1.681451979, Training Accuracy: 53.552\n",
            "Worker 1, [03/9]: Training Loss: 1.566403799, Training Accuracy: 56.220\n",
            "Worker 1, [04/9]: Training Loss: 1.431951785, Training Accuracy: 59.364\n",
            "Worker 1, [05/9]: Training Loss: 1.277955447, Training Accuracy: 63.304\n",
            "Worker 1, [06/9]: Training Loss: 1.112703146, Training Accuracy: 67.456\n",
            "Worker 1, [07/9]: Training Loss: 0.968773969, Training Accuracy: 71.488\n",
            "Worker 1, [08/9]: Training Loss: 0.850965244, Training Accuracy: 75.152\n",
            "Worker 1, [09/9]: Training Loss: 0.779569278, Training Accuracy: 77.120\n",
            "Time taken for training worker 1: 0:01:38.649848\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.833662659, Training Accuracy: 49.896\n",
            "Worker 2, [02/9]: Training Loss: 1.680923214, Training Accuracy: 53.516\n",
            "Worker 2, [03/9]: Training Loss: 1.579028689, Training Accuracy: 55.760\n",
            "Worker 2, [04/9]: Training Loss: 1.412768561, Training Accuracy: 59.936\n",
            "Worker 2, [05/9]: Training Loss: 1.267326297, Training Accuracy: 63.776\n",
            "Worker 2, [06/9]: Training Loss: 1.109315472, Training Accuracy: 67.828\n",
            "Worker 2, [07/9]: Training Loss: 0.973799451, Training Accuracy: 71.508\n",
            "Worker 2, [08/9]: Training Loss: 0.853865220, Training Accuracy: 75.024\n",
            "Worker 2, [09/9]: Training Loss: 0.785471770, Training Accuracy: 76.924\n",
            "Time taken for training worker 2: 0:01:39.130432\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000559\n",
            "Local Step 13: Test Loss: 1.843742144, Test Accuracy: 55.510\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.413983639, Training Accuracy: 61.120\n",
            "Worker 1, [02/9]: Training Loss: 1.360094752, Training Accuracy: 61.792\n",
            "Worker 1, [03/9]: Training Loss: 1.306462676, Training Accuracy: 62.648\n",
            "Worker 1, [04/9]: Training Loss: 1.274239064, Training Accuracy: 63.712\n",
            "Worker 1, [05/9]: Training Loss: 1.282286390, Training Accuracy: 63.068\n",
            "Worker 1, [06/9]: Training Loss: 1.327930162, Training Accuracy: 61.688\n",
            "Worker 1, [07/9]: Training Loss: 1.412318721, Training Accuracy: 59.812\n",
            "Worker 1, [08/9]: Training Loss: 1.497589257, Training Accuracy: 57.680\n",
            "Worker 1, [09/9]: Training Loss: 1.534199926, Training Accuracy: 56.676\n",
            "Time taken for training worker 1: 0:01:40.075214\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.868390542, Training Accuracy: 49.356\n",
            "Worker 2, [02/9]: Training Loss: 1.564520042, Training Accuracy: 56.304\n",
            "Worker 2, [03/9]: Training Loss: 1.402442082, Training Accuracy: 60.152\n",
            "Worker 2, [04/9]: Training Loss: 1.325217992, Training Accuracy: 62.272\n",
            "Worker 2, [05/9]: Training Loss: 1.291020137, Training Accuracy: 62.668\n",
            "Worker 2, [06/9]: Training Loss: 1.326672782, Training Accuracy: 62.216\n",
            "Worker 2, [07/9]: Training Loss: 1.385392829, Training Accuracy: 60.340\n",
            "Worker 2, [08/9]: Training Loss: 1.482793712, Training Accuracy: 57.864\n",
            "Worker 2, [09/9]: Training Loss: 1.534033224, Training Accuracy: 56.824\n",
            "Time taken for training worker 2: 0:01:36.587571\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000906\n",
            "Local Step 14: Test Loss: 2.149584260, Test Accuracy: 46.630\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.830038914, Training Accuracy: 50.376\n",
            "Worker 1, [02/9]: Training Loss: 1.658142622, Training Accuracy: 54.140\n",
            "Worker 1, [03/9]: Training Loss: 1.541656296, Training Accuracy: 56.572\n",
            "Worker 1, [04/9]: Training Loss: 1.385488451, Training Accuracy: 60.412\n",
            "Worker 1, [05/9]: Training Loss: 1.238352751, Training Accuracy: 64.052\n",
            "Worker 1, [06/9]: Training Loss: 1.079782548, Training Accuracy: 68.360\n",
            "Worker 1, [07/9]: Training Loss: 0.928662899, Training Accuracy: 72.816\n",
            "Worker 1, [08/9]: Training Loss: 0.811095324, Training Accuracy: 76.308\n",
            "Worker 1, [09/9]: Training Loss: 0.738402122, Training Accuracy: 78.524\n",
            "Time taken for training worker 1: 0:01:41.034041\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.812476418, Training Accuracy: 50.248\n",
            "Worker 2, [02/9]: Training Loss: 1.645432679, Training Accuracy: 54.324\n",
            "Worker 2, [03/9]: Training Loss: 1.523473260, Training Accuracy: 56.932\n",
            "Worker 2, [04/9]: Training Loss: 1.400884895, Training Accuracy: 60.264\n",
            "Worker 2, [05/9]: Training Loss: 1.243405976, Training Accuracy: 64.260\n",
            "Worker 2, [06/9]: Training Loss: 1.075976194, Training Accuracy: 68.524\n",
            "Worker 2, [07/9]: Training Loss: 0.934926777, Training Accuracy: 72.724\n",
            "Worker 2, [08/9]: Training Loss: 0.819583348, Training Accuracy: 76.164\n",
            "Worker 2, [09/9]: Training Loss: 0.748847352, Training Accuracy: 78.212\n",
            "Time taken for training worker 2: 0:01:36.507774\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000788\n",
            "Local Step 15: Test Loss: 1.844504314, Test Accuracy: 55.420\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.374947830, Training Accuracy: 61.616\n",
            "Worker 1, [02/9]: Training Loss: 1.328898641, Training Accuracy: 62.484\n",
            "Worker 1, [03/9]: Training Loss: 1.269727839, Training Accuracy: 63.200\n",
            "Worker 1, [04/9]: Training Loss: 1.239604397, Training Accuracy: 64.372\n",
            "Worker 1, [05/9]: Training Loss: 1.251297244, Training Accuracy: 64.036\n",
            "Worker 1, [06/9]: Training Loss: 1.303009640, Training Accuracy: 62.744\n",
            "Worker 1, [07/9]: Training Loss: 1.373302062, Training Accuracy: 60.816\n",
            "Worker 1, [08/9]: Training Loss: 1.473435723, Training Accuracy: 58.512\n",
            "Worker 1, [09/9]: Training Loss: 1.509482537, Training Accuracy: 57.172\n",
            "Time taken for training worker 1: 0:01:39.027197\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.816326565, Training Accuracy: 50.732\n",
            "Worker 2, [02/9]: Training Loss: 1.567552269, Training Accuracy: 55.972\n",
            "Worker 2, [03/9]: Training Loss: 1.402476515, Training Accuracy: 60.396\n",
            "Worker 2, [04/9]: Training Loss: 1.298336927, Training Accuracy: 62.608\n",
            "Worker 2, [05/9]: Training Loss: 1.273989089, Training Accuracy: 63.352\n",
            "Worker 2, [06/9]: Training Loss: 1.304667928, Training Accuracy: 62.676\n",
            "Worker 2, [07/9]: Training Loss: 1.353508816, Training Accuracy: 61.100\n",
            "Worker 2, [08/9]: Training Loss: 1.459006888, Training Accuracy: 58.560\n",
            "Worker 2, [09/9]: Training Loss: 1.497094224, Training Accuracy: 57.808\n",
            "Time taken for training worker 2: 0:01:35.969510\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000539\n",
            "Local Step 16: Test Loss: 2.113217030, Test Accuracy: 47.430\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:39.439349\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:32\n",
            "==================================================\n",
            "Worker 1, [01/4]: Training Loss: 4.348073257, Training Accuracy: 4.232\n",
            "Worker 1, [02/4]: Training Loss: 3.872225771, Training Accuracy: 9.940\n",
            "Worker 1, [03/4]: Training Loss: 3.591296089, Training Accuracy: 13.964\n",
            "Worker 1, [04/4]: Training Loss: 3.377171895, Training Accuracy: 18.480\n",
            "Time taken for training worker 1: 0:00:44.102318\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 4.336048966, Training Accuracy: 4.424\n",
            "Worker 2, [02/4]: Training Loss: 3.854070552, Training Accuracy: 10.368\n",
            "Worker 2, [03/4]: Training Loss: 3.573812619, Training Accuracy: 15.140\n",
            "Worker 2, [04/4]: Training Loss: 3.353990851, Training Accuracy: 19.084\n",
            "Time taken for training worker 2: 0:00:42.804817\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000618\n",
            "Local Step 01: Test Loss: 3.351924495, Test Accuracy: 20.160\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 3.410438085, Training Accuracy: 18.252\n",
            "Worker 1, [02/4]: Training Loss: 3.353194963, Training Accuracy: 18.724\n",
            "Worker 1, [03/4]: Training Loss: 3.367709175, Training Accuracy: 18.236\n",
            "Worker 1, [04/4]: Training Loss: 3.298917208, Training Accuracy: 19.020\n",
            "Time taken for training worker 1: 0:00:46.812024\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 3.250853182, Training Accuracy: 20.444\n",
            "Worker 2, [02/4]: Training Loss: 3.045931426, Training Accuracy: 24.620\n",
            "Worker 2, [03/4]: Training Loss: 3.055804362, Training Accuracy: 23.904\n",
            "Worker 2, [04/4]: Training Loss: 3.066574755, Training Accuracy: 24.400\n",
            "Time taken for training worker 2: 0:00:44.564370\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000661\n",
            "Local Step 02: Test Loss: 2.938973264, Test Accuracy: 27.070\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 3.023463541, Training Accuracy: 24.804\n",
            "Worker 1, [02/4]: Training Loss: 2.833461371, Training Accuracy: 28.356\n",
            "Worker 1, [03/4]: Training Loss: 2.591118956, Training Accuracy: 33.068\n",
            "Worker 1, [04/4]: Training Loss: 2.375415543, Training Accuracy: 37.828\n",
            "Time taken for training worker 1: 0:00:44.171356\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.800364060, Training Accuracy: 29.448\n",
            "Worker 2, [02/4]: Training Loss: 2.627753631, Training Accuracy: 32.416\n",
            "Worker 2, [03/4]: Training Loss: 2.414235442, Training Accuracy: 36.760\n",
            "Worker 2, [04/4]: Training Loss: 2.192908933, Training Accuracy: 41.636\n",
            "Time taken for training worker 2: 0:00:43.511935\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000617\n",
            "Local Step 03: Test Loss: 2.238606205, Test Accuracy: 41.070\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.325634063, Training Accuracy: 39.176\n",
            "Worker 1, [02/4]: Training Loss: 2.312347621, Training Accuracy: 39.512\n",
            "Worker 1, [03/4]: Training Loss: 2.391915461, Training Accuracy: 37.440\n",
            "Worker 1, [04/4]: Training Loss: 2.499278868, Training Accuracy: 34.960\n",
            "Time taken for training worker 1: 0:00:42.901979\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.544270371, Training Accuracy: 34.856\n",
            "Worker 2, [02/4]: Training Loss: 2.256208444, Training Accuracy: 40.580\n",
            "Worker 2, [03/4]: Training Loss: 2.290457059, Training Accuracy: 39.640\n",
            "Worker 2, [04/4]: Training Loss: 2.388414204, Training Accuracy: 37.444\n",
            "Time taken for training worker 2: 0:00:41.951206\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000621\n",
            "Local Step 04: Test Loss: 2.360803051, Test Accuracy: 38.450\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.474888651, Training Accuracy: 35.836\n",
            "Worker 1, [02/4]: Training Loss: 2.325376175, Training Accuracy: 38.420\n",
            "Worker 1, [03/4]: Training Loss: 2.108952491, Training Accuracy: 43.492\n",
            "Worker 1, [04/4]: Training Loss: 1.878694805, Training Accuracy: 48.932\n",
            "Time taken for training worker 1: 0:00:43.402131\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.392301046, Training Accuracy: 37.548\n",
            "Worker 2, [02/4]: Training Loss: 2.258370131, Training Accuracy: 40.380\n",
            "Worker 2, [03/4]: Training Loss: 2.025566295, Training Accuracy: 45.632\n",
            "Worker 2, [04/4]: Training Loss: 1.789347428, Training Accuracy: 50.792\n",
            "Time taken for training worker 2: 0:00:45.252136\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000686\n",
            "Local Step 05: Test Loss: 1.988490184, Test Accuracy: 47.720\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.985515710, Training Accuracy: 46.828\n",
            "Worker 1, [02/4]: Training Loss: 1.964702031, Training Accuracy: 47.288\n",
            "Worker 1, [03/4]: Training Loss: 2.049265102, Training Accuracy: 45.320\n",
            "Worker 1, [04/4]: Training Loss: 2.173468539, Training Accuracy: 42.024\n",
            "Time taken for training worker 1: 0:00:44.786211\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.234073095, Training Accuracy: 41.324\n",
            "Worker 2, [02/4]: Training Loss: 1.933291182, Training Accuracy: 48.148\n",
            "Worker 2, [03/4]: Training Loss: 1.972869728, Training Accuracy: 46.788\n",
            "Worker 2, [04/4]: Training Loss: 2.096941413, Training Accuracy: 43.964\n",
            "Time taken for training worker 2: 0:00:43.284862\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000575\n",
            "Local Step 06: Test Loss: 2.202962733, Test Accuracy: 42.170\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.251730271, Training Accuracy: 40.444\n",
            "Worker 1, [02/4]: Training Loss: 2.088042539, Training Accuracy: 44.672\n",
            "Worker 1, [03/4]: Training Loss: 1.856314643, Training Accuracy: 49.424\n",
            "Worker 1, [04/4]: Training Loss: 1.615081765, Training Accuracy: 55.156\n",
            "Time taken for training worker 1: 0:00:44.401061\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.185992408, Training Accuracy: 42.048\n",
            "Worker 2, [02/4]: Training Loss: 2.049906597, Training Accuracy: 45.104\n",
            "Worker 2, [03/4]: Training Loss: 1.825007758, Training Accuracy: 50.036\n",
            "Worker 2, [04/4]: Training Loss: 1.571290044, Training Accuracy: 56.264\n",
            "Time taken for training worker 2: 0:00:45.785542\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000565\n",
            "Local Step 07: Test Loss: 1.883759823, Test Accuracy: 50.830\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.806104008, Training Accuracy: 51.044\n",
            "Worker 1, [02/4]: Training Loss: 1.765142890, Training Accuracy: 51.980\n",
            "Worker 1, [03/4]: Training Loss: 1.838361693, Training Accuracy: 49.940\n",
            "Worker 1, [04/4]: Training Loss: 1.977299805, Training Accuracy: 46.704\n",
            "Time taken for training worker 1: 0:00:42.977980\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.077761013, Training Accuracy: 44.536\n",
            "Worker 2, [02/4]: Training Loss: 1.756702144, Training Accuracy: 51.784\n",
            "Worker 2, [03/4]: Training Loss: 1.787841222, Training Accuracy: 51.048\n",
            "Worker 2, [04/4]: Training Loss: 1.940968627, Training Accuracy: 47.584\n",
            "Time taken for training worker 2: 0:00:44.894576\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000686\n",
            "Local Step 08: Test Loss: 2.076219098, Test Accuracy: 45.380\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.088866038, Training Accuracy: 43.768\n",
            "Worker 1, [02/4]: Training Loss: 1.923703391, Training Accuracy: 48.116\n",
            "Worker 1, [03/4]: Training Loss: 1.694724712, Training Accuracy: 53.408\n",
            "Worker 1, [04/4]: Training Loss: 1.448772286, Training Accuracy: 59.568\n",
            "Time taken for training worker 1: 0:00:44.468397\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.080669196, Training Accuracy: 44.332\n",
            "Worker 2, [02/4]: Training Loss: 1.915370383, Training Accuracy: 48.240\n",
            "Worker 2, [03/4]: Training Loss: 1.675876613, Training Accuracy: 53.576\n",
            "Worker 2, [04/4]: Training Loss: 1.431753670, Training Accuracy: 59.864\n",
            "Time taken for training worker 2: 0:00:45.473188\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000789\n",
            "Local Step 09: Test Loss: 1.840536212, Test Accuracy: 52.280\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.665330072, Training Accuracy: 54.272\n",
            "Worker 1, [02/4]: Training Loss: 1.629492853, Training Accuracy: 55.180\n",
            "Worker 1, [03/4]: Training Loss: 1.708753229, Training Accuracy: 52.980\n",
            "Worker 1, [04/4]: Training Loss: 1.863875700, Training Accuracy: 49.212\n",
            "Time taken for training worker 1: 0:00:41.808879\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.950884084, Training Accuracy: 47.084\n",
            "Worker 2, [02/4]: Training Loss: 1.635044381, Training Accuracy: 54.756\n",
            "Worker 2, [03/4]: Training Loss: 1.669191278, Training Accuracy: 54.052\n",
            "Worker 2, [04/4]: Training Loss: 1.828279373, Training Accuracy: 50.200\n",
            "Time taken for training worker 2: 0:00:46.511721\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000614\n",
            "Local Step 10: Test Loss: 2.044736634, Test Accuracy: 46.420\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.003879314, Training Accuracy: 46.164\n",
            "Worker 1, [02/4]: Training Loss: 1.836931952, Training Accuracy: 49.916\n",
            "Worker 1, [03/4]: Training Loss: 1.592385610, Training Accuracy: 55.712\n",
            "Worker 1, [04/4]: Training Loss: 1.335624651, Training Accuracy: 62.544\n",
            "Time taken for training worker 1: 0:00:47.241717\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.004110800, Training Accuracy: 46.000\n",
            "Worker 2, [02/4]: Training Loss: 1.839823740, Training Accuracy: 49.956\n",
            "Worker 2, [03/4]: Training Loss: 1.580550606, Training Accuracy: 55.684\n",
            "Worker 2, [04/4]: Training Loss: 1.322496828, Training Accuracy: 62.768\n",
            "Time taken for training worker 2: 0:00:44.407421\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000570\n",
            "Local Step 11: Test Loss: 1.808807955, Test Accuracy: 52.630\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.601670848, Training Accuracy: 55.680\n",
            "Worker 1, [02/4]: Training Loss: 1.543475239, Training Accuracy: 57.452\n",
            "Worker 1, [03/4]: Training Loss: 1.624680288, Training Accuracy: 55.112\n",
            "Worker 1, [04/4]: Training Loss: 1.778792907, Training Accuracy: 50.728\n",
            "Time taken for training worker 1: 0:00:43.277263\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.823180905, Training Accuracy: 49.964\n",
            "Worker 2, [02/4]: Training Loss: 1.539195317, Training Accuracy: 57.112\n",
            "Worker 2, [03/4]: Training Loss: 1.568308421, Training Accuracy: 56.196\n",
            "Worker 2, [04/4]: Training Loss: 1.747458209, Training Accuracy: 51.696\n",
            "Time taken for training worker 2: 0:00:44.026946\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000651\n",
            "Local Step 12: Test Loss: 2.089877300, Test Accuracy: 46.030\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.919859145, Training Accuracy: 48.072\n",
            "Worker 1, [02/4]: Training Loss: 1.759836941, Training Accuracy: 51.804\n",
            "Worker 1, [03/4]: Training Loss: 1.522671751, Training Accuracy: 57.468\n",
            "Worker 1, [04/4]: Training Loss: 1.276841994, Training Accuracy: 63.812\n",
            "Time taken for training worker 1: 0:00:41.360187\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.930257330, Training Accuracy: 47.636\n",
            "Worker 2, [02/4]: Training Loss: 1.777346325, Training Accuracy: 51.152\n",
            "Worker 2, [03/4]: Training Loss: 1.521595048, Training Accuracy: 57.048\n",
            "Worker 2, [04/4]: Training Loss: 1.268864189, Training Accuracy: 64.036\n",
            "Time taken for training worker 2: 0:00:44.511899\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000654\n",
            "Local Step 13: Test Loss: 1.809772920, Test Accuracy: 53.440\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.528256552, Training Accuracy: 57.632\n",
            "Worker 1, [02/4]: Training Loss: 1.472085370, Training Accuracy: 58.668\n",
            "Worker 1, [03/4]: Training Loss: 1.562596681, Training Accuracy: 56.344\n",
            "Worker 1, [04/4]: Training Loss: 1.709944095, Training Accuracy: 52.456\n",
            "Time taken for training worker 1: 0:00:44.462289\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.837132332, Training Accuracy: 49.428\n",
            "Worker 2, [02/4]: Training Loss: 1.501802194, Training Accuracy: 57.632\n",
            "Worker 2, [03/4]: Training Loss: 1.525819093, Training Accuracy: 57.192\n",
            "Worker 2, [04/4]: Training Loss: 1.678171063, Training Accuracy: 53.328\n",
            "Time taken for training worker 2: 0:00:43.762265\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000629\n",
            "Local Step 14: Test Loss: 2.011079047, Test Accuracy: 47.590\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.876418160, Training Accuracy: 48.856\n",
            "Worker 1, [02/4]: Training Loss: 1.721607139, Training Accuracy: 52.668\n",
            "Worker 1, [03/4]: Training Loss: 1.450794033, Training Accuracy: 59.440\n",
            "Worker 1, [04/4]: Training Loss: 1.198735688, Training Accuracy: 65.920\n",
            "Time taken for training worker 1: 0:00:42.817902\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.900579228, Training Accuracy: 48.596\n",
            "Worker 2, [02/4]: Training Loss: 1.739322825, Training Accuracy: 52.020\n",
            "Worker 2, [03/4]: Training Loss: 1.456290686, Training Accuracy: 58.704\n",
            "Worker 2, [04/4]: Training Loss: 1.214327007, Training Accuracy: 65.348\n",
            "Time taken for training worker 2: 0:00:44.559919\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000785\n",
            "Local Step 15: Test Loss: 1.782678543, Test Accuracy: 54.370\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.463271341, Training Accuracy: 58.920\n",
            "Worker 1, [02/4]: Training Loss: 1.422258657, Training Accuracy: 60.116\n",
            "Worker 1, [03/4]: Training Loss: 1.510799287, Training Accuracy: 57.804\n",
            "Worker 1, [04/4]: Training Loss: 1.666333615, Training Accuracy: 53.644\n",
            "Time taken for training worker 1: 0:00:43.155189\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.739245860, Training Accuracy: 51.868\n",
            "Worker 2, [02/4]: Training Loss: 1.438776948, Training Accuracy: 59.364\n",
            "Worker 2, [03/4]: Training Loss: 1.469430429, Training Accuracy: 58.156\n",
            "Worker 2, [04/4]: Training Loss: 1.639545791, Training Accuracy: 53.848\n",
            "Time taken for training worker 2: 0:00:41.063034\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000565\n",
            "Local Step 16: Test Loss: 2.018011288, Test Accuracy: 47.760\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.834102556, Training Accuracy: 49.964\n",
            "Worker 1, [02/4]: Training Loss: 1.665712856, Training Accuracy: 53.640\n",
            "Worker 1, [03/4]: Training Loss: 1.388796680, Training Accuracy: 60.724\n",
            "Worker 1, [04/4]: Training Loss: 1.145000507, Training Accuracy: 67.292\n",
            "Time taken for training worker 1: 0:00:46.910689\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.863475082, Training Accuracy: 49.332\n",
            "Worker 2, [02/4]: Training Loss: 1.686110800, Training Accuracy: 53.220\n",
            "Worker 2, [03/4]: Training Loss: 1.428641979, Training Accuracy: 59.404\n",
            "Worker 2, [04/4]: Training Loss: 1.160014243, Training Accuracy: 67.024\n",
            "Time taken for training worker 2: 0:00:43.651715\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000891\n",
            "Local Step 17: Test Loss: 1.760213642, Test Accuracy: 54.740\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.423328553, Training Accuracy: 59.976\n",
            "Worker 1, [02/4]: Training Loss: 1.376494057, Training Accuracy: 61.376\n",
            "Worker 1, [03/4]: Training Loss: 1.467166516, Training Accuracy: 58.644\n",
            "Worker 1, [04/4]: Training Loss: 1.633114329, Training Accuracy: 54.568\n",
            "Time taken for training worker 1: 0:00:42.483997\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.720982234, Training Accuracy: 52.128\n",
            "Worker 2, [02/4]: Training Loss: 1.400073269, Training Accuracy: 60.332\n",
            "Worker 2, [03/4]: Training Loss: 1.438439443, Training Accuracy: 59.104\n",
            "Worker 2, [04/4]: Training Loss: 1.590371519, Training Accuracy: 55.516\n",
            "Time taken for training worker 2: 0:00:42.431115\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000614\n",
            "Local Step 18: Test Loss: 2.003104971, Test Accuracy: 48.550\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.798919086, Training Accuracy: 50.724\n",
            "Worker 1, [02/4]: Training Loss: 1.632841829, Training Accuracy: 54.456\n",
            "Worker 1, [03/4]: Training Loss: 1.367286505, Training Accuracy: 61.200\n",
            "Worker 1, [04/4]: Training Loss: 1.124327986, Training Accuracy: 67.732\n",
            "Time taken for training worker 1: 0:00:43.201343\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.836526249, Training Accuracy: 50.044\n",
            "Worker 2, [02/4]: Training Loss: 1.653638236, Training Accuracy: 54.036\n",
            "Worker 2, [03/4]: Training Loss: 1.378613435, Training Accuracy: 60.620\n",
            "Worker 2, [04/4]: Training Loss: 1.124294283, Training Accuracy: 67.652\n",
            "Time taken for training worker 2: 0:00:43.599629\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000760\n",
            "Local Step 19: Test Loss: 1.772540622, Test Accuracy: 55.060\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.390078098, Training Accuracy: 60.760\n",
            "Worker 1, [02/4]: Training Loss: 1.335964235, Training Accuracy: 62.092\n",
            "Worker 1, [03/4]: Training Loss: 1.431052295, Training Accuracy: 59.496\n",
            "Worker 1, [04/4]: Training Loss: 1.597879610, Training Accuracy: 55.336\n",
            "Time taken for training worker 1: 0:00:42.409652\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.694463917, Training Accuracy: 52.888\n",
            "Worker 2, [02/4]: Training Loss: 1.367939142, Training Accuracy: 61.200\n",
            "Worker 2, [03/4]: Training Loss: 1.389712914, Training Accuracy: 60.508\n",
            "Worker 2, [04/4]: Training Loss: 1.564739017, Training Accuracy: 56.032\n",
            "Time taken for training worker 2: 0:00:41.606499\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000523\n",
            "Local Step 20: Test Loss: 1.979550681, Test Accuracy: 49.650\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.765922781, Training Accuracy: 51.296\n",
            "Worker 1, [02/4]: Training Loss: 1.595169910, Training Accuracy: 55.688\n",
            "Worker 1, [03/4]: Training Loss: 1.352589506, Training Accuracy: 61.472\n",
            "Worker 1, [04/4]: Training Loss: 1.085824830, Training Accuracy: 68.572\n",
            "Time taken for training worker 1: 0:00:46.420685\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.797966129, Training Accuracy: 51.016\n",
            "Worker 2, [02/4]: Training Loss: 1.636307152, Training Accuracy: 54.236\n",
            "Worker 2, [03/4]: Training Loss: 1.354506969, Training Accuracy: 61.504\n",
            "Worker 2, [04/4]: Training Loss: 1.098506410, Training Accuracy: 68.232\n",
            "Time taken for training worker 2: 0:00:42.621870\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000625\n",
            "Local Step 21: Test Loss: 1.771157871, Test Accuracy: 54.340\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.374390797, Training Accuracy: 61.452\n",
            "Worker 1, [02/4]: Training Loss: 1.310174164, Training Accuracy: 62.784\n",
            "Worker 1, [03/4]: Training Loss: 1.418172239, Training Accuracy: 59.944\n",
            "Worker 1, [04/4]: Training Loss: 1.569126300, Training Accuracy: 55.976\n",
            "Time taken for training worker 1: 0:00:42.367356\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.744773526, Training Accuracy: 51.796\n",
            "Worker 2, [02/4]: Training Loss: 1.338115951, Training Accuracy: 61.796\n",
            "Worker 2, [03/4]: Training Loss: 1.369610295, Training Accuracy: 61.036\n",
            "Worker 2, [04/4]: Training Loss: 1.545786187, Training Accuracy: 56.468\n",
            "Time taken for training worker 2: 0:00:42.194253\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000525\n",
            "Local Step 22: Test Loss: 1.943296747, Test Accuracy: 49.590\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.785058189, Training Accuracy: 51.196\n",
            "Worker 1, [02/4]: Training Loss: 1.584156777, Training Accuracy: 55.676\n",
            "Worker 1, [03/4]: Training Loss: 1.319289711, Training Accuracy: 62.700\n",
            "Worker 1, [04/4]: Training Loss: 1.053827475, Training Accuracy: 69.540\n",
            "Time taken for training worker 1: 0:00:45.165941\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.767716257, Training Accuracy: 51.496\n",
            "Worker 2, [02/4]: Training Loss: 1.598674980, Training Accuracy: 55.364\n",
            "Worker 2, [03/4]: Training Loss: 1.335111738, Training Accuracy: 62.060\n",
            "Worker 2, [04/4]: Training Loss: 1.081312593, Training Accuracy: 68.784\n",
            "Time taken for training worker 2: 0:00:43.494631\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000551\n",
            "Local Step 23: Test Loss: 1.780703214, Test Accuracy: 55.170\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.364921068, Training Accuracy: 61.860\n",
            "Worker 1, [02/4]: Training Loss: 1.299927352, Training Accuracy: 62.952\n",
            "Worker 1, [03/4]: Training Loss: 1.389588444, Training Accuracy: 60.676\n",
            "Worker 1, [04/4]: Training Loss: 1.524517883, Training Accuracy: 57.212\n",
            "Time taken for training worker 1: 0:00:43.249091\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.643834566, Training Accuracy: 54.224\n",
            "Worker 2, [02/4]: Training Loss: 1.325563148, Training Accuracy: 62.464\n",
            "Worker 2, [03/4]: Training Loss: 1.344634651, Training Accuracy: 61.684\n",
            "Worker 2, [04/4]: Training Loss: 1.519659344, Training Accuracy: 56.852\n",
            "Time taken for training worker 2: 0:00:43.050448\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000542\n",
            "Local Step 24: Test Loss: 2.014742251, Test Accuracy: 48.340\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.732432235, Training Accuracy: 52.352\n",
            "Worker 1, [02/4]: Training Loss: 1.572683722, Training Accuracy: 56.308\n",
            "Worker 1, [03/4]: Training Loss: 1.278310521, Training Accuracy: 63.356\n",
            "Worker 1, [04/4]: Training Loss: 1.026567451, Training Accuracy: 70.356\n",
            "Time taken for training worker 1: 0:00:44.797597\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.772027920, Training Accuracy: 51.592\n",
            "Worker 2, [02/4]: Training Loss: 1.587663741, Training Accuracy: 55.984\n",
            "Worker 2, [03/4]: Training Loss: 1.312271786, Training Accuracy: 62.340\n",
            "Worker 2, [04/4]: Training Loss: 1.056713794, Training Accuracy: 69.276\n",
            "Time taken for training worker 2: 0:00:42.144557\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000600\n",
            "Local Step 25: Test Loss: 1.760861372, Test Accuracy: 55.060\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.330035254, Training Accuracy: 62.392\n",
            "Worker 1, [02/4]: Training Loss: 1.282743336, Training Accuracy: 63.532\n",
            "Worker 1, [03/4]: Training Loss: 1.357456485, Training Accuracy: 61.228\n",
            "Worker 1, [04/4]: Training Loss: 1.514193650, Training Accuracy: 57.524\n",
            "Time taken for training worker 1: 0:00:42.596740\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.605543209, Training Accuracy: 55.320\n",
            "Worker 2, [02/4]: Training Loss: 1.298184264, Training Accuracy: 62.968\n",
            "Worker 2, [03/4]: Training Loss: 1.336024267, Training Accuracy: 61.920\n",
            "Worker 2, [04/4]: Training Loss: 1.486484994, Training Accuracy: 58.172\n",
            "Time taken for training worker 2: 0:00:42.429255\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000585\n",
            "Local Step 26: Test Loss: 1.976579665, Test Accuracy: 49.440\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.713102216, Training Accuracy: 52.512\n",
            "Worker 1, [02/4]: Training Loss: 1.549803615, Training Accuracy: 56.996\n",
            "Worker 1, [03/4]: Training Loss: 1.259343674, Training Accuracy: 63.676\n",
            "Worker 1, [04/4]: Training Loss: 1.001092640, Training Accuracy: 70.916\n",
            "Time taken for training worker 1: 0:00:43.675270\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.759748654, Training Accuracy: 51.532\n",
            "Worker 2, [02/4]: Training Loss: 1.578981718, Training Accuracy: 55.944\n",
            "Worker 2, [03/4]: Training Loss: 1.279384422, Training Accuracy: 63.284\n",
            "Worker 2, [04/4]: Training Loss: 1.033018132, Training Accuracy: 69.976\n",
            "Time taken for training worker 2: 0:00:44.876611\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000619\n",
            "Local Step 27: Test Loss: 1.759186315, Test Accuracy: 55.200\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.319629975, Training Accuracy: 62.488\n",
            "Worker 1, [02/4]: Training Loss: 1.264997734, Training Accuracy: 64.180\n",
            "Worker 1, [03/4]: Training Loss: 1.336966598, Training Accuracy: 62.112\n",
            "Worker 1, [04/4]: Training Loss: 1.501691779, Training Accuracy: 57.676\n",
            "Time taken for training worker 1: 0:00:42.149137\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.605602376, Training Accuracy: 54.700\n",
            "Worker 2, [02/4]: Training Loss: 1.287824837, Training Accuracy: 62.948\n",
            "Worker 2, [03/4]: Training Loss: 1.313199363, Training Accuracy: 62.556\n",
            "Worker 2, [04/4]: Training Loss: 1.497629409, Training Accuracy: 57.496\n",
            "Time taken for training worker 2: 0:00:43.463143\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000636\n",
            "Local Step 28: Test Loss: 2.022973758, Test Accuracy: 48.390\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.717122072, Training Accuracy: 52.660\n",
            "Worker 1, [02/4]: Training Loss: 1.536283928, Training Accuracy: 57.008\n",
            "Worker 1, [03/4]: Training Loss: 1.245781268, Training Accuracy: 64.404\n",
            "Worker 1, [04/4]: Training Loss: 0.988803517, Training Accuracy: 71.172\n",
            "Time taken for training worker 1: 0:00:46.524010\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.718459650, Training Accuracy: 52.452\n",
            "Worker 2, [02/4]: Training Loss: 1.548780367, Training Accuracy: 56.640\n",
            "Worker 2, [03/4]: Training Loss: 1.263697061, Training Accuracy: 63.644\n",
            "Worker 2, [04/4]: Training Loss: 1.006219743, Training Accuracy: 70.768\n",
            "Time taken for training worker 2: 0:00:43.113220\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000546\n",
            "Local Step 29: Test Loss: 1.767320732, Test Accuracy: 55.390\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.307301434, Training Accuracy: 63.060\n",
            "Worker 1, [02/4]: Training Loss: 1.247282029, Training Accuracy: 64.340\n",
            "Worker 1, [03/4]: Training Loss: 1.321533160, Training Accuracy: 62.520\n",
            "Worker 1, [04/4]: Training Loss: 1.488955663, Training Accuracy: 58.224\n",
            "Time taken for training worker 1: 0:00:44.601997\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.525082694, Training Accuracy: 57.000\n",
            "Worker 2, [02/4]: Training Loss: 1.261578285, Training Accuracy: 64.140\n",
            "Worker 2, [03/4]: Training Loss: 1.298177208, Training Accuracy: 62.800\n",
            "Worker 2, [04/4]: Training Loss: 1.488209149, Training Accuracy: 58.060\n",
            "Time taken for training worker 2: 0:00:42.453117\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000653\n",
            "Local Step 30: Test Loss: 2.011767773, Test Accuracy: 48.090\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.688088540, Training Accuracy: 53.116\n",
            "Worker 1, [02/4]: Training Loss: 1.508138702, Training Accuracy: 57.528\n",
            "Worker 1, [03/4]: Training Loss: 1.226644298, Training Accuracy: 64.680\n",
            "Worker 1, [04/4]: Training Loss: 0.979095082, Training Accuracy: 71.436\n",
            "Time taken for training worker 1: 0:00:43.044339\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.718757240, Training Accuracy: 52.916\n",
            "Worker 2, [02/4]: Training Loss: 1.538589504, Training Accuracy: 57.024\n",
            "Worker 2, [03/4]: Training Loss: 1.264244589, Training Accuracy: 63.756\n",
            "Worker 2, [04/4]: Training Loss: 0.998047501, Training Accuracy: 71.260\n",
            "Time taken for training worker 2: 0:00:44.865968\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000580\n",
            "Local Step 31: Test Loss: 1.771151587, Test Accuracy: 54.910\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.294125433, Training Accuracy: 63.468\n",
            "Worker 1, [02/4]: Training Loss: 1.229984805, Training Accuracy: 64.824\n",
            "Worker 1, [03/4]: Training Loss: 1.317182755, Training Accuracy: 62.424\n",
            "Worker 1, [04/4]: Training Loss: 1.481254863, Training Accuracy: 58.416\n",
            "Time taken for training worker 1: 0:00:44.953550\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.627695296, Training Accuracy: 54.844\n",
            "Worker 2, [02/4]: Training Loss: 1.261872970, Training Accuracy: 63.820\n",
            "Worker 2, [03/4]: Training Loss: 1.286551295, Training Accuracy: 63.244\n",
            "Worker 2, [04/4]: Training Loss: 1.453360264, Training Accuracy: 58.556\n",
            "Time taken for training worker 2: 0:00:41.501513\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000548\n",
            "Local Step 32: Test Loss: 1.983455152, Test Accuracy: 49.070\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:47:06.891480\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:64\n",
            "==================================================\n",
            "Worker 1, [01/2]: Training Loss: 4.339584508, Training Accuracy: 4.280\n",
            "Worker 1, [02/2]: Training Loss: 3.874054162, Training Accuracy: 10.016\n",
            "Time taken for training worker 1: 0:00:21.812991\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 4.341273979, Training Accuracy: 4.368\n",
            "Worker 2, [02/2]: Training Loss: 3.874775571, Training Accuracy: 10.260\n",
            "Time taken for training worker 2: 0:00:22.641500\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000669\n",
            "Local Step 01: Test Loss: 3.729660200, Test Accuracy: 13.550\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.777467942, Training Accuracy: 12.244\n",
            "Worker 1, [02/2]: Training Loss: 3.703860592, Training Accuracy: 12.660\n",
            "Time taken for training worker 1: 0:00:20.994426\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.636075346, Training Accuracy: 13.428\n",
            "Worker 2, [02/2]: Training Loss: 3.526883252, Training Accuracy: 16.024\n",
            "Time taken for training worker 2: 0:00:21.777929\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000613\n",
            "Local Step 02: Test Loss: 3.362787979, Test Accuracy: 19.260\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.478643719, Training Accuracy: 16.164\n",
            "Worker 1, [02/2]: Training Loss: 3.176696296, Training Accuracy: 21.572\n",
            "Time taken for training worker 1: 0:00:21.153683\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.218032855, Training Accuracy: 20.928\n",
            "Worker 2, [02/2]: Training Loss: 2.935258368, Training Accuracy: 26.224\n",
            "Time taken for training worker 2: 0:00:20.814356\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000562\n",
            "Local Step 03: Test Loss: 2.786332455, Test Accuracy: 29.510\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.890951741, Training Accuracy: 27.352\n",
            "Worker 1, [02/2]: Training Loss: 2.870011042, Training Accuracy: 28.140\n",
            "Time taken for training worker 1: 0:00:22.923661\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.818242169, Training Accuracy: 28.832\n",
            "Worker 2, [02/2]: Training Loss: 2.770679959, Training Accuracy: 29.952\n",
            "Time taken for training worker 2: 0:00:21.285351\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000609\n",
            "Local Step 04: Test Loss: 2.639148685, Test Accuracy: 33.250\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.878588740, Training Accuracy: 27.784\n",
            "Worker 1, [02/2]: Training Loss: 2.600561905, Training Accuracy: 33.216\n",
            "Time taken for training worker 1: 0:00:21.011351\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.776601921, Training Accuracy: 29.824\n",
            "Worker 2, [02/2]: Training Loss: 2.487736191, Training Accuracy: 35.644\n",
            "Time taken for training worker 2: 0:00:21.003519\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000545\n",
            "Local Step 05: Test Loss: 2.414155404, Test Accuracy: 36.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.510592289, Training Accuracy: 35.068\n",
            "Worker 1, [02/2]: Training Loss: 2.493339947, Training Accuracy: 35.592\n",
            "Time taken for training worker 1: 0:00:22.693257\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.434972098, Training Accuracy: 36.600\n",
            "Worker 2, [02/2]: Training Loss: 2.412957897, Training Accuracy: 37.296\n",
            "Time taken for training worker 2: 0:00:22.161484\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000563\n",
            "Local Step 06: Test Loss: 2.357826870, Test Accuracy: 38.860\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.593937175, Training Accuracy: 33.128\n",
            "Worker 1, [02/2]: Training Loss: 2.301664485, Training Accuracy: 39.440\n",
            "Time taken for training worker 1: 0:00:21.848988\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.541244502, Training Accuracy: 34.484\n",
            "Worker 2, [02/2]: Training Loss: 2.263878875, Training Accuracy: 40.532\n",
            "Time taken for training worker 2: 0:00:22.674610\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000625\n",
            "Local Step 07: Test Loss: 2.206477235, Test Accuracy: 41.390\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.281724580, Training Accuracy: 40.308\n",
            "Worker 1, [02/2]: Training Loss: 2.256082137, Training Accuracy: 40.624\n",
            "Time taken for training worker 1: 0:00:21.329150\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.203878884, Training Accuracy: 41.656\n",
            "Worker 2, [02/2]: Training Loss: 2.192883017, Training Accuracy: 41.936\n",
            "Time taken for training worker 2: 0:00:21.073967\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000573\n",
            "Local Step 08: Test Loss: 2.197281825, Test Accuracy: 42.430\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.415693512, Training Accuracy: 37.372\n",
            "Worker 1, [02/2]: Training Loss: 2.125328095, Training Accuracy: 43.020\n",
            "Time taken for training worker 1: 0:00:21.520784\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.386345065, Training Accuracy: 37.788\n",
            "Worker 2, [02/2]: Training Loss: 2.091786752, Training Accuracy: 44.188\n",
            "Time taken for training worker 2: 0:00:22.037988\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000727\n",
            "Local Step 09: Test Loss: 2.111032428, Test Accuracy: 44.200\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.133306026, Training Accuracy: 43.564\n",
            "Worker 1, [02/2]: Training Loss: 2.096147724, Training Accuracy: 44.288\n",
            "Time taken for training worker 1: 0:00:22.335844\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.050143863, Training Accuracy: 45.020\n",
            "Worker 2, [02/2]: Training Loss: 2.033716653, Training Accuracy: 45.464\n",
            "Time taken for training worker 2: 0:00:23.279830\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000624\n",
            "Local Step 10: Test Loss: 2.088518593, Test Accuracy: 44.960\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.274003007, Training Accuracy: 40.228\n",
            "Worker 1, [02/2]: Training Loss: 1.979399181, Training Accuracy: 46.724\n",
            "Time taken for training worker 1: 0:00:21.652614\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.265900921, Training Accuracy: 40.452\n",
            "Worker 2, [02/2]: Training Loss: 1.960092030, Training Accuracy: 46.980\n",
            "Time taken for training worker 2: 0:00:21.259750\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000826\n",
            "Local Step 11: Test Loss: 2.075774307, Test Accuracy: 45.650\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.008490668, Training Accuracy: 46.396\n",
            "Worker 1, [02/2]: Training Loss: 1.997233052, Training Accuracy: 46.340\n",
            "Time taken for training worker 1: 0:00:21.551760\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.945424599, Training Accuracy: 47.788\n",
            "Worker 2, [02/2]: Training Loss: 1.898470994, Training Accuracy: 48.528\n",
            "Time taken for training worker 2: 0:00:20.813239\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000638\n",
            "Local Step 12: Test Loss: 1.992430348, Test Accuracy: 47.200\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.176493374, Training Accuracy: 42.000\n",
            "Worker 1, [02/2]: Training Loss: 1.890611031, Training Accuracy: 48.948\n",
            "Time taken for training worker 1: 0:00:22.280944\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.171980274, Training Accuracy: 42.592\n",
            "Worker 2, [02/2]: Training Loss: 1.877558443, Training Accuracy: 48.924\n",
            "Time taken for training worker 2: 0:00:21.448874\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000615\n",
            "Local Step 13: Test Loss: 2.000996513, Test Accuracy: 47.070\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.912703204, Training Accuracy: 48.204\n",
            "Worker 1, [02/2]: Training Loss: 1.891689387, Training Accuracy: 48.864\n",
            "Time taken for training worker 1: 0:00:21.206918\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.834270239, Training Accuracy: 49.892\n",
            "Worker 2, [02/2]: Training Loss: 1.819933240, Training Accuracy: 50.168\n",
            "Time taken for training worker 2: 0:00:20.807005\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000568\n",
            "Local Step 14: Test Loss: 1.963765772, Test Accuracy: 48.450\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.097421960, Training Accuracy: 44.236\n",
            "Worker 1, [02/2]: Training Loss: 1.780818525, Training Accuracy: 51.292\n",
            "Time taken for training worker 1: 0:00:22.858562\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.101468224, Training Accuracy: 43.696\n",
            "Worker 2, [02/2]: Training Loss: 1.786198690, Training Accuracy: 51.256\n",
            "Time taken for training worker 2: 0:00:22.316157\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000603\n",
            "Local Step 15: Test Loss: 1.969838918, Test Accuracy: 47.700\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.833429762, Training Accuracy: 50.412\n",
            "Worker 1, [02/2]: Training Loss: 1.819642657, Training Accuracy: 50.384\n",
            "Time taken for training worker 1: 0:00:21.662114\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.731885289, Training Accuracy: 52.520\n",
            "Worker 2, [02/2]: Training Loss: 1.728306423, Training Accuracy: 52.264\n",
            "Time taken for training worker 2: 0:00:21.408259\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000746\n",
            "Local Step 16: Test Loss: 1.948881666, Test Accuracy: 48.730\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.017093382, Training Accuracy: 45.668\n",
            "Worker 1, [02/2]: Training Loss: 1.724507289, Training Accuracy: 53.028\n",
            "Time taken for training worker 1: 0:00:21.784020\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.061826512, Training Accuracy: 45.156\n",
            "Worker 2, [02/2]: Training Loss: 1.727966510, Training Accuracy: 52.440\n",
            "Time taken for training worker 2: 0:00:22.855262\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000566\n",
            "Local Step 17: Test Loss: 1.969685523, Test Accuracy: 48.250\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.819519861, Training Accuracy: 50.424\n",
            "Worker 1, [02/2]: Training Loss: 1.768187464, Training Accuracy: 51.332\n",
            "Time taken for training worker 1: 0:00:22.214386\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.724818394, Training Accuracy: 52.484\n",
            "Worker 2, [02/2]: Training Loss: 1.671013938, Training Accuracy: 53.776\n",
            "Time taken for training worker 2: 0:00:22.708148\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000634\n",
            "Local Step 18: Test Loss: 1.895061990, Test Accuracy: 49.950\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.978609143, Training Accuracy: 46.648\n",
            "Worker 1, [02/2]: Training Loss: 1.656552936, Training Accuracy: 54.228\n",
            "Time taken for training worker 1: 0:00:22.941156\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.005142392, Training Accuracy: 46.012\n",
            "Worker 2, [02/2]: Training Loss: 1.663349129, Training Accuracy: 54.020\n",
            "Time taken for training worker 2: 0:00:20.833174\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000867\n",
            "Local Step 19: Test Loss: 1.968121574, Test Accuracy: 48.670\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.782592106, Training Accuracy: 51.280\n",
            "Worker 1, [02/2]: Training Loss: 1.700666089, Training Accuracy: 53.204\n",
            "Time taken for training worker 1: 0:00:20.071563\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.624913529, Training Accuracy: 54.912\n",
            "Worker 2, [02/2]: Training Loss: 1.632632453, Training Accuracy: 54.640\n",
            "Time taken for training worker 2: 0:00:22.344334\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000602\n",
            "Local Step 20: Test Loss: 1.897961425, Test Accuracy: 49.920\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.930600599, Training Accuracy: 47.432\n",
            "Worker 1, [02/2]: Training Loss: 1.613388961, Training Accuracy: 55.964\n",
            "Time taken for training worker 1: 0:00:21.774676\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.958146327, Training Accuracy: 47.120\n",
            "Worker 2, [02/2]: Training Loss: 1.624815512, Training Accuracy: 54.880\n",
            "Time taken for training worker 2: 0:00:20.491388\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000527\n",
            "Local Step 21: Test Loss: 1.936259156, Test Accuracy: 50.060\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.715400801, Training Accuracy: 53.172\n",
            "Worker 1, [02/2]: Training Loss: 1.672906745, Training Accuracy: 53.904\n",
            "Time taken for training worker 1: 0:00:20.117995\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.590451708, Training Accuracy: 55.792\n",
            "Worker 2, [02/2]: Training Loss: 1.574921652, Training Accuracy: 55.608\n",
            "Time taken for training worker 2: 0:00:24.174024\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000570\n",
            "Local Step 22: Test Loss: 1.868231638, Test Accuracy: 51.080\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.902644279, Training Accuracy: 48.188\n",
            "Worker 1, [02/2]: Training Loss: 1.586202789, Training Accuracy: 55.916\n",
            "Time taken for training worker 1: 0:00:22.793369\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.933099438, Training Accuracy: 47.580\n",
            "Worker 2, [02/2]: Training Loss: 1.590022002, Training Accuracy: 55.392\n",
            "Time taken for training worker 2: 0:00:20.685871\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000488\n",
            "Local Step 23: Test Loss: 1.886232184, Test Accuracy: 50.410\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.643776659, Training Accuracy: 54.448\n",
            "Worker 1, [02/2]: Training Loss: 1.624759542, Training Accuracy: 55.336\n",
            "Time taken for training worker 1: 0:00:21.085516\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.573855453, Training Accuracy: 56.284\n",
            "Worker 2, [02/2]: Training Loss: 1.546675307, Training Accuracy: 56.716\n",
            "Time taken for training worker 2: 0:00:20.469541\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000520\n",
            "Local Step 24: Test Loss: 1.861882476, Test Accuracy: 51.190\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.873636830, Training Accuracy: 48.892\n",
            "Worker 1, [02/2]: Training Loss: 1.551416953, Training Accuracy: 56.672\n",
            "Time taken for training worker 1: 0:00:19.618897\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.898209485, Training Accuracy: 48.540\n",
            "Worker 2, [02/2]: Training Loss: 1.559970725, Training Accuracy: 56.760\n",
            "Time taken for training worker 2: 0:00:19.882761\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000530\n",
            "Local Step 25: Test Loss: 1.903915572, Test Accuracy: 50.360\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.647060497, Training Accuracy: 54.488\n",
            "Worker 1, [02/2]: Training Loss: 1.605014335, Training Accuracy: 55.128\n",
            "Time taken for training worker 1: 0:00:20.028214\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.518679385, Training Accuracy: 57.640\n",
            "Worker 2, [02/2]: Training Loss: 1.517336442, Training Accuracy: 57.488\n",
            "Time taken for training worker 2: 0:00:21.168559\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000560\n",
            "Local Step 26: Test Loss: 1.833436170, Test Accuracy: 52.130\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.850049177, Training Accuracy: 49.488\n",
            "Worker 1, [02/2]: Training Loss: 1.513177783, Training Accuracy: 57.768\n",
            "Time taken for training worker 1: 0:00:21.228488\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.883667333, Training Accuracy: 48.800\n",
            "Worker 2, [02/2]: Training Loss: 1.538464798, Training Accuracy: 56.828\n",
            "Time taken for training worker 2: 0:00:19.985055\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000637\n",
            "Local Step 27: Test Loss: 1.864434543, Test Accuracy: 51.000\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.602584225, Training Accuracy: 55.700\n",
            "Worker 1, [02/2]: Training Loss: 1.573668883, Training Accuracy: 55.984\n",
            "Time taken for training worker 1: 0:00:19.730153\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.507591381, Training Accuracy: 57.616\n",
            "Worker 2, [02/2]: Training Loss: 1.476444143, Training Accuracy: 58.216\n",
            "Time taken for training worker 2: 0:00:20.522625\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000574\n",
            "Local Step 28: Test Loss: 1.865134007, Test Accuracy: 52.120\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.821069783, Training Accuracy: 50.336\n",
            "Worker 1, [02/2]: Training Loss: 1.487703266, Training Accuracy: 58.252\n",
            "Time taken for training worker 1: 0:00:19.255363\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.847110375, Training Accuracy: 49.120\n",
            "Worker 2, [02/2]: Training Loss: 1.507093264, Training Accuracy: 57.308\n",
            "Time taken for training worker 2: 0:00:19.653220\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000480\n",
            "Local Step 29: Test Loss: 1.855779030, Test Accuracy: 52.070\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.579880586, Training Accuracy: 56.268\n",
            "Worker 1, [02/2]: Training Loss: 1.547648041, Training Accuracy: 56.820\n",
            "Time taken for training worker 1: 0:00:21.215744\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.467164817, Training Accuracy: 58.916\n",
            "Worker 2, [02/2]: Training Loss: 1.464935257, Training Accuracy: 58.468\n",
            "Time taken for training worker 2: 0:00:19.804943\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000639\n",
            "Local Step 30: Test Loss: 1.818120845, Test Accuracy: 52.230\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.785937754, Training Accuracy: 50.996\n",
            "Worker 1, [02/2]: Training Loss: 1.461736090, Training Accuracy: 58.956\n",
            "Time taken for training worker 1: 0:00:20.996555\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.846083561, Training Accuracy: 49.596\n",
            "Worker 2, [02/2]: Training Loss: 1.477533863, Training Accuracy: 58.576\n",
            "Time taken for training worker 2: 0:00:20.471307\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000515\n",
            "Local Step 31: Test Loss: 1.848943147, Test Accuracy: 51.780\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.545885267, Training Accuracy: 56.372\n",
            "Worker 1, [02/2]: Training Loss: 1.511333193, Training Accuracy: 58.016\n",
            "Time taken for training worker 1: 0:00:21.049189\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.418047701, Training Accuracy: 59.780\n",
            "Worker 2, [02/2]: Training Loss: 1.436652352, Training Accuracy: 59.040\n",
            "Time taken for training worker 2: 0:00:19.996532\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000544\n",
            "Local Step 32: Test Loss: 1.846693895, Test Accuracy: 51.730\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.798173854, Training Accuracy: 50.852\n",
            "Worker 1, [02/2]: Training Loss: 1.441315609, Training Accuracy: 59.240\n",
            "Time taken for training worker 1: 0:00:22.330021\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.811911233, Training Accuracy: 50.232\n",
            "Worker 2, [02/2]: Training Loss: 1.460417252, Training Accuracy: 58.996\n",
            "Time taken for training worker 2: 0:00:22.207120\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000892\n",
            "Local Step 33: Test Loss: 1.839946972, Test Accuracy: 51.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.518647792, Training Accuracy: 57.076\n",
            "Worker 1, [02/2]: Training Loss: 1.497314778, Training Accuracy: 57.684\n",
            "Time taken for training worker 1: 0:00:18.907220\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.441028692, Training Accuracy: 59.508\n",
            "Worker 2, [02/2]: Training Loss: 1.417091716, Training Accuracy: 59.936\n",
            "Time taken for training worker 2: 0:00:20.373490\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000592\n",
            "Local Step 34: Test Loss: 1.842229533, Test Accuracy: 52.150\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.738827842, Training Accuracy: 52.104\n",
            "Worker 1, [02/2]: Training Loss: 1.418478461, Training Accuracy: 60.076\n",
            "Time taken for training worker 1: 0:00:20.477534\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.809631253, Training Accuracy: 50.360\n",
            "Worker 2, [02/2]: Training Loss: 1.440932464, Training Accuracy: 59.480\n",
            "Time taken for training worker 2: 0:00:21.303221\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000572\n",
            "Local Step 35: Test Loss: 1.852843806, Test Accuracy: 51.880\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.542373329, Training Accuracy: 57.120\n",
            "Worker 1, [02/2]: Training Loss: 1.492131226, Training Accuracy: 58.276\n",
            "Time taken for training worker 1: 0:00:19.556288\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.385546761, Training Accuracy: 60.412\n",
            "Worker 2, [02/2]: Training Loss: 1.396321322, Training Accuracy: 60.416\n",
            "Time taken for training worker 2: 0:00:19.924612\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000520\n",
            "Local Step 36: Test Loss: 1.834379236, Test Accuracy: 52.770\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.746874186, Training Accuracy: 52.068\n",
            "Worker 1, [02/2]: Training Loss: 1.417796901, Training Accuracy: 60.216\n",
            "Time taken for training worker 1: 0:00:20.235926\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.769324000, Training Accuracy: 51.388\n",
            "Worker 2, [02/2]: Training Loss: 1.424429999, Training Accuracy: 59.520\n",
            "Time taken for training worker 2: 0:00:19.074087\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000609\n",
            "Local Step 37: Test Loss: 1.838183889, Test Accuracy: 52.160\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.498710079, Training Accuracy: 57.912\n",
            "Worker 1, [02/2]: Training Loss: 1.466384375, Training Accuracy: 58.904\n",
            "Time taken for training worker 1: 0:00:19.889162\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.391728894, Training Accuracy: 60.336\n",
            "Worker 2, [02/2]: Training Loss: 1.361957793, Training Accuracy: 60.980\n",
            "Time taken for training worker 2: 0:00:21.720672\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000579\n",
            "Local Step 38: Test Loss: 1.837582871, Test Accuracy: 52.140\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.728336971, Training Accuracy: 52.356\n",
            "Worker 1, [02/2]: Training Loss: 1.394838987, Training Accuracy: 60.424\n",
            "Time taken for training worker 1: 0:00:19.375318\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.767628936, Training Accuracy: 51.360\n",
            "Worker 2, [02/2]: Training Loss: 1.404741653, Training Accuracy: 60.300\n",
            "Time taken for training worker 2: 0:00:19.212001\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000871\n",
            "Local Step 39: Test Loss: 1.842256436, Test Accuracy: 53.230\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.488972431, Training Accuracy: 58.120\n",
            "Worker 1, [02/2]: Training Loss: 1.456070983, Training Accuracy: 58.852\n",
            "Time taken for training worker 1: 0:00:19.767728\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.395030484, Training Accuracy: 60.592\n",
            "Worker 2, [02/2]: Training Loss: 1.358368273, Training Accuracy: 61.292\n",
            "Time taken for training worker 2: 0:00:19.196424\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000538\n",
            "Local Step 40: Test Loss: 1.825534420, Test Accuracy: 53.160\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.702786849, Training Accuracy: 52.900\n",
            "Worker 1, [02/2]: Training Loss: 1.362596657, Training Accuracy: 61.332\n",
            "Time taken for training worker 1: 0:00:18.953827\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.775839272, Training Accuracy: 51.448\n",
            "Worker 2, [02/2]: Training Loss: 1.401587303, Training Accuracy: 59.688\n",
            "Time taken for training worker 2: 0:00:19.586168\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000482\n",
            "Local Step 41: Test Loss: 1.861387537, Test Accuracy: 52.350\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.486386758, Training Accuracy: 58.592\n",
            "Worker 1, [02/2]: Training Loss: 1.449532656, Training Accuracy: 58.964\n",
            "Time taken for training worker 1: 0:00:19.008557\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.374638793, Training Accuracy: 60.720\n",
            "Worker 2, [02/2]: Training Loss: 1.361005472, Training Accuracy: 61.244\n",
            "Time taken for training worker 2: 0:00:19.489556\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000873\n",
            "Local Step 42: Test Loss: 1.837732837, Test Accuracy: 52.510\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.689342449, Training Accuracy: 53.636\n",
            "Worker 1, [02/2]: Training Loss: 1.367860007, Training Accuracy: 61.348\n",
            "Time taken for training worker 1: 0:00:20.193924\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.757853631, Training Accuracy: 51.592\n",
            "Worker 2, [02/2]: Training Loss: 1.394545939, Training Accuracy: 60.560\n",
            "Time taken for training worker 2: 0:00:20.133718\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000542\n",
            "Local Step 43: Test Loss: 1.814362746, Test Accuracy: 52.060\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.469028934, Training Accuracy: 58.764\n",
            "Worker 1, [02/2]: Training Loss: 1.419407156, Training Accuracy: 59.784\n",
            "Time taken for training worker 1: 0:00:19.347372\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.345104263, Training Accuracy: 61.808\n",
            "Worker 2, [02/2]: Training Loss: 1.334537852, Training Accuracy: 61.844\n",
            "Time taken for training worker 2: 0:00:20.253198\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000575\n",
            "Local Step 44: Test Loss: 1.824418632, Test Accuracy: 52.580\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.687346420, Training Accuracy: 53.140\n",
            "Worker 1, [02/2]: Training Loss: 1.357193806, Training Accuracy: 61.744\n",
            "Time taken for training worker 1: 0:00:20.163409\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.734868536, Training Accuracy: 52.104\n",
            "Worker 2, [02/2]: Training Loss: 1.378475327, Training Accuracy: 60.572\n",
            "Time taken for training worker 2: 0:00:20.848609\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 45: Test Loss: 1.850086310, Test Accuracy: 52.330\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.478854979, Training Accuracy: 58.480\n",
            "Worker 1, [02/2]: Training Loss: 1.413233649, Training Accuracy: 60.144\n",
            "Time taken for training worker 1: 0:00:18.817657\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.358898038, Training Accuracy: 61.556\n",
            "Worker 2, [02/2]: Training Loss: 1.319530252, Training Accuracy: 62.328\n",
            "Time taken for training worker 2: 0:00:19.894720\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000867\n",
            "Local Step 46: Test Loss: 1.818528380, Test Accuracy: 52.740\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.687646733, Training Accuracy: 53.184\n",
            "Worker 1, [02/2]: Training Loss: 1.344907524, Training Accuracy: 61.800\n",
            "Time taken for training worker 1: 0:00:20.121688\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.725757556, Training Accuracy: 52.512\n",
            "Worker 2, [02/2]: Training Loss: 1.372739237, Training Accuracy: 60.956\n",
            "Time taken for training worker 2: 0:00:20.430523\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000545\n",
            "Local Step 47: Test Loss: 1.866191177, Test Accuracy: 51.800\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.437402620, Training Accuracy: 59.580\n",
            "Worker 1, [02/2]: Training Loss: 1.413798197, Training Accuracy: 59.768\n",
            "Time taken for training worker 1: 0:00:22.201479\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.319752087, Training Accuracy: 62.452\n",
            "Worker 2, [02/2]: Training Loss: 1.309336024, Training Accuracy: 62.228\n",
            "Time taken for training worker 2: 0:00:21.839398\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000597\n",
            "Local Step 48: Test Loss: 1.803204016, Test Accuracy: 53.170\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.667773010, Training Accuracy: 53.992\n",
            "Worker 1, [02/2]: Training Loss: 1.321182045, Training Accuracy: 62.164\n",
            "Time taken for training worker 1: 0:00:19.229610\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.731301371, Training Accuracy: 51.956\n",
            "Worker 2, [02/2]: Training Loss: 1.350229082, Training Accuracy: 61.364\n",
            "Time taken for training worker 2: 0:00:19.487588\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000538\n",
            "Local Step 49: Test Loss: 1.821838795, Test Accuracy: 53.360\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.430986501, Training Accuracy: 59.780\n",
            "Worker 1, [02/2]: Training Loss: 1.404253275, Training Accuracy: 60.376\n",
            "Time taken for training worker 1: 0:00:19.000290\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.337524964, Training Accuracy: 61.768\n",
            "Worker 2, [02/2]: Training Loss: 1.293261226, Training Accuracy: 62.800\n",
            "Time taken for training worker 2: 0:00:19.302888\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000569\n",
            "Local Step 50: Test Loss: 1.832350010, Test Accuracy: 52.900\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.676903400, Training Accuracy: 53.212\n",
            "Worker 1, [02/2]: Training Loss: 1.312183417, Training Accuracy: 62.636\n",
            "Time taken for training worker 1: 0:00:22.343834\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.708713392, Training Accuracy: 52.976\n",
            "Worker 2, [02/2]: Training Loss: 1.347347074, Training Accuracy: 61.904\n",
            "Time taken for training worker 2: 0:00:21.426315\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000528\n",
            "Local Step 51: Test Loss: 1.826006482, Test Accuracy: 52.040\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.414955490, Training Accuracy: 59.856\n",
            "Worker 1, [02/2]: Training Loss: 1.381795979, Training Accuracy: 60.904\n",
            "Time taken for training worker 1: 0:00:19.882524\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.261350756, Training Accuracy: 63.716\n",
            "Worker 2, [02/2]: Training Loss: 1.302544827, Training Accuracy: 62.832\n",
            "Time taken for training worker 2: 0:00:21.118302\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000559\n",
            "Local Step 52: Test Loss: 1.864375907, Test Accuracy: 52.320\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.640433882, Training Accuracy: 54.724\n",
            "Worker 1, [02/2]: Training Loss: 1.304768125, Training Accuracy: 63.372\n",
            "Time taken for training worker 1: 0:00:19.400835\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.714641107, Training Accuracy: 52.812\n",
            "Worker 2, [02/2]: Training Loss: 1.341527536, Training Accuracy: 61.644\n",
            "Time taken for training worker 2: 0:00:20.118066\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000539\n",
            "Local Step 53: Test Loss: 1.859597461, Test Accuracy: 52.150\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.445623339, Training Accuracy: 59.216\n",
            "Worker 1, [02/2]: Training Loss: 1.377762251, Training Accuracy: 60.620\n",
            "Time taken for training worker 1: 0:00:18.938277\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.297453270, Training Accuracy: 63.016\n",
            "Worker 2, [02/2]: Training Loss: 1.290303100, Training Accuracy: 62.652\n",
            "Time taken for training worker 2: 0:00:19.181821\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000515\n",
            "Local Step 54: Test Loss: 1.851124218, Test Accuracy: 52.670\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.642524489, Training Accuracy: 54.676\n",
            "Worker 1, [02/2]: Training Loss: 1.304608423, Training Accuracy: 62.676\n",
            "Time taken for training worker 1: 0:00:20.264152\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.705506657, Training Accuracy: 52.616\n",
            "Worker 2, [02/2]: Training Loss: 1.331343080, Training Accuracy: 61.636\n",
            "Time taken for training worker 2: 0:00:19.578427\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000534\n",
            "Local Step 55: Test Loss: 1.895033547, Test Accuracy: 50.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.491227432, Training Accuracy: 57.976\n",
            "Worker 1, [02/2]: Training Loss: 1.384628076, Training Accuracy: 60.716\n",
            "Time taken for training worker 1: 0:00:19.578514\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.290272047, Training Accuracy: 63.168\n",
            "Worker 2, [02/2]: Training Loss: 1.272533551, Training Accuracy: 63.640\n",
            "Time taken for training worker 2: 0:00:20.747380\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000562\n",
            "Local Step 56: Test Loss: 1.805847614, Test Accuracy: 53.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.662118205, Training Accuracy: 53.692\n",
            "Worker 1, [02/2]: Training Loss: 1.297801167, Training Accuracy: 63.052\n",
            "Time taken for training worker 1: 0:00:21.780677\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.700686451, Training Accuracy: 52.816\n",
            "Worker 2, [02/2]: Training Loss: 1.341331953, Training Accuracy: 62.060\n",
            "Time taken for training worker 2: 0:00:22.066204\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000523\n",
            "Local Step 57: Test Loss: 1.832571652, Test Accuracy: 52.760\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.391635315, Training Accuracy: 60.164\n",
            "Worker 1, [02/2]: Training Loss: 1.357055471, Training Accuracy: 61.604\n",
            "Time taken for training worker 1: 0:00:21.362782\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.297931710, Training Accuracy: 62.828\n",
            "Worker 2, [02/2]: Training Loss: 1.269614047, Training Accuracy: 63.452\n",
            "Time taken for training worker 2: 0:00:19.098273\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000541\n",
            "Local Step 58: Test Loss: 1.867205650, Test Accuracy: 52.160\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.630558007, Training Accuracy: 54.240\n",
            "Worker 1, [02/2]: Training Loss: 1.296051999, Training Accuracy: 63.040\n",
            "Time taken for training worker 1: 0:00:20.177229\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.687857416, Training Accuracy: 52.728\n",
            "Worker 2, [02/2]: Training Loss: 1.322937730, Training Accuracy: 62.156\n",
            "Time taken for training worker 2: 0:00:20.915298\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000582\n",
            "Local Step 59: Test Loss: 1.829182232, Test Accuracy: 53.670\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.396682185, Training Accuracy: 60.444\n",
            "Worker 1, [02/2]: Training Loss: 1.370300056, Training Accuracy: 60.968\n",
            "Time taken for training worker 1: 0:00:20.034868\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.249151836, Training Accuracy: 63.948\n",
            "Worker 2, [02/2]: Training Loss: 1.251036363, Training Accuracy: 63.788\n",
            "Time taken for training worker 2: 0:00:20.356202\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000544\n",
            "Local Step 60: Test Loss: 1.811770344, Test Accuracy: 52.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.647114661, Training Accuracy: 54.156\n",
            "Worker 1, [02/2]: Training Loss: 1.290776109, Training Accuracy: 62.876\n",
            "Time taken for training worker 1: 0:00:20.374770\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.681668200, Training Accuracy: 53.208\n",
            "Worker 2, [02/2]: Training Loss: 1.303449560, Training Accuracy: 63.044\n",
            "Time taken for training worker 2: 0:00:20.678712\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000568\n",
            "Local Step 61: Test Loss: 1.787629918, Test Accuracy: 53.330\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.337548728, Training Accuracy: 61.772\n",
            "Worker 1, [02/2]: Training Loss: 1.349435210, Training Accuracy: 61.680\n",
            "Time taken for training worker 1: 0:00:20.716288\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.232295309, Training Accuracy: 64.684\n",
            "Worker 2, [02/2]: Training Loss: 1.240358603, Training Accuracy: 64.300\n",
            "Time taken for training worker 2: 0:00:20.289155\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000525\n",
            "Local Step 62: Test Loss: 1.798424972, Test Accuracy: 52.870\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.617483913, Training Accuracy: 54.620\n",
            "Worker 1, [02/2]: Training Loss: 1.267182056, Training Accuracy: 63.836\n",
            "Time taken for training worker 1: 0:00:20.744412\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.686193574, Training Accuracy: 53.452\n",
            "Worker 2, [02/2]: Training Loss: 1.295145087, Training Accuracy: 62.752\n",
            "Time taken for training worker 2: 0:00:19.247602\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000577\n",
            "Local Step 63: Test Loss: 1.869478748, Test Accuracy: 52.190\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.377557766, Training Accuracy: 60.716\n",
            "Worker 1, [02/2]: Training Loss: 1.334748004, Training Accuracy: 62.172\n",
            "Time taken for training worker 1: 0:00:20.345551\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.274708507, Training Accuracy: 63.368\n",
            "Worker 2, [02/2]: Training Loss: 1.253099498, Training Accuracy: 63.420\n",
            "Time taken for training worker 2: 0:00:19.491882\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000570\n",
            "Local Step 64: Test Loss: 1.832723895, Test Accuracy: 53.490\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:45:10.444534\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.529819812, Training Accuracy: 2.232\n",
            "Worker 1, [02/37]: Training Loss: 4.152790017, Training Accuracy: 6.032\n",
            "Worker 1, [03/37]: Training Loss: 3.923709221, Training Accuracy: 8.944\n",
            "Worker 1, [04/37]: Training Loss: 3.761995245, Training Accuracy: 11.704\n",
            "Worker 1, [05/37]: Training Loss: 3.602762232, Training Accuracy: 14.280\n",
            "Worker 1, [06/37]: Training Loss: 3.484567514, Training Accuracy: 16.328\n",
            "Worker 1, [07/37]: Training Loss: 3.367658239, Training Accuracy: 18.296\n",
            "Worker 1, [08/37]: Training Loss: 3.264558254, Training Accuracy: 19.928\n",
            "Worker 1, [09/37]: Training Loss: 3.174875930, Training Accuracy: 22.024\n",
            "Worker 1, [10/37]: Training Loss: 3.071129723, Training Accuracy: 23.408\n",
            "Worker 1, [11/37]: Training Loss: 2.983586365, Training Accuracy: 24.800\n",
            "Worker 1, [12/37]: Training Loss: 2.893567122, Training Accuracy: 27.296\n",
            "Worker 1, [13/37]: Training Loss: 2.812674695, Training Accuracy: 28.696\n",
            "Worker 1, [14/37]: Training Loss: 2.738788265, Training Accuracy: 29.960\n",
            "Worker 1, [15/37]: Training Loss: 2.647532712, Training Accuracy: 31.424\n",
            "Worker 1, [16/37]: Training Loss: 2.565826367, Training Accuracy: 32.928\n",
            "Worker 1, [17/37]: Training Loss: 2.488669817, Training Accuracy: 35.112\n",
            "Worker 1, [18/37]: Training Loss: 2.410349127, Training Accuracy: 36.768\n",
            "Worker 1, [19/37]: Training Loss: 2.355916943, Training Accuracy: 37.520\n",
            "Worker 1, [20/37]: Training Loss: 2.285146290, Training Accuracy: 38.800\n",
            "Worker 1, [21/37]: Training Loss: 2.195784501, Training Accuracy: 41.488\n",
            "Worker 1, [22/37]: Training Loss: 2.133707536, Training Accuracy: 42.520\n",
            "Worker 1, [23/37]: Training Loss: 2.062100682, Training Accuracy: 44.384\n",
            "Worker 1, [24/37]: Training Loss: 1.997470299, Training Accuracy: 45.528\n",
            "Worker 1, [25/37]: Training Loss: 1.917873066, Training Accuracy: 47.592\n",
            "Worker 1, [26/37]: Training Loss: 1.867301211, Training Accuracy: 48.608\n",
            "Worker 1, [27/37]: Training Loss: 1.813420794, Training Accuracy: 50.096\n",
            "Worker 1, [28/37]: Training Loss: 1.752660253, Training Accuracy: 51.968\n",
            "Worker 1, [29/37]: Training Loss: 1.699927640, Training Accuracy: 53.048\n",
            "Worker 1, [30/37]: Training Loss: 1.641381287, Training Accuracy: 54.952\n",
            "Worker 1, [31/37]: Training Loss: 1.593608303, Training Accuracy: 56.168\n",
            "Worker 1, [32/37]: Training Loss: 1.564741209, Training Accuracy: 56.512\n",
            "Worker 1, [33/37]: Training Loss: 1.525811141, Training Accuracy: 57.936\n",
            "Worker 1, [34/37]: Training Loss: 1.493500641, Training Accuracy: 58.464\n",
            "Worker 1, [35/37]: Training Loss: 1.467227096, Training Accuracy: 59.472\n",
            "Worker 1, [36/37]: Training Loss: 1.469709858, Training Accuracy: 59.424\n",
            "Worker 1, [37/37]: Training Loss: 1.458262299, Training Accuracy: 60.048\n",
            "Time taken for training worker 1: 0:03:05.815334\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.524511359, Training Accuracy: 2.400\n",
            "Worker 2, [02/37]: Training Loss: 4.147075086, Training Accuracy: 5.968\n",
            "Worker 2, [03/37]: Training Loss: 3.938834766, Training Accuracy: 9.128\n",
            "Worker 2, [04/37]: Training Loss: 3.786193443, Training Accuracy: 11.408\n",
            "Worker 2, [05/37]: Training Loss: 3.641534914, Training Accuracy: 13.448\n",
            "Worker 2, [06/37]: Training Loss: 3.518241257, Training Accuracy: 15.536\n",
            "Worker 2, [07/37]: Training Loss: 3.414621814, Training Accuracy: 17.272\n",
            "Worker 2, [08/37]: Training Loss: 3.291930570, Training Accuracy: 19.288\n",
            "Worker 2, [09/37]: Training Loss: 3.204497421, Training Accuracy: 21.128\n",
            "Worker 2, [10/37]: Training Loss: 3.089658217, Training Accuracy: 23.384\n",
            "Worker 2, [11/37]: Training Loss: 3.033837227, Training Accuracy: 24.184\n",
            "Worker 2, [12/37]: Training Loss: 2.948545491, Training Accuracy: 25.056\n",
            "Worker 2, [13/37]: Training Loss: 2.854903896, Training Accuracy: 27.584\n",
            "Worker 2, [14/37]: Training Loss: 2.763847341, Training Accuracy: 29.376\n",
            "Worker 2, [15/37]: Training Loss: 2.708080160, Training Accuracy: 30.416\n",
            "Worker 2, [16/37]: Training Loss: 2.632023297, Training Accuracy: 31.888\n",
            "Worker 2, [17/37]: Training Loss: 2.549513294, Training Accuracy: 33.096\n",
            "Worker 2, [18/37]: Training Loss: 2.468941791, Training Accuracy: 35.720\n",
            "Worker 2, [19/37]: Training Loss: 2.400102173, Training Accuracy: 36.016\n",
            "Worker 2, [20/37]: Training Loss: 2.332983199, Training Accuracy: 37.872\n",
            "Worker 2, [21/37]: Training Loss: 2.240417180, Training Accuracy: 40.144\n",
            "Worker 2, [22/37]: Training Loss: 2.190083360, Training Accuracy: 41.320\n",
            "Worker 2, [23/37]: Training Loss: 2.107516466, Training Accuracy: 42.744\n",
            "Worker 2, [24/37]: Training Loss: 2.038064440, Training Accuracy: 44.344\n",
            "Worker 2, [25/37]: Training Loss: 1.983999486, Training Accuracy: 45.840\n",
            "Worker 2, [26/37]: Training Loss: 1.921260821, Training Accuracy: 47.760\n",
            "Worker 2, [27/37]: Training Loss: 1.873315249, Training Accuracy: 47.984\n",
            "Worker 2, [28/37]: Training Loss: 1.798965259, Training Accuracy: 50.368\n",
            "Worker 2, [29/37]: Training Loss: 1.745059046, Training Accuracy: 51.936\n",
            "Worker 2, [30/37]: Training Loss: 1.688760894, Training Accuracy: 53.232\n",
            "Worker 2, [31/37]: Training Loss: 1.639750896, Training Accuracy: 54.184\n",
            "Worker 2, [32/37]: Training Loss: 1.611713372, Training Accuracy: 55.168\n",
            "Worker 2, [33/37]: Training Loss: 1.568222166, Training Accuracy: 56.328\n",
            "Worker 2, [34/37]: Training Loss: 1.534832212, Training Accuracy: 57.160\n",
            "Worker 2, [35/37]: Training Loss: 1.513420480, Training Accuracy: 57.736\n",
            "Worker 2, [36/37]: Training Loss: 1.506322739, Training Accuracy: 57.920\n",
            "Worker 2, [37/37]: Training Loss: 1.498361280, Training Accuracy: 58.248\n",
            "Time taken for training worker 2: 0:03:03.613146\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.533945492, Training Accuracy: 1.808\n",
            "Worker 3, [02/37]: Training Loss: 4.159363446, Training Accuracy: 5.904\n",
            "Worker 3, [03/37]: Training Loss: 3.942648981, Training Accuracy: 8.824\n",
            "Worker 3, [04/37]: Training Loss: 3.780196074, Training Accuracy: 10.816\n",
            "Worker 3, [05/37]: Training Loss: 3.625671737, Training Accuracy: 13.168\n",
            "Worker 3, [06/37]: Training Loss: 3.517711665, Training Accuracy: 15.584\n",
            "Worker 3, [07/37]: Training Loss: 3.395163181, Training Accuracy: 17.080\n",
            "Worker 3, [08/37]: Training Loss: 3.314999146, Training Accuracy: 18.440\n",
            "Worker 3, [09/37]: Training Loss: 3.209602889, Training Accuracy: 20.744\n",
            "Worker 3, [10/37]: Training Loss: 3.119944155, Training Accuracy: 21.952\n",
            "Worker 3, [11/37]: Training Loss: 3.039550211, Training Accuracy: 23.696\n",
            "Worker 3, [12/37]: Training Loss: 2.959377317, Training Accuracy: 25.184\n",
            "Worker 3, [13/37]: Training Loss: 2.870686434, Training Accuracy: 26.904\n",
            "Worker 3, [14/37]: Training Loss: 2.774272280, Training Accuracy: 28.752\n",
            "Worker 3, [15/37]: Training Loss: 2.732927142, Training Accuracy: 29.376\n",
            "Worker 3, [16/37]: Training Loss: 2.635842382, Training Accuracy: 30.952\n",
            "Worker 3, [17/37]: Training Loss: 2.559133375, Training Accuracy: 32.776\n",
            "Worker 3, [18/37]: Training Loss: 2.490217827, Training Accuracy: 34.600\n",
            "Worker 3, [19/37]: Training Loss: 2.407558113, Training Accuracy: 36.344\n",
            "Worker 3, [20/37]: Training Loss: 2.350636289, Training Accuracy: 37.344\n",
            "Worker 3, [21/37]: Training Loss: 2.273703644, Training Accuracy: 39.032\n",
            "Worker 3, [22/37]: Training Loss: 2.206330908, Training Accuracy: 40.360\n",
            "Worker 3, [23/37]: Training Loss: 2.134441397, Training Accuracy: 41.864\n",
            "Worker 3, [24/37]: Training Loss: 2.082172076, Training Accuracy: 43.984\n",
            "Worker 3, [25/37]: Training Loss: 2.001086559, Training Accuracy: 45.304\n",
            "Worker 3, [26/37]: Training Loss: 1.925804751, Training Accuracy: 46.808\n",
            "Worker 3, [27/37]: Training Loss: 1.887302537, Training Accuracy: 48.192\n",
            "Worker 3, [28/37]: Training Loss: 1.821351179, Training Accuracy: 49.184\n",
            "Worker 3, [29/37]: Training Loss: 1.772259331, Training Accuracy: 51.192\n",
            "Worker 3, [30/37]: Training Loss: 1.709572201, Training Accuracy: 52.672\n",
            "Worker 3, [31/37]: Training Loss: 1.673968237, Training Accuracy: 53.176\n",
            "Worker 3, [32/37]: Training Loss: 1.617560080, Training Accuracy: 55.104\n",
            "Worker 3, [33/37]: Training Loss: 1.602739827, Training Accuracy: 54.840\n",
            "Worker 3, [34/37]: Training Loss: 1.569602111, Training Accuracy: 56.344\n",
            "Worker 3, [35/37]: Training Loss: 1.558396728, Training Accuracy: 56.616\n",
            "Worker 3, [36/37]: Training Loss: 1.536650709, Training Accuracy: 57.360\n",
            "Worker 3, [37/37]: Training Loss: 1.528698084, Training Accuracy: 57.496\n",
            "Time taken for training worker 3: 0:03:05.548269\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.516920095, Training Accuracy: 2.384\n",
            "Worker 4, [02/37]: Training Loss: 4.136763282, Training Accuracy: 6.544\n",
            "Worker 4, [03/37]: Training Loss: 3.922337864, Training Accuracy: 9.336\n",
            "Worker 4, [04/37]: Training Loss: 3.753245498, Training Accuracy: 12.088\n",
            "Worker 4, [05/37]: Training Loss: 3.610417221, Training Accuracy: 13.992\n",
            "Worker 4, [06/37]: Training Loss: 3.493326485, Training Accuracy: 16.080\n",
            "Worker 4, [07/37]: Training Loss: 3.381068663, Training Accuracy: 18.256\n",
            "Worker 4, [08/37]: Training Loss: 3.280015292, Training Accuracy: 19.616\n",
            "Worker 4, [09/37]: Training Loss: 3.183192467, Training Accuracy: 21.576\n",
            "Worker 4, [10/37]: Training Loss: 3.101050541, Training Accuracy: 23.008\n",
            "Worker 4, [11/37]: Training Loss: 3.003113243, Training Accuracy: 25.592\n",
            "Worker 4, [12/37]: Training Loss: 2.926489986, Training Accuracy: 26.016\n",
            "Worker 4, [13/37]: Training Loss: 2.851928656, Training Accuracy: 27.840\n",
            "Worker 4, [14/37]: Training Loss: 2.775677443, Training Accuracy: 29.256\n",
            "Worker 4, [15/37]: Training Loss: 2.681247349, Training Accuracy: 31.072\n",
            "Worker 4, [16/37]: Training Loss: 2.615350329, Training Accuracy: 31.664\n",
            "Worker 4, [17/37]: Training Loss: 2.528417402, Training Accuracy: 34.080\n",
            "Worker 4, [18/37]: Training Loss: 2.449633710, Training Accuracy: 35.720\n",
            "Worker 4, [19/37]: Training Loss: 2.387251474, Training Accuracy: 37.112\n",
            "Worker 4, [20/37]: Training Loss: 2.309407687, Training Accuracy: 38.424\n",
            "Worker 4, [21/37]: Training Loss: 2.267064773, Training Accuracy: 39.776\n",
            "Worker 4, [22/37]: Training Loss: 2.178858826, Training Accuracy: 41.432\n",
            "Worker 4, [23/37]: Training Loss: 2.109792799, Training Accuracy: 43.680\n",
            "Worker 4, [24/37]: Training Loss: 2.037220269, Training Accuracy: 45.096\n",
            "Worker 4, [25/37]: Training Loss: 1.987720532, Training Accuracy: 46.432\n",
            "Worker 4, [26/37]: Training Loss: 1.917008815, Training Accuracy: 47.504\n",
            "Worker 4, [27/37]: Training Loss: 1.852504474, Training Accuracy: 48.992\n",
            "Worker 4, [28/37]: Training Loss: 1.794488813, Training Accuracy: 50.848\n",
            "Worker 4, [29/37]: Training Loss: 1.754518761, Training Accuracy: 51.784\n",
            "Worker 4, [30/37]: Training Loss: 1.716291206, Training Accuracy: 52.696\n",
            "Worker 4, [31/37]: Training Loss: 1.666729971, Training Accuracy: 54.272\n",
            "Worker 4, [32/37]: Training Loss: 1.620052235, Training Accuracy: 55.432\n",
            "Worker 4, [33/37]: Training Loss: 1.588922179, Training Accuracy: 55.680\n",
            "Worker 4, [34/37]: Training Loss: 1.552921619, Training Accuracy: 57.352\n",
            "Worker 4, [35/37]: Training Loss: 1.528719664, Training Accuracy: 58.096\n",
            "Worker 4, [36/37]: Training Loss: 1.518076961, Training Accuracy: 58.056\n",
            "Worker 4, [37/37]: Training Loss: 1.501286810, Training Accuracy: 58.368\n",
            "Time taken for training worker 4: 0:03:07.492986\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000637\n",
            "Local Step 01: Test Loss: 2.935250569, Test Accuracy: 28.550\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.980787732, Training Accuracy: 27.408\n",
            "Worker 1, [02/37]: Training Loss: 2.960457343, Training Accuracy: 27.976\n",
            "Worker 1, [03/37]: Training Loss: 2.857360350, Training Accuracy: 29.416\n",
            "Worker 1, [04/37]: Training Loss: 2.749846902, Training Accuracy: 30.960\n",
            "Worker 1, [05/37]: Training Loss: 2.667994924, Training Accuracy: 32.048\n",
            "Worker 1, [06/37]: Training Loss: 2.600868845, Training Accuracy: 33.856\n",
            "Worker 1, [07/37]: Training Loss: 2.542846107, Training Accuracy: 34.720\n",
            "Worker 1, [08/37]: Training Loss: 2.488452549, Training Accuracy: 35.864\n",
            "Worker 1, [09/37]: Training Loss: 2.452489180, Training Accuracy: 36.560\n",
            "Worker 1, [10/37]: Training Loss: 2.432003246, Training Accuracy: 36.840\n",
            "Worker 1, [11/37]: Training Loss: 2.392358476, Training Accuracy: 37.504\n",
            "Worker 1, [12/37]: Training Loss: 2.357644043, Training Accuracy: 37.672\n",
            "Worker 1, [13/37]: Training Loss: 2.338584973, Training Accuracy: 38.568\n",
            "Worker 1, [14/37]: Training Loss: 2.341704291, Training Accuracy: 38.504\n",
            "Worker 1, [15/37]: Training Loss: 2.307045411, Training Accuracy: 38.960\n",
            "Worker 1, [16/37]: Training Loss: 2.287714207, Training Accuracy: 39.336\n",
            "Worker 1, [17/37]: Training Loss: 2.260464857, Training Accuracy: 39.472\n",
            "Worker 1, [18/37]: Training Loss: 2.245941918, Training Accuracy: 40.200\n",
            "Worker 1, [19/37]: Training Loss: 2.224970517, Training Accuracy: 40.464\n",
            "Worker 1, [20/37]: Training Loss: 2.212531236, Training Accuracy: 40.480\n",
            "Worker 1, [21/37]: Training Loss: 2.184354168, Training Accuracy: 41.408\n",
            "Worker 1, [22/37]: Training Loss: 2.162891238, Training Accuracy: 41.496\n",
            "Worker 1, [23/37]: Training Loss: 2.140077003, Training Accuracy: 42.320\n",
            "Worker 1, [24/37]: Training Loss: 2.102174958, Training Accuracy: 42.728\n",
            "Worker 1, [25/37]: Training Loss: 2.098440909, Training Accuracy: 42.920\n",
            "Worker 1, [26/37]: Training Loss: 2.084283199, Training Accuracy: 43.632\n",
            "Worker 1, [27/37]: Training Loss: 2.033803876, Training Accuracy: 44.120\n",
            "Worker 1, [28/37]: Training Loss: 2.019547506, Training Accuracy: 45.024\n",
            "Worker 1, [29/37]: Training Loss: 2.026130239, Training Accuracy: 44.480\n",
            "Worker 1, [30/37]: Training Loss: 2.002224825, Training Accuracy: 45.120\n",
            "Worker 1, [31/37]: Training Loss: 1.938363331, Training Accuracy: 46.936\n",
            "Worker 1, [32/37]: Training Loss: 1.958574934, Training Accuracy: 46.416\n",
            "Worker 1, [33/37]: Training Loss: 1.916386220, Training Accuracy: 47.040\n",
            "Worker 1, [34/37]: Training Loss: 1.905648638, Training Accuracy: 47.096\n",
            "Worker 1, [35/37]: Training Loss: 1.866163665, Training Accuracy: 48.304\n",
            "Worker 1, [36/37]: Training Loss: 1.813860507, Training Accuracy: 49.456\n",
            "Worker 1, [37/37]: Training Loss: 1.799882282, Training Accuracy: 50.344\n",
            "Time taken for training worker 1: 0:03:07.004132\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.103236498, Training Accuracy: 30.840\n",
            "Worker 2, [02/37]: Training Loss: 3.024928224, Training Accuracy: 31.512\n",
            "Worker 2, [03/37]: Training Loss: 2.851682107, Training Accuracy: 32.728\n",
            "Worker 2, [04/37]: Training Loss: 2.722414587, Training Accuracy: 33.272\n",
            "Worker 2, [05/37]: Training Loss: 2.628157971, Training Accuracy: 35.112\n",
            "Worker 2, [06/37]: Training Loss: 2.548950285, Training Accuracy: 36.576\n",
            "Worker 2, [07/37]: Training Loss: 2.480212851, Training Accuracy: 37.456\n",
            "Worker 2, [08/37]: Training Loss: 2.402805445, Training Accuracy: 38.648\n",
            "Worker 2, [09/37]: Training Loss: 2.327095534, Training Accuracy: 40.208\n",
            "Worker 2, [10/37]: Training Loss: 2.271226873, Training Accuracy: 41.176\n",
            "Worker 2, [11/37]: Training Loss: 2.219284336, Training Accuracy: 41.912\n",
            "Worker 2, [12/37]: Training Loss: 2.162354071, Training Accuracy: 43.192\n",
            "Worker 2, [13/37]: Training Loss: 2.117288609, Training Accuracy: 44.328\n",
            "Worker 2, [14/37]: Training Loss: 2.068333226, Training Accuracy: 45.656\n",
            "Worker 2, [15/37]: Training Loss: 2.011618840, Training Accuracy: 46.456\n",
            "Worker 2, [16/37]: Training Loss: 1.977292036, Training Accuracy: 47.056\n",
            "Worker 2, [17/37]: Training Loss: 1.936757700, Training Accuracy: 48.184\n",
            "Worker 2, [18/37]: Training Loss: 1.905239584, Training Accuracy: 48.256\n",
            "Worker 2, [19/37]: Training Loss: 1.882970122, Training Accuracy: 48.992\n",
            "Worker 2, [20/37]: Training Loss: 1.843894901, Training Accuracy: 50.144\n",
            "Worker 2, [21/37]: Training Loss: 1.815354405, Training Accuracy: 50.376\n",
            "Worker 2, [22/37]: Training Loss: 1.804860291, Training Accuracy: 50.352\n",
            "Worker 2, [23/37]: Training Loss: 1.780744309, Training Accuracy: 50.800\n",
            "Worker 2, [24/37]: Training Loss: 1.759165978, Training Accuracy: 51.792\n",
            "Worker 2, [25/37]: Training Loss: 1.764137296, Training Accuracy: 51.376\n",
            "Worker 2, [26/37]: Training Loss: 1.720242072, Training Accuracy: 52.072\n",
            "Worker 2, [27/37]: Training Loss: 1.704549943, Training Accuracy: 52.352\n",
            "Worker 2, [28/37]: Training Loss: 1.709206473, Training Accuracy: 52.248\n",
            "Worker 2, [29/37]: Training Loss: 1.697922963, Training Accuracy: 52.712\n",
            "Worker 2, [30/37]: Training Loss: 1.668254888, Training Accuracy: 53.824\n",
            "Worker 2, [31/37]: Training Loss: 1.659365189, Training Accuracy: 54.024\n",
            "Worker 2, [32/37]: Training Loss: 1.658842538, Training Accuracy: 53.640\n",
            "Worker 2, [33/37]: Training Loss: 1.660022634, Training Accuracy: 53.448\n",
            "Worker 2, [34/37]: Training Loss: 1.604620652, Training Accuracy: 54.680\n",
            "Worker 2, [35/37]: Training Loss: 1.613728321, Training Accuracy: 54.856\n",
            "Worker 2, [36/37]: Training Loss: 1.576658257, Training Accuracy: 55.704\n",
            "Worker 2, [37/37]: Training Loss: 1.538433194, Training Accuracy: 56.552\n",
            "Time taken for training worker 2: 0:03:03.450909\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.985459455, Training Accuracy: 31.832\n",
            "Worker 3, [02/37]: Training Loss: 2.934488098, Training Accuracy: 32.560\n",
            "Worker 3, [03/37]: Training Loss: 2.795259241, Training Accuracy: 33.592\n",
            "Worker 3, [04/37]: Training Loss: 2.669102415, Training Accuracy: 35.104\n",
            "Worker 3, [05/37]: Training Loss: 2.581493521, Training Accuracy: 36.248\n",
            "Worker 3, [06/37]: Training Loss: 2.470625846, Training Accuracy: 37.976\n",
            "Worker 3, [07/37]: Training Loss: 2.395571013, Training Accuracy: 39.624\n",
            "Worker 3, [08/37]: Training Loss: 2.328939573, Training Accuracy: 40.360\n",
            "Worker 3, [09/37]: Training Loss: 2.265516567, Training Accuracy: 41.704\n",
            "Worker 3, [10/37]: Training Loss: 2.186780796, Training Accuracy: 43.128\n",
            "Worker 3, [11/37]: Training Loss: 2.121637339, Training Accuracy: 44.296\n",
            "Worker 3, [12/37]: Training Loss: 2.052971548, Training Accuracy: 45.688\n",
            "Worker 3, [13/37]: Training Loss: 2.025437265, Training Accuracy: 46.264\n",
            "Worker 3, [14/37]: Training Loss: 1.941831406, Training Accuracy: 48.432\n",
            "Worker 3, [15/37]: Training Loss: 1.860834755, Training Accuracy: 49.512\n",
            "Worker 3, [16/37]: Training Loss: 1.836268443, Training Accuracy: 49.888\n",
            "Worker 3, [17/37]: Training Loss: 1.802037229, Training Accuracy: 50.624\n",
            "Worker 3, [18/37]: Training Loss: 1.760152195, Training Accuracy: 52.008\n",
            "Worker 3, [19/37]: Training Loss: 1.724459763, Training Accuracy: 52.344\n",
            "Worker 3, [20/37]: Training Loss: 1.697456329, Training Accuracy: 53.400\n",
            "Worker 3, [21/37]: Training Loss: 1.672024460, Training Accuracy: 53.264\n",
            "Worker 3, [22/37]: Training Loss: 1.627215109, Training Accuracy: 54.592\n",
            "Worker 3, [23/37]: Training Loss: 1.613602285, Training Accuracy: 55.200\n",
            "Worker 3, [24/37]: Training Loss: 1.601923992, Training Accuracy: 54.848\n",
            "Worker 3, [25/37]: Training Loss: 1.608626910, Training Accuracy: 54.768\n",
            "Worker 3, [26/37]: Training Loss: 1.606663613, Training Accuracy: 54.824\n",
            "Worker 3, [27/37]: Training Loss: 1.566200959, Training Accuracy: 55.624\n",
            "Worker 3, [28/37]: Training Loss: 1.562747643, Training Accuracy: 55.392\n",
            "Worker 3, [29/37]: Training Loss: 1.554204969, Training Accuracy: 55.568\n",
            "Worker 3, [30/37]: Training Loss: 1.546154737, Training Accuracy: 55.824\n",
            "Worker 3, [31/37]: Training Loss: 1.538804620, Training Accuracy: 55.872\n",
            "Worker 3, [32/37]: Training Loss: 1.517710201, Training Accuracy: 56.848\n",
            "Worker 3, [33/37]: Training Loss: 1.519068210, Training Accuracy: 56.888\n",
            "Worker 3, [34/37]: Training Loss: 1.495820744, Training Accuracy: 57.240\n",
            "Worker 3, [35/37]: Training Loss: 1.484466521, Training Accuracy: 57.528\n",
            "Worker 3, [36/37]: Training Loss: 1.449634247, Training Accuracy: 58.592\n",
            "Worker 3, [37/37]: Training Loss: 1.481341083, Training Accuracy: 57.952\n",
            "Time taken for training worker 3: 0:03:03.525973\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 2.963402550, Training Accuracy: 34.576\n",
            "Worker 4, [02/37]: Training Loss: 2.886693001, Training Accuracy: 35.344\n",
            "Worker 4, [03/37]: Training Loss: 2.717777770, Training Accuracy: 36.736\n",
            "Worker 4, [04/37]: Training Loss: 2.579433959, Training Accuracy: 38.160\n",
            "Worker 4, [05/37]: Training Loss: 2.472905202, Training Accuracy: 39.096\n",
            "Worker 4, [06/37]: Training Loss: 2.386426390, Training Accuracy: 39.784\n",
            "Worker 4, [07/37]: Training Loss: 2.309761463, Training Accuracy: 41.584\n",
            "Worker 4, [08/37]: Training Loss: 2.244646516, Training Accuracy: 42.816\n",
            "Worker 4, [09/37]: Training Loss: 2.154469094, Training Accuracy: 44.560\n",
            "Worker 4, [10/37]: Training Loss: 2.080515684, Training Accuracy: 45.824\n",
            "Worker 4, [11/37]: Training Loss: 2.013184091, Training Accuracy: 47.512\n",
            "Worker 4, [12/37]: Training Loss: 1.952174915, Training Accuracy: 48.520\n",
            "Worker 4, [13/37]: Training Loss: 1.884301303, Training Accuracy: 49.560\n",
            "Worker 4, [14/37]: Training Loss: 1.832869614, Training Accuracy: 51.024\n",
            "Worker 4, [15/37]: Training Loss: 1.777002042, Training Accuracy: 52.024\n",
            "Worker 4, [16/37]: Training Loss: 1.726839969, Training Accuracy: 53.120\n",
            "Worker 4, [17/37]: Training Loss: 1.680535596, Training Accuracy: 54.384\n",
            "Worker 4, [18/37]: Training Loss: 1.658228490, Training Accuracy: 54.744\n",
            "Worker 4, [19/37]: Training Loss: 1.617424386, Training Accuracy: 54.928\n",
            "Worker 4, [20/37]: Training Loss: 1.588242511, Training Accuracy: 55.856\n",
            "Worker 4, [21/37]: Training Loss: 1.550389200, Training Accuracy: 56.576\n",
            "Worker 4, [22/37]: Training Loss: 1.526536014, Training Accuracy: 57.008\n",
            "Worker 4, [23/37]: Training Loss: 1.500903349, Training Accuracy: 57.216\n",
            "Worker 4, [24/37]: Training Loss: 1.486819054, Training Accuracy: 57.736\n",
            "Worker 4, [25/37]: Training Loss: 1.496046090, Training Accuracy: 57.736\n",
            "Worker 4, [26/37]: Training Loss: 1.457409483, Training Accuracy: 59.192\n",
            "Worker 4, [27/37]: Training Loss: 1.463172822, Training Accuracy: 58.792\n",
            "Worker 4, [28/37]: Training Loss: 1.443555847, Training Accuracy: 58.720\n",
            "Worker 4, [29/37]: Training Loss: 1.450673220, Training Accuracy: 58.152\n",
            "Worker 4, [30/37]: Training Loss: 1.457239141, Training Accuracy: 58.280\n",
            "Worker 4, [31/37]: Training Loss: 1.423658549, Training Accuracy: 59.840\n",
            "Worker 4, [32/37]: Training Loss: 1.446605488, Training Accuracy: 58.488\n",
            "Worker 4, [33/37]: Training Loss: 1.417380415, Training Accuracy: 59.616\n",
            "Worker 4, [34/37]: Training Loss: 1.404760797, Training Accuracy: 59.464\n",
            "Worker 4, [35/37]: Training Loss: 1.419783184, Training Accuracy: 59.392\n",
            "Worker 4, [36/37]: Training Loss: 1.392821879, Training Accuracy: 60.064\n",
            "Worker 4, [37/37]: Training Loss: 1.366309544, Training Accuracy: 60.704\n",
            "Time taken for training worker 4: 0:03:07.463503\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 02: Test Loss: 2.639676708, Test Accuracy: 39.540\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.611593889, Training Accuracy: 35.944\n",
            "Worker 1, [02/37]: Training Loss: 2.258640069, Training Accuracy: 42.176\n",
            "Worker 1, [03/37]: Training Loss: 2.095285413, Training Accuracy: 45.376\n",
            "Worker 1, [04/37]: Training Loss: 1.938541516, Training Accuracy: 48.056\n",
            "Worker 1, [05/37]: Training Loss: 1.861822856, Training Accuracy: 49.728\n",
            "Worker 1, [06/37]: Training Loss: 1.763798441, Training Accuracy: 51.888\n",
            "Worker 1, [07/37]: Training Loss: 1.673561751, Training Accuracy: 54.032\n",
            "Worker 1, [08/37]: Training Loss: 1.606669142, Training Accuracy: 55.552\n",
            "Worker 1, [09/37]: Training Loss: 1.539014498, Training Accuracy: 56.888\n",
            "Worker 1, [10/37]: Training Loss: 1.485043577, Training Accuracy: 58.176\n",
            "Worker 1, [11/37]: Training Loss: 1.429254346, Training Accuracy: 59.384\n",
            "Worker 1, [12/37]: Training Loss: 1.349009272, Training Accuracy: 61.496\n",
            "Worker 1, [13/37]: Training Loss: 1.289870093, Training Accuracy: 63.144\n",
            "Worker 1, [14/37]: Training Loss: 1.215404686, Training Accuracy: 64.656\n",
            "Worker 1, [15/37]: Training Loss: 1.139854873, Training Accuracy: 67.216\n",
            "Worker 1, [16/37]: Training Loss: 1.086981758, Training Accuracy: 68.472\n",
            "Worker 1, [17/37]: Training Loss: 0.995014609, Training Accuracy: 70.928\n",
            "Worker 1, [18/37]: Training Loss: 0.959704142, Training Accuracy: 71.680\n",
            "Worker 1, [19/37]: Training Loss: 0.897458481, Training Accuracy: 73.448\n",
            "Worker 1, [20/37]: Training Loss: 0.836770210, Training Accuracy: 75.344\n",
            "Worker 1, [21/37]: Training Loss: 0.775303963, Training Accuracy: 76.888\n",
            "Worker 1, [22/37]: Training Loss: 0.717910553, Training Accuracy: 78.800\n",
            "Worker 1, [23/37]: Training Loss: 0.666731212, Training Accuracy: 80.584\n",
            "Worker 1, [24/37]: Training Loss: 0.629826538, Training Accuracy: 81.560\n",
            "Worker 1, [25/37]: Training Loss: 0.566561031, Training Accuracy: 83.592\n",
            "Worker 1, [26/37]: Training Loss: 0.510211789, Training Accuracy: 84.624\n",
            "Worker 1, [27/37]: Training Loss: 0.474043860, Training Accuracy: 86.472\n",
            "Worker 1, [28/37]: Training Loss: 0.448917275, Training Accuracy: 87.296\n",
            "Worker 1, [29/37]: Training Loss: 0.417071365, Training Accuracy: 87.784\n",
            "Worker 1, [30/37]: Training Loss: 0.383316080, Training Accuracy: 89.032\n",
            "Worker 1, [31/37]: Training Loss: 0.374850838, Training Accuracy: 89.592\n",
            "Worker 1, [32/37]: Training Loss: 0.365120972, Training Accuracy: 89.688\n",
            "Worker 1, [33/37]: Training Loss: 0.337217468, Training Accuracy: 90.864\n",
            "Worker 1, [34/37]: Training Loss: 0.317554056, Training Accuracy: 91.200\n",
            "Worker 1, [35/37]: Training Loss: 0.328301494, Training Accuracy: 90.936\n",
            "Worker 1, [36/37]: Training Loss: 0.314094362, Training Accuracy: 91.496\n",
            "Worker 1, [37/37]: Training Loss: 0.312480317, Training Accuracy: 91.608\n",
            "Time taken for training worker 1: 0:03:07.056965\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.697822328, Training Accuracy: 34.376\n",
            "Worker 2, [02/37]: Training Loss: 2.213348671, Training Accuracy: 42.408\n",
            "Worker 2, [03/37]: Training Loss: 2.052788615, Training Accuracy: 45.656\n",
            "Worker 2, [04/37]: Training Loss: 1.882066984, Training Accuracy: 48.672\n",
            "Worker 2, [05/37]: Training Loss: 1.813742734, Training Accuracy: 51.104\n",
            "Worker 2, [06/37]: Training Loss: 1.725477778, Training Accuracy: 52.488\n",
            "Worker 2, [07/37]: Training Loss: 1.655709959, Training Accuracy: 54.224\n",
            "Worker 2, [08/37]: Training Loss: 1.582489954, Training Accuracy: 56.272\n",
            "Worker 2, [09/37]: Training Loss: 1.492165163, Training Accuracy: 58.344\n",
            "Worker 2, [10/37]: Training Loss: 1.442247552, Training Accuracy: 58.968\n",
            "Worker 2, [11/37]: Training Loss: 1.354712012, Training Accuracy: 61.344\n",
            "Worker 2, [12/37]: Training Loss: 1.266779904, Training Accuracy: 63.544\n",
            "Worker 2, [13/37]: Training Loss: 1.245629382, Training Accuracy: 64.096\n",
            "Worker 2, [14/37]: Training Loss: 1.157125693, Training Accuracy: 66.560\n",
            "Worker 2, [15/37]: Training Loss: 1.096965706, Training Accuracy: 68.184\n",
            "Worker 2, [16/37]: Training Loss: 1.050872061, Training Accuracy: 68.960\n",
            "Worker 2, [17/37]: Training Loss: 0.987108141, Training Accuracy: 71.024\n",
            "Worker 2, [18/37]: Training Loss: 0.913056676, Training Accuracy: 72.648\n",
            "Worker 2, [19/37]: Training Loss: 0.863162181, Training Accuracy: 73.936\n",
            "Worker 2, [20/37]: Training Loss: 0.792656334, Training Accuracy: 76.408\n",
            "Worker 2, [21/37]: Training Loss: 0.725640929, Training Accuracy: 78.328\n",
            "Worker 2, [22/37]: Training Loss: 0.677342906, Training Accuracy: 79.424\n",
            "Worker 2, [23/37]: Training Loss: 0.603589535, Training Accuracy: 81.776\n",
            "Worker 2, [24/37]: Training Loss: 0.567769679, Training Accuracy: 83.176\n",
            "Worker 2, [25/37]: Training Loss: 0.510741225, Training Accuracy: 85.168\n",
            "Worker 2, [26/37]: Training Loss: 0.457030147, Training Accuracy: 86.440\n",
            "Worker 2, [27/37]: Training Loss: 0.429199458, Training Accuracy: 87.216\n",
            "Worker 2, [28/37]: Training Loss: 0.408567188, Training Accuracy: 88.144\n",
            "Worker 2, [29/37]: Training Loss: 0.364207965, Training Accuracy: 89.632\n",
            "Worker 2, [30/37]: Training Loss: 0.351097877, Training Accuracy: 90.008\n",
            "Worker 2, [31/37]: Training Loss: 0.340006627, Training Accuracy: 90.448\n",
            "Worker 2, [32/37]: Training Loss: 0.313436238, Training Accuracy: 91.144\n",
            "Worker 2, [33/37]: Training Loss: 0.317666619, Training Accuracy: 91.160\n",
            "Worker 2, [34/37]: Training Loss: 0.288249686, Training Accuracy: 92.024\n",
            "Worker 2, [35/37]: Training Loss: 0.286040355, Training Accuracy: 92.128\n",
            "Worker 2, [36/37]: Training Loss: 0.286001014, Training Accuracy: 92.408\n",
            "Worker 2, [37/37]: Training Loss: 0.283247613, Training Accuracy: 92.104\n",
            "Time taken for training worker 2: 0:03:09.135836\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.656643990, Training Accuracy: 34.512\n",
            "Worker 3, [02/37]: Training Loss: 2.186674959, Training Accuracy: 42.520\n",
            "Worker 3, [03/37]: Training Loss: 2.012545600, Training Accuracy: 46.080\n",
            "Worker 3, [04/37]: Training Loss: 1.873628697, Training Accuracy: 48.912\n",
            "Worker 3, [05/37]: Training Loss: 1.777727513, Training Accuracy: 51.280\n",
            "Worker 3, [06/37]: Training Loss: 1.696294398, Training Accuracy: 53.320\n",
            "Worker 3, [07/37]: Training Loss: 1.591733867, Training Accuracy: 55.328\n",
            "Worker 3, [08/37]: Training Loss: 1.509658498, Training Accuracy: 57.464\n",
            "Worker 3, [09/37]: Training Loss: 1.448428053, Training Accuracy: 58.848\n",
            "Worker 3, [10/37]: Training Loss: 1.378373433, Training Accuracy: 60.032\n",
            "Worker 3, [11/37]: Training Loss: 1.313744445, Training Accuracy: 62.416\n",
            "Worker 3, [12/37]: Training Loss: 1.250976529, Training Accuracy: 63.672\n",
            "Worker 3, [13/37]: Training Loss: 1.174678893, Training Accuracy: 65.968\n",
            "Worker 3, [14/37]: Training Loss: 1.133357418, Training Accuracy: 66.680\n",
            "Worker 3, [15/37]: Training Loss: 1.064959975, Training Accuracy: 68.616\n",
            "Worker 3, [16/37]: Training Loss: 0.984501975, Training Accuracy: 70.840\n",
            "Worker 3, [17/37]: Training Loss: 0.931971462, Training Accuracy: 72.320\n",
            "Worker 3, [18/37]: Training Loss: 0.868552088, Training Accuracy: 74.352\n",
            "Worker 3, [19/37]: Training Loss: 0.789443458, Training Accuracy: 76.552\n",
            "Worker 3, [20/37]: Training Loss: 0.743055074, Training Accuracy: 77.776\n",
            "Worker 3, [21/37]: Training Loss: 0.684856538, Training Accuracy: 79.288\n",
            "Worker 3, [22/37]: Training Loss: 0.645172181, Training Accuracy: 80.280\n",
            "Worker 3, [23/37]: Training Loss: 0.586895776, Training Accuracy: 82.720\n",
            "Worker 3, [24/37]: Training Loss: 0.541556119, Training Accuracy: 83.632\n",
            "Worker 3, [25/37]: Training Loss: 0.480769538, Training Accuracy: 85.832\n",
            "Worker 3, [26/37]: Training Loss: 0.450073940, Training Accuracy: 86.816\n",
            "Worker 3, [27/37]: Training Loss: 0.398943231, Training Accuracy: 88.568\n",
            "Worker 3, [28/37]: Training Loss: 0.388368707, Training Accuracy: 89.208\n",
            "Worker 3, [29/37]: Training Loss: 0.345060970, Training Accuracy: 90.096\n",
            "Worker 3, [30/37]: Training Loss: 0.323822354, Training Accuracy: 90.720\n",
            "Worker 3, [31/37]: Training Loss: 0.320342052, Training Accuracy: 91.064\n",
            "Worker 3, [32/37]: Training Loss: 0.289748541, Training Accuracy: 91.952\n",
            "Worker 3, [33/37]: Training Loss: 0.282157169, Training Accuracy: 92.376\n",
            "Worker 3, [34/37]: Training Loss: 0.273411275, Training Accuracy: 92.624\n",
            "Worker 3, [35/37]: Training Loss: 0.270091738, Training Accuracy: 92.552\n",
            "Worker 3, [36/37]: Training Loss: 0.264479625, Training Accuracy: 93.000\n",
            "Worker 3, [37/37]: Training Loss: 0.256721584, Training Accuracy: 93.120\n",
            "Time taken for training worker 3: 0:03:08.244429\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 2.599719161, Training Accuracy: 36.640\n",
            "Worker 4, [02/37]: Training Loss: 2.151145707, Training Accuracy: 43.896\n",
            "Worker 4, [03/37]: Training Loss: 1.962607552, Training Accuracy: 47.416\n",
            "Worker 4, [04/37]: Training Loss: 1.846509167, Training Accuracy: 49.360\n",
            "Worker 4, [05/37]: Training Loss: 1.732013285, Training Accuracy: 52.928\n",
            "Worker 4, [06/37]: Training Loss: 1.641067425, Training Accuracy: 54.320\n",
            "Worker 4, [07/37]: Training Loss: 1.552805668, Training Accuracy: 56.656\n",
            "Worker 4, [08/37]: Training Loss: 1.486125101, Training Accuracy: 57.704\n",
            "Worker 4, [09/37]: Training Loss: 1.424804510, Training Accuracy: 60.136\n",
            "Worker 4, [10/37]: Training Loss: 1.354782712, Training Accuracy: 61.584\n",
            "Worker 4, [11/37]: Training Loss: 1.292994752, Training Accuracy: 63.048\n",
            "Worker 4, [12/37]: Training Loss: 1.248229877, Training Accuracy: 64.568\n",
            "Worker 4, [13/37]: Training Loss: 1.140061333, Training Accuracy: 67.064\n",
            "Worker 4, [14/37]: Training Loss: 1.087572510, Training Accuracy: 67.816\n",
            "Worker 4, [15/37]: Training Loss: 1.018291833, Training Accuracy: 70.160\n",
            "Worker 4, [16/37]: Training Loss: 0.961036443, Training Accuracy: 71.656\n",
            "Worker 4, [17/37]: Training Loss: 0.881845777, Training Accuracy: 73.968\n",
            "Worker 4, [18/37]: Training Loss: 0.861368975, Training Accuracy: 74.312\n",
            "Worker 4, [19/37]: Training Loss: 0.777214412, Training Accuracy: 76.920\n",
            "Worker 4, [20/37]: Training Loss: 0.726821569, Training Accuracy: 78.312\n",
            "Worker 4, [21/37]: Training Loss: 0.669842421, Training Accuracy: 80.296\n",
            "Worker 4, [22/37]: Training Loss: 0.598488902, Training Accuracy: 81.760\n",
            "Worker 4, [23/37]: Training Loss: 0.556676668, Training Accuracy: 83.224\n",
            "Worker 4, [24/37]: Training Loss: 0.518778874, Training Accuracy: 84.576\n",
            "Worker 4, [25/37]: Training Loss: 0.471724504, Training Accuracy: 86.064\n",
            "Worker 4, [26/37]: Training Loss: 0.424745610, Training Accuracy: 87.184\n",
            "Worker 4, [27/37]: Training Loss: 0.402417083, Training Accuracy: 88.176\n",
            "Worker 4, [28/37]: Training Loss: 0.363333940, Training Accuracy: 89.200\n",
            "Worker 4, [29/37]: Training Loss: 0.334842907, Training Accuracy: 90.592\n",
            "Worker 4, [30/37]: Training Loss: 0.315152310, Training Accuracy: 91.112\n",
            "Worker 4, [31/37]: Training Loss: 0.306714634, Training Accuracy: 91.272\n",
            "Worker 4, [32/37]: Training Loss: 0.293119307, Training Accuracy: 91.672\n",
            "Worker 4, [33/37]: Training Loss: 0.268602003, Training Accuracy: 92.648\n",
            "Worker 4, [34/37]: Training Loss: 0.268139068, Training Accuracy: 92.672\n",
            "Worker 4, [35/37]: Training Loss: 0.255951284, Training Accuracy: 93.168\n",
            "Worker 4, [36/37]: Training Loss: 0.258172760, Training Accuracy: 92.856\n",
            "Worker 4, [37/37]: Training Loss: 0.250630382, Training Accuracy: 93.312\n",
            "Time taken for training worker 4: 0:03:08.771176\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000588\n",
            "Local Step 03: Test Loss: 2.777041115, Test Accuracy: 48.150\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.810245500, Training Accuracy: 46.088\n",
            "Worker 1, [02/37]: Training Loss: 2.746679434, Training Accuracy: 45.680\n",
            "Worker 1, [03/37]: Training Loss: 2.619624106, Training Accuracy: 46.336\n",
            "Worker 1, [04/37]: Training Loss: 2.379580093, Training Accuracy: 46.288\n",
            "Worker 1, [05/37]: Training Loss: 2.216299311, Training Accuracy: 46.360\n",
            "Worker 1, [06/37]: Training Loss: 2.067536779, Training Accuracy: 48.496\n",
            "Worker 1, [07/37]: Training Loss: 1.982864250, Training Accuracy: 48.712\n",
            "Worker 1, [08/37]: Training Loss: 1.893064680, Training Accuracy: 50.632\n",
            "Worker 1, [09/37]: Training Loss: 1.802541811, Training Accuracy: 52.360\n",
            "Worker 1, [10/37]: Training Loss: 1.727771081, Training Accuracy: 53.136\n",
            "Worker 1, [11/37]: Training Loss: 1.650172625, Training Accuracy: 55.400\n",
            "Worker 1, [12/37]: Training Loss: 1.580930415, Training Accuracy: 56.992\n",
            "Worker 1, [13/37]: Training Loss: 1.520910244, Training Accuracy: 58.024\n",
            "Worker 1, [14/37]: Training Loss: 1.468284362, Training Accuracy: 59.328\n",
            "Worker 1, [15/37]: Training Loss: 1.402674661, Training Accuracy: 60.824\n",
            "Worker 1, [16/37]: Training Loss: 1.354154846, Training Accuracy: 61.656\n",
            "Worker 1, [17/37]: Training Loss: 1.318768542, Training Accuracy: 62.648\n",
            "Worker 1, [18/37]: Training Loss: 1.306773973, Training Accuracy: 62.632\n",
            "Worker 1, [19/37]: Training Loss: 1.260176175, Training Accuracy: 63.776\n",
            "Worker 1, [20/37]: Training Loss: 1.236196163, Training Accuracy: 64.288\n",
            "Worker 1, [21/37]: Training Loss: 1.207822063, Training Accuracy: 64.792\n",
            "Worker 1, [22/37]: Training Loss: 1.200812225, Training Accuracy: 64.840\n",
            "Worker 1, [23/37]: Training Loss: 1.219014137, Training Accuracy: 64.392\n",
            "Worker 1, [24/37]: Training Loss: 1.242412333, Training Accuracy: 64.288\n",
            "Worker 1, [25/37]: Training Loss: 1.194545591, Training Accuracy: 65.152\n",
            "Worker 1, [26/37]: Training Loss: 1.201913225, Training Accuracy: 65.024\n",
            "Worker 1, [27/37]: Training Loss: 1.224108028, Training Accuracy: 64.264\n",
            "Worker 1, [28/37]: Training Loss: 1.212493938, Training Accuracy: 64.408\n",
            "Worker 1, [29/37]: Training Loss: 1.217533758, Training Accuracy: 64.888\n",
            "Worker 1, [30/37]: Training Loss: 1.205611030, Training Accuracy: 64.904\n",
            "Worker 1, [31/37]: Training Loss: 1.185890676, Training Accuracy: 65.296\n",
            "Worker 1, [32/37]: Training Loss: 1.213113998, Training Accuracy: 64.656\n",
            "Worker 1, [33/37]: Training Loss: 1.206593923, Training Accuracy: 64.904\n",
            "Worker 1, [34/37]: Training Loss: 1.194240052, Training Accuracy: 64.880\n",
            "Worker 1, [35/37]: Training Loss: 1.160063788, Training Accuracy: 66.344\n",
            "Worker 1, [36/37]: Training Loss: 1.179779418, Training Accuracy: 65.368\n",
            "Worker 1, [37/37]: Training Loss: 1.212187373, Training Accuracy: 64.672\n",
            "Time taken for training worker 1: 0:03:07.837095\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.772467829, Training Accuracy: 37.616\n",
            "Worker 2, [02/37]: Training Loss: 2.727902883, Training Accuracy: 38.000\n",
            "Worker 2, [03/37]: Training Loss: 2.559128566, Training Accuracy: 40.000\n",
            "Worker 2, [04/37]: Training Loss: 2.426975700, Training Accuracy: 41.248\n",
            "Worker 2, [05/37]: Training Loss: 2.288646152, Training Accuracy: 43.208\n",
            "Worker 2, [06/37]: Training Loss: 2.205646712, Training Accuracy: 44.080\n",
            "Worker 2, [07/37]: Training Loss: 2.115204379, Training Accuracy: 46.016\n",
            "Worker 2, [08/37]: Training Loss: 2.025193503, Training Accuracy: 47.752\n",
            "Worker 2, [09/37]: Training Loss: 1.961440940, Training Accuracy: 48.696\n",
            "Worker 2, [10/37]: Training Loss: 1.838237127, Training Accuracy: 50.944\n",
            "Worker 2, [11/37]: Training Loss: 1.792096438, Training Accuracy: 51.760\n",
            "Worker 2, [12/37]: Training Loss: 1.703263799, Training Accuracy: 53.792\n",
            "Worker 2, [13/37]: Training Loss: 1.645503859, Training Accuracy: 55.472\n",
            "Worker 2, [14/37]: Training Loss: 1.570664816, Training Accuracy: 56.616\n",
            "Worker 2, [15/37]: Training Loss: 1.499070126, Training Accuracy: 58.304\n",
            "Worker 2, [16/37]: Training Loss: 1.441572357, Training Accuracy: 59.224\n",
            "Worker 2, [17/37]: Training Loss: 1.389544345, Training Accuracy: 61.096\n",
            "Worker 2, [18/37]: Training Loss: 1.362447466, Training Accuracy: 61.408\n",
            "Worker 2, [19/37]: Training Loss: 1.307533592, Training Accuracy: 62.712\n",
            "Worker 2, [20/37]: Training Loss: 1.287299268, Training Accuracy: 63.024\n",
            "Worker 2, [21/37]: Training Loss: 1.250680219, Training Accuracy: 64.408\n",
            "Worker 2, [22/37]: Training Loss: 1.228678911, Training Accuracy: 64.240\n",
            "Worker 2, [23/37]: Training Loss: 1.232445763, Training Accuracy: 64.352\n",
            "Worker 2, [24/37]: Training Loss: 1.191670456, Training Accuracy: 64.544\n",
            "Worker 2, [25/37]: Training Loss: 1.211692781, Training Accuracy: 64.608\n",
            "Worker 2, [26/37]: Training Loss: 1.202363099, Training Accuracy: 65.104\n",
            "Worker 2, [27/37]: Training Loss: 1.222126010, Training Accuracy: 64.648\n",
            "Worker 2, [28/37]: Training Loss: 1.218555873, Training Accuracy: 64.424\n",
            "Worker 2, [29/37]: Training Loss: 1.209347656, Training Accuracy: 64.856\n",
            "Worker 2, [30/37]: Training Loss: 1.217704543, Training Accuracy: 64.648\n",
            "Worker 2, [31/37]: Training Loss: 1.224874246, Training Accuracy: 64.432\n",
            "Worker 2, [32/37]: Training Loss: 1.177857832, Training Accuracy: 65.264\n",
            "Worker 2, [33/37]: Training Loss: 1.190436548, Training Accuracy: 65.032\n",
            "Worker 2, [34/37]: Training Loss: 1.195377701, Training Accuracy: 65.160\n",
            "Worker 2, [35/37]: Training Loss: 1.218401427, Training Accuracy: 64.568\n",
            "Worker 2, [36/37]: Training Loss: 1.186636239, Training Accuracy: 65.984\n",
            "Worker 2, [37/37]: Training Loss: 1.158110777, Training Accuracy: 66.080\n",
            "Time taken for training worker 2: 0:03:05.981086\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.862629431, Training Accuracy: 38.160\n",
            "Worker 3, [02/37]: Training Loss: 2.762251085, Training Accuracy: 39.056\n",
            "Worker 3, [03/37]: Training Loss: 2.570585757, Training Accuracy: 40.496\n",
            "Worker 3, [04/37]: Training Loss: 2.402533837, Training Accuracy: 42.064\n",
            "Worker 3, [05/37]: Training Loss: 2.289262395, Training Accuracy: 43.056\n",
            "Worker 3, [06/37]: Training Loss: 2.199647243, Training Accuracy: 44.896\n",
            "Worker 3, [07/37]: Training Loss: 2.108877510, Training Accuracy: 45.704\n",
            "Worker 3, [08/37]: Training Loss: 1.995436016, Training Accuracy: 47.664\n",
            "Worker 3, [09/37]: Training Loss: 1.930343502, Training Accuracy: 49.128\n",
            "Worker 3, [10/37]: Training Loss: 1.866626556, Training Accuracy: 50.304\n",
            "Worker 3, [11/37]: Training Loss: 1.763193985, Training Accuracy: 52.496\n",
            "Worker 3, [12/37]: Training Loss: 1.680585217, Training Accuracy: 54.008\n",
            "Worker 3, [13/37]: Training Loss: 1.621628566, Training Accuracy: 55.480\n",
            "Worker 3, [14/37]: Training Loss: 1.553121958, Training Accuracy: 56.664\n",
            "Worker 3, [15/37]: Training Loss: 1.493557689, Training Accuracy: 58.056\n",
            "Worker 3, [16/37]: Training Loss: 1.433570573, Training Accuracy: 59.984\n",
            "Worker 3, [17/37]: Training Loss: 1.354670446, Training Accuracy: 61.128\n",
            "Worker 3, [18/37]: Training Loss: 1.339420331, Training Accuracy: 62.192\n",
            "Worker 3, [19/37]: Training Loss: 1.317600956, Training Accuracy: 62.424\n",
            "Worker 3, [20/37]: Training Loss: 1.266003517, Training Accuracy: 63.344\n",
            "Worker 3, [21/37]: Training Loss: 1.244788792, Training Accuracy: 64.288\n",
            "Worker 3, [22/37]: Training Loss: 1.236632621, Training Accuracy: 63.888\n",
            "Worker 3, [23/37]: Training Loss: 1.214917147, Training Accuracy: 64.536\n",
            "Worker 3, [24/37]: Training Loss: 1.190744312, Training Accuracy: 65.352\n",
            "Worker 3, [25/37]: Training Loss: 1.173558626, Training Accuracy: 65.600\n",
            "Worker 3, [26/37]: Training Loss: 1.209632545, Training Accuracy: 64.704\n",
            "Worker 3, [27/37]: Training Loss: 1.180177438, Training Accuracy: 65.792\n",
            "Worker 3, [28/37]: Training Loss: 1.176468304, Training Accuracy: 65.664\n",
            "Worker 3, [29/37]: Training Loss: 1.184996195, Training Accuracy: 65.088\n",
            "Worker 3, [30/37]: Training Loss: 1.181434631, Training Accuracy: 65.336\n",
            "Worker 3, [31/37]: Training Loss: 1.164265783, Training Accuracy: 65.344\n",
            "Worker 3, [32/37]: Training Loss: 1.175367185, Training Accuracy: 65.672\n",
            "Worker 3, [33/37]: Training Loss: 1.210498760, Training Accuracy: 65.000\n",
            "Worker 3, [34/37]: Training Loss: 1.181913917, Training Accuracy: 65.224\n",
            "Worker 3, [35/37]: Training Loss: 1.192892768, Training Accuracy: 65.336\n",
            "Worker 3, [36/37]: Training Loss: 1.165741115, Training Accuracy: 66.208\n",
            "Worker 3, [37/37]: Training Loss: 1.133479762, Training Accuracy: 66.672\n",
            "Time taken for training worker 3: 0:03:06.339593\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 2.717028217, Training Accuracy: 39.128\n",
            "Worker 4, [02/37]: Training Loss: 2.696917781, Training Accuracy: 39.744\n",
            "Worker 4, [03/37]: Training Loss: 2.510436047, Training Accuracy: 41.496\n",
            "Worker 4, [04/37]: Training Loss: 2.370716810, Training Accuracy: 42.792\n",
            "Worker 4, [05/37]: Training Loss: 2.258909678, Training Accuracy: 43.928\n",
            "Worker 4, [06/37]: Training Loss: 2.140817013, Training Accuracy: 45.552\n",
            "Worker 4, [07/37]: Training Loss: 2.048027007, Training Accuracy: 47.128\n",
            "Worker 4, [08/37]: Training Loss: 1.975643659, Training Accuracy: 48.728\n",
            "Worker 4, [09/37]: Training Loss: 1.886883799, Training Accuracy: 50.312\n",
            "Worker 4, [10/37]: Training Loss: 1.815151358, Training Accuracy: 51.384\n",
            "Worker 4, [11/37]: Training Loss: 1.730451229, Training Accuracy: 53.448\n",
            "Worker 4, [12/37]: Training Loss: 1.657250384, Training Accuracy: 54.984\n",
            "Worker 4, [13/37]: Training Loss: 1.594698987, Training Accuracy: 56.056\n",
            "Worker 4, [14/37]: Training Loss: 1.527572846, Training Accuracy: 58.192\n",
            "Worker 4, [15/37]: Training Loss: 1.452932918, Training Accuracy: 59.632\n",
            "Worker 4, [16/37]: Training Loss: 1.388819194, Training Accuracy: 60.816\n",
            "Worker 4, [17/37]: Training Loss: 1.368136808, Training Accuracy: 61.040\n",
            "Worker 4, [18/37]: Training Loss: 1.293962777, Training Accuracy: 63.720\n",
            "Worker 4, [19/37]: Training Loss: 1.246926602, Training Accuracy: 64.264\n",
            "Worker 4, [20/37]: Training Loss: 1.242591859, Training Accuracy: 64.456\n",
            "Worker 4, [21/37]: Training Loss: 1.196795705, Training Accuracy: 65.216\n",
            "Worker 4, [22/37]: Training Loss: 1.178720620, Training Accuracy: 65.552\n",
            "Worker 4, [23/37]: Training Loss: 1.173390461, Training Accuracy: 65.800\n",
            "Worker 4, [24/37]: Training Loss: 1.172262380, Training Accuracy: 65.832\n",
            "Worker 4, [25/37]: Training Loss: 1.162520559, Training Accuracy: 65.944\n",
            "Worker 4, [26/37]: Training Loss: 1.170244359, Training Accuracy: 65.552\n",
            "Worker 4, [27/37]: Training Loss: 1.161405823, Training Accuracy: 66.240\n",
            "Worker 4, [28/37]: Training Loss: 1.149089338, Training Accuracy: 66.272\n",
            "Worker 4, [29/37]: Training Loss: 1.142137871, Training Accuracy: 66.168\n",
            "Worker 4, [30/37]: Training Loss: 1.183346565, Training Accuracy: 65.720\n",
            "Worker 4, [31/37]: Training Loss: 1.145272663, Training Accuracy: 66.904\n",
            "Worker 4, [32/37]: Training Loss: 1.138752054, Training Accuracy: 66.792\n",
            "Worker 4, [33/37]: Training Loss: 1.137032406, Training Accuracy: 66.448\n",
            "Worker 4, [34/37]: Training Loss: 1.124351611, Training Accuracy: 67.352\n",
            "Worker 4, [35/37]: Training Loss: 1.163812460, Training Accuracy: 66.760\n",
            "Worker 4, [36/37]: Training Loss: 1.124562667, Training Accuracy: 67.264\n",
            "Worker 4, [37/37]: Training Loss: 1.093363165, Training Accuracy: 68.088\n",
            "Time taken for training worker 4: 0:03:19.617330\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000629\n",
            "Local Step 04: Test Loss: 2.670036790, Test Accuracy: 41.020\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:49:59.998077\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.528700303, Training Accuracy: 2.344\n",
            "Worker 1, [02/18]: Training Loss: 4.141531103, Training Accuracy: 6.232\n",
            "Worker 1, [03/18]: Training Loss: 3.929015359, Training Accuracy: 8.928\n",
            "Worker 1, [04/18]: Training Loss: 3.758738638, Training Accuracy: 11.544\n",
            "Worker 1, [05/18]: Training Loss: 3.634474713, Training Accuracy: 13.512\n",
            "Worker 1, [06/18]: Training Loss: 3.499566421, Training Accuracy: 16.176\n",
            "Worker 1, [07/18]: Training Loss: 3.376260573, Training Accuracy: 17.600\n",
            "Worker 1, [08/18]: Training Loss: 3.270045766, Training Accuracy: 20.216\n",
            "Worker 1, [09/18]: Training Loss: 3.160704739, Training Accuracy: 22.192\n",
            "Worker 1, [10/18]: Training Loss: 3.069072517, Training Accuracy: 23.592\n",
            "Worker 1, [11/18]: Training Loss: 2.969995517, Training Accuracy: 25.144\n",
            "Worker 1, [12/18]: Training Loss: 2.876394835, Training Accuracy: 27.288\n",
            "Worker 1, [13/18]: Training Loss: 2.782062781, Training Accuracy: 29.448\n",
            "Worker 1, [14/18]: Training Loss: 2.723820674, Training Accuracy: 30.688\n",
            "Worker 1, [15/18]: Training Loss: 2.645186626, Training Accuracy: 32.040\n",
            "Worker 1, [16/18]: Training Loss: 2.606397821, Training Accuracy: 33.328\n",
            "Worker 1, [17/18]: Training Loss: 2.561499535, Training Accuracy: 34.544\n",
            "Worker 1, [18/18]: Training Loss: 2.535257858, Training Accuracy: 34.536\n",
            "Time taken for training worker 1: 0:01:36.386161\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.530163281, Training Accuracy: 2.600\n",
            "Worker 2, [02/18]: Training Loss: 4.149868723, Training Accuracy: 6.248\n",
            "Worker 2, [03/18]: Training Loss: 3.951935168, Training Accuracy: 9.216\n",
            "Worker 2, [04/18]: Training Loss: 3.787024133, Training Accuracy: 11.472\n",
            "Worker 2, [05/18]: Training Loss: 3.637793635, Training Accuracy: 13.976\n",
            "Worker 2, [06/18]: Training Loss: 3.517433267, Training Accuracy: 15.936\n",
            "Worker 2, [07/18]: Training Loss: 3.392324679, Training Accuracy: 17.752\n",
            "Worker 2, [08/18]: Training Loss: 3.276865690, Training Accuracy: 19.704\n",
            "Worker 2, [09/18]: Training Loss: 3.165091124, Training Accuracy: 22.336\n",
            "Worker 2, [10/18]: Training Loss: 3.073454993, Training Accuracy: 23.568\n",
            "Worker 2, [11/18]: Training Loss: 2.972624969, Training Accuracy: 25.720\n",
            "Worker 2, [12/18]: Training Loss: 2.903031658, Training Accuracy: 27.032\n",
            "Worker 2, [13/18]: Training Loss: 2.801722446, Training Accuracy: 28.856\n",
            "Worker 2, [14/18]: Training Loss: 2.732187997, Training Accuracy: 30.600\n",
            "Worker 2, [15/18]: Training Loss: 2.660609411, Training Accuracy: 31.984\n",
            "Worker 2, [16/18]: Training Loss: 2.604246517, Training Accuracy: 33.376\n",
            "Worker 2, [17/18]: Training Loss: 2.559567342, Training Accuracy: 33.944\n",
            "Worker 2, [18/18]: Training Loss: 2.541737397, Training Accuracy: 34.112\n",
            "Time taken for training worker 2: 0:01:35.928503\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.529371816, Training Accuracy: 2.128\n",
            "Worker 3, [02/18]: Training Loss: 4.146822943, Training Accuracy: 6.016\n",
            "Worker 3, [03/18]: Training Loss: 3.928933332, Training Accuracy: 8.800\n",
            "Worker 3, [04/18]: Training Loss: 3.770457214, Training Accuracy: 11.424\n",
            "Worker 3, [05/18]: Training Loss: 3.641730414, Training Accuracy: 13.552\n",
            "Worker 3, [06/18]: Training Loss: 3.487770373, Training Accuracy: 16.072\n",
            "Worker 3, [07/18]: Training Loss: 3.389170804, Training Accuracy: 17.408\n",
            "Worker 3, [08/18]: Training Loss: 3.260205944, Training Accuracy: 19.824\n",
            "Worker 3, [09/18]: Training Loss: 3.175211868, Training Accuracy: 21.240\n",
            "Worker 3, [10/18]: Training Loss: 3.068469377, Training Accuracy: 23.536\n",
            "Worker 3, [11/18]: Training Loss: 2.969359622, Training Accuracy: 25.400\n",
            "Worker 3, [12/18]: Training Loss: 2.897644790, Training Accuracy: 26.816\n",
            "Worker 3, [13/18]: Training Loss: 2.798946226, Training Accuracy: 28.168\n",
            "Worker 3, [14/18]: Training Loss: 2.731797601, Training Accuracy: 30.288\n",
            "Worker 3, [15/18]: Training Loss: 2.661030803, Training Accuracy: 31.768\n",
            "Worker 3, [16/18]: Training Loss: 2.607520796, Training Accuracy: 32.880\n",
            "Worker 3, [17/18]: Training Loss: 2.580430821, Training Accuracy: 33.632\n",
            "Worker 3, [18/18]: Training Loss: 2.540003384, Training Accuracy: 34.344\n",
            "Time taken for training worker 3: 0:01:37.297518\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.521782104, Training Accuracy: 2.208\n",
            "Worker 4, [02/18]: Training Loss: 4.138783926, Training Accuracy: 6.544\n",
            "Worker 4, [03/18]: Training Loss: 3.921525162, Training Accuracy: 8.880\n",
            "Worker 4, [04/18]: Training Loss: 3.767480158, Training Accuracy: 11.264\n",
            "Worker 4, [05/18]: Training Loss: 3.622565632, Training Accuracy: 13.840\n",
            "Worker 4, [06/18]: Training Loss: 3.471356846, Training Accuracy: 16.904\n",
            "Worker 4, [07/18]: Training Loss: 3.367857400, Training Accuracy: 18.328\n",
            "Worker 4, [08/18]: Training Loss: 3.230024541, Training Accuracy: 20.856\n",
            "Worker 4, [09/18]: Training Loss: 3.133282130, Training Accuracy: 22.192\n",
            "Worker 4, [10/18]: Training Loss: 3.028468302, Training Accuracy: 24.432\n",
            "Worker 4, [11/18]: Training Loss: 2.932483884, Training Accuracy: 25.976\n",
            "Worker 4, [12/18]: Training Loss: 2.839138411, Training Accuracy: 28.232\n",
            "Worker 4, [13/18]: Training Loss: 2.756389569, Training Accuracy: 29.976\n",
            "Worker 4, [14/18]: Training Loss: 2.684769695, Training Accuracy: 31.216\n",
            "Worker 4, [15/18]: Training Loss: 2.607976320, Training Accuracy: 33.112\n",
            "Worker 4, [16/18]: Training Loss: 2.555502257, Training Accuracy: 33.448\n",
            "Worker 4, [17/18]: Training Loss: 2.517645233, Training Accuracy: 34.704\n",
            "Worker 4, [18/18]: Training Loss: 2.485965299, Training Accuracy: 36.024\n",
            "Time taken for training worker 4: 0:01:41.567117\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000672\n",
            "Local Step 01: Test Loss: 3.066464260, Test Accuracy: 26.550\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.143375809, Training Accuracy: 24.632\n",
            "Worker 1, [02/18]: Training Loss: 3.086487370, Training Accuracy: 25.184\n",
            "Worker 1, [03/18]: Training Loss: 3.008687225, Training Accuracy: 25.832\n",
            "Worker 1, [04/18]: Training Loss: 2.954879869, Training Accuracy: 26.848\n",
            "Worker 1, [05/18]: Training Loss: 2.928180521, Training Accuracy: 26.904\n",
            "Worker 1, [06/18]: Training Loss: 2.908180670, Training Accuracy: 27.128\n",
            "Worker 1, [07/18]: Training Loss: 2.905498809, Training Accuracy: 27.240\n",
            "Worker 1, [08/18]: Training Loss: 2.889076451, Training Accuracy: 27.408\n",
            "Worker 1, [09/18]: Training Loss: 2.875018279, Training Accuracy: 27.912\n",
            "Worker 1, [10/18]: Training Loss: 2.852743599, Training Accuracy: 27.488\n",
            "Worker 1, [11/18]: Training Loss: 2.827119479, Training Accuracy: 28.440\n",
            "Worker 1, [12/18]: Training Loss: 2.808304397, Training Accuracy: 28.760\n",
            "Worker 1, [13/18]: Training Loss: 2.739558303, Training Accuracy: 30.112\n",
            "Worker 1, [14/18]: Training Loss: 2.723390053, Training Accuracy: 30.616\n",
            "Worker 1, [15/18]: Training Loss: 2.685864422, Training Accuracy: 31.336\n",
            "Worker 1, [16/18]: Training Loss: 2.631662375, Training Accuracy: 32.208\n",
            "Worker 1, [17/18]: Training Loss: 2.580604312, Training Accuracy: 33.216\n",
            "Worker 1, [18/18]: Training Loss: 2.524980610, Training Accuracy: 33.752\n",
            "Time taken for training worker 1: 0:01:36.950135\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.870823812, Training Accuracy: 28.392\n",
            "Worker 2, [02/18]: Training Loss: 2.803499106, Training Accuracy: 30.216\n",
            "Worker 2, [03/18]: Training Loss: 2.728378067, Training Accuracy: 31.520\n",
            "Worker 2, [04/18]: Training Loss: 2.659020947, Training Accuracy: 33.040\n",
            "Worker 2, [05/18]: Training Loss: 2.578066281, Training Accuracy: 34.480\n",
            "Worker 2, [06/18]: Training Loss: 2.530425926, Training Accuracy: 34.992\n",
            "Worker 2, [07/18]: Training Loss: 2.492665521, Training Accuracy: 36.040\n",
            "Worker 2, [08/18]: Training Loss: 2.447972424, Training Accuracy: 36.376\n",
            "Worker 2, [09/18]: Training Loss: 2.432210591, Training Accuracy: 36.728\n",
            "Worker 2, [10/18]: Training Loss: 2.397936447, Training Accuracy: 37.144\n",
            "Worker 2, [11/18]: Training Loss: 2.392786066, Training Accuracy: 37.016\n",
            "Worker 2, [12/18]: Training Loss: 2.355659225, Training Accuracy: 37.840\n",
            "Worker 2, [13/18]: Training Loss: 2.352754176, Training Accuracy: 37.920\n",
            "Worker 2, [14/18]: Training Loss: 2.333817155, Training Accuracy: 38.672\n",
            "Worker 2, [15/18]: Training Loss: 2.290025193, Training Accuracy: 39.232\n",
            "Worker 2, [16/18]: Training Loss: 2.264334770, Training Accuracy: 39.352\n",
            "Worker 2, [17/18]: Training Loss: 2.261746003, Training Accuracy: 40.096\n",
            "Worker 2, [18/18]: Training Loss: 2.218271555, Training Accuracy: 40.792\n",
            "Time taken for training worker 2: 0:01:41.284976\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.716770160, Training Accuracy: 32.664\n",
            "Worker 3, [02/18]: Training Loss: 2.678409811, Training Accuracy: 33.040\n",
            "Worker 3, [03/18]: Training Loss: 2.557612324, Training Accuracy: 35.056\n",
            "Worker 3, [04/18]: Training Loss: 2.466564511, Training Accuracy: 36.608\n",
            "Worker 3, [05/18]: Training Loss: 2.410039069, Training Accuracy: 37.712\n",
            "Worker 3, [06/18]: Training Loss: 2.346066946, Training Accuracy: 39.128\n",
            "Worker 3, [07/18]: Training Loss: 2.308950598, Training Accuracy: 39.904\n",
            "Worker 3, [08/18]: Training Loss: 2.251730153, Training Accuracy: 40.864\n",
            "Worker 3, [09/18]: Training Loss: 2.228884993, Training Accuracy: 41.048\n",
            "Worker 3, [10/18]: Training Loss: 2.201856843, Training Accuracy: 41.664\n",
            "Worker 3, [11/18]: Training Loss: 2.180848218, Training Accuracy: 41.272\n",
            "Worker 3, [12/18]: Training Loss: 2.170907898, Training Accuracy: 41.864\n",
            "Worker 3, [13/18]: Training Loss: 2.143287171, Training Accuracy: 42.448\n",
            "Worker 3, [14/18]: Training Loss: 2.109906651, Training Accuracy: 43.192\n",
            "Worker 3, [15/18]: Training Loss: 2.076937347, Training Accuracy: 43.400\n",
            "Worker 3, [16/18]: Training Loss: 2.096934126, Training Accuracy: 43.160\n",
            "Worker 3, [17/18]: Training Loss: 2.094067873, Training Accuracy: 43.352\n",
            "Worker 3, [18/18]: Training Loss: 2.008908135, Training Accuracy: 45.184\n",
            "Time taken for training worker 3: 0:01:35.575078\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.682183752, Training Accuracy: 33.504\n",
            "Worker 4, [02/18]: Training Loss: 2.576309416, Training Accuracy: 35.352\n",
            "Worker 4, [03/18]: Training Loss: 2.429050173, Training Accuracy: 38.232\n",
            "Worker 4, [04/18]: Training Loss: 2.343229801, Training Accuracy: 39.808\n",
            "Worker 4, [05/18]: Training Loss: 2.285683734, Training Accuracy: 40.800\n",
            "Worker 4, [06/18]: Training Loss: 2.211282029, Training Accuracy: 42.800\n",
            "Worker 4, [07/18]: Training Loss: 2.139979443, Training Accuracy: 43.952\n",
            "Worker 4, [08/18]: Training Loss: 2.099857301, Training Accuracy: 44.592\n",
            "Worker 4, [09/18]: Training Loss: 2.060707066, Training Accuracy: 45.096\n",
            "Worker 4, [10/18]: Training Loss: 2.035493505, Training Accuracy: 45.568\n",
            "Worker 4, [11/18]: Training Loss: 2.015567418, Training Accuracy: 45.960\n",
            "Worker 4, [12/18]: Training Loss: 1.978155652, Training Accuracy: 47.088\n",
            "Worker 4, [13/18]: Training Loss: 1.971109317, Training Accuracy: 46.752\n",
            "Worker 4, [14/18]: Training Loss: 1.970345420, Training Accuracy: 47.120\n",
            "Worker 4, [15/18]: Training Loss: 1.955889952, Training Accuracy: 47.048\n",
            "Worker 4, [16/18]: Training Loss: 1.937635539, Training Accuracy: 47.128\n",
            "Worker 4, [17/18]: Training Loss: 1.911921859, Training Accuracy: 48.224\n",
            "Worker 4, [18/18]: Training Loss: 1.914914848, Training Accuracy: 47.656\n",
            "Time taken for training worker 4: 0:01:36.569037\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000650\n",
            "Local Step 02: Test Loss: 2.499759830, Test Accuracy: 38.460\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.542235865, Training Accuracy: 35.544\n",
            "Worker 1, [02/18]: Training Loss: 2.314340362, Training Accuracy: 39.688\n",
            "Worker 1, [03/18]: Training Loss: 2.164346660, Training Accuracy: 42.856\n",
            "Worker 1, [04/18]: Training Loss: 2.060185030, Training Accuracy: 44.928\n",
            "Worker 1, [05/18]: Training Loss: 1.974378625, Training Accuracy: 46.968\n",
            "Worker 1, [06/18]: Training Loss: 1.874320106, Training Accuracy: 48.584\n",
            "Worker 1, [07/18]: Training Loss: 1.740956778, Training Accuracy: 51.712\n",
            "Worker 1, [08/18]: Training Loss: 1.644516788, Training Accuracy: 54.104\n",
            "Worker 1, [09/18]: Training Loss: 1.546619750, Training Accuracy: 56.856\n",
            "Worker 1, [10/18]: Training Loss: 1.433170842, Training Accuracy: 59.880\n",
            "Worker 1, [11/18]: Training Loss: 1.342771898, Training Accuracy: 62.264\n",
            "Worker 1, [12/18]: Training Loss: 1.245938671, Training Accuracy: 64.248\n",
            "Worker 1, [13/18]: Training Loss: 1.159233293, Training Accuracy: 66.552\n",
            "Worker 1, [14/18]: Training Loss: 1.062418673, Training Accuracy: 68.920\n",
            "Worker 1, [15/18]: Training Loss: 1.010526651, Training Accuracy: 70.984\n",
            "Worker 1, [16/18]: Training Loss: 0.929353319, Training Accuracy: 72.976\n",
            "Worker 1, [17/18]: Training Loss: 0.905799097, Training Accuracy: 74.040\n",
            "Worker 1, [18/18]: Training Loss: 0.896987245, Training Accuracy: 74.808\n",
            "Time taken for training worker 1: 0:01:38.759195\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.516786644, Training Accuracy: 36.552\n",
            "Worker 2, [02/18]: Training Loss: 2.239447586, Training Accuracy: 41.272\n",
            "Worker 2, [03/18]: Training Loss: 2.101332446, Training Accuracy: 44.056\n",
            "Worker 2, [04/18]: Training Loss: 1.983833744, Training Accuracy: 46.400\n",
            "Worker 2, [05/18]: Training Loss: 1.861871250, Training Accuracy: 49.016\n",
            "Worker 2, [06/18]: Training Loss: 1.778114163, Training Accuracy: 50.896\n",
            "Worker 2, [07/18]: Training Loss: 1.649703426, Training Accuracy: 54.368\n",
            "Worker 2, [08/18]: Training Loss: 1.582625606, Training Accuracy: 55.912\n",
            "Worker 2, [09/18]: Training Loss: 1.461996702, Training Accuracy: 58.744\n",
            "Worker 2, [10/18]: Training Loss: 1.349498226, Training Accuracy: 61.368\n",
            "Worker 2, [11/18]: Training Loss: 1.245594652, Training Accuracy: 64.160\n",
            "Worker 2, [12/18]: Training Loss: 1.151385143, Training Accuracy: 67.336\n",
            "Worker 2, [13/18]: Training Loss: 1.053715071, Training Accuracy: 69.640\n",
            "Worker 2, [14/18]: Training Loss: 0.961443292, Training Accuracy: 72.416\n",
            "Worker 2, [15/18]: Training Loss: 0.896852419, Training Accuracy: 74.216\n",
            "Worker 2, [16/18]: Training Loss: 0.844005511, Training Accuracy: 76.000\n",
            "Worker 2, [17/18]: Training Loss: 0.813595476, Training Accuracy: 76.568\n",
            "Worker 2, [18/18]: Training Loss: 0.779922769, Training Accuracy: 77.392\n",
            "Time taken for training worker 2: 0:01:36.795632\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.517139816, Training Accuracy: 35.744\n",
            "Worker 3, [02/18]: Training Loss: 2.158933140, Training Accuracy: 43.112\n",
            "Worker 3, [03/18]: Training Loss: 2.057613220, Training Accuracy: 44.512\n",
            "Worker 3, [04/18]: Training Loss: 1.926018273, Training Accuracy: 47.776\n",
            "Worker 3, [05/18]: Training Loss: 1.799225571, Training Accuracy: 50.784\n",
            "Worker 3, [06/18]: Training Loss: 1.707418285, Training Accuracy: 52.616\n",
            "Worker 3, [07/18]: Training Loss: 1.613901624, Training Accuracy: 54.728\n",
            "Worker 3, [08/18]: Training Loss: 1.475503623, Training Accuracy: 57.648\n",
            "Worker 3, [09/18]: Training Loss: 1.394266758, Training Accuracy: 60.168\n",
            "Worker 3, [10/18]: Training Loss: 1.281262559, Training Accuracy: 62.968\n",
            "Worker 3, [11/18]: Training Loss: 1.182539901, Training Accuracy: 65.304\n",
            "Worker 3, [12/18]: Training Loss: 1.069134513, Training Accuracy: 68.880\n",
            "Worker 3, [13/18]: Training Loss: 0.997315947, Training Accuracy: 70.744\n",
            "Worker 3, [14/18]: Training Loss: 0.917000710, Training Accuracy: 73.464\n",
            "Worker 3, [15/18]: Training Loss: 0.833435964, Training Accuracy: 75.728\n",
            "Worker 3, [16/18]: Training Loss: 0.798374060, Training Accuracy: 76.600\n",
            "Worker 3, [17/18]: Training Loss: 0.759108807, Training Accuracy: 78.264\n",
            "Worker 3, [18/18]: Training Loss: 0.742041775, Training Accuracy: 78.720\n",
            "Time taken for training worker 3: 0:01:38.849608\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.428090120, Training Accuracy: 38.080\n",
            "Worker 4, [02/18]: Training Loss: 2.099144181, Training Accuracy: 44.928\n",
            "Worker 4, [03/18]: Training Loss: 1.961674572, Training Accuracy: 47.576\n",
            "Worker 4, [04/18]: Training Loss: 1.840327797, Training Accuracy: 49.800\n",
            "Worker 4, [05/18]: Training Loss: 1.722041912, Training Accuracy: 52.592\n",
            "Worker 4, [06/18]: Training Loss: 1.649651821, Training Accuracy: 54.336\n",
            "Worker 4, [07/18]: Training Loss: 1.529594285, Training Accuracy: 57.088\n",
            "Worker 4, [08/18]: Training Loss: 1.440308153, Training Accuracy: 59.288\n",
            "Worker 4, [09/18]: Training Loss: 1.317824953, Training Accuracy: 62.216\n",
            "Worker 4, [10/18]: Training Loss: 1.216612753, Training Accuracy: 64.920\n",
            "Worker 4, [11/18]: Training Loss: 1.102555048, Training Accuracy: 68.056\n",
            "Worker 4, [12/18]: Training Loss: 0.999947943, Training Accuracy: 70.952\n",
            "Worker 4, [13/18]: Training Loss: 0.906706379, Training Accuracy: 73.496\n",
            "Worker 4, [14/18]: Training Loss: 0.809746976, Training Accuracy: 76.792\n",
            "Worker 4, [15/18]: Training Loss: 0.777398812, Training Accuracy: 77.656\n",
            "Worker 4, [16/18]: Training Loss: 0.727052123, Training Accuracy: 79.152\n",
            "Worker 4, [17/18]: Training Loss: 0.678773213, Training Accuracy: 80.520\n",
            "Worker 4, [18/18]: Training Loss: 0.667434594, Training Accuracy: 80.824\n",
            "Time taken for training worker 4: 0:01:37.024736\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000827\n",
            "Local Step 03: Test Loss: 2.298510370, Test Accuracy: 48.440\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.288083212, Training Accuracy: 46.880\n",
            "Worker 1, [02/18]: Training Loss: 2.197271643, Training Accuracy: 47.272\n",
            "Worker 1, [03/18]: Training Loss: 2.078849180, Training Accuracy: 47.632\n",
            "Worker 1, [04/18]: Training Loss: 1.979822057, Training Accuracy: 48.040\n",
            "Worker 1, [05/18]: Training Loss: 1.852633312, Training Accuracy: 50.688\n",
            "Worker 1, [06/18]: Training Loss: 1.811601375, Training Accuracy: 51.528\n",
            "Worker 1, [07/18]: Training Loss: 1.735887804, Training Accuracy: 52.768\n",
            "Worker 1, [08/18]: Training Loss: 1.676956199, Training Accuracy: 53.984\n",
            "Worker 1, [09/18]: Training Loss: 1.639640271, Training Accuracy: 54.624\n",
            "Worker 1, [10/18]: Training Loss: 1.593919972, Training Accuracy: 55.672\n",
            "Worker 1, [11/18]: Training Loss: 1.568003638, Training Accuracy: 56.016\n",
            "Worker 1, [12/18]: Training Loss: 1.571516691, Training Accuracy: 56.120\n",
            "Worker 1, [13/18]: Training Loss: 1.536570284, Training Accuracy: 56.720\n",
            "Worker 1, [14/18]: Training Loss: 1.558074185, Training Accuracy: 56.208\n",
            "Worker 1, [15/18]: Training Loss: 1.526522989, Training Accuracy: 56.504\n",
            "Worker 1, [16/18]: Training Loss: 1.589493748, Training Accuracy: 54.944\n",
            "Worker 1, [17/18]: Training Loss: 1.540417188, Training Accuracy: 56.576\n",
            "Worker 1, [18/18]: Training Loss: 1.489644578, Training Accuracy: 57.632\n",
            "Time taken for training worker 1: 0:01:36.634599\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.501202333, Training Accuracy: 40.648\n",
            "Worker 2, [02/18]: Training Loss: 2.337567044, Training Accuracy: 42.216\n",
            "Worker 2, [03/18]: Training Loss: 2.168487405, Training Accuracy: 44.336\n",
            "Worker 2, [04/18]: Training Loss: 2.052646146, Training Accuracy: 46.632\n",
            "Worker 2, [05/18]: Training Loss: 1.935694998, Training Accuracy: 48.576\n",
            "Worker 2, [06/18]: Training Loss: 1.845823736, Training Accuracy: 50.928\n",
            "Worker 2, [07/18]: Training Loss: 1.747263540, Training Accuracy: 52.672\n",
            "Worker 2, [08/18]: Training Loss: 1.691946279, Training Accuracy: 53.768\n",
            "Worker 2, [09/18]: Training Loss: 1.636861664, Training Accuracy: 54.952\n",
            "Worker 2, [10/18]: Training Loss: 1.582004346, Training Accuracy: 55.640\n",
            "Worker 2, [11/18]: Training Loss: 1.577479242, Training Accuracy: 55.920\n",
            "Worker 2, [12/18]: Training Loss: 1.539140646, Training Accuracy: 56.632\n",
            "Worker 2, [13/18]: Training Loss: 1.545486552, Training Accuracy: 56.600\n",
            "Worker 2, [14/18]: Training Loss: 1.531921701, Training Accuracy: 56.928\n",
            "Worker 2, [15/18]: Training Loss: 1.550349274, Training Accuracy: 55.704\n",
            "Worker 2, [16/18]: Training Loss: 1.524392054, Training Accuracy: 56.840\n",
            "Worker 2, [17/18]: Training Loss: 1.533812403, Training Accuracy: 56.784\n",
            "Worker 2, [18/18]: Training Loss: 1.518424839, Training Accuracy: 57.280\n",
            "Time taken for training worker 2: 0:01:36.069716\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.431974270, Training Accuracy: 39.176\n",
            "Worker 3, [02/18]: Training Loss: 2.309001465, Training Accuracy: 41.120\n",
            "Worker 3, [03/18]: Training Loss: 2.147337785, Training Accuracy: 44.064\n",
            "Worker 3, [04/18]: Training Loss: 2.032564029, Training Accuracy: 45.968\n",
            "Worker 3, [05/18]: Training Loss: 1.912975295, Training Accuracy: 48.728\n",
            "Worker 3, [06/18]: Training Loss: 1.819513922, Training Accuracy: 50.744\n",
            "Worker 3, [07/18]: Training Loss: 1.748623578, Training Accuracy: 52.064\n",
            "Worker 3, [08/18]: Training Loss: 1.656995487, Training Accuracy: 54.256\n",
            "Worker 3, [09/18]: Training Loss: 1.613985627, Training Accuracy: 55.200\n",
            "Worker 3, [10/18]: Training Loss: 1.569973823, Training Accuracy: 56.016\n",
            "Worker 3, [11/18]: Training Loss: 1.539261250, Training Accuracy: 56.744\n",
            "Worker 3, [12/18]: Training Loss: 1.517641465, Training Accuracy: 57.136\n",
            "Worker 3, [13/18]: Training Loss: 1.498466168, Training Accuracy: 57.712\n",
            "Worker 3, [14/18]: Training Loss: 1.500761596, Training Accuracy: 57.544\n",
            "Worker 3, [15/18]: Training Loss: 1.504631223, Training Accuracy: 56.976\n",
            "Worker 3, [16/18]: Training Loss: 1.520451529, Training Accuracy: 56.792\n",
            "Worker 3, [17/18]: Training Loss: 1.484012654, Training Accuracy: 58.280\n",
            "Worker 3, [18/18]: Training Loss: 1.471506830, Training Accuracy: 58.384\n",
            "Time taken for training worker 3: 0:01:38.130837\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.373945127, Training Accuracy: 42.072\n",
            "Worker 4, [02/18]: Training Loss: 2.237370829, Training Accuracy: 43.912\n",
            "Worker 4, [03/18]: Training Loss: 2.076066049, Training Accuracy: 46.256\n",
            "Worker 4, [04/18]: Training Loss: 1.981268104, Training Accuracy: 47.800\n",
            "Worker 4, [05/18]: Training Loss: 1.873146191, Training Accuracy: 50.240\n",
            "Worker 4, [06/18]: Training Loss: 1.765724142, Training Accuracy: 52.008\n",
            "Worker 4, [07/18]: Training Loss: 1.686201211, Training Accuracy: 54.056\n",
            "Worker 4, [08/18]: Training Loss: 1.606911542, Training Accuracy: 55.328\n",
            "Worker 4, [09/18]: Training Loss: 1.544660028, Training Accuracy: 56.768\n",
            "Worker 4, [10/18]: Training Loss: 1.497771156, Training Accuracy: 57.624\n",
            "Worker 4, [11/18]: Training Loss: 1.498556795, Training Accuracy: 58.008\n",
            "Worker 4, [12/18]: Training Loss: 1.475615566, Training Accuracy: 58.272\n",
            "Worker 4, [13/18]: Training Loss: 1.438655600, Training Accuracy: 58.792\n",
            "Worker 4, [14/18]: Training Loss: 1.444839230, Training Accuracy: 59.192\n",
            "Worker 4, [15/18]: Training Loss: 1.447629309, Training Accuracy: 59.224\n",
            "Worker 4, [16/18]: Training Loss: 1.454833266, Training Accuracy: 58.528\n",
            "Worker 4, [17/18]: Training Loss: 1.426817222, Training Accuracy: 59.448\n",
            "Worker 4, [18/18]: Training Loss: 1.403357957, Training Accuracy: 60.320\n",
            "Time taken for training worker 4: 0:01:37.059948\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000702\n",
            "Local Step 04: Test Loss: 2.397611376, Test Accuracy: 43.940\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.275809980, Training Accuracy: 41.392\n",
            "Worker 1, [02/18]: Training Loss: 1.949231965, Training Accuracy: 47.656\n",
            "Worker 1, [03/18]: Training Loss: 1.818078583, Training Accuracy: 51.104\n",
            "Worker 1, [04/18]: Training Loss: 1.669311636, Training Accuracy: 53.496\n",
            "Worker 1, [05/18]: Training Loss: 1.558574976, Training Accuracy: 56.152\n",
            "Worker 1, [06/18]: Training Loss: 1.445987564, Training Accuracy: 59.088\n",
            "Worker 1, [07/18]: Training Loss: 1.346549072, Training Accuracy: 61.264\n",
            "Worker 1, [08/18]: Training Loss: 1.242506490, Training Accuracy: 64.392\n",
            "Worker 1, [09/18]: Training Loss: 1.125476223, Training Accuracy: 67.400\n",
            "Worker 1, [10/18]: Training Loss: 1.033806459, Training Accuracy: 69.400\n",
            "Worker 1, [11/18]: Training Loss: 0.923033275, Training Accuracy: 72.720\n",
            "Worker 1, [12/18]: Training Loss: 0.821863976, Training Accuracy: 75.800\n",
            "Worker 1, [13/18]: Training Loss: 0.740047740, Training Accuracy: 78.528\n",
            "Worker 1, [14/18]: Training Loss: 0.672143218, Training Accuracy: 80.072\n",
            "Worker 1, [15/18]: Training Loss: 0.612131056, Training Accuracy: 82.592\n",
            "Worker 1, [16/18]: Training Loss: 0.579978654, Training Accuracy: 82.936\n",
            "Worker 1, [17/18]: Training Loss: 0.547013923, Training Accuracy: 84.432\n",
            "Worker 1, [18/18]: Training Loss: 0.529898634, Training Accuracy: 84.808\n",
            "Time taken for training worker 1: 0:01:36.427980\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.297068981, Training Accuracy: 41.744\n",
            "Worker 2, [02/18]: Training Loss: 1.949479169, Training Accuracy: 48.104\n",
            "Worker 2, [03/18]: Training Loss: 1.783741561, Training Accuracy: 51.392\n",
            "Worker 2, [04/18]: Training Loss: 1.667112146, Training Accuracy: 53.864\n",
            "Worker 2, [05/18]: Training Loss: 1.556081673, Training Accuracy: 56.576\n",
            "Worker 2, [06/18]: Training Loss: 1.457312255, Training Accuracy: 58.760\n",
            "Worker 2, [07/18]: Training Loss: 1.330527457, Training Accuracy: 62.088\n",
            "Worker 2, [08/18]: Training Loss: 1.240909768, Training Accuracy: 64.608\n",
            "Worker 2, [09/18]: Training Loss: 1.103483779, Training Accuracy: 67.944\n",
            "Worker 2, [10/18]: Training Loss: 1.020384416, Training Accuracy: 69.944\n",
            "Worker 2, [11/18]: Training Loss: 0.904200613, Training Accuracy: 73.312\n",
            "Worker 2, [12/18]: Training Loss: 0.813407443, Training Accuracy: 76.232\n",
            "Worker 2, [13/18]: Training Loss: 0.727096529, Training Accuracy: 78.640\n",
            "Worker 2, [14/18]: Training Loss: 0.666624424, Training Accuracy: 80.696\n",
            "Worker 2, [15/18]: Training Loss: 0.593238067, Training Accuracy: 83.088\n",
            "Worker 2, [16/18]: Training Loss: 0.551855710, Training Accuracy: 83.920\n",
            "Worker 2, [17/18]: Training Loss: 0.528486127, Training Accuracy: 84.880\n",
            "Worker 2, [18/18]: Training Loss: 0.513175974, Training Accuracy: 85.400\n",
            "Time taken for training worker 2: 0:01:35.041922\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.323978297, Training Accuracy: 40.696\n",
            "Worker 3, [02/18]: Training Loss: 1.944069827, Training Accuracy: 48.184\n",
            "Worker 3, [03/18]: Training Loss: 1.796328188, Training Accuracy: 51.256\n",
            "Worker 3, [04/18]: Training Loss: 1.636105231, Training Accuracy: 54.600\n",
            "Worker 3, [05/18]: Training Loss: 1.559037816, Training Accuracy: 56.592\n",
            "Worker 3, [06/18]: Training Loss: 1.435850194, Training Accuracy: 59.384\n",
            "Worker 3, [07/18]: Training Loss: 1.315990999, Training Accuracy: 61.904\n",
            "Worker 3, [08/18]: Training Loss: 1.202267589, Training Accuracy: 64.656\n",
            "Worker 3, [09/18]: Training Loss: 1.097059066, Training Accuracy: 67.912\n",
            "Worker 3, [10/18]: Training Loss: 1.012949318, Training Accuracy: 70.520\n",
            "Worker 3, [11/18]: Training Loss: 0.898868800, Training Accuracy: 73.584\n",
            "Worker 3, [12/18]: Training Loss: 0.805678957, Training Accuracy: 75.856\n",
            "Worker 3, [13/18]: Training Loss: 0.722086970, Training Accuracy: 78.512\n",
            "Worker 3, [14/18]: Training Loss: 0.636132548, Training Accuracy: 81.080\n",
            "Worker 3, [15/18]: Training Loss: 0.571723389, Training Accuracy: 83.232\n",
            "Worker 3, [16/18]: Training Loss: 0.540822146, Training Accuracy: 84.184\n",
            "Worker 3, [17/18]: Training Loss: 0.505757949, Training Accuracy: 85.400\n",
            "Worker 3, [18/18]: Training Loss: 0.502375460, Training Accuracy: 85.504\n",
            "Time taken for training worker 3: 0:01:36.936389\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.275150834, Training Accuracy: 41.880\n",
            "Worker 4, [02/18]: Training Loss: 1.891345378, Training Accuracy: 48.816\n",
            "Worker 4, [03/18]: Training Loss: 1.741448361, Training Accuracy: 52.312\n",
            "Worker 4, [04/18]: Training Loss: 1.628210714, Training Accuracy: 54.984\n",
            "Worker 4, [05/18]: Training Loss: 1.510773989, Training Accuracy: 57.592\n",
            "Worker 4, [06/18]: Training Loss: 1.395766618, Training Accuracy: 60.048\n",
            "Worker 4, [07/18]: Training Loss: 1.291303291, Training Accuracy: 63.248\n",
            "Worker 4, [08/18]: Training Loss: 1.183372331, Training Accuracy: 65.632\n",
            "Worker 4, [09/18]: Training Loss: 1.062121972, Training Accuracy: 69.232\n",
            "Worker 4, [10/18]: Training Loss: 0.960234942, Training Accuracy: 72.152\n",
            "Worker 4, [11/18]: Training Loss: 0.860409099, Training Accuracy: 74.312\n",
            "Worker 4, [12/18]: Training Loss: 0.754195369, Training Accuracy: 77.808\n",
            "Worker 4, [13/18]: Training Loss: 0.681650503, Training Accuracy: 79.752\n",
            "Worker 4, [14/18]: Training Loss: 0.604785864, Training Accuracy: 82.064\n",
            "Worker 4, [15/18]: Training Loss: 0.550885373, Training Accuracy: 83.816\n",
            "Worker 4, [16/18]: Training Loss: 0.526263550, Training Accuracy: 84.848\n",
            "Worker 4, [17/18]: Training Loss: 0.500957494, Training Accuracy: 85.744\n",
            "Worker 4, [18/18]: Training Loss: 0.473858208, Training Accuracy: 86.472\n",
            "Time taken for training worker 4: 0:01:37.074151\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 05: Test Loss: 2.314392764, Test Accuracy: 50.290\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.129371618, Training Accuracy: 50.872\n",
            "Worker 1, [02/18]: Training Loss: 2.065746403, Training Accuracy: 50.768\n",
            "Worker 1, [03/18]: Training Loss: 1.910941015, Training Accuracy: 51.360\n",
            "Worker 1, [04/18]: Training Loss: 1.805029271, Training Accuracy: 52.184\n",
            "Worker 1, [05/18]: Training Loss: 1.701042362, Training Accuracy: 53.704\n",
            "Worker 1, [06/18]: Training Loss: 1.591759853, Training Accuracy: 56.424\n",
            "Worker 1, [07/18]: Training Loss: 1.521568537, Training Accuracy: 57.888\n",
            "Worker 1, [08/18]: Training Loss: 1.449934317, Training Accuracy: 59.248\n",
            "Worker 1, [09/18]: Training Loss: 1.412428981, Training Accuracy: 60.120\n",
            "Worker 1, [10/18]: Training Loss: 1.374909596, Training Accuracy: 60.368\n",
            "Worker 1, [11/18]: Training Loss: 1.346332481, Training Accuracy: 61.608\n",
            "Worker 1, [12/18]: Training Loss: 1.326034076, Training Accuracy: 61.544\n",
            "Worker 1, [13/18]: Training Loss: 1.350367483, Training Accuracy: 60.680\n",
            "Worker 1, [14/18]: Training Loss: 1.350851628, Training Accuracy: 61.128\n",
            "Worker 1, [15/18]: Training Loss: 1.349536333, Training Accuracy: 61.112\n",
            "Worker 1, [16/18]: Training Loss: 1.380716234, Training Accuracy: 60.432\n",
            "Worker 1, [17/18]: Training Loss: 1.343936972, Training Accuracy: 61.760\n",
            "Worker 1, [18/18]: Training Loss: 1.371450065, Training Accuracy: 60.192\n",
            "Time taken for training worker 1: 0:01:36.734380\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.416313851, Training Accuracy: 41.480\n",
            "Worker 2, [02/18]: Training Loss: 2.273346985, Training Accuracy: 43.272\n",
            "Worker 2, [03/18]: Training Loss: 2.076997896, Training Accuracy: 46.096\n",
            "Worker 2, [04/18]: Training Loss: 1.925489576, Training Accuracy: 48.824\n",
            "Worker 2, [05/18]: Training Loss: 1.816695946, Training Accuracy: 51.272\n",
            "Worker 2, [06/18]: Training Loss: 1.702436371, Training Accuracy: 53.856\n",
            "Worker 2, [07/18]: Training Loss: 1.605348587, Training Accuracy: 55.776\n",
            "Worker 2, [08/18]: Training Loss: 1.530667734, Training Accuracy: 57.864\n",
            "Worker 2, [09/18]: Training Loss: 1.463391345, Training Accuracy: 59.072\n",
            "Worker 2, [10/18]: Training Loss: 1.408207500, Training Accuracy: 60.400\n",
            "Worker 2, [11/18]: Training Loss: 1.360744177, Training Accuracy: 61.944\n",
            "Worker 2, [12/18]: Training Loss: 1.377123991, Training Accuracy: 60.752\n",
            "Worker 2, [13/18]: Training Loss: 1.366601283, Training Accuracy: 60.768\n",
            "Worker 2, [14/18]: Training Loss: 1.349402773, Training Accuracy: 60.656\n",
            "Worker 2, [15/18]: Training Loss: 1.330482246, Training Accuracy: 61.416\n",
            "Worker 2, [16/18]: Training Loss: 1.357199322, Training Accuracy: 61.144\n",
            "Worker 2, [17/18]: Training Loss: 1.365617632, Training Accuracy: 60.920\n",
            "Worker 2, [18/18]: Training Loss: 1.333781631, Training Accuracy: 61.872\n",
            "Time taken for training worker 2: 0:01:35.697778\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.358027324, Training Accuracy: 41.608\n",
            "Worker 3, [02/18]: Training Loss: 2.218227336, Training Accuracy: 44.360\n",
            "Worker 3, [03/18]: Training Loss: 2.055946595, Training Accuracy: 46.824\n",
            "Worker 3, [04/18]: Training Loss: 1.899565146, Training Accuracy: 49.296\n",
            "Worker 3, [05/18]: Training Loss: 1.792253211, Training Accuracy: 51.320\n",
            "Worker 3, [06/18]: Training Loss: 1.688429786, Training Accuracy: 53.632\n",
            "Worker 3, [07/18]: Training Loss: 1.597698176, Training Accuracy: 55.416\n",
            "Worker 3, [08/18]: Training Loss: 1.505088230, Training Accuracy: 57.880\n",
            "Worker 3, [09/18]: Training Loss: 1.454355156, Training Accuracy: 58.672\n",
            "Worker 3, [10/18]: Training Loss: 1.413952678, Training Accuracy: 59.624\n",
            "Worker 3, [11/18]: Training Loss: 1.365372322, Training Accuracy: 60.984\n",
            "Worker 3, [12/18]: Training Loss: 1.359559624, Training Accuracy: 60.856\n",
            "Worker 3, [13/18]: Training Loss: 1.355688529, Training Accuracy: 61.288\n",
            "Worker 3, [14/18]: Training Loss: 1.356741545, Training Accuracy: 61.128\n",
            "Worker 3, [15/18]: Training Loss: 1.345918952, Training Accuracy: 60.520\n",
            "Worker 3, [16/18]: Training Loss: 1.353789912, Training Accuracy: 60.992\n",
            "Worker 3, [17/18]: Training Loss: 1.333049570, Training Accuracy: 61.576\n",
            "Worker 3, [18/18]: Training Loss: 1.333264039, Training Accuracy: 61.744\n",
            "Time taken for training worker 3: 0:01:40.193844\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.303606468, Training Accuracy: 43.920\n",
            "Worker 4, [02/18]: Training Loss: 2.176356300, Training Accuracy: 45.592\n",
            "Worker 4, [03/18]: Training Loss: 1.995793617, Training Accuracy: 47.752\n",
            "Worker 4, [04/18]: Training Loss: 1.857728729, Training Accuracy: 50.696\n",
            "Worker 4, [05/18]: Training Loss: 1.759454279, Training Accuracy: 52.232\n",
            "Worker 4, [06/18]: Training Loss: 1.662047831, Training Accuracy: 54.824\n",
            "Worker 4, [07/18]: Training Loss: 1.570680470, Training Accuracy: 56.704\n",
            "Worker 4, [08/18]: Training Loss: 1.481762524, Training Accuracy: 58.832\n",
            "Worker 4, [09/18]: Training Loss: 1.434212013, Training Accuracy: 59.584\n",
            "Worker 4, [10/18]: Training Loss: 1.376911969, Training Accuracy: 61.024\n",
            "Worker 4, [11/18]: Training Loss: 1.353426476, Training Accuracy: 61.248\n",
            "Worker 4, [12/18]: Training Loss: 1.315254075, Training Accuracy: 62.592\n",
            "Worker 4, [13/18]: Training Loss: 1.310390257, Training Accuracy: 62.504\n",
            "Worker 4, [14/18]: Training Loss: 1.313954844, Training Accuracy: 61.736\n",
            "Worker 4, [15/18]: Training Loss: 1.300161145, Training Accuracy: 62.256\n",
            "Worker 4, [16/18]: Training Loss: 1.302721111, Training Accuracy: 62.312\n",
            "Worker 4, [17/18]: Training Loss: 1.284022918, Training Accuracy: 62.752\n",
            "Worker 4, [18/18]: Training Loss: 1.292060954, Training Accuracy: 63.120\n",
            "Time taken for training worker 4: 0:01:38.090837\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000606\n",
            "Local Step 06: Test Loss: 2.387462140, Test Accuracy: 43.030\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.186731798, Training Accuracy: 43.440\n",
            "Worker 1, [02/18]: Training Loss: 1.859959895, Training Accuracy: 49.872\n",
            "Worker 1, [03/18]: Training Loss: 1.675736401, Training Accuracy: 54.224\n",
            "Worker 1, [04/18]: Training Loss: 1.554409084, Training Accuracy: 56.288\n",
            "Worker 1, [05/18]: Training Loss: 1.412190386, Training Accuracy: 60.240\n",
            "Worker 1, [06/18]: Training Loss: 1.339055537, Training Accuracy: 61.896\n",
            "Worker 1, [07/18]: Training Loss: 1.251017753, Training Accuracy: 63.984\n",
            "Worker 1, [08/18]: Training Loss: 1.131565152, Training Accuracy: 67.304\n",
            "Worker 1, [09/18]: Training Loss: 1.026152571, Training Accuracy: 69.832\n",
            "Worker 1, [10/18]: Training Loss: 0.894609607, Training Accuracy: 73.520\n",
            "Worker 1, [11/18]: Training Loss: 0.797206625, Training Accuracy: 76.208\n",
            "Worker 1, [12/18]: Training Loss: 0.701672302, Training Accuracy: 79.176\n",
            "Worker 1, [13/18]: Training Loss: 0.646103876, Training Accuracy: 81.000\n",
            "Worker 1, [14/18]: Training Loss: 0.557215526, Training Accuracy: 83.488\n",
            "Worker 1, [15/18]: Training Loss: 0.508140818, Training Accuracy: 85.424\n",
            "Worker 1, [16/18]: Training Loss: 0.467438419, Training Accuracy: 86.360\n",
            "Worker 1, [17/18]: Training Loss: 0.452564552, Training Accuracy: 86.944\n",
            "Worker 1, [18/18]: Training Loss: 0.435138114, Training Accuracy: 87.544\n",
            "Time taken for training worker 1: 0:01:35.841819\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.223472540, Training Accuracy: 42.816\n",
            "Worker 2, [02/18]: Training Loss: 1.865135633, Training Accuracy: 49.600\n",
            "Worker 2, [03/18]: Training Loss: 1.702897648, Training Accuracy: 53.456\n",
            "Worker 2, [04/18]: Training Loss: 1.548728889, Training Accuracy: 56.768\n",
            "Worker 2, [05/18]: Training Loss: 1.478134393, Training Accuracy: 58.928\n",
            "Worker 2, [06/18]: Training Loss: 1.309540229, Training Accuracy: 62.488\n",
            "Worker 2, [07/18]: Training Loss: 1.207170731, Training Accuracy: 65.392\n",
            "Worker 2, [08/18]: Training Loss: 1.107303023, Training Accuracy: 67.824\n",
            "Worker 2, [09/18]: Training Loss: 1.006387510, Training Accuracy: 70.592\n",
            "Worker 2, [10/18]: Training Loss: 0.891882563, Training Accuracy: 74.152\n",
            "Worker 2, [11/18]: Training Loss: 0.806093388, Training Accuracy: 76.000\n",
            "Worker 2, [12/18]: Training Loss: 0.703835921, Training Accuracy: 78.984\n",
            "Worker 2, [13/18]: Training Loss: 0.613578610, Training Accuracy: 82.000\n",
            "Worker 2, [14/18]: Training Loss: 0.537525058, Training Accuracy: 84.216\n",
            "Worker 2, [15/18]: Training Loss: 0.499992088, Training Accuracy: 85.496\n",
            "Worker 2, [16/18]: Training Loss: 0.459138391, Training Accuracy: 87.128\n",
            "Worker 2, [17/18]: Training Loss: 0.433190769, Training Accuracy: 87.904\n",
            "Worker 2, [18/18]: Training Loss: 0.426301225, Training Accuracy: 88.016\n",
            "Time taken for training worker 2: 0:01:34.974344\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.231278407, Training Accuracy: 42.224\n",
            "Worker 3, [02/18]: Training Loss: 1.873394231, Training Accuracy: 49.168\n",
            "Worker 3, [03/18]: Training Loss: 1.684819366, Training Accuracy: 53.136\n",
            "Worker 3, [04/18]: Training Loss: 1.539986833, Training Accuracy: 56.360\n",
            "Worker 3, [05/18]: Training Loss: 1.425066376, Training Accuracy: 59.432\n",
            "Worker 3, [06/18]: Training Loss: 1.339918841, Training Accuracy: 61.488\n",
            "Worker 3, [07/18]: Training Loss: 1.223521639, Training Accuracy: 64.536\n",
            "Worker 3, [08/18]: Training Loss: 1.119121092, Training Accuracy: 67.416\n",
            "Worker 3, [09/18]: Training Loss: 0.987200281, Training Accuracy: 71.136\n",
            "Worker 3, [10/18]: Training Loss: 0.928118115, Training Accuracy: 72.160\n",
            "Worker 3, [11/18]: Training Loss: 0.802552354, Training Accuracy: 76.208\n",
            "Worker 3, [12/18]: Training Loss: 0.705909576, Training Accuracy: 78.840\n",
            "Worker 3, [13/18]: Training Loss: 0.622479561, Training Accuracy: 81.760\n",
            "Worker 3, [14/18]: Training Loss: 0.552397418, Training Accuracy: 83.864\n",
            "Worker 3, [15/18]: Training Loss: 0.505358849, Training Accuracy: 85.456\n",
            "Worker 3, [16/18]: Training Loss: 0.468310115, Training Accuracy: 86.584\n",
            "Worker 3, [17/18]: Training Loss: 0.448497983, Training Accuracy: 87.136\n",
            "Worker 3, [18/18]: Training Loss: 0.432564357, Training Accuracy: 87.984\n",
            "Time taken for training worker 3: 0:01:35.529988\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.166903352, Training Accuracy: 43.824\n",
            "Worker 4, [02/18]: Training Loss: 1.810774070, Training Accuracy: 51.304\n",
            "Worker 4, [03/18]: Training Loss: 1.668911641, Training Accuracy: 53.656\n",
            "Worker 4, [04/18]: Training Loss: 1.552531355, Training Accuracy: 56.472\n",
            "Worker 4, [05/18]: Training Loss: 1.423834807, Training Accuracy: 59.464\n",
            "Worker 4, [06/18]: Training Loss: 1.317446170, Training Accuracy: 62.560\n",
            "Worker 4, [07/18]: Training Loss: 1.191456328, Training Accuracy: 65.688\n",
            "Worker 4, [08/18]: Training Loss: 1.088289696, Training Accuracy: 68.136\n",
            "Worker 4, [09/18]: Training Loss: 0.977238002, Training Accuracy: 71.568\n",
            "Worker 4, [10/18]: Training Loss: 0.880146937, Training Accuracy: 73.776\n",
            "Worker 4, [11/18]: Training Loss: 0.770232915, Training Accuracy: 77.480\n",
            "Worker 4, [12/18]: Training Loss: 0.664842886, Training Accuracy: 80.464\n",
            "Worker 4, [13/18]: Training Loss: 0.602297723, Training Accuracy: 81.896\n",
            "Worker 4, [14/18]: Training Loss: 0.516418045, Training Accuracy: 84.864\n",
            "Worker 4, [15/18]: Training Loss: 0.480742117, Training Accuracy: 85.800\n",
            "Worker 4, [16/18]: Training Loss: 0.452370841, Training Accuracy: 86.744\n",
            "Worker 4, [17/18]: Training Loss: 0.428532150, Training Accuracy: 87.864\n",
            "Worker 4, [18/18]: Training Loss: 0.401678999, Training Accuracy: 88.424\n",
            "Time taken for training worker 4: 0:01:36.011733\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000823\n",
            "Local Step 07: Test Loss: 2.324464313, Test Accuracy: 50.700\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.041485441, Training Accuracy: 52.552\n",
            "Worker 1, [02/18]: Training Loss: 2.026568497, Training Accuracy: 52.152\n",
            "Worker 1, [03/18]: Training Loss: 1.848077212, Training Accuracy: 53.056\n",
            "Worker 1, [04/18]: Training Loss: 1.720713277, Training Accuracy: 53.992\n",
            "Worker 1, [05/18]: Training Loss: 1.605009147, Training Accuracy: 56.488\n",
            "Worker 1, [06/18]: Training Loss: 1.532117509, Training Accuracy: 57.616\n",
            "Worker 1, [07/18]: Training Loss: 1.438816094, Training Accuracy: 59.392\n",
            "Worker 1, [08/18]: Training Loss: 1.380113908, Training Accuracy: 60.976\n",
            "Worker 1, [09/18]: Training Loss: 1.304286870, Training Accuracy: 62.848\n",
            "Worker 1, [10/18]: Training Loss: 1.253778517, Training Accuracy: 64.456\n",
            "Worker 1, [11/18]: Training Loss: 1.272502421, Training Accuracy: 63.256\n",
            "Worker 1, [12/18]: Training Loss: 1.275229668, Training Accuracy: 63.512\n",
            "Worker 1, [13/18]: Training Loss: 1.252643864, Training Accuracy: 63.792\n",
            "Worker 1, [14/18]: Training Loss: 1.250965571, Training Accuracy: 63.424\n",
            "Worker 1, [15/18]: Training Loss: 1.263665387, Training Accuracy: 63.144\n",
            "Worker 1, [16/18]: Training Loss: 1.258290257, Training Accuracy: 63.376\n",
            "Worker 1, [17/18]: Training Loss: 1.272763536, Training Accuracy: 63.016\n",
            "Worker 1, [18/18]: Training Loss: 1.259522543, Training Accuracy: 63.616\n",
            "Time taken for training worker 1: 0:01:37.470056\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.328860577, Training Accuracy: 43.352\n",
            "Worker 2, [02/18]: Training Loss: 2.179230483, Training Accuracy: 45.496\n",
            "Worker 2, [03/18]: Training Loss: 1.981024131, Training Accuracy: 48.488\n",
            "Worker 2, [04/18]: Training Loss: 1.842471936, Training Accuracy: 50.824\n",
            "Worker 2, [05/18]: Training Loss: 1.728111866, Training Accuracy: 52.856\n",
            "Worker 2, [06/18]: Training Loss: 1.624884938, Training Accuracy: 55.744\n",
            "Worker 2, [07/18]: Training Loss: 1.516515682, Training Accuracy: 58.208\n",
            "Worker 2, [08/18]: Training Loss: 1.454891240, Training Accuracy: 59.448\n",
            "Worker 2, [09/18]: Training Loss: 1.362247814, Training Accuracy: 61.248\n",
            "Worker 2, [10/18]: Training Loss: 1.331648174, Training Accuracy: 62.032\n",
            "Worker 2, [11/18]: Training Loss: 1.279086452, Training Accuracy: 63.096\n",
            "Worker 2, [12/18]: Training Loss: 1.309730626, Training Accuracy: 62.264\n",
            "Worker 2, [13/18]: Training Loss: 1.297267997, Training Accuracy: 62.592\n",
            "Worker 2, [14/18]: Training Loss: 1.251413065, Training Accuracy: 63.584\n",
            "Worker 2, [15/18]: Training Loss: 1.273608994, Training Accuracy: 63.560\n",
            "Worker 2, [16/18]: Training Loss: 1.292342748, Training Accuracy: 62.672\n",
            "Worker 2, [17/18]: Training Loss: 1.279017328, Training Accuracy: 63.072\n",
            "Worker 2, [18/18]: Training Loss: 1.268167001, Training Accuracy: 63.416\n",
            "Time taken for training worker 2: 0:01:33.716227\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.355436131, Training Accuracy: 42.472\n",
            "Worker 3, [02/18]: Training Loss: 2.204153251, Training Accuracy: 44.192\n",
            "Worker 3, [03/18]: Training Loss: 1.996510934, Training Accuracy: 48.288\n",
            "Worker 3, [04/18]: Training Loss: 1.858753220, Training Accuracy: 50.536\n",
            "Worker 3, [05/18]: Training Loss: 1.741902263, Training Accuracy: 52.552\n",
            "Worker 3, [06/18]: Training Loss: 1.623106583, Training Accuracy: 55.184\n",
            "Worker 3, [07/18]: Training Loss: 1.536839756, Training Accuracy: 57.008\n",
            "Worker 3, [08/18]: Training Loss: 1.443099149, Training Accuracy: 59.248\n",
            "Worker 3, [09/18]: Training Loss: 1.403455321, Training Accuracy: 59.696\n",
            "Worker 3, [10/18]: Training Loss: 1.331676980, Training Accuracy: 61.680\n",
            "Worker 3, [11/18]: Training Loss: 1.295112632, Training Accuracy: 62.864\n",
            "Worker 3, [12/18]: Training Loss: 1.265897099, Training Accuracy: 63.408\n",
            "Worker 3, [13/18]: Training Loss: 1.298080003, Training Accuracy: 62.104\n",
            "Worker 3, [14/18]: Training Loss: 1.270457087, Training Accuracy: 62.872\n",
            "Worker 3, [15/18]: Training Loss: 1.270853628, Training Accuracy: 62.960\n",
            "Worker 3, [16/18]: Training Loss: 1.272863899, Training Accuracy: 62.816\n",
            "Worker 3, [17/18]: Training Loss: 1.292388798, Training Accuracy: 62.528\n",
            "Worker 3, [18/18]: Training Loss: 1.244866791, Training Accuracy: 63.608\n",
            "Time taken for training worker 3: 0:01:37.878622\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.287947560, Training Accuracy: 44.152\n",
            "Worker 4, [02/18]: Training Loss: 2.132989160, Training Accuracy: 46.464\n",
            "Worker 4, [03/18]: Training Loss: 1.944092586, Training Accuracy: 48.888\n",
            "Worker 4, [04/18]: Training Loss: 1.811844004, Training Accuracy: 51.080\n",
            "Worker 4, [05/18]: Training Loss: 1.686656880, Training Accuracy: 54.128\n",
            "Worker 4, [06/18]: Training Loss: 1.589688794, Training Accuracy: 56.312\n",
            "Worker 4, [07/18]: Training Loss: 1.501672641, Training Accuracy: 58.448\n",
            "Worker 4, [08/18]: Training Loss: 1.420555450, Training Accuracy: 59.904\n",
            "Worker 4, [09/18]: Training Loss: 1.350616159, Training Accuracy: 61.856\n",
            "Worker 4, [10/18]: Training Loss: 1.294011059, Training Accuracy: 62.992\n",
            "Worker 4, [11/18]: Training Loss: 1.273803091, Training Accuracy: 63.400\n",
            "Worker 4, [12/18]: Training Loss: 1.260365081, Training Accuracy: 63.336\n",
            "Worker 4, [13/18]: Training Loss: 1.234533276, Training Accuracy: 63.880\n",
            "Worker 4, [14/18]: Training Loss: 1.266814892, Training Accuracy: 63.536\n",
            "Worker 4, [15/18]: Training Loss: 1.239740306, Training Accuracy: 64.440\n",
            "Worker 4, [16/18]: Training Loss: 1.259337165, Training Accuracy: 63.520\n",
            "Worker 4, [17/18]: Training Loss: 1.282367388, Training Accuracy: 62.848\n",
            "Worker 4, [18/18]: Training Loss: 1.261055270, Training Accuracy: 63.488\n",
            "Time taken for training worker 4: 0:01:36.200060\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000743\n",
            "Local Step 08: Test Loss: 2.520489815, Test Accuracy: 42.450\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:51.179257\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:16\n",
            "==================================================\n",
            "Worker 1, [01/9]: Training Loss: 4.522943450, Training Accuracy: 2.312\n",
            "Worker 1, [02/9]: Training Loss: 4.148964405, Training Accuracy: 6.512\n",
            "Worker 1, [03/9]: Training Loss: 3.924811729, Training Accuracy: 9.376\n",
            "Worker 1, [04/9]: Training Loss: 3.752008639, Training Accuracy: 11.960\n",
            "Worker 1, [05/9]: Training Loss: 3.602250668, Training Accuracy: 14.496\n",
            "Worker 1, [06/9]: Training Loss: 3.456956132, Training Accuracy: 17.096\n",
            "Worker 1, [07/9]: Training Loss: 3.341059687, Training Accuracy: 18.856\n",
            "Worker 1, [08/9]: Training Loss: 3.231928703, Training Accuracy: 21.336\n",
            "Worker 1, [09/9]: Training Loss: 3.173736008, Training Accuracy: 22.608\n",
            "Time taken for training worker 1: 0:00:49.146816\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 4.533173038, Training Accuracy: 2.296\n",
            "Worker 2, [02/9]: Training Loss: 4.158115625, Training Accuracy: 5.984\n",
            "Worker 2, [03/9]: Training Loss: 3.943472389, Training Accuracy: 8.776\n",
            "Worker 2, [04/9]: Training Loss: 3.770387433, Training Accuracy: 11.712\n",
            "Worker 2, [05/9]: Training Loss: 3.625695817, Training Accuracy: 13.984\n",
            "Worker 2, [06/9]: Training Loss: 3.497190780, Training Accuracy: 16.152\n",
            "Worker 2, [07/9]: Training Loss: 3.366588426, Training Accuracy: 18.880\n",
            "Worker 2, [08/9]: Training Loss: 3.277924296, Training Accuracy: 20.312\n",
            "Worker 2, [09/9]: Training Loss: 3.206362677, Training Accuracy: 21.824\n",
            "Time taken for training worker 2: 0:00:48.718935\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 4.530504560, Training Accuracy: 2.272\n",
            "Worker 3, [02/9]: Training Loss: 4.155880692, Training Accuracy: 5.776\n",
            "Worker 3, [03/9]: Training Loss: 3.925889140, Training Accuracy: 8.872\n",
            "Worker 3, [04/9]: Training Loss: 3.745465935, Training Accuracy: 12.208\n",
            "Worker 3, [05/9]: Training Loss: 3.608012416, Training Accuracy: 14.104\n",
            "Worker 3, [06/9]: Training Loss: 3.480932844, Training Accuracy: 16.400\n",
            "Worker 3, [07/9]: Training Loss: 3.354593129, Training Accuracy: 18.544\n",
            "Worker 3, [08/9]: Training Loss: 3.258249355, Training Accuracy: 20.472\n",
            "Worker 3, [09/9]: Training Loss: 3.194212939, Training Accuracy: 21.968\n",
            "Time taken for training worker 3: 0:00:47.808631\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 4.520948792, Training Accuracy: 2.392\n",
            "Worker 4, [02/9]: Training Loss: 4.139702670, Training Accuracy: 6.424\n",
            "Worker 4, [03/9]: Training Loss: 3.922476428, Training Accuracy: 9.240\n",
            "Worker 4, [04/9]: Training Loss: 3.753042855, Training Accuracy: 11.712\n",
            "Worker 4, [05/9]: Training Loss: 3.616312074, Training Accuracy: 14.080\n",
            "Worker 4, [06/9]: Training Loss: 3.480655479, Training Accuracy: 16.344\n",
            "Worker 4, [07/9]: Training Loss: 3.355720920, Training Accuracy: 18.880\n",
            "Worker 4, [08/9]: Training Loss: 3.258307264, Training Accuracy: 20.664\n",
            "Worker 4, [09/9]: Training Loss: 3.198289113, Training Accuracy: 21.640\n",
            "Time taken for training worker 4: 0:00:47.599816\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000695\n",
            "Local Step 01: Test Loss: 3.393974600, Test Accuracy: 20.040\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 3.450966480, Training Accuracy: 18.024\n",
            "Worker 1, [02/9]: Training Loss: 3.395088308, Training Accuracy: 18.768\n",
            "Worker 1, [03/9]: Training Loss: 3.363191157, Training Accuracy: 18.992\n",
            "Worker 1, [04/9]: Training Loss: 3.346852896, Training Accuracy: 19.144\n",
            "Worker 1, [05/9]: Training Loss: 3.346896240, Training Accuracy: 19.160\n",
            "Worker 1, [06/9]: Training Loss: 3.312349285, Training Accuracy: 19.296\n",
            "Worker 1, [07/9]: Training Loss: 3.284550931, Training Accuracy: 20.160\n",
            "Worker 1, [08/9]: Training Loss: 3.209345063, Training Accuracy: 21.152\n",
            "Worker 1, [09/9]: Training Loss: 3.155518389, Training Accuracy: 22.360\n",
            "Time taken for training worker 1: 0:00:48.777386\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 3.209623721, Training Accuracy: 21.360\n",
            "Worker 2, [02/9]: Training Loss: 3.087404127, Training Accuracy: 24.392\n",
            "Worker 2, [03/9]: Training Loss: 3.023206714, Training Accuracy: 25.632\n",
            "Worker 2, [04/9]: Training Loss: 2.971525552, Training Accuracy: 26.144\n",
            "Worker 2, [05/9]: Training Loss: 2.960108495, Training Accuracy: 26.328\n",
            "Worker 2, [06/9]: Training Loss: 2.943808805, Training Accuracy: 25.920\n",
            "Worker 2, [07/9]: Training Loss: 2.925633720, Training Accuracy: 26.184\n",
            "Worker 2, [08/9]: Training Loss: 2.900830989, Training Accuracy: 27.208\n",
            "Worker 2, [09/9]: Training Loss: 2.845945880, Training Accuracy: 28.248\n",
            "Time taken for training worker 2: 0:00:48.414252\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 3.047014440, Training Accuracy: 24.592\n",
            "Worker 3, [02/9]: Training Loss: 2.869508273, Training Accuracy: 28.088\n",
            "Worker 3, [03/9]: Training Loss: 2.769534813, Training Accuracy: 30.056\n",
            "Worker 3, [04/9]: Training Loss: 2.714161962, Training Accuracy: 31.256\n",
            "Worker 3, [05/9]: Training Loss: 2.706487123, Training Accuracy: 30.608\n",
            "Worker 3, [06/9]: Training Loss: 2.692365053, Training Accuracy: 30.776\n",
            "Worker 3, [07/9]: Training Loss: 2.697591564, Training Accuracy: 30.680\n",
            "Worker 3, [08/9]: Training Loss: 2.689495002, Training Accuracy: 30.872\n",
            "Worker 3, [09/9]: Training Loss: 2.635449664, Training Accuracy: 31.632\n",
            "Time taken for training worker 3: 0:00:48.211039\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.864693570, Training Accuracy: 27.960\n",
            "Worker 4, [02/9]: Training Loss: 2.665643767, Training Accuracy: 32.632\n",
            "Worker 4, [03/9]: Training Loss: 2.558503914, Training Accuracy: 34.712\n",
            "Worker 4, [04/9]: Training Loss: 2.519199128, Training Accuracy: 34.968\n",
            "Worker 4, [05/9]: Training Loss: 2.517061125, Training Accuracy: 34.952\n",
            "Worker 4, [06/9]: Training Loss: 2.494036389, Training Accuracy: 35.176\n",
            "Worker 4, [07/9]: Training Loss: 2.495919662, Training Accuracy: 35.456\n",
            "Worker 4, [08/9]: Training Loss: 2.490665495, Training Accuracy: 35.256\n",
            "Worker 4, [09/9]: Training Loss: 2.491016895, Training Accuracy: 35.344\n",
            "Time taken for training worker 4: 0:00:49.166128\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000659\n",
            "Local Step 02: Test Loss: 2.587131456, Test Accuracy: 34.720\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.724923954, Training Accuracy: 31.392\n",
            "Worker 1, [02/9]: Training Loss: 2.568314178, Training Accuracy: 34.816\n",
            "Worker 1, [03/9]: Training Loss: 2.456321859, Training Accuracy: 36.296\n",
            "Worker 1, [04/9]: Training Loss: 2.274067772, Training Accuracy: 39.784\n",
            "Worker 1, [05/9]: Training Loss: 2.147999052, Training Accuracy: 42.712\n",
            "Worker 1, [06/9]: Training Loss: 1.997980896, Training Accuracy: 46.136\n",
            "Worker 1, [07/9]: Training Loss: 1.855477253, Training Accuracy: 49.424\n",
            "Worker 1, [08/9]: Training Loss: 1.760194795, Training Accuracy: 52.072\n",
            "Worker 1, [09/9]: Training Loss: 1.684578817, Training Accuracy: 53.840\n",
            "Time taken for training worker 1: 0:00:48.241626\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.617298775, Training Accuracy: 33.296\n",
            "Worker 2, [02/9]: Training Loss: 2.444872441, Training Accuracy: 36.520\n",
            "Worker 2, [03/9]: Training Loss: 2.318775901, Training Accuracy: 39.080\n",
            "Worker 2, [04/9]: Training Loss: 2.173566513, Training Accuracy: 42.096\n",
            "Worker 2, [05/9]: Training Loss: 2.017970527, Training Accuracy: 44.928\n",
            "Worker 2, [06/9]: Training Loss: 1.882856361, Training Accuracy: 48.680\n",
            "Worker 2, [07/9]: Training Loss: 1.727441136, Training Accuracy: 52.264\n",
            "Worker 2, [08/9]: Training Loss: 1.607811354, Training Accuracy: 55.544\n",
            "Worker 2, [09/9]: Training Loss: 1.536564328, Training Accuracy: 57.504\n",
            "Time taken for training worker 2: 0:00:48.535083\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.558992355, Training Accuracy: 34.512\n",
            "Worker 3, [02/9]: Training Loss: 2.387778989, Training Accuracy: 37.400\n",
            "Worker 3, [03/9]: Training Loss: 2.224783936, Training Accuracy: 40.744\n",
            "Worker 3, [04/9]: Training Loss: 2.083906219, Training Accuracy: 43.552\n",
            "Worker 3, [05/9]: Training Loss: 1.935046290, Training Accuracy: 47.424\n",
            "Worker 3, [06/9]: Training Loss: 1.798115540, Training Accuracy: 50.640\n",
            "Worker 3, [07/9]: Training Loss: 1.636589939, Training Accuracy: 54.200\n",
            "Worker 3, [08/9]: Training Loss: 1.526620290, Training Accuracy: 57.336\n",
            "Worker 3, [09/9]: Training Loss: 1.438092071, Training Accuracy: 59.872\n",
            "Time taken for training worker 3: 0:00:48.977258\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.447333367, Training Accuracy: 37.216\n",
            "Worker 4, [02/9]: Training Loss: 2.280517638, Training Accuracy: 40.032\n",
            "Worker 4, [03/9]: Training Loss: 2.156350383, Training Accuracy: 42.472\n",
            "Worker 4, [04/9]: Training Loss: 1.992657825, Training Accuracy: 45.848\n",
            "Worker 4, [05/9]: Training Loss: 1.847859344, Training Accuracy: 49.880\n",
            "Worker 4, [06/9]: Training Loss: 1.677721438, Training Accuracy: 53.856\n",
            "Worker 4, [07/9]: Training Loss: 1.536302450, Training Accuracy: 57.440\n",
            "Worker 4, [08/9]: Training Loss: 1.424254146, Training Accuracy: 60.000\n",
            "Worker 4, [09/9]: Training Loss: 1.346291852, Training Accuracy: 62.432\n",
            "Time taken for training worker 4: 0:00:48.138904\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000672\n",
            "Local Step 03: Test Loss: 2.086564725, Test Accuracy: 47.130\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.157519429, Training Accuracy: 44.880\n",
            "Worker 1, [02/9]: Training Loss: 2.083033411, Training Accuracy: 45.928\n",
            "Worker 1, [03/9]: Training Loss: 2.057290114, Training Accuracy: 46.280\n",
            "Worker 1, [04/9]: Training Loss: 2.010771693, Training Accuracy: 46.528\n",
            "Worker 1, [05/9]: Training Loss: 1.981296047, Training Accuracy: 46.824\n",
            "Worker 1, [06/9]: Training Loss: 1.977917818, Training Accuracy: 46.848\n",
            "Worker 1, [07/9]: Training Loss: 1.988307829, Training Accuracy: 46.168\n",
            "Worker 1, [08/9]: Training Loss: 1.994493764, Training Accuracy: 45.984\n",
            "Worker 1, [09/9]: Training Loss: 1.983539922, Training Accuracy: 46.984\n",
            "Time taken for training worker 1: 0:00:50.070750\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.369893679, Training Accuracy: 39.152\n",
            "Worker 2, [02/9]: Training Loss: 2.190394128, Training Accuracy: 42.656\n",
            "Worker 2, [03/9]: Training Loss: 2.063515301, Training Accuracy: 45.016\n",
            "Worker 2, [04/9]: Training Loss: 1.999544335, Training Accuracy: 46.296\n",
            "Worker 2, [05/9]: Training Loss: 1.947357335, Training Accuracy: 47.296\n",
            "Worker 2, [06/9]: Training Loss: 1.942953894, Training Accuracy: 47.592\n",
            "Worker 2, [07/9]: Training Loss: 1.941784426, Training Accuracy: 47.528\n",
            "Worker 2, [08/9]: Training Loss: 1.958886841, Training Accuracy: 46.352\n",
            "Worker 2, [09/9]: Training Loss: 1.946677351, Training Accuracy: 46.600\n",
            "Time taken for training worker 2: 0:00:50.073785\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.409357612, Training Accuracy: 37.552\n",
            "Worker 3, [02/9]: Training Loss: 2.188556950, Training Accuracy: 41.896\n",
            "Worker 3, [03/9]: Training Loss: 2.040757036, Training Accuracy: 45.464\n",
            "Worker 3, [04/9]: Training Loss: 1.964700267, Training Accuracy: 47.448\n",
            "Worker 3, [05/9]: Training Loss: 1.895964972, Training Accuracy: 48.648\n",
            "Worker 3, [06/9]: Training Loss: 1.863942385, Training Accuracy: 48.808\n",
            "Worker 3, [07/9]: Training Loss: 1.889720267, Training Accuracy: 47.936\n",
            "Worker 3, [08/9]: Training Loss: 1.884786735, Training Accuracy: 48.008\n",
            "Worker 3, [09/9]: Training Loss: 1.884774131, Training Accuracy: 48.176\n",
            "Time taken for training worker 3: 0:00:47.134411\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.248300801, Training Accuracy: 41.632\n",
            "Worker 4, [02/9]: Training Loss: 2.093261548, Training Accuracy: 44.432\n",
            "Worker 4, [03/9]: Training Loss: 1.947617747, Training Accuracy: 47.344\n",
            "Worker 4, [04/9]: Training Loss: 1.876162968, Training Accuracy: 49.904\n",
            "Worker 4, [05/9]: Training Loss: 1.830480680, Training Accuracy: 50.224\n",
            "Worker 4, [06/9]: Training Loss: 1.805270713, Training Accuracy: 50.768\n",
            "Worker 4, [07/9]: Training Loss: 1.791813039, Training Accuracy: 50.976\n",
            "Worker 4, [08/9]: Training Loss: 1.832944939, Training Accuracy: 49.656\n",
            "Worker 4, [09/9]: Training Loss: 1.819326483, Training Accuracy: 49.912\n",
            "Time taken for training worker 4: 0:00:51.994948\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000672\n",
            "Local Step 04: Test Loss: 2.245281731, Test Accuracy: 43.320\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.272225556, Training Accuracy: 40.832\n",
            "Worker 1, [02/9]: Training Loss: 2.046801672, Training Accuracy: 45.008\n",
            "Worker 1, [03/9]: Training Loss: 1.918272628, Training Accuracy: 48.480\n",
            "Worker 1, [04/9]: Training Loss: 1.755534386, Training Accuracy: 51.624\n",
            "Worker 1, [05/9]: Training Loss: 1.559264762, Training Accuracy: 56.592\n",
            "Worker 1, [06/9]: Training Loss: 1.406119424, Training Accuracy: 60.152\n",
            "Worker 1, [07/9]: Training Loss: 1.277042948, Training Accuracy: 63.288\n",
            "Worker 1, [08/9]: Training Loss: 1.146019665, Training Accuracy: 67.816\n",
            "Worker 1, [09/9]: Training Loss: 1.084155007, Training Accuracy: 69.288\n",
            "Time taken for training worker 1: 0:00:47.792399\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.258163771, Training Accuracy: 41.040\n",
            "Worker 2, [02/9]: Training Loss: 2.017195904, Training Accuracy: 46.000\n",
            "Worker 2, [03/9]: Training Loss: 1.871722013, Training Accuracy: 49.136\n",
            "Worker 2, [04/9]: Training Loss: 1.720319048, Training Accuracy: 52.992\n",
            "Worker 2, [05/9]: Training Loss: 1.551688058, Training Accuracy: 56.672\n",
            "Worker 2, [06/9]: Training Loss: 1.395318624, Training Accuracy: 60.184\n",
            "Worker 2, [07/9]: Training Loss: 1.219870531, Training Accuracy: 65.536\n",
            "Worker 2, [08/9]: Training Loss: 1.109410506, Training Accuracy: 68.280\n",
            "Worker 2, [09/9]: Training Loss: 1.026855005, Training Accuracy: 70.592\n",
            "Time taken for training worker 2: 0:00:46.519258\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.212390842, Training Accuracy: 41.672\n",
            "Worker 3, [02/9]: Training Loss: 2.010334583, Training Accuracy: 46.080\n",
            "Worker 3, [03/9]: Training Loss: 1.841209567, Training Accuracy: 49.376\n",
            "Worker 3, [04/9]: Training Loss: 1.679188869, Training Accuracy: 53.208\n",
            "Worker 3, [05/9]: Training Loss: 1.514176422, Training Accuracy: 56.768\n",
            "Worker 3, [06/9]: Training Loss: 1.360801549, Training Accuracy: 61.280\n",
            "Worker 3, [07/9]: Training Loss: 1.200757531, Training Accuracy: 65.976\n",
            "Worker 3, [08/9]: Training Loss: 1.090485508, Training Accuracy: 69.176\n",
            "Worker 3, [09/9]: Training Loss: 1.025574184, Training Accuracy: 70.680\n",
            "Time taken for training worker 3: 0:00:48.645664\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.172152889, Training Accuracy: 42.840\n",
            "Worker 4, [02/9]: Training Loss: 1.934218584, Training Accuracy: 47.120\n",
            "Worker 4, [03/9]: Training Loss: 1.787180670, Training Accuracy: 51.112\n",
            "Worker 4, [04/9]: Training Loss: 1.640805121, Training Accuracy: 54.368\n",
            "Worker 4, [05/9]: Training Loss: 1.464558430, Training Accuracy: 58.952\n",
            "Worker 4, [06/9]: Training Loss: 1.310947537, Training Accuracy: 62.472\n",
            "Worker 4, [07/9]: Training Loss: 1.171340182, Training Accuracy: 66.680\n",
            "Worker 4, [08/9]: Training Loss: 1.041260273, Training Accuracy: 69.872\n",
            "Worker 4, [09/9]: Training Loss: 0.958932958, Training Accuracy: 72.368\n",
            "Time taken for training worker 4: 0:00:48.881236\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000714\n",
            "Local Step 05: Test Loss: 2.011860420, Test Accuracy: 50.570\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.928190177, Training Accuracy: 51.072\n",
            "Worker 1, [02/9]: Training Loss: 1.845220953, Training Accuracy: 51.480\n",
            "Worker 1, [03/9]: Training Loss: 1.774617808, Training Accuracy: 52.576\n",
            "Worker 1, [04/9]: Training Loss: 1.717676313, Training Accuracy: 52.496\n",
            "Worker 1, [05/9]: Training Loss: 1.676573336, Training Accuracy: 54.216\n",
            "Worker 1, [06/9]: Training Loss: 1.673821006, Training Accuracy: 53.776\n",
            "Worker 1, [07/9]: Training Loss: 1.691810034, Training Accuracy: 53.416\n",
            "Worker 1, [08/9]: Training Loss: 1.713571212, Training Accuracy: 52.280\n",
            "Worker 1, [09/9]: Training Loss: 1.671483412, Training Accuracy: 53.352\n",
            "Time taken for training worker 1: 0:00:49.030221\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.167865983, Training Accuracy: 43.744\n",
            "Worker 2, [02/9]: Training Loss: 1.989344198, Training Accuracy: 46.880\n",
            "Worker 2, [03/9]: Training Loss: 1.836322007, Training Accuracy: 50.160\n",
            "Worker 2, [04/9]: Training Loss: 1.746743884, Training Accuracy: 52.176\n",
            "Worker 2, [05/9]: Training Loss: 1.681557006, Training Accuracy: 53.584\n",
            "Worker 2, [06/9]: Training Loss: 1.661827895, Training Accuracy: 54.072\n",
            "Worker 2, [07/9]: Training Loss: 1.656154594, Training Accuracy: 53.768\n",
            "Worker 2, [08/9]: Training Loss: 1.682243939, Training Accuracy: 53.352\n",
            "Worker 2, [09/9]: Training Loss: 1.676516486, Training Accuracy: 53.064\n",
            "Time taken for training worker 2: 0:00:47.815659\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.134905779, Training Accuracy: 43.432\n",
            "Worker 3, [02/9]: Training Loss: 1.962311526, Training Accuracy: 47.288\n",
            "Worker 3, [03/9]: Training Loss: 1.819508693, Training Accuracy: 50.336\n",
            "Worker 3, [04/9]: Training Loss: 1.716780195, Training Accuracy: 52.448\n",
            "Worker 3, [05/9]: Training Loss: 1.656741534, Training Accuracy: 54.224\n",
            "Worker 3, [06/9]: Training Loss: 1.620599374, Training Accuracy: 54.504\n",
            "Worker 3, [07/9]: Training Loss: 1.637649540, Training Accuracy: 53.648\n",
            "Worker 3, [08/9]: Training Loss: 1.663038281, Training Accuracy: 53.608\n",
            "Worker 3, [09/9]: Training Loss: 1.633591346, Training Accuracy: 53.792\n",
            "Time taken for training worker 3: 0:00:47.267660\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.191301649, Training Accuracy: 43.584\n",
            "Worker 4, [02/9]: Training Loss: 1.916915802, Training Accuracy: 48.040\n",
            "Worker 4, [03/9]: Training Loss: 1.761696562, Training Accuracy: 52.200\n",
            "Worker 4, [04/9]: Training Loss: 1.656962380, Training Accuracy: 54.520\n",
            "Worker 4, [05/9]: Training Loss: 1.621951398, Training Accuracy: 54.736\n",
            "Worker 4, [06/9]: Training Loss: 1.574184546, Training Accuracy: 56.000\n",
            "Worker 4, [07/9]: Training Loss: 1.576552821, Training Accuracy: 55.792\n",
            "Worker 4, [08/9]: Training Loss: 1.620160561, Training Accuracy: 54.448\n",
            "Worker 4, [09/9]: Training Loss: 1.619988243, Training Accuracy: 54.880\n",
            "Time taken for training worker 4: 0:00:48.340964\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000595\n",
            "Local Step 06: Test Loss: 2.237627707, Test Accuracy: 43.910\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.110279790, Training Accuracy: 43.960\n",
            "Worker 1, [02/9]: Training Loss: 1.861755977, Training Accuracy: 50.048\n",
            "Worker 1, [03/9]: Training Loss: 1.705611563, Training Accuracy: 52.960\n",
            "Worker 1, [04/9]: Training Loss: 1.552109936, Training Accuracy: 56.616\n",
            "Worker 1, [05/9]: Training Loss: 1.357315415, Training Accuracy: 61.832\n",
            "Worker 1, [06/9]: Training Loss: 1.230343967, Training Accuracy: 65.088\n",
            "Worker 1, [07/9]: Training Loss: 1.055706833, Training Accuracy: 69.680\n",
            "Worker 1, [08/9]: Training Loss: 0.940367438, Training Accuracy: 72.728\n",
            "Worker 1, [09/9]: Training Loss: 0.872154002, Training Accuracy: 75.024\n",
            "Time taken for training worker 1: 0:00:47.519547\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.097568699, Training Accuracy: 44.936\n",
            "Worker 2, [02/9]: Training Loss: 1.861346602, Training Accuracy: 49.416\n",
            "Worker 2, [03/9]: Training Loss: 1.700572544, Training Accuracy: 52.976\n",
            "Worker 2, [04/9]: Training Loss: 1.525215699, Training Accuracy: 56.608\n",
            "Worker 2, [05/9]: Training Loss: 1.375977456, Training Accuracy: 60.912\n",
            "Worker 2, [06/9]: Training Loss: 1.197494465, Training Accuracy: 65.664\n",
            "Worker 2, [07/9]: Training Loss: 1.038867136, Training Accuracy: 70.120\n",
            "Worker 2, [08/9]: Training Loss: 0.918067345, Training Accuracy: 73.816\n",
            "Worker 2, [09/9]: Training Loss: 0.848230954, Training Accuracy: 75.704\n",
            "Time taken for training worker 2: 0:00:49.805072\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.081133167, Training Accuracy: 44.528\n",
            "Worker 3, [02/9]: Training Loss: 1.855518291, Training Accuracy: 49.128\n",
            "Worker 3, [03/9]: Training Loss: 1.667002328, Training Accuracy: 53.416\n",
            "Worker 3, [04/9]: Training Loss: 1.510024065, Training Accuracy: 57.320\n",
            "Worker 3, [05/9]: Training Loss: 1.347265923, Training Accuracy: 61.432\n",
            "Worker 3, [06/9]: Training Loss: 1.175721051, Training Accuracy: 66.224\n",
            "Worker 3, [07/9]: Training Loss: 1.017395972, Training Accuracy: 70.448\n",
            "Worker 3, [08/9]: Training Loss: 0.903954298, Training Accuracy: 73.408\n",
            "Worker 3, [09/9]: Training Loss: 0.851864709, Training Accuracy: 75.496\n",
            "Time taken for training worker 3: 0:00:49.480894\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.097887480, Training Accuracy: 44.464\n",
            "Worker 4, [02/9]: Training Loss: 1.836685558, Training Accuracy: 50.088\n",
            "Worker 4, [03/9]: Training Loss: 1.650506759, Training Accuracy: 54.336\n",
            "Worker 4, [04/9]: Training Loss: 1.519097532, Training Accuracy: 57.144\n",
            "Worker 4, [05/9]: Training Loss: 1.314878464, Training Accuracy: 62.704\n",
            "Worker 4, [06/9]: Training Loss: 1.162342188, Training Accuracy: 66.200\n",
            "Worker 4, [07/9]: Training Loss: 0.995134939, Training Accuracy: 70.984\n",
            "Worker 4, [08/9]: Training Loss: 0.889936005, Training Accuracy: 74.272\n",
            "Worker 4, [09/9]: Training Loss: 0.824238060, Training Accuracy: 76.368\n",
            "Time taken for training worker 4: 0:00:48.689180\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000995\n",
            "Local Step 07: Test Loss: 2.018183833, Test Accuracy: 51.270\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.808893003, Training Accuracy: 53.584\n",
            "Worker 1, [02/9]: Training Loss: 1.736036216, Training Accuracy: 53.912\n",
            "Worker 1, [03/9]: Training Loss: 1.638617603, Training Accuracy: 55.424\n",
            "Worker 1, [04/9]: Training Loss: 1.584425220, Training Accuracy: 56.648\n",
            "Worker 1, [05/9]: Training Loss: 1.530291918, Training Accuracy: 57.256\n",
            "Worker 1, [06/9]: Training Loss: 1.511183059, Training Accuracy: 57.952\n",
            "Worker 1, [07/9]: Training Loss: 1.549156894, Training Accuracy: 56.360\n",
            "Worker 1, [08/9]: Training Loss: 1.530676436, Training Accuracy: 57.216\n",
            "Worker 1, [09/9]: Training Loss: 1.539153511, Training Accuracy: 57.000\n",
            "Time taken for training worker 1: 0:00:48.038831\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.111161664, Training Accuracy: 45.376\n",
            "Worker 2, [02/9]: Training Loss: 1.910683468, Training Accuracy: 48.960\n",
            "Worker 2, [03/9]: Training Loss: 1.731095676, Training Accuracy: 52.800\n",
            "Worker 2, [04/9]: Training Loss: 1.620092806, Training Accuracy: 55.152\n",
            "Worker 2, [05/9]: Training Loss: 1.547122466, Training Accuracy: 56.384\n",
            "Worker 2, [06/9]: Training Loss: 1.542227865, Training Accuracy: 57.024\n",
            "Worker 2, [07/9]: Training Loss: 1.534084355, Training Accuracy: 56.560\n",
            "Worker 2, [08/9]: Training Loss: 1.553363509, Training Accuracy: 56.248\n",
            "Worker 2, [09/9]: Training Loss: 1.554859048, Training Accuracy: 56.024\n",
            "Time taken for training worker 2: 0:00:50.684822\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.108755892, Training Accuracy: 44.304\n",
            "Worker 3, [02/9]: Training Loss: 1.877554681, Training Accuracy: 49.312\n",
            "Worker 3, [03/9]: Training Loss: 1.704786605, Training Accuracy: 53.392\n",
            "Worker 3, [04/9]: Training Loss: 1.603361253, Training Accuracy: 54.928\n",
            "Worker 3, [05/9]: Training Loss: 1.528528670, Training Accuracy: 57.216\n",
            "Worker 3, [06/9]: Training Loss: 1.505959849, Training Accuracy: 57.776\n",
            "Worker 3, [07/9]: Training Loss: 1.512251451, Training Accuracy: 56.936\n",
            "Worker 3, [08/9]: Training Loss: 1.524023329, Training Accuracy: 56.528\n",
            "Worker 3, [09/9]: Training Loss: 1.526208054, Training Accuracy: 56.744\n",
            "Time taken for training worker 3: 0:00:48.656681\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.958722847, Training Accuracy: 47.200\n",
            "Worker 4, [02/9]: Training Loss: 1.808618811, Training Accuracy: 50.568\n",
            "Worker 4, [03/9]: Training Loss: 1.666377476, Training Accuracy: 54.128\n",
            "Worker 4, [04/9]: Training Loss: 1.571276507, Training Accuracy: 56.080\n",
            "Worker 4, [05/9]: Training Loss: 1.498132065, Training Accuracy: 57.512\n",
            "Worker 4, [06/9]: Training Loss: 1.460168030, Training Accuracy: 58.856\n",
            "Worker 4, [07/9]: Training Loss: 1.478419208, Training Accuracy: 58.136\n",
            "Worker 4, [08/9]: Training Loss: 1.488113464, Training Accuracy: 57.928\n",
            "Worker 4, [09/9]: Training Loss: 1.513778101, Training Accuracy: 57.448\n",
            "Time taken for training worker 4: 0:00:47.793060\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000641\n",
            "Local Step 08: Test Loss: 2.204498685, Test Accuracy: 45.010\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.036199198, Training Accuracy: 45.824\n",
            "Worker 1, [02/9]: Training Loss: 1.760260370, Training Accuracy: 51.536\n",
            "Worker 1, [03/9]: Training Loss: 1.601289211, Training Accuracy: 55.712\n",
            "Worker 1, [04/9]: Training Loss: 1.427328816, Training Accuracy: 59.120\n",
            "Worker 1, [05/9]: Training Loss: 1.265103321, Training Accuracy: 64.192\n",
            "Worker 1, [06/9]: Training Loss: 1.080976814, Training Accuracy: 68.440\n",
            "Worker 1, [07/9]: Training Loss: 0.935653004, Training Accuracy: 72.640\n",
            "Worker 1, [08/9]: Training Loss: 0.834136393, Training Accuracy: 75.968\n",
            "Worker 1, [09/9]: Training Loss: 0.772503988, Training Accuracy: 77.984\n",
            "Time taken for training worker 1: 0:00:47.574419\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.030337848, Training Accuracy: 46.168\n",
            "Worker 2, [02/9]: Training Loss: 1.774085775, Training Accuracy: 51.736\n",
            "Worker 2, [03/9]: Training Loss: 1.590004558, Training Accuracy: 55.472\n",
            "Worker 2, [04/9]: Training Loss: 1.427594931, Training Accuracy: 59.664\n",
            "Worker 2, [05/9]: Training Loss: 1.257160003, Training Accuracy: 63.752\n",
            "Worker 2, [06/9]: Training Loss: 1.096364858, Training Accuracy: 68.088\n",
            "Worker 2, [07/9]: Training Loss: 0.945125063, Training Accuracy: 72.448\n",
            "Worker 2, [08/9]: Training Loss: 0.836191268, Training Accuracy: 75.424\n",
            "Worker 2, [09/9]: Training Loss: 0.767706489, Training Accuracy: 77.424\n",
            "Time taken for training worker 2: 0:00:47.099687\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.019806748, Training Accuracy: 46.072\n",
            "Worker 3, [02/9]: Training Loss: 1.769503831, Training Accuracy: 51.168\n",
            "Worker 3, [03/9]: Training Loss: 1.584569475, Training Accuracy: 55.304\n",
            "Worker 3, [04/9]: Training Loss: 1.403519650, Training Accuracy: 59.376\n",
            "Worker 3, [05/9]: Training Loss: 1.233161985, Training Accuracy: 64.440\n",
            "Worker 3, [06/9]: Training Loss: 1.059453146, Training Accuracy: 68.592\n",
            "Worker 3, [07/9]: Training Loss: 0.920191415, Training Accuracy: 72.848\n",
            "Worker 3, [08/9]: Training Loss: 0.797542478, Training Accuracy: 76.488\n",
            "Worker 3, [09/9]: Training Loss: 0.748556688, Training Accuracy: 78.688\n",
            "Time taken for training worker 3: 0:00:47.774651\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.011249708, Training Accuracy: 46.216\n",
            "Worker 4, [02/9]: Training Loss: 1.753069762, Training Accuracy: 51.560\n",
            "Worker 4, [03/9]: Training Loss: 1.576151454, Training Accuracy: 55.664\n",
            "Worker 4, [04/9]: Training Loss: 1.417644834, Training Accuracy: 59.704\n",
            "Worker 4, [05/9]: Training Loss: 1.230839288, Training Accuracy: 65.048\n",
            "Worker 4, [06/9]: Training Loss: 1.061494196, Training Accuracy: 69.224\n",
            "Worker 4, [07/9]: Training Loss: 0.907057654, Training Accuracy: 73.400\n",
            "Worker 4, [08/9]: Training Loss: 0.797858259, Training Accuracy: 76.984\n",
            "Worker 4, [09/9]: Training Loss: 0.734951475, Training Accuracy: 78.288\n",
            "Time taken for training worker 4: 0:00:47.953386\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000909\n",
            "Local Step 09: Test Loss: 2.017951222, Test Accuracy: 52.010\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.723265460, Training Accuracy: 54.928\n",
            "Worker 1, [02/9]: Training Loss: 1.666332474, Training Accuracy: 54.888\n",
            "Worker 1, [03/9]: Training Loss: 1.586547862, Training Accuracy: 56.672\n",
            "Worker 1, [04/9]: Training Loss: 1.496108742, Training Accuracy: 58.072\n",
            "Worker 1, [05/9]: Training Loss: 1.461506184, Training Accuracy: 58.992\n",
            "Worker 1, [06/9]: Training Loss: 1.444902062, Training Accuracy: 59.480\n",
            "Worker 1, [07/9]: Training Loss: 1.458992650, Training Accuracy: 58.760\n",
            "Worker 1, [08/9]: Training Loss: 1.452065677, Training Accuracy: 58.968\n",
            "Worker 1, [09/9]: Training Loss: 1.471761213, Training Accuracy: 58.560\n",
            "Time taken for training worker 1: 0:00:49.591320\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.019862732, Training Accuracy: 46.784\n",
            "Worker 2, [02/9]: Training Loss: 1.811461653, Training Accuracy: 50.808\n",
            "Worker 2, [03/9]: Training Loss: 1.677788676, Training Accuracy: 53.992\n",
            "Worker 2, [04/9]: Training Loss: 1.568470116, Training Accuracy: 56.312\n",
            "Worker 2, [05/9]: Training Loss: 1.482145807, Training Accuracy: 58.032\n",
            "Worker 2, [06/9]: Training Loss: 1.443637102, Training Accuracy: 58.760\n",
            "Worker 2, [07/9]: Training Loss: 1.459707466, Training Accuracy: 58.288\n",
            "Worker 2, [08/9]: Training Loss: 1.464685920, Training Accuracy: 58.680\n",
            "Worker 2, [09/9]: Training Loss: 1.506750544, Training Accuracy: 57.664\n",
            "Time taken for training worker 2: 0:00:49.533501\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.099721902, Training Accuracy: 45.616\n",
            "Worker 3, [02/9]: Training Loss: 1.814618252, Training Accuracy: 50.640\n",
            "Worker 3, [03/9]: Training Loss: 1.639224499, Training Accuracy: 54.616\n",
            "Worker 3, [04/9]: Training Loss: 1.538810652, Training Accuracy: 56.328\n",
            "Worker 3, [05/9]: Training Loss: 1.451705344, Training Accuracy: 58.536\n",
            "Worker 3, [06/9]: Training Loss: 1.425525898, Training Accuracy: 59.576\n",
            "Worker 3, [07/9]: Training Loss: 1.436225340, Training Accuracy: 59.368\n",
            "Worker 3, [08/9]: Training Loss: 1.449284611, Training Accuracy: 58.552\n",
            "Worker 3, [09/9]: Training Loss: 1.462065433, Training Accuracy: 58.264\n",
            "Time taken for training worker 3: 0:00:47.418108\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.938015059, Training Accuracy: 48.152\n",
            "Worker 4, [02/9]: Training Loss: 1.747481717, Training Accuracy: 51.784\n",
            "Worker 4, [03/9]: Training Loss: 1.587517089, Training Accuracy: 55.304\n",
            "Worker 4, [04/9]: Training Loss: 1.497228163, Training Accuracy: 58.400\n",
            "Worker 4, [05/9]: Training Loss: 1.409540702, Training Accuracy: 59.928\n",
            "Worker 4, [06/9]: Training Loss: 1.372417503, Training Accuracy: 60.912\n",
            "Worker 4, [07/9]: Training Loss: 1.394956491, Training Accuracy: 60.168\n",
            "Worker 4, [08/9]: Training Loss: 1.435868314, Training Accuracy: 59.080\n",
            "Worker 4, [09/9]: Training Loss: 1.453648932, Training Accuracy: 58.216\n",
            "Time taken for training worker 4: 0:00:48.849206\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000578\n",
            "Local Step 10: Test Loss: 2.201271897, Test Accuracy: 45.910\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.944707174, Training Accuracy: 48.328\n",
            "Worker 1, [02/9]: Training Loss: 1.704464013, Training Accuracy: 53.048\n",
            "Worker 1, [03/9]: Training Loss: 1.497555475, Training Accuracy: 58.072\n",
            "Worker 1, [04/9]: Training Loss: 1.359056185, Training Accuracy: 60.976\n",
            "Worker 1, [05/9]: Training Loss: 1.181220710, Training Accuracy: 66.000\n",
            "Worker 1, [06/9]: Training Loss: 0.998727633, Training Accuracy: 70.736\n",
            "Worker 1, [07/9]: Training Loss: 0.866471990, Training Accuracy: 74.712\n",
            "Worker 1, [08/9]: Training Loss: 0.758289173, Training Accuracy: 77.832\n",
            "Worker 1, [09/9]: Training Loss: 0.693995926, Training Accuracy: 79.928\n",
            "Time taken for training worker 1: 0:00:47.299762\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.004343729, Training Accuracy: 46.952\n",
            "Worker 2, [02/9]: Training Loss: 1.713024865, Training Accuracy: 53.048\n",
            "Worker 2, [03/9]: Training Loss: 1.525342156, Training Accuracy: 57.616\n",
            "Worker 2, [04/9]: Training Loss: 1.374688630, Training Accuracy: 60.616\n",
            "Worker 2, [05/9]: Training Loss: 1.196287465, Training Accuracy: 65.672\n",
            "Worker 2, [06/9]: Training Loss: 1.021216645, Training Accuracy: 70.376\n",
            "Worker 2, [07/9]: Training Loss: 0.868454743, Training Accuracy: 74.840\n",
            "Worker 2, [08/9]: Training Loss: 0.749134241, Training Accuracy: 78.376\n",
            "Worker 2, [09/9]: Training Loss: 0.698417186, Training Accuracy: 79.640\n",
            "Time taken for training worker 2: 0:00:47.844338\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.005179350, Training Accuracy: 45.904\n",
            "Worker 3, [02/9]: Training Loss: 1.697134587, Training Accuracy: 53.288\n",
            "Worker 3, [03/9]: Training Loss: 1.540926231, Training Accuracy: 56.752\n",
            "Worker 3, [04/9]: Training Loss: 1.383514304, Training Accuracy: 60.600\n",
            "Worker 3, [05/9]: Training Loss: 1.204813051, Training Accuracy: 65.048\n",
            "Worker 3, [06/9]: Training Loss: 1.016418514, Training Accuracy: 69.968\n",
            "Worker 3, [07/9]: Training Loss: 0.871068540, Training Accuracy: 74.064\n",
            "Worker 3, [08/9]: Training Loss: 0.776495952, Training Accuracy: 77.520\n",
            "Worker 3, [09/9]: Training Loss: 0.703536890, Training Accuracy: 79.624\n",
            "Time taken for training worker 3: 0:00:47.583307\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.981913478, Training Accuracy: 47.216\n",
            "Worker 4, [02/9]: Training Loss: 1.685796921, Training Accuracy: 52.912\n",
            "Worker 4, [03/9]: Training Loss: 1.511124250, Training Accuracy: 57.912\n",
            "Worker 4, [04/9]: Training Loss: 1.324222379, Training Accuracy: 62.536\n",
            "Worker 4, [05/9]: Training Loss: 1.163983088, Training Accuracy: 66.488\n",
            "Worker 4, [06/9]: Training Loss: 1.001950188, Training Accuracy: 70.480\n",
            "Worker 4, [07/9]: Training Loss: 0.854073547, Training Accuracy: 75.016\n",
            "Worker 4, [08/9]: Training Loss: 0.739953386, Training Accuracy: 78.544\n",
            "Worker 4, [09/9]: Training Loss: 0.686503646, Training Accuracy: 80.048\n",
            "Time taken for training worker 4: 0:00:48.110223\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000681\n",
            "Local Step 11: Test Loss: 2.015457050, Test Accuracy: 52.920\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.680341295, Training Accuracy: 55.960\n",
            "Worker 1, [02/9]: Training Loss: 1.623949884, Training Accuracy: 56.160\n",
            "Worker 1, [03/9]: Training Loss: 1.521336150, Training Accuracy: 58.168\n",
            "Worker 1, [04/9]: Training Loss: 1.445129714, Training Accuracy: 59.704\n",
            "Worker 1, [05/9]: Training Loss: 1.400399297, Training Accuracy: 60.200\n",
            "Worker 1, [06/9]: Training Loss: 1.371142825, Training Accuracy: 61.248\n",
            "Worker 1, [07/9]: Training Loss: 1.396288964, Training Accuracy: 60.472\n",
            "Worker 1, [08/9]: Training Loss: 1.432591079, Training Accuracy: 59.744\n",
            "Worker 1, [09/9]: Training Loss: 1.443166846, Training Accuracy: 58.688\n",
            "Time taken for training worker 1: 0:00:48.636799\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.031735440, Training Accuracy: 46.768\n",
            "Worker 2, [02/9]: Training Loss: 1.803675261, Training Accuracy: 50.912\n",
            "Worker 2, [03/9]: Training Loss: 1.628429679, Training Accuracy: 54.920\n",
            "Worker 2, [04/9]: Training Loss: 1.501811072, Training Accuracy: 57.792\n",
            "Worker 2, [05/9]: Training Loss: 1.429639548, Training Accuracy: 59.592\n",
            "Worker 2, [06/9]: Training Loss: 1.415581715, Training Accuracy: 59.912\n",
            "Worker 2, [07/9]: Training Loss: 1.411035203, Training Accuracy: 59.656\n",
            "Worker 2, [08/9]: Training Loss: 1.430355114, Training Accuracy: 59.024\n",
            "Worker 2, [09/9]: Training Loss: 1.425653057, Training Accuracy: 59.248\n",
            "Time taken for training worker 2: 0:00:49.720342\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 1.967174427, Training Accuracy: 47.888\n",
            "Worker 3, [02/9]: Training Loss: 1.768182045, Training Accuracy: 51.272\n",
            "Worker 3, [03/9]: Training Loss: 1.597436757, Training Accuracy: 55.544\n",
            "Worker 3, [04/9]: Training Loss: 1.479621039, Training Accuracy: 57.976\n",
            "Worker 3, [05/9]: Training Loss: 1.408724970, Training Accuracy: 59.736\n",
            "Worker 3, [06/9]: Training Loss: 1.378881847, Training Accuracy: 60.728\n",
            "Worker 3, [07/9]: Training Loss: 1.387405508, Training Accuracy: 60.520\n",
            "Worker 3, [08/9]: Training Loss: 1.414005953, Training Accuracy: 59.504\n",
            "Worker 3, [09/9]: Training Loss: 1.407530867, Training Accuracy: 59.520\n",
            "Time taken for training worker 3: 0:00:47.235530\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.937295099, Training Accuracy: 48.248\n",
            "Worker 4, [02/9]: Training Loss: 1.739217174, Training Accuracy: 51.952\n",
            "Worker 4, [03/9]: Training Loss: 1.568333018, Training Accuracy: 56.080\n",
            "Worker 4, [04/9]: Training Loss: 1.456984689, Training Accuracy: 58.944\n",
            "Worker 4, [05/9]: Training Loss: 1.364668972, Training Accuracy: 60.856\n",
            "Worker 4, [06/9]: Training Loss: 1.352443045, Training Accuracy: 61.160\n",
            "Worker 4, [07/9]: Training Loss: 1.355957645, Training Accuracy: 61.296\n",
            "Worker 4, [08/9]: Training Loss: 1.371236023, Training Accuracy: 60.392\n",
            "Worker 4, [09/9]: Training Loss: 1.396730249, Training Accuracy: 60.392\n",
            "Time taken for training worker 4: 0:00:47.084513\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000593\n",
            "Local Step 12: Test Loss: 2.136757260, Test Accuracy: 46.860\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.944965380, Training Accuracy: 47.864\n",
            "Worker 1, [02/9]: Training Loss: 1.641726037, Training Accuracy: 54.824\n",
            "Worker 1, [03/9]: Training Loss: 1.484793159, Training Accuracy: 58.440\n",
            "Worker 1, [04/9]: Training Loss: 1.315013295, Training Accuracy: 62.504\n",
            "Worker 1, [05/9]: Training Loss: 1.125899754, Training Accuracy: 67.368\n",
            "Worker 1, [06/9]: Training Loss: 0.967797194, Training Accuracy: 71.904\n",
            "Worker 1, [07/9]: Training Loss: 0.823260504, Training Accuracy: 75.824\n",
            "Worker 1, [08/9]: Training Loss: 0.704684099, Training Accuracy: 79.272\n",
            "Worker 1, [09/9]: Training Loss: 0.656848818, Training Accuracy: 81.032\n",
            "Time taken for training worker 1: 0:00:49.488911\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.969055297, Training Accuracy: 47.000\n",
            "Worker 2, [02/9]: Training Loss: 1.684995777, Training Accuracy: 53.704\n",
            "Worker 2, [03/9]: Training Loss: 1.492182228, Training Accuracy: 57.672\n",
            "Worker 2, [04/9]: Training Loss: 1.321321495, Training Accuracy: 62.176\n",
            "Worker 2, [05/9]: Training Loss: 1.155888498, Training Accuracy: 66.392\n",
            "Worker 2, [06/9]: Training Loss: 0.972848061, Training Accuracy: 71.600\n",
            "Worker 2, [07/9]: Training Loss: 0.836870148, Training Accuracy: 75.464\n",
            "Worker 2, [08/9]: Training Loss: 0.737934822, Training Accuracy: 78.448\n",
            "Worker 2, [09/9]: Training Loss: 0.662092372, Training Accuracy: 81.120\n",
            "Time taken for training worker 2: 0:00:48.797186\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 1.940305508, Training Accuracy: 47.344\n",
            "Worker 3, [02/9]: Training Loss: 1.666462494, Training Accuracy: 54.024\n",
            "Worker 3, [03/9]: Training Loss: 1.494289116, Training Accuracy: 57.504\n",
            "Worker 3, [04/9]: Training Loss: 1.331862077, Training Accuracy: 61.456\n",
            "Worker 3, [05/9]: Training Loss: 1.164428389, Training Accuracy: 66.072\n",
            "Worker 3, [06/9]: Training Loss: 0.984529621, Training Accuracy: 71.096\n",
            "Worker 3, [07/9]: Training Loss: 0.822962339, Training Accuracy: 75.936\n",
            "Worker 3, [08/9]: Training Loss: 0.723545666, Training Accuracy: 78.928\n",
            "Worker 3, [09/9]: Training Loss: 0.653379604, Training Accuracy: 80.880\n",
            "Time taken for training worker 3: 0:00:46.934734\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.938106106, Training Accuracy: 47.720\n",
            "Worker 4, [02/9]: Training Loss: 1.689452890, Training Accuracy: 53.064\n",
            "Worker 4, [03/9]: Training Loss: 1.487571120, Training Accuracy: 58.200\n",
            "Worker 4, [04/9]: Training Loss: 1.317243721, Training Accuracy: 62.592\n",
            "Worker 4, [05/9]: Training Loss: 1.102390191, Training Accuracy: 68.216\n",
            "Worker 4, [06/9]: Training Loss: 0.968292328, Training Accuracy: 71.672\n",
            "Worker 4, [07/9]: Training Loss: 0.810315257, Training Accuracy: 76.336\n",
            "Worker 4, [08/9]: Training Loss: 0.698106246, Training Accuracy: 79.920\n",
            "Worker 4, [09/9]: Training Loss: 0.641086020, Training Accuracy: 81.512\n",
            "Time taken for training worker 4: 0:00:47.048028\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000581\n",
            "Local Step 13: Test Loss: 2.002151732, Test Accuracy: 53.070\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.675007124, Training Accuracy: 56.208\n",
            "Worker 1, [02/9]: Training Loss: 1.583476436, Training Accuracy: 57.352\n",
            "Worker 1, [03/9]: Training Loss: 1.488261587, Training Accuracy: 58.656\n",
            "Worker 1, [04/9]: Training Loss: 1.419971590, Training Accuracy: 59.880\n",
            "Worker 1, [05/9]: Training Loss: 1.364573758, Training Accuracy: 61.392\n",
            "Worker 1, [06/9]: Training Loss: 1.335266060, Training Accuracy: 61.848\n",
            "Worker 1, [07/9]: Training Loss: 1.355662503, Training Accuracy: 61.504\n",
            "Worker 1, [08/9]: Training Loss: 1.371630121, Training Accuracy: 60.312\n",
            "Worker 1, [09/9]: Training Loss: 1.381788685, Training Accuracy: 60.440\n",
            "Time taken for training worker 1: 0:00:47.617220\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.000687071, Training Accuracy: 47.608\n",
            "Worker 2, [02/9]: Training Loss: 1.762794189, Training Accuracy: 52.680\n",
            "Worker 2, [03/9]: Training Loss: 1.592823583, Training Accuracy: 56.080\n",
            "Worker 2, [04/9]: Training Loss: 1.468972330, Training Accuracy: 58.784\n",
            "Worker 2, [05/9]: Training Loss: 1.399925944, Training Accuracy: 60.672\n",
            "Worker 2, [06/9]: Training Loss: 1.366345640, Training Accuracy: 60.944\n",
            "Worker 2, [07/9]: Training Loss: 1.389250326, Training Accuracy: 60.312\n",
            "Worker 2, [08/9]: Training Loss: 1.385924815, Training Accuracy: 59.896\n",
            "Worker 2, [09/9]: Training Loss: 1.379527181, Training Accuracy: 60.592\n",
            "Time taken for training worker 2: 0:00:46.758142\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 1.998418844, Training Accuracy: 46.976\n",
            "Worker 3, [02/9]: Training Loss: 1.730595586, Training Accuracy: 51.952\n",
            "Worker 3, [03/9]: Training Loss: 1.590313851, Training Accuracy: 55.600\n",
            "Worker 3, [04/9]: Training Loss: 1.454557531, Training Accuracy: 58.856\n",
            "Worker 3, [05/9]: Training Loss: 1.373168370, Training Accuracy: 61.096\n",
            "Worker 3, [06/9]: Training Loss: 1.372205784, Training Accuracy: 60.224\n",
            "Worker 3, [07/9]: Training Loss: 1.354142529, Training Accuracy: 61.272\n",
            "Worker 3, [08/9]: Training Loss: 1.377432536, Training Accuracy: 59.848\n",
            "Worker 3, [09/9]: Training Loss: 1.379840794, Training Accuracy: 60.416\n",
            "Time taken for training worker 3: 0:00:47.161838\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.887696294, Training Accuracy: 49.080\n",
            "Worker 4, [02/9]: Training Loss: 1.698797809, Training Accuracy: 53.248\n",
            "Worker 4, [03/9]: Training Loss: 1.539278311, Training Accuracy: 56.736\n",
            "Worker 4, [04/9]: Training Loss: 1.428970424, Training Accuracy: 59.472\n",
            "Worker 4, [05/9]: Training Loss: 1.342440513, Training Accuracy: 61.256\n",
            "Worker 4, [06/9]: Training Loss: 1.328217450, Training Accuracy: 61.696\n",
            "Worker 4, [07/9]: Training Loss: 1.327528774, Training Accuracy: 61.752\n",
            "Worker 4, [08/9]: Training Loss: 1.358220888, Training Accuracy: 61.000\n",
            "Worker 4, [09/9]: Training Loss: 1.372875936, Training Accuracy: 60.424\n",
            "Time taken for training worker 4: 0:00:47.073906\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000980\n",
            "Local Step 14: Test Loss: 2.269809658, Test Accuracy: 45.220\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.927081862, Training Accuracy: 48.888\n",
            "Worker 1, [02/9]: Training Loss: 1.627187046, Training Accuracy: 55.968\n",
            "Worker 1, [03/9]: Training Loss: 1.446691435, Training Accuracy: 59.224\n",
            "Worker 1, [04/9]: Training Loss: 1.282590480, Training Accuracy: 63.224\n",
            "Worker 1, [05/9]: Training Loss: 1.131952331, Training Accuracy: 67.384\n",
            "Worker 1, [06/9]: Training Loss: 0.933999278, Training Accuracy: 72.744\n",
            "Worker 1, [07/9]: Training Loss: 0.793728380, Training Accuracy: 76.736\n",
            "Worker 1, [08/9]: Training Loss: 0.687490762, Training Accuracy: 79.864\n",
            "Worker 1, [09/9]: Training Loss: 0.625198766, Training Accuracy: 81.656\n",
            "Time taken for training worker 1: 0:00:49.868600\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.924790711, Training Accuracy: 48.352\n",
            "Worker 2, [02/9]: Training Loss: 1.651493052, Training Accuracy: 53.816\n",
            "Worker 2, [03/9]: Training Loss: 1.468060843, Training Accuracy: 58.248\n",
            "Worker 2, [04/9]: Training Loss: 1.300731898, Training Accuracy: 62.872\n",
            "Worker 2, [05/9]: Training Loss: 1.118514031, Training Accuracy: 67.792\n",
            "Worker 2, [06/9]: Training Loss: 0.930069411, Training Accuracy: 72.880\n",
            "Worker 2, [07/9]: Training Loss: 0.796573679, Training Accuracy: 76.368\n",
            "Worker 2, [08/9]: Training Loss: 0.692134555, Training Accuracy: 79.760\n",
            "Worker 2, [09/9]: Training Loss: 0.633482390, Training Accuracy: 81.712\n",
            "Time taken for training worker 2: 0:00:49.513380\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 1.920646354, Training Accuracy: 48.000\n",
            "Worker 3, [02/9]: Training Loss: 1.635831273, Training Accuracy: 53.968\n",
            "Worker 3, [03/9]: Training Loss: 1.454591615, Training Accuracy: 58.712\n",
            "Worker 3, [04/9]: Training Loss: 1.311620298, Training Accuracy: 61.808\n",
            "Worker 3, [05/9]: Training Loss: 1.101327143, Training Accuracy: 67.704\n",
            "Worker 3, [06/9]: Training Loss: 0.939130926, Training Accuracy: 72.096\n",
            "Worker 3, [07/9]: Training Loss: 0.787209385, Training Accuracy: 76.576\n",
            "Worker 3, [08/9]: Training Loss: 0.693039476, Training Accuracy: 79.824\n",
            "Worker 3, [09/9]: Training Loss: 0.624439678, Training Accuracy: 81.976\n",
            "Time taken for training worker 3: 0:00:47.120799\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.926432821, Training Accuracy: 48.744\n",
            "Worker 4, [02/9]: Training Loss: 1.626265833, Training Accuracy: 54.616\n",
            "Worker 4, [03/9]: Training Loss: 1.435559316, Training Accuracy: 59.240\n",
            "Worker 4, [04/9]: Training Loss: 1.262090917, Training Accuracy: 64.248\n",
            "Worker 4, [05/9]: Training Loss: 1.071216569, Training Accuracy: 68.544\n",
            "Worker 4, [06/9]: Training Loss: 0.918038819, Training Accuracy: 73.096\n",
            "Worker 4, [07/9]: Training Loss: 0.766884928, Training Accuracy: 77.296\n",
            "Worker 4, [08/9]: Training Loss: 0.678115494, Training Accuracy: 80.320\n",
            "Worker 4, [09/9]: Training Loss: 0.615828352, Training Accuracy: 82.160\n",
            "Time taken for training worker 4: 0:00:49.975704\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000713\n",
            "Local Step 15: Test Loss: 2.025315075, Test Accuracy: 52.880\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.641170395, Training Accuracy: 56.944\n",
            "Worker 1, [02/9]: Training Loss: 1.549996505, Training Accuracy: 57.936\n",
            "Worker 1, [03/9]: Training Loss: 1.473365091, Training Accuracy: 59.072\n",
            "Worker 1, [04/9]: Training Loss: 1.389502635, Training Accuracy: 60.616\n",
            "Worker 1, [05/9]: Training Loss: 1.316641911, Training Accuracy: 63.160\n",
            "Worker 1, [06/9]: Training Loss: 1.315564252, Training Accuracy: 62.584\n",
            "Worker 1, [07/9]: Training Loss: 1.359376335, Training Accuracy: 60.984\n",
            "Worker 1, [08/9]: Training Loss: 1.380258526, Training Accuracy: 59.920\n",
            "Worker 1, [09/9]: Training Loss: 1.346463297, Training Accuracy: 61.528\n",
            "Time taken for training worker 1: 0:00:47.424005\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 1.967673629, Training Accuracy: 48.432\n",
            "Worker 2, [02/9]: Training Loss: 1.731373033, Training Accuracy: 53.248\n",
            "Worker 2, [03/9]: Training Loss: 1.582974736, Training Accuracy: 56.000\n",
            "Worker 2, [04/9]: Training Loss: 1.460591565, Training Accuracy: 58.624\n",
            "Worker 2, [05/9]: Training Loss: 1.365509731, Training Accuracy: 61.128\n",
            "Worker 2, [06/9]: Training Loss: 1.341642115, Training Accuracy: 61.536\n",
            "Worker 2, [07/9]: Training Loss: 1.331556975, Training Accuracy: 61.384\n",
            "Worker 2, [08/9]: Training Loss: 1.396621009, Training Accuracy: 59.936\n",
            "Worker 2, [09/9]: Training Loss: 1.376472932, Training Accuracy: 60.912\n",
            "Time taken for training worker 2: 0:00:50.786204\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 1.919901674, Training Accuracy: 48.096\n",
            "Worker 3, [02/9]: Training Loss: 1.732106850, Training Accuracy: 51.960\n",
            "Worker 3, [03/9]: Training Loss: 1.552751306, Training Accuracy: 56.432\n",
            "Worker 3, [04/9]: Training Loss: 1.430222649, Training Accuracy: 59.624\n",
            "Worker 3, [05/9]: Training Loss: 1.356287766, Training Accuracy: 61.312\n",
            "Worker 3, [06/9]: Training Loss: 1.344667855, Training Accuracy: 61.352\n",
            "Worker 3, [07/9]: Training Loss: 1.331408950, Training Accuracy: 61.760\n",
            "Worker 3, [08/9]: Training Loss: 1.360904387, Training Accuracy: 60.664\n",
            "Worker 3, [09/9]: Training Loss: 1.374478219, Training Accuracy: 60.224\n",
            "Time taken for training worker 3: 0:00:47.300604\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 1.971999051, Training Accuracy: 47.832\n",
            "Worker 4, [02/9]: Training Loss: 1.690771083, Training Accuracy: 53.352\n",
            "Worker 4, [03/9]: Training Loss: 1.533443765, Training Accuracy: 57.688\n",
            "Worker 4, [04/9]: Training Loss: 1.417584452, Training Accuracy: 59.904\n",
            "Worker 4, [05/9]: Training Loss: 1.309540727, Training Accuracy: 62.400\n",
            "Worker 4, [06/9]: Training Loss: 1.294179297, Training Accuracy: 62.528\n",
            "Worker 4, [07/9]: Training Loss: 1.301675406, Training Accuracy: 62.936\n",
            "Worker 4, [08/9]: Training Loss: 1.326802602, Training Accuracy: 61.760\n",
            "Worker 4, [09/9]: Training Loss: 1.339402759, Training Accuracy: 61.320\n",
            "Time taken for training worker 4: 0:00:47.797102\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000836\n",
            "Local Step 16: Test Loss: 2.215590182, Test Accuracy: 45.980\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:49.491078\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:32\n",
            "==================================================\n",
            "Worker 1, [01/4]: Training Loss: 4.529302488, Training Accuracy: 2.280\n",
            "Worker 1, [02/4]: Training Loss: 4.151918995, Training Accuracy: 6.192\n",
            "Worker 1, [03/4]: Training Loss: 3.923752234, Training Accuracy: 9.264\n",
            "Worker 1, [04/4]: Training Loss: 3.760815155, Training Accuracy: 12.424\n",
            "Time taken for training worker 1: 0:00:21.983998\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 4.529092616, Training Accuracy: 2.448\n",
            "Worker 2, [02/4]: Training Loss: 4.145936763, Training Accuracy: 6.360\n",
            "Worker 2, [03/4]: Training Loss: 3.941606096, Training Accuracy: 8.928\n",
            "Worker 2, [04/4]: Training Loss: 3.798119508, Training Accuracy: 11.328\n",
            "Time taken for training worker 2: 0:00:20.638323\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 4.526104161, Training Accuracy: 2.192\n",
            "Worker 3, [02/4]: Training Loss: 4.150162182, Training Accuracy: 5.888\n",
            "Worker 3, [03/4]: Training Loss: 3.934698431, Training Accuracy: 8.840\n",
            "Worker 3, [04/4]: Training Loss: 3.776400223, Training Accuracy: 11.768\n",
            "Time taken for training worker 3: 0:00:21.406507\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 4.515389924, Training Accuracy: 2.568\n",
            "Worker 4, [02/4]: Training Loss: 4.126711937, Training Accuracy: 6.768\n",
            "Worker 4, [03/4]: Training Loss: 3.916603908, Training Accuracy: 9.336\n",
            "Worker 4, [04/4]: Training Loss: 3.750706605, Training Accuracy: 12.528\n",
            "Time taken for training worker 4: 0:00:20.875589\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000618\n",
            "Local Step 01: Test Loss: 3.790356849, Test Accuracy: 13.270\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 3.829079858, Training Accuracy: 12.056\n",
            "Worker 1, [02/4]: Training Loss: 3.779517697, Training Accuracy: 12.400\n",
            "Worker 1, [03/4]: Training Loss: 3.764270435, Training Accuracy: 11.912\n",
            "Worker 1, [04/4]: Training Loss: 3.707255973, Training Accuracy: 12.336\n",
            "Time taken for training worker 1: 0:00:21.571281\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 3.678747003, Training Accuracy: 13.360\n",
            "Worker 2, [02/4]: Training Loss: 3.560807479, Training Accuracy: 15.896\n",
            "Worker 2, [03/4]: Training Loss: 3.533104709, Training Accuracy: 15.792\n",
            "Worker 2, [04/4]: Training Loss: 3.487021554, Training Accuracy: 16.248\n",
            "Time taken for training worker 2: 0:00:22.637477\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 3.569568767, Training Accuracy: 14.704\n",
            "Worker 3, [02/4]: Training Loss: 3.335845486, Training Accuracy: 19.320\n",
            "Worker 3, [03/4]: Training Loss: 3.334137873, Training Accuracy: 19.072\n",
            "Worker 3, [04/4]: Training Loss: 3.326988032, Training Accuracy: 18.400\n",
            "Time taken for training worker 3: 0:00:21.141272\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 3.328939928, Training Accuracy: 19.792\n",
            "Worker 4, [02/4]: Training Loss: 3.125679898, Training Accuracy: 23.320\n",
            "Worker 4, [03/4]: Training Loss: 3.137580260, Training Accuracy: 22.720\n",
            "Worker 4, [04/4]: Training Loss: 3.152912825, Training Accuracy: 22.208\n",
            "Time taken for training worker 4: 0:00:21.644449\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000658\n",
            "Local Step 02: Test Loss: 3.113764386, Test Accuracy: 23.510\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 3.221516047, Training Accuracy: 21.432\n",
            "Worker 1, [02/4]: Training Loss: 3.044507066, Training Accuracy: 24.928\n",
            "Worker 1, [03/4]: Training Loss: 2.838844045, Training Accuracy: 28.304\n",
            "Worker 1, [04/4]: Training Loss: 2.626917789, Training Accuracy: 32.664\n",
            "Time taken for training worker 1: 0:00:22.828936\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 3.079083418, Training Accuracy: 24.072\n",
            "Worker 2, [02/4]: Training Loss: 2.918005660, Training Accuracy: 27.216\n",
            "Worker 2, [03/4]: Training Loss: 2.691336921, Training Accuracy: 31.392\n",
            "Worker 2, [04/4]: Training Loss: 2.469644272, Training Accuracy: 35.712\n",
            "Time taken for training worker 2: 0:00:21.378111\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.952655987, Training Accuracy: 25.456\n",
            "Worker 3, [02/4]: Training Loss: 2.787304680, Training Accuracy: 29.216\n",
            "Worker 3, [03/4]: Training Loss: 2.555899278, Training Accuracy: 33.408\n",
            "Worker 3, [04/4]: Training Loss: 2.347682626, Training Accuracy: 38.288\n",
            "Time taken for training worker 3: 0:00:20.650057\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.807673078, Training Accuracy: 28.824\n",
            "Worker 4, [02/4]: Training Loss: 2.634295113, Training Accuracy: 32.384\n",
            "Worker 4, [03/4]: Training Loss: 2.438570689, Training Accuracy: 36.960\n",
            "Worker 4, [04/4]: Training Loss: 2.206428572, Training Accuracy: 41.544\n",
            "Time taken for training worker 4: 0:00:21.394517\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000647\n",
            "Local Step 03: Test Loss: 2.355597962, Test Accuracy: 38.740\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.492526823, Training Accuracy: 36.312\n",
            "Worker 1, [02/4]: Training Loss: 2.458100565, Training Accuracy: 37.008\n",
            "Worker 1, [03/4]: Training Loss: 2.494930165, Training Accuracy: 35.808\n",
            "Worker 1, [04/4]: Training Loss: 2.554466487, Training Accuracy: 33.992\n",
            "Time taken for training worker 1: 0:00:21.945318\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.674308728, Training Accuracy: 31.608\n",
            "Worker 2, [02/4]: Training Loss: 2.448227502, Training Accuracy: 36.728\n",
            "Worker 2, [03/4]: Training Loss: 2.442526044, Training Accuracy: 36.664\n",
            "Worker 2, [04/4]: Training Loss: 2.505970341, Training Accuracy: 35.136\n",
            "Time taken for training worker 2: 0:00:23.292690\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.612038414, Training Accuracy: 32.376\n",
            "Worker 3, [02/4]: Training Loss: 2.389239503, Training Accuracy: 37.824\n",
            "Worker 3, [03/4]: Training Loss: 2.420471829, Training Accuracy: 36.720\n",
            "Worker 3, [04/4]: Training Loss: 2.466913232, Training Accuracy: 35.976\n",
            "Time taken for training worker 3: 0:00:23.331296\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.528627952, Training Accuracy: 34.496\n",
            "Worker 4, [02/4]: Training Loss: 2.301153725, Training Accuracy: 39.408\n",
            "Worker 4, [03/4]: Training Loss: 2.326584835, Training Accuracy: 38.960\n",
            "Worker 4, [04/4]: Training Loss: 2.378946876, Training Accuracy: 37.872\n",
            "Time taken for training worker 4: 0:00:21.275943\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000830\n",
            "Local Step 04: Test Loss: 2.476776438, Test Accuracy: 36.690\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.565607685, Training Accuracy: 34.120\n",
            "Worker 1, [02/4]: Training Loss: 2.384531166, Training Accuracy: 37.608\n",
            "Worker 1, [03/4]: Training Loss: 2.161484877, Training Accuracy: 42.776\n",
            "Worker 1, [04/4]: Training Loss: 1.912109104, Training Accuracy: 48.400\n",
            "Time taken for training worker 1: 0:00:21.351620\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.519405926, Training Accuracy: 35.296\n",
            "Worker 2, [02/4]: Training Loss: 2.318275023, Training Accuracy: 38.880\n",
            "Worker 2, [03/4]: Training Loss: 2.086814305, Training Accuracy: 43.480\n",
            "Worker 2, [04/4]: Training Loss: 1.851531651, Training Accuracy: 49.952\n",
            "Time taken for training worker 2: 0:00:21.122492\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.495564488, Training Accuracy: 35.056\n",
            "Worker 3, [02/4]: Training Loss: 2.317770811, Training Accuracy: 38.664\n",
            "Worker 3, [03/4]: Training Loss: 2.043745099, Training Accuracy: 44.776\n",
            "Worker 3, [04/4]: Training Loss: 1.805522891, Training Accuracy: 50.696\n",
            "Time taken for training worker 3: 0:00:20.936892\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.403795124, Training Accuracy: 37.544\n",
            "Worker 4, [02/4]: Training Loss: 2.219615356, Training Accuracy: 41.008\n",
            "Worker 4, [03/4]: Training Loss: 1.977903206, Training Accuracy: 46.616\n",
            "Worker 4, [04/4]: Training Loss: 1.749101553, Training Accuracy: 52.016\n",
            "Time taken for training worker 4: 0:00:21.098670\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000614\n",
            "Local Step 05: Test Loss: 2.094635175, Test Accuracy: 45.590\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.148659825, Training Accuracy: 43.744\n",
            "Worker 1, [02/4]: Training Loss: 2.088750072, Training Accuracy: 44.496\n",
            "Worker 1, [03/4]: Training Loss: 2.125600138, Training Accuracy: 43.880\n",
            "Worker 1, [04/4]: Training Loss: 2.177849209, Training Accuracy: 42.400\n",
            "Time taken for training worker 1: 0:00:21.147241\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.341585410, Training Accuracy: 39.504\n",
            "Worker 2, [02/4]: Training Loss: 2.103916026, Training Accuracy: 43.984\n",
            "Worker 2, [03/4]: Training Loss: 2.099575869, Training Accuracy: 44.256\n",
            "Worker 2, [04/4]: Training Loss: 2.176975893, Training Accuracy: 41.936\n",
            "Time taken for training worker 2: 0:00:20.969433\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.300614828, Training Accuracy: 38.936\n",
            "Worker 3, [02/4]: Training Loss: 2.066577463, Training Accuracy: 44.272\n",
            "Worker 3, [03/4]: Training Loss: 2.064425416, Training Accuracy: 44.400\n",
            "Worker 3, [04/4]: Training Loss: 2.123779365, Training Accuracy: 42.536\n",
            "Time taken for training worker 3: 0:00:20.604475\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.185089576, Training Accuracy: 41.992\n",
            "Worker 4, [02/4]: Training Loss: 1.998078956, Training Accuracy: 46.320\n",
            "Worker 4, [03/4]: Training Loss: 1.993149004, Training Accuracy: 45.784\n",
            "Worker 4, [04/4]: Training Loss: 2.072187601, Training Accuracy: 44.240\n",
            "Time taken for training worker 4: 0:00:20.568160\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000613\n",
            "Local Step 06: Test Loss: 2.278050918, Test Accuracy: 41.060\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.312338817, Training Accuracy: 39.648\n",
            "Worker 1, [02/4]: Training Loss: 2.101562357, Training Accuracy: 43.792\n",
            "Worker 1, [03/4]: Training Loss: 1.841352782, Training Accuracy: 50.024\n",
            "Worker 1, [04/4]: Training Loss: 1.600232146, Training Accuracy: 55.712\n",
            "Time taken for training worker 1: 0:00:22.465209\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.286386968, Training Accuracy: 40.152\n",
            "Worker 2, [02/4]: Training Loss: 2.091058527, Training Accuracy: 43.616\n",
            "Worker 2, [03/4]: Training Loss: 1.818265312, Training Accuracy: 50.712\n",
            "Worker 2, [04/4]: Training Loss: 1.571286898, Training Accuracy: 56.448\n",
            "Time taken for training worker 2: 0:00:22.073120\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.262397165, Training Accuracy: 39.912\n",
            "Worker 3, [02/4]: Training Loss: 2.045742991, Training Accuracy: 44.776\n",
            "Worker 3, [03/4]: Training Loss: 1.796089116, Training Accuracy: 50.568\n",
            "Worker 3, [04/4]: Training Loss: 1.549324553, Training Accuracy: 56.848\n",
            "Time taken for training worker 3: 0:00:20.825810\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.244442125, Training Accuracy: 40.928\n",
            "Worker 4, [02/4]: Training Loss: 2.003742810, Training Accuracy: 45.808\n",
            "Worker 4, [03/4]: Training Loss: 1.762393739, Training Accuracy: 51.264\n",
            "Worker 4, [04/4]: Training Loss: 1.514089568, Training Accuracy: 57.936\n",
            "Time taken for training worker 4: 0:00:20.807232\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000596\n",
            "Local Step 07: Test Loss: 1.982295518, Test Accuracy: 48.780\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.938065011, Training Accuracy: 47.904\n",
            "Worker 1, [02/4]: Training Loss: 1.875576138, Training Accuracy: 49.656\n",
            "Worker 1, [03/4]: Training Loss: 1.920603534, Training Accuracy: 48.304\n",
            "Worker 1, [04/4]: Training Loss: 1.978231363, Training Accuracy: 46.496\n",
            "Time taken for training worker 1: 0:00:21.002658\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.111205465, Training Accuracy: 43.760\n",
            "Worker 2, [02/4]: Training Loss: 1.918457997, Training Accuracy: 48.328\n",
            "Worker 2, [03/4]: Training Loss: 1.890892756, Training Accuracy: 48.896\n",
            "Worker 2, [04/4]: Training Loss: 1.965516885, Training Accuracy: 47.104\n",
            "Time taken for training worker 2: 0:00:20.923588\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.066286713, Training Accuracy: 45.072\n",
            "Worker 3, [02/4]: Training Loss: 1.856571430, Training Accuracy: 49.480\n",
            "Worker 3, [03/4]: Training Loss: 1.866648829, Training Accuracy: 49.168\n",
            "Worker 3, [04/4]: Training Loss: 1.916164541, Training Accuracy: 47.632\n",
            "Time taken for training worker 3: 0:00:21.606034\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.054548372, Training Accuracy: 44.880\n",
            "Worker 4, [02/4]: Training Loss: 1.813195484, Training Accuracy: 50.656\n",
            "Worker 4, [03/4]: Training Loss: 1.810059373, Training Accuracy: 50.336\n",
            "Worker 4, [04/4]: Training Loss: 1.851553166, Training Accuracy: 49.448\n",
            "Time taken for training worker 4: 0:00:23.345632\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000659\n",
            "Local Step 08: Test Loss: 2.123251289, Test Accuracy: 44.600\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.141104561, Training Accuracy: 43.656\n",
            "Worker 1, [02/4]: Training Loss: 1.905787820, Training Accuracy: 48.480\n",
            "Worker 1, [03/4]: Training Loss: 1.643138471, Training Accuracy: 55.144\n",
            "Worker 1, [04/4]: Training Loss: 1.408557211, Training Accuracy: 60.520\n",
            "Time taken for training worker 1: 0:00:20.401943\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.148269026, Training Accuracy: 43.184\n",
            "Worker 2, [02/4]: Training Loss: 1.932730621, Training Accuracy: 47.576\n",
            "Worker 2, [03/4]: Training Loss: 1.650431056, Training Accuracy: 53.856\n",
            "Worker 2, [04/4]: Training Loss: 1.407508863, Training Accuracy: 60.288\n",
            "Time taken for training worker 2: 0:00:21.271553\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.128030837, Training Accuracy: 43.584\n",
            "Worker 3, [02/4]: Training Loss: 1.942359425, Training Accuracy: 47.424\n",
            "Worker 3, [03/4]: Training Loss: 1.632003939, Training Accuracy: 54.560\n",
            "Worker 3, [04/4]: Training Loss: 1.392846798, Training Accuracy: 60.496\n",
            "Time taken for training worker 3: 0:00:21.169430\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.102205224, Training Accuracy: 43.816\n",
            "Worker 4, [02/4]: Training Loss: 1.881277329, Training Accuracy: 48.912\n",
            "Worker 4, [03/4]: Training Loss: 1.615959311, Training Accuracy: 54.576\n",
            "Worker 4, [04/4]: Training Loss: 1.368300974, Training Accuracy: 61.136\n",
            "Time taken for training worker 4: 0:00:20.320283\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000570\n",
            "Local Step 09: Test Loss: 1.935635286, Test Accuracy: 49.800\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.815163092, Training Accuracy: 51.320\n",
            "Worker 1, [02/4]: Training Loss: 1.753352109, Training Accuracy: 52.248\n",
            "Worker 1, [03/4]: Training Loss: 1.779845803, Training Accuracy: 51.328\n",
            "Worker 1, [04/4]: Training Loss: 1.832029474, Training Accuracy: 50.088\n",
            "Time taken for training worker 1: 0:00:21.729027\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.039013549, Training Accuracy: 45.808\n",
            "Worker 2, [02/4]: Training Loss: 1.781441274, Training Accuracy: 51.304\n",
            "Worker 2, [03/4]: Training Loss: 1.760216757, Training Accuracy: 51.704\n",
            "Worker 2, [04/4]: Training Loss: 1.845031072, Training Accuracy: 49.968\n",
            "Time taken for training worker 2: 0:00:21.968327\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.959859233, Training Accuracy: 47.080\n",
            "Worker 3, [02/4]: Training Loss: 1.729369382, Training Accuracy: 52.264\n",
            "Worker 3, [03/4]: Training Loss: 1.728791764, Training Accuracy: 51.896\n",
            "Worker 3, [04/4]: Training Loss: 1.780997205, Training Accuracy: 50.504\n",
            "Time taken for training worker 3: 0:00:22.475508\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.910831778, Training Accuracy: 47.520\n",
            "Worker 4, [02/4]: Training Loss: 1.679794892, Training Accuracy: 53.576\n",
            "Worker 4, [03/4]: Training Loss: 1.668776786, Training Accuracy: 53.624\n",
            "Worker 4, [04/4]: Training Loss: 1.766130151, Training Accuracy: 50.832\n",
            "Time taken for training worker 4: 0:00:21.215230\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000633\n",
            "Local Step 10: Test Loss: 2.086472388, Test Accuracy: 46.510\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.028884543, Training Accuracy: 46.008\n",
            "Worker 1, [02/4]: Training Loss: 1.802822201, Training Accuracy: 50.536\n",
            "Worker 1, [03/4]: Training Loss: 1.529087655, Training Accuracy: 57.368\n",
            "Worker 1, [04/4]: Training Loss: 1.276774354, Training Accuracy: 63.632\n",
            "Time taken for training worker 1: 0:00:20.941301\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.074156518, Training Accuracy: 44.552\n",
            "Worker 2, [02/4]: Training Loss: 1.831347791, Training Accuracy: 49.824\n",
            "Worker 2, [03/4]: Training Loss: 1.528943699, Training Accuracy: 57.248\n",
            "Worker 2, [04/4]: Training Loss: 1.275138447, Training Accuracy: 63.552\n",
            "Time taken for training worker 2: 0:00:21.276345\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.062718883, Training Accuracy: 44.624\n",
            "Worker 3, [02/4]: Training Loss: 1.802781024, Training Accuracy: 50.336\n",
            "Worker 3, [03/4]: Training Loss: 1.536991383, Training Accuracy: 56.544\n",
            "Worker 3, [04/4]: Training Loss: 1.289116551, Training Accuracy: 63.808\n",
            "Time taken for training worker 3: 0:00:22.315143\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.040569312, Training Accuracy: 45.344\n",
            "Worker 4, [02/4]: Training Loss: 1.807044150, Training Accuracy: 50.376\n",
            "Worker 4, [03/4]: Training Loss: 1.490949674, Training Accuracy: 58.056\n",
            "Worker 4, [04/4]: Training Loss: 1.263871761, Training Accuracy: 64.560\n",
            "Time taken for training worker 4: 0:00:22.505891\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000664\n",
            "Local Step 11: Test Loss: 1.904625619, Test Accuracy: 51.290\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.735335288, Training Accuracy: 53.288\n",
            "Worker 1, [02/4]: Training Loss: 1.667229682, Training Accuracy: 54.992\n",
            "Worker 1, [03/4]: Training Loss: 1.683368391, Training Accuracy: 53.608\n",
            "Worker 1, [04/4]: Training Loss: 1.756037250, Training Accuracy: 51.712\n",
            "Time taken for training worker 1: 0:00:22.007380\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.909894331, Training Accuracy: 48.176\n",
            "Worker 2, [02/4]: Training Loss: 1.682377254, Training Accuracy: 53.440\n",
            "Worker 2, [03/4]: Training Loss: 1.678569533, Training Accuracy: 53.960\n",
            "Worker 2, [04/4]: Training Loss: 1.754276624, Training Accuracy: 51.744\n",
            "Time taken for training worker 2: 0:00:20.549305\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.003299060, Training Accuracy: 46.288\n",
            "Worker 3, [02/4]: Training Loss: 1.668138152, Training Accuracy: 53.744\n",
            "Worker 3, [03/4]: Training Loss: 1.631458611, Training Accuracy: 54.976\n",
            "Worker 3, [04/4]: Training Loss: 1.721914559, Training Accuracy: 52.240\n",
            "Time taken for training worker 3: 0:00:21.907798\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.895696936, Training Accuracy: 48.552\n",
            "Worker 4, [02/4]: Training Loss: 1.613762936, Training Accuracy: 55.232\n",
            "Worker 4, [03/4]: Training Loss: 1.568604520, Training Accuracy: 55.656\n",
            "Worker 4, [04/4]: Training Loss: 1.678840251, Training Accuracy: 53.496\n",
            "Time taken for training worker 4: 0:00:21.480272\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000721\n",
            "Local Step 12: Test Loss: 2.108562503, Test Accuracy: 45.930\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.950781185, Training Accuracy: 47.648\n",
            "Worker 1, [02/4]: Training Loss: 1.719757818, Training Accuracy: 52.992\n",
            "Worker 1, [03/4]: Training Loss: 1.421481991, Training Accuracy: 59.448\n",
            "Worker 1, [04/4]: Training Loss: 1.188459949, Training Accuracy: 66.328\n",
            "Time taken for training worker 1: 0:00:21.148830\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.985091092, Training Accuracy: 46.216\n",
            "Worker 2, [02/4]: Training Loss: 1.726399821, Training Accuracy: 52.608\n",
            "Worker 2, [03/4]: Training Loss: 1.471398690, Training Accuracy: 58.608\n",
            "Worker 2, [04/4]: Training Loss: 1.220924255, Training Accuracy: 65.776\n",
            "Time taken for training worker 2: 0:00:22.264642\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.986145214, Training Accuracy: 46.496\n",
            "Worker 3, [02/4]: Training Loss: 1.745463882, Training Accuracy: 51.784\n",
            "Worker 3, [03/4]: Training Loss: 1.468310945, Training Accuracy: 58.672\n",
            "Worker 3, [04/4]: Training Loss: 1.197424816, Training Accuracy: 66.144\n",
            "Time taken for training worker 3: 0:00:21.196825\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.952849257, Training Accuracy: 47.456\n",
            "Worker 4, [02/4]: Training Loss: 1.704758828, Training Accuracy: 52.896\n",
            "Worker 4, [03/4]: Training Loss: 1.424807438, Training Accuracy: 59.328\n",
            "Worker 4, [04/4]: Training Loss: 1.179908845, Training Accuracy: 66.504\n",
            "Time taken for training worker 4: 0:00:20.593710\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000608\n",
            "Local Step 13: Test Loss: 1.912695968, Test Accuracy: 51.480\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.654701892, Training Accuracy: 54.800\n",
            "Worker 1, [02/4]: Training Loss: 1.603875063, Training Accuracy: 55.384\n",
            "Worker 1, [03/4]: Training Loss: 1.619394488, Training Accuracy: 55.200\n",
            "Worker 1, [04/4]: Training Loss: 1.705792265, Training Accuracy: 53.216\n",
            "Time taken for training worker 1: 0:00:21.817860\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.878921874, Training Accuracy: 48.432\n",
            "Worker 2, [02/4]: Training Loss: 1.633441903, Training Accuracy: 54.768\n",
            "Worker 2, [03/4]: Training Loss: 1.585963529, Training Accuracy: 55.832\n",
            "Worker 2, [04/4]: Training Loss: 1.661257187, Training Accuracy: 53.912\n",
            "Time taken for training worker 2: 0:00:21.935512\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.859610451, Training Accuracy: 49.216\n",
            "Worker 3, [02/4]: Training Loss: 1.600178534, Training Accuracy: 55.368\n",
            "Worker 3, [03/4]: Training Loss: 1.573854204, Training Accuracy: 56.128\n",
            "Worker 3, [04/4]: Training Loss: 1.643246500, Training Accuracy: 54.136\n",
            "Time taken for training worker 3: 0:00:21.679363\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.810715415, Training Accuracy: 49.888\n",
            "Worker 4, [02/4]: Training Loss: 1.531159077, Training Accuracy: 56.536\n",
            "Worker 4, [03/4]: Training Loss: 1.505419714, Training Accuracy: 57.448\n",
            "Worker 4, [04/4]: Training Loss: 1.599383648, Training Accuracy: 55.272\n",
            "Time taken for training worker 4: 0:00:22.056283\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000680\n",
            "Local Step 14: Test Loss: 2.046685113, Test Accuracy: 47.020\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.930856514, Training Accuracy: 48.192\n",
            "Worker 1, [02/4]: Training Loss: 1.654724568, Training Accuracy: 54.544\n",
            "Worker 1, [03/4]: Training Loss: 1.381413478, Training Accuracy: 61.256\n",
            "Worker 1, [04/4]: Training Loss: 1.133169943, Training Accuracy: 67.840\n",
            "Time taken for training worker 1: 0:00:22.481120\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.938065760, Training Accuracy: 47.672\n",
            "Worker 2, [02/4]: Training Loss: 1.671562641, Training Accuracy: 53.912\n",
            "Worker 2, [03/4]: Training Loss: 1.400238033, Training Accuracy: 60.144\n",
            "Worker 2, [04/4]: Training Loss: 1.138440218, Training Accuracy: 67.936\n",
            "Time taken for training worker 2: 0:00:21.687469\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.949985876, Training Accuracy: 47.368\n",
            "Worker 3, [02/4]: Training Loss: 1.694779204, Training Accuracy: 53.160\n",
            "Worker 3, [03/4]: Training Loss: 1.396165667, Training Accuracy: 60.136\n",
            "Worker 3, [04/4]: Training Loss: 1.147733955, Training Accuracy: 67.128\n",
            "Time taken for training worker 3: 0:00:20.756192\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.915719487, Training Accuracy: 48.328\n",
            "Worker 4, [02/4]: Training Loss: 1.679450944, Training Accuracy: 53.648\n",
            "Worker 4, [03/4]: Training Loss: 1.387521280, Training Accuracy: 60.712\n",
            "Worker 4, [04/4]: Training Loss: 1.121038881, Training Accuracy: 67.752\n",
            "Time taken for training worker 4: 0:00:21.424422\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000585\n",
            "Local Step 15: Test Loss: 1.899008612, Test Accuracy: 51.670\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.609603751, Training Accuracy: 55.936\n",
            "Worker 1, [02/4]: Training Loss: 1.554819237, Training Accuracy: 57.024\n",
            "Worker 1, [03/4]: Training Loss: 1.559071482, Training Accuracy: 56.808\n",
            "Worker 1, [04/4]: Training Loss: 1.630626224, Training Accuracy: 54.656\n",
            "Time taken for training worker 1: 0:00:21.574722\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.872197017, Training Accuracy: 49.904\n",
            "Worker 2, [02/4]: Training Loss: 1.590658232, Training Accuracy: 56.000\n",
            "Worker 2, [03/4]: Training Loss: 1.543748095, Training Accuracy: 56.848\n",
            "Worker 2, [04/4]: Training Loss: 1.611562036, Training Accuracy: 55.104\n",
            "Time taken for training worker 2: 0:00:20.569586\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.816987348, Training Accuracy: 50.512\n",
            "Worker 3, [02/4]: Training Loss: 1.551422270, Training Accuracy: 56.520\n",
            "Worker 3, [03/4]: Training Loss: 1.537532226, Training Accuracy: 56.904\n",
            "Worker 3, [04/4]: Training Loss: 1.608948111, Training Accuracy: 55.440\n",
            "Time taken for training worker 3: 0:00:20.502971\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.755642024, Training Accuracy: 51.592\n",
            "Worker 4, [02/4]: Training Loss: 1.514299028, Training Accuracy: 57.424\n",
            "Worker 4, [03/4]: Training Loss: 1.476694601, Training Accuracy: 58.160\n",
            "Worker 4, [04/4]: Training Loss: 1.529978472, Training Accuracy: 56.568\n",
            "Time taken for training worker 4: 0:00:21.852719\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000627\n",
            "Local Step 16: Test Loss: 2.096720693, Test Accuracy: 47.280\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.847623676, Training Accuracy: 49.680\n",
            "Worker 1, [02/4]: Training Loss: 1.624189247, Training Accuracy: 55.408\n",
            "Worker 1, [03/4]: Training Loss: 1.324936939, Training Accuracy: 62.920\n",
            "Worker 1, [04/4]: Training Loss: 1.059331404, Training Accuracy: 69.736\n",
            "Time taken for training worker 1: 0:00:20.979975\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.879224159, Training Accuracy: 49.056\n",
            "Worker 2, [02/4]: Training Loss: 1.627449054, Training Accuracy: 55.120\n",
            "Worker 2, [03/4]: Training Loss: 1.336527560, Training Accuracy: 61.896\n",
            "Worker 2, [04/4]: Training Loss: 1.094217301, Training Accuracy: 68.712\n",
            "Time taken for training worker 2: 0:00:21.605004\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.911090197, Training Accuracy: 48.424\n",
            "Worker 3, [02/4]: Training Loss: 1.649675762, Training Accuracy: 53.968\n",
            "Worker 3, [03/4]: Training Loss: 1.352917382, Training Accuracy: 61.256\n",
            "Worker 3, [04/4]: Training Loss: 1.097920552, Training Accuracy: 68.304\n",
            "Time taken for training worker 3: 0:00:20.628428\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.866615067, Training Accuracy: 49.616\n",
            "Worker 4, [02/4]: Training Loss: 1.613785585, Training Accuracy: 54.928\n",
            "Worker 4, [03/4]: Training Loss: 1.323280627, Training Accuracy: 62.440\n",
            "Worker 4, [04/4]: Training Loss: 1.088281680, Training Accuracy: 69.176\n",
            "Time taken for training worker 4: 0:00:20.566326\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001023\n",
            "Local Step 17: Test Loss: 1.899039234, Test Accuracy: 52.400\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.575111353, Training Accuracy: 56.672\n",
            "Worker 1, [02/4]: Training Loss: 1.514472733, Training Accuracy: 58.032\n",
            "Worker 1, [03/4]: Training Loss: 1.526356164, Training Accuracy: 57.800\n",
            "Worker 1, [04/4]: Training Loss: 1.569349007, Training Accuracy: 55.896\n",
            "Time taken for training worker 1: 0:00:22.256673\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.812168770, Training Accuracy: 50.792\n",
            "Worker 2, [02/4]: Training Loss: 1.530841738, Training Accuracy: 57.504\n",
            "Worker 2, [03/4]: Training Loss: 1.509578824, Training Accuracy: 57.416\n",
            "Worker 2, [04/4]: Training Loss: 1.546139192, Training Accuracy: 56.720\n",
            "Time taken for training worker 2: 0:00:22.865886\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.836251096, Training Accuracy: 49.456\n",
            "Worker 3, [02/4]: Training Loss: 1.527907324, Training Accuracy: 56.696\n",
            "Worker 3, [03/4]: Training Loss: 1.472275922, Training Accuracy: 58.080\n",
            "Worker 3, [04/4]: Training Loss: 1.559994255, Training Accuracy: 56.080\n",
            "Time taken for training worker 3: 0:00:21.823187\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.705430518, Training Accuracy: 52.632\n",
            "Worker 4, [02/4]: Training Loss: 1.449333294, Training Accuracy: 58.936\n",
            "Worker 4, [03/4]: Training Loss: 1.417980465, Training Accuracy: 59.672\n",
            "Worker 4, [04/4]: Training Loss: 1.523465036, Training Accuracy: 57.048\n",
            "Time taken for training worker 4: 0:00:21.164227\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000720\n",
            "Local Step 18: Test Loss: 2.062606925, Test Accuracy: 48.400\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.856908666, Training Accuracy: 50.256\n",
            "Worker 1, [02/4]: Training Loss: 1.595148444, Training Accuracy: 55.896\n",
            "Worker 1, [03/4]: Training Loss: 1.304041428, Training Accuracy: 63.464\n",
            "Worker 1, [04/4]: Training Loss: 1.007076450, Training Accuracy: 71.312\n",
            "Time taken for training worker 1: 0:00:20.653548\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.857300240, Training Accuracy: 49.072\n",
            "Worker 2, [02/4]: Training Loss: 1.612549600, Training Accuracy: 55.128\n",
            "Worker 2, [03/4]: Training Loss: 1.312019296, Training Accuracy: 62.400\n",
            "Worker 2, [04/4]: Training Loss: 1.052916467, Training Accuracy: 69.904\n",
            "Time taken for training worker 2: 0:00:20.803823\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.856155660, Training Accuracy: 49.248\n",
            "Worker 3, [02/4]: Training Loss: 1.603555345, Training Accuracy: 55.040\n",
            "Worker 3, [03/4]: Training Loss: 1.319877848, Training Accuracy: 62.552\n",
            "Worker 3, [04/4]: Training Loss: 1.057902689, Training Accuracy: 69.392\n",
            "Time taken for training worker 3: 0:00:22.731611\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.862213017, Training Accuracy: 48.928\n",
            "Worker 4, [02/4]: Training Loss: 1.590726625, Training Accuracy: 55.152\n",
            "Worker 4, [03/4]: Training Loss: 1.304888959, Training Accuracy: 62.752\n",
            "Worker 4, [04/4]: Training Loss: 1.026897217, Training Accuracy: 70.464\n",
            "Time taken for training worker 4: 0:00:22.855365\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000713\n",
            "Local Step 19: Test Loss: 1.900653299, Test Accuracy: 53.190\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.559967276, Training Accuracy: 56.928\n",
            "Worker 1, [02/4]: Training Loss: 1.486667844, Training Accuracy: 58.144\n",
            "Worker 1, [03/4]: Training Loss: 1.485943739, Training Accuracy: 58.520\n",
            "Worker 1, [04/4]: Training Loss: 1.557676309, Training Accuracy: 56.456\n",
            "Time taken for training worker 1: 0:00:21.936932\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.786487717, Training Accuracy: 51.560\n",
            "Worker 2, [02/4]: Training Loss: 1.516080673, Training Accuracy: 57.928\n",
            "Worker 2, [03/4]: Training Loss: 1.475520835, Training Accuracy: 58.352\n",
            "Worker 2, [04/4]: Training Loss: 1.570697108, Training Accuracy: 56.088\n",
            "Time taken for training worker 2: 0:00:20.251266\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.858058250, Training Accuracy: 50.048\n",
            "Worker 3, [02/4]: Training Loss: 1.504692979, Training Accuracy: 58.272\n",
            "Worker 3, [03/4]: Training Loss: 1.443995680, Training Accuracy: 59.152\n",
            "Worker 3, [04/4]: Training Loss: 1.517295385, Training Accuracy: 56.728\n",
            "Time taken for training worker 3: 0:00:22.319913\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.741453904, Training Accuracy: 52.096\n",
            "Worker 4, [02/4]: Training Loss: 1.430009325, Training Accuracy: 59.768\n",
            "Worker 4, [03/4]: Training Loss: 1.385635914, Training Accuracy: 60.752\n",
            "Worker 4, [04/4]: Training Loss: 1.472378023, Training Accuracy: 58.392\n",
            "Time taken for training worker 4: 0:00:20.823809\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000591\n",
            "Local Step 20: Test Loss: 2.045412077, Test Accuracy: 48.560\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.817283476, Training Accuracy: 50.544\n",
            "Worker 1, [02/4]: Training Loss: 1.563845412, Training Accuracy: 56.688\n",
            "Worker 1, [03/4]: Training Loss: 1.244656793, Training Accuracy: 64.992\n",
            "Worker 1, [04/4]: Training Loss: 0.986997327, Training Accuracy: 71.664\n",
            "Time taken for training worker 1: 0:00:20.904512\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.829868728, Training Accuracy: 50.224\n",
            "Worker 2, [02/4]: Training Loss: 1.596987230, Training Accuracy: 55.608\n",
            "Worker 2, [03/4]: Training Loss: 1.281231289, Training Accuracy: 63.160\n",
            "Worker 2, [04/4]: Training Loss: 1.011019086, Training Accuracy: 70.672\n",
            "Time taken for training worker 2: 0:00:21.882129\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.831678012, Training Accuracy: 49.632\n",
            "Worker 3, [02/4]: Training Loss: 1.588619058, Training Accuracy: 56.000\n",
            "Worker 3, [03/4]: Training Loss: 1.283520265, Training Accuracy: 63.544\n",
            "Worker 3, [04/4]: Training Loss: 1.022634392, Training Accuracy: 70.728\n",
            "Time taken for training worker 3: 0:00:20.261445\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.820326331, Training Accuracy: 50.416\n",
            "Worker 4, [02/4]: Training Loss: 1.579074090, Training Accuracy: 56.336\n",
            "Worker 4, [03/4]: Training Loss: 1.272364810, Training Accuracy: 63.744\n",
            "Worker 4, [04/4]: Training Loss: 1.003364178, Training Accuracy: 71.024\n",
            "Time taken for training worker 4: 0:00:21.286003\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000596\n",
            "Local Step 21: Test Loss: 1.920337699, Test Accuracy: 52.560\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.551744501, Training Accuracy: 58.040\n",
            "Worker 1, [02/4]: Training Loss: 1.456428189, Training Accuracy: 59.088\n",
            "Worker 1, [03/4]: Training Loss: 1.463866397, Training Accuracy: 59.216\n",
            "Worker 1, [04/4]: Training Loss: 1.529731965, Training Accuracy: 57.024\n",
            "Time taken for training worker 1: 0:00:23.059756\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.741884572, Training Accuracy: 52.240\n",
            "Worker 2, [02/4]: Training Loss: 1.472615555, Training Accuracy: 58.600\n",
            "Worker 2, [03/4]: Training Loss: 1.439167257, Training Accuracy: 59.832\n",
            "Worker 2, [04/4]: Training Loss: 1.507058644, Training Accuracy: 57.336\n",
            "Time taken for training worker 2: 0:00:22.775657\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.709177526, Training Accuracy: 52.696\n",
            "Worker 3, [02/4]: Training Loss: 1.450269178, Training Accuracy: 58.448\n",
            "Worker 3, [03/4]: Training Loss: 1.408354558, Training Accuracy: 60.056\n",
            "Worker 3, [04/4]: Training Loss: 1.493857235, Training Accuracy: 57.632\n",
            "Time taken for training worker 3: 0:00:21.540591\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.678901910, Training Accuracy: 53.592\n",
            "Worker 4, [02/4]: Training Loss: 1.410287620, Training Accuracy: 60.000\n",
            "Worker 4, [03/4]: Training Loss: 1.378026936, Training Accuracy: 60.856\n",
            "Worker 4, [04/4]: Training Loss: 1.448856238, Training Accuracy: 58.520\n",
            "Time taken for training worker 4: 0:00:20.641330\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000719\n",
            "Local Step 22: Test Loss: 2.100427915, Test Accuracy: 47.410\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.795314978, Training Accuracy: 50.920\n",
            "Worker 1, [02/4]: Training Loss: 1.519219908, Training Accuracy: 57.512\n",
            "Worker 1, [03/4]: Training Loss: 1.203585906, Training Accuracy: 65.560\n",
            "Worker 1, [04/4]: Training Loss: 0.972315125, Training Accuracy: 71.784\n",
            "Time taken for training worker 1: 0:00:21.383481\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.839789330, Training Accuracy: 49.968\n",
            "Worker 2, [02/4]: Training Loss: 1.534475839, Training Accuracy: 57.080\n",
            "Worker 2, [03/4]: Training Loss: 1.245753988, Training Accuracy: 64.120\n",
            "Worker 2, [04/4]: Training Loss: 0.995014987, Training Accuracy: 71.032\n",
            "Time taken for training worker 2: 0:00:22.276102\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.816349822, Training Accuracy: 50.984\n",
            "Worker 3, [02/4]: Training Loss: 1.569986394, Training Accuracy: 55.584\n",
            "Worker 3, [03/4]: Training Loss: 1.243223196, Training Accuracy: 64.352\n",
            "Worker 3, [04/4]: Training Loss: 0.996105779, Training Accuracy: 70.976\n",
            "Time taken for training worker 3: 0:00:22.639016\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.817007940, Training Accuracy: 50.576\n",
            "Worker 4, [02/4]: Training Loss: 1.528695467, Training Accuracy: 57.408\n",
            "Worker 4, [03/4]: Training Loss: 1.228460982, Training Accuracy: 64.880\n",
            "Worker 4, [04/4]: Training Loss: 0.981523186, Training Accuracy: 71.736\n",
            "Time taken for training worker 4: 0:00:23.182619\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001001\n",
            "Local Step 23: Test Loss: 1.892907637, Test Accuracy: 52.930\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.499759082, Training Accuracy: 58.728\n",
            "Worker 1, [02/4]: Training Loss: 1.435483020, Training Accuracy: 60.296\n",
            "Worker 1, [03/4]: Training Loss: 1.435915291, Training Accuracy: 59.400\n",
            "Worker 1, [04/4]: Training Loss: 1.501976653, Training Accuracy: 57.872\n",
            "Time taken for training worker 1: 0:00:21.091504\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.775976562, Training Accuracy: 51.192\n",
            "Worker 2, [02/4]: Training Loss: 1.476157555, Training Accuracy: 59.168\n",
            "Worker 2, [03/4]: Training Loss: 1.426561687, Training Accuracy: 59.872\n",
            "Worker 2, [04/4]: Training Loss: 1.491638839, Training Accuracy: 57.608\n",
            "Time taken for training worker 2: 0:00:21.340224\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.690162232, Training Accuracy: 52.952\n",
            "Worker 3, [02/4]: Training Loss: 1.425332914, Training Accuracy: 59.480\n",
            "Worker 3, [03/4]: Training Loss: 1.419443294, Training Accuracy: 60.032\n",
            "Worker 3, [04/4]: Training Loss: 1.476376749, Training Accuracy: 57.936\n",
            "Time taken for training worker 3: 0:00:21.124748\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.680306869, Training Accuracy: 53.632\n",
            "Worker 4, [02/4]: Training Loss: 1.383784530, Training Accuracy: 60.616\n",
            "Worker 4, [03/4]: Training Loss: 1.328164269, Training Accuracy: 62.288\n",
            "Worker 4, [04/4]: Training Loss: 1.414095174, Training Accuracy: 59.784\n",
            "Time taken for training worker 4: 0:00:20.726548\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000691\n",
            "Local Step 24: Test Loss: 2.117820731, Test Accuracy: 47.430\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.774695094, Training Accuracy: 51.776\n",
            "Worker 1, [02/4]: Training Loss: 1.492434343, Training Accuracy: 58.288\n",
            "Worker 1, [03/4]: Training Loss: 1.203076803, Training Accuracy: 65.432\n",
            "Worker 1, [04/4]: Training Loss: 0.948723813, Training Accuracy: 72.784\n",
            "Time taken for training worker 1: 0:00:21.033569\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.800730691, Training Accuracy: 50.800\n",
            "Worker 2, [02/4]: Training Loss: 1.552193695, Training Accuracy: 56.776\n",
            "Worker 2, [03/4]: Training Loss: 1.212070749, Training Accuracy: 65.240\n",
            "Worker 2, [04/4]: Training Loss: 0.973083221, Training Accuracy: 71.624\n",
            "Time taken for training worker 2: 0:00:20.514062\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.819360912, Training Accuracy: 50.208\n",
            "Worker 3, [02/4]: Training Loss: 1.549001428, Training Accuracy: 56.528\n",
            "Worker 3, [03/4]: Training Loss: 1.239259387, Training Accuracy: 64.608\n",
            "Worker 3, [04/4]: Training Loss: 0.973928954, Training Accuracy: 72.296\n",
            "Time taken for training worker 3: 0:00:20.479386\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.800019967, Training Accuracy: 50.896\n",
            "Worker 4, [02/4]: Training Loss: 1.530435931, Training Accuracy: 57.208\n",
            "Worker 4, [03/4]: Training Loss: 1.218080003, Training Accuracy: 64.984\n",
            "Worker 4, [04/4]: Training Loss: 0.960082850, Training Accuracy: 72.112\n",
            "Time taken for training worker 4: 0:00:20.676878\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000646\n",
            "Local Step 25: Test Loss: 1.910548635, Test Accuracy: 52.850\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.483670369, Training Accuracy: 58.920\n",
            "Worker 1, [02/4]: Training Loss: 1.398647179, Training Accuracy: 60.424\n",
            "Worker 1, [03/4]: Training Loss: 1.414342179, Training Accuracy: 60.088\n",
            "Worker 1, [04/4]: Training Loss: 1.500434248, Training Accuracy: 57.728\n",
            "Time taken for training worker 1: 0:00:22.308771\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.734764956, Training Accuracy: 52.360\n",
            "Worker 2, [02/4]: Training Loss: 1.459796975, Training Accuracy: 58.504\n",
            "Worker 2, [03/4]: Training Loss: 1.408353230, Training Accuracy: 60.344\n",
            "Worker 2, [04/4]: Training Loss: 1.479295836, Training Accuracy: 58.344\n",
            "Time taken for training worker 2: 0:00:21.373340\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.715393332, Training Accuracy: 52.312\n",
            "Worker 3, [02/4]: Training Loss: 1.419825632, Training Accuracy: 60.016\n",
            "Worker 3, [03/4]: Training Loss: 1.371633282, Training Accuracy: 60.560\n",
            "Worker 3, [04/4]: Training Loss: 1.435104412, Training Accuracy: 58.976\n",
            "Time taken for training worker 3: 0:00:22.779788\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.621750647, Training Accuracy: 54.816\n",
            "Worker 4, [02/4]: Training Loss: 1.347714966, Training Accuracy: 61.752\n",
            "Worker 4, [03/4]: Training Loss: 1.321039248, Training Accuracy: 62.480\n",
            "Worker 4, [04/4]: Training Loss: 1.425932826, Training Accuracy: 58.752\n",
            "Time taken for training worker 4: 0:00:20.947953\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000625\n",
            "Local Step 26: Test Loss: 2.050861546, Test Accuracy: 48.040\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.754542942, Training Accuracy: 51.800\n",
            "Worker 1, [02/4]: Training Loss: 1.468971155, Training Accuracy: 58.576\n",
            "Worker 1, [03/4]: Training Loss: 1.179341966, Training Accuracy: 65.752\n",
            "Worker 1, [04/4]: Training Loss: 0.909714664, Training Accuracy: 73.904\n",
            "Time taken for training worker 1: 0:00:20.868653\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.776711149, Training Accuracy: 51.024\n",
            "Worker 2, [02/4]: Training Loss: 1.500953761, Training Accuracy: 57.712\n",
            "Worker 2, [03/4]: Training Loss: 1.223559164, Training Accuracy: 65.000\n",
            "Worker 2, [04/4]: Training Loss: 0.953847349, Training Accuracy: 72.728\n",
            "Time taken for training worker 2: 0:00:21.924308\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.787404143, Training Accuracy: 50.664\n",
            "Worker 3, [02/4]: Training Loss: 1.522120981, Training Accuracy: 57.440\n",
            "Worker 3, [03/4]: Training Loss: 1.219365831, Training Accuracy: 64.984\n",
            "Worker 3, [04/4]: Training Loss: 0.960287389, Training Accuracy: 71.968\n",
            "Time taken for training worker 3: 0:00:23.326586\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.769609979, Training Accuracy: 51.856\n",
            "Worker 4, [02/4]: Training Loss: 1.517580329, Training Accuracy: 57.528\n",
            "Worker 4, [03/4]: Training Loss: 1.216386501, Training Accuracy: 65.256\n",
            "Worker 4, [04/4]: Training Loss: 0.934984429, Training Accuracy: 72.888\n",
            "Time taken for training worker 4: 0:00:20.914276\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000603\n",
            "Local Step 27: Test Loss: 1.893840805, Test Accuracy: 53.380\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.466534469, Training Accuracy: 59.464\n",
            "Worker 1, [02/4]: Training Loss: 1.371692251, Training Accuracy: 60.928\n",
            "Worker 1, [03/4]: Training Loss: 1.380987477, Training Accuracy: 60.888\n",
            "Worker 1, [04/4]: Training Loss: 1.462927558, Training Accuracy: 57.872\n",
            "Time taken for training worker 1: 0:00:21.013726\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.745042649, Training Accuracy: 52.888\n",
            "Worker 2, [02/4]: Training Loss: 1.434993763, Training Accuracy: 59.640\n",
            "Worker 2, [03/4]: Training Loss: 1.378214108, Training Accuracy: 60.816\n",
            "Worker 2, [04/4]: Training Loss: 1.465329559, Training Accuracy: 58.664\n",
            "Time taken for training worker 2: 0:00:21.370448\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.732133212, Training Accuracy: 52.408\n",
            "Worker 3, [02/4]: Training Loss: 1.405931970, Training Accuracy: 59.976\n",
            "Worker 3, [03/4]: Training Loss: 1.363702356, Training Accuracy: 60.744\n",
            "Worker 3, [04/4]: Training Loss: 1.429255181, Training Accuracy: 59.064\n",
            "Time taken for training worker 3: 0:00:21.198148\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.689101378, Training Accuracy: 53.184\n",
            "Worker 4, [02/4]: Training Loss: 1.363660964, Training Accuracy: 60.896\n",
            "Worker 4, [03/4]: Training Loss: 1.316160964, Training Accuracy: 62.776\n",
            "Worker 4, [04/4]: Training Loss: 1.404893501, Training Accuracy: 59.608\n",
            "Time taken for training worker 4: 0:00:21.165429\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000611\n",
            "Local Step 28: Test Loss: 2.058929969, Test Accuracy: 48.510\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.744329573, Training Accuracy: 52.520\n",
            "Worker 1, [02/4]: Training Loss: 1.460300069, Training Accuracy: 59.136\n",
            "Worker 1, [03/4]: Training Loss: 1.163445673, Training Accuracy: 66.504\n",
            "Worker 1, [04/4]: Training Loss: 0.901382425, Training Accuracy: 74.216\n",
            "Time taken for training worker 1: 0:00:23.284029\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.776995473, Training Accuracy: 51.560\n",
            "Worker 2, [02/4]: Training Loss: 1.501155169, Training Accuracy: 57.712\n",
            "Worker 2, [03/4]: Training Loss: 1.192126208, Training Accuracy: 65.944\n",
            "Worker 2, [04/4]: Training Loss: 0.937258601, Training Accuracy: 73.112\n",
            "Time taken for training worker 2: 0:00:22.162135\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.803635198, Training Accuracy: 50.704\n",
            "Worker 3, [02/4]: Training Loss: 1.491410234, Training Accuracy: 57.424\n",
            "Worker 3, [03/4]: Training Loss: 1.214815420, Training Accuracy: 64.952\n",
            "Worker 3, [04/4]: Training Loss: 0.949759362, Training Accuracy: 72.192\n",
            "Time taken for training worker 3: 0:00:20.708904\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.742283834, Training Accuracy: 52.176\n",
            "Worker 4, [02/4]: Training Loss: 1.493028603, Training Accuracy: 57.848\n",
            "Worker 4, [03/4]: Training Loss: 1.183055291, Training Accuracy: 66.072\n",
            "Worker 4, [04/4]: Training Loss: 0.923562561, Training Accuracy: 73.400\n",
            "Time taken for training worker 4: 0:00:21.168558\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000692\n",
            "Local Step 29: Test Loss: 1.902387876, Test Accuracy: 53.470\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.449991651, Training Accuracy: 60.208\n",
            "Worker 1, [02/4]: Training Loss: 1.377540885, Training Accuracy: 60.688\n",
            "Worker 1, [03/4]: Training Loss: 1.394463452, Training Accuracy: 60.328\n",
            "Worker 1, [04/4]: Training Loss: 1.437847479, Training Accuracy: 58.864\n",
            "Time taken for training worker 1: 0:00:20.719318\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.708750763, Training Accuracy: 52.624\n",
            "Worker 2, [02/4]: Training Loss: 1.427053486, Training Accuracy: 59.648\n",
            "Worker 2, [03/4]: Training Loss: 1.380242077, Training Accuracy: 60.304\n",
            "Worker 2, [04/4]: Training Loss: 1.447039410, Training Accuracy: 58.952\n",
            "Time taken for training worker 2: 0:00:22.774397\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.685644326, Training Accuracy: 53.272\n",
            "Worker 3, [02/4]: Training Loss: 1.392100185, Training Accuracy: 60.528\n",
            "Worker 3, [03/4]: Training Loss: 1.325273307, Training Accuracy: 61.968\n",
            "Worker 3, [04/4]: Training Loss: 1.422458252, Training Accuracy: 59.680\n",
            "Time taken for training worker 3: 0:00:22.320392\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.677487610, Training Accuracy: 53.336\n",
            "Worker 4, [02/4]: Training Loss: 1.326923653, Training Accuracy: 62.280\n",
            "Worker 4, [03/4]: Training Loss: 1.317358149, Training Accuracy: 62.736\n",
            "Worker 4, [04/4]: Training Loss: 1.373970787, Training Accuracy: 61.304\n",
            "Time taken for training worker 4: 0:00:21.109496\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000624\n",
            "Local Step 30: Test Loss: 2.044943645, Test Accuracy: 49.370\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.719393059, Training Accuracy: 53.064\n",
            "Worker 1, [02/4]: Training Loss: 1.457817997, Training Accuracy: 59.208\n",
            "Worker 1, [03/4]: Training Loss: 1.151976097, Training Accuracy: 66.512\n",
            "Worker 1, [04/4]: Training Loss: 0.901445433, Training Accuracy: 74.312\n",
            "Time taken for training worker 1: 0:00:21.442513\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.751166007, Training Accuracy: 52.424\n",
            "Worker 2, [02/4]: Training Loss: 1.458960555, Training Accuracy: 59.232\n",
            "Worker 2, [03/4]: Training Loss: 1.166593334, Training Accuracy: 66.656\n",
            "Worker 2, [04/4]: Training Loss: 0.909344704, Training Accuracy: 73.440\n",
            "Time taken for training worker 2: 0:00:20.866752\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.798253828, Training Accuracy: 50.872\n",
            "Worker 3, [02/4]: Training Loss: 1.504237025, Training Accuracy: 57.624\n",
            "Worker 3, [03/4]: Training Loss: 1.196638240, Training Accuracy: 65.648\n",
            "Worker 3, [04/4]: Training Loss: 0.927782401, Training Accuracy: 73.584\n",
            "Time taken for training worker 3: 0:00:20.804264\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.768497128, Training Accuracy: 51.792\n",
            "Worker 4, [02/4]: Training Loss: 1.457904117, Training Accuracy: 58.984\n",
            "Worker 4, [03/4]: Training Loss: 1.164885819, Training Accuracy: 66.680\n",
            "Worker 4, [04/4]: Training Loss: 0.913761260, Training Accuracy: 73.800\n",
            "Time taken for training worker 4: 0:00:21.224412\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000629\n",
            "Local Step 31: Test Loss: 1.872153338, Test Accuracy: 54.200\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.426647361, Training Accuracy: 60.072\n",
            "Worker 1, [02/4]: Training Loss: 1.368993924, Training Accuracy: 61.304\n",
            "Worker 1, [03/4]: Training Loss: 1.369536962, Training Accuracy: 61.184\n",
            "Worker 1, [04/4]: Training Loss: 1.444919702, Training Accuracy: 59.280\n",
            "Time taken for training worker 1: 0:00:21.328053\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.708202850, Training Accuracy: 53.256\n",
            "Worker 2, [02/4]: Training Loss: 1.390799813, Training Accuracy: 60.536\n",
            "Worker 2, [03/4]: Training Loss: 1.350729101, Training Accuracy: 61.528\n",
            "Worker 2, [04/4]: Training Loss: 1.457392687, Training Accuracy: 58.928\n",
            "Time taken for training worker 2: 0:00:21.884032\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.653535241, Training Accuracy: 53.824\n",
            "Worker 3, [02/4]: Training Loss: 1.365392041, Training Accuracy: 60.928\n",
            "Worker 3, [03/4]: Training Loss: 1.321734870, Training Accuracy: 61.824\n",
            "Worker 3, [04/4]: Training Loss: 1.444382401, Training Accuracy: 58.752\n",
            "Time taken for training worker 3: 0:00:21.829951\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.615644799, Training Accuracy: 55.264\n",
            "Worker 4, [02/4]: Training Loss: 1.317308666, Training Accuracy: 62.464\n",
            "Worker 4, [03/4]: Training Loss: 1.283981457, Training Accuracy: 63.336\n",
            "Worker 4, [04/4]: Training Loss: 1.375773171, Training Accuracy: 60.168\n",
            "Time taken for training worker 4: 0:00:21.419206\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000685\n",
            "Local Step 32: Test Loss: 2.004914000, Test Accuracy: 49.280\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:46:19.651205\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:64\n",
            "==================================================\n",
            "Worker 1, [01/2]: Training Loss: 4.528419706, Training Accuracy: 2.120\n",
            "Worker 1, [02/2]: Training Loss: 4.166516045, Training Accuracy: 6.128\n",
            "Time taken for training worker 1: 0:00:10.436769\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 4.525874379, Training Accuracy: 2.264\n",
            "Worker 2, [02/2]: Training Loss: 4.149172458, Training Accuracy: 6.472\n",
            "Time taken for training worker 2: 0:00:10.278259\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 4.526407203, Training Accuracy: 2.208\n",
            "Worker 3, [02/2]: Training Loss: 4.152078834, Training Accuracy: 6.096\n",
            "Time taken for training worker 3: 0:00:10.269843\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 4.515858626, Training Accuracy: 2.456\n",
            "Worker 4, [02/2]: Training Loss: 4.135930193, Training Accuracy: 6.384\n",
            "Time taken for training worker 4: 0:00:10.177801\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000639\n",
            "Local Step 01: Test Loss: 4.042775338, Test Accuracy: 8.350\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 4.071112347, Training Accuracy: 8.088\n",
            "Worker 1, [02/2]: Training Loss: 4.011511615, Training Accuracy: 8.192\n",
            "Time taken for training worker 1: 0:00:11.808203\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.954654085, Training Accuracy: 8.928\n",
            "Worker 2, [02/2]: Training Loss: 3.908860952, Training Accuracy: 9.968\n",
            "Time taken for training worker 2: 0:00:11.846451\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 3.818513916, Training Accuracy: 10.744\n",
            "Worker 3, [02/2]: Training Loss: 3.778221507, Training Accuracy: 11.560\n",
            "Time taken for training worker 3: 0:00:11.643410\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 3.694645872, Training Accuracy: 13.216\n",
            "Worker 4, [02/2]: Training Loss: 3.664779439, Training Accuracy: 13.624\n",
            "Time taken for training worker 4: 0:00:11.176974\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000606\n",
            "Local Step 02: Test Loss: 3.609705553, Test Accuracy: 14.980\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.675290327, Training Accuracy: 13.224\n",
            "Worker 1, [02/2]: Training Loss: 3.431602611, Training Accuracy: 17.872\n",
            "Time taken for training worker 1: 0:00:10.915565\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.511446207, Training Accuracy: 16.392\n",
            "Worker 2, [02/2]: Training Loss: 3.265397375, Training Accuracy: 20.152\n",
            "Time taken for training worker 2: 0:00:11.007275\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 3.364818178, Training Accuracy: 17.960\n",
            "Worker 3, [02/2]: Training Loss: 3.131162283, Training Accuracy: 22.424\n",
            "Time taken for training worker 3: 0:00:11.457366\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 3.228444714, Training Accuracy: 20.984\n",
            "Worker 4, [02/2]: Training Loss: 2.988912630, Training Accuracy: 25.544\n",
            "Time taken for training worker 4: 0:00:10.612190\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000610\n",
            "Local Step 03: Test Loss: 2.968990642, Test Accuracy: 25.590\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.076790161, Training Accuracy: 23.616\n",
            "Worker 1, [02/2]: Training Loss: 3.025094462, Training Accuracy: 24.384\n",
            "Time taken for training worker 1: 0:00:11.505207\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.992970833, Training Accuracy: 25.376\n",
            "Worker 2, [02/2]: Training Loss: 2.964068734, Training Accuracy: 26.120\n",
            "Time taken for training worker 2: 0:00:11.523325\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.938984089, Training Accuracy: 26.040\n",
            "Worker 3, [02/2]: Training Loss: 2.954984420, Training Accuracy: 25.824\n",
            "Time taken for training worker 3: 0:00:10.413211\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.840039225, Training Accuracy: 28.280\n",
            "Worker 4, [02/2]: Training Loss: 2.841973473, Training Accuracy: 28.544\n",
            "Time taken for training worker 4: 0:00:11.064376\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000617\n",
            "Local Step 04: Test Loss: 2.763904936, Test Accuracy: 30.440\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.007310748, Training Accuracy: 25.032\n",
            "Worker 1, [02/2]: Training Loss: 2.720554027, Training Accuracy: 30.936\n",
            "Time taken for training worker 1: 0:00:10.288604\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.943510945, Training Accuracy: 26.440\n",
            "Worker 2, [02/2]: Training Loss: 2.659439998, Training Accuracy: 31.800\n",
            "Time taken for training worker 2: 0:00:11.028408\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.864990631, Training Accuracy: 27.656\n",
            "Worker 3, [02/2]: Training Loss: 2.579581314, Training Accuracy: 32.976\n",
            "Time taken for training worker 3: 0:00:10.843399\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.770487205, Training Accuracy: 29.688\n",
            "Worker 4, [02/2]: Training Loss: 2.498144357, Training Accuracy: 35.192\n",
            "Time taken for training worker 4: 0:00:10.257833\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000747\n",
            "Local Step 05: Test Loss: 2.469353510, Test Accuracy: 36.230\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.584808993, Training Accuracy: 33.752\n",
            "Worker 1, [02/2]: Training Loss: 2.589813909, Training Accuracy: 33.896\n",
            "Time taken for training worker 1: 0:00:10.794510\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.567213374, Training Accuracy: 33.928\n",
            "Worker 2, [02/2]: Training Loss: 2.515915344, Training Accuracy: 35.152\n",
            "Time taken for training worker 2: 0:00:10.319858\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.494178251, Training Accuracy: 35.168\n",
            "Worker 3, [02/2]: Training Loss: 2.498105376, Training Accuracy: 34.672\n",
            "Time taken for training worker 3: 0:00:10.408549\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.412866321, Training Accuracy: 36.720\n",
            "Worker 4, [02/2]: Training Loss: 2.421329720, Training Accuracy: 36.504\n",
            "Time taken for training worker 4: 0:00:10.846179\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000677\n",
            "Local Step 06: Test Loss: 2.376207499, Test Accuracy: 37.760\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.663489667, Training Accuracy: 32.664\n",
            "Worker 1, [02/2]: Training Loss: 2.349613348, Training Accuracy: 38.952\n",
            "Time taken for training worker 1: 0:00:10.491006\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.636666673, Training Accuracy: 32.584\n",
            "Worker 2, [02/2]: Training Loss: 2.334118774, Training Accuracy: 38.984\n",
            "Time taken for training worker 2: 0:00:10.334062\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.584166863, Training Accuracy: 33.200\n",
            "Worker 3, [02/2]: Training Loss: 2.320114242, Training Accuracy: 38.424\n",
            "Time taken for training worker 3: 0:00:10.233979\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.578547486, Training Accuracy: 34.368\n",
            "Worker 4, [02/2]: Training Loss: 2.248934709, Training Accuracy: 40.448\n",
            "Time taken for training worker 4: 0:00:11.369194\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000737\n",
            "Local Step 07: Test Loss: 2.373724438, Test Accuracy: 38.960\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.436797437, Training Accuracy: 36.888\n",
            "Worker 1, [02/2]: Training Loss: 2.357385935, Training Accuracy: 38.768\n",
            "Time taken for training worker 1: 0:00:10.243800\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.317736258, Training Accuracy: 39.696\n",
            "Worker 2, [02/2]: Training Loss: 2.293307480, Training Accuracy: 39.736\n",
            "Time taken for training worker 2: 0:00:10.461520\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.259691250, Training Accuracy: 40.416\n",
            "Worker 3, [02/2]: Training Loss: 2.256158089, Training Accuracy: 40.184\n",
            "Time taken for training worker 3: 0:00:10.111844\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.166716940, Training Accuracy: 42.432\n",
            "Worker 4, [02/2]: Training Loss: 2.187953436, Training Accuracy: 41.648\n",
            "Time taken for training worker 4: 0:00:10.997451\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000662\n",
            "Local Step 08: Test Loss: 2.244143280, Test Accuracy: 40.790\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.446722978, Training Accuracy: 36.456\n",
            "Worker 1, [02/2]: Training Loss: 2.161072595, Training Accuracy: 42.704\n",
            "Time taken for training worker 1: 0:00:11.056174\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.454288342, Training Accuracy: 36.520\n",
            "Worker 2, [02/2]: Training Loss: 2.123316941, Training Accuracy: 43.320\n",
            "Time taken for training worker 2: 0:00:10.421252\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.428433753, Training Accuracy: 36.640\n",
            "Worker 3, [02/2]: Training Loss: 2.090489480, Training Accuracy: 43.912\n",
            "Time taken for training worker 3: 0:00:11.415501\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.383808848, Training Accuracy: 37.824\n",
            "Worker 4, [02/2]: Training Loss: 2.047761871, Training Accuracy: 44.736\n",
            "Time taken for training worker 4: 0:00:10.350039\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000595\n",
            "Local Step 09: Test Loss: 2.169345121, Test Accuracy: 43.340\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.183963073, Training Accuracy: 42.192\n",
            "Worker 1, [02/2]: Training Loss: 2.181857880, Training Accuracy: 42.512\n",
            "Time taken for training worker 1: 0:00:10.371238\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.149620521, Training Accuracy: 42.784\n",
            "Worker 2, [02/2]: Training Loss: 2.125060185, Training Accuracy: 43.704\n",
            "Time taken for training worker 2: 0:00:10.365527\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.082164179, Training Accuracy: 43.808\n",
            "Worker 3, [02/2]: Training Loss: 2.106645419, Training Accuracy: 43.368\n",
            "Time taken for training worker 3: 0:00:10.872089\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.987806195, Training Accuracy: 46.632\n",
            "Worker 4, [02/2]: Training Loss: 2.020732411, Training Accuracy: 45.592\n",
            "Time taken for training worker 4: 0:00:10.422342\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000536\n",
            "Local Step 10: Test Loss: 2.114058990, Test Accuracy: 44.120\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.307606360, Training Accuracy: 39.976\n",
            "Worker 1, [02/2]: Training Loss: 1.989507071, Training Accuracy: 46.408\n",
            "Time taken for training worker 1: 0:00:10.617327\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.308896725, Training Accuracy: 39.912\n",
            "Worker 2, [02/2]: Training Loss: 1.989714185, Training Accuracy: 46.344\n",
            "Time taken for training worker 2: 0:00:10.501788\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.291518720, Training Accuracy: 39.528\n",
            "Worker 3, [02/2]: Training Loss: 1.967569979, Training Accuracy: 46.744\n",
            "Time taken for training worker 3: 0:00:10.425654\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.266017894, Training Accuracy: 39.864\n",
            "Worker 4, [02/2]: Training Loss: 1.930503363, Training Accuracy: 47.880\n",
            "Time taken for training worker 4: 0:00:10.594352\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000558\n",
            "Local Step 11: Test Loss: 2.071542009, Test Accuracy: 45.600\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.056487475, Training Accuracy: 44.904\n",
            "Worker 1, [02/2]: Training Loss: 2.062235369, Training Accuracy: 44.952\n",
            "Time taken for training worker 1: 0:00:11.136660\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.020317688, Training Accuracy: 45.488\n",
            "Worker 2, [02/2]: Training Loss: 2.001267144, Training Accuracy: 46.232\n",
            "Time taken for training worker 2: 0:00:11.478089\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.969098682, Training Accuracy: 46.408\n",
            "Worker 3, [02/2]: Training Loss: 1.957420766, Training Accuracy: 46.816\n",
            "Time taken for training worker 3: 0:00:11.122915\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.907805274, Training Accuracy: 48.264\n",
            "Worker 4, [02/2]: Training Loss: 1.901292568, Training Accuracy: 48.704\n",
            "Time taken for training worker 4: 0:00:10.678153\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001068\n",
            "Local Step 12: Test Loss: 2.071236747, Test Accuracy: 45.360\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.194105819, Training Accuracy: 41.712\n",
            "Worker 1, [02/2]: Training Loss: 1.868952887, Training Accuracy: 49.384\n",
            "Time taken for training worker 1: 0:00:10.351919\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.208558021, Training Accuracy: 41.256\n",
            "Worker 2, [02/2]: Training Loss: 1.888311941, Training Accuracy: 48.704\n",
            "Time taken for training worker 2: 0:00:10.427353\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.202745633, Training Accuracy: 41.432\n",
            "Worker 3, [02/2]: Training Loss: 1.881484710, Training Accuracy: 48.752\n",
            "Time taken for training worker 3: 0:00:10.354272\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.181348886, Training Accuracy: 42.080\n",
            "Worker 4, [02/2]: Training Loss: 1.843008350, Training Accuracy: 49.592\n",
            "Time taken for training worker 4: 0:00:10.611972\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000632\n",
            "Local Step 13: Test Loss: 2.035834303, Test Accuracy: 46.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.984621738, Training Accuracy: 46.504\n",
            "Worker 1, [02/2]: Training Loss: 1.970956222, Training Accuracy: 46.984\n",
            "Time taken for training worker 1: 0:00:11.064274\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.936847014, Training Accuracy: 47.680\n",
            "Worker 2, [02/2]: Training Loss: 1.904183125, Training Accuracy: 48.792\n",
            "Time taken for training worker 2: 0:00:10.696387\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.898356398, Training Accuracy: 48.408\n",
            "Worker 3, [02/2]: Training Loss: 1.870167667, Training Accuracy: 49.152\n",
            "Time taken for training worker 3: 0:00:10.504676\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.801402463, Training Accuracy: 50.704\n",
            "Worker 4, [02/2]: Training Loss: 1.822545373, Training Accuracy: 49.944\n",
            "Time taken for training worker 4: 0:00:10.611233\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000655\n",
            "Local Step 14: Test Loss: 1.985244191, Test Accuracy: 47.250\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.107745468, Training Accuracy: 43.720\n",
            "Worker 1, [02/2]: Training Loss: 1.774054182, Training Accuracy: 51.480\n",
            "Time taken for training worker 1: 0:00:10.600094\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.129264892, Training Accuracy: 43.504\n",
            "Worker 2, [02/2]: Training Loss: 1.801663725, Training Accuracy: 51.328\n",
            "Time taken for training worker 2: 0:00:11.110255\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.143098949, Training Accuracy: 43.192\n",
            "Worker 3, [02/2]: Training Loss: 1.800949861, Training Accuracy: 50.424\n",
            "Time taken for training worker 3: 0:00:10.604224\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.094778398, Training Accuracy: 44.072\n",
            "Worker 4, [02/2]: Training Loss: 1.760346336, Training Accuracy: 51.648\n",
            "Time taken for training worker 4: 0:00:10.307089\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000620\n",
            "Local Step 15: Test Loss: 2.073086392, Test Accuracy: 46.360\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.000427874, Training Accuracy: 46.488\n",
            "Worker 1, [02/2]: Training Loss: 1.945212038, Training Accuracy: 47.616\n",
            "Time taken for training worker 1: 0:00:10.066237\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.889450252, Training Accuracy: 48.744\n",
            "Worker 2, [02/2]: Training Loss: 1.840142374, Training Accuracy: 49.576\n",
            "Time taken for training worker 2: 0:00:10.674770\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.810979975, Training Accuracy: 50.104\n",
            "Worker 3, [02/2]: Training Loss: 1.804212004, Training Accuracy: 50.408\n",
            "Time taken for training worker 3: 0:00:10.885260\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.726225188, Training Accuracy: 52.712\n",
            "Worker 4, [02/2]: Training Loss: 1.706100581, Training Accuracy: 52.968\n",
            "Time taken for training worker 4: 0:00:10.872902\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000583\n",
            "Local Step 16: Test Loss: 1.943056847, Test Accuracy: 48.590\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.044925844, Training Accuracy: 45.976\n",
            "Worker 1, [02/2]: Training Loss: 1.709744750, Training Accuracy: 53.328\n",
            "Time taken for training worker 1: 0:00:10.809489\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.092492107, Training Accuracy: 44.256\n",
            "Worker 2, [02/2]: Training Loss: 1.722592491, Training Accuracy: 52.112\n",
            "Time taken for training worker 2: 0:00:10.411162\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.087358519, Training Accuracy: 44.040\n",
            "Worker 3, [02/2]: Training Loss: 1.726805065, Training Accuracy: 51.600\n",
            "Time taken for training worker 3: 0:00:10.722722\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.033133565, Training Accuracy: 45.496\n",
            "Worker 4, [02/2]: Training Loss: 1.681056339, Training Accuracy: 53.160\n",
            "Time taken for training worker 4: 0:00:10.871909\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000655\n",
            "Local Step 17: Test Loss: 1.958710179, Test Accuracy: 48.440\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.854759267, Training Accuracy: 50.104\n",
            "Worker 1, [02/2]: Training Loss: 1.844358299, Training Accuracy: 50.008\n",
            "Time taken for training worker 1: 0:00:11.203097\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.809012814, Training Accuracy: 50.400\n",
            "Worker 2, [02/2]: Training Loss: 1.781165441, Training Accuracy: 51.264\n",
            "Time taken for training worker 2: 0:00:11.526998\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.763218712, Training Accuracy: 51.512\n",
            "Worker 3, [02/2]: Training Loss: 1.732152155, Training Accuracy: 52.032\n",
            "Time taken for training worker 3: 0:00:11.308178\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.667816914, Training Accuracy: 53.512\n",
            "Worker 4, [02/2]: Training Loss: 1.666701763, Training Accuracy: 54.320\n",
            "Time taken for training worker 4: 0:00:11.938848\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000674\n",
            "Local Step 18: Test Loss: 1.967415606, Test Accuracy: 48.120\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.977546389, Training Accuracy: 46.496\n",
            "Worker 1, [02/2]: Training Loss: 1.638020490, Training Accuracy: 54.216\n",
            "Time taken for training worker 1: 0:00:10.136932\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.030863665, Training Accuracy: 45.672\n",
            "Worker 2, [02/2]: Training Loss: 1.658160474, Training Accuracy: 53.904\n",
            "Time taken for training worker 2: 0:00:10.819234\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.022273705, Training Accuracy: 45.424\n",
            "Worker 3, [02/2]: Training Loss: 1.657322229, Training Accuracy: 53.768\n",
            "Time taken for training worker 3: 0:00:10.527201\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.012489487, Training Accuracy: 45.992\n",
            "Worker 4, [02/2]: Training Loss: 1.641386368, Training Accuracy: 55.160\n",
            "Time taken for training worker 4: 0:00:10.680213\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000982\n",
            "Local Step 19: Test Loss: 1.964457942, Test Accuracy: 48.700\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.789628326, Training Accuracy: 51.752\n",
            "Worker 1, [02/2]: Training Loss: 1.767937903, Training Accuracy: 51.320\n",
            "Time taken for training worker 1: 0:00:09.992102\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.774422284, Training Accuracy: 51.256\n",
            "Worker 2, [02/2]: Training Loss: 1.712909210, Training Accuracy: 53.232\n",
            "Time taken for training worker 2: 0:00:10.998641\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.707302203, Training Accuracy: 52.608\n",
            "Worker 3, [02/2]: Training Loss: 1.687509320, Training Accuracy: 53.448\n",
            "Time taken for training worker 3: 0:00:11.409265\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.618262350, Training Accuracy: 55.032\n",
            "Worker 4, [02/2]: Training Loss: 1.591566448, Training Accuracy: 55.952\n",
            "Time taken for training worker 4: 0:00:11.775208\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000670\n",
            "Local Step 20: Test Loss: 1.911284762, Test Accuracy: 49.930\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.930782294, Training Accuracy: 48.040\n",
            "Worker 1, [02/2]: Training Loss: 1.573631792, Training Accuracy: 56.040\n",
            "Time taken for training worker 1: 0:00:10.389967\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.985932125, Training Accuracy: 46.736\n",
            "Worker 2, [02/2]: Training Loss: 1.614695538, Training Accuracy: 55.440\n",
            "Time taken for training worker 2: 0:00:10.346329\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.990724396, Training Accuracy: 45.944\n",
            "Worker 3, [02/2]: Training Loss: 1.637270611, Training Accuracy: 54.296\n",
            "Time taken for training worker 3: 0:00:10.734922\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.981514028, Training Accuracy: 46.776\n",
            "Worker 4, [02/2]: Training Loss: 1.592506249, Training Accuracy: 56.144\n",
            "Time taken for training worker 4: 0:00:11.020873\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000657\n",
            "Local Step 21: Test Loss: 1.958966740, Test Accuracy: 48.980\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.768891178, Training Accuracy: 51.672\n",
            "Worker 1, [02/2]: Training Loss: 1.737274178, Training Accuracy: 52.592\n",
            "Time taken for training worker 1: 0:00:10.390702\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.697903581, Training Accuracy: 53.232\n",
            "Worker 2, [02/2]: Training Loss: 1.674108044, Training Accuracy: 53.928\n",
            "Time taken for training worker 2: 0:00:10.655085\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.667911276, Training Accuracy: 53.384\n",
            "Worker 3, [02/2]: Training Loss: 1.637796962, Training Accuracy: 54.064\n",
            "Time taken for training worker 3: 0:00:10.328510\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.555030069, Training Accuracy: 56.712\n",
            "Worker 4, [02/2]: Training Loss: 1.555453224, Training Accuracy: 56.392\n",
            "Time taken for training worker 4: 0:00:10.681895\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001014\n",
            "Local Step 22: Test Loss: 1.870703419, Test Accuracy: 50.760\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.885206306, Training Accuracy: 48.992\n",
            "Worker 1, [02/2]: Training Loss: 1.527544585, Training Accuracy: 57.536\n",
            "Time taken for training worker 1: 0:00:11.821407\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.940420452, Training Accuracy: 47.616\n",
            "Worker 2, [02/2]: Training Loss: 1.560506243, Training Accuracy: 56.688\n",
            "Time taken for training worker 2: 0:00:11.594655\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.961165066, Training Accuracy: 47.272\n",
            "Worker 3, [02/2]: Training Loss: 1.576000120, Training Accuracy: 55.512\n",
            "Time taken for training worker 3: 0:00:11.054499\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.924957989, Training Accuracy: 48.032\n",
            "Worker 4, [02/2]: Training Loss: 1.575249745, Training Accuracy: 56.256\n",
            "Time taken for training worker 4: 0:00:10.766574\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000629\n",
            "Local Step 23: Test Loss: 1.911439092, Test Accuracy: 49.990\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.712648816, Training Accuracy: 52.584\n",
            "Worker 1, [02/2]: Training Loss: 1.669202640, Training Accuracy: 54.112\n",
            "Time taken for training worker 1: 0:00:10.877578\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.692606007, Training Accuracy: 53.640\n",
            "Worker 2, [02/2]: Training Loss: 1.674045782, Training Accuracy: 54.048\n",
            "Time taken for training worker 2: 0:00:11.098040\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.642618094, Training Accuracy: 53.960\n",
            "Worker 3, [02/2]: Training Loss: 1.615695241, Training Accuracy: 54.864\n",
            "Time taken for training worker 3: 0:00:11.065499\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.555801957, Training Accuracy: 56.560\n",
            "Worker 4, [02/2]: Training Loss: 1.511662765, Training Accuracy: 57.880\n",
            "Time taken for training worker 4: 0:00:11.137315\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000776\n",
            "Local Step 24: Test Loss: 1.865343058, Test Accuracy: 51.340\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.857414140, Training Accuracy: 49.080\n",
            "Worker 1, [02/2]: Training Loss: 1.493711431, Training Accuracy: 58.256\n",
            "Time taken for training worker 1: 0:00:11.057920\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.888426745, Training Accuracy: 48.632\n",
            "Worker 2, [02/2]: Training Loss: 1.523584629, Training Accuracy: 57.088\n",
            "Time taken for training worker 2: 0:00:10.925325\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.935413022, Training Accuracy: 47.352\n",
            "Worker 3, [02/2]: Training Loss: 1.541064683, Training Accuracy: 56.688\n",
            "Time taken for training worker 3: 0:00:11.303648\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.886120296, Training Accuracy: 48.960\n",
            "Worker 4, [02/2]: Training Loss: 1.507313185, Training Accuracy: 57.792\n",
            "Time taken for training worker 4: 0:00:10.955118\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000630\n",
            "Local Step 25: Test Loss: 1.938719246, Test Accuracy: 50.300\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.702569162, Training Accuracy: 52.680\n",
            "Worker 1, [02/2]: Training Loss: 1.636276238, Training Accuracy: 55.056\n",
            "Time taken for training worker 1: 0:00:10.305487\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.659845588, Training Accuracy: 54.344\n",
            "Worker 2, [02/2]: Training Loss: 1.604761605, Training Accuracy: 55.664\n",
            "Time taken for training worker 2: 0:00:10.642868\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.567626046, Training Accuracy: 55.336\n",
            "Worker 3, [02/2]: Training Loss: 1.543987842, Training Accuracy: 56.448\n",
            "Time taken for training worker 3: 0:00:10.339077\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.550194990, Training Accuracy: 56.336\n",
            "Worker 4, [02/2]: Training Loss: 1.499754920, Training Accuracy: 58.064\n",
            "Time taken for training worker 4: 0:00:11.237105\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000697\n",
            "Local Step 26: Test Loss: 1.912469676, Test Accuracy: 50.630\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.834792823, Training Accuracy: 50.336\n",
            "Worker 1, [02/2]: Training Loss: 1.455916466, Training Accuracy: 59.328\n",
            "Time taken for training worker 1: 0:00:10.973629\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.875338398, Training Accuracy: 49.520\n",
            "Worker 2, [02/2]: Training Loss: 1.480970350, Training Accuracy: 58.024\n",
            "Time taken for training worker 2: 0:00:11.867601\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.914195497, Training Accuracy: 47.832\n",
            "Worker 3, [02/2]: Training Loss: 1.498670753, Training Accuracy: 57.696\n",
            "Time taken for training worker 3: 0:00:11.031870\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.836692808, Training Accuracy: 49.368\n",
            "Worker 4, [02/2]: Training Loss: 1.492938231, Training Accuracy: 58.608\n",
            "Time taken for training worker 4: 0:00:11.932869\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000664\n",
            "Local Step 27: Test Loss: 1.902766140, Test Accuracy: 49.860\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.665594848, Training Accuracy: 54.264\n",
            "Worker 1, [02/2]: Training Loss: 1.613181246, Training Accuracy: 55.168\n",
            "Time taken for training worker 1: 0:00:10.481056\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.639866457, Training Accuracy: 54.232\n",
            "Worker 2, [02/2]: Training Loss: 1.589543245, Training Accuracy: 55.960\n",
            "Time taken for training worker 2: 0:00:11.397456\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.551370726, Training Accuracy: 55.936\n",
            "Worker 3, [02/2]: Training Loss: 1.527571324, Training Accuracy: 57.240\n",
            "Time taken for training worker 3: 0:00:11.845499\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.468668848, Training Accuracy: 58.728\n",
            "Worker 4, [02/2]: Training Loss: 1.455777216, Training Accuracy: 59.240\n",
            "Time taken for training worker 4: 0:00:10.979285\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000602\n",
            "Local Step 28: Test Loss: 1.847494589, Test Accuracy: 51.810\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.778123949, Training Accuracy: 51.080\n",
            "Worker 1, [02/2]: Training Loss: 1.426620284, Training Accuracy: 59.616\n",
            "Time taken for training worker 1: 0:00:10.272269\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.857825818, Training Accuracy: 49.696\n",
            "Worker 2, [02/2]: Training Loss: 1.480677449, Training Accuracy: 58.464\n",
            "Time taken for training worker 2: 0:00:11.344314\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.853963447, Training Accuracy: 49.000\n",
            "Worker 3, [02/2]: Training Loss: 1.475380624, Training Accuracy: 58.320\n",
            "Time taken for training worker 3: 0:00:11.146263\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.850864767, Training Accuracy: 49.600\n",
            "Worker 4, [02/2]: Training Loss: 1.456842532, Training Accuracy: 58.920\n",
            "Time taken for training worker 4: 0:00:11.000941\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000602\n",
            "Local Step 29: Test Loss: 1.886539215, Test Accuracy: 50.550\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.627493877, Training Accuracy: 55.232\n",
            "Worker 1, [02/2]: Training Loss: 1.610278099, Training Accuracy: 54.952\n",
            "Time taken for training worker 1: 0:00:10.857312\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.647727529, Training Accuracy: 54.296\n",
            "Worker 2, [02/2]: Training Loss: 1.573913396, Training Accuracy: 56.216\n",
            "Time taken for training worker 2: 0:00:10.555109\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.515768075, Training Accuracy: 57.344\n",
            "Worker 3, [02/2]: Training Loss: 1.501850667, Training Accuracy: 57.832\n",
            "Time taken for training worker 3: 0:00:10.806139\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.479113165, Training Accuracy: 58.424\n",
            "Worker 4, [02/2]: Training Loss: 1.434237614, Training Accuracy: 59.520\n",
            "Time taken for training worker 4: 0:00:11.361693\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000973\n",
            "Local Step 30: Test Loss: 1.890612286, Test Accuracy: 50.400\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.781664068, Training Accuracy: 51.432\n",
            "Worker 1, [02/2]: Training Loss: 1.421884329, Training Accuracy: 59.408\n",
            "Time taken for training worker 1: 0:00:11.001528\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.826715556, Training Accuracy: 50.168\n",
            "Worker 2, [02/2]: Training Loss: 1.430189415, Training Accuracy: 60.120\n",
            "Time taken for training worker 2: 0:00:11.035234\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.853648990, Training Accuracy: 49.424\n",
            "Worker 3, [02/2]: Training Loss: 1.453611494, Training Accuracy: 58.776\n",
            "Time taken for training worker 3: 0:00:11.105465\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.836370449, Training Accuracy: 49.536\n",
            "Worker 4, [02/2]: Training Loss: 1.414235882, Training Accuracy: 59.744\n",
            "Time taken for training worker 4: 0:00:10.399481\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000582\n",
            "Local Step 31: Test Loss: 1.913307425, Test Accuracy: 50.910\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.628148806, Training Accuracy: 55.008\n",
            "Worker 1, [02/2]: Training Loss: 1.589487920, Training Accuracy: 55.784\n",
            "Time taken for training worker 1: 0:00:10.146890\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.523258615, Training Accuracy: 57.752\n",
            "Worker 2, [02/2]: Training Loss: 1.530955614, Training Accuracy: 57.488\n",
            "Time taken for training worker 2: 0:00:10.314584\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.513176575, Training Accuracy: 57.568\n",
            "Worker 3, [02/2]: Training Loss: 1.473779743, Training Accuracy: 58.560\n",
            "Time taken for training worker 3: 0:00:10.869348\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.425786444, Training Accuracy: 59.288\n",
            "Worker 4, [02/2]: Training Loss: 1.408200501, Training Accuracy: 59.920\n",
            "Time taken for training worker 4: 0:00:10.923320\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000769\n",
            "Local Step 32: Test Loss: 1.877943948, Test Accuracy: 51.400\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.719499820, Training Accuracy: 52.592\n",
            "Worker 1, [02/2]: Training Loss: 1.373251274, Training Accuracy: 60.944\n",
            "Time taken for training worker 1: 0:00:10.310980\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.830444815, Training Accuracy: 50.304\n",
            "Worker 2, [02/2]: Training Loss: 1.412342984, Training Accuracy: 59.856\n",
            "Time taken for training worker 2: 0:00:10.308046\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.837545130, Training Accuracy: 49.376\n",
            "Worker 3, [02/2]: Training Loss: 1.448914592, Training Accuracy: 59.120\n",
            "Time taken for training worker 3: 0:00:10.657547\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.809199333, Training Accuracy: 50.240\n",
            "Worker 4, [02/2]: Training Loss: 1.423220104, Training Accuracy: 59.696\n",
            "Time taken for training worker 4: 0:00:10.689753\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000855\n",
            "Local Step 33: Test Loss: 1.846697670, Test Accuracy: 51.820\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.563277949, Training Accuracy: 56.392\n",
            "Worker 1, [02/2]: Training Loss: 1.559450764, Training Accuracy: 56.920\n",
            "Time taken for training worker 1: 0:00:10.697269\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.551233386, Training Accuracy: 56.040\n",
            "Worker 2, [02/2]: Training Loss: 1.505309275, Training Accuracy: 57.712\n",
            "Time taken for training worker 2: 0:00:10.589195\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.528157355, Training Accuracy: 56.568\n",
            "Worker 3, [02/2]: Training Loss: 1.485436391, Training Accuracy: 57.968\n",
            "Time taken for training worker 3: 0:00:10.180302\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.461568106, Training Accuracy: 58.992\n",
            "Worker 4, [02/2]: Training Loss: 1.388180507, Training Accuracy: 60.720\n",
            "Time taken for training worker 4: 0:00:11.222313\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000950\n",
            "Local Step 34: Test Loss: 1.863602692, Test Accuracy: 52.030\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.728257165, Training Accuracy: 52.400\n",
            "Worker 1, [02/2]: Training Loss: 1.366440098, Training Accuracy: 61.200\n",
            "Time taken for training worker 1: 0:00:11.223506\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.796993011, Training Accuracy: 50.664\n",
            "Worker 2, [02/2]: Training Loss: 1.379423251, Training Accuracy: 60.840\n",
            "Time taken for training worker 2: 0:00:11.644476\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.806699596, Training Accuracy: 50.032\n",
            "Worker 3, [02/2]: Training Loss: 1.401466496, Training Accuracy: 60.120\n",
            "Time taken for training worker 3: 0:00:10.630293\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.797885957, Training Accuracy: 50.552\n",
            "Worker 4, [02/2]: Training Loss: 1.381769921, Training Accuracy: 61.304\n",
            "Time taken for training worker 4: 0:00:11.545050\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000693\n",
            "Local Step 35: Test Loss: 1.899092737, Test Accuracy: 51.610\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.582722618, Training Accuracy: 55.696\n",
            "Worker 1, [02/2]: Training Loss: 1.536073941, Training Accuracy: 57.224\n",
            "Time taken for training worker 1: 0:00:11.009232\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.529782001, Training Accuracy: 57.304\n",
            "Worker 2, [02/2]: Training Loss: 1.496746580, Training Accuracy: 57.608\n",
            "Time taken for training worker 2: 0:00:10.351336\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.490247553, Training Accuracy: 57.432\n",
            "Worker 3, [02/2]: Training Loss: 1.464197996, Training Accuracy: 58.408\n",
            "Time taken for training worker 3: 0:00:10.607244\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.398082156, Training Accuracy: 60.488\n",
            "Worker 4, [02/2]: Training Loss: 1.353575832, Training Accuracy: 61.264\n",
            "Time taken for training worker 4: 0:00:10.406376\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000580\n",
            "Local Step 36: Test Loss: 1.793979859, Test Accuracy: 52.580\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.723145335, Training Accuracy: 52.728\n",
            "Worker 1, [02/2]: Training Loss: 1.324678094, Training Accuracy: 62.424\n",
            "Time taken for training worker 1: 0:00:10.626823\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.784029414, Training Accuracy: 50.808\n",
            "Worker 2, [02/2]: Training Loss: 1.414827536, Training Accuracy: 60.448\n",
            "Time taken for training worker 2: 0:00:10.341838\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.788580314, Training Accuracy: 50.824\n",
            "Worker 3, [02/2]: Training Loss: 1.417387917, Training Accuracy: 59.816\n",
            "Time taken for training worker 3: 0:00:10.836748\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.770406945, Training Accuracy: 51.344\n",
            "Worker 4, [02/2]: Training Loss: 1.376339206, Training Accuracy: 61.432\n",
            "Time taken for training worker 4: 0:00:10.193470\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000664\n",
            "Local Step 37: Test Loss: 1.925996871, Test Accuracy: 50.560\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.595485465, Training Accuracy: 55.176\n",
            "Worker 1, [02/2]: Training Loss: 1.519670454, Training Accuracy: 57.104\n",
            "Time taken for training worker 1: 0:00:10.597282\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.505675662, Training Accuracy: 57.920\n",
            "Worker 2, [02/2]: Training Loss: 1.485751185, Training Accuracy: 58.392\n",
            "Time taken for training worker 2: 0:00:10.773495\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.472128278, Training Accuracy: 58.376\n",
            "Worker 3, [02/2]: Training Loss: 1.410893662, Training Accuracy: 59.512\n",
            "Time taken for training worker 3: 0:00:10.588831\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.360409246, Training Accuracy: 60.776\n",
            "Worker 4, [02/2]: Training Loss: 1.342109509, Training Accuracy: 61.896\n",
            "Time taken for training worker 4: 0:00:10.454400\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000660\n",
            "Local Step 38: Test Loss: 1.859557815, Test Accuracy: 52.260\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.721148464, Training Accuracy: 52.840\n",
            "Worker 1, [02/2]: Training Loss: 1.326678842, Training Accuracy: 61.904\n",
            "Time taken for training worker 1: 0:00:11.101347\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.770320352, Training Accuracy: 52.024\n",
            "Worker 2, [02/2]: Training Loss: 1.368024915, Training Accuracy: 60.920\n",
            "Time taken for training worker 2: 0:00:10.250022\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.791121964, Training Accuracy: 50.504\n",
            "Worker 3, [02/2]: Training Loss: 1.365932566, Training Accuracy: 61.192\n",
            "Time taken for training worker 3: 0:00:10.111217\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.769807880, Training Accuracy: 51.800\n",
            "Worker 4, [02/2]: Training Loss: 1.348926877, Training Accuracy: 62.016\n",
            "Time taken for training worker 4: 0:00:10.366238\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000967\n",
            "Local Step 39: Test Loss: 1.902316661, Test Accuracy: 50.570\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.562879211, Training Accuracy: 56.328\n",
            "Worker 1, [02/2]: Training Loss: 1.485194638, Training Accuracy: 58.440\n",
            "Time taken for training worker 1: 0:00:11.608494\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.482725977, Training Accuracy: 58.400\n",
            "Worker 2, [02/2]: Training Loss: 1.461147907, Training Accuracy: 59.016\n",
            "Time taken for training worker 2: 0:00:10.280480\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.435081018, Training Accuracy: 59.240\n",
            "Worker 3, [02/2]: Training Loss: 1.400872316, Training Accuracy: 59.944\n",
            "Time taken for training worker 3: 0:00:10.378141\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.366050747, Training Accuracy: 60.784\n",
            "Worker 4, [02/2]: Training Loss: 1.328864577, Training Accuracy: 61.872\n",
            "Time taken for training worker 4: 0:00:10.565630\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000602\n",
            "Local Step 40: Test Loss: 1.854371804, Test Accuracy: 52.170\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.688492315, Training Accuracy: 53.016\n",
            "Worker 1, [02/2]: Training Loss: 1.295310702, Training Accuracy: 63.040\n",
            "Time taken for training worker 1: 0:00:11.177896\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.756589258, Training Accuracy: 51.176\n",
            "Worker 2, [02/2]: Training Loss: 1.344393461, Training Accuracy: 61.360\n",
            "Time taken for training worker 2: 0:00:11.686363\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.779603574, Training Accuracy: 50.424\n",
            "Worker 3, [02/2]: Training Loss: 1.363344228, Training Accuracy: 61.072\n",
            "Time taken for training worker 3: 0:00:10.701569\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.735031729, Training Accuracy: 51.816\n",
            "Worker 4, [02/2]: Training Loss: 1.360690971, Training Accuracy: 61.232\n",
            "Time taken for training worker 4: 0:00:11.292457\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000661\n",
            "Local Step 41: Test Loss: 1.872689756, Test Accuracy: 52.150\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.532655160, Training Accuracy: 57.120\n",
            "Worker 1, [02/2]: Training Loss: 1.472930516, Training Accuracy: 58.760\n",
            "Time taken for training worker 1: 0:00:10.892202\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.479481782, Training Accuracy: 58.648\n",
            "Worker 2, [02/2]: Training Loss: 1.453226608, Training Accuracy: 59.376\n",
            "Time taken for training worker 2: 0:00:10.538753\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.472324016, Training Accuracy: 58.120\n",
            "Worker 3, [02/2]: Training Loss: 1.400056679, Training Accuracy: 60.072\n",
            "Time taken for training worker 3: 0:00:10.482001\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.385585985, Training Accuracy: 60.576\n",
            "Worker 4, [02/2]: Training Loss: 1.314398772, Training Accuracy: 62.768\n",
            "Time taken for training worker 4: 0:00:10.770134\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000657\n",
            "Local Step 42: Test Loss: 1.854015074, Test Accuracy: 52.320\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.667907913, Training Accuracy: 54.312\n",
            "Worker 1, [02/2]: Training Loss: 1.296718062, Training Accuracy: 63.456\n",
            "Time taken for training worker 1: 0:00:10.359226\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.735795469, Training Accuracy: 52.224\n",
            "Worker 2, [02/2]: Training Loss: 1.337625901, Training Accuracy: 61.864\n",
            "Time taken for training worker 2: 0:00:10.389370\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.749801091, Training Accuracy: 51.672\n",
            "Worker 3, [02/2]: Training Loss: 1.380940646, Training Accuracy: 60.632\n",
            "Time taken for training worker 3: 0:00:10.298911\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.727749719, Training Accuracy: 52.088\n",
            "Worker 4, [02/2]: Training Loss: 1.341091053, Training Accuracy: 61.480\n",
            "Time taken for training worker 4: 0:00:10.334156\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000616\n",
            "Local Step 43: Test Loss: 1.918381787, Test Accuracy: 50.990\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.549720114, Training Accuracy: 56.616\n",
            "Worker 1, [02/2]: Training Loss: 1.495134675, Training Accuracy: 57.520\n",
            "Time taken for training worker 1: 0:00:11.489766\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.483286946, Training Accuracy: 58.240\n",
            "Worker 2, [02/2]: Training Loss: 1.413838219, Training Accuracy: 59.872\n",
            "Time taken for training worker 2: 0:00:11.781998\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.388554285, Training Accuracy: 59.912\n",
            "Worker 3, [02/2]: Training Loss: 1.370810692, Training Accuracy: 60.248\n",
            "Time taken for training worker 3: 0:00:10.518802\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.360952373, Training Accuracy: 60.864\n",
            "Worker 4, [02/2]: Training Loss: 1.293239536, Training Accuracy: 62.944\n",
            "Time taken for training worker 4: 0:00:10.861389\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000736\n",
            "Local Step 44: Test Loss: 1.868374035, Test Accuracy: 52.260\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.689166980, Training Accuracy: 53.192\n",
            "Worker 1, [02/2]: Training Loss: 1.280952189, Training Accuracy: 63.992\n",
            "Time taken for training worker 1: 0:00:11.194006\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.737221060, Training Accuracy: 52.280\n",
            "Worker 2, [02/2]: Training Loss: 1.333267897, Training Accuracy: 61.912\n",
            "Time taken for training worker 2: 0:00:09.970309\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.743694681, Training Accuracy: 51.408\n",
            "Worker 3, [02/2]: Training Loss: 1.350940193, Training Accuracy: 61.624\n",
            "Time taken for training worker 3: 0:00:10.782680\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.737329313, Training Accuracy: 51.816\n",
            "Worker 4, [02/2]: Training Loss: 1.339920512, Training Accuracy: 61.672\n",
            "Time taken for training worker 4: 0:00:10.447525\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000735\n",
            "Local Step 45: Test Loss: 1.874441372, Test Accuracy: 51.960\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.509183930, Training Accuracy: 57.720\n",
            "Worker 1, [02/2]: Training Loss: 1.462709507, Training Accuracy: 58.416\n",
            "Time taken for training worker 1: 0:00:10.547696\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.513414501, Training Accuracy: 57.336\n",
            "Worker 2, [02/2]: Training Loss: 1.422144891, Training Accuracy: 59.824\n",
            "Time taken for training worker 2: 0:00:10.318169\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.408364958, Training Accuracy: 59.912\n",
            "Worker 3, [02/2]: Training Loss: 1.372633530, Training Accuracy: 60.456\n",
            "Time taken for training worker 3: 0:00:10.270823\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.338980557, Training Accuracy: 61.608\n",
            "Worker 4, [02/2]: Training Loss: 1.293753109, Training Accuracy: 63.040\n",
            "Time taken for training worker 4: 0:00:10.238533\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000780\n",
            "Local Step 46: Test Loss: 1.839386063, Test Accuracy: 52.140\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.651225122, Training Accuracy: 53.792\n",
            "Worker 1, [02/2]: Training Loss: 1.263305007, Training Accuracy: 63.864\n",
            "Time taken for training worker 1: 0:00:10.242854\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.735406109, Training Accuracy: 52.656\n",
            "Worker 2, [02/2]: Training Loss: 1.316272325, Training Accuracy: 62.504\n",
            "Time taken for training worker 2: 0:00:10.862622\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.726315754, Training Accuracy: 52.056\n",
            "Worker 3, [02/2]: Training Loss: 1.309026629, Training Accuracy: 62.440\n",
            "Time taken for training worker 3: 0:00:10.629968\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.725515172, Training Accuracy: 52.248\n",
            "Worker 4, [02/2]: Training Loss: 1.333795249, Training Accuracy: 61.984\n",
            "Time taken for training worker 4: 0:00:10.462890\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000780\n",
            "Local Step 47: Test Loss: 1.900264200, Test Accuracy: 51.200\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.506662510, Training Accuracy: 57.984\n",
            "Worker 1, [02/2]: Training Loss: 1.476792858, Training Accuracy: 58.768\n",
            "Time taken for training worker 1: 0:00:10.687769\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.460962504, Training Accuracy: 58.736\n",
            "Worker 2, [02/2]: Training Loss: 1.423330211, Training Accuracy: 59.480\n",
            "Time taken for training worker 2: 0:00:10.651555\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.393863863, Training Accuracy: 60.304\n",
            "Worker 3, [02/2]: Training Loss: 1.361750983, Training Accuracy: 60.872\n",
            "Time taken for training worker 3: 0:00:10.163774\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.317539641, Training Accuracy: 62.352\n",
            "Worker 4, [02/2]: Training Loss: 1.291389701, Training Accuracy: 63.128\n",
            "Time taken for training worker 4: 0:00:10.922721\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000832\n",
            "Local Step 48: Test Loss: 1.865288964, Test Accuracy: 52.980\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.654126102, Training Accuracy: 54.248\n",
            "Worker 1, [02/2]: Training Loss: 1.247451417, Training Accuracy: 64.424\n",
            "Time taken for training worker 1: 0:00:10.416709\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.717972336, Training Accuracy: 52.848\n",
            "Worker 2, [02/2]: Training Loss: 1.325440704, Training Accuracy: 62.456\n",
            "Time taken for training worker 2: 0:00:10.385772\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.719092654, Training Accuracy: 52.904\n",
            "Worker 3, [02/2]: Training Loss: 1.310397663, Training Accuracy: 62.408\n",
            "Time taken for training worker 3: 0:00:10.458449\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.728517402, Training Accuracy: 52.232\n",
            "Worker 4, [02/2]: Training Loss: 1.324760596, Training Accuracy: 62.376\n",
            "Time taken for training worker 4: 0:00:10.781880\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000911\n",
            "Local Step 49: Test Loss: 1.925054246, Test Accuracy: 50.680\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.535926437, Training Accuracy: 57.192\n",
            "Worker 1, [02/2]: Training Loss: 1.451967398, Training Accuracy: 59.240\n",
            "Time taken for training worker 1: 0:00:10.394922\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.489593783, Training Accuracy: 58.384\n",
            "Worker 2, [02/2]: Training Loss: 1.402073125, Training Accuracy: 60.480\n",
            "Time taken for training worker 2: 0:00:10.923004\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.373110110, Training Accuracy: 60.936\n",
            "Worker 3, [02/2]: Training Loss: 1.337971193, Training Accuracy: 61.896\n",
            "Time taken for training worker 3: 0:00:10.648212\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.254293979, Training Accuracy: 63.816\n",
            "Worker 4, [02/2]: Training Loss: 1.277827197, Training Accuracy: 63.384\n",
            "Time taken for training worker 4: 0:00:10.303210\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000679\n",
            "Local Step 50: Test Loss: 1.873896660, Test Accuracy: 51.620\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.635427629, Training Accuracy: 54.632\n",
            "Worker 1, [02/2]: Training Loss: 1.256616113, Training Accuracy: 63.888\n",
            "Time taken for training worker 1: 0:00:11.062169\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.704067529, Training Accuracy: 53.192\n",
            "Worker 2, [02/2]: Training Loss: 1.330880547, Training Accuracy: 62.280\n",
            "Time taken for training worker 2: 0:00:11.500091\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.728365741, Training Accuracy: 52.328\n",
            "Worker 3, [02/2]: Training Loss: 1.306892950, Training Accuracy: 62.912\n",
            "Time taken for training worker 3: 0:00:11.112536\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.709335854, Training Accuracy: 52.856\n",
            "Worker 4, [02/2]: Training Loss: 1.303270565, Training Accuracy: 63.096\n",
            "Time taken for training worker 4: 0:00:10.574849\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000586\n",
            "Local Step 51: Test Loss: 1.878607964, Test Accuracy: 51.750\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.482463036, Training Accuracy: 58.168\n",
            "Worker 1, [02/2]: Training Loss: 1.451002889, Training Accuracy: 59.024\n",
            "Time taken for training worker 1: 0:00:11.076390\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.418267879, Training Accuracy: 59.680\n",
            "Worker 2, [02/2]: Training Loss: 1.373518833, Training Accuracy: 60.848\n",
            "Time taken for training worker 2: 0:00:11.755515\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.411592415, Training Accuracy: 60.776\n",
            "Worker 3, [02/2]: Training Loss: 1.347089381, Training Accuracy: 61.208\n",
            "Time taken for training worker 3: 0:00:11.237480\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.270276544, Training Accuracy: 63.576\n",
            "Worker 4, [02/2]: Training Loss: 1.276121568, Training Accuracy: 63.384\n",
            "Time taken for training worker 4: 0:00:11.673662\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000745\n",
            "Local Step 52: Test Loss: 1.821159098, Test Accuracy: 52.510\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.627927862, Training Accuracy: 54.848\n",
            "Worker 1, [02/2]: Training Loss: 1.231400398, Training Accuracy: 64.776\n",
            "Time taken for training worker 1: 0:00:11.833736\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.707650991, Training Accuracy: 52.840\n",
            "Worker 2, [02/2]: Training Loss: 1.288118630, Training Accuracy: 63.280\n",
            "Time taken for training worker 2: 0:00:11.517499\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.718759640, Training Accuracy: 52.528\n",
            "Worker 3, [02/2]: Training Loss: 1.286255235, Training Accuracy: 62.832\n",
            "Time taken for training worker 3: 0:00:11.528811\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.713598178, Training Accuracy: 52.176\n",
            "Worker 4, [02/2]: Training Loss: 1.289147829, Training Accuracy: 63.024\n",
            "Time taken for training worker 4: 0:00:11.019845\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000605\n",
            "Local Step 53: Test Loss: 1.896005306, Test Accuracy: 51.750\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.473445547, Training Accuracy: 58.928\n",
            "Worker 1, [02/2]: Training Loss: 1.422904671, Training Accuracy: 59.936\n",
            "Time taken for training worker 1: 0:00:11.120707\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.416187427, Training Accuracy: 59.960\n",
            "Worker 2, [02/2]: Training Loss: 1.396374249, Training Accuracy: 60.616\n",
            "Time taken for training worker 2: 0:00:10.315589\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.431845421, Training Accuracy: 59.816\n",
            "Worker 3, [02/2]: Training Loss: 1.333203512, Training Accuracy: 61.520\n",
            "Time taken for training worker 3: 0:00:09.943310\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.297889569, Training Accuracy: 62.760\n",
            "Worker 4, [02/2]: Training Loss: 1.255517304, Training Accuracy: 64.192\n",
            "Time taken for training worker 4: 0:00:10.822774\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000792\n",
            "Local Step 54: Test Loss: 1.877911927, Test Accuracy: 51.710\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.623481507, Training Accuracy: 55.304\n",
            "Worker 1, [02/2]: Training Loss: 1.229660259, Training Accuracy: 64.824\n",
            "Time taken for training worker 1: 0:00:10.241725\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.698447812, Training Accuracy: 53.096\n",
            "Worker 2, [02/2]: Training Loss: 1.295364259, Training Accuracy: 63.032\n",
            "Time taken for training worker 2: 0:00:10.562166\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.692010822, Training Accuracy: 52.904\n",
            "Worker 3, [02/2]: Training Loss: 1.277240064, Training Accuracy: 62.848\n",
            "Time taken for training worker 3: 0:00:11.026094\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.720145860, Training Accuracy: 52.376\n",
            "Worker 4, [02/2]: Training Loss: 1.295680062, Training Accuracy: 62.552\n",
            "Time taken for training worker 4: 0:00:10.704027\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000638\n",
            "Local Step 55: Test Loss: 1.913152399, Test Accuracy: 51.730\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.501200847, Training Accuracy: 57.536\n",
            "Worker 1, [02/2]: Training Loss: 1.411392854, Training Accuracy: 59.696\n",
            "Time taken for training worker 1: 0:00:10.399810\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.438863997, Training Accuracy: 59.624\n",
            "Worker 2, [02/2]: Training Loss: 1.363256229, Training Accuracy: 60.864\n",
            "Time taken for training worker 2: 0:00:10.786802\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.353676010, Training Accuracy: 60.984\n",
            "Worker 3, [02/2]: Training Loss: 1.324365477, Training Accuracy: 61.424\n",
            "Time taken for training worker 3: 0:00:10.415061\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.248133705, Training Accuracy: 64.296\n",
            "Worker 4, [02/2]: Training Loss: 1.244726236, Training Accuracy: 63.912\n",
            "Time taken for training worker 4: 0:00:10.754961\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000628\n",
            "Local Step 56: Test Loss: 1.887100294, Test Accuracy: 51.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.639528006, Training Accuracy: 54.128\n",
            "Worker 1, [02/2]: Training Loss: 1.245634558, Training Accuracy: 64.656\n",
            "Time taken for training worker 1: 0:00:11.104074\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.686774101, Training Accuracy: 52.832\n",
            "Worker 2, [02/2]: Training Loss: 1.260303042, Training Accuracy: 63.912\n",
            "Time taken for training worker 2: 0:00:10.432903\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.694843085, Training Accuracy: 52.704\n",
            "Worker 3, [02/2]: Training Loss: 1.291806250, Training Accuracy: 62.704\n",
            "Time taken for training worker 3: 0:00:11.492822\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.693376708, Training Accuracy: 52.960\n",
            "Worker 4, [02/2]: Training Loss: 1.257141289, Training Accuracy: 63.952\n",
            "Time taken for training worker 4: 0:00:11.361438\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001012\n",
            "Local Step 57: Test Loss: 1.901527760, Test Accuracy: 51.220\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.485251910, Training Accuracy: 58.560\n",
            "Worker 1, [02/2]: Training Loss: 1.406676499, Training Accuracy: 60.336\n",
            "Time taken for training worker 1: 0:00:10.714405\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.425785663, Training Accuracy: 59.480\n",
            "Worker 2, [02/2]: Training Loss: 1.362557261, Training Accuracy: 61.304\n",
            "Time taken for training worker 2: 0:00:10.641308\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.348810219, Training Accuracy: 60.856\n",
            "Worker 3, [02/2]: Training Loss: 1.308158271, Training Accuracy: 62.184\n",
            "Time taken for training worker 3: 0:00:11.377433\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.304282873, Training Accuracy: 62.384\n",
            "Worker 4, [02/2]: Training Loss: 1.250689605, Training Accuracy: 64.128\n",
            "Time taken for training worker 4: 0:00:11.064089\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000723\n",
            "Local Step 58: Test Loss: 1.860958130, Test Accuracy: 52.850\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.619025131, Training Accuracy: 55.160\n",
            "Worker 1, [02/2]: Training Loss: 1.223426470, Training Accuracy: 64.960\n",
            "Time taken for training worker 1: 0:00:11.183855\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.658099296, Training Accuracy: 53.608\n",
            "Worker 2, [02/2]: Training Loss: 1.268878809, Training Accuracy: 63.880\n",
            "Time taken for training worker 2: 0:00:10.930683\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.681175914, Training Accuracy: 52.488\n",
            "Worker 3, [02/2]: Training Loss: 1.258971278, Training Accuracy: 63.504\n",
            "Time taken for training worker 3: 0:00:10.965661\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.699814529, Training Accuracy: 53.096\n",
            "Worker 4, [02/2]: Training Loss: 1.282911807, Training Accuracy: 63.600\n",
            "Time taken for training worker 4: 0:00:10.904250\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000598\n",
            "Local Step 59: Test Loss: 1.899436451, Test Accuracy: 51.890\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.472212711, Training Accuracy: 59.056\n",
            "Worker 1, [02/2]: Training Loss: 1.414857113, Training Accuracy: 59.952\n",
            "Time taken for training worker 1: 0:00:10.370951\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.406628358, Training Accuracy: 60.416\n",
            "Worker 2, [02/2]: Training Loss: 1.375914529, Training Accuracy: 61.040\n",
            "Time taken for training worker 2: 0:00:10.803838\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.371079727, Training Accuracy: 61.248\n",
            "Worker 3, [02/2]: Training Loss: 1.290282141, Training Accuracy: 62.408\n",
            "Time taken for training worker 3: 0:00:11.332286\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.240617448, Training Accuracy: 63.840\n",
            "Worker 4, [02/2]: Training Loss: 1.233516355, Training Accuracy: 64.336\n",
            "Time taken for training worker 4: 0:00:10.499630\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000694\n",
            "Local Step 60: Test Loss: 1.845626599, Test Accuracy: 52.940\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.589359093, Training Accuracy: 55.904\n",
            "Worker 1, [02/2]: Training Loss: 1.217371928, Training Accuracy: 65.408\n",
            "Time taken for training worker 1: 0:00:10.280016\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.673428479, Training Accuracy: 53.296\n",
            "Worker 2, [02/2]: Training Loss: 1.243944568, Training Accuracy: 64.128\n",
            "Time taken for training worker 2: 0:00:10.363292\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.695403399, Training Accuracy: 52.912\n",
            "Worker 3, [02/2]: Training Loss: 1.283660359, Training Accuracy: 62.968\n",
            "Time taken for training worker 3: 0:00:10.139870\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.699463809, Training Accuracy: 52.792\n",
            "Worker 4, [02/2]: Training Loss: 1.269014637, Training Accuracy: 63.440\n",
            "Time taken for training worker 4: 0:00:10.856738\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000636\n",
            "Local Step 61: Test Loss: 1.888520891, Test Accuracy: 51.930\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.439051979, Training Accuracy: 59.000\n",
            "Worker 1, [02/2]: Training Loss: 1.401038119, Training Accuracy: 60.648\n",
            "Time taken for training worker 1: 0:00:10.413722\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.443449580, Training Accuracy: 59.312\n",
            "Worker 2, [02/2]: Training Loss: 1.353527537, Training Accuracy: 61.184\n",
            "Time taken for training worker 2: 0:00:10.608835\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.334326553, Training Accuracy: 61.792\n",
            "Worker 3, [02/2]: Training Loss: 1.300539083, Training Accuracy: 62.416\n",
            "Time taken for training worker 3: 0:00:11.698318\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.265211089, Training Accuracy: 63.696\n",
            "Worker 4, [02/2]: Training Loss: 1.230810400, Training Accuracy: 64.688\n",
            "Time taken for training worker 4: 0:00:10.654754\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000675\n",
            "Local Step 62: Test Loss: 1.851005092, Test Accuracy: 52.310\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.597949338, Training Accuracy: 55.464\n",
            "Worker 1, [02/2]: Training Loss: 1.185339767, Training Accuracy: 66.152\n",
            "Time taken for training worker 1: 0:00:10.388453\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.678084106, Training Accuracy: 53.432\n",
            "Worker 2, [02/2]: Training Loss: 1.257405568, Training Accuracy: 64.552\n",
            "Time taken for training worker 2: 0:00:10.288632\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.677328171, Training Accuracy: 53.080\n",
            "Worker 3, [02/2]: Training Loss: 1.278060336, Training Accuracy: 63.120\n",
            "Time taken for training worker 3: 0:00:10.506411\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.683410570, Training Accuracy: 53.224\n",
            "Worker 4, [02/2]: Training Loss: 1.269234508, Training Accuracy: 63.752\n",
            "Time taken for training worker 4: 0:00:10.572657\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000631\n",
            "Local Step 63: Test Loss: 1.890682401, Test Accuracy: 51.420\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.440391022, Training Accuracy: 59.312\n",
            "Worker 1, [02/2]: Training Loss: 1.378304789, Training Accuracy: 60.584\n",
            "Time taken for training worker 1: 0:00:11.597398\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.416800095, Training Accuracy: 59.936\n",
            "Worker 2, [02/2]: Training Loss: 1.347348343, Training Accuracy: 61.440\n",
            "Time taken for training worker 2: 0:00:10.450680\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.348515939, Training Accuracy: 61.520\n",
            "Worker 3, [02/2]: Training Loss: 1.289616209, Training Accuracy: 63.224\n",
            "Time taken for training worker 3: 0:00:10.265778\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.288905639, Training Accuracy: 63.064\n",
            "Worker 4, [02/2]: Training Loss: 1.238259553, Training Accuracy: 63.984\n",
            "Time taken for training worker 4: 0:00:10.745662\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001020\n",
            "Local Step 64: Test Loss: 1.835262084, Test Accuracy: 52.680\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:46:53.881523\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.593017238, Training Accuracy: 1.392\n",
            "Worker 1, [02/37]: Training Loss: 4.438430596, Training Accuracy: 3.184\n",
            "Worker 1, [03/37]: Training Loss: 4.192359932, Training Accuracy: 5.424\n",
            "Worker 1, [04/37]: Training Loss: 4.057424005, Training Accuracy: 7.024\n",
            "Worker 1, [05/37]: Training Loss: 3.947833244, Training Accuracy: 8.736\n",
            "Worker 1, [06/37]: Training Loss: 3.843711860, Training Accuracy: 10.720\n",
            "Worker 1, [07/37]: Training Loss: 3.752451816, Training Accuracy: 11.360\n",
            "Worker 1, [08/37]: Training Loss: 3.662737447, Training Accuracy: 13.072\n",
            "Worker 1, [09/37]: Training Loss: 3.583450685, Training Accuracy: 14.960\n",
            "Worker 1, [10/37]: Training Loss: 3.475540577, Training Accuracy: 16.160\n",
            "Worker 1, [11/37]: Training Loss: 3.433992880, Training Accuracy: 17.040\n",
            "Worker 1, [12/37]: Training Loss: 3.328677336, Training Accuracy: 18.576\n",
            "Worker 1, [13/37]: Training Loss: 3.281595398, Training Accuracy: 19.984\n",
            "Worker 1, [14/37]: Training Loss: 3.210747456, Training Accuracy: 21.664\n",
            "Worker 1, [15/37]: Training Loss: 3.135100194, Training Accuracy: 21.856\n",
            "Worker 1, [16/37]: Training Loss: 3.026095390, Training Accuracy: 24.240\n",
            "Worker 1, [17/37]: Training Loss: 2.982743022, Training Accuracy: 24.400\n",
            "Worker 1, [18/37]: Training Loss: 2.889493709, Training Accuracy: 25.904\n",
            "Worker 1, [19/37]: Training Loss: 2.861739752, Training Accuracy: 26.672\n",
            "Worker 1, [20/37]: Training Loss: 2.767311276, Training Accuracy: 28.928\n",
            "Worker 1, [21/37]: Training Loss: 2.699705355, Training Accuracy: 30.192\n",
            "Worker 1, [22/37]: Training Loss: 2.642044252, Training Accuracy: 31.136\n",
            "Worker 1, [23/37]: Training Loss: 2.575264627, Training Accuracy: 32.880\n",
            "Worker 1, [24/37]: Training Loss: 2.506809018, Training Accuracy: 33.952\n",
            "Worker 1, [25/37]: Training Loss: 2.446967857, Training Accuracy: 35.680\n",
            "Worker 1, [26/37]: Training Loss: 2.400348781, Training Accuracy: 36.976\n",
            "Worker 1, [27/37]: Training Loss: 2.340128096, Training Accuracy: 38.192\n",
            "Worker 1, [28/37]: Training Loss: 2.276764444, Training Accuracy: 39.824\n",
            "Worker 1, [29/37]: Training Loss: 2.235903028, Training Accuracy: 40.272\n",
            "Worker 1, [30/37]: Training Loss: 2.175147928, Training Accuracy: 42.144\n",
            "Worker 1, [31/37]: Training Loss: 2.124158828, Training Accuracy: 42.896\n",
            "Worker 1, [32/37]: Training Loss: 2.091433607, Training Accuracy: 43.920\n",
            "Worker 1, [33/37]: Training Loss: 2.067863219, Training Accuracy: 44.896\n",
            "Worker 1, [34/37]: Training Loss: 2.036021653, Training Accuracy: 45.760\n",
            "Worker 1, [35/37]: Training Loss: 2.011993283, Training Accuracy: 46.512\n",
            "Worker 1, [36/37]: Training Loss: 1.994871812, Training Accuracy: 46.816\n",
            "Worker 1, [37/37]: Training Loss: 1.979785727, Training Accuracy: 46.976\n",
            "Time taken for training worker 1: 0:01:39.748177\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.594309549, Training Accuracy: 1.392\n",
            "Worker 2, [02/37]: Training Loss: 4.463448953, Training Accuracy: 3.248\n",
            "Worker 2, [03/37]: Training Loss: 4.211571951, Training Accuracy: 5.136\n",
            "Worker 2, [04/37]: Training Loss: 4.062105870, Training Accuracy: 6.944\n",
            "Worker 2, [05/37]: Training Loss: 3.948145280, Training Accuracy: 8.848\n",
            "Worker 2, [06/37]: Training Loss: 3.855218975, Training Accuracy: 9.648\n",
            "Worker 2, [07/37]: Training Loss: 3.761202029, Training Accuracy: 11.856\n",
            "Worker 2, [08/37]: Training Loss: 3.676971990, Training Accuracy: 12.320\n",
            "Worker 2, [09/37]: Training Loss: 3.585811703, Training Accuracy: 14.048\n",
            "Worker 2, [10/37]: Training Loss: 3.518880954, Training Accuracy: 14.912\n",
            "Worker 2, [11/37]: Training Loss: 3.419565646, Training Accuracy: 16.160\n",
            "Worker 2, [12/37]: Training Loss: 3.366010929, Training Accuracy: 18.144\n",
            "Worker 2, [13/37]: Training Loss: 3.274883803, Training Accuracy: 19.600\n",
            "Worker 2, [14/37]: Training Loss: 3.199363584, Training Accuracy: 20.640\n",
            "Worker 2, [15/37]: Training Loss: 3.128925029, Training Accuracy: 21.568\n",
            "Worker 2, [16/37]: Training Loss: 3.062094299, Training Accuracy: 23.120\n",
            "Worker 2, [17/37]: Training Loss: 3.000264883, Training Accuracy: 24.384\n",
            "Worker 2, [18/37]: Training Loss: 2.908880163, Training Accuracy: 26.560\n",
            "Worker 2, [19/37]: Training Loss: 2.886477086, Training Accuracy: 26.400\n",
            "Worker 2, [20/37]: Training Loss: 2.800483237, Training Accuracy: 27.440\n",
            "Worker 2, [21/37]: Training Loss: 2.744102254, Training Accuracy: 28.752\n",
            "Worker 2, [22/37]: Training Loss: 2.670001711, Training Accuracy: 30.176\n",
            "Worker 2, [23/37]: Training Loss: 2.593571726, Training Accuracy: 32.224\n",
            "Worker 2, [24/37]: Training Loss: 2.536272326, Training Accuracy: 33.168\n",
            "Worker 2, [25/37]: Training Loss: 2.471679318, Training Accuracy: 33.968\n",
            "Worker 2, [26/37]: Training Loss: 2.402448410, Training Accuracy: 36.560\n",
            "Worker 2, [27/37]: Training Loss: 2.354795508, Training Accuracy: 37.344\n",
            "Worker 2, [28/37]: Training Loss: 2.305188143, Training Accuracy: 37.696\n",
            "Worker 2, [29/37]: Training Loss: 2.241666554, Training Accuracy: 39.872\n",
            "Worker 2, [30/37]: Training Loss: 2.179669518, Training Accuracy: 41.152\n",
            "Worker 2, [31/37]: Training Loss: 2.145515443, Training Accuracy: 42.208\n",
            "Worker 2, [32/37]: Training Loss: 2.092040349, Training Accuracy: 44.224\n",
            "Worker 2, [33/37]: Training Loss: 2.069146027, Training Accuracy: 44.032\n",
            "Worker 2, [34/37]: Training Loss: 2.047354466, Training Accuracy: 45.168\n",
            "Worker 2, [35/37]: Training Loss: 2.024185035, Training Accuracy: 44.976\n",
            "Worker 2, [36/37]: Training Loss: 1.994134204, Training Accuracy: 45.632\n",
            "Worker 2, [37/37]: Training Loss: 1.981690845, Training Accuracy: 46.240\n",
            "Time taken for training worker 2: 0:01:39.922547\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.593409095, Training Accuracy: 1.504\n",
            "Worker 3, [02/37]: Training Loss: 4.450160606, Training Accuracy: 3.440\n",
            "Worker 3, [03/37]: Training Loss: 4.190631373, Training Accuracy: 5.936\n",
            "Worker 3, [04/37]: Training Loss: 4.050876192, Training Accuracy: 6.944\n",
            "Worker 3, [05/37]: Training Loss: 3.945483317, Training Accuracy: 8.288\n",
            "Worker 3, [06/37]: Training Loss: 3.860284769, Training Accuracy: 10.448\n",
            "Worker 3, [07/37]: Training Loss: 3.774083821, Training Accuracy: 11.312\n",
            "Worker 3, [08/37]: Training Loss: 3.686911357, Training Accuracy: 12.624\n",
            "Worker 3, [09/37]: Training Loss: 3.612374931, Training Accuracy: 13.968\n",
            "Worker 3, [10/37]: Training Loss: 3.503396540, Training Accuracy: 15.616\n",
            "Worker 3, [11/37]: Training Loss: 3.428576448, Training Accuracy: 16.688\n",
            "Worker 3, [12/37]: Training Loss: 3.359980595, Training Accuracy: 18.736\n",
            "Worker 3, [13/37]: Training Loss: 3.278121043, Training Accuracy: 19.904\n",
            "Worker 3, [14/37]: Training Loss: 3.191857282, Training Accuracy: 20.464\n",
            "Worker 3, [15/37]: Training Loss: 3.146704664, Training Accuracy: 22.240\n",
            "Worker 3, [16/37]: Training Loss: 3.069179871, Training Accuracy: 22.528\n",
            "Worker 3, [17/37]: Training Loss: 3.019053140, Training Accuracy: 23.792\n",
            "Worker 3, [18/37]: Training Loss: 2.926080290, Training Accuracy: 25.920\n",
            "Worker 3, [19/37]: Training Loss: 2.872456395, Training Accuracy: 26.768\n",
            "Worker 3, [20/37]: Training Loss: 2.789802077, Training Accuracy: 28.416\n",
            "Worker 3, [21/37]: Training Loss: 2.727727058, Training Accuracy: 29.040\n",
            "Worker 3, [22/37]: Training Loss: 2.641468014, Training Accuracy: 31.168\n",
            "Worker 3, [23/37]: Training Loss: 2.595027600, Training Accuracy: 32.128\n",
            "Worker 3, [24/37]: Training Loss: 2.527182117, Training Accuracy: 33.600\n",
            "Worker 3, [25/37]: Training Loss: 2.458810140, Training Accuracy: 34.672\n",
            "Worker 3, [26/37]: Training Loss: 2.387237670, Training Accuracy: 36.912\n",
            "Worker 3, [27/37]: Training Loss: 2.337981616, Training Accuracy: 37.152\n",
            "Worker 3, [28/37]: Training Loss: 2.273918388, Training Accuracy: 38.592\n",
            "Worker 3, [29/37]: Training Loss: 2.226081560, Training Accuracy: 40.576\n",
            "Worker 3, [30/37]: Training Loss: 2.158738647, Training Accuracy: 42.624\n",
            "Worker 3, [31/37]: Training Loss: 2.099512363, Training Accuracy: 43.424\n",
            "Worker 3, [32/37]: Training Loss: 2.073613039, Training Accuracy: 44.224\n",
            "Worker 3, [33/37]: Training Loss: 2.032903092, Training Accuracy: 44.832\n",
            "Worker 3, [34/37]: Training Loss: 2.006405215, Training Accuracy: 45.952\n",
            "Worker 3, [35/37]: Training Loss: 2.007755272, Training Accuracy: 45.712\n",
            "Worker 3, [36/37]: Training Loss: 1.985557911, Training Accuracy: 46.336\n",
            "Worker 3, [37/37]: Training Loss: 1.976138806, Training Accuracy: 46.288\n",
            "Time taken for training worker 3: 0:01:39.289397\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.592555975, Training Accuracy: 1.408\n",
            "Worker 4, [02/37]: Training Loss: 4.426769398, Training Accuracy: 3.312\n",
            "Worker 4, [03/37]: Training Loss: 4.172907206, Training Accuracy: 5.808\n",
            "Worker 4, [04/37]: Training Loss: 4.032871633, Training Accuracy: 7.632\n",
            "Worker 4, [05/37]: Training Loss: 3.922916678, Training Accuracy: 8.848\n",
            "Worker 4, [06/37]: Training Loss: 3.831542385, Training Accuracy: 10.272\n",
            "Worker 4, [07/37]: Training Loss: 3.738503154, Training Accuracy: 12.048\n",
            "Worker 4, [08/37]: Training Loss: 3.650414795, Training Accuracy: 13.024\n",
            "Worker 4, [09/37]: Training Loss: 3.555531901, Training Accuracy: 14.896\n",
            "Worker 4, [10/37]: Training Loss: 3.495901495, Training Accuracy: 16.448\n",
            "Worker 4, [11/37]: Training Loss: 3.407415760, Training Accuracy: 16.896\n",
            "Worker 4, [12/37]: Training Loss: 3.327006313, Training Accuracy: 18.272\n",
            "Worker 4, [13/37]: Training Loss: 3.254918322, Training Accuracy: 19.008\n",
            "Worker 4, [14/37]: Training Loss: 3.210648430, Training Accuracy: 20.992\n",
            "Worker 4, [15/37]: Training Loss: 3.108659511, Training Accuracy: 21.664\n",
            "Worker 4, [16/37]: Training Loss: 3.017590306, Training Accuracy: 24.304\n",
            "Worker 4, [17/37]: Training Loss: 2.964247010, Training Accuracy: 24.480\n",
            "Worker 4, [18/37]: Training Loss: 2.894788971, Training Accuracy: 25.936\n",
            "Worker 4, [19/37]: Training Loss: 2.831188540, Training Accuracy: 27.440\n",
            "Worker 4, [20/37]: Training Loss: 2.741739791, Training Accuracy: 28.816\n",
            "Worker 4, [21/37]: Training Loss: 2.709867738, Training Accuracy: 29.520\n",
            "Worker 4, [22/37]: Training Loss: 2.648447071, Training Accuracy: 31.376\n",
            "Worker 4, [23/37]: Training Loss: 2.535955592, Training Accuracy: 33.328\n",
            "Worker 4, [24/37]: Training Loss: 2.494680478, Training Accuracy: 34.080\n",
            "Worker 4, [25/37]: Training Loss: 2.415991303, Training Accuracy: 36.800\n",
            "Worker 4, [26/37]: Training Loss: 2.354966485, Training Accuracy: 36.976\n",
            "Worker 4, [27/37]: Training Loss: 2.307438287, Training Accuracy: 38.464\n",
            "Worker 4, [28/37]: Training Loss: 2.235919320, Training Accuracy: 39.872\n",
            "Worker 4, [29/37]: Training Loss: 2.188487026, Training Accuracy: 41.280\n",
            "Worker 4, [30/37]: Training Loss: 2.141681103, Training Accuracy: 41.936\n",
            "Worker 4, [31/37]: Training Loss: 2.072067931, Training Accuracy: 43.920\n",
            "Worker 4, [32/37]: Training Loss: 2.050526973, Training Accuracy: 44.400\n",
            "Worker 4, [33/37]: Training Loss: 2.013742176, Training Accuracy: 45.056\n",
            "Worker 4, [34/37]: Training Loss: 1.989921358, Training Accuracy: 45.744\n",
            "Worker 4, [35/37]: Training Loss: 1.960847493, Training Accuracy: 46.976\n",
            "Worker 4, [36/37]: Training Loss: 1.960275250, Training Accuracy: 46.976\n",
            "Worker 4, [37/37]: Training Loss: 1.940912199, Training Accuracy: 47.840\n",
            "Time taken for training worker 4: 0:01:39.867058\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 4.596931107, Training Accuracy: 1.408\n",
            "Worker 5, [02/37]: Training Loss: 4.454949613, Training Accuracy: 3.024\n",
            "Worker 5, [03/37]: Training Loss: 4.211036242, Training Accuracy: 5.856\n",
            "Worker 5, [04/37]: Training Loss: 4.077374123, Training Accuracy: 7.472\n",
            "Worker 5, [05/37]: Training Loss: 3.954911251, Training Accuracy: 8.640\n",
            "Worker 5, [06/37]: Training Loss: 3.854502391, Training Accuracy: 10.240\n",
            "Worker 5, [07/37]: Training Loss: 3.753876394, Training Accuracy: 11.136\n",
            "Worker 5, [08/37]: Training Loss: 3.670442837, Training Accuracy: 12.480\n",
            "Worker 5, [09/37]: Training Loss: 3.586307370, Training Accuracy: 14.288\n",
            "Worker 5, [10/37]: Training Loss: 3.518788744, Training Accuracy: 15.088\n",
            "Worker 5, [11/37]: Training Loss: 3.434641490, Training Accuracy: 17.184\n",
            "Worker 5, [12/37]: Training Loss: 3.345801658, Training Accuracy: 18.400\n",
            "Worker 5, [13/37]: Training Loss: 3.276871034, Training Accuracy: 18.832\n",
            "Worker 5, [14/37]: Training Loss: 3.199670957, Training Accuracy: 20.960\n",
            "Worker 5, [15/37]: Training Loss: 3.158465816, Training Accuracy: 21.616\n",
            "Worker 5, [16/37]: Training Loss: 3.075257953, Training Accuracy: 22.528\n",
            "Worker 5, [17/37]: Training Loss: 3.008996280, Training Accuracy: 24.048\n",
            "Worker 5, [18/37]: Training Loss: 2.921623162, Training Accuracy: 25.808\n",
            "Worker 5, [19/37]: Training Loss: 2.865476560, Training Accuracy: 26.320\n",
            "Worker 5, [20/37]: Training Loss: 2.809353074, Training Accuracy: 27.760\n",
            "Worker 5, [21/37]: Training Loss: 2.737275712, Training Accuracy: 28.656\n",
            "Worker 5, [22/37]: Training Loss: 2.666437096, Training Accuracy: 30.528\n",
            "Worker 5, [23/37]: Training Loss: 2.604454062, Training Accuracy: 31.776\n",
            "Worker 5, [24/37]: Training Loss: 2.498495160, Training Accuracy: 34.016\n",
            "Worker 5, [25/37]: Training Loss: 2.446226530, Training Accuracy: 34.928\n",
            "Worker 5, [26/37]: Training Loss: 2.399093916, Training Accuracy: 36.224\n",
            "Worker 5, [27/37]: Training Loss: 2.345520080, Training Accuracy: 36.704\n",
            "Worker 5, [28/37]: Training Loss: 2.273481510, Training Accuracy: 38.480\n",
            "Worker 5, [29/37]: Training Loss: 2.216321543, Training Accuracy: 41.152\n",
            "Worker 5, [30/37]: Training Loss: 2.163528420, Training Accuracy: 41.392\n",
            "Worker 5, [31/37]: Training Loss: 2.110351393, Training Accuracy: 42.592\n",
            "Worker 5, [32/37]: Training Loss: 2.084671098, Training Accuracy: 43.216\n",
            "Worker 5, [33/37]: Training Loss: 2.049115525, Training Accuracy: 45.088\n",
            "Worker 5, [34/37]: Training Loss: 2.019816115, Training Accuracy: 45.472\n",
            "Worker 5, [35/37]: Training Loss: 1.998134806, Training Accuracy: 45.760\n",
            "Worker 5, [36/37]: Training Loss: 1.979247118, Training Accuracy: 46.640\n",
            "Worker 5, [37/37]: Training Loss: 1.962863507, Training Accuracy: 46.976\n",
            "Time taken for training worker 5: 0:01:39.685743\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 4.590674337, Training Accuracy: 1.456\n",
            "Worker 6, [02/37]: Training Loss: 4.435610976, Training Accuracy: 3.344\n",
            "Worker 6, [03/37]: Training Loss: 4.166482497, Training Accuracy: 5.744\n",
            "Worker 6, [04/37]: Training Loss: 4.020046957, Training Accuracy: 7.568\n",
            "Worker 6, [05/37]: Training Loss: 3.900294440, Training Accuracy: 8.704\n",
            "Worker 6, [06/37]: Training Loss: 3.787029841, Training Accuracy: 10.592\n",
            "Worker 6, [07/37]: Training Loss: 3.685592136, Training Accuracy: 12.448\n",
            "Worker 6, [08/37]: Training Loss: 3.608496778, Training Accuracy: 13.984\n",
            "Worker 6, [09/37]: Training Loss: 3.512612447, Training Accuracy: 15.312\n",
            "Worker 6, [10/37]: Training Loss: 3.453299554, Training Accuracy: 16.176\n",
            "Worker 6, [11/37]: Training Loss: 3.358155886, Training Accuracy: 17.792\n",
            "Worker 6, [12/37]: Training Loss: 3.288231519, Training Accuracy: 19.472\n",
            "Worker 6, [13/37]: Training Loss: 3.207405628, Training Accuracy: 20.928\n",
            "Worker 6, [14/37]: Training Loss: 3.134238061, Training Accuracy: 21.728\n",
            "Worker 6, [15/37]: Training Loss: 3.064936949, Training Accuracy: 23.008\n",
            "Worker 6, [16/37]: Training Loss: 2.996469422, Training Accuracy: 24.560\n",
            "Worker 6, [17/37]: Training Loss: 2.927674804, Training Accuracy: 24.992\n",
            "Worker 6, [18/37]: Training Loss: 2.857248328, Training Accuracy: 27.184\n",
            "Worker 6, [19/37]: Training Loss: 2.786942886, Training Accuracy: 27.712\n",
            "Worker 6, [20/37]: Training Loss: 2.710345487, Training Accuracy: 29.648\n",
            "Worker 6, [21/37]: Training Loss: 2.651109790, Training Accuracy: 31.920\n",
            "Worker 6, [22/37]: Training Loss: 2.588849946, Training Accuracy: 31.776\n",
            "Worker 6, [23/37]: Training Loss: 2.528985775, Training Accuracy: 33.632\n",
            "Worker 6, [24/37]: Training Loss: 2.455764222, Training Accuracy: 34.864\n",
            "Worker 6, [25/37]: Training Loss: 2.387921646, Training Accuracy: 36.752\n",
            "Worker 6, [26/37]: Training Loss: 2.352288723, Training Accuracy: 37.472\n",
            "Worker 6, [27/37]: Training Loss: 2.275343039, Training Accuracy: 38.352\n",
            "Worker 6, [28/37]: Training Loss: 2.226688863, Training Accuracy: 40.240\n",
            "Worker 6, [29/37]: Training Loss: 2.154130936, Training Accuracy: 41.968\n",
            "Worker 6, [30/37]: Training Loss: 2.108878788, Training Accuracy: 42.544\n",
            "Worker 6, [31/37]: Training Loss: 2.071795566, Training Accuracy: 43.440\n",
            "Worker 6, [32/37]: Training Loss: 2.038379460, Training Accuracy: 45.264\n",
            "Worker 6, [33/37]: Training Loss: 1.993617859, Training Accuracy: 45.888\n",
            "Worker 6, [34/37]: Training Loss: 1.968312551, Training Accuracy: 47.056\n",
            "Worker 6, [35/37]: Training Loss: 1.956506845, Training Accuracy: 47.120\n",
            "Worker 6, [36/37]: Training Loss: 1.945772565, Training Accuracy: 47.968\n",
            "Worker 6, [37/37]: Training Loss: 1.923785431, Training Accuracy: 48.416\n",
            "Time taken for training worker 6: 0:01:39.546635\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 4.591084354, Training Accuracy: 1.792\n",
            "Worker 7, [02/37]: Training Loss: 4.436350676, Training Accuracy: 3.632\n",
            "Worker 7, [03/37]: Training Loss: 4.184120151, Training Accuracy: 5.264\n",
            "Worker 7, [04/37]: Training Loss: 4.036372598, Training Accuracy: 7.296\n",
            "Worker 7, [05/37]: Training Loss: 3.891650978, Training Accuracy: 10.272\n",
            "Worker 7, [06/37]: Training Loss: 3.800877968, Training Accuracy: 10.736\n",
            "Worker 7, [07/37]: Training Loss: 3.694126968, Training Accuracy: 12.704\n",
            "Worker 7, [08/37]: Training Loss: 3.607362886, Training Accuracy: 13.744\n",
            "Worker 7, [09/37]: Training Loss: 3.532539635, Training Accuracy: 15.024\n",
            "Worker 7, [10/37]: Training Loss: 3.464776088, Training Accuracy: 15.920\n",
            "Worker 7, [11/37]: Training Loss: 3.398677551, Training Accuracy: 17.552\n",
            "Worker 7, [12/37]: Training Loss: 3.328828145, Training Accuracy: 18.848\n",
            "Worker 7, [13/37]: Training Loss: 3.227037987, Training Accuracy: 20.864\n",
            "Worker 7, [14/37]: Training Loss: 3.139406932, Training Accuracy: 22.176\n",
            "Worker 7, [15/37]: Training Loss: 3.097800303, Training Accuracy: 22.864\n",
            "Worker 7, [16/37]: Training Loss: 3.008602768, Training Accuracy: 24.736\n",
            "Worker 7, [17/37]: Training Loss: 2.951962233, Training Accuracy: 25.552\n",
            "Worker 7, [18/37]: Training Loss: 2.895521276, Training Accuracy: 26.320\n",
            "Worker 7, [19/37]: Training Loss: 2.794390841, Training Accuracy: 28.688\n",
            "Worker 7, [20/37]: Training Loss: 2.763429557, Training Accuracy: 28.864\n",
            "Worker 7, [21/37]: Training Loss: 2.666162525, Training Accuracy: 30.816\n",
            "Worker 7, [22/37]: Training Loss: 2.609470674, Training Accuracy: 32.496\n",
            "Worker 7, [23/37]: Training Loss: 2.528714404, Training Accuracy: 34.400\n",
            "Worker 7, [24/37]: Training Loss: 2.476948273, Training Accuracy: 35.472\n",
            "Worker 7, [25/37]: Training Loss: 2.424212933, Training Accuracy: 36.624\n",
            "Worker 7, [26/37]: Training Loss: 2.350101152, Training Accuracy: 38.080\n",
            "Worker 7, [27/37]: Training Loss: 2.259169244, Training Accuracy: 40.176\n",
            "Worker 7, [28/37]: Training Loss: 2.208049611, Training Accuracy: 41.232\n",
            "Worker 7, [29/37]: Training Loss: 2.176445500, Training Accuracy: 41.664\n",
            "Worker 7, [30/37]: Training Loss: 2.117457907, Training Accuracy: 42.960\n",
            "Worker 7, [31/37]: Training Loss: 2.068692835, Training Accuracy: 43.872\n",
            "Worker 7, [32/37]: Training Loss: 2.021233778, Training Accuracy: 45.904\n",
            "Worker 7, [33/37]: Training Loss: 1.977434422, Training Accuracy: 46.960\n",
            "Worker 7, [34/37]: Training Loss: 1.968527537, Training Accuracy: 47.136\n",
            "Worker 7, [35/37]: Training Loss: 1.934056837, Training Accuracy: 48.224\n",
            "Worker 7, [36/37]: Training Loss: 1.912952732, Training Accuracy: 47.856\n",
            "Worker 7, [37/37]: Training Loss: 1.922366193, Training Accuracy: 48.192\n",
            "Time taken for training worker 7: 0:01:41.290725\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 4.595120610, Training Accuracy: 1.456\n",
            "Worker 8, [02/37]: Training Loss: 4.464359746, Training Accuracy: 3.168\n",
            "Worker 8, [03/37]: Training Loss: 4.205295013, Training Accuracy: 6.112\n",
            "Worker 8, [04/37]: Training Loss: 4.039331692, Training Accuracy: 7.264\n",
            "Worker 8, [05/37]: Training Loss: 3.928539283, Training Accuracy: 9.344\n",
            "Worker 8, [06/37]: Training Loss: 3.823823554, Training Accuracy: 10.640\n",
            "Worker 8, [07/37]: Training Loss: 3.730988301, Training Accuracy: 12.288\n",
            "Worker 8, [08/37]: Training Loss: 3.640476981, Training Accuracy: 13.328\n",
            "Worker 8, [09/37]: Training Loss: 3.549650929, Training Accuracy: 14.704\n",
            "Worker 8, [10/37]: Training Loss: 3.466589239, Training Accuracy: 16.832\n",
            "Worker 8, [11/37]: Training Loss: 3.381318562, Training Accuracy: 17.488\n",
            "Worker 8, [12/37]: Training Loss: 3.298584116, Training Accuracy: 19.056\n",
            "Worker 8, [13/37]: Training Loss: 3.235961011, Training Accuracy: 20.128\n",
            "Worker 8, [14/37]: Training Loss: 3.168648846, Training Accuracy: 20.928\n",
            "Worker 8, [15/37]: Training Loss: 3.100508921, Training Accuracy: 22.880\n",
            "Worker 8, [16/37]: Training Loss: 3.048148379, Training Accuracy: 22.976\n",
            "Worker 8, [17/37]: Training Loss: 2.966884769, Training Accuracy: 25.264\n",
            "Worker 8, [18/37]: Training Loss: 2.881034289, Training Accuracy: 26.848\n",
            "Worker 8, [19/37]: Training Loss: 2.830266464, Training Accuracy: 27.120\n",
            "Worker 8, [20/37]: Training Loss: 2.766374286, Training Accuracy: 28.336\n",
            "Worker 8, [21/37]: Training Loss: 2.723349094, Training Accuracy: 29.552\n",
            "Worker 8, [22/37]: Training Loss: 2.627453259, Training Accuracy: 31.568\n",
            "Worker 8, [23/37]: Training Loss: 2.564567943, Training Accuracy: 32.640\n",
            "Worker 8, [24/37]: Training Loss: 2.508629142, Training Accuracy: 34.384\n",
            "Worker 8, [25/37]: Training Loss: 2.435737815, Training Accuracy: 35.552\n",
            "Worker 8, [26/37]: Training Loss: 2.384823853, Training Accuracy: 36.992\n",
            "Worker 8, [27/37]: Training Loss: 2.299282623, Training Accuracy: 38.656\n",
            "Worker 8, [28/37]: Training Loss: 2.277473978, Training Accuracy: 38.928\n",
            "Worker 8, [29/37]: Training Loss: 2.206006791, Training Accuracy: 41.472\n",
            "Worker 8, [30/37]: Training Loss: 2.173706367, Training Accuracy: 41.776\n",
            "Worker 8, [31/37]: Training Loss: 2.133503476, Training Accuracy: 43.184\n",
            "Worker 8, [32/37]: Training Loss: 2.086665916, Training Accuracy: 44.016\n",
            "Worker 8, [33/37]: Training Loss: 2.050456862, Training Accuracy: 44.624\n",
            "Worker 8, [34/37]: Training Loss: 2.028504330, Training Accuracy: 45.760\n",
            "Worker 8, [35/37]: Training Loss: 2.009522796, Training Accuracy: 45.936\n",
            "Worker 8, [36/37]: Training Loss: 1.991544086, Training Accuracy: 46.208\n",
            "Worker 8, [37/37]: Training Loss: 1.985989709, Training Accuracy: 46.672\n",
            "Time taken for training worker 8: 0:01:42.355148\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000906\n",
            "Local Step 01: Test Loss: 3.204207750, Test Accuracy: 22.490\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.275926782, Training Accuracy: 21.040\n",
            "Worker 1, [02/37]: Training Loss: 3.271956741, Training Accuracy: 20.784\n",
            "Worker 1, [03/37]: Training Loss: 3.225213297, Training Accuracy: 21.744\n",
            "Worker 1, [04/37]: Training Loss: 3.170492586, Training Accuracy: 23.584\n",
            "Worker 1, [05/37]: Training Loss: 3.115072644, Training Accuracy: 24.144\n",
            "Worker 1, [06/37]: Training Loss: 3.061853367, Training Accuracy: 24.464\n",
            "Worker 1, [07/37]: Training Loss: 3.013885778, Training Accuracy: 25.120\n",
            "Worker 1, [08/37]: Training Loss: 2.971806006, Training Accuracy: 26.368\n",
            "Worker 1, [09/37]: Training Loss: 2.942787309, Training Accuracy: 26.400\n",
            "Worker 1, [10/37]: Training Loss: 2.897559263, Training Accuracy: 27.168\n",
            "Worker 1, [11/37]: Training Loss: 2.884937861, Training Accuracy: 27.584\n",
            "Worker 1, [12/37]: Training Loss: 2.842464250, Training Accuracy: 28.560\n",
            "Worker 1, [13/37]: Training Loss: 2.801578665, Training Accuracy: 28.880\n",
            "Worker 1, [14/37]: Training Loss: 2.782156630, Training Accuracy: 28.896\n",
            "Worker 1, [15/37]: Training Loss: 2.770876249, Training Accuracy: 29.216\n",
            "Worker 1, [16/37]: Training Loss: 2.744197979, Training Accuracy: 29.824\n",
            "Worker 1, [17/37]: Training Loss: 2.697905750, Training Accuracy: 30.752\n",
            "Worker 1, [18/37]: Training Loss: 2.685133107, Training Accuracy: 30.704\n",
            "Worker 1, [19/37]: Training Loss: 2.679092998, Training Accuracy: 30.128\n",
            "Worker 1, [20/37]: Training Loss: 2.627007806, Training Accuracy: 32.096\n",
            "Worker 1, [21/37]: Training Loss: 2.589206187, Training Accuracy: 32.320\n",
            "Worker 1, [22/37]: Training Loss: 2.607721253, Training Accuracy: 31.824\n",
            "Worker 1, [23/37]: Training Loss: 2.558920728, Training Accuracy: 32.416\n",
            "Worker 1, [24/37]: Training Loss: 2.477919940, Training Accuracy: 34.816\n",
            "Worker 1, [25/37]: Training Loss: 2.470158752, Training Accuracy: 34.000\n",
            "Worker 1, [26/37]: Training Loss: 2.424001475, Training Accuracy: 35.968\n",
            "Worker 1, [27/37]: Training Loss: 2.409213508, Training Accuracy: 35.824\n",
            "Worker 1, [28/37]: Training Loss: 2.364847496, Training Accuracy: 36.896\n",
            "Worker 1, [29/37]: Training Loss: 2.306983588, Training Accuracy: 38.096\n",
            "Worker 1, [30/37]: Training Loss: 2.234513589, Training Accuracy: 39.728\n",
            "Worker 1, [31/37]: Training Loss: 2.243933136, Training Accuracy: 38.880\n",
            "Worker 1, [32/37]: Training Loss: 2.173019346, Training Accuracy: 40.656\n",
            "Worker 1, [33/37]: Training Loss: 2.115326279, Training Accuracy: 42.000\n",
            "Worker 1, [34/37]: Training Loss: 2.045231746, Training Accuracy: 44.096\n",
            "Worker 1, [35/37]: Training Loss: 2.026959401, Training Accuracy: 44.944\n",
            "Worker 1, [36/37]: Training Loss: 1.961103774, Training Accuracy: 45.680\n",
            "Worker 1, [37/37]: Training Loss: 1.940664194, Training Accuracy: 46.528\n",
            "Time taken for training worker 1: 0:01:40.436779\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.529899887, Training Accuracy: 23.888\n",
            "Worker 2, [02/37]: Training Loss: 3.509315571, Training Accuracy: 23.360\n",
            "Worker 2, [03/37]: Training Loss: 3.403368106, Training Accuracy: 24.176\n",
            "Worker 2, [04/37]: Training Loss: 3.223636639, Training Accuracy: 24.592\n",
            "Worker 2, [05/37]: Training Loss: 3.108259809, Training Accuracy: 26.432\n",
            "Worker 2, [06/37]: Training Loss: 2.980292038, Training Accuracy: 28.080\n",
            "Worker 2, [07/37]: Training Loss: 2.908829665, Training Accuracy: 29.776\n",
            "Worker 2, [08/37]: Training Loss: 2.818594390, Training Accuracy: 30.912\n",
            "Worker 2, [09/37]: Training Loss: 2.743363349, Training Accuracy: 31.616\n",
            "Worker 2, [10/37]: Training Loss: 2.665616138, Training Accuracy: 34.080\n",
            "Worker 2, [11/37]: Training Loss: 2.589541331, Training Accuracy: 34.864\n",
            "Worker 2, [12/37]: Training Loss: 2.529774486, Training Accuracy: 36.480\n",
            "Worker 2, [13/37]: Training Loss: 2.460070873, Training Accuracy: 36.432\n",
            "Worker 2, [14/37]: Training Loss: 2.357743505, Training Accuracy: 38.864\n",
            "Worker 2, [15/37]: Training Loss: 2.312974413, Training Accuracy: 39.344\n",
            "Worker 2, [16/37]: Training Loss: 2.257047736, Training Accuracy: 41.024\n",
            "Worker 2, [17/37]: Training Loss: 2.195611000, Training Accuracy: 42.432\n",
            "Worker 2, [18/37]: Training Loss: 2.148412819, Training Accuracy: 41.728\n",
            "Worker 2, [19/37]: Training Loss: 2.091914132, Training Accuracy: 44.560\n",
            "Worker 2, [20/37]: Training Loss: 2.050865336, Training Accuracy: 43.856\n",
            "Worker 2, [21/37]: Training Loss: 2.011838932, Training Accuracy: 45.824\n",
            "Worker 2, [22/37]: Training Loss: 1.974654456, Training Accuracy: 46.336\n",
            "Worker 2, [23/37]: Training Loss: 1.943635122, Training Accuracy: 46.912\n",
            "Worker 2, [24/37]: Training Loss: 1.890875162, Training Accuracy: 48.384\n",
            "Worker 2, [25/37]: Training Loss: 1.838109896, Training Accuracy: 49.376\n",
            "Worker 2, [26/37]: Training Loss: 1.811906154, Training Accuracy: 49.600\n",
            "Worker 2, [27/37]: Training Loss: 1.760790332, Training Accuracy: 50.384\n",
            "Worker 2, [28/37]: Training Loss: 1.728018232, Training Accuracy: 52.224\n",
            "Worker 2, [29/37]: Training Loss: 1.727135695, Training Accuracy: 52.064\n",
            "Worker 2, [30/37]: Training Loss: 1.714742598, Training Accuracy: 51.008\n",
            "Worker 2, [31/37]: Training Loss: 1.648741281, Training Accuracy: 53.136\n",
            "Worker 2, [32/37]: Training Loss: 1.679662076, Training Accuracy: 52.464\n",
            "Worker 2, [33/37]: Training Loss: 1.571302981, Training Accuracy: 55.264\n",
            "Worker 2, [34/37]: Training Loss: 1.565877908, Training Accuracy: 55.040\n",
            "Worker 2, [35/37]: Training Loss: 1.543324413, Training Accuracy: 55.552\n",
            "Worker 2, [36/37]: Training Loss: 1.484417950, Training Accuracy: 57.120\n",
            "Worker 2, [37/37]: Training Loss: 1.447212444, Training Accuracy: 59.008\n",
            "Time taken for training worker 2: 0:01:40.669130\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.727161843, Training Accuracy: 25.728\n",
            "Worker 3, [02/37]: Training Loss: 3.663315926, Training Accuracy: 26.080\n",
            "Worker 3, [03/37]: Training Loss: 3.482192261, Training Accuracy: 26.704\n",
            "Worker 3, [04/37]: Training Loss: 3.294716402, Training Accuracy: 26.880\n",
            "Worker 3, [05/37]: Training Loss: 3.088545230, Training Accuracy: 28.240\n",
            "Worker 3, [06/37]: Training Loss: 2.954721461, Training Accuracy: 30.256\n",
            "Worker 3, [07/37]: Training Loss: 2.843847915, Training Accuracy: 31.424\n",
            "Worker 3, [08/37]: Training Loss: 2.778424117, Training Accuracy: 32.112\n",
            "Worker 3, [09/37]: Training Loss: 2.660780435, Training Accuracy: 34.400\n",
            "Worker 3, [10/37]: Training Loss: 2.564572835, Training Accuracy: 35.984\n",
            "Worker 3, [11/37]: Training Loss: 2.478394482, Training Accuracy: 37.600\n",
            "Worker 3, [12/37]: Training Loss: 2.377967400, Training Accuracy: 38.832\n",
            "Worker 3, [13/37]: Training Loss: 2.309546416, Training Accuracy: 40.320\n",
            "Worker 3, [14/37]: Training Loss: 2.231407111, Training Accuracy: 42.192\n",
            "Worker 3, [15/37]: Training Loss: 2.137864134, Training Accuracy: 43.808\n",
            "Worker 3, [16/37]: Training Loss: 2.056032869, Training Accuracy: 44.896\n",
            "Worker 3, [17/37]: Training Loss: 1.991845879, Training Accuracy: 46.432\n",
            "Worker 3, [18/37]: Training Loss: 1.916499528, Training Accuracy: 47.872\n",
            "Worker 3, [19/37]: Training Loss: 1.867950903, Training Accuracy: 48.720\n",
            "Worker 3, [20/37]: Training Loss: 1.798735037, Training Accuracy: 50.336\n",
            "Worker 3, [21/37]: Training Loss: 1.729966547, Training Accuracy: 52.320\n",
            "Worker 3, [22/37]: Training Loss: 1.680676452, Training Accuracy: 53.440\n",
            "Worker 3, [23/37]: Training Loss: 1.670553696, Training Accuracy: 53.520\n",
            "Worker 3, [24/37]: Training Loss: 1.608684297, Training Accuracy: 55.296\n",
            "Worker 3, [25/37]: Training Loss: 1.580660241, Training Accuracy: 55.024\n",
            "Worker 3, [26/37]: Training Loss: 1.519192416, Training Accuracy: 56.832\n",
            "Worker 3, [27/37]: Training Loss: 1.484714004, Training Accuracy: 57.184\n",
            "Worker 3, [28/37]: Training Loss: 1.484463489, Training Accuracy: 57.616\n",
            "Worker 3, [29/37]: Training Loss: 1.454836142, Training Accuracy: 58.032\n",
            "Worker 3, [30/37]: Training Loss: 1.466593270, Training Accuracy: 57.824\n",
            "Worker 3, [31/37]: Training Loss: 1.416582547, Training Accuracy: 59.696\n",
            "Worker 3, [32/37]: Training Loss: 1.386303265, Training Accuracy: 60.976\n",
            "Worker 3, [33/37]: Training Loss: 1.347848451, Training Accuracy: 60.800\n",
            "Worker 3, [34/37]: Training Loss: 1.347646792, Training Accuracy: 61.024\n",
            "Worker 3, [35/37]: Training Loss: 1.368758109, Training Accuracy: 60.432\n",
            "Worker 3, [36/37]: Training Loss: 1.318574166, Training Accuracy: 62.336\n",
            "Worker 3, [37/37]: Training Loss: 1.251596052, Training Accuracy: 63.888\n",
            "Time taken for training worker 3: 0:01:39.932419\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.727112845, Training Accuracy: 26.992\n",
            "Worker 4, [02/37]: Training Loss: 3.692357163, Training Accuracy: 26.992\n",
            "Worker 4, [03/37]: Training Loss: 3.449507105, Training Accuracy: 28.448\n",
            "Worker 4, [04/37]: Training Loss: 3.272020734, Training Accuracy: 28.960\n",
            "Worker 4, [05/37]: Training Loss: 3.076724330, Training Accuracy: 30.544\n",
            "Worker 4, [06/37]: Training Loss: 2.956119919, Training Accuracy: 30.368\n",
            "Worker 4, [07/37]: Training Loss: 2.843843662, Training Accuracy: 32.032\n",
            "Worker 4, [08/37]: Training Loss: 2.739898665, Training Accuracy: 33.488\n",
            "Worker 4, [09/37]: Training Loss: 2.598051451, Training Accuracy: 35.728\n",
            "Worker 4, [10/37]: Training Loss: 2.532239058, Training Accuracy: 36.656\n",
            "Worker 4, [11/37]: Training Loss: 2.415325621, Training Accuracy: 38.864\n",
            "Worker 4, [12/37]: Training Loss: 2.324166793, Training Accuracy: 41.088\n",
            "Worker 4, [13/37]: Training Loss: 2.242523129, Training Accuracy: 42.256\n",
            "Worker 4, [14/37]: Training Loss: 2.145995740, Training Accuracy: 44.512\n",
            "Worker 4, [15/37]: Training Loss: 2.084108701, Training Accuracy: 45.856\n",
            "Worker 4, [16/37]: Training Loss: 1.949929074, Training Accuracy: 47.856\n",
            "Worker 4, [17/37]: Training Loss: 1.897368218, Training Accuracy: 48.480\n",
            "Worker 4, [18/37]: Training Loss: 1.785822837, Training Accuracy: 51.424\n",
            "Worker 4, [19/37]: Training Loss: 1.752746937, Training Accuracy: 52.768\n",
            "Worker 4, [20/37]: Training Loss: 1.674645997, Training Accuracy: 54.432\n",
            "Worker 4, [21/37]: Training Loss: 1.625389333, Training Accuracy: 55.104\n",
            "Worker 4, [22/37]: Training Loss: 1.549620392, Training Accuracy: 56.400\n",
            "Worker 4, [23/37]: Training Loss: 1.549765446, Training Accuracy: 57.376\n",
            "Worker 4, [24/37]: Training Loss: 1.513625447, Training Accuracy: 57.696\n",
            "Worker 4, [25/37]: Training Loss: 1.450036738, Training Accuracy: 59.040\n",
            "Worker 4, [26/37]: Training Loss: 1.424517910, Training Accuracy: 59.952\n",
            "Worker 4, [27/37]: Training Loss: 1.389206477, Training Accuracy: 60.544\n",
            "Worker 4, [28/37]: Training Loss: 1.393093390, Training Accuracy: 60.032\n",
            "Worker 4, [29/37]: Training Loss: 1.351235668, Training Accuracy: 61.392\n",
            "Worker 4, [30/37]: Training Loss: 1.308770292, Training Accuracy: 62.032\n",
            "Worker 4, [31/37]: Training Loss: 1.322877535, Training Accuracy: 61.600\n",
            "Worker 4, [32/37]: Training Loss: 1.251121020, Training Accuracy: 64.064\n",
            "Worker 4, [33/37]: Training Loss: 1.279638999, Training Accuracy: 63.344\n",
            "Worker 4, [34/37]: Training Loss: 1.238303475, Training Accuracy: 64.896\n",
            "Worker 4, [35/37]: Training Loss: 1.213959483, Training Accuracy: 64.880\n",
            "Worker 4, [36/37]: Training Loss: 1.126104245, Training Accuracy: 67.728\n",
            "Worker 4, [37/37]: Training Loss: 1.098274605, Training Accuracy: 68.624\n",
            "Time taken for training worker 4: 0:01:40.008120\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.788116229, Training Accuracy: 27.472\n",
            "Worker 5, [02/37]: Training Loss: 3.779748007, Training Accuracy: 27.552\n",
            "Worker 5, [03/37]: Training Loss: 3.559543062, Training Accuracy: 28.800\n",
            "Worker 5, [04/37]: Training Loss: 3.316859121, Training Accuracy: 29.632\n",
            "Worker 5, [05/37]: Training Loss: 3.115960700, Training Accuracy: 29.568\n",
            "Worker 5, [06/37]: Training Loss: 2.975669598, Training Accuracy: 31.184\n",
            "Worker 5, [07/37]: Training Loss: 2.846797775, Training Accuracy: 33.088\n",
            "Worker 5, [08/37]: Training Loss: 2.743715549, Training Accuracy: 33.504\n",
            "Worker 5, [09/37]: Training Loss: 2.645031157, Training Accuracy: 35.248\n",
            "Worker 5, [10/37]: Training Loss: 2.536399625, Training Accuracy: 36.992\n",
            "Worker 5, [11/37]: Training Loss: 2.432242149, Training Accuracy: 39.584\n",
            "Worker 5, [12/37]: Training Loss: 2.336580101, Training Accuracy: 41.344\n",
            "Worker 5, [13/37]: Training Loss: 2.224248712, Training Accuracy: 42.656\n",
            "Worker 5, [14/37]: Training Loss: 2.146254695, Training Accuracy: 44.672\n",
            "Worker 5, [15/37]: Training Loss: 2.061496480, Training Accuracy: 46.432\n",
            "Worker 5, [16/37]: Training Loss: 1.990302239, Training Accuracy: 47.472\n",
            "Worker 5, [17/37]: Training Loss: 1.879365674, Training Accuracy: 49.088\n",
            "Worker 5, [18/37]: Training Loss: 1.816051551, Training Accuracy: 50.800\n",
            "Worker 5, [19/37]: Training Loss: 1.719777855, Training Accuracy: 52.752\n",
            "Worker 5, [20/37]: Training Loss: 1.692766066, Training Accuracy: 53.136\n",
            "Worker 5, [21/37]: Training Loss: 1.609542502, Training Accuracy: 54.576\n",
            "Worker 5, [22/37]: Training Loss: 1.517325080, Training Accuracy: 57.328\n",
            "Worker 5, [23/37]: Training Loss: 1.513059812, Training Accuracy: 57.264\n",
            "Worker 5, [24/37]: Training Loss: 1.451649015, Training Accuracy: 59.040\n",
            "Worker 5, [25/37]: Training Loss: 1.416885780, Training Accuracy: 59.024\n",
            "Worker 5, [26/37]: Training Loss: 1.382542585, Training Accuracy: 60.640\n",
            "Worker 5, [27/37]: Training Loss: 1.344160785, Training Accuracy: 61.360\n",
            "Worker 5, [28/37]: Training Loss: 1.302015055, Training Accuracy: 63.056\n",
            "Worker 5, [29/37]: Training Loss: 1.303221588, Training Accuracy: 62.432\n",
            "Worker 5, [30/37]: Training Loss: 1.287221651, Training Accuracy: 62.560\n",
            "Worker 5, [31/37]: Training Loss: 1.234094974, Training Accuracy: 64.224\n",
            "Worker 5, [32/37]: Training Loss: 1.188876190, Training Accuracy: 65.456\n",
            "Worker 5, [33/37]: Training Loss: 1.220607848, Training Accuracy: 64.448\n",
            "Worker 5, [34/37]: Training Loss: 1.200375064, Training Accuracy: 64.592\n",
            "Worker 5, [35/37]: Training Loss: 1.144325306, Training Accuracy: 66.304\n",
            "Worker 5, [36/37]: Training Loss: 1.159888162, Training Accuracy: 66.608\n",
            "Worker 5, [37/37]: Training Loss: 1.090624455, Training Accuracy: 67.984\n",
            "Time taken for training worker 5: 0:01:37.854444\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.833384609, Training Accuracy: 28.096\n",
            "Worker 6, [02/37]: Training Loss: 3.776428210, Training Accuracy: 28.208\n",
            "Worker 6, [03/37]: Training Loss: 3.600654510, Training Accuracy: 28.864\n",
            "Worker 6, [04/37]: Training Loss: 3.330864172, Training Accuracy: 29.168\n",
            "Worker 6, [05/37]: Training Loss: 3.079885130, Training Accuracy: 30.624\n",
            "Worker 6, [06/37]: Training Loss: 2.916923737, Training Accuracy: 31.312\n",
            "Worker 6, [07/37]: Training Loss: 2.797623732, Training Accuracy: 33.168\n",
            "Worker 6, [08/37]: Training Loss: 2.668453934, Training Accuracy: 34.960\n",
            "Worker 6, [09/37]: Training Loss: 2.556833604, Training Accuracy: 37.408\n",
            "Worker 6, [10/37]: Training Loss: 2.430043607, Training Accuracy: 39.664\n",
            "Worker 6, [11/37]: Training Loss: 2.338361438, Training Accuracy: 41.776\n",
            "Worker 6, [12/37]: Training Loss: 2.232627777, Training Accuracy: 42.496\n",
            "Worker 6, [13/37]: Training Loss: 2.139692206, Training Accuracy: 44.880\n",
            "Worker 6, [14/37]: Training Loss: 2.044735210, Training Accuracy: 46.864\n",
            "Worker 6, [15/37]: Training Loss: 1.952767193, Training Accuracy: 47.728\n",
            "Worker 6, [16/37]: Training Loss: 1.854164370, Training Accuracy: 50.352\n",
            "Worker 6, [17/37]: Training Loss: 1.778472334, Training Accuracy: 52.256\n",
            "Worker 6, [18/37]: Training Loss: 1.696442660, Training Accuracy: 54.208\n",
            "Worker 6, [19/37]: Training Loss: 1.630491007, Training Accuracy: 55.248\n",
            "Worker 6, [20/37]: Training Loss: 1.531116370, Training Accuracy: 57.696\n",
            "Worker 6, [21/37]: Training Loss: 1.482154218, Training Accuracy: 58.480\n",
            "Worker 6, [22/37]: Training Loss: 1.452826494, Training Accuracy: 59.184\n",
            "Worker 6, [23/37]: Training Loss: 1.378117166, Training Accuracy: 61.504\n",
            "Worker 6, [24/37]: Training Loss: 1.327684083, Training Accuracy: 61.920\n",
            "Worker 6, [25/37]: Training Loss: 1.324156183, Training Accuracy: 62.304\n",
            "Worker 6, [26/37]: Training Loss: 1.260993411, Training Accuracy: 63.904\n",
            "Worker 6, [27/37]: Training Loss: 1.207297916, Training Accuracy: 65.264\n",
            "Worker 6, [28/37]: Training Loss: 1.182742305, Training Accuracy: 65.840\n",
            "Worker 6, [29/37]: Training Loss: 1.211737328, Training Accuracy: 65.056\n",
            "Worker 6, [30/37]: Training Loss: 1.180027668, Training Accuracy: 66.208\n",
            "Worker 6, [31/37]: Training Loss: 1.172484988, Training Accuracy: 66.384\n",
            "Worker 6, [32/37]: Training Loss: 1.146756794, Training Accuracy: 66.176\n",
            "Worker 6, [33/37]: Training Loss: 1.120148097, Training Accuracy: 67.312\n",
            "Worker 6, [34/37]: Training Loss: 1.104390751, Training Accuracy: 68.224\n",
            "Worker 6, [35/37]: Training Loss: 1.091781639, Training Accuracy: 67.648\n",
            "Worker 6, [36/37]: Training Loss: 1.085618577, Training Accuracy: 68.224\n",
            "Worker 6, [37/37]: Training Loss: 1.037509956, Training Accuracy: 69.808\n",
            "Time taken for training worker 6: 0:01:41.684926\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.935951583, Training Accuracy: 28.544\n",
            "Worker 7, [02/37]: Training Loss: 3.864471793, Training Accuracy: 28.960\n",
            "Worker 7, [03/37]: Training Loss: 3.617960190, Training Accuracy: 30.128\n",
            "Worker 7, [04/37]: Training Loss: 3.359999199, Training Accuracy: 30.528\n",
            "Worker 7, [05/37]: Training Loss: 3.072036373, Training Accuracy: 31.536\n",
            "Worker 7, [06/37]: Training Loss: 2.905064160, Training Accuracy: 32.592\n",
            "Worker 7, [07/37]: Training Loss: 2.775564622, Training Accuracy: 33.296\n",
            "Worker 7, [08/37]: Training Loss: 2.631227561, Training Accuracy: 36.016\n",
            "Worker 7, [09/37]: Training Loss: 2.534306072, Training Accuracy: 36.752\n",
            "Worker 7, [10/37]: Training Loss: 2.436683498, Training Accuracy: 39.552\n",
            "Worker 7, [11/37]: Training Loss: 2.345817208, Training Accuracy: 40.912\n",
            "Worker 7, [12/37]: Training Loss: 2.217876146, Training Accuracy: 42.528\n",
            "Worker 7, [13/37]: Training Loss: 2.139206700, Training Accuracy: 44.320\n",
            "Worker 7, [14/37]: Training Loss: 2.050881445, Training Accuracy: 46.976\n",
            "Worker 7, [15/37]: Training Loss: 1.931819078, Training Accuracy: 49.312\n",
            "Worker 7, [16/37]: Training Loss: 1.894168146, Training Accuracy: 50.016\n",
            "Worker 7, [17/37]: Training Loss: 1.777867405, Training Accuracy: 52.800\n",
            "Worker 7, [18/37]: Training Loss: 1.663831253, Training Accuracy: 54.880\n",
            "Worker 7, [19/37]: Training Loss: 1.617977719, Training Accuracy: 55.248\n",
            "Worker 7, [20/37]: Training Loss: 1.562532026, Training Accuracy: 57.088\n",
            "Worker 7, [21/37]: Training Loss: 1.515677783, Training Accuracy: 57.984\n",
            "Worker 7, [22/37]: Training Loss: 1.443796449, Training Accuracy: 59.360\n",
            "Worker 7, [23/37]: Training Loss: 1.382859678, Training Accuracy: 61.088\n",
            "Worker 7, [24/37]: Training Loss: 1.346785567, Training Accuracy: 61.568\n",
            "Worker 7, [25/37]: Training Loss: 1.291629709, Training Accuracy: 62.848\n",
            "Worker 7, [26/37]: Training Loss: 1.239020292, Training Accuracy: 64.800\n",
            "Worker 7, [27/37]: Training Loss: 1.255877198, Training Accuracy: 64.624\n",
            "Worker 7, [28/37]: Training Loss: 1.198952734, Training Accuracy: 65.408\n",
            "Worker 7, [29/37]: Training Loss: 1.121388481, Training Accuracy: 67.376\n",
            "Worker 7, [30/37]: Training Loss: 1.181392453, Training Accuracy: 66.192\n",
            "Worker 7, [31/37]: Training Loss: 1.137884838, Training Accuracy: 67.008\n",
            "Worker 7, [32/37]: Training Loss: 1.102678495, Training Accuracy: 67.488\n",
            "Worker 7, [33/37]: Training Loss: 1.122397885, Training Accuracy: 67.216\n",
            "Worker 7, [34/37]: Training Loss: 1.085371433, Training Accuracy: 68.352\n",
            "Worker 7, [35/37]: Training Loss: 1.087549310, Training Accuracy: 67.952\n",
            "Worker 7, [36/37]: Training Loss: 1.075690134, Training Accuracy: 68.800\n",
            "Worker 7, [37/37]: Training Loss: 0.975859063, Training Accuracy: 71.040\n",
            "Time taken for training worker 7: 0:01:39.325184\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.721037629, Training Accuracy: 29.376\n",
            "Worker 8, [02/37]: Training Loss: 3.692948101, Training Accuracy: 28.720\n",
            "Worker 8, [03/37]: Training Loss: 3.490199386, Training Accuracy: 29.904\n",
            "Worker 8, [04/37]: Training Loss: 3.280044271, Training Accuracy: 30.464\n",
            "Worker 8, [05/37]: Training Loss: 3.078748066, Training Accuracy: 30.896\n",
            "Worker 8, [06/37]: Training Loss: 2.888828837, Training Accuracy: 32.640\n",
            "Worker 8, [07/37]: Training Loss: 2.768052568, Training Accuracy: 34.272\n",
            "Worker 8, [08/37]: Training Loss: 2.654286387, Training Accuracy: 35.520\n",
            "Worker 8, [09/37]: Training Loss: 2.550415426, Training Accuracy: 36.832\n",
            "Worker 8, [10/37]: Training Loss: 2.430955888, Training Accuracy: 38.704\n",
            "Worker 8, [11/37]: Training Loss: 2.332015429, Training Accuracy: 40.672\n",
            "Worker 8, [12/37]: Training Loss: 2.225604386, Training Accuracy: 43.072\n",
            "Worker 8, [13/37]: Training Loss: 2.127633083, Training Accuracy: 45.136\n",
            "Worker 8, [14/37]: Training Loss: 2.038707923, Training Accuracy: 46.400\n",
            "Worker 8, [15/37]: Training Loss: 1.923501951, Training Accuracy: 48.752\n",
            "Worker 8, [16/37]: Training Loss: 1.844609413, Training Accuracy: 50.560\n",
            "Worker 8, [17/37]: Training Loss: 1.743388199, Training Accuracy: 53.168\n",
            "Worker 8, [18/37]: Training Loss: 1.645499032, Training Accuracy: 54.912\n",
            "Worker 8, [19/37]: Training Loss: 1.580424057, Training Accuracy: 56.112\n",
            "Worker 8, [20/37]: Training Loss: 1.496153338, Training Accuracy: 58.240\n",
            "Worker 8, [21/37]: Training Loss: 1.454186734, Training Accuracy: 60.112\n",
            "Worker 8, [22/37]: Training Loss: 1.385231412, Training Accuracy: 61.120\n",
            "Worker 8, [23/37]: Training Loss: 1.372369933, Training Accuracy: 61.152\n",
            "Worker 8, [24/37]: Training Loss: 1.287283151, Training Accuracy: 63.408\n",
            "Worker 8, [25/37]: Training Loss: 1.216723867, Training Accuracy: 64.016\n",
            "Worker 8, [26/37]: Training Loss: 1.202203445, Training Accuracy: 65.488\n",
            "Worker 8, [27/37]: Training Loss: 1.202468516, Training Accuracy: 65.248\n",
            "Worker 8, [28/37]: Training Loss: 1.154808397, Training Accuracy: 66.192\n",
            "Worker 8, [29/37]: Training Loss: 1.133171742, Training Accuracy: 67.600\n",
            "Worker 8, [30/37]: Training Loss: 1.152517774, Training Accuracy: 66.368\n",
            "Worker 8, [31/37]: Training Loss: 1.101289187, Training Accuracy: 68.144\n",
            "Worker 8, [32/37]: Training Loss: 1.074586952, Training Accuracy: 68.672\n",
            "Worker 8, [33/37]: Training Loss: 1.016775589, Training Accuracy: 70.464\n",
            "Worker 8, [34/37]: Training Loss: 1.047755533, Training Accuracy: 69.408\n",
            "Worker 8, [35/37]: Training Loss: 1.037601168, Training Accuracy: 69.840\n",
            "Worker 8, [36/37]: Training Loss: 0.932392731, Training Accuracy: 72.496\n",
            "Worker 8, [37/37]: Training Loss: 0.956767747, Training Accuracy: 71.936\n",
            "Time taken for training worker 8: 0:01:39.652266\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000853\n",
            "Local Step 02: Test Loss: 3.711187492, Test Accuracy: 32.940\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.167322288, Training Accuracy: 26.496\n",
            "Worker 1, [02/37]: Training Loss: 2.557704305, Training Accuracy: 36.224\n",
            "Worker 1, [03/37]: Training Loss: 2.296744929, Training Accuracy: 41.744\n",
            "Worker 1, [04/37]: Training Loss: 2.082288403, Training Accuracy: 45.952\n",
            "Worker 1, [05/37]: Training Loss: 1.944653262, Training Accuracy: 48.400\n",
            "Worker 1, [06/37]: Training Loss: 1.774824057, Training Accuracy: 52.000\n",
            "Worker 1, [07/37]: Training Loss: 1.660325430, Training Accuracy: 55.024\n",
            "Worker 1, [08/37]: Training Loss: 1.553086871, Training Accuracy: 57.184\n",
            "Worker 1, [09/37]: Training Loss: 1.417564713, Training Accuracy: 60.704\n",
            "Worker 1, [10/37]: Training Loss: 1.324019418, Training Accuracy: 62.608\n",
            "Worker 1, [11/37]: Training Loss: 1.252062366, Training Accuracy: 64.160\n",
            "Worker 1, [12/37]: Training Loss: 1.130126769, Training Accuracy: 67.856\n",
            "Worker 1, [13/37]: Training Loss: 1.048185838, Training Accuracy: 70.256\n",
            "Worker 1, [14/37]: Training Loss: 1.022788109, Training Accuracy: 70.528\n",
            "Worker 1, [15/37]: Training Loss: 0.908423149, Training Accuracy: 72.832\n",
            "Worker 1, [16/37]: Training Loss: 0.808980619, Training Accuracy: 76.688\n",
            "Worker 1, [17/37]: Training Loss: 0.730089251, Training Accuracy: 78.768\n",
            "Worker 1, [18/37]: Training Loss: 0.674450131, Training Accuracy: 79.840\n",
            "Worker 1, [19/37]: Training Loss: 0.630968401, Training Accuracy: 82.016\n",
            "Worker 1, [20/37]: Training Loss: 0.545893735, Training Accuracy: 83.760\n",
            "Worker 1, [21/37]: Training Loss: 0.513426703, Training Accuracy: 85.312\n",
            "Worker 1, [22/37]: Training Loss: 0.435935082, Training Accuracy: 87.296\n",
            "Worker 1, [23/37]: Training Loss: 0.388257390, Training Accuracy: 88.816\n",
            "Worker 1, [24/37]: Training Loss: 0.358741371, Training Accuracy: 89.232\n",
            "Worker 1, [25/37]: Training Loss: 0.324832949, Training Accuracy: 90.928\n",
            "Worker 1, [26/37]: Training Loss: 0.289660407, Training Accuracy: 92.016\n",
            "Worker 1, [27/37]: Training Loss: 0.272387866, Training Accuracy: 92.816\n",
            "Worker 1, [28/37]: Training Loss: 0.246474821, Training Accuracy: 93.696\n",
            "Worker 1, [29/37]: Training Loss: 0.227164260, Training Accuracy: 93.632\n",
            "Worker 1, [30/37]: Training Loss: 0.205567553, Training Accuracy: 94.512\n",
            "Worker 1, [31/37]: Training Loss: 0.206485703, Training Accuracy: 94.480\n",
            "Worker 1, [32/37]: Training Loss: 0.185834604, Training Accuracy: 95.232\n",
            "Worker 1, [33/37]: Training Loss: 0.179346952, Training Accuracy: 95.536\n",
            "Worker 1, [34/37]: Training Loss: 0.184800646, Training Accuracy: 95.488\n",
            "Worker 1, [35/37]: Training Loss: 0.170482673, Training Accuracy: 95.872\n",
            "Worker 1, [36/37]: Training Loss: 0.190352472, Training Accuracy: 95.088\n",
            "Worker 1, [37/37]: Training Loss: 0.160255314, Training Accuracy: 95.776\n",
            "Time taken for training worker 1: 0:01:38.891855\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.188985185, Training Accuracy: 27.504\n",
            "Worker 2, [02/37]: Training Loss: 2.523480817, Training Accuracy: 36.320\n",
            "Worker 2, [03/37]: Training Loss: 2.241879107, Training Accuracy: 41.888\n",
            "Worker 2, [04/37]: Training Loss: 2.026601744, Training Accuracy: 46.192\n",
            "Worker 2, [05/37]: Training Loss: 1.895019171, Training Accuracy: 48.944\n",
            "Worker 2, [06/37]: Training Loss: 1.708553638, Training Accuracy: 53.088\n",
            "Worker 2, [07/37]: Training Loss: 1.646756481, Training Accuracy: 54.848\n",
            "Worker 2, [08/37]: Training Loss: 1.501910908, Training Accuracy: 58.064\n",
            "Worker 2, [09/37]: Training Loss: 1.395576323, Training Accuracy: 60.320\n",
            "Worker 2, [10/37]: Training Loss: 1.253473769, Training Accuracy: 64.224\n",
            "Worker 2, [11/37]: Training Loss: 1.184826106, Training Accuracy: 65.616\n",
            "Worker 2, [12/37]: Training Loss: 1.128671852, Training Accuracy: 68.192\n",
            "Worker 2, [13/37]: Training Loss: 1.021144428, Training Accuracy: 70.528\n",
            "Worker 2, [14/37]: Training Loss: 0.934876129, Training Accuracy: 73.232\n",
            "Worker 2, [15/37]: Training Loss: 0.847638821, Training Accuracy: 74.896\n",
            "Worker 2, [16/37]: Training Loss: 0.780503390, Training Accuracy: 77.424\n",
            "Worker 2, [17/37]: Training Loss: 0.710867870, Training Accuracy: 78.944\n",
            "Worker 2, [18/37]: Training Loss: 0.628136447, Training Accuracy: 82.016\n",
            "Worker 2, [19/37]: Training Loss: 0.551073933, Training Accuracy: 83.776\n",
            "Worker 2, [20/37]: Training Loss: 0.540190073, Training Accuracy: 84.080\n",
            "Worker 2, [21/37]: Training Loss: 0.462631729, Training Accuracy: 86.624\n",
            "Worker 2, [22/37]: Training Loss: 0.418136337, Training Accuracy: 87.680\n",
            "Worker 2, [23/37]: Training Loss: 0.368107507, Training Accuracy: 89.792\n",
            "Worker 2, [24/37]: Training Loss: 0.321247509, Training Accuracy: 90.848\n",
            "Worker 2, [25/37]: Training Loss: 0.285192168, Training Accuracy: 92.352\n",
            "Worker 2, [26/37]: Training Loss: 0.265637762, Training Accuracy: 92.528\n",
            "Worker 2, [27/37]: Training Loss: 0.251380090, Training Accuracy: 93.088\n",
            "Worker 2, [28/37]: Training Loss: 0.235258955, Training Accuracy: 93.760\n",
            "Worker 2, [29/37]: Training Loss: 0.210501707, Training Accuracy: 94.336\n",
            "Worker 2, [30/37]: Training Loss: 0.193922833, Training Accuracy: 95.216\n",
            "Worker 2, [31/37]: Training Loss: 0.177565469, Training Accuracy: 95.520\n",
            "Worker 2, [32/37]: Training Loss: 0.175923799, Training Accuracy: 95.392\n",
            "Worker 2, [33/37]: Training Loss: 0.168975638, Training Accuracy: 95.936\n",
            "Worker 2, [34/37]: Training Loss: 0.155732611, Training Accuracy: 96.080\n",
            "Worker 2, [35/37]: Training Loss: 0.158435988, Training Accuracy: 96.256\n",
            "Worker 2, [36/37]: Training Loss: 0.161817247, Training Accuracy: 96.032\n",
            "Worker 2, [37/37]: Training Loss: 0.156289594, Training Accuracy: 96.144\n",
            "Time taken for training worker 2: 0:01:39.550064\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.174212524, Training Accuracy: 26.992\n",
            "Worker 3, [02/37]: Training Loss: 2.450422701, Training Accuracy: 37.264\n",
            "Worker 3, [03/37]: Training Loss: 2.173802629, Training Accuracy: 43.584\n",
            "Worker 3, [04/37]: Training Loss: 1.977090260, Training Accuracy: 47.056\n",
            "Worker 3, [05/37]: Training Loss: 1.820696643, Training Accuracy: 50.720\n",
            "Worker 3, [06/37]: Training Loss: 1.662366303, Training Accuracy: 54.336\n",
            "Worker 3, [07/37]: Training Loss: 1.523120650, Training Accuracy: 57.664\n",
            "Worker 3, [08/37]: Training Loss: 1.404986866, Training Accuracy: 61.360\n",
            "Worker 3, [09/37]: Training Loss: 1.318931327, Training Accuracy: 62.208\n",
            "Worker 3, [10/37]: Training Loss: 1.244194429, Training Accuracy: 64.416\n",
            "Worker 3, [11/37]: Training Loss: 1.126942468, Training Accuracy: 67.008\n",
            "Worker 3, [12/37]: Training Loss: 1.014148721, Training Accuracy: 70.832\n",
            "Worker 3, [13/37]: Training Loss: 0.967669817, Training Accuracy: 71.248\n",
            "Worker 3, [14/37]: Training Loss: 0.857864110, Training Accuracy: 74.752\n",
            "Worker 3, [15/37]: Training Loss: 0.803956390, Training Accuracy: 76.416\n",
            "Worker 3, [16/37]: Training Loss: 0.721500791, Training Accuracy: 78.160\n",
            "Worker 3, [17/37]: Training Loss: 0.680874831, Training Accuracy: 79.952\n",
            "Worker 3, [18/37]: Training Loss: 0.584982727, Training Accuracy: 82.720\n",
            "Worker 3, [19/37]: Training Loss: 0.512799083, Training Accuracy: 85.072\n",
            "Worker 3, [20/37]: Training Loss: 0.497514866, Training Accuracy: 85.360\n",
            "Worker 3, [21/37]: Training Loss: 0.436848272, Training Accuracy: 87.392\n",
            "Worker 3, [22/37]: Training Loss: 0.380039741, Training Accuracy: 89.216\n",
            "Worker 3, [23/37]: Training Loss: 0.350285529, Training Accuracy: 89.984\n",
            "Worker 3, [24/37]: Training Loss: 0.310263393, Training Accuracy: 91.488\n",
            "Worker 3, [25/37]: Training Loss: 0.268930211, Training Accuracy: 92.480\n",
            "Worker 3, [26/37]: Training Loss: 0.241067561, Training Accuracy: 93.584\n",
            "Worker 3, [27/37]: Training Loss: 0.232168566, Training Accuracy: 93.472\n",
            "Worker 3, [28/37]: Training Loss: 0.206217454, Training Accuracy: 94.352\n",
            "Worker 3, [29/37]: Training Loss: 0.190045342, Training Accuracy: 94.880\n",
            "Worker 3, [30/37]: Training Loss: 0.168833541, Training Accuracy: 95.744\n",
            "Worker 3, [31/37]: Training Loss: 0.162497824, Training Accuracy: 95.952\n",
            "Worker 3, [32/37]: Training Loss: 0.158697742, Training Accuracy: 96.032\n",
            "Worker 3, [33/37]: Training Loss: 0.155952769, Training Accuracy: 96.080\n",
            "Worker 3, [34/37]: Training Loss: 0.137989787, Training Accuracy: 96.704\n",
            "Worker 3, [35/37]: Training Loss: 0.136709033, Training Accuracy: 96.688\n",
            "Worker 3, [36/37]: Training Loss: 0.144749763, Training Accuracy: 96.384\n",
            "Worker 3, [37/37]: Training Loss: 0.138306177, Training Accuracy: 96.880\n",
            "Time taken for training worker 3: 0:01:40.038388\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.113644289, Training Accuracy: 27.952\n",
            "Worker 4, [02/37]: Training Loss: 2.375583098, Training Accuracy: 40.208\n",
            "Worker 4, [03/37]: Training Loss: 2.127204118, Training Accuracy: 44.384\n",
            "Worker 4, [04/37]: Training Loss: 1.946397221, Training Accuracy: 48.368\n",
            "Worker 4, [05/37]: Training Loss: 1.795542691, Training Accuracy: 51.376\n",
            "Worker 4, [06/37]: Training Loss: 1.665490275, Training Accuracy: 53.696\n",
            "Worker 4, [07/37]: Training Loss: 1.526070931, Training Accuracy: 57.760\n",
            "Worker 4, [08/37]: Training Loss: 1.426811726, Training Accuracy: 59.600\n",
            "Worker 4, [09/37]: Training Loss: 1.340542101, Training Accuracy: 62.016\n",
            "Worker 4, [10/37]: Training Loss: 1.250121958, Training Accuracy: 64.064\n",
            "Worker 4, [11/37]: Training Loss: 1.142281334, Training Accuracy: 67.136\n",
            "Worker 4, [12/37]: Training Loss: 1.069236885, Training Accuracy: 68.976\n",
            "Worker 4, [13/37]: Training Loss: 0.981648246, Training Accuracy: 70.896\n",
            "Worker 4, [14/37]: Training Loss: 0.857976696, Training Accuracy: 74.512\n",
            "Worker 4, [15/37]: Training Loss: 0.803047466, Training Accuracy: 76.448\n",
            "Worker 4, [16/37]: Training Loss: 0.711462560, Training Accuracy: 78.784\n",
            "Worker 4, [17/37]: Training Loss: 0.675619235, Training Accuracy: 80.080\n",
            "Worker 4, [18/37]: Training Loss: 0.577716650, Training Accuracy: 82.864\n",
            "Worker 4, [19/37]: Training Loss: 0.503304954, Training Accuracy: 85.440\n",
            "Worker 4, [20/37]: Training Loss: 0.487689027, Training Accuracy: 85.344\n",
            "Worker 4, [21/37]: Training Loss: 0.422972657, Training Accuracy: 88.096\n",
            "Worker 4, [22/37]: Training Loss: 0.379933917, Training Accuracy: 89.184\n",
            "Worker 4, [23/37]: Training Loss: 0.317042151, Training Accuracy: 90.832\n",
            "Worker 4, [24/37]: Training Loss: 0.301708409, Training Accuracy: 91.632\n",
            "Worker 4, [25/37]: Training Loss: 0.265698317, Training Accuracy: 92.800\n",
            "Worker 4, [26/37]: Training Loss: 0.234366456, Training Accuracy: 93.360\n",
            "Worker 4, [27/37]: Training Loss: 0.220835015, Training Accuracy: 94.208\n",
            "Worker 4, [28/37]: Training Loss: 0.208899940, Training Accuracy: 94.512\n",
            "Worker 4, [29/37]: Training Loss: 0.195498553, Training Accuracy: 94.944\n",
            "Worker 4, [30/37]: Training Loss: 0.189561136, Training Accuracy: 95.152\n",
            "Worker 4, [31/37]: Training Loss: 0.167377217, Training Accuracy: 95.856\n",
            "Worker 4, [32/37]: Training Loss: 0.157395022, Training Accuracy: 95.952\n",
            "Worker 4, [33/37]: Training Loss: 0.160938952, Training Accuracy: 95.952\n",
            "Worker 4, [34/37]: Training Loss: 0.147918847, Training Accuracy: 96.624\n",
            "Worker 4, [35/37]: Training Loss: 0.150294149, Training Accuracy: 96.384\n",
            "Worker 4, [36/37]: Training Loss: 0.137931820, Training Accuracy: 96.624\n",
            "Worker 4, [37/37]: Training Loss: 0.137311061, Training Accuracy: 96.768\n",
            "Time taken for training worker 4: 0:01:39.499654\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.120400619, Training Accuracy: 28.608\n",
            "Worker 5, [02/37]: Training Loss: 2.401903250, Training Accuracy: 38.544\n",
            "Worker 5, [03/37]: Training Loss: 2.160757098, Training Accuracy: 43.040\n",
            "Worker 5, [04/37]: Training Loss: 1.953655403, Training Accuracy: 48.720\n",
            "Worker 5, [05/37]: Training Loss: 1.784780349, Training Accuracy: 51.936\n",
            "Worker 5, [06/37]: Training Loss: 1.683682338, Training Accuracy: 54.032\n",
            "Worker 5, [07/37]: Training Loss: 1.527483668, Training Accuracy: 57.280\n",
            "Worker 5, [08/37]: Training Loss: 1.394112984, Training Accuracy: 60.992\n",
            "Worker 5, [09/37]: Training Loss: 1.315431797, Training Accuracy: 62.576\n",
            "Worker 5, [10/37]: Training Loss: 1.185689407, Training Accuracy: 65.408\n",
            "Worker 5, [11/37]: Training Loss: 1.143900228, Training Accuracy: 67.232\n",
            "Worker 5, [12/37]: Training Loss: 1.022896550, Training Accuracy: 70.624\n",
            "Worker 5, [13/37]: Training Loss: 0.992872211, Training Accuracy: 70.800\n",
            "Worker 5, [14/37]: Training Loss: 0.856729887, Training Accuracy: 74.720\n",
            "Worker 5, [15/37]: Training Loss: 0.802375599, Training Accuracy: 76.064\n",
            "Worker 5, [16/37]: Training Loss: 0.694005944, Training Accuracy: 79.696\n",
            "Worker 5, [17/37]: Training Loss: 0.650947007, Training Accuracy: 80.768\n",
            "Worker 5, [18/37]: Training Loss: 0.586471370, Training Accuracy: 82.928\n",
            "Worker 5, [19/37]: Training Loss: 0.521765852, Training Accuracy: 84.592\n",
            "Worker 5, [20/37]: Training Loss: 0.477914536, Training Accuracy: 85.792\n",
            "Worker 5, [21/37]: Training Loss: 0.422555954, Training Accuracy: 88.096\n",
            "Worker 5, [22/37]: Training Loss: 0.347154078, Training Accuracy: 90.016\n",
            "Worker 5, [23/37]: Training Loss: 0.335223344, Training Accuracy: 90.704\n",
            "Worker 5, [24/37]: Training Loss: 0.285319592, Training Accuracy: 92.080\n",
            "Worker 5, [25/37]: Training Loss: 0.255153657, Training Accuracy: 92.688\n",
            "Worker 5, [26/37]: Training Loss: 0.237458092, Training Accuracy: 93.120\n",
            "Worker 5, [27/37]: Training Loss: 0.229899715, Training Accuracy: 93.696\n",
            "Worker 5, [28/37]: Training Loss: 0.192590623, Training Accuracy: 94.944\n",
            "Worker 5, [29/37]: Training Loss: 0.174488081, Training Accuracy: 95.600\n",
            "Worker 5, [30/37]: Training Loss: 0.173483084, Training Accuracy: 95.488\n",
            "Worker 5, [31/37]: Training Loss: 0.152483258, Training Accuracy: 96.208\n",
            "Worker 5, [32/37]: Training Loss: 0.151902457, Training Accuracy: 96.224\n",
            "Worker 5, [33/37]: Training Loss: 0.153841095, Training Accuracy: 96.064\n",
            "Worker 5, [34/37]: Training Loss: 0.135052761, Training Accuracy: 96.880\n",
            "Worker 5, [35/37]: Training Loss: 0.146529698, Training Accuracy: 96.576\n",
            "Worker 5, [36/37]: Training Loss: 0.131591002, Training Accuracy: 96.816\n",
            "Worker 5, [37/37]: Training Loss: 0.141996772, Training Accuracy: 96.480\n",
            "Time taken for training worker 5: 0:01:38.636911\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.123544669, Training Accuracy: 28.304\n",
            "Worker 6, [02/37]: Training Loss: 2.355449923, Training Accuracy: 40.064\n",
            "Worker 6, [03/37]: Training Loss: 2.125178116, Training Accuracy: 44.624\n",
            "Worker 6, [04/37]: Training Loss: 1.910389138, Training Accuracy: 49.536\n",
            "Worker 6, [05/37]: Training Loss: 1.740266897, Training Accuracy: 52.112\n",
            "Worker 6, [06/37]: Training Loss: 1.568303106, Training Accuracy: 57.120\n",
            "Worker 6, [07/37]: Training Loss: 1.442451906, Training Accuracy: 59.696\n",
            "Worker 6, [08/37]: Training Loss: 1.365544235, Training Accuracy: 62.000\n",
            "Worker 6, [09/37]: Training Loss: 1.231687391, Training Accuracy: 65.072\n",
            "Worker 6, [10/37]: Training Loss: 1.142111550, Training Accuracy: 66.736\n",
            "Worker 6, [11/37]: Training Loss: 1.056985358, Training Accuracy: 69.024\n",
            "Worker 6, [12/37]: Training Loss: 0.984636113, Training Accuracy: 71.312\n",
            "Worker 6, [13/37]: Training Loss: 0.876909828, Training Accuracy: 73.872\n",
            "Worker 6, [14/37]: Training Loss: 0.808126173, Training Accuracy: 76.752\n",
            "Worker 6, [15/37]: Training Loss: 0.747348992, Training Accuracy: 78.080\n",
            "Worker 6, [16/37]: Training Loss: 0.658233132, Training Accuracy: 80.672\n",
            "Worker 6, [17/37]: Training Loss: 0.604672966, Training Accuracy: 82.032\n",
            "Worker 6, [18/37]: Training Loss: 0.526057509, Training Accuracy: 84.576\n",
            "Worker 6, [19/37]: Training Loss: 0.483271330, Training Accuracy: 85.728\n",
            "Worker 6, [20/37]: Training Loss: 0.431197372, Training Accuracy: 86.944\n",
            "Worker 6, [21/37]: Training Loss: 0.383056663, Training Accuracy: 88.672\n",
            "Worker 6, [22/37]: Training Loss: 0.333293817, Training Accuracy: 90.240\n",
            "Worker 6, [23/37]: Training Loss: 0.313350644, Training Accuracy: 90.624\n",
            "Worker 6, [24/37]: Training Loss: 0.265915637, Training Accuracy: 92.400\n",
            "Worker 6, [25/37]: Training Loss: 0.236896324, Training Accuracy: 93.488\n",
            "Worker 6, [26/37]: Training Loss: 0.226033224, Training Accuracy: 93.792\n",
            "Worker 6, [27/37]: Training Loss: 0.201744058, Training Accuracy: 94.592\n",
            "Worker 6, [28/37]: Training Loss: 0.191436361, Training Accuracy: 95.072\n",
            "Worker 6, [29/37]: Training Loss: 0.181344108, Training Accuracy: 95.120\n",
            "Worker 6, [30/37]: Training Loss: 0.158999606, Training Accuracy: 95.792\n",
            "Worker 6, [31/37]: Training Loss: 0.143264668, Training Accuracy: 96.288\n",
            "Worker 6, [32/37]: Training Loss: 0.145547719, Training Accuracy: 96.544\n",
            "Worker 6, [33/37]: Training Loss: 0.137026344, Training Accuracy: 96.544\n",
            "Worker 6, [34/37]: Training Loss: 0.136223725, Training Accuracy: 96.672\n",
            "Worker 6, [35/37]: Training Loss: 0.121708335, Training Accuracy: 97.152\n",
            "Worker 6, [36/37]: Training Loss: 0.126156149, Training Accuracy: 96.944\n",
            "Worker 6, [37/37]: Training Loss: 0.123483144, Training Accuracy: 97.104\n",
            "Time taken for training worker 6: 0:01:38.840881\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.094655224, Training Accuracy: 30.080\n",
            "Worker 7, [02/37]: Training Loss: 2.410875623, Training Accuracy: 38.576\n",
            "Worker 7, [03/37]: Training Loss: 2.124952249, Training Accuracy: 44.048\n",
            "Worker 7, [04/37]: Training Loss: 1.916396243, Training Accuracy: 48.416\n",
            "Worker 7, [05/37]: Training Loss: 1.757540734, Training Accuracy: 52.160\n",
            "Worker 7, [06/37]: Training Loss: 1.599353725, Training Accuracy: 56.144\n",
            "Worker 7, [07/37]: Training Loss: 1.509324195, Training Accuracy: 58.624\n",
            "Worker 7, [08/37]: Training Loss: 1.404065468, Training Accuracy: 60.640\n",
            "Worker 7, [09/37]: Training Loss: 1.326423579, Training Accuracy: 62.224\n",
            "Worker 7, [10/37]: Training Loss: 1.159749347, Training Accuracy: 66.592\n",
            "Worker 7, [11/37]: Training Loss: 1.057881856, Training Accuracy: 69.168\n",
            "Worker 7, [12/37]: Training Loss: 0.985707338, Training Accuracy: 71.696\n",
            "Worker 7, [13/37]: Training Loss: 0.908028487, Training Accuracy: 73.232\n",
            "Worker 7, [14/37]: Training Loss: 0.804939624, Training Accuracy: 76.320\n",
            "Worker 7, [15/37]: Training Loss: 0.738326327, Training Accuracy: 78.304\n",
            "Worker 7, [16/37]: Training Loss: 0.666317364, Training Accuracy: 80.000\n",
            "Worker 7, [17/37]: Training Loss: 0.598691688, Training Accuracy: 82.480\n",
            "Worker 7, [18/37]: Training Loss: 0.564817611, Training Accuracy: 83.040\n",
            "Worker 7, [19/37]: Training Loss: 0.496453024, Training Accuracy: 85.584\n",
            "Worker 7, [20/37]: Training Loss: 0.432428152, Training Accuracy: 86.848\n",
            "Worker 7, [21/37]: Training Loss: 0.376719185, Training Accuracy: 88.912\n",
            "Worker 7, [22/37]: Training Loss: 0.353628612, Training Accuracy: 89.712\n",
            "Worker 7, [23/37]: Training Loss: 0.316291078, Training Accuracy: 91.040\n",
            "Worker 7, [24/37]: Training Loss: 0.267081339, Training Accuracy: 92.720\n",
            "Worker 7, [25/37]: Training Loss: 0.243057476, Training Accuracy: 93.328\n",
            "Worker 7, [26/37]: Training Loss: 0.208485881, Training Accuracy: 94.256\n",
            "Worker 7, [27/37]: Training Loss: 0.202738654, Training Accuracy: 94.688\n",
            "Worker 7, [28/37]: Training Loss: 0.193443849, Training Accuracy: 94.896\n",
            "Worker 7, [29/37]: Training Loss: 0.182338197, Training Accuracy: 95.024\n",
            "Worker 7, [30/37]: Training Loss: 0.163235960, Training Accuracy: 95.760\n",
            "Worker 7, [31/37]: Training Loss: 0.140858762, Training Accuracy: 96.560\n",
            "Worker 7, [32/37]: Training Loss: 0.131852823, Training Accuracy: 96.784\n",
            "Worker 7, [33/37]: Training Loss: 0.131857574, Training Accuracy: 96.672\n",
            "Worker 7, [34/37]: Training Loss: 0.148145884, Training Accuracy: 96.144\n",
            "Worker 7, [35/37]: Training Loss: 0.124744539, Training Accuracy: 97.184\n",
            "Worker 7, [36/37]: Training Loss: 0.135949282, Training Accuracy: 96.848\n",
            "Worker 7, [37/37]: Training Loss: 0.132221750, Training Accuracy: 97.008\n",
            "Time taken for training worker 7: 0:01:40.877027\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.065717478, Training Accuracy: 29.296\n",
            "Worker 8, [02/37]: Training Loss: 2.354550060, Training Accuracy: 40.272\n",
            "Worker 8, [03/37]: Training Loss: 2.050511934, Training Accuracy: 45.728\n",
            "Worker 8, [04/37]: Training Loss: 1.831632484, Training Accuracy: 50.464\n",
            "Worker 8, [05/37]: Training Loss: 1.697488461, Training Accuracy: 53.424\n",
            "Worker 8, [06/37]: Training Loss: 1.583888615, Training Accuracy: 55.888\n",
            "Worker 8, [07/37]: Training Loss: 1.477791371, Training Accuracy: 58.432\n",
            "Worker 8, [08/37]: Training Loss: 1.373035652, Training Accuracy: 61.536\n",
            "Worker 8, [09/37]: Training Loss: 1.272500623, Training Accuracy: 63.232\n",
            "Worker 8, [10/37]: Training Loss: 1.152608997, Training Accuracy: 66.288\n",
            "Worker 8, [11/37]: Training Loss: 1.047112767, Training Accuracy: 69.008\n",
            "Worker 8, [12/37]: Training Loss: 0.963821127, Training Accuracy: 71.584\n",
            "Worker 8, [13/37]: Training Loss: 0.865311011, Training Accuracy: 73.872\n",
            "Worker 8, [14/37]: Training Loss: 0.783688304, Training Accuracy: 77.056\n",
            "Worker 8, [15/37]: Training Loss: 0.711209611, Training Accuracy: 78.496\n",
            "Worker 8, [16/37]: Training Loss: 0.637048039, Training Accuracy: 81.616\n",
            "Worker 8, [17/37]: Training Loss: 0.578049564, Training Accuracy: 82.784\n",
            "Worker 8, [18/37]: Training Loss: 0.524438206, Training Accuracy: 84.176\n",
            "Worker 8, [19/37]: Training Loss: 0.461060682, Training Accuracy: 86.352\n",
            "Worker 8, [20/37]: Training Loss: 0.404020747, Training Accuracy: 88.320\n",
            "Worker 8, [21/37]: Training Loss: 0.369544637, Training Accuracy: 89.200\n",
            "Worker 8, [22/37]: Training Loss: 0.322990852, Training Accuracy: 90.720\n",
            "Worker 8, [23/37]: Training Loss: 0.298635841, Training Accuracy: 91.280\n",
            "Worker 8, [24/37]: Training Loss: 0.267013501, Training Accuracy: 92.496\n",
            "Worker 8, [25/37]: Training Loss: 0.232413598, Training Accuracy: 93.376\n",
            "Worker 8, [26/37]: Training Loss: 0.213314290, Training Accuracy: 93.936\n",
            "Worker 8, [27/37]: Training Loss: 0.199071000, Training Accuracy: 94.384\n",
            "Worker 8, [28/37]: Training Loss: 0.164251119, Training Accuracy: 95.728\n",
            "Worker 8, [29/37]: Training Loss: 0.162544158, Training Accuracy: 95.936\n",
            "Worker 8, [30/37]: Training Loss: 0.146012183, Training Accuracy: 96.224\n",
            "Worker 8, [31/37]: Training Loss: 0.148527478, Training Accuracy: 96.208\n",
            "Worker 8, [32/37]: Training Loss: 0.138573460, Training Accuracy: 96.512\n",
            "Worker 8, [33/37]: Training Loss: 0.126516432, Training Accuracy: 96.960\n",
            "Worker 8, [34/37]: Training Loss: 0.120228415, Training Accuracy: 97.056\n",
            "Worker 8, [35/37]: Training Loss: 0.127851891, Training Accuracy: 96.592\n",
            "Worker 8, [36/37]: Training Loss: 0.117395498, Training Accuracy: 97.328\n",
            "Worker 8, [37/37]: Training Loss: 0.114059779, Training Accuracy: 97.408\n",
            "Time taken for training worker 8: 0:01:39.806103\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000889\n",
            "Local Step 03: Test Loss: 3.595600632, Test Accuracy: 41.930\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.686335024, Training Accuracy: 39.376\n",
            "Worker 1, [02/37]: Training Loss: 3.702701204, Training Accuracy: 38.656\n",
            "Worker 1, [03/37]: Training Loss: 3.421884004, Training Accuracy: 39.616\n",
            "Worker 1, [04/37]: Training Loss: 3.135692932, Training Accuracy: 39.616\n",
            "Worker 1, [05/37]: Training Loss: 2.823306045, Training Accuracy: 39.104\n",
            "Worker 1, [06/37]: Training Loss: 2.560449844, Training Accuracy: 40.864\n",
            "Worker 1, [07/37]: Training Loss: 2.427682424, Training Accuracy: 41.616\n",
            "Worker 1, [08/37]: Training Loss: 2.284744705, Training Accuracy: 43.328\n",
            "Worker 1, [09/37]: Training Loss: 2.151679462, Training Accuracy: 45.536\n",
            "Worker 1, [10/37]: Training Loss: 2.033743350, Training Accuracy: 48.112\n",
            "Worker 1, [11/37]: Training Loss: 1.914100988, Training Accuracy: 49.952\n",
            "Worker 1, [12/37]: Training Loss: 1.805971841, Training Accuracy: 51.808\n",
            "Worker 1, [13/37]: Training Loss: 1.713265420, Training Accuracy: 54.224\n",
            "Worker 1, [14/37]: Training Loss: 1.636292070, Training Accuracy: 55.296\n",
            "Worker 1, [15/37]: Training Loss: 1.534521875, Training Accuracy: 57.904\n",
            "Worker 1, [16/37]: Training Loss: 1.459028353, Training Accuracy: 59.488\n",
            "Worker 1, [17/37]: Training Loss: 1.379388634, Training Accuracy: 62.016\n",
            "Worker 1, [18/37]: Training Loss: 1.286669946, Training Accuracy: 64.176\n",
            "Worker 1, [19/37]: Training Loss: 1.247178305, Training Accuracy: 64.432\n",
            "Worker 1, [20/37]: Training Loss: 1.200506342, Training Accuracy: 65.696\n",
            "Worker 1, [21/37]: Training Loss: 1.153103190, Training Accuracy: 66.784\n",
            "Worker 1, [22/37]: Training Loss: 1.097074596, Training Accuracy: 68.064\n",
            "Worker 1, [23/37]: Training Loss: 1.067596966, Training Accuracy: 68.848\n",
            "Worker 1, [24/37]: Training Loss: 1.001559407, Training Accuracy: 70.784\n",
            "Worker 1, [25/37]: Training Loss: 0.956719090, Training Accuracy: 72.288\n",
            "Worker 1, [26/37]: Training Loss: 1.004912317, Training Accuracy: 70.624\n",
            "Worker 1, [27/37]: Training Loss: 0.994851036, Training Accuracy: 71.392\n",
            "Worker 1, [28/37]: Training Loss: 1.012397320, Training Accuracy: 70.576\n",
            "Worker 1, [29/37]: Training Loss: 0.953208161, Training Accuracy: 71.952\n",
            "Worker 1, [30/37]: Training Loss: 0.918278439, Training Accuracy: 72.912\n",
            "Worker 1, [31/37]: Training Loss: 0.915240829, Training Accuracy: 73.104\n",
            "Worker 1, [32/37]: Training Loss: 0.903065692, Training Accuracy: 74.048\n",
            "Worker 1, [33/37]: Training Loss: 0.899260248, Training Accuracy: 73.696\n",
            "Worker 1, [34/37]: Training Loss: 0.886078630, Training Accuracy: 74.064\n",
            "Worker 1, [35/37]: Training Loss: 0.887531720, Training Accuracy: 73.776\n",
            "Worker 1, [36/37]: Training Loss: 0.859059020, Training Accuracy: 74.720\n",
            "Worker 1, [37/37]: Training Loss: 0.842259679, Training Accuracy: 74.224\n",
            "Time taken for training worker 1: 0:01:42.488362\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.593657209, Training Accuracy: 33.536\n",
            "Worker 2, [02/37]: Training Loss: 3.471317442, Training Accuracy: 34.032\n",
            "Worker 2, [03/37]: Training Loss: 3.278894077, Training Accuracy: 35.104\n",
            "Worker 2, [04/37]: Training Loss: 2.996534669, Training Accuracy: 34.624\n",
            "Worker 2, [05/37]: Training Loss: 2.797722269, Training Accuracy: 36.128\n",
            "Worker 2, [06/37]: Training Loss: 2.610217218, Training Accuracy: 38.672\n",
            "Worker 2, [07/37]: Training Loss: 2.478005027, Training Accuracy: 39.648\n",
            "Worker 2, [08/37]: Training Loss: 2.376523715, Training Accuracy: 41.680\n",
            "Worker 2, [09/37]: Training Loss: 2.254546305, Training Accuracy: 43.168\n",
            "Worker 2, [10/37]: Training Loss: 2.155682171, Training Accuracy: 44.736\n",
            "Worker 2, [11/37]: Training Loss: 2.026237661, Training Accuracy: 47.552\n",
            "Worker 2, [12/37]: Training Loss: 1.939912808, Training Accuracy: 49.728\n",
            "Worker 2, [13/37]: Training Loss: 1.827287943, Training Accuracy: 51.824\n",
            "Worker 2, [14/37]: Training Loss: 1.704078489, Training Accuracy: 53.936\n",
            "Worker 2, [15/37]: Training Loss: 1.626528573, Training Accuracy: 56.432\n",
            "Worker 2, [16/37]: Training Loss: 1.544304132, Training Accuracy: 57.920\n",
            "Worker 2, [17/37]: Training Loss: 1.459335595, Training Accuracy: 59.632\n",
            "Worker 2, [18/37]: Training Loss: 1.375929416, Training Accuracy: 61.712\n",
            "Worker 2, [19/37]: Training Loss: 1.277098837, Training Accuracy: 63.984\n",
            "Worker 2, [20/37]: Training Loss: 1.258450060, Training Accuracy: 63.840\n",
            "Worker 2, [21/37]: Training Loss: 1.202802133, Training Accuracy: 65.904\n",
            "Worker 2, [22/37]: Training Loss: 1.145536365, Training Accuracy: 67.296\n",
            "Worker 2, [23/37]: Training Loss: 1.080594377, Training Accuracy: 67.600\n",
            "Worker 2, [24/37]: Training Loss: 1.073421636, Training Accuracy: 68.384\n",
            "Worker 2, [25/37]: Training Loss: 1.028553619, Training Accuracy: 69.824\n",
            "Worker 2, [26/37]: Training Loss: 0.998712454, Training Accuracy: 70.816\n",
            "Worker 2, [27/37]: Training Loss: 0.944933767, Training Accuracy: 71.696\n",
            "Worker 2, [28/37]: Training Loss: 0.913429301, Training Accuracy: 72.608\n",
            "Worker 2, [29/37]: Training Loss: 0.950400990, Training Accuracy: 71.520\n",
            "Worker 2, [30/37]: Training Loss: 0.949364148, Training Accuracy: 72.624\n",
            "Worker 2, [31/37]: Training Loss: 0.928732686, Training Accuracy: 72.432\n",
            "Worker 2, [32/37]: Training Loss: 0.917943945, Training Accuracy: 73.024\n",
            "Worker 2, [33/37]: Training Loss: 0.924780383, Training Accuracy: 72.368\n",
            "Worker 2, [34/37]: Training Loss: 0.891628845, Training Accuracy: 73.728\n",
            "Worker 2, [35/37]: Training Loss: 0.868528765, Training Accuracy: 73.744\n",
            "Worker 2, [36/37]: Training Loss: 0.843898643, Training Accuracy: 74.992\n",
            "Worker 2, [37/37]: Training Loss: 0.825628414, Training Accuracy: 76.032\n",
            "Time taken for training worker 2: 0:01:40.325013\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.638111978, Training Accuracy: 32.064\n",
            "Worker 3, [02/37]: Training Loss: 3.524614273, Training Accuracy: 32.832\n",
            "Worker 3, [03/37]: Training Loss: 3.329203066, Training Accuracy: 34.400\n",
            "Worker 3, [04/37]: Training Loss: 3.081901010, Training Accuracy: 35.104\n",
            "Worker 3, [05/37]: Training Loss: 2.853250428, Training Accuracy: 36.000\n",
            "Worker 3, [06/37]: Training Loss: 2.661246465, Training Accuracy: 37.264\n",
            "Worker 3, [07/37]: Training Loss: 2.545667500, Training Accuracy: 38.608\n",
            "Worker 3, [08/37]: Training Loss: 2.400757280, Training Accuracy: 40.752\n",
            "Worker 3, [09/37]: Training Loss: 2.284865069, Training Accuracy: 43.520\n",
            "Worker 3, [10/37]: Training Loss: 2.163052368, Training Accuracy: 45.296\n",
            "Worker 3, [11/37]: Training Loss: 2.062264068, Training Accuracy: 46.736\n",
            "Worker 3, [12/37]: Training Loss: 1.961186987, Training Accuracy: 49.376\n",
            "Worker 3, [13/37]: Training Loss: 1.857144498, Training Accuracy: 51.200\n",
            "Worker 3, [14/37]: Training Loss: 1.755601367, Training Accuracy: 53.072\n",
            "Worker 3, [15/37]: Training Loss: 1.652262624, Training Accuracy: 55.600\n",
            "Worker 3, [16/37]: Training Loss: 1.572523808, Training Accuracy: 57.424\n",
            "Worker 3, [17/37]: Training Loss: 1.466206865, Training Accuracy: 59.728\n",
            "Worker 3, [18/37]: Training Loss: 1.379330877, Training Accuracy: 62.096\n",
            "Worker 3, [19/37]: Training Loss: 1.283531882, Training Accuracy: 63.664\n",
            "Worker 3, [20/37]: Training Loss: 1.229891815, Training Accuracy: 64.944\n",
            "Worker 3, [21/37]: Training Loss: 1.181365502, Training Accuracy: 65.760\n",
            "Worker 3, [22/37]: Training Loss: 1.142520051, Training Accuracy: 67.824\n",
            "Worker 3, [23/37]: Training Loss: 1.066968612, Training Accuracy: 68.752\n",
            "Worker 3, [24/37]: Training Loss: 1.053595838, Training Accuracy: 68.928\n",
            "Worker 3, [25/37]: Training Loss: 0.977906118, Training Accuracy: 71.568\n",
            "Worker 3, [26/37]: Training Loss: 1.043756382, Training Accuracy: 69.712\n",
            "Worker 3, [27/37]: Training Loss: 0.957239721, Training Accuracy: 71.424\n",
            "Worker 3, [28/37]: Training Loss: 0.947558212, Training Accuracy: 72.208\n",
            "Worker 3, [29/37]: Training Loss: 0.890352684, Training Accuracy: 74.032\n",
            "Worker 3, [30/37]: Training Loss: 0.908271231, Training Accuracy: 73.520\n",
            "Worker 3, [31/37]: Training Loss: 0.895256668, Training Accuracy: 73.184\n",
            "Worker 3, [32/37]: Training Loss: 0.850405776, Training Accuracy: 74.736\n",
            "Worker 3, [33/37]: Training Loss: 0.873795119, Training Accuracy: 73.728\n",
            "Worker 3, [34/37]: Training Loss: 0.827610734, Training Accuracy: 75.120\n",
            "Worker 3, [35/37]: Training Loss: 0.847484129, Training Accuracy: 75.840\n",
            "Worker 3, [36/37]: Training Loss: 0.809398602, Training Accuracy: 75.328\n",
            "Worker 3, [37/37]: Training Loss: 0.772998851, Training Accuracy: 77.520\n",
            "Time taken for training worker 3: 0:01:38.482635\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.553807937, Training Accuracy: 32.240\n",
            "Worker 4, [02/37]: Training Loss: 3.454087501, Training Accuracy: 33.872\n",
            "Worker 4, [03/37]: Training Loss: 3.221232984, Training Accuracy: 35.136\n",
            "Worker 4, [04/37]: Training Loss: 2.976932494, Training Accuracy: 35.536\n",
            "Worker 4, [05/37]: Training Loss: 2.808751583, Training Accuracy: 36.080\n",
            "Worker 4, [06/37]: Training Loss: 2.633987997, Training Accuracy: 37.952\n",
            "Worker 4, [07/37]: Training Loss: 2.470285440, Training Accuracy: 39.856\n",
            "Worker 4, [08/37]: Training Loss: 2.359913873, Training Accuracy: 41.568\n",
            "Worker 4, [09/37]: Training Loss: 2.278141808, Training Accuracy: 42.592\n",
            "Worker 4, [10/37]: Training Loss: 2.145207915, Training Accuracy: 45.648\n",
            "Worker 4, [11/37]: Training Loss: 2.036200096, Training Accuracy: 47.408\n",
            "Worker 4, [12/37]: Training Loss: 1.941567963, Training Accuracy: 49.168\n",
            "Worker 4, [13/37]: Training Loss: 1.855746543, Training Accuracy: 51.008\n",
            "Worker 4, [14/37]: Training Loss: 1.718012273, Training Accuracy: 53.936\n",
            "Worker 4, [15/37]: Training Loss: 1.656235431, Training Accuracy: 55.328\n",
            "Worker 4, [16/37]: Training Loss: 1.540100446, Training Accuracy: 57.520\n",
            "Worker 4, [17/37]: Training Loss: 1.468075403, Training Accuracy: 59.920\n",
            "Worker 4, [18/37]: Training Loss: 1.384102802, Training Accuracy: 61.184\n",
            "Worker 4, [19/37]: Training Loss: 1.335322646, Training Accuracy: 63.104\n",
            "Worker 4, [20/37]: Training Loss: 1.210321901, Training Accuracy: 65.760\n",
            "Worker 4, [21/37]: Training Loss: 1.192230310, Training Accuracy: 65.488\n",
            "Worker 4, [22/37]: Training Loss: 1.124756329, Training Accuracy: 68.032\n",
            "Worker 4, [23/37]: Training Loss: 1.082227034, Training Accuracy: 68.928\n",
            "Worker 4, [24/37]: Training Loss: 1.062188924, Training Accuracy: 69.200\n",
            "Worker 4, [25/37]: Training Loss: 1.032094016, Training Accuracy: 69.536\n",
            "Worker 4, [26/37]: Training Loss: 1.001205615, Training Accuracy: 71.024\n",
            "Worker 4, [27/37]: Training Loss: 0.962415941, Training Accuracy: 71.536\n",
            "Worker 4, [28/37]: Training Loss: 0.907128361, Training Accuracy: 72.880\n",
            "Worker 4, [29/37]: Training Loss: 0.903406402, Training Accuracy: 73.664\n",
            "Worker 4, [30/37]: Training Loss: 0.920966887, Training Accuracy: 72.080\n",
            "Worker 4, [31/37]: Training Loss: 0.850005890, Training Accuracy: 74.448\n",
            "Worker 4, [32/37]: Training Loss: 0.907195900, Training Accuracy: 72.848\n",
            "Worker 4, [33/37]: Training Loss: 0.850881106, Training Accuracy: 74.592\n",
            "Worker 4, [34/37]: Training Loss: 0.843379994, Training Accuracy: 74.736\n",
            "Worker 4, [35/37]: Training Loss: 0.813715567, Training Accuracy: 75.840\n",
            "Worker 4, [36/37]: Training Loss: 0.866159742, Training Accuracy: 74.192\n",
            "Worker 4, [37/37]: Training Loss: 0.773310898, Training Accuracy: 77.664\n",
            "Time taken for training worker 4: 0:01:40.014150\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.654551321, Training Accuracy: 33.664\n",
            "Worker 5, [02/37]: Training Loss: 3.629657826, Training Accuracy: 33.920\n",
            "Worker 5, [03/37]: Training Loss: 3.376288482, Training Accuracy: 34.528\n",
            "Worker 5, [04/37]: Training Loss: 3.072055736, Training Accuracy: 36.016\n",
            "Worker 5, [05/37]: Training Loss: 2.863108867, Training Accuracy: 36.128\n",
            "Worker 5, [06/37]: Training Loss: 2.680253652, Training Accuracy: 37.280\n",
            "Worker 5, [07/37]: Training Loss: 2.559131336, Training Accuracy: 38.288\n",
            "Worker 5, [08/37]: Training Loss: 2.391381308, Training Accuracy: 40.848\n",
            "Worker 5, [09/37]: Training Loss: 2.302024452, Training Accuracy: 42.832\n",
            "Worker 5, [10/37]: Training Loss: 2.184226056, Training Accuracy: 44.608\n",
            "Worker 5, [11/37]: Training Loss: 2.048804823, Training Accuracy: 46.768\n",
            "Worker 5, [12/37]: Training Loss: 1.969345133, Training Accuracy: 49.024\n",
            "Worker 5, [13/37]: Training Loss: 1.872145024, Training Accuracy: 50.800\n",
            "Worker 5, [14/37]: Training Loss: 1.737743435, Training Accuracy: 53.216\n",
            "Worker 5, [15/37]: Training Loss: 1.684144016, Training Accuracy: 54.544\n",
            "Worker 5, [16/37]: Training Loss: 1.588060580, Training Accuracy: 56.544\n",
            "Worker 5, [17/37]: Training Loss: 1.489327335, Training Accuracy: 58.304\n",
            "Worker 5, [18/37]: Training Loss: 1.383948534, Training Accuracy: 61.376\n",
            "Worker 5, [19/37]: Training Loss: 1.322125064, Training Accuracy: 63.520\n",
            "Worker 5, [20/37]: Training Loss: 1.234199463, Training Accuracy: 65.248\n",
            "Worker 5, [21/37]: Training Loss: 1.194040598, Training Accuracy: 65.600\n",
            "Worker 5, [22/37]: Training Loss: 1.145358458, Training Accuracy: 66.496\n",
            "Worker 5, [23/37]: Training Loss: 1.104424174, Training Accuracy: 68.368\n",
            "Worker 5, [24/37]: Training Loss: 1.059935385, Training Accuracy: 69.312\n",
            "Worker 5, [25/37]: Training Loss: 0.987472400, Training Accuracy: 71.936\n",
            "Worker 5, [26/37]: Training Loss: 0.994048555, Training Accuracy: 71.072\n",
            "Worker 5, [27/37]: Training Loss: 0.957127969, Training Accuracy: 71.456\n",
            "Worker 5, [28/37]: Training Loss: 0.973411644, Training Accuracy: 71.456\n",
            "Worker 5, [29/37]: Training Loss: 0.984605814, Training Accuracy: 70.544\n",
            "Worker 5, [30/37]: Training Loss: 0.946752351, Training Accuracy: 72.352\n",
            "Worker 5, [31/37]: Training Loss: 0.865714431, Training Accuracy: 74.576\n",
            "Worker 5, [32/37]: Training Loss: 0.862749814, Training Accuracy: 74.832\n",
            "Worker 5, [33/37]: Training Loss: 0.858997891, Training Accuracy: 74.448\n",
            "Worker 5, [34/37]: Training Loss: 0.848652495, Training Accuracy: 74.720\n",
            "Worker 5, [35/37]: Training Loss: 0.829595280, Training Accuracy: 75.728\n",
            "Worker 5, [36/37]: Training Loss: 0.800795430, Training Accuracy: 75.792\n",
            "Worker 5, [37/37]: Training Loss: 0.761159734, Training Accuracy: 77.344\n",
            "Time taken for training worker 5: 0:01:40.509334\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.609369207, Training Accuracy: 34.144\n",
            "Worker 6, [02/37]: Training Loss: 3.529398497, Training Accuracy: 34.560\n",
            "Worker 6, [03/37]: Training Loss: 3.286423909, Training Accuracy: 36.032\n",
            "Worker 6, [04/37]: Training Loss: 3.046944572, Training Accuracy: 36.224\n",
            "Worker 6, [05/37]: Training Loss: 2.780620570, Training Accuracy: 37.696\n",
            "Worker 6, [06/37]: Training Loss: 2.634001403, Training Accuracy: 37.536\n",
            "Worker 6, [07/37]: Training Loss: 2.486293822, Training Accuracy: 39.968\n",
            "Worker 6, [08/37]: Training Loss: 2.336206513, Training Accuracy: 42.256\n",
            "Worker 6, [09/37]: Training Loss: 2.235251784, Training Accuracy: 43.408\n",
            "Worker 6, [10/37]: Training Loss: 2.116448207, Training Accuracy: 46.304\n",
            "Worker 6, [11/37]: Training Loss: 1.997586573, Training Accuracy: 47.856\n",
            "Worker 6, [12/37]: Training Loss: 1.908636082, Training Accuracy: 50.000\n",
            "Worker 6, [13/37]: Training Loss: 1.772515005, Training Accuracy: 52.832\n",
            "Worker 6, [14/37]: Training Loss: 1.693798469, Training Accuracy: 54.080\n",
            "Worker 6, [15/37]: Training Loss: 1.583056374, Training Accuracy: 56.640\n",
            "Worker 6, [16/37]: Training Loss: 1.495513682, Training Accuracy: 58.512\n",
            "Worker 6, [17/37]: Training Loss: 1.430390215, Training Accuracy: 61.136\n",
            "Worker 6, [18/37]: Training Loss: 1.363431147, Training Accuracy: 61.344\n",
            "Worker 6, [19/37]: Training Loss: 1.241298239, Training Accuracy: 64.736\n",
            "Worker 6, [20/37]: Training Loss: 1.206477239, Training Accuracy: 65.216\n",
            "Worker 6, [21/37]: Training Loss: 1.128340404, Training Accuracy: 67.296\n",
            "Worker 6, [22/37]: Training Loss: 1.082383193, Training Accuracy: 68.768\n",
            "Worker 6, [23/37]: Training Loss: 1.013879300, Training Accuracy: 70.848\n",
            "Worker 6, [24/37]: Training Loss: 0.966988204, Training Accuracy: 71.376\n",
            "Worker 6, [25/37]: Training Loss: 0.963854519, Training Accuracy: 71.920\n",
            "Worker 6, [26/37]: Training Loss: 0.907344202, Training Accuracy: 73.680\n",
            "Worker 6, [27/37]: Training Loss: 0.915421819, Training Accuracy: 73.056\n",
            "Worker 6, [28/37]: Training Loss: 0.872033177, Training Accuracy: 73.616\n",
            "Worker 6, [29/37]: Training Loss: 0.856193126, Training Accuracy: 74.336\n",
            "Worker 6, [30/37]: Training Loss: 0.875763109, Training Accuracy: 73.872\n",
            "Worker 6, [31/37]: Training Loss: 0.831826434, Training Accuracy: 75.536\n",
            "Worker 6, [32/37]: Training Loss: 0.847350031, Training Accuracy: 74.640\n",
            "Worker 6, [33/37]: Training Loss: 0.873182187, Training Accuracy: 74.416\n",
            "Worker 6, [34/37]: Training Loss: 0.847394885, Training Accuracy: 74.688\n",
            "Worker 6, [35/37]: Training Loss: 0.767724755, Training Accuracy: 77.056\n",
            "Worker 6, [36/37]: Training Loss: 0.735335265, Training Accuracy: 78.096\n",
            "Worker 6, [37/37]: Training Loss: 0.785102585, Training Accuracy: 76.976\n",
            "Time taken for training worker 6: 0:01:40.639230\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.548944957, Training Accuracy: 33.984\n",
            "Worker 7, [02/37]: Training Loss: 3.443735938, Training Accuracy: 34.544\n",
            "Worker 7, [03/37]: Training Loss: 3.260586563, Training Accuracy: 35.504\n",
            "Worker 7, [04/37]: Training Loss: 3.018723201, Training Accuracy: 35.712\n",
            "Worker 7, [05/37]: Training Loss: 2.793689120, Training Accuracy: 36.784\n",
            "Worker 7, [06/37]: Training Loss: 2.639923400, Training Accuracy: 38.320\n",
            "Worker 7, [07/37]: Training Loss: 2.485279181, Training Accuracy: 39.600\n",
            "Worker 7, [08/37]: Training Loss: 2.357229907, Training Accuracy: 42.176\n",
            "Worker 7, [09/37]: Training Loss: 2.229210646, Training Accuracy: 44.176\n",
            "Worker 7, [10/37]: Training Loss: 2.142595882, Training Accuracy: 45.152\n",
            "Worker 7, [11/37]: Training Loss: 2.036654590, Training Accuracy: 47.920\n",
            "Worker 7, [12/37]: Training Loss: 1.934890220, Training Accuracy: 49.248\n",
            "Worker 7, [13/37]: Training Loss: 1.828792612, Training Accuracy: 51.984\n",
            "Worker 7, [14/37]: Training Loss: 1.720668223, Training Accuracy: 53.952\n",
            "Worker 7, [15/37]: Training Loss: 1.624277446, Training Accuracy: 55.856\n",
            "Worker 7, [16/37]: Training Loss: 1.550467396, Training Accuracy: 57.824\n",
            "Worker 7, [17/37]: Training Loss: 1.446615564, Training Accuracy: 60.128\n",
            "Worker 7, [18/37]: Training Loss: 1.369983967, Training Accuracy: 62.256\n",
            "Worker 7, [19/37]: Training Loss: 1.265634480, Training Accuracy: 64.752\n",
            "Worker 7, [20/37]: Training Loss: 1.244552434, Training Accuracy: 64.896\n",
            "Worker 7, [21/37]: Training Loss: 1.178168448, Training Accuracy: 66.560\n",
            "Worker 7, [22/37]: Training Loss: 1.100981300, Training Accuracy: 68.080\n",
            "Worker 7, [23/37]: Training Loss: 1.049598302, Training Accuracy: 69.376\n",
            "Worker 7, [24/37]: Training Loss: 1.020737067, Training Accuracy: 70.048\n",
            "Worker 7, [25/37]: Training Loss: 0.956709452, Training Accuracy: 72.000\n",
            "Worker 7, [26/37]: Training Loss: 0.938867529, Training Accuracy: 72.208\n",
            "Worker 7, [27/37]: Training Loss: 0.929281566, Training Accuracy: 72.480\n",
            "Worker 7, [28/37]: Training Loss: 0.920559531, Training Accuracy: 72.560\n",
            "Worker 7, [29/37]: Training Loss: 0.871519314, Training Accuracy: 73.936\n",
            "Worker 7, [30/37]: Training Loss: 0.884485416, Training Accuracy: 74.272\n",
            "Worker 7, [31/37]: Training Loss: 0.844403296, Training Accuracy: 74.896\n",
            "Worker 7, [32/37]: Training Loss: 0.845389424, Training Accuracy: 74.384\n",
            "Worker 7, [33/37]: Training Loss: 0.804619749, Training Accuracy: 76.528\n",
            "Worker 7, [34/37]: Training Loss: 0.806574993, Training Accuracy: 75.872\n",
            "Worker 7, [35/37]: Training Loss: 0.829884663, Training Accuracy: 75.616\n",
            "Worker 7, [36/37]: Training Loss: 0.759783417, Training Accuracy: 77.744\n",
            "Worker 7, [37/37]: Training Loss: 0.800456538, Training Accuracy: 76.016\n",
            "Time taken for training worker 7: 0:01:40.803291\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.556197882, Training Accuracy: 34.496\n",
            "Worker 8, [02/37]: Training Loss: 3.501307896, Training Accuracy: 34.240\n",
            "Worker 8, [03/37]: Training Loss: 3.299798922, Training Accuracy: 34.832\n",
            "Worker 8, [04/37]: Training Loss: 3.023635258, Training Accuracy: 36.432\n",
            "Worker 8, [05/37]: Training Loss: 2.791560611, Training Accuracy: 37.328\n",
            "Worker 8, [06/37]: Training Loss: 2.619311480, Training Accuracy: 38.080\n",
            "Worker 8, [07/37]: Training Loss: 2.452724666, Training Accuracy: 40.336\n",
            "Worker 8, [08/37]: Training Loss: 2.352617315, Training Accuracy: 41.712\n",
            "Worker 8, [09/37]: Training Loss: 2.221698417, Training Accuracy: 44.032\n",
            "Worker 8, [10/37]: Training Loss: 2.125211953, Training Accuracy: 45.264\n",
            "Worker 8, [11/37]: Training Loss: 2.027781946, Training Accuracy: 47.552\n",
            "Worker 8, [12/37]: Training Loss: 1.886349465, Training Accuracy: 50.320\n",
            "Worker 8, [13/37]: Training Loss: 1.775725688, Training Accuracy: 51.760\n",
            "Worker 8, [14/37]: Training Loss: 1.691326005, Training Accuracy: 53.744\n",
            "Worker 8, [15/37]: Training Loss: 1.568833824, Training Accuracy: 56.688\n",
            "Worker 8, [16/37]: Training Loss: 1.502830553, Training Accuracy: 58.320\n",
            "Worker 8, [17/37]: Training Loss: 1.417904255, Training Accuracy: 60.288\n",
            "Worker 8, [18/37]: Training Loss: 1.344780295, Training Accuracy: 62.368\n",
            "Worker 8, [19/37]: Training Loss: 1.258753846, Training Accuracy: 64.432\n",
            "Worker 8, [20/37]: Training Loss: 1.196167487, Training Accuracy: 66.096\n",
            "Worker 8, [21/37]: Training Loss: 1.099463888, Training Accuracy: 68.160\n",
            "Worker 8, [22/37]: Training Loss: 1.053717795, Training Accuracy: 68.944\n",
            "Worker 8, [23/37]: Training Loss: 1.030138806, Training Accuracy: 70.144\n",
            "Worker 8, [24/37]: Training Loss: 1.001660009, Training Accuracy: 70.992\n",
            "Worker 8, [25/37]: Training Loss: 1.001354874, Training Accuracy: 70.640\n",
            "Worker 8, [26/37]: Training Loss: 0.959304824, Training Accuracy: 71.904\n",
            "Worker 8, [27/37]: Training Loss: 0.910509374, Training Accuracy: 72.592\n",
            "Worker 8, [28/37]: Training Loss: 0.895418057, Training Accuracy: 73.264\n",
            "Worker 8, [29/37]: Training Loss: 0.905991090, Training Accuracy: 72.448\n",
            "Worker 8, [30/37]: Training Loss: 0.877878545, Training Accuracy: 74.736\n",
            "Worker 8, [31/37]: Training Loss: 0.835949804, Training Accuracy: 75.136\n",
            "Worker 8, [32/37]: Training Loss: 0.859947237, Training Accuracy: 74.336\n",
            "Worker 8, [33/37]: Training Loss: 0.890439155, Training Accuracy: 73.904\n",
            "Worker 8, [34/37]: Training Loss: 0.823091239, Training Accuracy: 75.904\n",
            "Worker 8, [35/37]: Training Loss: 0.783876994, Training Accuracy: 76.432\n",
            "Worker 8, [36/37]: Training Loss: 0.789491856, Training Accuracy: 75.968\n",
            "Worker 8, [37/37]: Training Loss: 0.778510036, Training Accuracy: 76.656\n",
            "Time taken for training worker 8: 0:01:41.403314\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000711\n",
            "Local Step 04: Test Loss: 3.322228234, Test Accuracy: 38.120\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:53:25.360590\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.593723939, Training Accuracy: 1.328\n",
            "Worker 1, [02/18]: Training Loss: 4.446402316, Training Accuracy: 3.184\n",
            "Worker 1, [03/18]: Training Loss: 4.199968795, Training Accuracy: 4.944\n",
            "Worker 1, [04/18]: Training Loss: 4.064594157, Training Accuracy: 7.232\n",
            "Worker 1, [05/18]: Training Loss: 3.943653075, Training Accuracy: 8.240\n",
            "Worker 1, [06/18]: Training Loss: 3.835344003, Training Accuracy: 10.512\n",
            "Worker 1, [07/18]: Training Loss: 3.744529264, Training Accuracy: 12.160\n",
            "Worker 1, [08/18]: Training Loss: 3.645545760, Training Accuracy: 13.232\n",
            "Worker 1, [09/18]: Training Loss: 3.554142874, Training Accuracy: 15.088\n",
            "Worker 1, [10/18]: Training Loss: 3.489152147, Training Accuracy: 16.224\n",
            "Worker 1, [11/18]: Training Loss: 3.388319405, Training Accuracy: 17.696\n",
            "Worker 1, [12/18]: Training Loss: 3.306818597, Training Accuracy: 19.088\n",
            "Worker 1, [13/18]: Training Loss: 3.223739281, Training Accuracy: 20.720\n",
            "Worker 1, [14/18]: Training Loss: 3.155948028, Training Accuracy: 21.488\n",
            "Worker 1, [15/18]: Training Loss: 3.114983174, Training Accuracy: 22.688\n",
            "Worker 1, [16/18]: Training Loss: 3.049290791, Training Accuracy: 24.240\n",
            "Worker 1, [17/18]: Training Loss: 3.015608252, Training Accuracy: 25.504\n",
            "Worker 1, [18/18]: Training Loss: 3.005337044, Training Accuracy: 25.776\n",
            "Time taken for training worker 1: 0:00:48.810930\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.593558706, Training Accuracy: 1.296\n",
            "Worker 2, [02/18]: Training Loss: 4.449805041, Training Accuracy: 3.168\n",
            "Worker 2, [03/18]: Training Loss: 4.212214219, Training Accuracy: 5.344\n",
            "Worker 2, [04/18]: Training Loss: 4.066263664, Training Accuracy: 7.360\n",
            "Worker 2, [05/18]: Training Loss: 3.936319271, Training Accuracy: 8.352\n",
            "Worker 2, [06/18]: Training Loss: 3.852526550, Training Accuracy: 10.208\n",
            "Worker 2, [07/18]: Training Loss: 3.741105245, Training Accuracy: 12.240\n",
            "Worker 2, [08/18]: Training Loss: 3.653352633, Training Accuracy: 13.024\n",
            "Worker 2, [09/18]: Training Loss: 3.560733866, Training Accuracy: 14.320\n",
            "Worker 2, [10/18]: Training Loss: 3.469086141, Training Accuracy: 16.688\n",
            "Worker 2, [11/18]: Training Loss: 3.410907025, Training Accuracy: 17.408\n",
            "Worker 2, [12/18]: Training Loss: 3.324408621, Training Accuracy: 18.496\n",
            "Worker 2, [13/18]: Training Loss: 3.267902832, Training Accuracy: 19.808\n",
            "Worker 2, [14/18]: Training Loss: 3.196284277, Training Accuracy: 21.312\n",
            "Worker 2, [15/18]: Training Loss: 3.149989960, Training Accuracy: 22.368\n",
            "Worker 2, [16/18]: Training Loss: 3.091239576, Training Accuracy: 23.056\n",
            "Worker 2, [17/18]: Training Loss: 3.051023999, Training Accuracy: 24.464\n",
            "Worker 2, [18/18]: Training Loss: 3.029111969, Training Accuracy: 24.256\n",
            "Time taken for training worker 2: 0:00:47.649143\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.592879334, Training Accuracy: 1.600\n",
            "Worker 3, [02/18]: Training Loss: 4.456348784, Training Accuracy: 3.024\n",
            "Worker 3, [03/18]: Training Loss: 4.181929063, Training Accuracy: 5.856\n",
            "Worker 3, [04/18]: Training Loss: 4.048716701, Training Accuracy: 7.536\n",
            "Worker 3, [05/18]: Training Loss: 3.939198886, Training Accuracy: 8.304\n",
            "Worker 3, [06/18]: Training Loss: 3.859863245, Training Accuracy: 10.288\n",
            "Worker 3, [07/18]: Training Loss: 3.745531389, Training Accuracy: 11.840\n",
            "Worker 3, [08/18]: Training Loss: 3.655442578, Training Accuracy: 13.264\n",
            "Worker 3, [09/18]: Training Loss: 3.569700521, Training Accuracy: 14.144\n",
            "Worker 3, [10/18]: Training Loss: 3.481395928, Training Accuracy: 16.320\n",
            "Worker 3, [11/18]: Training Loss: 3.430213692, Training Accuracy: 17.248\n",
            "Worker 3, [12/18]: Training Loss: 3.348945228, Training Accuracy: 18.944\n",
            "Worker 3, [13/18]: Training Loss: 3.260354538, Training Accuracy: 19.936\n",
            "Worker 3, [14/18]: Training Loss: 3.205913702, Training Accuracy: 20.848\n",
            "Worker 3, [15/18]: Training Loss: 3.134885250, Training Accuracy: 21.888\n",
            "Worker 3, [16/18]: Training Loss: 3.095780319, Training Accuracy: 22.688\n",
            "Worker 3, [17/18]: Training Loss: 3.052482578, Training Accuracy: 24.208\n",
            "Worker 3, [18/18]: Training Loss: 3.035027764, Training Accuracy: 24.352\n",
            "Time taken for training worker 3: 0:00:47.679621\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.594124784, Training Accuracy: 1.408\n",
            "Worker 4, [02/18]: Training Loss: 4.458117456, Training Accuracy: 3.296\n",
            "Worker 4, [03/18]: Training Loss: 4.203906911, Training Accuracy: 5.888\n",
            "Worker 4, [04/18]: Training Loss: 4.047599953, Training Accuracy: 7.440\n",
            "Worker 4, [05/18]: Training Loss: 3.922178777, Training Accuracy: 9.072\n",
            "Worker 4, [06/18]: Training Loss: 3.801885422, Training Accuracy: 11.040\n",
            "Worker 4, [07/18]: Training Loss: 3.720024510, Training Accuracy: 12.464\n",
            "Worker 4, [08/18]: Training Loss: 3.655099995, Training Accuracy: 13.328\n",
            "Worker 4, [09/18]: Training Loss: 3.556674495, Training Accuracy: 15.104\n",
            "Worker 4, [10/18]: Training Loss: 3.487710016, Training Accuracy: 16.240\n",
            "Worker 4, [11/18]: Training Loss: 3.388225901, Training Accuracy: 17.808\n",
            "Worker 4, [12/18]: Training Loss: 3.330920086, Training Accuracy: 18.912\n",
            "Worker 4, [13/18]: Training Loss: 3.253497844, Training Accuracy: 20.144\n",
            "Worker 4, [14/18]: Training Loss: 3.187703539, Training Accuracy: 21.424\n",
            "Worker 4, [15/18]: Training Loss: 3.121694679, Training Accuracy: 22.528\n",
            "Worker 4, [16/18]: Training Loss: 3.073057394, Training Accuracy: 24.256\n",
            "Worker 4, [17/18]: Training Loss: 3.043658030, Training Accuracy: 24.992\n",
            "Worker 4, [18/18]: Training Loss: 3.012400270, Training Accuracy: 25.776\n",
            "Time taken for training worker 4: 0:00:47.826833\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 4.595853767, Training Accuracy: 1.808\n",
            "Worker 5, [02/18]: Training Loss: 4.449591598, Training Accuracy: 3.104\n",
            "Worker 5, [03/18]: Training Loss: 4.210976829, Training Accuracy: 5.584\n",
            "Worker 5, [04/18]: Training Loss: 4.073080790, Training Accuracy: 7.616\n",
            "Worker 5, [05/18]: Training Loss: 3.968873489, Training Accuracy: 8.400\n",
            "Worker 5, [06/18]: Training Loss: 3.859955532, Training Accuracy: 10.080\n",
            "Worker 5, [07/18]: Training Loss: 3.759040626, Training Accuracy: 11.648\n",
            "Worker 5, [08/18]: Training Loss: 3.670409577, Training Accuracy: 12.976\n",
            "Worker 5, [09/18]: Training Loss: 3.588359419, Training Accuracy: 14.432\n",
            "Worker 5, [10/18]: Training Loss: 3.485902723, Training Accuracy: 16.032\n",
            "Worker 5, [11/18]: Training Loss: 3.418018699, Training Accuracy: 16.816\n",
            "Worker 5, [12/18]: Training Loss: 3.355405598, Training Accuracy: 18.000\n",
            "Worker 5, [13/18]: Training Loss: 3.280644485, Training Accuracy: 19.712\n",
            "Worker 5, [14/18]: Training Loss: 3.223837232, Training Accuracy: 20.688\n",
            "Worker 5, [15/18]: Training Loss: 3.165111768, Training Accuracy: 21.536\n",
            "Worker 5, [16/18]: Training Loss: 3.115638847, Training Accuracy: 22.608\n",
            "Worker 5, [17/18]: Training Loss: 3.088685778, Training Accuracy: 23.888\n",
            "Worker 5, [18/18]: Training Loss: 3.067868843, Training Accuracy: 23.904\n",
            "Time taken for training worker 5: 0:00:49.495933\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 4.590760878, Training Accuracy: 1.408\n",
            "Worker 6, [02/18]: Training Loss: 4.426323501, Training Accuracy: 3.536\n",
            "Worker 6, [03/18]: Training Loss: 4.170231376, Training Accuracy: 5.840\n",
            "Worker 6, [04/18]: Training Loss: 4.025930334, Training Accuracy: 7.216\n",
            "Worker 6, [05/18]: Training Loss: 3.913945568, Training Accuracy: 9.296\n",
            "Worker 6, [06/18]: Training Loss: 3.810890553, Training Accuracy: 10.368\n",
            "Worker 6, [07/18]: Training Loss: 3.710085528, Training Accuracy: 12.288\n",
            "Worker 6, [08/18]: Training Loss: 3.635126092, Training Accuracy: 12.928\n",
            "Worker 6, [09/18]: Training Loss: 3.532430189, Training Accuracy: 15.616\n",
            "Worker 6, [10/18]: Training Loss: 3.452408725, Training Accuracy: 16.800\n",
            "Worker 6, [11/18]: Training Loss: 3.375215058, Training Accuracy: 17.904\n",
            "Worker 6, [12/18]: Training Loss: 3.283983819, Training Accuracy: 19.520\n",
            "Worker 6, [13/18]: Training Loss: 3.236361319, Training Accuracy: 20.208\n",
            "Worker 6, [14/18]: Training Loss: 3.166036234, Training Accuracy: 21.312\n",
            "Worker 6, [15/18]: Training Loss: 3.105470983, Training Accuracy: 22.816\n",
            "Worker 6, [16/18]: Training Loss: 3.068657121, Training Accuracy: 23.872\n",
            "Worker 6, [17/18]: Training Loss: 3.016773922, Training Accuracy: 24.848\n",
            "Worker 6, [18/18]: Training Loss: 2.988060173, Training Accuracy: 25.296\n",
            "Time taken for training worker 6: 0:00:48.852299\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 4.591137789, Training Accuracy: 1.680\n",
            "Worker 7, [02/18]: Training Loss: 4.449195278, Training Accuracy: 3.248\n",
            "Worker 7, [03/18]: Training Loss: 4.197504606, Training Accuracy: 5.184\n",
            "Worker 7, [04/18]: Training Loss: 4.044914939, Training Accuracy: 7.344\n",
            "Worker 7, [05/18]: Training Loss: 3.912672795, Training Accuracy: 8.784\n",
            "Worker 7, [06/18]: Training Loss: 3.797308435, Training Accuracy: 10.640\n",
            "Worker 7, [07/18]: Training Loss: 3.692049017, Training Accuracy: 12.912\n",
            "Worker 7, [08/18]: Training Loss: 3.616921135, Training Accuracy: 14.096\n",
            "Worker 7, [09/18]: Training Loss: 3.525824737, Training Accuracy: 15.872\n",
            "Worker 7, [10/18]: Training Loss: 3.445378885, Training Accuracy: 17.056\n",
            "Worker 7, [11/18]: Training Loss: 3.350532576, Training Accuracy: 18.592\n",
            "Worker 7, [12/18]: Training Loss: 3.276690848, Training Accuracy: 20.272\n",
            "Worker 7, [13/18]: Training Loss: 3.210687827, Training Accuracy: 21.184\n",
            "Worker 7, [14/18]: Training Loss: 3.140819294, Training Accuracy: 22.640\n",
            "Worker 7, [15/18]: Training Loss: 3.065564129, Training Accuracy: 24.672\n",
            "Worker 7, [16/18]: Training Loss: 3.033376871, Training Accuracy: 25.088\n",
            "Worker 7, [17/18]: Training Loss: 2.980347461, Training Accuracy: 26.192\n",
            "Worker 7, [18/18]: Training Loss: 2.971487340, Training Accuracy: 26.688\n",
            "Time taken for training worker 7: 0:00:49.860005\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 4.592051326, Training Accuracy: 1.312\n",
            "Worker 8, [02/18]: Training Loss: 4.449133678, Training Accuracy: 3.280\n",
            "Worker 8, [03/18]: Training Loss: 4.187163964, Training Accuracy: 5.936\n",
            "Worker 8, [04/18]: Training Loss: 4.044127445, Training Accuracy: 8.000\n",
            "Worker 8, [05/18]: Training Loss: 3.917816512, Training Accuracy: 9.440\n",
            "Worker 8, [06/18]: Training Loss: 3.808442447, Training Accuracy: 11.024\n",
            "Worker 8, [07/18]: Training Loss: 3.720790875, Training Accuracy: 12.480\n",
            "Worker 8, [08/18]: Training Loss: 3.631231320, Training Accuracy: 13.856\n",
            "Worker 8, [09/18]: Training Loss: 3.557239022, Training Accuracy: 15.568\n",
            "Worker 8, [10/18]: Training Loss: 3.473594055, Training Accuracy: 16.448\n",
            "Worker 8, [11/18]: Training Loss: 3.396795596, Training Accuracy: 17.184\n",
            "Worker 8, [12/18]: Training Loss: 3.306066056, Training Accuracy: 19.632\n",
            "Worker 8, [13/18]: Training Loss: 3.214872020, Training Accuracy: 21.296\n",
            "Worker 8, [14/18]: Training Loss: 3.164851500, Training Accuracy: 21.616\n",
            "Worker 8, [15/18]: Training Loss: 3.125266927, Training Accuracy: 23.136\n",
            "Worker 8, [16/18]: Training Loss: 3.073275481, Training Accuracy: 23.872\n",
            "Worker 8, [17/18]: Training Loss: 3.020465934, Training Accuracy: 24.800\n",
            "Worker 8, [18/18]: Training Loss: 3.017849406, Training Accuracy: 25.424\n",
            "Time taken for training worker 8: 0:00:49.267410\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000847\n",
            "Local Step 01: Test Loss: 3.470624915, Test Accuracy: 18.190\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.536628735, Training Accuracy: 16.512\n",
            "Worker 1, [02/18]: Training Loss: 3.515114410, Training Accuracy: 17.056\n",
            "Worker 1, [03/18]: Training Loss: 3.469158041, Training Accuracy: 17.968\n",
            "Worker 1, [04/18]: Training Loss: 3.423496623, Training Accuracy: 18.512\n",
            "Worker 1, [05/18]: Training Loss: 3.407837958, Training Accuracy: 18.848\n",
            "Worker 1, [06/18]: Training Loss: 3.380446320, Training Accuracy: 19.008\n",
            "Worker 1, [07/18]: Training Loss: 3.354680616, Training Accuracy: 19.632\n",
            "Worker 1, [08/18]: Training Loss: 3.327590344, Training Accuracy: 19.392\n",
            "Worker 1, [09/18]: Training Loss: 3.326755487, Training Accuracy: 19.248\n",
            "Worker 1, [10/18]: Training Loss: 3.284738054, Training Accuracy: 20.320\n",
            "Worker 1, [11/18]: Training Loss: 3.246671954, Training Accuracy: 20.384\n",
            "Worker 1, [12/18]: Training Loss: 3.203370887, Training Accuracy: 20.736\n",
            "Worker 1, [13/18]: Training Loss: 3.176335666, Training Accuracy: 21.504\n",
            "Worker 1, [14/18]: Training Loss: 3.136097640, Training Accuracy: 22.352\n",
            "Worker 1, [15/18]: Training Loss: 3.075274891, Training Accuracy: 23.312\n",
            "Worker 1, [16/18]: Training Loss: 3.022863476, Training Accuracy: 23.760\n",
            "Worker 1, [17/18]: Training Loss: 2.969643493, Training Accuracy: 25.184\n",
            "Worker 1, [18/18]: Training Loss: 2.912062151, Training Accuracy: 26.688\n",
            "Time taken for training worker 1: 0:00:48.644355\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.425982461, Training Accuracy: 19.616\n",
            "Worker 2, [02/18]: Training Loss: 3.291076787, Training Accuracy: 21.184\n",
            "Worker 2, [03/18]: Training Loss: 3.187733782, Training Accuracy: 23.008\n",
            "Worker 2, [04/18]: Training Loss: 3.110845819, Training Accuracy: 24.576\n",
            "Worker 2, [05/18]: Training Loss: 3.071951367, Training Accuracy: 24.256\n",
            "Worker 2, [06/18]: Training Loss: 2.999175828, Training Accuracy: 25.232\n",
            "Worker 2, [07/18]: Training Loss: 2.975347731, Training Accuracy: 26.336\n",
            "Worker 2, [08/18]: Training Loss: 2.911186778, Training Accuracy: 27.296\n",
            "Worker 2, [09/18]: Training Loss: 2.892803418, Training Accuracy: 27.552\n",
            "Worker 2, [10/18]: Training Loss: 2.869344833, Training Accuracy: 27.360\n",
            "Worker 2, [11/18]: Training Loss: 2.834185167, Training Accuracy: 27.664\n",
            "Worker 2, [12/18]: Training Loss: 2.780098368, Training Accuracy: 28.672\n",
            "Worker 2, [13/18]: Training Loss: 2.800934772, Training Accuracy: 28.064\n",
            "Worker 2, [14/18]: Training Loss: 2.728593053, Training Accuracy: 30.352\n",
            "Worker 2, [15/18]: Training Loss: 2.698772421, Training Accuracy: 29.360\n",
            "Worker 2, [16/18]: Training Loss: 2.658015614, Training Accuracy: 30.864\n",
            "Worker 2, [17/18]: Training Loss: 2.568232164, Training Accuracy: 32.320\n",
            "Worker 2, [18/18]: Training Loss: 2.540800518, Training Accuracy: 32.832\n",
            "Time taken for training worker 2: 0:00:50.206605\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.195600244, Training Accuracy: 24.048\n",
            "Worker 3, [02/18]: Training Loss: 3.121997434, Training Accuracy: 24.944\n",
            "Worker 3, [03/18]: Training Loss: 3.008381591, Training Accuracy: 26.624\n",
            "Worker 3, [04/18]: Training Loss: 2.944569259, Training Accuracy: 27.392\n",
            "Worker 3, [05/18]: Training Loss: 2.857132077, Training Accuracy: 29.264\n",
            "Worker 3, [06/18]: Training Loss: 2.782013937, Training Accuracy: 30.864\n",
            "Worker 3, [07/18]: Training Loss: 2.712772528, Training Accuracy: 31.840\n",
            "Worker 3, [08/18]: Training Loss: 2.652247405, Training Accuracy: 31.840\n",
            "Worker 3, [09/18]: Training Loss: 2.607053783, Training Accuracy: 33.312\n",
            "Worker 3, [10/18]: Training Loss: 2.575236535, Training Accuracy: 34.096\n",
            "Worker 3, [11/18]: Training Loss: 2.544021097, Training Accuracy: 33.792\n",
            "Worker 3, [12/18]: Training Loss: 2.500756935, Training Accuracy: 34.224\n",
            "Worker 3, [13/18]: Training Loss: 2.487055229, Training Accuracy: 34.992\n",
            "Worker 3, [14/18]: Training Loss: 2.399717162, Training Accuracy: 36.368\n",
            "Worker 3, [15/18]: Training Loss: 2.389149780, Training Accuracy: 36.688\n",
            "Worker 3, [16/18]: Training Loss: 2.337390434, Training Accuracy: 36.992\n",
            "Worker 3, [17/18]: Training Loss: 2.311184661, Training Accuracy: 38.368\n",
            "Worker 3, [18/18]: Training Loss: 2.237235265, Training Accuracy: 39.488\n",
            "Time taken for training worker 3: 0:00:50.148850\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.166338417, Training Accuracy: 25.584\n",
            "Worker 4, [02/18]: Training Loss: 3.050193641, Training Accuracy: 26.992\n",
            "Worker 4, [03/18]: Training Loss: 2.896352257, Training Accuracy: 29.008\n",
            "Worker 4, [04/18]: Training Loss: 2.767432570, Training Accuracy: 31.808\n",
            "Worker 4, [05/18]: Training Loss: 2.692504834, Training Accuracy: 33.008\n",
            "Worker 4, [06/18]: Training Loss: 2.611590154, Training Accuracy: 34.432\n",
            "Worker 4, [07/18]: Training Loss: 2.545182848, Training Accuracy: 35.440\n",
            "Worker 4, [08/18]: Training Loss: 2.469366456, Training Accuracy: 36.496\n",
            "Worker 4, [09/18]: Training Loss: 2.430592920, Training Accuracy: 37.744\n",
            "Worker 4, [10/18]: Training Loss: 2.385680695, Training Accuracy: 37.984\n",
            "Worker 4, [11/18]: Training Loss: 2.313118503, Training Accuracy: 39.280\n",
            "Worker 4, [12/18]: Training Loss: 2.308142422, Training Accuracy: 38.656\n",
            "Worker 4, [13/18]: Training Loss: 2.256322621, Training Accuracy: 39.424\n",
            "Worker 4, [14/18]: Training Loss: 2.225523398, Training Accuracy: 40.800\n",
            "Worker 4, [15/18]: Training Loss: 2.177166945, Training Accuracy: 41.696\n",
            "Worker 4, [16/18]: Training Loss: 2.185142438, Training Accuracy: 41.008\n",
            "Worker 4, [17/18]: Training Loss: 2.119965955, Training Accuracy: 42.544\n",
            "Worker 4, [18/18]: Training Loss: 2.054710005, Training Accuracy: 44.144\n",
            "Time taken for training worker 4: 0:00:48.580861\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.072987914, Training Accuracy: 28.592\n",
            "Worker 5, [02/18]: Training Loss: 3.006465540, Training Accuracy: 29.440\n",
            "Worker 5, [03/18]: Training Loss: 2.861153661, Training Accuracy: 30.336\n",
            "Worker 5, [04/18]: Training Loss: 2.756034474, Training Accuracy: 31.728\n",
            "Worker 5, [05/18]: Training Loss: 2.665611321, Training Accuracy: 33.792\n",
            "Worker 5, [06/18]: Training Loss: 2.587986343, Training Accuracy: 34.576\n",
            "Worker 5, [07/18]: Training Loss: 2.496766589, Training Accuracy: 36.896\n",
            "Worker 5, [08/18]: Training Loss: 2.393245690, Training Accuracy: 38.416\n",
            "Worker 5, [09/18]: Training Loss: 2.350015470, Training Accuracy: 39.232\n",
            "Worker 5, [10/18]: Training Loss: 2.291505396, Training Accuracy: 39.856\n",
            "Worker 5, [11/18]: Training Loss: 2.245927936, Training Accuracy: 40.560\n",
            "Worker 5, [12/18]: Training Loss: 2.198701207, Training Accuracy: 41.248\n",
            "Worker 5, [13/18]: Training Loss: 2.148781286, Training Accuracy: 42.208\n",
            "Worker 5, [14/18]: Training Loss: 2.103699243, Training Accuracy: 43.824\n",
            "Worker 5, [15/18]: Training Loss: 2.035130989, Training Accuracy: 44.272\n",
            "Worker 5, [16/18]: Training Loss: 1.995618883, Training Accuracy: 45.360\n",
            "Worker 5, [17/18]: Training Loss: 1.966183457, Training Accuracy: 45.760\n",
            "Worker 5, [18/18]: Training Loss: 1.932744400, Training Accuracy: 46.832\n",
            "Time taken for training worker 5: 0:00:49.698170\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.006959847, Training Accuracy: 30.336\n",
            "Worker 6, [02/18]: Training Loss: 2.965993769, Training Accuracy: 30.160\n",
            "Worker 6, [03/18]: Training Loss: 2.800879184, Training Accuracy: 32.192\n",
            "Worker 6, [04/18]: Training Loss: 2.674364282, Training Accuracy: 34.224\n",
            "Worker 6, [05/18]: Training Loss: 2.553650529, Training Accuracy: 35.840\n",
            "Worker 6, [06/18]: Training Loss: 2.470485108, Training Accuracy: 36.928\n",
            "Worker 6, [07/18]: Training Loss: 2.348799044, Training Accuracy: 39.936\n",
            "Worker 6, [08/18]: Training Loss: 2.302579700, Training Accuracy: 40.752\n",
            "Worker 6, [09/18]: Training Loss: 2.210107828, Training Accuracy: 42.976\n",
            "Worker 6, [10/18]: Training Loss: 2.135848470, Training Accuracy: 43.984\n",
            "Worker 6, [11/18]: Training Loss: 2.105923711, Training Accuracy: 43.312\n",
            "Worker 6, [12/18]: Training Loss: 2.078847004, Training Accuracy: 44.240\n",
            "Worker 6, [13/18]: Training Loss: 1.993732261, Training Accuracy: 46.432\n",
            "Worker 6, [14/18]: Training Loss: 1.962692194, Training Accuracy: 46.736\n",
            "Worker 6, [15/18]: Training Loss: 1.879751703, Training Accuracy: 48.240\n",
            "Worker 6, [16/18]: Training Loss: 1.855505396, Training Accuracy: 48.688\n",
            "Worker 6, [17/18]: Training Loss: 1.823964193, Training Accuracy: 49.184\n",
            "Worker 6, [18/18]: Training Loss: 1.746881922, Training Accuracy: 51.168\n",
            "Time taken for training worker 6: 0:00:48.811737\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.040798345, Training Accuracy: 31.024\n",
            "Worker 7, [02/18]: Training Loss: 2.937795800, Training Accuracy: 31.376\n",
            "Worker 7, [03/18]: Training Loss: 2.787986152, Training Accuracy: 32.816\n",
            "Worker 7, [04/18]: Training Loss: 2.645078357, Training Accuracy: 35.472\n",
            "Worker 7, [05/18]: Training Loss: 2.533454506, Training Accuracy: 37.248\n",
            "Worker 7, [06/18]: Training Loss: 2.448331755, Training Accuracy: 38.304\n",
            "Worker 7, [07/18]: Training Loss: 2.371136013, Training Accuracy: 39.136\n",
            "Worker 7, [08/18]: Training Loss: 2.245780753, Training Accuracy: 41.856\n",
            "Worker 7, [09/18]: Training Loss: 2.195359069, Training Accuracy: 42.208\n",
            "Worker 7, [10/18]: Training Loss: 2.118440511, Training Accuracy: 43.936\n",
            "Worker 7, [11/18]: Training Loss: 2.066207010, Training Accuracy: 43.808\n",
            "Worker 7, [12/18]: Training Loss: 2.011212564, Training Accuracy: 46.432\n",
            "Worker 7, [13/18]: Training Loss: 1.946523452, Training Accuracy: 47.072\n",
            "Worker 7, [14/18]: Training Loss: 1.909946106, Training Accuracy: 47.424\n",
            "Worker 7, [15/18]: Training Loss: 1.890997342, Training Accuracy: 48.064\n",
            "Worker 7, [16/18]: Training Loss: 1.836662711, Training Accuracy: 49.008\n",
            "Worker 7, [17/18]: Training Loss: 1.789230341, Training Accuracy: 50.560\n",
            "Worker 7, [18/18]: Training Loss: 1.715876203, Training Accuracy: 52.912\n",
            "Time taken for training worker 7: 0:00:47.382121\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.039882023, Training Accuracy: 29.904\n",
            "Worker 8, [02/18]: Training Loss: 2.894017531, Training Accuracy: 31.856\n",
            "Worker 8, [03/18]: Training Loss: 2.734267281, Training Accuracy: 32.896\n",
            "Worker 8, [04/18]: Training Loss: 2.592780532, Training Accuracy: 34.624\n",
            "Worker 8, [05/18]: Training Loss: 2.470078884, Training Accuracy: 37.696\n",
            "Worker 8, [06/18]: Training Loss: 2.368362013, Training Accuracy: 39.360\n",
            "Worker 8, [07/18]: Training Loss: 2.276644255, Training Accuracy: 40.992\n",
            "Worker 8, [08/18]: Training Loss: 2.194721003, Training Accuracy: 42.976\n",
            "Worker 8, [09/18]: Training Loss: 2.110897697, Training Accuracy: 44.224\n",
            "Worker 8, [10/18]: Training Loss: 2.031275997, Training Accuracy: 45.696\n",
            "Worker 8, [11/18]: Training Loss: 1.984315296, Training Accuracy: 47.456\n",
            "Worker 8, [12/18]: Training Loss: 1.891167361, Training Accuracy: 48.992\n",
            "Worker 8, [13/18]: Training Loss: 1.848683708, Training Accuracy: 49.280\n",
            "Worker 8, [14/18]: Training Loss: 1.821612221, Training Accuracy: 49.440\n",
            "Worker 8, [15/18]: Training Loss: 1.757098254, Training Accuracy: 50.864\n",
            "Worker 8, [16/18]: Training Loss: 1.737615342, Training Accuracy: 51.904\n",
            "Worker 8, [17/18]: Training Loss: 1.703327178, Training Accuracy: 52.624\n",
            "Worker 8, [18/18]: Training Loss: 1.679075559, Training Accuracy: 52.848\n",
            "Time taken for training worker 8: 0:00:49.965780\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000785\n",
            "Local Step 02: Test Loss: 2.840461815, Test Accuracy: 33.670\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.793568816, Training Accuracy: 31.536\n",
            "Worker 1, [02/18]: Training Loss: 2.423860045, Training Accuracy: 38.160\n",
            "Worker 1, [03/18]: Training Loss: 2.243740584, Training Accuracy: 41.488\n",
            "Worker 1, [04/18]: Training Loss: 2.074108259, Training Accuracy: 45.456\n",
            "Worker 1, [05/18]: Training Loss: 1.925922595, Training Accuracy: 47.952\n",
            "Worker 1, [06/18]: Training Loss: 1.802861976, Training Accuracy: 50.864\n",
            "Worker 1, [07/18]: Training Loss: 1.663056105, Training Accuracy: 54.448\n",
            "Worker 1, [08/18]: Training Loss: 1.553064495, Training Accuracy: 56.208\n",
            "Worker 1, [09/18]: Training Loss: 1.381586468, Training Accuracy: 61.376\n",
            "Worker 1, [10/18]: Training Loss: 1.259587529, Training Accuracy: 64.496\n",
            "Worker 1, [11/18]: Training Loss: 1.157385090, Training Accuracy: 67.200\n",
            "Worker 1, [12/18]: Training Loss: 1.038873677, Training Accuracy: 69.792\n",
            "Worker 1, [13/18]: Training Loss: 0.932051328, Training Accuracy: 73.328\n",
            "Worker 1, [14/18]: Training Loss: 0.863278883, Training Accuracy: 76.064\n",
            "Worker 1, [15/18]: Training Loss: 0.797801250, Training Accuracy: 77.744\n",
            "Worker 1, [16/18]: Training Loss: 0.761577303, Training Accuracy: 78.592\n",
            "Worker 1, [17/18]: Training Loss: 0.713583417, Training Accuracy: 80.800\n",
            "Worker 1, [18/18]: Training Loss: 0.706874652, Training Accuracy: 79.984\n",
            "Time taken for training worker 1: 0:00:49.040187\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.874709030, Training Accuracy: 30.880\n",
            "Worker 2, [02/18]: Training Loss: 2.410253415, Training Accuracy: 38.480\n",
            "Worker 2, [03/18]: Training Loss: 2.218167719, Training Accuracy: 41.776\n",
            "Worker 2, [04/18]: Training Loss: 2.051186964, Training Accuracy: 45.264\n",
            "Worker 2, [05/18]: Training Loss: 1.880534701, Training Accuracy: 48.640\n",
            "Worker 2, [06/18]: Training Loss: 1.737639497, Training Accuracy: 52.320\n",
            "Worker 2, [07/18]: Training Loss: 1.617151204, Training Accuracy: 55.136\n",
            "Worker 2, [08/18]: Training Loss: 1.467717101, Training Accuracy: 58.848\n",
            "Worker 2, [09/18]: Training Loss: 1.337646048, Training Accuracy: 62.256\n",
            "Worker 2, [10/18]: Training Loss: 1.207697576, Training Accuracy: 64.944\n",
            "Worker 2, [11/18]: Training Loss: 1.107293395, Training Accuracy: 67.760\n",
            "Worker 2, [12/18]: Training Loss: 1.013487084, Training Accuracy: 70.704\n",
            "Worker 2, [13/18]: Training Loss: 0.920226667, Training Accuracy: 73.680\n",
            "Worker 2, [14/18]: Training Loss: 0.821112594, Training Accuracy: 76.400\n",
            "Worker 2, [15/18]: Training Loss: 0.750919954, Training Accuracy: 79.184\n",
            "Worker 2, [16/18]: Training Loss: 0.702190528, Training Accuracy: 80.640\n",
            "Worker 2, [17/18]: Training Loss: 0.667258082, Training Accuracy: 81.008\n",
            "Worker 2, [18/18]: Training Loss: 0.669329792, Training Accuracy: 81.152\n",
            "Time taken for training worker 2: 0:00:48.141279\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.805054599, Training Accuracy: 31.392\n",
            "Worker 3, [02/18]: Training Loss: 2.374409840, Training Accuracy: 38.800\n",
            "Worker 3, [03/18]: Training Loss: 2.123954408, Training Accuracy: 43.472\n",
            "Worker 3, [04/18]: Training Loss: 1.984866298, Training Accuracy: 45.616\n",
            "Worker 3, [05/18]: Training Loss: 1.777859918, Training Accuracy: 51.200\n",
            "Worker 3, [06/18]: Training Loss: 1.647809150, Training Accuracy: 54.400\n",
            "Worker 3, [07/18]: Training Loss: 1.547378904, Training Accuracy: 56.640\n",
            "Worker 3, [08/18]: Training Loss: 1.390180314, Training Accuracy: 61.392\n",
            "Worker 3, [09/18]: Training Loss: 1.259904846, Training Accuracy: 64.032\n",
            "Worker 3, [10/18]: Training Loss: 1.156730998, Training Accuracy: 66.592\n",
            "Worker 3, [11/18]: Training Loss: 1.053201413, Training Accuracy: 69.568\n",
            "Worker 3, [12/18]: Training Loss: 0.924246706, Training Accuracy: 73.344\n",
            "Worker 3, [13/18]: Training Loss: 0.826087762, Training Accuracy: 76.416\n",
            "Worker 3, [14/18]: Training Loss: 0.749219662, Training Accuracy: 78.368\n",
            "Worker 3, [15/18]: Training Loss: 0.709241403, Training Accuracy: 79.792\n",
            "Worker 3, [16/18]: Training Loss: 0.635739155, Training Accuracy: 82.384\n",
            "Worker 3, [17/18]: Training Loss: 0.616546631, Training Accuracy: 83.040\n",
            "Worker 3, [18/18]: Training Loss: 0.588656668, Training Accuracy: 83.552\n",
            "Time taken for training worker 3: 0:00:49.089115\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.741654754, Training Accuracy: 32.560\n",
            "Worker 4, [02/18]: Training Loss: 2.308325424, Training Accuracy: 40.960\n",
            "Worker 4, [03/18]: Training Loss: 2.061737884, Training Accuracy: 45.152\n",
            "Worker 4, [04/18]: Training Loss: 1.924980384, Training Accuracy: 48.848\n",
            "Worker 4, [05/18]: Training Loss: 1.779649170, Training Accuracy: 51.136\n",
            "Worker 4, [06/18]: Training Loss: 1.598764619, Training Accuracy: 55.424\n",
            "Worker 4, [07/18]: Training Loss: 1.510708991, Training Accuracy: 57.056\n",
            "Worker 4, [08/18]: Training Loss: 1.367134187, Training Accuracy: 61.040\n",
            "Worker 4, [09/18]: Training Loss: 1.250921034, Training Accuracy: 64.048\n",
            "Worker 4, [10/18]: Training Loss: 1.125819125, Training Accuracy: 67.088\n",
            "Worker 4, [11/18]: Training Loss: 1.011169460, Training Accuracy: 70.640\n",
            "Worker 4, [12/18]: Training Loss: 0.914776465, Training Accuracy: 73.552\n",
            "Worker 4, [13/18]: Training Loss: 0.799026712, Training Accuracy: 76.816\n",
            "Worker 4, [14/18]: Training Loss: 0.745051172, Training Accuracy: 78.752\n",
            "Worker 4, [15/18]: Training Loss: 0.674038797, Training Accuracy: 81.376\n",
            "Worker 4, [16/18]: Training Loss: 0.628470719, Training Accuracy: 81.728\n",
            "Worker 4, [17/18]: Training Loss: 0.606249968, Training Accuracy: 82.848\n",
            "Worker 4, [18/18]: Training Loss: 0.593142827, Training Accuracy: 83.392\n",
            "Time taken for training worker 4: 0:00:48.114061\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.787319035, Training Accuracy: 32.176\n",
            "Worker 5, [02/18]: Training Loss: 2.317659547, Training Accuracy: 40.128\n",
            "Worker 5, [03/18]: Training Loss: 2.088827823, Training Accuracy: 44.224\n",
            "Worker 5, [04/18]: Training Loss: 1.940963819, Training Accuracy: 47.824\n",
            "Worker 5, [05/18]: Training Loss: 1.789768775, Training Accuracy: 50.544\n",
            "Worker 5, [06/18]: Training Loss: 1.593994509, Training Accuracy: 56.032\n",
            "Worker 5, [07/18]: Training Loss: 1.465019572, Training Accuracy: 58.944\n",
            "Worker 5, [08/18]: Training Loss: 1.379468136, Training Accuracy: 60.864\n",
            "Worker 5, [09/18]: Training Loss: 1.206235426, Training Accuracy: 65.520\n",
            "Worker 5, [10/18]: Training Loss: 1.090300907, Training Accuracy: 68.944\n",
            "Worker 5, [11/18]: Training Loss: 1.006144485, Training Accuracy: 71.280\n",
            "Worker 5, [12/18]: Training Loss: 0.880582678, Training Accuracy: 74.608\n",
            "Worker 5, [13/18]: Training Loss: 0.786014050, Training Accuracy: 77.248\n",
            "Worker 5, [14/18]: Training Loss: 0.706358906, Training Accuracy: 79.008\n",
            "Worker 5, [15/18]: Training Loss: 0.646026835, Training Accuracy: 81.264\n",
            "Worker 5, [16/18]: Training Loss: 0.599017715, Training Accuracy: 83.264\n",
            "Worker 5, [17/18]: Training Loss: 0.585456676, Training Accuracy: 83.520\n",
            "Worker 5, [18/18]: Training Loss: 0.569529416, Training Accuracy: 84.304\n",
            "Time taken for training worker 5: 0:00:48.148849\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.702343257, Training Accuracy: 33.488\n",
            "Worker 6, [02/18]: Training Loss: 2.193557206, Training Accuracy: 42.704\n",
            "Worker 6, [03/18]: Training Loss: 1.993804270, Training Accuracy: 46.464\n",
            "Worker 6, [04/18]: Training Loss: 1.840102396, Training Accuracy: 50.064\n",
            "Worker 6, [05/18]: Training Loss: 1.680261646, Training Accuracy: 53.184\n",
            "Worker 6, [06/18]: Training Loss: 1.519516339, Training Accuracy: 57.600\n",
            "Worker 6, [07/18]: Training Loss: 1.404402587, Training Accuracy: 59.696\n",
            "Worker 6, [08/18]: Training Loss: 1.270695446, Training Accuracy: 63.120\n",
            "Worker 6, [09/18]: Training Loss: 1.138895593, Training Accuracy: 66.976\n",
            "Worker 6, [10/18]: Training Loss: 1.024396538, Training Accuracy: 69.984\n",
            "Worker 6, [11/18]: Training Loss: 0.871426036, Training Accuracy: 74.848\n",
            "Worker 6, [12/18]: Training Loss: 0.800536879, Training Accuracy: 76.800\n",
            "Worker 6, [13/18]: Training Loss: 0.711566430, Training Accuracy: 79.696\n",
            "Worker 6, [14/18]: Training Loss: 0.647550368, Training Accuracy: 81.104\n",
            "Worker 6, [15/18]: Training Loss: 0.600552355, Training Accuracy: 82.784\n",
            "Worker 6, [16/18]: Training Loss: 0.555329926, Training Accuracy: 84.208\n",
            "Worker 6, [17/18]: Training Loss: 0.524584183, Training Accuracy: 85.968\n",
            "Worker 6, [18/18]: Training Loss: 0.502629200, Training Accuracy: 86.160\n",
            "Time taken for training worker 6: 0:00:48.955459\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.700394546, Training Accuracy: 33.792\n",
            "Worker 7, [02/18]: Training Loss: 2.220355146, Training Accuracy: 42.944\n",
            "Worker 7, [03/18]: Training Loss: 2.011834338, Training Accuracy: 46.128\n",
            "Worker 7, [04/18]: Training Loss: 1.851644342, Training Accuracy: 50.560\n",
            "Worker 7, [05/18]: Training Loss: 1.698928003, Training Accuracy: 53.712\n",
            "Worker 7, [06/18]: Training Loss: 1.546533893, Training Accuracy: 55.872\n",
            "Worker 7, [07/18]: Training Loss: 1.414077852, Training Accuracy: 60.400\n",
            "Worker 7, [08/18]: Training Loss: 1.257023172, Training Accuracy: 64.336\n",
            "Worker 7, [09/18]: Training Loss: 1.120791601, Training Accuracy: 68.384\n",
            "Worker 7, [10/18]: Training Loss: 0.999984674, Training Accuracy: 71.376\n",
            "Worker 7, [11/18]: Training Loss: 0.900285476, Training Accuracy: 73.792\n",
            "Worker 7, [12/18]: Training Loss: 0.776258176, Training Accuracy: 77.680\n",
            "Worker 7, [13/18]: Training Loss: 0.708248890, Training Accuracy: 79.408\n",
            "Worker 7, [14/18]: Training Loss: 0.625609414, Training Accuracy: 82.064\n",
            "Worker 7, [15/18]: Training Loss: 0.587989259, Training Accuracy: 83.232\n",
            "Worker 7, [16/18]: Training Loss: 0.524032059, Training Accuracy: 85.904\n",
            "Worker 7, [17/18]: Training Loss: 0.508311506, Training Accuracy: 86.144\n",
            "Worker 7, [18/18]: Training Loss: 0.486464642, Training Accuracy: 86.864\n",
            "Time taken for training worker 7: 0:00:47.637723\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.668292951, Training Accuracy: 34.720\n",
            "Worker 8, [02/18]: Training Loss: 2.205837021, Training Accuracy: 42.560\n",
            "Worker 8, [03/18]: Training Loss: 1.967896555, Training Accuracy: 46.576\n",
            "Worker 8, [04/18]: Training Loss: 1.803414708, Training Accuracy: 50.592\n",
            "Worker 8, [05/18]: Training Loss: 1.657640100, Training Accuracy: 54.016\n",
            "Worker 8, [06/18]: Training Loss: 1.539438155, Training Accuracy: 57.360\n",
            "Worker 8, [07/18]: Training Loss: 1.379347078, Training Accuracy: 60.256\n",
            "Worker 8, [08/18]: Training Loss: 1.237112143, Training Accuracy: 64.064\n",
            "Worker 8, [09/18]: Training Loss: 1.085343262, Training Accuracy: 68.672\n",
            "Worker 8, [10/18]: Training Loss: 0.980888925, Training Accuracy: 71.472\n",
            "Worker 8, [11/18]: Training Loss: 0.875404881, Training Accuracy: 74.832\n",
            "Worker 8, [12/18]: Training Loss: 0.764427963, Training Accuracy: 77.664\n",
            "Worker 8, [13/18]: Training Loss: 0.709092595, Training Accuracy: 79.472\n",
            "Worker 8, [14/18]: Training Loss: 0.599910822, Training Accuracy: 82.592\n",
            "Worker 8, [15/18]: Training Loss: 0.576463335, Training Accuracy: 83.552\n",
            "Worker 8, [16/18]: Training Loss: 0.544261196, Training Accuracy: 84.240\n",
            "Worker 8, [17/18]: Training Loss: 0.498210618, Training Accuracy: 85.264\n",
            "Worker 8, [18/18]: Training Loss: 0.486993024, Training Accuracy: 86.656\n",
            "Time taken for training worker 8: 0:00:49.285458\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001040\n",
            "Local Step 03: Test Loss: 2.793572710, Test Accuracy: 43.560\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.880632377, Training Accuracy: 41.632\n",
            "Worker 1, [02/18]: Training Loss: 2.783099174, Training Accuracy: 41.296\n",
            "Worker 1, [03/18]: Training Loss: 2.539008739, Training Accuracy: 41.664\n",
            "Worker 1, [04/18]: Training Loss: 2.309360889, Training Accuracy: 42.816\n",
            "Worker 1, [05/18]: Training Loss: 2.166757623, Training Accuracy: 44.656\n",
            "Worker 1, [06/18]: Training Loss: 2.022771755, Training Accuracy: 47.312\n",
            "Worker 1, [07/18]: Training Loss: 1.909301994, Training Accuracy: 49.984\n",
            "Worker 1, [08/18]: Training Loss: 1.789002606, Training Accuracy: 51.392\n",
            "Worker 1, [09/18]: Training Loss: 1.717224816, Training Accuracy: 52.896\n",
            "Worker 1, [10/18]: Training Loss: 1.592313459, Training Accuracy: 55.504\n",
            "Worker 1, [11/18]: Training Loss: 1.568682127, Training Accuracy: 56.224\n",
            "Worker 1, [12/18]: Training Loss: 1.521444336, Training Accuracy: 57.360\n",
            "Worker 1, [13/18]: Training Loss: 1.485138169, Training Accuracy: 57.408\n",
            "Worker 1, [14/18]: Training Loss: 1.409810767, Training Accuracy: 59.824\n",
            "Worker 1, [15/18]: Training Loss: 1.448295509, Training Accuracy: 59.104\n",
            "Worker 1, [16/18]: Training Loss: 1.320667537, Training Accuracy: 62.400\n",
            "Worker 1, [17/18]: Training Loss: 1.332527967, Training Accuracy: 61.776\n",
            "Worker 1, [18/18]: Training Loss: 1.266699910, Training Accuracy: 63.776\n",
            "Time taken for training worker 1: 0:00:49.007911\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.756628095, Training Accuracy: 36.656\n",
            "Worker 2, [02/18]: Training Loss: 2.664906265, Training Accuracy: 37.280\n",
            "Worker 2, [03/18]: Training Loss: 2.472763263, Training Accuracy: 39.408\n",
            "Worker 2, [04/18]: Training Loss: 2.306173722, Training Accuracy: 41.472\n",
            "Worker 2, [05/18]: Training Loss: 2.188168596, Training Accuracy: 42.432\n",
            "Worker 2, [06/18]: Training Loss: 2.056621905, Training Accuracy: 46.464\n",
            "Worker 2, [07/18]: Training Loss: 1.938923656, Training Accuracy: 48.224\n",
            "Worker 2, [08/18]: Training Loss: 1.836918741, Training Accuracy: 49.808\n",
            "Worker 2, [09/18]: Training Loss: 1.753116698, Training Accuracy: 52.400\n",
            "Worker 2, [10/18]: Training Loss: 1.636142275, Training Accuracy: 54.528\n",
            "Worker 2, [11/18]: Training Loss: 1.560102638, Training Accuracy: 56.432\n",
            "Worker 2, [12/18]: Training Loss: 1.522296081, Training Accuracy: 57.712\n",
            "Worker 2, [13/18]: Training Loss: 1.461170368, Training Accuracy: 58.640\n",
            "Worker 2, [14/18]: Training Loss: 1.437409273, Training Accuracy: 59.392\n",
            "Worker 2, [15/18]: Training Loss: 1.384281152, Training Accuracy: 60.352\n",
            "Worker 2, [16/18]: Training Loss: 1.348636819, Training Accuracy: 61.488\n",
            "Worker 2, [17/18]: Training Loss: 1.285516618, Training Accuracy: 63.104\n",
            "Worker 2, [18/18]: Training Loss: 1.289917566, Training Accuracy: 63.568\n",
            "Time taken for training worker 2: 0:00:48.735631\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.928068334, Training Accuracy: 35.216\n",
            "Worker 3, [02/18]: Training Loss: 2.732648735, Training Accuracy: 37.360\n",
            "Worker 3, [03/18]: Training Loss: 2.482753552, Training Accuracy: 39.840\n",
            "Worker 3, [04/18]: Training Loss: 2.317867000, Training Accuracy: 41.808\n",
            "Worker 3, [05/18]: Training Loss: 2.172273377, Training Accuracy: 43.440\n",
            "Worker 3, [06/18]: Training Loss: 2.061403596, Training Accuracy: 45.728\n",
            "Worker 3, [07/18]: Training Loss: 1.907091185, Training Accuracy: 48.144\n",
            "Worker 3, [08/18]: Training Loss: 1.808813802, Training Accuracy: 50.496\n",
            "Worker 3, [09/18]: Training Loss: 1.693570698, Training Accuracy: 53.888\n",
            "Worker 3, [10/18]: Training Loss: 1.610161840, Training Accuracy: 55.584\n",
            "Worker 3, [11/18]: Training Loss: 1.550280715, Training Accuracy: 56.528\n",
            "Worker 3, [12/18]: Training Loss: 1.484004321, Training Accuracy: 58.256\n",
            "Worker 3, [13/18]: Training Loss: 1.427966405, Training Accuracy: 59.712\n",
            "Worker 3, [14/18]: Training Loss: 1.371813139, Training Accuracy: 60.256\n",
            "Worker 3, [15/18]: Training Loss: 1.307044491, Training Accuracy: 62.112\n",
            "Worker 3, [16/18]: Training Loss: 1.303483849, Training Accuracy: 62.384\n",
            "Worker 3, [17/18]: Training Loss: 1.288266133, Training Accuracy: 62.752\n",
            "Worker 3, [18/18]: Training Loss: 1.233804755, Training Accuracy: 64.080\n",
            "Time taken for training worker 3: 0:00:48.256480\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.731635011, Training Accuracy: 39.264\n",
            "Worker 4, [02/18]: Training Loss: 2.661216336, Training Accuracy: 38.976\n",
            "Worker 4, [03/18]: Training Loss: 2.444380961, Training Accuracy: 40.944\n",
            "Worker 4, [04/18]: Training Loss: 2.296644674, Training Accuracy: 42.688\n",
            "Worker 4, [05/18]: Training Loss: 2.150167476, Training Accuracy: 45.056\n",
            "Worker 4, [06/18]: Training Loss: 2.036818210, Training Accuracy: 46.912\n",
            "Worker 4, [07/18]: Training Loss: 1.930297954, Training Accuracy: 48.288\n",
            "Worker 4, [08/18]: Training Loss: 1.818536205, Training Accuracy: 51.152\n",
            "Worker 4, [09/18]: Training Loss: 1.733993766, Training Accuracy: 52.528\n",
            "Worker 4, [10/18]: Training Loss: 1.598417005, Training Accuracy: 56.000\n",
            "Worker 4, [11/18]: Training Loss: 1.533811984, Training Accuracy: 57.424\n",
            "Worker 4, [12/18]: Training Loss: 1.497736128, Training Accuracy: 58.080\n",
            "Worker 4, [13/18]: Training Loss: 1.418492416, Training Accuracy: 59.920\n",
            "Worker 4, [14/18]: Training Loss: 1.376323609, Training Accuracy: 60.592\n",
            "Worker 4, [15/18]: Training Loss: 1.341732756, Training Accuracy: 61.408\n",
            "Worker 4, [16/18]: Training Loss: 1.324639000, Training Accuracy: 61.344\n",
            "Worker 4, [17/18]: Training Loss: 1.304586554, Training Accuracy: 62.608\n",
            "Worker 4, [18/18]: Training Loss: 1.175369864, Training Accuracy: 65.408\n",
            "Time taken for training worker 4: 0:00:49.318962\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.792167501, Training Accuracy: 36.432\n",
            "Worker 5, [02/18]: Training Loss: 2.688716687, Training Accuracy: 37.136\n",
            "Worker 5, [03/18]: Training Loss: 2.526951683, Training Accuracy: 38.992\n",
            "Worker 5, [04/18]: Training Loss: 2.327567025, Training Accuracy: 41.664\n",
            "Worker 5, [05/18]: Training Loss: 2.213263918, Training Accuracy: 43.376\n",
            "Worker 5, [06/18]: Training Loss: 2.068594383, Training Accuracy: 45.712\n",
            "Worker 5, [07/18]: Training Loss: 1.948120474, Training Accuracy: 47.904\n",
            "Worker 5, [08/18]: Training Loss: 1.838109108, Training Accuracy: 50.400\n",
            "Worker 5, [09/18]: Training Loss: 1.739953438, Training Accuracy: 52.480\n",
            "Worker 5, [10/18]: Training Loss: 1.649168038, Training Accuracy: 55.024\n",
            "Worker 5, [11/18]: Training Loss: 1.550928021, Training Accuracy: 56.720\n",
            "Worker 5, [12/18]: Training Loss: 1.503707520, Training Accuracy: 57.792\n",
            "Worker 5, [13/18]: Training Loss: 1.424365916, Training Accuracy: 59.520\n",
            "Worker 5, [14/18]: Training Loss: 1.387382190, Training Accuracy: 60.128\n",
            "Worker 5, [15/18]: Training Loss: 1.352100757, Training Accuracy: 61.408\n",
            "Worker 5, [16/18]: Training Loss: 1.305208148, Training Accuracy: 61.920\n",
            "Worker 5, [17/18]: Training Loss: 1.323676989, Training Accuracy: 61.888\n",
            "Worker 5, [18/18]: Training Loss: 1.205519059, Training Accuracy: 64.800\n",
            "Time taken for training worker 5: 0:00:49.219640\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.847857191, Training Accuracy: 36.800\n",
            "Worker 6, [02/18]: Training Loss: 2.658622070, Training Accuracy: 38.112\n",
            "Worker 6, [03/18]: Training Loss: 2.434038929, Training Accuracy: 40.112\n",
            "Worker 6, [04/18]: Training Loss: 2.254831444, Training Accuracy: 43.104\n",
            "Worker 6, [05/18]: Training Loss: 2.119249450, Training Accuracy: 44.832\n",
            "Worker 6, [06/18]: Training Loss: 1.992126535, Training Accuracy: 47.872\n",
            "Worker 6, [07/18]: Training Loss: 1.876222132, Training Accuracy: 50.464\n",
            "Worker 6, [08/18]: Training Loss: 1.751958736, Training Accuracy: 52.768\n",
            "Worker 6, [09/18]: Training Loss: 1.666605351, Training Accuracy: 54.080\n",
            "Worker 6, [10/18]: Training Loss: 1.580544104, Training Accuracy: 56.064\n",
            "Worker 6, [11/18]: Training Loss: 1.480388595, Training Accuracy: 58.816\n",
            "Worker 6, [12/18]: Training Loss: 1.454913293, Training Accuracy: 58.384\n",
            "Worker 6, [13/18]: Training Loss: 1.371017584, Training Accuracy: 61.296\n",
            "Worker 6, [14/18]: Training Loss: 1.307299030, Training Accuracy: 62.800\n",
            "Worker 6, [15/18]: Training Loss: 1.313098544, Training Accuracy: 62.752\n",
            "Worker 6, [16/18]: Training Loss: 1.283487297, Training Accuracy: 63.536\n",
            "Worker 6, [17/18]: Training Loss: 1.214897700, Training Accuracy: 65.440\n",
            "Worker 6, [18/18]: Training Loss: 1.151573120, Training Accuracy: 66.144\n",
            "Time taken for training worker 6: 0:00:48.443591\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.806117486, Training Accuracy: 39.136\n",
            "Worker 7, [02/18]: Training Loss: 2.701581821, Training Accuracy: 39.440\n",
            "Worker 7, [03/18]: Training Loss: 2.439202993, Training Accuracy: 41.344\n",
            "Worker 7, [04/18]: Training Loss: 2.268607281, Training Accuracy: 43.184\n",
            "Worker 7, [05/18]: Training Loss: 2.132800072, Training Accuracy: 45.072\n",
            "Worker 7, [06/18]: Training Loss: 1.988739960, Training Accuracy: 47.776\n",
            "Worker 7, [07/18]: Training Loss: 1.853303789, Training Accuracy: 50.176\n",
            "Worker 7, [08/18]: Training Loss: 1.762063731, Training Accuracy: 52.144\n",
            "Worker 7, [09/18]: Training Loss: 1.651177095, Training Accuracy: 54.592\n",
            "Worker 7, [10/18]: Training Loss: 1.555744888, Training Accuracy: 57.232\n",
            "Worker 7, [11/18]: Training Loss: 1.496872455, Training Accuracy: 58.496\n",
            "Worker 7, [12/18]: Training Loss: 1.404792609, Training Accuracy: 61.152\n",
            "Worker 7, [13/18]: Training Loss: 1.391586737, Training Accuracy: 59.792\n",
            "Worker 7, [14/18]: Training Loss: 1.307962519, Training Accuracy: 62.288\n",
            "Worker 7, [15/18]: Training Loss: 1.274848894, Training Accuracy: 63.920\n",
            "Worker 7, [16/18]: Training Loss: 1.272170895, Training Accuracy: 63.120\n",
            "Worker 7, [17/18]: Training Loss: 1.209000060, Training Accuracy: 64.928\n",
            "Worker 7, [18/18]: Training Loss: 1.144014083, Training Accuracy: 66.912\n",
            "Time taken for training worker 7: 0:00:49.543546\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.715446633, Training Accuracy: 37.120\n",
            "Worker 8, [02/18]: Training Loss: 2.611794638, Training Accuracy: 38.288\n",
            "Worker 8, [03/18]: Training Loss: 2.406202678, Training Accuracy: 40.832\n",
            "Worker 8, [04/18]: Training Loss: 2.241961107, Training Accuracy: 42.704\n",
            "Worker 8, [05/18]: Training Loss: 2.103920467, Training Accuracy: 45.456\n",
            "Worker 8, [06/18]: Training Loss: 1.937578730, Training Accuracy: 49.184\n",
            "Worker 8, [07/18]: Training Loss: 1.853493322, Training Accuracy: 50.032\n",
            "Worker 8, [08/18]: Training Loss: 1.701711095, Training Accuracy: 53.392\n",
            "Worker 8, [09/18]: Training Loss: 1.614985702, Training Accuracy: 55.744\n",
            "Worker 8, [10/18]: Training Loss: 1.551613830, Training Accuracy: 56.960\n",
            "Worker 8, [11/18]: Training Loss: 1.467200794, Training Accuracy: 58.896\n",
            "Worker 8, [12/18]: Training Loss: 1.405533525, Training Accuracy: 59.248\n",
            "Worker 8, [13/18]: Training Loss: 1.350215025, Training Accuracy: 61.904\n",
            "Worker 8, [14/18]: Training Loss: 1.275959761, Training Accuracy: 63.456\n",
            "Worker 8, [15/18]: Training Loss: 1.227609298, Training Accuracy: 64.400\n",
            "Worker 8, [16/18]: Training Loss: 1.258618542, Training Accuracy: 63.664\n",
            "Worker 8, [17/18]: Training Loss: 1.184632123, Training Accuracy: 65.904\n",
            "Worker 8, [18/18]: Training Loss: 1.120208267, Training Accuracy: 67.824\n",
            "Time taken for training worker 8: 0:00:48.198636\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000761\n",
            "Local Step 04: Test Loss: 2.743815947, Test Accuracy: 40.280\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.554817385, Training Accuracy: 37.184\n",
            "Worker 1, [02/18]: Training Loss: 2.071012021, Training Accuracy: 45.408\n",
            "Worker 1, [03/18]: Training Loss: 1.792421679, Training Accuracy: 52.112\n",
            "Worker 1, [04/18]: Training Loss: 1.644910017, Training Accuracy: 55.024\n",
            "Worker 1, [05/18]: Training Loss: 1.483939542, Training Accuracy: 59.104\n",
            "Worker 1, [06/18]: Training Loss: 1.321102127, Training Accuracy: 62.240\n",
            "Worker 1, [07/18]: Training Loss: 1.186479885, Training Accuracy: 66.192\n",
            "Worker 1, [08/18]: Training Loss: 1.072728259, Training Accuracy: 69.632\n",
            "Worker 1, [09/18]: Training Loss: 0.921116592, Training Accuracy: 72.912\n",
            "Worker 1, [10/18]: Training Loss: 0.803393252, Training Accuracy: 76.320\n",
            "Worker 1, [11/18]: Training Loss: 0.709854291, Training Accuracy: 79.040\n",
            "Worker 1, [12/18]: Training Loss: 0.622860377, Training Accuracy: 81.968\n",
            "Worker 1, [13/18]: Training Loss: 0.541048951, Training Accuracy: 84.656\n",
            "Worker 1, [14/18]: Training Loss: 0.486448257, Training Accuracy: 86.272\n",
            "Worker 1, [15/18]: Training Loss: 0.432821740, Training Accuracy: 87.744\n",
            "Worker 1, [16/18]: Training Loss: 0.410444436, Training Accuracy: 88.784\n",
            "Worker 1, [17/18]: Training Loss: 0.399670399, Training Accuracy: 89.088\n",
            "Worker 1, [18/18]: Training Loss: 0.395991038, Training Accuracy: 88.960\n",
            "Time taken for training worker 1: 0:00:48.127877\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.551958101, Training Accuracy: 38.032\n",
            "Worker 2, [02/18]: Training Loss: 2.044395202, Training Accuracy: 45.424\n",
            "Worker 2, [03/18]: Training Loss: 1.812693584, Training Accuracy: 50.912\n",
            "Worker 2, [04/18]: Training Loss: 1.651866120, Training Accuracy: 54.576\n",
            "Worker 2, [05/18]: Training Loss: 1.452955426, Training Accuracy: 58.928\n",
            "Worker 2, [06/18]: Training Loss: 1.285419544, Training Accuracy: 63.056\n",
            "Worker 2, [07/18]: Training Loss: 1.204154279, Training Accuracy: 65.584\n",
            "Worker 2, [08/18]: Training Loss: 1.067306657, Training Accuracy: 69.312\n",
            "Worker 2, [09/18]: Training Loss: 0.902227878, Training Accuracy: 74.112\n",
            "Worker 2, [10/18]: Training Loss: 0.820597347, Training Accuracy: 76.368\n",
            "Worker 2, [11/18]: Training Loss: 0.710080592, Training Accuracy: 79.168\n",
            "Worker 2, [12/18]: Training Loss: 0.636881991, Training Accuracy: 81.856\n",
            "Worker 2, [13/18]: Training Loss: 0.556345713, Training Accuracy: 84.000\n",
            "Worker 2, [14/18]: Training Loss: 0.485695126, Training Accuracy: 86.608\n",
            "Worker 2, [15/18]: Training Loss: 0.430694638, Training Accuracy: 88.320\n",
            "Worker 2, [16/18]: Training Loss: 0.408278201, Training Accuracy: 88.592\n",
            "Worker 2, [17/18]: Training Loss: 0.397593230, Training Accuracy: 89.104\n",
            "Worker 2, [18/18]: Training Loss: 0.382195718, Training Accuracy: 89.184\n",
            "Time taken for training worker 2: 0:00:48.172561\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.561089685, Training Accuracy: 36.944\n",
            "Worker 3, [02/18]: Training Loss: 1.999522579, Training Accuracy: 47.136\n",
            "Worker 3, [03/18]: Training Loss: 1.761739272, Training Accuracy: 52.032\n",
            "Worker 3, [04/18]: Training Loss: 1.564422030, Training Accuracy: 55.968\n",
            "Worker 3, [05/18]: Training Loss: 1.417593938, Training Accuracy: 60.192\n",
            "Worker 3, [06/18]: Training Loss: 1.289901112, Training Accuracy: 62.880\n",
            "Worker 3, [07/18]: Training Loss: 1.136667699, Training Accuracy: 66.880\n",
            "Worker 3, [08/18]: Training Loss: 1.002390789, Training Accuracy: 70.560\n",
            "Worker 3, [09/18]: Training Loss: 0.886892514, Training Accuracy: 73.776\n",
            "Worker 3, [10/18]: Training Loss: 0.770777755, Training Accuracy: 77.072\n",
            "Worker 3, [11/18]: Training Loss: 0.667676514, Training Accuracy: 80.848\n",
            "Worker 3, [12/18]: Training Loss: 0.584703150, Training Accuracy: 83.264\n",
            "Worker 3, [13/18]: Training Loss: 0.523985310, Training Accuracy: 84.912\n",
            "Worker 3, [14/18]: Training Loss: 0.440952480, Training Accuracy: 86.976\n",
            "Worker 3, [15/18]: Training Loss: 0.407225220, Training Accuracy: 88.448\n",
            "Worker 3, [16/18]: Training Loss: 0.391268379, Training Accuracy: 89.408\n",
            "Worker 3, [17/18]: Training Loss: 0.357178135, Training Accuracy: 90.496\n",
            "Worker 3, [18/18]: Training Loss: 0.346392095, Training Accuracy: 90.784\n",
            "Time taken for training worker 3: 0:00:49.563233\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.556777481, Training Accuracy: 37.072\n",
            "Worker 4, [02/18]: Training Loss: 2.014958750, Training Accuracy: 45.808\n",
            "Worker 4, [03/18]: Training Loss: 1.796664491, Training Accuracy: 51.056\n",
            "Worker 4, [04/18]: Training Loss: 1.580416800, Training Accuracy: 56.480\n",
            "Worker 4, [05/18]: Training Loss: 1.454157812, Training Accuracy: 58.448\n",
            "Worker 4, [06/18]: Training Loss: 1.277684757, Training Accuracy: 64.432\n",
            "Worker 4, [07/18]: Training Loss: 1.183376953, Training Accuracy: 65.904\n",
            "Worker 4, [08/18]: Training Loss: 1.012631202, Training Accuracy: 70.528\n",
            "Worker 4, [09/18]: Training Loss: 0.892913341, Training Accuracy: 73.648\n",
            "Worker 4, [10/18]: Training Loss: 0.805438433, Training Accuracy: 76.416\n",
            "Worker 4, [11/18]: Training Loss: 0.657826359, Training Accuracy: 80.512\n",
            "Worker 4, [12/18]: Training Loss: 0.571676774, Training Accuracy: 83.536\n",
            "Worker 4, [13/18]: Training Loss: 0.553477715, Training Accuracy: 83.712\n",
            "Worker 4, [14/18]: Training Loss: 0.455073594, Training Accuracy: 86.848\n",
            "Worker 4, [15/18]: Training Loss: 0.414176250, Training Accuracy: 88.144\n",
            "Worker 4, [16/18]: Training Loss: 0.385404090, Training Accuracy: 89.600\n",
            "Worker 4, [17/18]: Training Loss: 0.374773272, Training Accuracy: 89.680\n",
            "Worker 4, [18/18]: Training Loss: 0.356233423, Training Accuracy: 90.800\n",
            "Time taken for training worker 4: 0:00:48.331452\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.613839935, Training Accuracy: 35.616\n",
            "Worker 5, [02/18]: Training Loss: 2.062015137, Training Accuracy: 45.888\n",
            "Worker 5, [03/18]: Training Loss: 1.819010863, Training Accuracy: 50.416\n",
            "Worker 5, [04/18]: Training Loss: 1.632282086, Training Accuracy: 54.784\n",
            "Worker 5, [05/18]: Training Loss: 1.491080481, Training Accuracy: 58.096\n",
            "Worker 5, [06/18]: Training Loss: 1.305472374, Training Accuracy: 63.200\n",
            "Worker 5, [07/18]: Training Loss: 1.148975593, Training Accuracy: 66.816\n",
            "Worker 5, [08/18]: Training Loss: 1.035108474, Training Accuracy: 69.904\n",
            "Worker 5, [09/18]: Training Loss: 0.901087658, Training Accuracy: 73.488\n",
            "Worker 5, [10/18]: Training Loss: 0.784302254, Training Accuracy: 76.896\n",
            "Worker 5, [11/18]: Training Loss: 0.674190460, Training Accuracy: 80.384\n",
            "Worker 5, [12/18]: Training Loss: 0.611148908, Training Accuracy: 82.160\n",
            "Worker 5, [13/18]: Training Loss: 0.515850585, Training Accuracy: 85.504\n",
            "Worker 5, [14/18]: Training Loss: 0.464308408, Training Accuracy: 87.088\n",
            "Worker 5, [15/18]: Training Loss: 0.439457450, Training Accuracy: 87.792\n",
            "Worker 5, [16/18]: Training Loss: 0.390013603, Training Accuracy: 89.248\n",
            "Worker 5, [17/18]: Training Loss: 0.375735700, Training Accuracy: 89.984\n",
            "Worker 5, [18/18]: Training Loss: 0.367960933, Training Accuracy: 89.568\n",
            "Time taken for training worker 5: 0:00:46.834025\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.469459793, Training Accuracy: 38.352\n",
            "Worker 6, [02/18]: Training Loss: 1.953424508, Training Accuracy: 47.856\n",
            "Worker 6, [03/18]: Training Loss: 1.725431248, Training Accuracy: 52.288\n",
            "Worker 6, [04/18]: Training Loss: 1.557952836, Training Accuracy: 56.800\n",
            "Worker 6, [05/18]: Training Loss: 1.374246465, Training Accuracy: 61.152\n",
            "Worker 6, [06/18]: Training Loss: 1.214085171, Training Accuracy: 65.824\n",
            "Worker 6, [07/18]: Training Loss: 1.121773790, Training Accuracy: 67.424\n",
            "Worker 6, [08/18]: Training Loss: 0.979943676, Training Accuracy: 71.184\n",
            "Worker 6, [09/18]: Training Loss: 0.840578292, Training Accuracy: 74.864\n",
            "Worker 6, [10/18]: Training Loss: 0.733237245, Training Accuracy: 78.336\n",
            "Worker 6, [11/18]: Training Loss: 0.638388238, Training Accuracy: 81.072\n",
            "Worker 6, [12/18]: Training Loss: 0.564325116, Training Accuracy: 83.696\n",
            "Worker 6, [13/18]: Training Loss: 0.483530153, Training Accuracy: 85.312\n",
            "Worker 6, [14/18]: Training Loss: 0.424331907, Training Accuracy: 87.584\n",
            "Worker 6, [15/18]: Training Loss: 0.392259327, Training Accuracy: 88.688\n",
            "Worker 6, [16/18]: Training Loss: 0.365034177, Training Accuracy: 89.968\n",
            "Worker 6, [17/18]: Training Loss: 0.353425041, Training Accuracy: 90.288\n",
            "Worker 6, [18/18]: Training Loss: 0.330527131, Training Accuracy: 90.848\n",
            "Time taken for training worker 6: 0:00:49.028821\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.538463409, Training Accuracy: 37.328\n",
            "Worker 7, [02/18]: Training Loss: 1.963104366, Training Accuracy: 49.040\n",
            "Worker 7, [03/18]: Training Loss: 1.762397550, Training Accuracy: 51.776\n",
            "Worker 7, [04/18]: Training Loss: 1.574518561, Training Accuracy: 56.784\n",
            "Worker 7, [05/18]: Training Loss: 1.433012288, Training Accuracy: 59.456\n",
            "Worker 7, [06/18]: Training Loss: 1.279388942, Training Accuracy: 64.064\n",
            "Worker 7, [07/18]: Training Loss: 1.116535118, Training Accuracy: 67.344\n",
            "Worker 7, [08/18]: Training Loss: 0.997483156, Training Accuracy: 70.864\n",
            "Worker 7, [09/18]: Training Loss: 0.882890004, Training Accuracy: 74.336\n",
            "Worker 7, [10/18]: Training Loss: 0.791211467, Training Accuracy: 77.248\n",
            "Worker 7, [11/18]: Training Loss: 0.658177363, Training Accuracy: 81.008\n",
            "Worker 7, [12/18]: Training Loss: 0.576703139, Training Accuracy: 83.248\n",
            "Worker 7, [13/18]: Training Loss: 0.501382267, Training Accuracy: 85.856\n",
            "Worker 7, [14/18]: Training Loss: 0.444911696, Training Accuracy: 87.440\n",
            "Worker 7, [15/18]: Training Loss: 0.397646283, Training Accuracy: 88.848\n",
            "Worker 7, [16/18]: Training Loss: 0.378925580, Training Accuracy: 89.648\n",
            "Worker 7, [17/18]: Training Loss: 0.360251516, Training Accuracy: 90.448\n",
            "Worker 7, [18/18]: Training Loss: 0.342146688, Training Accuracy: 90.848\n",
            "Time taken for training worker 7: 0:00:46.954037\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.514211597, Training Accuracy: 37.648\n",
            "Worker 8, [02/18]: Training Loss: 1.979696510, Training Accuracy: 47.696\n",
            "Worker 8, [03/18]: Training Loss: 1.742599274, Training Accuracy: 52.752\n",
            "Worker 8, [04/18]: Training Loss: 1.564227619, Training Accuracy: 55.744\n",
            "Worker 8, [05/18]: Training Loss: 1.405501686, Training Accuracy: 59.696\n",
            "Worker 8, [06/18]: Training Loss: 1.287202156, Training Accuracy: 63.200\n",
            "Worker 8, [07/18]: Training Loss: 1.108452382, Training Accuracy: 67.504\n",
            "Worker 8, [08/18]: Training Loss: 0.973329174, Training Accuracy: 71.568\n",
            "Worker 8, [09/18]: Training Loss: 0.845320030, Training Accuracy: 75.344\n",
            "Worker 8, [10/18]: Training Loss: 0.744504508, Training Accuracy: 78.720\n",
            "Worker 8, [11/18]: Training Loss: 0.644012526, Training Accuracy: 81.216\n",
            "Worker 8, [12/18]: Training Loss: 0.546986600, Training Accuracy: 83.680\n",
            "Worker 8, [13/18]: Training Loss: 0.469992967, Training Accuracy: 86.448\n",
            "Worker 8, [14/18]: Training Loss: 0.416700852, Training Accuracy: 88.256\n",
            "Worker 8, [15/18]: Training Loss: 0.394641029, Training Accuracy: 88.944\n",
            "Worker 8, [16/18]: Training Loss: 0.365160614, Training Accuracy: 90.016\n",
            "Worker 8, [17/18]: Training Loss: 0.330106697, Training Accuracy: 90.912\n",
            "Worker 8, [18/18]: Training Loss: 0.347504352, Training Accuracy: 90.576\n",
            "Time taken for training worker 8: 0:00:48.613914\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000773\n",
            "Local Step 05: Test Loss: 2.759658198, Test Accuracy: 45.890\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.707740298, Training Accuracy: 44.736\n",
            "Worker 1, [02/18]: Training Loss: 2.583235449, Training Accuracy: 44.144\n",
            "Worker 1, [03/18]: Training Loss: 2.373994883, Training Accuracy: 44.864\n",
            "Worker 1, [04/18]: Training Loss: 2.136695615, Training Accuracy: 46.512\n",
            "Worker 1, [05/18]: Training Loss: 1.950811643, Training Accuracy: 49.008\n",
            "Worker 1, [06/18]: Training Loss: 1.809646923, Training Accuracy: 51.984\n",
            "Worker 1, [07/18]: Training Loss: 1.694899659, Training Accuracy: 54.176\n",
            "Worker 1, [08/18]: Training Loss: 1.590400302, Training Accuracy: 55.952\n",
            "Worker 1, [09/18]: Training Loss: 1.497874715, Training Accuracy: 58.224\n",
            "Worker 1, [10/18]: Training Loss: 1.395042315, Training Accuracy: 60.816\n",
            "Worker 1, [11/18]: Training Loss: 1.339466027, Training Accuracy: 62.176\n",
            "Worker 1, [12/18]: Training Loss: 1.267751278, Training Accuracy: 64.832\n",
            "Worker 1, [13/18]: Training Loss: 1.220942641, Training Accuracy: 64.832\n",
            "Worker 1, [14/18]: Training Loss: 1.213447905, Training Accuracy: 65.040\n",
            "Worker 1, [15/18]: Training Loss: 1.150690079, Training Accuracy: 66.304\n",
            "Worker 1, [16/18]: Training Loss: 1.185292358, Training Accuracy: 66.016\n",
            "Worker 1, [17/18]: Training Loss: 1.095602695, Training Accuracy: 67.824\n",
            "Worker 1, [18/18]: Training Loss: 1.116101724, Training Accuracy: 67.488\n",
            "Time taken for training worker 1: 0:00:48.038640\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.662513550, Training Accuracy: 39.952\n",
            "Worker 2, [02/18]: Training Loss: 2.538590010, Training Accuracy: 40.016\n",
            "Worker 2, [03/18]: Training Loss: 2.320752175, Training Accuracy: 42.416\n",
            "Worker 2, [04/18]: Training Loss: 2.133386041, Training Accuracy: 45.216\n",
            "Worker 2, [05/18]: Training Loss: 2.019333349, Training Accuracy: 46.688\n",
            "Worker 2, [06/18]: Training Loss: 1.870905722, Training Accuracy: 50.432\n",
            "Worker 2, [07/18]: Training Loss: 1.760760071, Training Accuracy: 52.336\n",
            "Worker 2, [08/18]: Training Loss: 1.642667859, Training Accuracy: 55.328\n",
            "Worker 2, [09/18]: Training Loss: 1.538537331, Training Accuracy: 56.624\n",
            "Worker 2, [10/18]: Training Loss: 1.435473700, Training Accuracy: 59.856\n",
            "Worker 2, [11/18]: Training Loss: 1.350918802, Training Accuracy: 61.632\n",
            "Worker 2, [12/18]: Training Loss: 1.302258299, Training Accuracy: 62.640\n",
            "Worker 2, [13/18]: Training Loss: 1.225078723, Training Accuracy: 63.904\n",
            "Worker 2, [14/18]: Training Loss: 1.234743477, Training Accuracy: 64.240\n",
            "Worker 2, [15/18]: Training Loss: 1.190458321, Training Accuracy: 65.216\n",
            "Worker 2, [16/18]: Training Loss: 1.126214159, Training Accuracy: 66.464\n",
            "Worker 2, [17/18]: Training Loss: 1.106461125, Training Accuracy: 68.000\n",
            "Worker 2, [18/18]: Training Loss: 1.081177361, Training Accuracy: 67.952\n",
            "Time taken for training worker 2: 0:00:47.535754\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.645447843, Training Accuracy: 40.288\n",
            "Worker 3, [02/18]: Training Loss: 2.555407288, Training Accuracy: 41.136\n",
            "Worker 3, [03/18]: Training Loss: 2.352487647, Training Accuracy: 43.024\n",
            "Worker 3, [04/18]: Training Loss: 2.157110638, Training Accuracy: 44.288\n",
            "Worker 3, [05/18]: Training Loss: 2.022018603, Training Accuracy: 48.048\n",
            "Worker 3, [06/18]: Training Loss: 1.875404790, Training Accuracy: 49.696\n",
            "Worker 3, [07/18]: Training Loss: 1.730100814, Training Accuracy: 53.808\n",
            "Worker 3, [08/18]: Training Loss: 1.624867353, Training Accuracy: 55.216\n",
            "Worker 3, [09/18]: Training Loss: 1.507401352, Training Accuracy: 57.808\n",
            "Worker 3, [10/18]: Training Loss: 1.414194682, Training Accuracy: 60.736\n",
            "Worker 3, [11/18]: Training Loss: 1.353576458, Training Accuracy: 62.016\n",
            "Worker 3, [12/18]: Training Loss: 1.259966886, Training Accuracy: 63.568\n",
            "Worker 3, [13/18]: Training Loss: 1.251753608, Training Accuracy: 63.616\n",
            "Worker 3, [14/18]: Training Loss: 1.184158260, Training Accuracy: 66.240\n",
            "Worker 3, [15/18]: Training Loss: 1.142458835, Training Accuracy: 65.968\n",
            "Worker 3, [16/18]: Training Loss: 1.132230828, Training Accuracy: 66.720\n",
            "Worker 3, [17/18]: Training Loss: 1.096925074, Training Accuracy: 67.424\n",
            "Worker 3, [18/18]: Training Loss: 1.034165981, Training Accuracy: 69.904\n",
            "Time taken for training worker 3: 0:00:47.553243\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.607544667, Training Accuracy: 39.744\n",
            "Worker 4, [02/18]: Training Loss: 2.528324812, Training Accuracy: 40.464\n",
            "Worker 4, [03/18]: Training Loss: 2.320180558, Training Accuracy: 42.736\n",
            "Worker 4, [04/18]: Training Loss: 2.147214112, Training Accuracy: 45.360\n",
            "Worker 4, [05/18]: Training Loss: 1.996364649, Training Accuracy: 48.304\n",
            "Worker 4, [06/18]: Training Loss: 1.874703041, Training Accuracy: 50.272\n",
            "Worker 4, [07/18]: Training Loss: 1.737335968, Training Accuracy: 52.416\n",
            "Worker 4, [08/18]: Training Loss: 1.613065270, Training Accuracy: 55.696\n",
            "Worker 4, [09/18]: Training Loss: 1.512842456, Training Accuracy: 57.760\n",
            "Worker 4, [10/18]: Training Loss: 1.412347607, Training Accuracy: 60.608\n",
            "Worker 4, [11/18]: Training Loss: 1.374967349, Training Accuracy: 61.440\n",
            "Worker 4, [12/18]: Training Loss: 1.287125892, Training Accuracy: 62.672\n",
            "Worker 4, [13/18]: Training Loss: 1.213816789, Training Accuracy: 65.024\n",
            "Worker 4, [14/18]: Training Loss: 1.219470176, Training Accuracy: 65.216\n",
            "Worker 4, [15/18]: Training Loss: 1.131935884, Training Accuracy: 66.688\n",
            "Worker 4, [16/18]: Training Loss: 1.151047348, Training Accuracy: 66.736\n",
            "Worker 4, [17/18]: Training Loss: 1.113857571, Training Accuracy: 67.600\n",
            "Worker 4, [18/18]: Training Loss: 1.051023163, Training Accuracy: 68.912\n",
            "Time taken for training worker 4: 0:00:51.772030\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.908246583, Training Accuracy: 36.912\n",
            "Worker 5, [02/18]: Training Loss: 2.691204121, Training Accuracy: 38.928\n",
            "Worker 5, [03/18]: Training Loss: 2.414141076, Training Accuracy: 41.072\n",
            "Worker 5, [04/18]: Training Loss: 2.198627620, Training Accuracy: 44.416\n",
            "Worker 5, [05/18]: Training Loss: 2.049904070, Training Accuracy: 46.640\n",
            "Worker 5, [06/18]: Training Loss: 1.912409635, Training Accuracy: 49.536\n",
            "Worker 5, [07/18]: Training Loss: 1.793099367, Training Accuracy: 51.200\n",
            "Worker 5, [08/18]: Training Loss: 1.664233418, Training Accuracy: 54.896\n",
            "Worker 5, [09/18]: Training Loss: 1.547644984, Training Accuracy: 56.912\n",
            "Worker 5, [10/18]: Training Loss: 1.445404878, Training Accuracy: 59.856\n",
            "Worker 5, [11/18]: Training Loss: 1.383930897, Training Accuracy: 60.992\n",
            "Worker 5, [12/18]: Training Loss: 1.285873366, Training Accuracy: 63.936\n",
            "Worker 5, [13/18]: Training Loss: 1.228338117, Training Accuracy: 64.736\n",
            "Worker 5, [14/18]: Training Loss: 1.177859674, Training Accuracy: 66.656\n",
            "Worker 5, [15/18]: Training Loss: 1.170812662, Training Accuracy: 65.456\n",
            "Worker 5, [16/18]: Training Loss: 1.158331939, Training Accuracy: 66.320\n",
            "Worker 5, [17/18]: Training Loss: 1.125553550, Training Accuracy: 67.456\n",
            "Worker 5, [18/18]: Training Loss: 1.117263373, Training Accuracy: 67.728\n",
            "Time taken for training worker 5: 0:00:48.377012\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.563362193, Training Accuracy: 39.888\n",
            "Worker 6, [02/18]: Training Loss: 2.465155198, Training Accuracy: 40.528\n",
            "Worker 6, [03/18]: Training Loss: 2.297943658, Training Accuracy: 43.312\n",
            "Worker 6, [04/18]: Training Loss: 2.135674938, Training Accuracy: 44.912\n",
            "Worker 6, [05/18]: Training Loss: 2.007017400, Training Accuracy: 47.520\n",
            "Worker 6, [06/18]: Training Loss: 1.873417918, Training Accuracy: 50.576\n",
            "Worker 6, [07/18]: Training Loss: 1.743067328, Training Accuracy: 52.640\n",
            "Worker 6, [08/18]: Training Loss: 1.607316214, Training Accuracy: 55.824\n",
            "Worker 6, [09/18]: Training Loss: 1.491961731, Training Accuracy: 59.024\n",
            "Worker 6, [10/18]: Training Loss: 1.399096890, Training Accuracy: 60.624\n",
            "Worker 6, [11/18]: Training Loss: 1.328522662, Training Accuracy: 61.920\n",
            "Worker 6, [12/18]: Training Loss: 1.247216574, Training Accuracy: 64.256\n",
            "Worker 6, [13/18]: Training Loss: 1.198059810, Training Accuracy: 65.600\n",
            "Worker 6, [14/18]: Training Loss: 1.149304457, Training Accuracy: 66.128\n",
            "Worker 6, [15/18]: Training Loss: 1.101657180, Training Accuracy: 68.112\n",
            "Worker 6, [16/18]: Training Loss: 1.074696057, Training Accuracy: 67.984\n",
            "Worker 6, [17/18]: Training Loss: 1.071468136, Training Accuracy: 68.320\n",
            "Worker 6, [18/18]: Training Loss: 1.019426464, Training Accuracy: 70.160\n",
            "Time taken for training worker 6: 0:00:49.182778\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.623262087, Training Accuracy: 40.304\n",
            "Worker 7, [02/18]: Training Loss: 2.528195628, Training Accuracy: 40.928\n",
            "Worker 7, [03/18]: Training Loss: 2.312938999, Training Accuracy: 43.632\n",
            "Worker 7, [04/18]: Training Loss: 2.124202503, Training Accuracy: 46.544\n",
            "Worker 7, [05/18]: Training Loss: 1.978733727, Training Accuracy: 48.336\n",
            "Worker 7, [06/18]: Training Loss: 1.829223696, Training Accuracy: 51.104\n",
            "Worker 7, [07/18]: Training Loss: 1.751120520, Training Accuracy: 52.896\n",
            "Worker 7, [08/18]: Training Loss: 1.633754694, Training Accuracy: 55.632\n",
            "Worker 7, [09/18]: Training Loss: 1.536089615, Training Accuracy: 57.904\n",
            "Worker 7, [10/18]: Training Loss: 1.405014599, Training Accuracy: 60.256\n",
            "Worker 7, [11/18]: Training Loss: 1.381262647, Training Accuracy: 61.744\n",
            "Worker 7, [12/18]: Training Loss: 1.283571170, Training Accuracy: 63.888\n",
            "Worker 7, [13/18]: Training Loss: 1.230859224, Training Accuracy: 64.992\n",
            "Worker 7, [14/18]: Training Loss: 1.175360444, Training Accuracy: 65.968\n",
            "Worker 7, [15/18]: Training Loss: 1.150614535, Training Accuracy: 66.448\n",
            "Worker 7, [16/18]: Training Loss: 1.128863015, Training Accuracy: 67.184\n",
            "Worker 7, [17/18]: Training Loss: 1.115022931, Training Accuracy: 67.616\n",
            "Worker 7, [18/18]: Training Loss: 1.042894598, Training Accuracy: 69.152\n",
            "Time taken for training worker 7: 0:00:49.615091\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.670502699, Training Accuracy: 39.264\n",
            "Worker 8, [02/18]: Training Loss: 2.517492474, Training Accuracy: 40.656\n",
            "Worker 8, [03/18]: Training Loss: 2.279380070, Training Accuracy: 43.456\n",
            "Worker 8, [04/18]: Training Loss: 2.111415822, Training Accuracy: 44.688\n",
            "Worker 8, [05/18]: Training Loss: 1.964532405, Training Accuracy: 48.592\n",
            "Worker 8, [06/18]: Training Loss: 1.846533149, Training Accuracy: 50.240\n",
            "Worker 8, [07/18]: Training Loss: 1.697637384, Training Accuracy: 54.480\n",
            "Worker 8, [08/18]: Training Loss: 1.590302617, Training Accuracy: 56.080\n",
            "Worker 8, [09/18]: Training Loss: 1.484989205, Training Accuracy: 58.704\n",
            "Worker 8, [10/18]: Training Loss: 1.398101940, Training Accuracy: 60.240\n",
            "Worker 8, [11/18]: Training Loss: 1.341058159, Training Accuracy: 61.040\n",
            "Worker 8, [12/18]: Training Loss: 1.264596954, Training Accuracy: 63.344\n",
            "Worker 8, [13/18]: Training Loss: 1.186110234, Training Accuracy: 65.376\n",
            "Worker 8, [14/18]: Training Loss: 1.156507202, Training Accuracy: 66.592\n",
            "Worker 8, [15/18]: Training Loss: 1.195886034, Training Accuracy: 64.896\n",
            "Worker 8, [16/18]: Training Loss: 1.150156395, Training Accuracy: 66.544\n",
            "Worker 8, [17/18]: Training Loss: 1.052441031, Training Accuracy: 69.664\n",
            "Worker 8, [18/18]: Training Loss: 1.035656304, Training Accuracy: 69.664\n",
            "Time taken for training worker 8: 0:00:47.663588\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001173\n",
            "Local Step 06: Test Loss: 2.810665922, Test Accuracy: 38.920\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.447370229, Training Accuracy: 39.424\n",
            "Worker 1, [02/18]: Training Loss: 1.958124466, Training Accuracy: 48.448\n",
            "Worker 1, [03/18]: Training Loss: 1.696561686, Training Accuracy: 54.096\n",
            "Worker 1, [04/18]: Training Loss: 1.532062968, Training Accuracy: 57.536\n",
            "Worker 1, [05/18]: Training Loss: 1.325299450, Training Accuracy: 62.480\n",
            "Worker 1, [06/18]: Training Loss: 1.206962840, Training Accuracy: 64.976\n",
            "Worker 1, [07/18]: Training Loss: 1.053026609, Training Accuracy: 69.520\n",
            "Worker 1, [08/18]: Training Loss: 0.926033011, Training Accuracy: 73.120\n",
            "Worker 1, [09/18]: Training Loss: 0.819719784, Training Accuracy: 76.464\n",
            "Worker 1, [10/18]: Training Loss: 0.703306184, Training Accuracy: 79.760\n",
            "Worker 1, [11/18]: Training Loss: 0.607821860, Training Accuracy: 82.416\n",
            "Worker 1, [12/18]: Training Loss: 0.519459528, Training Accuracy: 85.344\n",
            "Worker 1, [13/18]: Training Loss: 0.459383591, Training Accuracy: 86.976\n",
            "Worker 1, [14/18]: Training Loss: 0.404910740, Training Accuracy: 88.752\n",
            "Worker 1, [15/18]: Training Loss: 0.380700116, Training Accuracy: 89.680\n",
            "Worker 1, [16/18]: Training Loss: 0.339248093, Training Accuracy: 90.560\n",
            "Worker 1, [17/18]: Training Loss: 0.317214732, Training Accuracy: 91.536\n",
            "Worker 1, [18/18]: Training Loss: 0.301255631, Training Accuracy: 92.160\n",
            "Time taken for training worker 1: 0:00:47.463963\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.440261608, Training Accuracy: 39.616\n",
            "Worker 2, [02/18]: Training Loss: 1.921590471, Training Accuracy: 48.192\n",
            "Worker 2, [03/18]: Training Loss: 1.693786673, Training Accuracy: 53.856\n",
            "Worker 2, [04/18]: Training Loss: 1.483408879, Training Accuracy: 58.240\n",
            "Worker 2, [05/18]: Training Loss: 1.317390071, Training Accuracy: 62.832\n",
            "Worker 2, [06/18]: Training Loss: 1.197747688, Training Accuracy: 65.184\n",
            "Worker 2, [07/18]: Training Loss: 1.061307014, Training Accuracy: 68.448\n",
            "Worker 2, [08/18]: Training Loss: 0.948240338, Training Accuracy: 72.096\n",
            "Worker 2, [09/18]: Training Loss: 0.799709626, Training Accuracy: 76.480\n",
            "Worker 2, [10/18]: Training Loss: 0.683045078, Training Accuracy: 79.440\n",
            "Worker 2, [11/18]: Training Loss: 0.625752500, Training Accuracy: 81.904\n",
            "Worker 2, [12/18]: Training Loss: 0.503336158, Training Accuracy: 85.424\n",
            "Worker 2, [13/18]: Training Loss: 0.429097741, Training Accuracy: 87.632\n",
            "Worker 2, [14/18]: Training Loss: 0.399434908, Training Accuracy: 88.688\n",
            "Worker 2, [15/18]: Training Loss: 0.347798801, Training Accuracy: 90.320\n",
            "Worker 2, [16/18]: Training Loss: 0.319334907, Training Accuracy: 91.088\n",
            "Worker 2, [17/18]: Training Loss: 0.306558310, Training Accuracy: 91.616\n",
            "Worker 2, [18/18]: Training Loss: 0.307059462, Training Accuracy: 92.016\n",
            "Time taken for training worker 2: 0:00:48.412472\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.451409535, Training Accuracy: 39.648\n",
            "Worker 3, [02/18]: Training Loss: 1.902547397, Training Accuracy: 48.960\n",
            "Worker 3, [03/18]: Training Loss: 1.660846506, Training Accuracy: 54.800\n",
            "Worker 3, [04/18]: Training Loss: 1.461419660, Training Accuracy: 58.464\n",
            "Worker 3, [05/18]: Training Loss: 1.329518646, Training Accuracy: 61.952\n",
            "Worker 3, [06/18]: Training Loss: 1.172562813, Training Accuracy: 66.688\n",
            "Worker 3, [07/18]: Training Loss: 1.028512901, Training Accuracy: 69.680\n",
            "Worker 3, [08/18]: Training Loss: 0.895839574, Training Accuracy: 73.984\n",
            "Worker 3, [09/18]: Training Loss: 0.784820206, Training Accuracy: 76.928\n",
            "Worker 3, [10/18]: Training Loss: 0.674460807, Training Accuracy: 80.080\n",
            "Worker 3, [11/18]: Training Loss: 0.560095539, Training Accuracy: 83.920\n",
            "Worker 3, [12/18]: Training Loss: 0.483438783, Training Accuracy: 85.952\n",
            "Worker 3, [13/18]: Training Loss: 0.432742081, Training Accuracy: 87.440\n",
            "Worker 3, [14/18]: Training Loss: 0.355951300, Training Accuracy: 89.776\n",
            "Worker 3, [15/18]: Training Loss: 0.344096390, Training Accuracy: 90.080\n",
            "Worker 3, [16/18]: Training Loss: 0.308258816, Training Accuracy: 91.536\n",
            "Worker 3, [17/18]: Training Loss: 0.296000958, Training Accuracy: 91.664\n",
            "Worker 3, [18/18]: Training Loss: 0.289701004, Training Accuracy: 92.384\n",
            "Time taken for training worker 3: 0:00:47.752000\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.436148226, Training Accuracy: 40.224\n",
            "Worker 4, [02/18]: Training Loss: 1.941848164, Training Accuracy: 48.656\n",
            "Worker 4, [03/18]: Training Loss: 1.703432086, Training Accuracy: 53.488\n",
            "Worker 4, [04/18]: Training Loss: 1.491797268, Training Accuracy: 58.304\n",
            "Worker 4, [05/18]: Training Loss: 1.300729423, Training Accuracy: 62.560\n",
            "Worker 4, [06/18]: Training Loss: 1.194010488, Training Accuracy: 65.760\n",
            "Worker 4, [07/18]: Training Loss: 1.041136793, Training Accuracy: 69.568\n",
            "Worker 4, [08/18]: Training Loss: 0.919098035, Training Accuracy: 72.992\n",
            "Worker 4, [09/18]: Training Loss: 0.787845174, Training Accuracy: 76.624\n",
            "Worker 4, [10/18]: Training Loss: 0.692475965, Training Accuracy: 80.112\n",
            "Worker 4, [11/18]: Training Loss: 0.599337478, Training Accuracy: 82.144\n",
            "Worker 4, [12/18]: Training Loss: 0.484714791, Training Accuracy: 85.904\n",
            "Worker 4, [13/18]: Training Loss: 0.448622868, Training Accuracy: 86.400\n",
            "Worker 4, [14/18]: Training Loss: 0.393668520, Training Accuracy: 88.624\n",
            "Worker 4, [15/18]: Training Loss: 0.358612936, Training Accuracy: 90.544\n",
            "Worker 4, [16/18]: Training Loss: 0.307770866, Training Accuracy: 91.472\n",
            "Worker 4, [17/18]: Training Loss: 0.305884892, Training Accuracy: 91.776\n",
            "Worker 4, [18/18]: Training Loss: 0.299223454, Training Accuracy: 91.856\n",
            "Time taken for training worker 4: 0:00:47.726837\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.472468624, Training Accuracy: 38.656\n",
            "Worker 5, [02/18]: Training Loss: 1.925546922, Training Accuracy: 49.184\n",
            "Worker 5, [03/18]: Training Loss: 1.659504230, Training Accuracy: 53.824\n",
            "Worker 5, [04/18]: Training Loss: 1.469813844, Training Accuracy: 58.848\n",
            "Worker 5, [05/18]: Training Loss: 1.331448657, Training Accuracy: 62.528\n",
            "Worker 5, [06/18]: Training Loss: 1.161554241, Training Accuracy: 66.464\n",
            "Worker 5, [07/18]: Training Loss: 1.038100887, Training Accuracy: 69.744\n",
            "Worker 5, [08/18]: Training Loss: 0.973023024, Training Accuracy: 71.120\n",
            "Worker 5, [09/18]: Training Loss: 0.804036628, Training Accuracy: 76.080\n",
            "Worker 5, [10/18]: Training Loss: 0.677717126, Training Accuracy: 80.272\n",
            "Worker 5, [11/18]: Training Loss: 0.587287140, Training Accuracy: 83.104\n",
            "Worker 5, [12/18]: Training Loss: 0.495186763, Training Accuracy: 85.536\n",
            "Worker 5, [13/18]: Training Loss: 0.436836681, Training Accuracy: 87.120\n",
            "Worker 5, [14/18]: Training Loss: 0.383486591, Training Accuracy: 89.072\n",
            "Worker 5, [15/18]: Training Loss: 0.345500428, Training Accuracy: 90.480\n",
            "Worker 5, [16/18]: Training Loss: 0.320736602, Training Accuracy: 91.232\n",
            "Worker 5, [17/18]: Training Loss: 0.305538887, Training Accuracy: 91.568\n",
            "Worker 5, [18/18]: Training Loss: 0.301645877, Training Accuracy: 92.176\n",
            "Time taken for training worker 5: 0:00:47.991815\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.407263008, Training Accuracy: 40.480\n",
            "Worker 6, [02/18]: Training Loss: 1.869241107, Training Accuracy: 49.920\n",
            "Worker 6, [03/18]: Training Loss: 1.646316291, Training Accuracy: 54.208\n",
            "Worker 6, [04/18]: Training Loss: 1.461792897, Training Accuracy: 59.504\n",
            "Worker 6, [05/18]: Training Loss: 1.294862351, Training Accuracy: 63.024\n",
            "Worker 6, [06/18]: Training Loss: 1.179076775, Training Accuracy: 65.520\n",
            "Worker 6, [07/18]: Training Loss: 1.041371561, Training Accuracy: 69.840\n",
            "Worker 6, [08/18]: Training Loss: 0.883623332, Training Accuracy: 74.752\n",
            "Worker 6, [09/18]: Training Loss: 0.759790592, Training Accuracy: 76.960\n",
            "Worker 6, [10/18]: Training Loss: 0.664248972, Training Accuracy: 79.712\n",
            "Worker 6, [11/18]: Training Loss: 0.545865580, Training Accuracy: 84.064\n",
            "Worker 6, [12/18]: Training Loss: 0.464620213, Training Accuracy: 86.752\n",
            "Worker 6, [13/18]: Training Loss: 0.416859152, Training Accuracy: 88.064\n",
            "Worker 6, [14/18]: Training Loss: 0.370561818, Training Accuracy: 89.840\n",
            "Worker 6, [15/18]: Training Loss: 0.312885082, Training Accuracy: 91.408\n",
            "Worker 6, [16/18]: Training Loss: 0.306492964, Training Accuracy: 91.616\n",
            "Worker 6, [17/18]: Training Loss: 0.281892067, Training Accuracy: 92.320\n",
            "Worker 6, [18/18]: Training Loss: 0.273376357, Training Accuracy: 92.688\n",
            "Time taken for training worker 6: 0:00:47.507594\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.467496337, Training Accuracy: 39.264\n",
            "Worker 7, [02/18]: Training Loss: 1.926798105, Training Accuracy: 48.400\n",
            "Worker 7, [03/18]: Training Loss: 1.659346126, Training Accuracy: 53.584\n",
            "Worker 7, [04/18]: Training Loss: 1.446409640, Training Accuracy: 60.368\n",
            "Worker 7, [05/18]: Training Loss: 1.325483579, Training Accuracy: 62.528\n",
            "Worker 7, [06/18]: Training Loss: 1.166560436, Training Accuracy: 66.128\n",
            "Worker 7, [07/18]: Training Loss: 1.073305787, Training Accuracy: 68.960\n",
            "Worker 7, [08/18]: Training Loss: 0.930000077, Training Accuracy: 72.752\n",
            "Worker 7, [09/18]: Training Loss: 0.769862568, Training Accuracy: 77.504\n",
            "Worker 7, [10/18]: Training Loss: 0.669973498, Training Accuracy: 80.400\n",
            "Worker 7, [11/18]: Training Loss: 0.602758715, Training Accuracy: 83.040\n",
            "Worker 7, [12/18]: Training Loss: 0.507463602, Training Accuracy: 85.440\n",
            "Worker 7, [13/18]: Training Loss: 0.433303918, Training Accuracy: 87.888\n",
            "Worker 7, [14/18]: Training Loss: 0.382115699, Training Accuracy: 89.392\n",
            "Worker 7, [15/18]: Training Loss: 0.348369093, Training Accuracy: 90.480\n",
            "Worker 7, [16/18]: Training Loss: 0.320165492, Training Accuracy: 91.408\n",
            "Worker 7, [17/18]: Training Loss: 0.288820755, Training Accuracy: 92.224\n",
            "Worker 7, [18/18]: Training Loss: 0.295719160, Training Accuracy: 91.984\n",
            "Time taken for training worker 7: 0:00:48.734341\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.415608430, Training Accuracy: 39.552\n",
            "Worker 8, [02/18]: Training Loss: 1.926716605, Training Accuracy: 47.536\n",
            "Worker 8, [03/18]: Training Loss: 1.632004435, Training Accuracy: 54.944\n",
            "Worker 8, [04/18]: Training Loss: 1.445014775, Training Accuracy: 59.648\n",
            "Worker 8, [05/18]: Training Loss: 1.283557469, Training Accuracy: 63.440\n",
            "Worker 8, [06/18]: Training Loss: 1.144361171, Training Accuracy: 66.480\n",
            "Worker 8, [07/18]: Training Loss: 1.054926929, Training Accuracy: 69.456\n",
            "Worker 8, [08/18]: Training Loss: 0.870583328, Training Accuracy: 74.480\n",
            "Worker 8, [09/18]: Training Loss: 0.807035929, Training Accuracy: 76.448\n",
            "Worker 8, [10/18]: Training Loss: 0.648874583, Training Accuracy: 80.832\n",
            "Worker 8, [11/18]: Training Loss: 0.600312085, Training Accuracy: 82.096\n",
            "Worker 8, [12/18]: Training Loss: 0.475038661, Training Accuracy: 86.160\n",
            "Worker 8, [13/18]: Training Loss: 0.418485854, Training Accuracy: 88.128\n",
            "Worker 8, [14/18]: Training Loss: 0.355533544, Training Accuracy: 89.872\n",
            "Worker 8, [15/18]: Training Loss: 0.341865426, Training Accuracy: 90.688\n",
            "Worker 8, [16/18]: Training Loss: 0.288936032, Training Accuracy: 92.192\n",
            "Worker 8, [17/18]: Training Loss: 0.280140206, Training Accuracy: 92.624\n",
            "Worker 8, [18/18]: Training Loss: 0.266229962, Training Accuracy: 92.896\n",
            "Time taken for training worker 8: 0:00:47.701254\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000881\n",
            "Local Step 07: Test Loss: 2.745497656, Test Accuracy: 46.970\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.619490420, Training Accuracy: 46.176\n",
            "Worker 1, [02/18]: Training Loss: 2.481247989, Training Accuracy: 46.720\n",
            "Worker 1, [03/18]: Training Loss: 2.273105721, Training Accuracy: 46.336\n",
            "Worker 1, [04/18]: Training Loss: 2.042170177, Training Accuracy: 48.480\n",
            "Worker 1, [05/18]: Training Loss: 1.879721188, Training Accuracy: 50.352\n",
            "Worker 1, [06/18]: Training Loss: 1.721555082, Training Accuracy: 54.400\n",
            "Worker 1, [07/18]: Training Loss: 1.604883883, Training Accuracy: 56.048\n",
            "Worker 1, [08/18]: Training Loss: 1.500174454, Training Accuracy: 58.976\n",
            "Worker 1, [09/18]: Training Loss: 1.398187660, Training Accuracy: 60.912\n",
            "Worker 1, [10/18]: Training Loss: 1.292587172, Training Accuracy: 63.632\n",
            "Worker 1, [11/18]: Training Loss: 1.250176106, Training Accuracy: 64.320\n",
            "Worker 1, [12/18]: Training Loss: 1.208510705, Training Accuracy: 65.632\n",
            "Worker 1, [13/18]: Training Loss: 1.121357539, Training Accuracy: 67.664\n",
            "Worker 1, [14/18]: Training Loss: 1.119505082, Training Accuracy: 67.664\n",
            "Worker 1, [15/18]: Training Loss: 1.104295543, Training Accuracy: 67.840\n",
            "Worker 1, [16/18]: Training Loss: 1.042281651, Training Accuracy: 69.520\n",
            "Worker 1, [17/18]: Training Loss: 1.047296618, Training Accuracy: 69.584\n",
            "Worker 1, [18/18]: Training Loss: 0.971058488, Training Accuracy: 71.920\n",
            "Time taken for training worker 1: 0:00:47.902045\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.613017388, Training Accuracy: 41.376\n",
            "Worker 2, [02/18]: Training Loss: 2.490207692, Training Accuracy: 41.856\n",
            "Worker 2, [03/18]: Training Loss: 2.283141842, Training Accuracy: 44.224\n",
            "Worker 2, [04/18]: Training Loss: 2.081652790, Training Accuracy: 46.816\n",
            "Worker 2, [05/18]: Training Loss: 1.933379173, Training Accuracy: 49.200\n",
            "Worker 2, [06/18]: Training Loss: 1.810752701, Training Accuracy: 51.408\n",
            "Worker 2, [07/18]: Training Loss: 1.681958076, Training Accuracy: 53.952\n",
            "Worker 2, [08/18]: Training Loss: 1.547514111, Training Accuracy: 57.744\n",
            "Worker 2, [09/18]: Training Loss: 1.435970544, Training Accuracy: 59.648\n",
            "Worker 2, [10/18]: Training Loss: 1.345054269, Training Accuracy: 61.040\n",
            "Worker 2, [11/18]: Training Loss: 1.256433100, Training Accuracy: 63.920\n",
            "Worker 2, [12/18]: Training Loss: 1.222253967, Training Accuracy: 64.608\n",
            "Worker 2, [13/18]: Training Loss: 1.156048263, Training Accuracy: 66.096\n",
            "Worker 2, [14/18]: Training Loss: 1.115690417, Training Accuracy: 67.104\n",
            "Worker 2, [15/18]: Training Loss: 1.073968067, Training Accuracy: 68.224\n",
            "Worker 2, [16/18]: Training Loss: 1.013745604, Training Accuracy: 70.480\n",
            "Worker 2, [17/18]: Training Loss: 1.058039974, Training Accuracy: 68.960\n",
            "Worker 2, [18/18]: Training Loss: 0.993447484, Training Accuracy: 71.056\n",
            "Time taken for training worker 2: 0:00:47.720837\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.586259613, Training Accuracy: 40.544\n",
            "Worker 3, [02/18]: Training Loss: 2.496318309, Training Accuracy: 41.776\n",
            "Worker 3, [03/18]: Training Loss: 2.267983489, Training Accuracy: 44.080\n",
            "Worker 3, [04/18]: Training Loss: 2.101864601, Training Accuracy: 45.648\n",
            "Worker 3, [05/18]: Training Loss: 1.946456680, Training Accuracy: 48.880\n",
            "Worker 3, [06/18]: Training Loss: 1.822090361, Training Accuracy: 50.624\n",
            "Worker 3, [07/18]: Training Loss: 1.653902674, Training Accuracy: 54.544\n",
            "Worker 3, [08/18]: Training Loss: 1.560264294, Training Accuracy: 56.352\n",
            "Worker 3, [09/18]: Training Loss: 1.442571887, Training Accuracy: 59.696\n",
            "Worker 3, [10/18]: Training Loss: 1.323526137, Training Accuracy: 61.728\n",
            "Worker 3, [11/18]: Training Loss: 1.237492785, Training Accuracy: 64.272\n",
            "Worker 3, [12/18]: Training Loss: 1.181246781, Training Accuracy: 65.872\n",
            "Worker 3, [13/18]: Training Loss: 1.154186096, Training Accuracy: 66.224\n",
            "Worker 3, [14/18]: Training Loss: 1.119341473, Training Accuracy: 66.784\n",
            "Worker 3, [15/18]: Training Loss: 1.067184938, Training Accuracy: 68.528\n",
            "Worker 3, [16/18]: Training Loss: 1.036515976, Training Accuracy: 69.408\n",
            "Worker 3, [17/18]: Training Loss: 1.022311808, Training Accuracy: 70.336\n",
            "Worker 3, [18/18]: Training Loss: 0.964742379, Training Accuracy: 71.392\n",
            "Time taken for training worker 3: 0:00:50.978718\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.730351755, Training Accuracy: 39.616\n",
            "Worker 4, [02/18]: Training Loss: 2.538481559, Training Accuracy: 41.328\n",
            "Worker 4, [03/18]: Training Loss: 2.285250011, Training Accuracy: 44.448\n",
            "Worker 4, [04/18]: Training Loss: 2.075200193, Training Accuracy: 47.696\n",
            "Worker 4, [05/18]: Training Loss: 1.938884443, Training Accuracy: 48.992\n",
            "Worker 4, [06/18]: Training Loss: 1.819075421, Training Accuracy: 51.824\n",
            "Worker 4, [07/18]: Training Loss: 1.667859419, Training Accuracy: 54.656\n",
            "Worker 4, [08/18]: Training Loss: 1.548678903, Training Accuracy: 57.360\n",
            "Worker 4, [09/18]: Training Loss: 1.445750264, Training Accuracy: 59.536\n",
            "Worker 4, [10/18]: Training Loss: 1.348337015, Training Accuracy: 62.240\n",
            "Worker 4, [11/18]: Training Loss: 1.283922727, Training Accuracy: 63.440\n",
            "Worker 4, [12/18]: Training Loss: 1.221274869, Training Accuracy: 64.864\n",
            "Worker 4, [13/18]: Training Loss: 1.121985560, Training Accuracy: 67.760\n",
            "Worker 4, [14/18]: Training Loss: 1.116306070, Training Accuracy: 68.224\n",
            "Worker 4, [15/18]: Training Loss: 1.090097365, Training Accuracy: 67.856\n",
            "Worker 4, [16/18]: Training Loss: 1.065152151, Training Accuracy: 68.672\n",
            "Worker 4, [17/18]: Training Loss: 1.055320276, Training Accuracy: 69.392\n",
            "Worker 4, [18/18]: Training Loss: 0.960745231, Training Accuracy: 71.728\n",
            "Time taken for training worker 4: 0:00:50.056800\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 2.593615874, Training Accuracy: 40.544\n",
            "Worker 5, [02/18]: Training Loss: 2.487997499, Training Accuracy: 41.520\n",
            "Worker 5, [03/18]: Training Loss: 2.302220837, Training Accuracy: 43.680\n",
            "Worker 5, [04/18]: Training Loss: 2.126993223, Training Accuracy: 46.064\n",
            "Worker 5, [05/18]: Training Loss: 1.987768118, Training Accuracy: 47.952\n",
            "Worker 5, [06/18]: Training Loss: 1.831875571, Training Accuracy: 51.088\n",
            "Worker 5, [07/18]: Training Loss: 1.680563888, Training Accuracy: 54.512\n",
            "Worker 5, [08/18]: Training Loss: 1.581556110, Training Accuracy: 56.656\n",
            "Worker 5, [09/18]: Training Loss: 1.450803366, Training Accuracy: 58.688\n",
            "Worker 5, [10/18]: Training Loss: 1.369607245, Training Accuracy: 60.528\n",
            "Worker 5, [11/18]: Training Loss: 1.283282302, Training Accuracy: 63.648\n",
            "Worker 5, [12/18]: Training Loss: 1.214037391, Training Accuracy: 64.752\n",
            "Worker 5, [13/18]: Training Loss: 1.161047996, Training Accuracy: 66.192\n",
            "Worker 5, [14/18]: Training Loss: 1.117139679, Training Accuracy: 67.568\n",
            "Worker 5, [15/18]: Training Loss: 1.080188231, Training Accuracy: 68.768\n",
            "Worker 5, [16/18]: Training Loss: 1.070952151, Training Accuracy: 68.464\n",
            "Worker 5, [17/18]: Training Loss: 1.040102498, Training Accuracy: 69.152\n",
            "Worker 5, [18/18]: Training Loss: 1.002211996, Training Accuracy: 69.712\n",
            "Time taken for training worker 5: 0:00:47.884193\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 2.613928999, Training Accuracy: 42.048\n",
            "Worker 6, [02/18]: Training Loss: 2.496337961, Training Accuracy: 42.640\n",
            "Worker 6, [03/18]: Training Loss: 2.227916591, Training Accuracy: 44.928\n",
            "Worker 6, [04/18]: Training Loss: 2.062890544, Training Accuracy: 47.040\n",
            "Worker 6, [05/18]: Training Loss: 1.910039471, Training Accuracy: 49.600\n",
            "Worker 6, [06/18]: Training Loss: 1.756458613, Training Accuracy: 52.336\n",
            "Worker 6, [07/18]: Training Loss: 1.640568052, Training Accuracy: 55.232\n",
            "Worker 6, [08/18]: Training Loss: 1.493634397, Training Accuracy: 58.880\n",
            "Worker 6, [09/18]: Training Loss: 1.420310831, Training Accuracy: 60.080\n",
            "Worker 6, [10/18]: Training Loss: 1.290751777, Training Accuracy: 62.896\n",
            "Worker 6, [11/18]: Training Loss: 1.243884484, Training Accuracy: 64.192\n",
            "Worker 6, [12/18]: Training Loss: 1.180599237, Training Accuracy: 65.760\n",
            "Worker 6, [13/18]: Training Loss: 1.151378944, Training Accuracy: 66.128\n",
            "Worker 6, [14/18]: Training Loss: 1.122470578, Training Accuracy: 67.536\n",
            "Worker 6, [15/18]: Training Loss: 1.041599220, Training Accuracy: 68.512\n",
            "Worker 6, [16/18]: Training Loss: 1.027100242, Training Accuracy: 69.616\n",
            "Worker 6, [17/18]: Training Loss: 1.023699920, Training Accuracy: 69.168\n",
            "Worker 6, [18/18]: Training Loss: 0.988467100, Training Accuracy: 70.720\n",
            "Time taken for training worker 6: 0:00:49.153037\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 2.679126142, Training Accuracy: 41.328\n",
            "Worker 7, [02/18]: Training Loss: 2.542152328, Training Accuracy: 42.352\n",
            "Worker 7, [03/18]: Training Loss: 2.285285232, Training Accuracy: 43.568\n",
            "Worker 7, [04/18]: Training Loss: 2.110661938, Training Accuracy: 47.040\n",
            "Worker 7, [05/18]: Training Loss: 1.956942747, Training Accuracy: 48.416\n",
            "Worker 7, [06/18]: Training Loss: 1.811456701, Training Accuracy: 52.064\n",
            "Worker 7, [07/18]: Training Loss: 1.688212132, Training Accuracy: 54.208\n",
            "Worker 7, [08/18]: Training Loss: 1.577104559, Training Accuracy: 56.560\n",
            "Worker 7, [09/18]: Training Loss: 1.466432127, Training Accuracy: 59.056\n",
            "Worker 7, [10/18]: Training Loss: 1.354010072, Training Accuracy: 62.192\n",
            "Worker 7, [11/18]: Training Loss: 1.271465394, Training Accuracy: 63.360\n",
            "Worker 7, [12/18]: Training Loss: 1.224365984, Training Accuracy: 65.632\n",
            "Worker 7, [13/18]: Training Loss: 1.204826172, Training Accuracy: 65.136\n",
            "Worker 7, [14/18]: Training Loss: 1.145712339, Training Accuracy: 66.256\n",
            "Worker 7, [15/18]: Training Loss: 1.090762012, Training Accuracy: 68.000\n",
            "Worker 7, [16/18]: Training Loss: 1.029297456, Training Accuracy: 70.064\n",
            "Worker 7, [17/18]: Training Loss: 1.024258037, Training Accuracy: 70.208\n",
            "Worker 7, [18/18]: Training Loss: 1.000042302, Training Accuracy: 69.968\n",
            "Time taken for training worker 7: 0:00:50.754867\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 2.501121211, Training Accuracy: 41.872\n",
            "Worker 8, [02/18]: Training Loss: 2.439837979, Training Accuracy: 41.952\n",
            "Worker 8, [03/18]: Training Loss: 2.241397309, Training Accuracy: 44.432\n",
            "Worker 8, [04/18]: Training Loss: 2.062197212, Training Accuracy: 46.704\n",
            "Worker 8, [05/18]: Training Loss: 1.904287228, Training Accuracy: 49.072\n",
            "Worker 8, [06/18]: Training Loss: 1.772165508, Training Accuracy: 51.984\n",
            "Worker 8, [07/18]: Training Loss: 1.624239591, Training Accuracy: 55.072\n",
            "Worker 8, [08/18]: Training Loss: 1.518744823, Training Accuracy: 57.808\n",
            "Worker 8, [09/18]: Training Loss: 1.405605922, Training Accuracy: 60.352\n",
            "Worker 8, [10/18]: Training Loss: 1.306586070, Training Accuracy: 62.688\n",
            "Worker 8, [11/18]: Training Loss: 1.242067669, Training Accuracy: 64.512\n",
            "Worker 8, [12/18]: Training Loss: 1.156445565, Training Accuracy: 66.320\n",
            "Worker 8, [13/18]: Training Loss: 1.159156316, Training Accuracy: 65.792\n",
            "Worker 8, [14/18]: Training Loss: 1.094440351, Training Accuracy: 67.792\n",
            "Worker 8, [15/18]: Training Loss: 1.043368157, Training Accuracy: 69.296\n",
            "Worker 8, [16/18]: Training Loss: 1.028195033, Training Accuracy: 69.360\n",
            "Worker 8, [17/18]: Training Loss: 0.995438980, Training Accuracy: 70.512\n",
            "Worker 8, [18/18]: Training Loss: 0.945593241, Training Accuracy: 71.792\n",
            "Time taken for training worker 8: 0:00:50.724460\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000734\n",
            "Local Step 08: Test Loss: 2.734007218, Test Accuracy: 42.430\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:02.499967\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:16\n",
            "==================================================\n",
            "Worker 1, [01/9]: Training Loss: 4.594541793, Training Accuracy: 1.776\n",
            "Worker 1, [02/9]: Training Loss: 4.444125589, Training Accuracy: 3.216\n",
            "Worker 1, [03/9]: Training Loss: 4.206475839, Training Accuracy: 5.520\n",
            "Worker 1, [04/9]: Training Loss: 4.053926950, Training Accuracy: 6.960\n",
            "Worker 1, [05/9]: Training Loss: 3.940721702, Training Accuracy: 8.784\n",
            "Worker 1, [06/9]: Training Loss: 3.840872923, Training Accuracy: 10.336\n",
            "Worker 1, [07/9]: Training Loss: 3.752894312, Training Accuracy: 12.080\n",
            "Worker 1, [08/9]: Training Loss: 3.678969459, Training Accuracy: 13.776\n",
            "Worker 1, [09/9]: Training Loss: 3.621595602, Training Accuracy: 15.120\n",
            "Time taken for training worker 1: 0:00:24.816024\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 4.593137303, Training Accuracy: 1.536\n",
            "Worker 2, [02/9]: Training Loss: 4.452541303, Training Accuracy: 3.072\n",
            "Worker 2, [03/9]: Training Loss: 4.198553723, Training Accuracy: 5.328\n",
            "Worker 2, [04/9]: Training Loss: 4.061899302, Training Accuracy: 6.912\n",
            "Worker 2, [05/9]: Training Loss: 3.940384549, Training Accuracy: 8.960\n",
            "Worker 2, [06/9]: Training Loss: 3.854062606, Training Accuracy: 10.400\n",
            "Worker 2, [07/9]: Training Loss: 3.747978575, Training Accuracy: 12.160\n",
            "Worker 2, [08/9]: Training Loss: 3.672857024, Training Accuracy: 13.728\n",
            "Worker 2, [09/9]: Training Loss: 3.636394688, Training Accuracy: 14.384\n",
            "Time taken for training worker 2: 0:00:24.664756\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 4.592911642, Training Accuracy: 1.408\n",
            "Worker 3, [02/9]: Training Loss: 4.453471237, Training Accuracy: 3.472\n",
            "Worker 3, [03/9]: Training Loss: 4.186167508, Training Accuracy: 5.664\n",
            "Worker 3, [04/9]: Training Loss: 4.046535001, Training Accuracy: 7.632\n",
            "Worker 3, [05/9]: Training Loss: 3.935220171, Training Accuracy: 9.296\n",
            "Worker 3, [06/9]: Training Loss: 3.843367455, Training Accuracy: 10.432\n",
            "Worker 3, [07/9]: Training Loss: 3.761337441, Training Accuracy: 12.160\n",
            "Worker 3, [08/9]: Training Loss: 3.697356324, Training Accuracy: 12.944\n",
            "Worker 3, [09/9]: Training Loss: 3.651443124, Training Accuracy: 13.888\n",
            "Time taken for training worker 3: 0:00:24.361035\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 4.593544741, Training Accuracy: 1.600\n",
            "Worker 4, [02/9]: Training Loss: 4.433548339, Training Accuracy: 3.056\n",
            "Worker 4, [03/9]: Training Loss: 4.176336169, Training Accuracy: 5.792\n",
            "Worker 4, [04/9]: Training Loss: 4.040808829, Training Accuracy: 7.392\n",
            "Worker 4, [05/9]: Training Loss: 3.919964737, Training Accuracy: 9.088\n",
            "Worker 4, [06/9]: Training Loss: 3.797996723, Training Accuracy: 11.328\n",
            "Worker 4, [07/9]: Training Loss: 3.722586734, Training Accuracy: 11.680\n",
            "Worker 4, [08/9]: Training Loss: 3.658083947, Training Accuracy: 13.712\n",
            "Worker 4, [09/9]: Training Loss: 3.608467185, Training Accuracy: 14.720\n",
            "Time taken for training worker 4: 0:00:24.842318\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 4.596666998, Training Accuracy: 1.328\n",
            "Worker 5, [02/9]: Training Loss: 4.452951353, Training Accuracy: 3.040\n",
            "Worker 5, [03/9]: Training Loss: 4.204436689, Training Accuracy: 5.824\n",
            "Worker 5, [04/9]: Training Loss: 4.083867496, Training Accuracy: 7.296\n",
            "Worker 5, [05/9]: Training Loss: 3.970505887, Training Accuracy: 8.720\n",
            "Worker 5, [06/9]: Training Loss: 3.852819951, Training Accuracy: 10.576\n",
            "Worker 5, [07/9]: Training Loss: 3.764811518, Training Accuracy: 11.904\n",
            "Worker 5, [08/9]: Training Loss: 3.681389220, Training Accuracy: 13.296\n",
            "Worker 5, [09/9]: Training Loss: 3.640684863, Training Accuracy: 14.512\n",
            "Time taken for training worker 5: 0:00:24.999967\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 4.589828024, Training Accuracy: 1.664\n",
            "Worker 6, [02/9]: Training Loss: 4.427756455, Training Accuracy: 3.520\n",
            "Worker 6, [03/9]: Training Loss: 4.158507415, Training Accuracy: 5.968\n",
            "Worker 6, [04/9]: Training Loss: 4.013513779, Training Accuracy: 7.936\n",
            "Worker 6, [05/9]: Training Loss: 3.901616347, Training Accuracy: 9.744\n",
            "Worker 6, [06/9]: Training Loss: 3.806233975, Training Accuracy: 9.856\n",
            "Worker 6, [07/9]: Training Loss: 3.706688295, Training Accuracy: 12.368\n",
            "Worker 6, [08/9]: Training Loss: 3.641556516, Training Accuracy: 14.256\n",
            "Worker 6, [09/9]: Training Loss: 3.597524526, Training Accuracy: 14.976\n",
            "Time taken for training worker 6: 0:00:24.872517\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 4.590369993, Training Accuracy: 1.728\n",
            "Worker 7, [02/9]: Training Loss: 4.436512675, Training Accuracy: 3.024\n",
            "Worker 7, [03/9]: Training Loss: 4.185853209, Training Accuracy: 5.648\n",
            "Worker 7, [04/9]: Training Loss: 4.027175417, Training Accuracy: 7.616\n",
            "Worker 7, [05/9]: Training Loss: 3.908938525, Training Accuracy: 8.688\n",
            "Worker 7, [06/9]: Training Loss: 3.790931617, Training Accuracy: 11.344\n",
            "Worker 7, [07/9]: Training Loss: 3.693434341, Training Accuracy: 13.024\n",
            "Worker 7, [08/9]: Training Loss: 3.623334641, Training Accuracy: 14.800\n",
            "Worker 7, [09/9]: Training Loss: 3.571175295, Training Accuracy: 15.024\n",
            "Time taken for training worker 7: 0:00:24.551383\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 4.595027023, Training Accuracy: 1.424\n",
            "Worker 8, [02/9]: Training Loss: 4.468093882, Training Accuracy: 3.552\n",
            "Worker 8, [03/9]: Training Loss: 4.206131675, Training Accuracy: 6.160\n",
            "Worker 8, [04/9]: Training Loss: 4.049293645, Training Accuracy: 7.776\n",
            "Worker 8, [05/9]: Training Loss: 3.946064341, Training Accuracy: 8.992\n",
            "Worker 8, [06/9]: Training Loss: 3.842198440, Training Accuracy: 10.320\n",
            "Worker 8, [07/9]: Training Loss: 3.742385327, Training Accuracy: 12.032\n",
            "Worker 8, [08/9]: Training Loss: 3.662868629, Training Accuracy: 13.408\n",
            "Worker 8, [09/9]: Training Loss: 3.615979275, Training Accuracy: 14.256\n",
            "Time taken for training worker 8: 0:00:24.391434\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000818\n",
            "Local Step 01: Test Loss: 3.764326544, Test Accuracy: 13.400\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 3.815548172, Training Accuracy: 11.792\n",
            "Worker 1, [02/9]: Training Loss: 3.791137231, Training Accuracy: 12.384\n",
            "Worker 1, [03/9]: Training Loss: 3.768165963, Training Accuracy: 12.768\n",
            "Worker 1, [04/9]: Training Loss: 3.757168247, Training Accuracy: 12.416\n",
            "Worker 1, [05/9]: Training Loss: 3.740398835, Training Accuracy: 12.432\n",
            "Worker 1, [06/9]: Training Loss: 3.714964346, Training Accuracy: 12.784\n",
            "Worker 1, [07/9]: Training Loss: 3.661905741, Training Accuracy: 14.160\n",
            "Worker 1, [08/9]: Training Loss: 3.621164731, Training Accuracy: 13.440\n",
            "Worker 1, [09/9]: Training Loss: 3.542196872, Training Accuracy: 15.152\n",
            "Time taken for training worker 1: 0:00:23.642105\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 3.657084519, Training Accuracy: 13.728\n",
            "Worker 2, [02/9]: Training Loss: 3.580452340, Training Accuracy: 15.184\n",
            "Worker 2, [03/9]: Training Loss: 3.484049009, Training Accuracy: 17.024\n",
            "Worker 2, [04/9]: Training Loss: 3.443362586, Training Accuracy: 17.088\n",
            "Worker 2, [05/9]: Training Loss: 3.417568005, Training Accuracy: 17.168\n",
            "Worker 2, [06/9]: Training Loss: 3.388578203, Training Accuracy: 17.776\n",
            "Worker 2, [07/9]: Training Loss: 3.348623852, Training Accuracy: 18.464\n",
            "Worker 2, [08/9]: Training Loss: 3.336921412, Training Accuracy: 18.064\n",
            "Worker 2, [09/9]: Training Loss: 3.285583732, Training Accuracy: 19.264\n",
            "Time taken for training worker 2: 0:00:24.539191\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 3.470665012, Training Accuracy: 18.400\n",
            "Worker 3, [02/9]: Training Loss: 3.327874300, Training Accuracy: 20.240\n",
            "Worker 3, [03/9]: Training Loss: 3.242232744, Training Accuracy: 21.616\n",
            "Worker 3, [04/9]: Training Loss: 3.216693443, Training Accuracy: 21.568\n",
            "Worker 3, [05/9]: Training Loss: 3.179721475, Training Accuracy: 22.304\n",
            "Worker 3, [06/9]: Training Loss: 3.143359043, Training Accuracy: 22.528\n",
            "Worker 3, [07/9]: Training Loss: 3.136735802, Training Accuracy: 22.688\n",
            "Worker 3, [08/9]: Training Loss: 3.112032202, Training Accuracy: 22.992\n",
            "Worker 3, [09/9]: Training Loss: 3.080343385, Training Accuracy: 23.328\n",
            "Time taken for training worker 3: 0:00:24.066011\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 3.258778655, Training Accuracy: 20.496\n",
            "Worker 4, [02/9]: Training Loss: 3.147409320, Training Accuracy: 22.864\n",
            "Worker 4, [03/9]: Training Loss: 3.067896656, Training Accuracy: 24.288\n",
            "Worker 4, [04/9]: Training Loss: 3.006249240, Training Accuracy: 25.520\n",
            "Worker 4, [05/9]: Training Loss: 2.992905485, Training Accuracy: 26.448\n",
            "Worker 4, [06/9]: Training Loss: 2.966130249, Training Accuracy: 26.016\n",
            "Worker 4, [07/9]: Training Loss: 2.922147435, Training Accuracy: 26.624\n",
            "Worker 4, [08/9]: Training Loss: 2.907036713, Training Accuracy: 26.592\n",
            "Worker 4, [09/9]: Training Loss: 2.866614021, Training Accuracy: 27.232\n",
            "Time taken for training worker 4: 0:00:24.266794\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 3.165101231, Training Accuracy: 22.384\n",
            "Worker 5, [02/9]: Training Loss: 3.056808625, Training Accuracy: 24.720\n",
            "Worker 5, [03/9]: Training Loss: 2.983787108, Training Accuracy: 25.856\n",
            "Worker 5, [04/9]: Training Loss: 2.906167488, Training Accuracy: 27.440\n",
            "Worker 5, [05/9]: Training Loss: 2.870147060, Training Accuracy: 27.632\n",
            "Worker 5, [06/9]: Training Loss: 2.839263746, Training Accuracy: 28.016\n",
            "Worker 5, [07/9]: Training Loss: 2.851532819, Training Accuracy: 27.312\n",
            "Worker 5, [08/9]: Training Loss: 2.804536484, Training Accuracy: 28.592\n",
            "Worker 5, [09/9]: Training Loss: 2.783698761, Training Accuracy: 29.392\n",
            "Time taken for training worker 5: 0:00:24.451723\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 3.128702621, Training Accuracy: 24.112\n",
            "Worker 6, [02/9]: Training Loss: 2.929828138, Training Accuracy: 27.488\n",
            "Worker 6, [03/9]: Training Loss: 2.798167443, Training Accuracy: 30.048\n",
            "Worker 6, [04/9]: Training Loss: 2.750977813, Training Accuracy: 31.008\n",
            "Worker 6, [05/9]: Training Loss: 2.692198440, Training Accuracy: 31.472\n",
            "Worker 6, [06/9]: Training Loss: 2.661902304, Training Accuracy: 32.224\n",
            "Worker 6, [07/9]: Training Loss: 2.648457559, Training Accuracy: 32.000\n",
            "Worker 6, [08/9]: Training Loss: 2.616641687, Training Accuracy: 32.528\n",
            "Worker 6, [09/9]: Training Loss: 2.595521272, Training Accuracy: 32.752\n",
            "Time taken for training worker 6: 0:00:25.132116\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.984274857, Training Accuracy: 27.296\n",
            "Worker 7, [02/9]: Training Loss: 2.823242477, Training Accuracy: 30.512\n",
            "Worker 7, [03/9]: Training Loss: 2.741463727, Training Accuracy: 31.776\n",
            "Worker 7, [04/9]: Training Loss: 2.662517453, Training Accuracy: 33.296\n",
            "Worker 7, [05/9]: Training Loss: 2.618963208, Training Accuracy: 33.696\n",
            "Worker 7, [06/9]: Training Loss: 2.577213104, Training Accuracy: 33.984\n",
            "Worker 7, [07/9]: Training Loss: 2.579969104, Training Accuracy: 33.040\n",
            "Worker 7, [08/9]: Training Loss: 2.556917767, Training Accuracy: 34.144\n",
            "Worker 7, [09/9]: Training Loss: 2.507776020, Training Accuracy: 35.216\n",
            "Time taken for training worker 7: 0:00:24.263239\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.910961256, Training Accuracy: 27.104\n",
            "Worker 8, [02/9]: Training Loss: 2.781904294, Training Accuracy: 29.392\n",
            "Worker 8, [03/9]: Training Loss: 2.654210244, Training Accuracy: 32.640\n",
            "Worker 8, [04/9]: Training Loss: 2.593779340, Training Accuracy: 33.312\n",
            "Worker 8, [05/9]: Training Loss: 2.550569038, Training Accuracy: 33.664\n",
            "Worker 8, [06/9]: Training Loss: 2.499135579, Training Accuracy: 34.864\n",
            "Worker 8, [07/9]: Training Loss: 2.478404842, Training Accuracy: 35.280\n",
            "Worker 8, [08/9]: Training Loss: 2.448362948, Training Accuracy: 35.168\n",
            "Worker 8, [09/9]: Training Loss: 2.423330232, Training Accuracy: 35.648\n",
            "Time taken for training worker 8: 0:00:23.876432\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000851\n",
            "Local Step 02: Test Loss: 2.786384378, Test Accuracy: 30.570\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.860922879, Training Accuracy: 29.424\n",
            "Worker 1, [02/9]: Training Loss: 2.607540228, Training Accuracy: 33.040\n",
            "Worker 1, [03/9]: Training Loss: 2.500833229, Training Accuracy: 35.920\n",
            "Worker 1, [04/9]: Training Loss: 2.325166196, Training Accuracy: 39.280\n",
            "Worker 1, [05/9]: Training Loss: 2.155426645, Training Accuracy: 42.864\n",
            "Worker 1, [06/9]: Training Loss: 1.994772125, Training Accuracy: 46.128\n",
            "Worker 1, [07/9]: Training Loss: 1.846967791, Training Accuracy: 49.984\n",
            "Worker 1, [08/9]: Training Loss: 1.738138477, Training Accuracy: 52.800\n",
            "Worker 1, [09/9]: Training Loss: 1.670901836, Training Accuracy: 54.176\n",
            "Time taken for training worker 1: 0:00:24.696441\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.773755672, Training Accuracy: 30.496\n",
            "Worker 2, [02/9]: Training Loss: 2.545724458, Training Accuracy: 34.736\n",
            "Worker 2, [03/9]: Training Loss: 2.411089628, Training Accuracy: 37.072\n",
            "Worker 2, [04/9]: Training Loss: 2.244237439, Training Accuracy: 40.240\n",
            "Worker 2, [05/9]: Training Loss: 2.071473839, Training Accuracy: 44.672\n",
            "Worker 2, [06/9]: Training Loss: 1.924362072, Training Accuracy: 47.680\n",
            "Worker 2, [07/9]: Training Loss: 1.766507028, Training Accuracy: 51.200\n",
            "Worker 2, [08/9]: Training Loss: 1.634447430, Training Accuracy: 54.816\n",
            "Worker 2, [09/9]: Training Loss: 1.577012019, Training Accuracy: 56.816\n",
            "Time taken for training worker 2: 0:00:23.984731\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.724148568, Training Accuracy: 31.824\n",
            "Worker 3, [02/9]: Training Loss: 2.486266473, Training Accuracy: 35.872\n",
            "Worker 3, [03/9]: Training Loss: 2.332413596, Training Accuracy: 38.608\n",
            "Worker 3, [04/9]: Training Loss: 2.132680095, Training Accuracy: 43.120\n",
            "Worker 3, [05/9]: Training Loss: 1.964768770, Training Accuracy: 46.224\n",
            "Worker 3, [06/9]: Training Loss: 1.828639271, Training Accuracy: 49.760\n",
            "Worker 3, [07/9]: Training Loss: 1.674661152, Training Accuracy: 53.984\n",
            "Worker 3, [08/9]: Training Loss: 1.547070214, Training Accuracy: 56.800\n",
            "Worker 3, [09/9]: Training Loss: 1.445674284, Training Accuracy: 59.168\n",
            "Time taken for training worker 3: 0:00:25.448776\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.699106134, Training Accuracy: 32.112\n",
            "Worker 4, [02/9]: Training Loss: 2.442325013, Training Accuracy: 36.528\n",
            "Worker 4, [03/9]: Training Loss: 2.264829214, Training Accuracy: 40.368\n",
            "Worker 4, [04/9]: Training Loss: 2.084972312, Training Accuracy: 43.616\n",
            "Worker 4, [05/9]: Training Loss: 1.926664843, Training Accuracy: 46.816\n",
            "Worker 4, [06/9]: Training Loss: 1.761068778, Training Accuracy: 51.152\n",
            "Worker 4, [07/9]: Training Loss: 1.601428814, Training Accuracy: 55.472\n",
            "Worker 4, [08/9]: Training Loss: 1.475682574, Training Accuracy: 58.352\n",
            "Worker 4, [09/9]: Training Loss: 1.412978824, Training Accuracy: 60.400\n",
            "Time taken for training worker 4: 0:00:24.041203\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.685465929, Training Accuracy: 31.856\n",
            "Worker 5, [02/9]: Training Loss: 2.423263224, Training Accuracy: 36.960\n",
            "Worker 5, [03/9]: Training Loss: 2.235067282, Training Accuracy: 40.208\n",
            "Worker 5, [04/9]: Training Loss: 2.065934000, Training Accuracy: 44.688\n",
            "Worker 5, [05/9]: Training Loss: 1.866359165, Training Accuracy: 48.800\n",
            "Worker 5, [06/9]: Training Loss: 1.736334077, Training Accuracy: 51.824\n",
            "Worker 5, [07/9]: Training Loss: 1.561064493, Training Accuracy: 56.064\n",
            "Worker 5, [08/9]: Training Loss: 1.432902656, Training Accuracy: 60.032\n",
            "Worker 5, [09/9]: Training Loss: 1.369069122, Training Accuracy: 61.328\n",
            "Time taken for training worker 5: 0:00:24.262495\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.608835666, Training Accuracy: 34.336\n",
            "Worker 6, [02/9]: Training Loss: 2.306381741, Training Accuracy: 40.240\n",
            "Worker 6, [03/9]: Training Loss: 2.154227723, Training Accuracy: 42.432\n",
            "Worker 6, [04/9]: Training Loss: 1.963220466, Training Accuracy: 46.640\n",
            "Worker 6, [05/9]: Training Loss: 1.810405406, Training Accuracy: 50.192\n",
            "Worker 6, [06/9]: Training Loss: 1.615090121, Training Accuracy: 54.848\n",
            "Worker 6, [07/9]: Training Loss: 1.463060609, Training Accuracy: 58.992\n",
            "Worker 6, [08/9]: Training Loss: 1.377189170, Training Accuracy: 61.392\n",
            "Worker 6, [09/9]: Training Loss: 1.291292888, Training Accuracy: 64.320\n",
            "Time taken for training worker 6: 0:00:24.855749\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.578359370, Training Accuracy: 35.008\n",
            "Worker 7, [02/9]: Training Loss: 2.314318052, Training Accuracy: 40.176\n",
            "Worker 7, [03/9]: Training Loss: 2.105766226, Training Accuracy: 44.384\n",
            "Worker 7, [04/9]: Training Loss: 1.989227307, Training Accuracy: 46.528\n",
            "Worker 7, [05/9]: Training Loss: 1.786298538, Training Accuracy: 51.424\n",
            "Worker 7, [06/9]: Training Loss: 1.598968511, Training Accuracy: 56.560\n",
            "Worker 7, [07/9]: Training Loss: 1.459360108, Training Accuracy: 60.048\n",
            "Worker 7, [08/9]: Training Loss: 1.333989992, Training Accuracy: 62.656\n",
            "Worker 7, [09/9]: Training Loss: 1.260749316, Training Accuracy: 65.456\n",
            "Time taken for training worker 7: 0:00:24.796036\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.539744318, Training Accuracy: 35.376\n",
            "Worker 8, [02/9]: Training Loss: 2.247338627, Training Accuracy: 40.272\n",
            "Worker 8, [03/9]: Training Loss: 2.071328389, Training Accuracy: 44.656\n",
            "Worker 8, [04/9]: Training Loss: 1.894160490, Training Accuracy: 48.336\n",
            "Worker 8, [05/9]: Training Loss: 1.728154989, Training Accuracy: 52.080\n",
            "Worker 8, [06/9]: Training Loss: 1.533173059, Training Accuracy: 56.416\n",
            "Worker 8, [07/9]: Training Loss: 1.417011098, Training Accuracy: 60.160\n",
            "Worker 8, [08/9]: Training Loss: 1.273083461, Training Accuracy: 64.304\n",
            "Worker 8, [09/9]: Training Loss: 1.195568877, Training Accuracy: 66.272\n",
            "Time taken for training worker 8: 0:00:24.638887\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001040\n",
            "Local Step 03: Test Loss: 2.290791004, Test Accuracy: 44.350\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.408448699, Training Accuracy: 41.792\n",
            "Worker 1, [02/9]: Training Loss: 2.318690894, Training Accuracy: 42.112\n",
            "Worker 1, [03/9]: Training Loss: 2.223144564, Training Accuracy: 42.448\n",
            "Worker 1, [04/9]: Training Loss: 2.136002431, Training Accuracy: 44.336\n",
            "Worker 1, [05/9]: Training Loss: 2.071503199, Training Accuracy: 45.344\n",
            "Worker 1, [06/9]: Training Loss: 2.020030165, Training Accuracy: 46.448\n",
            "Worker 1, [07/9]: Training Loss: 1.953714854, Training Accuracy: 47.616\n",
            "Worker 1, [08/9]: Training Loss: 1.928045336, Training Accuracy: 47.664\n",
            "Worker 1, [09/9]: Training Loss: 1.878487980, Training Accuracy: 48.416\n",
            "Time taken for training worker 1: 0:00:23.568386\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.538173611, Training Accuracy: 35.472\n",
            "Worker 2, [02/9]: Training Loss: 2.393017575, Training Accuracy: 38.384\n",
            "Worker 2, [03/9]: Training Loss: 2.231545693, Training Accuracy: 42.080\n",
            "Worker 2, [04/9]: Training Loss: 2.152667757, Training Accuracy: 44.096\n",
            "Worker 2, [05/9]: Training Loss: 2.048356723, Training Accuracy: 45.216\n",
            "Worker 2, [06/9]: Training Loss: 1.996240482, Training Accuracy: 46.064\n",
            "Worker 2, [07/9]: Training Loss: 1.949286288, Training Accuracy: 46.912\n",
            "Worker 2, [08/9]: Training Loss: 1.915188469, Training Accuracy: 47.888\n",
            "Worker 2, [09/9]: Training Loss: 1.859493938, Training Accuracy: 48.304\n",
            "Time taken for training worker 2: 0:00:26.014183\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.520350141, Training Accuracy: 37.072\n",
            "Worker 3, [02/9]: Training Loss: 2.340859808, Training Accuracy: 40.640\n",
            "Worker 3, [03/9]: Training Loss: 2.202516969, Training Accuracy: 42.448\n",
            "Worker 3, [04/9]: Training Loss: 2.086786367, Training Accuracy: 45.184\n",
            "Worker 3, [05/9]: Training Loss: 2.016226744, Training Accuracy: 45.840\n",
            "Worker 3, [06/9]: Training Loss: 1.942249871, Training Accuracy: 48.320\n",
            "Worker 3, [07/9]: Training Loss: 1.925697149, Training Accuracy: 48.272\n",
            "Worker 3, [08/9]: Training Loss: 1.850987378, Training Accuracy: 49.504\n",
            "Worker 3, [09/9]: Training Loss: 1.796634943, Training Accuracy: 50.848\n",
            "Time taken for training worker 3: 0:00:23.694630\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.507775908, Training Accuracy: 36.800\n",
            "Worker 4, [02/9]: Training Loss: 2.288608142, Training Accuracy: 40.304\n",
            "Worker 4, [03/9]: Training Loss: 2.152912493, Training Accuracy: 43.856\n",
            "Worker 4, [04/9]: Training Loss: 2.050925928, Training Accuracy: 45.360\n",
            "Worker 4, [05/9]: Training Loss: 1.964113435, Training Accuracy: 47.040\n",
            "Worker 4, [06/9]: Training Loss: 1.899030623, Training Accuracy: 48.368\n",
            "Worker 4, [07/9]: Training Loss: 1.890455237, Training Accuracy: 48.480\n",
            "Worker 4, [08/9]: Training Loss: 1.849223580, Training Accuracy: 49.392\n",
            "Worker 4, [09/9]: Training Loss: 1.823681385, Training Accuracy: 48.944\n",
            "Time taken for training worker 4: 0:00:25.423162\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.451415550, Training Accuracy: 37.248\n",
            "Worker 5, [02/9]: Training Loss: 2.307080388, Training Accuracy: 40.432\n",
            "Worker 5, [03/9]: Training Loss: 2.164064014, Training Accuracy: 43.424\n",
            "Worker 5, [04/9]: Training Loss: 2.064185021, Training Accuracy: 45.552\n",
            "Worker 5, [05/9]: Training Loss: 1.985786663, Training Accuracy: 46.240\n",
            "Worker 5, [06/9]: Training Loss: 1.910466774, Training Accuracy: 48.320\n",
            "Worker 5, [07/9]: Training Loss: 1.861129087, Training Accuracy: 50.064\n",
            "Worker 5, [08/9]: Training Loss: 1.800951294, Training Accuracy: 49.504\n",
            "Worker 5, [09/9]: Training Loss: 1.774939951, Training Accuracy: 50.928\n",
            "Time taken for training worker 5: 0:00:26.234111\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.482743100, Training Accuracy: 37.104\n",
            "Worker 6, [02/9]: Training Loss: 2.276583841, Training Accuracy: 40.992\n",
            "Worker 6, [03/9]: Training Loss: 2.123462533, Training Accuracy: 44.592\n",
            "Worker 6, [04/9]: Training Loss: 1.993268057, Training Accuracy: 47.120\n",
            "Worker 6, [05/9]: Training Loss: 1.920701250, Training Accuracy: 48.096\n",
            "Worker 6, [06/9]: Training Loss: 1.854304904, Training Accuracy: 49.888\n",
            "Worker 6, [07/9]: Training Loss: 1.789550628, Training Accuracy: 50.224\n",
            "Worker 6, [08/9]: Training Loss: 1.791651944, Training Accuracy: 50.240\n",
            "Worker 6, [09/9]: Training Loss: 1.754256819, Training Accuracy: 50.912\n",
            "Time taken for training worker 6: 0:00:25.561057\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.439406166, Training Accuracy: 39.168\n",
            "Worker 7, [02/9]: Training Loss: 2.251207624, Training Accuracy: 41.536\n",
            "Worker 7, [03/9]: Training Loss: 2.095010525, Training Accuracy: 44.816\n",
            "Worker 7, [04/9]: Training Loss: 1.986275630, Training Accuracy: 47.008\n",
            "Worker 7, [05/9]: Training Loss: 1.935709967, Training Accuracy: 47.952\n",
            "Worker 7, [06/9]: Training Loss: 1.825034388, Training Accuracy: 50.832\n",
            "Worker 7, [07/9]: Training Loss: 1.784392388, Training Accuracy: 51.552\n",
            "Worker 7, [08/9]: Training Loss: 1.759284011, Training Accuracy: 51.312\n",
            "Worker 7, [09/9]: Training Loss: 1.709572844, Training Accuracy: 52.704\n",
            "Time taken for training worker 7: 0:00:25.593066\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.379865457, Training Accuracy: 39.552\n",
            "Worker 8, [02/9]: Training Loss: 2.208264861, Training Accuracy: 41.376\n",
            "Worker 8, [03/9]: Training Loss: 2.079219609, Training Accuracy: 43.984\n",
            "Worker 8, [04/9]: Training Loss: 1.957030242, Training Accuracy: 46.848\n",
            "Worker 8, [05/9]: Training Loss: 1.833151591, Training Accuracy: 49.904\n",
            "Worker 8, [06/9]: Training Loss: 1.784335524, Training Accuracy: 51.264\n",
            "Worker 8, [07/9]: Training Loss: 1.742081866, Training Accuracy: 51.808\n",
            "Worker 8, [08/9]: Training Loss: 1.723252658, Training Accuracy: 52.048\n",
            "Worker 8, [09/9]: Training Loss: 1.656363507, Training Accuracy: 54.000\n",
            "Time taken for training worker 8: 0:00:24.790391\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000752\n",
            "Local Step 04: Test Loss: 2.507265563, Test Accuracy: 39.820\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.364158219, Training Accuracy: 39.472\n",
            "Worker 1, [02/9]: Training Loss: 2.019786216, Training Accuracy: 46.640\n",
            "Worker 1, [03/9]: Training Loss: 1.794785329, Training Accuracy: 51.760\n",
            "Worker 1, [04/9]: Training Loss: 1.652407832, Training Accuracy: 54.656\n",
            "Worker 1, [05/9]: Training Loss: 1.485605886, Training Accuracy: 58.192\n",
            "Worker 1, [06/9]: Training Loss: 1.275567219, Training Accuracy: 63.616\n",
            "Worker 1, [07/9]: Training Loss: 1.135508519, Training Accuracy: 67.680\n",
            "Worker 1, [08/9]: Training Loss: 1.004920429, Training Accuracy: 71.648\n",
            "Worker 1, [09/9]: Training Loss: 0.962608621, Training Accuracy: 73.456\n",
            "Time taken for training worker 1: 0:00:24.864674\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.368999662, Training Accuracy: 39.648\n",
            "Worker 2, [02/9]: Training Loss: 2.023092927, Training Accuracy: 46.064\n",
            "Worker 2, [03/9]: Training Loss: 1.804553555, Training Accuracy: 50.528\n",
            "Worker 2, [04/9]: Training Loss: 1.616940221, Training Accuracy: 55.712\n",
            "Worker 2, [05/9]: Training Loss: 1.444303410, Training Accuracy: 59.504\n",
            "Worker 2, [06/9]: Training Loss: 1.243395330, Training Accuracy: 64.096\n",
            "Worker 2, [07/9]: Training Loss: 1.085745122, Training Accuracy: 68.944\n",
            "Worker 2, [08/9]: Training Loss: 0.976681330, Training Accuracy: 72.576\n",
            "Worker 2, [09/9]: Training Loss: 0.909155565, Training Accuracy: 74.512\n",
            "Time taken for training worker 2: 0:00:26.206198\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.363019363, Training Accuracy: 38.864\n",
            "Worker 3, [02/9]: Training Loss: 1.974010447, Training Accuracy: 46.784\n",
            "Worker 3, [03/9]: Training Loss: 1.778435537, Training Accuracy: 51.744\n",
            "Worker 3, [04/9]: Training Loss: 1.577007008, Training Accuracy: 56.016\n",
            "Worker 3, [05/9]: Training Loss: 1.422109387, Training Accuracy: 59.312\n",
            "Worker 3, [06/9]: Training Loss: 1.223534527, Training Accuracy: 65.072\n",
            "Worker 3, [07/9]: Training Loss: 1.058431144, Training Accuracy: 69.008\n",
            "Worker 3, [08/9]: Training Loss: 0.945505632, Training Accuracy: 73.040\n",
            "Worker 3, [09/9]: Training Loss: 0.868722258, Training Accuracy: 75.424\n",
            "Time taken for training worker 3: 0:00:24.776397\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.347775773, Training Accuracy: 39.408\n",
            "Worker 4, [02/9]: Training Loss: 1.995377071, Training Accuracy: 46.640\n",
            "Worker 4, [03/9]: Training Loss: 1.826481745, Training Accuracy: 50.656\n",
            "Worker 4, [04/9]: Training Loss: 1.582482843, Training Accuracy: 55.408\n",
            "Worker 4, [05/9]: Training Loss: 1.424848199, Training Accuracy: 60.288\n",
            "Worker 4, [06/9]: Training Loss: 1.231818763, Training Accuracy: 64.976\n",
            "Worker 4, [07/9]: Training Loss: 1.062345265, Training Accuracy: 70.192\n",
            "Worker 4, [08/9]: Training Loss: 0.943574665, Training Accuracy: 73.312\n",
            "Worker 4, [09/9]: Training Loss: 0.912240303, Training Accuracy: 74.256\n",
            "Time taken for training worker 4: 0:00:24.672080\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.337742804, Training Accuracy: 40.288\n",
            "Worker 5, [02/9]: Training Loss: 1.988936065, Training Accuracy: 46.896\n",
            "Worker 5, [03/9]: Training Loss: 1.788169861, Training Accuracy: 51.136\n",
            "Worker 5, [04/9]: Training Loss: 1.598477356, Training Accuracy: 55.376\n",
            "Worker 5, [05/9]: Training Loss: 1.428293437, Training Accuracy: 59.024\n",
            "Worker 5, [06/9]: Training Loss: 1.225084290, Training Accuracy: 65.312\n",
            "Worker 5, [07/9]: Training Loss: 1.074834374, Training Accuracy: 68.880\n",
            "Worker 5, [08/9]: Training Loss: 0.954042145, Training Accuracy: 73.264\n",
            "Worker 5, [09/9]: Training Loss: 0.892243071, Training Accuracy: 74.544\n",
            "Time taken for training worker 5: 0:00:26.358555\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.297973054, Training Accuracy: 40.928\n",
            "Worker 6, [02/9]: Training Loss: 1.971000364, Training Accuracy: 47.104\n",
            "Worker 6, [03/9]: Training Loss: 1.749649697, Training Accuracy: 51.696\n",
            "Worker 6, [04/9]: Training Loss: 1.551127416, Training Accuracy: 56.544\n",
            "Worker 6, [05/9]: Training Loss: 1.359839413, Training Accuracy: 61.296\n",
            "Worker 6, [06/9]: Training Loss: 1.194693238, Training Accuracy: 66.080\n",
            "Worker 6, [07/9]: Training Loss: 1.020980957, Training Accuracy: 70.384\n",
            "Worker 6, [08/9]: Training Loss: 0.922274887, Training Accuracy: 73.648\n",
            "Worker 6, [09/9]: Training Loss: 0.856115564, Training Accuracy: 75.360\n",
            "Time taken for training worker 6: 0:00:24.058013\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.316873190, Training Accuracy: 40.848\n",
            "Worker 7, [02/9]: Training Loss: 1.951075776, Training Accuracy: 47.504\n",
            "Worker 7, [03/9]: Training Loss: 1.749749495, Training Accuracy: 52.624\n",
            "Worker 7, [04/9]: Training Loss: 1.576091983, Training Accuracy: 56.464\n",
            "Worker 7, [05/9]: Training Loss: 1.353924359, Training Accuracy: 61.280\n",
            "Worker 7, [06/9]: Training Loss: 1.203690820, Training Accuracy: 65.232\n",
            "Worker 7, [07/9]: Training Loss: 1.042150863, Training Accuracy: 70.256\n",
            "Worker 7, [08/9]: Training Loss: 0.930919922, Training Accuracy: 73.664\n",
            "Worker 7, [09/9]: Training Loss: 0.861944496, Training Accuracy: 75.712\n",
            "Time taken for training worker 7: 0:00:24.761570\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.263620333, Training Accuracy: 41.520\n",
            "Worker 8, [02/9]: Training Loss: 1.937991261, Training Accuracy: 47.616\n",
            "Worker 8, [03/9]: Training Loss: 1.719883011, Training Accuracy: 52.192\n",
            "Worker 8, [04/9]: Training Loss: 1.533722665, Training Accuracy: 56.176\n",
            "Worker 8, [05/9]: Training Loss: 1.338020527, Training Accuracy: 61.824\n",
            "Worker 8, [06/9]: Training Loss: 1.157221440, Training Accuracy: 67.232\n",
            "Worker 8, [07/9]: Training Loss: 0.984643863, Training Accuracy: 71.152\n",
            "Worker 8, [08/9]: Training Loss: 0.878472003, Training Accuracy: 74.720\n",
            "Worker 8, [09/9]: Training Loss: 0.842372310, Training Accuracy: 75.728\n",
            "Time taken for training worker 8: 0:00:24.328992\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000898\n",
            "Local Step 05: Test Loss: 2.234679949, Test Accuracy: 47.910\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.172056798, Training Accuracy: 47.664\n",
            "Worker 1, [02/9]: Training Loss: 2.061681633, Training Accuracy: 48.144\n",
            "Worker 1, [03/9]: Training Loss: 1.930114871, Training Accuracy: 48.960\n",
            "Worker 1, [04/9]: Training Loss: 1.814925650, Training Accuracy: 50.688\n",
            "Worker 1, [05/9]: Training Loss: 1.744168549, Training Accuracy: 52.752\n",
            "Worker 1, [06/9]: Training Loss: 1.694754817, Training Accuracy: 53.760\n",
            "Worker 1, [07/9]: Training Loss: 1.609850542, Training Accuracy: 55.312\n",
            "Worker 1, [08/9]: Training Loss: 1.576148428, Training Accuracy: 56.624\n",
            "Worker 1, [09/9]: Training Loss: 1.577090081, Training Accuracy: 56.576\n",
            "Time taken for training worker 1: 0:00:25.093796\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.345863578, Training Accuracy: 40.256\n",
            "Worker 2, [02/9]: Training Loss: 2.144150376, Training Accuracy: 43.840\n",
            "Worker 2, [03/9]: Training Loss: 1.963729958, Training Accuracy: 47.616\n",
            "Worker 2, [04/9]: Training Loss: 1.861912742, Training Accuracy: 50.064\n",
            "Worker 2, [05/9]: Training Loss: 1.731278759, Training Accuracy: 52.528\n",
            "Worker 2, [06/9]: Training Loss: 1.696016040, Training Accuracy: 53.216\n",
            "Worker 2, [07/9]: Training Loss: 1.620084477, Training Accuracy: 54.416\n",
            "Worker 2, [08/9]: Training Loss: 1.565128444, Training Accuracy: 55.872\n",
            "Worker 2, [09/9]: Training Loss: 1.542627211, Training Accuracy: 57.472\n",
            "Time taken for training worker 2: 0:00:23.924510\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.231264321, Training Accuracy: 42.624\n",
            "Worker 3, [02/9]: Training Loss: 2.091015491, Training Accuracy: 45.296\n",
            "Worker 3, [03/9]: Training Loss: 1.938575863, Training Accuracy: 48.096\n",
            "Worker 3, [04/9]: Training Loss: 1.825670066, Training Accuracy: 50.352\n",
            "Worker 3, [05/9]: Training Loss: 1.714324887, Training Accuracy: 53.168\n",
            "Worker 3, [06/9]: Training Loss: 1.637572758, Training Accuracy: 54.048\n",
            "Worker 3, [07/9]: Training Loss: 1.575018649, Training Accuracy: 55.856\n",
            "Worker 3, [08/9]: Training Loss: 1.573532106, Training Accuracy: 55.968\n",
            "Worker 3, [09/9]: Training Loss: 1.527431439, Training Accuracy: 56.224\n",
            "Time taken for training worker 3: 0:00:25.629120\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.241567250, Training Accuracy: 41.392\n",
            "Worker 4, [02/9]: Training Loss: 2.091386581, Training Accuracy: 44.752\n",
            "Worker 4, [03/9]: Training Loss: 1.929152447, Training Accuracy: 48.336\n",
            "Worker 4, [04/9]: Training Loss: 1.808579981, Training Accuracy: 51.232\n",
            "Worker 4, [05/9]: Training Loss: 1.698709530, Training Accuracy: 53.904\n",
            "Worker 4, [06/9]: Training Loss: 1.657603754, Training Accuracy: 54.304\n",
            "Worker 4, [07/9]: Training Loss: 1.598697002, Training Accuracy: 54.992\n",
            "Worker 4, [08/9]: Training Loss: 1.537330887, Training Accuracy: 56.528\n",
            "Worker 4, [09/9]: Training Loss: 1.538764618, Training Accuracy: 56.880\n",
            "Time taken for training worker 4: 0:00:24.964966\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.363333001, Training Accuracy: 40.816\n",
            "Worker 5, [02/9]: Training Loss: 2.137723029, Training Accuracy: 43.840\n",
            "Worker 5, [03/9]: Training Loss: 1.962930375, Training Accuracy: 47.024\n",
            "Worker 5, [04/9]: Training Loss: 1.822328575, Training Accuracy: 50.160\n",
            "Worker 5, [05/9]: Training Loss: 1.708441257, Training Accuracy: 53.664\n",
            "Worker 5, [06/9]: Training Loss: 1.642499129, Training Accuracy: 54.832\n",
            "Worker 5, [07/9]: Training Loss: 1.596499186, Training Accuracy: 55.776\n",
            "Worker 5, [08/9]: Training Loss: 1.576172448, Training Accuracy: 55.568\n",
            "Worker 5, [09/9]: Training Loss: 1.492380676, Training Accuracy: 57.952\n",
            "Time taken for training worker 5: 0:00:25.464879\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.374587407, Training Accuracy: 39.760\n",
            "Worker 6, [02/9]: Training Loss: 2.147583230, Training Accuracy: 44.064\n",
            "Worker 6, [03/9]: Training Loss: 1.916756540, Training Accuracy: 48.528\n",
            "Worker 6, [04/9]: Training Loss: 1.777453769, Training Accuracy: 51.824\n",
            "Worker 6, [05/9]: Training Loss: 1.682981888, Training Accuracy: 53.776\n",
            "Worker 6, [06/9]: Training Loss: 1.578525079, Training Accuracy: 55.360\n",
            "Worker 6, [07/9]: Training Loss: 1.551082895, Training Accuracy: 56.944\n",
            "Worker 6, [08/9]: Training Loss: 1.517345529, Training Accuracy: 56.560\n",
            "Worker 6, [09/9]: Training Loss: 1.478270973, Training Accuracy: 57.840\n",
            "Time taken for training worker 6: 0:00:23.756639\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.242414319, Training Accuracy: 43.104\n",
            "Worker 7, [02/9]: Training Loss: 2.075963728, Training Accuracy: 45.440\n",
            "Worker 7, [03/9]: Training Loss: 1.915997101, Training Accuracy: 48.672\n",
            "Worker 7, [04/9]: Training Loss: 1.772007246, Training Accuracy: 51.440\n",
            "Worker 7, [05/9]: Training Loss: 1.675345766, Training Accuracy: 54.224\n",
            "Worker 7, [06/9]: Training Loss: 1.601735003, Training Accuracy: 56.000\n",
            "Worker 7, [07/9]: Training Loss: 1.523834905, Training Accuracy: 56.896\n",
            "Worker 7, [08/9]: Training Loss: 1.529892702, Training Accuracy: 56.272\n",
            "Worker 7, [09/9]: Training Loss: 1.447400138, Training Accuracy: 58.800\n",
            "Time taken for training worker 7: 0:00:23.852198\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.275460664, Training Accuracy: 41.136\n",
            "Worker 8, [02/9]: Training Loss: 2.057774664, Training Accuracy: 45.456\n",
            "Worker 8, [03/9]: Training Loss: 1.882503561, Training Accuracy: 49.312\n",
            "Worker 8, [04/9]: Training Loss: 1.744438472, Training Accuracy: 51.536\n",
            "Worker 8, [05/9]: Training Loss: 1.623677884, Training Accuracy: 53.728\n",
            "Worker 8, [06/9]: Training Loss: 1.546616257, Training Accuracy: 56.480\n",
            "Worker 8, [07/9]: Training Loss: 1.532632605, Training Accuracy: 56.832\n",
            "Worker 8, [08/9]: Training Loss: 1.511983461, Training Accuracy: 57.056\n",
            "Worker 8, [09/9]: Training Loss: 1.435647000, Training Accuracy: 58.368\n",
            "Time taken for training worker 8: 0:00:26.527475\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000738\n",
            "Local Step 06: Test Loss: 2.357929615, Test Accuracy: 42.660\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.239024432, Training Accuracy: 41.104\n",
            "Worker 1, [02/9]: Training Loss: 1.823583534, Training Accuracy: 50.112\n",
            "Worker 1, [03/9]: Training Loss: 1.627500005, Training Accuracy: 55.216\n",
            "Worker 1, [04/9]: Training Loss: 1.425015651, Training Accuracy: 59.744\n",
            "Worker 1, [05/9]: Training Loss: 1.206312786, Training Accuracy: 66.032\n",
            "Worker 1, [06/9]: Training Loss: 1.048836403, Training Accuracy: 69.392\n",
            "Worker 1, [07/9]: Training Loss: 0.891066515, Training Accuracy: 75.024\n",
            "Worker 1, [08/9]: Training Loss: 0.782365800, Training Accuracy: 78.096\n",
            "Worker 1, [09/9]: Training Loss: 0.740570515, Training Accuracy: 79.136\n",
            "Time taken for training worker 1: 0:00:23.586593\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.241300683, Training Accuracy: 42.288\n",
            "Worker 2, [02/9]: Training Loss: 1.844298222, Training Accuracy: 49.584\n",
            "Worker 2, [03/9]: Training Loss: 1.639853091, Training Accuracy: 54.400\n",
            "Worker 2, [04/9]: Training Loss: 1.443724742, Training Accuracy: 58.976\n",
            "Worker 2, [05/9]: Training Loss: 1.224322242, Training Accuracy: 64.880\n",
            "Worker 2, [06/9]: Training Loss: 1.050422411, Training Accuracy: 69.904\n",
            "Worker 2, [07/9]: Training Loss: 0.899902831, Training Accuracy: 74.384\n",
            "Worker 2, [08/9]: Training Loss: 0.777184453, Training Accuracy: 78.208\n",
            "Worker 2, [09/9]: Training Loss: 0.727183131, Training Accuracy: 79.792\n",
            "Time taken for training worker 2: 0:00:24.152167\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.203579091, Training Accuracy: 42.640\n",
            "Worker 3, [02/9]: Training Loss: 1.800769581, Training Accuracy: 50.992\n",
            "Worker 3, [03/9]: Training Loss: 1.580046818, Training Accuracy: 55.920\n",
            "Worker 3, [04/9]: Training Loss: 1.401151669, Training Accuracy: 60.752\n",
            "Worker 3, [05/9]: Training Loss: 1.167622476, Training Accuracy: 66.256\n",
            "Worker 3, [06/9]: Training Loss: 0.983209773, Training Accuracy: 71.072\n",
            "Worker 3, [07/9]: Training Loss: 0.867768442, Training Accuracy: 74.640\n",
            "Worker 3, [08/9]: Training Loss: 0.762543568, Training Accuracy: 77.728\n",
            "Worker 3, [09/9]: Training Loss: 0.699975787, Training Accuracy: 79.808\n",
            "Time taken for training worker 3: 0:00:24.082892\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.219610867, Training Accuracy: 42.992\n",
            "Worker 4, [02/9]: Training Loss: 1.816930453, Training Accuracy: 50.144\n",
            "Worker 4, [03/9]: Training Loss: 1.599170383, Training Accuracy: 55.968\n",
            "Worker 4, [04/9]: Training Loss: 1.416706284, Training Accuracy: 60.624\n",
            "Worker 4, [05/9]: Training Loss: 1.195691230, Training Accuracy: 65.712\n",
            "Worker 4, [06/9]: Training Loss: 1.047352737, Training Accuracy: 69.616\n",
            "Worker 4, [07/9]: Training Loss: 0.864758123, Training Accuracy: 74.736\n",
            "Worker 4, [08/9]: Training Loss: 0.757827562, Training Accuracy: 77.968\n",
            "Worker 4, [09/9]: Training Loss: 0.721094347, Training Accuracy: 78.992\n",
            "Time taken for training worker 4: 0:00:23.966520\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.233750739, Training Accuracy: 41.648\n",
            "Worker 5, [02/9]: Training Loss: 1.820139459, Training Accuracy: 50.432\n",
            "Worker 5, [03/9]: Training Loss: 1.616515607, Training Accuracy: 55.472\n",
            "Worker 5, [04/9]: Training Loss: 1.423771326, Training Accuracy: 59.888\n",
            "Worker 5, [05/9]: Training Loss: 1.225575586, Training Accuracy: 64.608\n",
            "Worker 5, [06/9]: Training Loss: 1.030571065, Training Accuracy: 70.160\n",
            "Worker 5, [07/9]: Training Loss: 0.880813074, Training Accuracy: 74.496\n",
            "Worker 5, [08/9]: Training Loss: 0.792963916, Training Accuracy: 77.472\n",
            "Worker 5, [09/9]: Training Loss: 0.729178133, Training Accuracy: 78.832\n",
            "Time taken for training worker 5: 0:00:24.519850\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.165336491, Training Accuracy: 43.408\n",
            "Worker 6, [02/9]: Training Loss: 1.862141724, Training Accuracy: 49.744\n",
            "Worker 6, [03/9]: Training Loss: 1.603989362, Training Accuracy: 54.768\n",
            "Worker 6, [04/9]: Training Loss: 1.381434055, Training Accuracy: 60.624\n",
            "Worker 6, [05/9]: Training Loss: 1.207212941, Training Accuracy: 64.992\n",
            "Worker 6, [06/9]: Training Loss: 1.009305961, Training Accuracy: 71.056\n",
            "Worker 6, [07/9]: Training Loss: 0.856421244, Training Accuracy: 75.520\n",
            "Worker 6, [08/9]: Training Loss: 0.762596226, Training Accuracy: 78.512\n",
            "Worker 6, [09/9]: Training Loss: 0.723301975, Training Accuracy: 79.376\n",
            "Time taken for training worker 6: 0:00:23.577770\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.162396916, Training Accuracy: 43.904\n",
            "Worker 7, [02/9]: Training Loss: 1.811894822, Training Accuracy: 50.720\n",
            "Worker 7, [03/9]: Training Loss: 1.570621246, Training Accuracy: 56.560\n",
            "Worker 7, [04/9]: Training Loss: 1.395414919, Training Accuracy: 60.720\n",
            "Worker 7, [05/9]: Training Loss: 1.187538412, Training Accuracy: 66.096\n",
            "Worker 7, [06/9]: Training Loss: 1.035783943, Training Accuracy: 69.648\n",
            "Worker 7, [07/9]: Training Loss: 0.882976296, Training Accuracy: 74.560\n",
            "Worker 7, [08/9]: Training Loss: 0.754060083, Training Accuracy: 78.592\n",
            "Worker 7, [09/9]: Training Loss: 0.713423458, Training Accuracy: 79.648\n",
            "Time taken for training worker 7: 0:00:24.977509\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.150576573, Training Accuracy: 43.712\n",
            "Worker 8, [02/9]: Training Loss: 1.798692930, Training Accuracy: 50.080\n",
            "Worker 8, [03/9]: Training Loss: 1.562888672, Training Accuracy: 56.624\n",
            "Worker 8, [04/9]: Training Loss: 1.374394701, Training Accuracy: 60.960\n",
            "Worker 8, [05/9]: Training Loss: 1.179549954, Training Accuracy: 65.856\n",
            "Worker 8, [06/9]: Training Loss: 1.004242823, Training Accuracy: 70.640\n",
            "Worker 8, [07/9]: Training Loss: 0.839101570, Training Accuracy: 76.544\n",
            "Worker 8, [08/9]: Training Loss: 0.726989696, Training Accuracy: 79.184\n",
            "Worker 8, [09/9]: Training Loss: 0.678588478, Training Accuracy: 80.272\n",
            "Time taken for training worker 8: 0:00:25.558633\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000755\n",
            "Local Step 07: Test Loss: 2.234288189, Test Accuracy: 49.320\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.067161783, Training Accuracy: 49.200\n",
            "Worker 1, [02/9]: Training Loss: 1.972358715, Training Accuracy: 49.936\n",
            "Worker 1, [03/9]: Training Loss: 1.812841683, Training Accuracy: 51.728\n",
            "Worker 1, [04/9]: Training Loss: 1.694195075, Training Accuracy: 53.648\n",
            "Worker 1, [05/9]: Training Loss: 1.597664725, Training Accuracy: 56.688\n",
            "Worker 1, [06/9]: Training Loss: 1.521093982, Training Accuracy: 57.808\n",
            "Worker 1, [07/9]: Training Loss: 1.450945760, Training Accuracy: 58.976\n",
            "Worker 1, [08/9]: Training Loss: 1.415475665, Training Accuracy: 59.664\n",
            "Worker 1, [09/9]: Training Loss: 1.421687289, Training Accuracy: 58.864\n",
            "Time taken for training worker 1: 0:00:25.871256\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.234654997, Training Accuracy: 43.456\n",
            "Worker 2, [02/9]: Training Loss: 2.058595033, Training Accuracy: 46.160\n",
            "Worker 2, [03/9]: Training Loss: 1.902306119, Training Accuracy: 48.992\n",
            "Worker 2, [04/9]: Training Loss: 1.742333947, Training Accuracy: 52.464\n",
            "Worker 2, [05/9]: Training Loss: 1.594766658, Training Accuracy: 55.904\n",
            "Worker 2, [06/9]: Training Loss: 1.511215915, Training Accuracy: 57.952\n",
            "Worker 2, [07/9]: Training Loss: 1.491182349, Training Accuracy: 57.376\n",
            "Worker 2, [08/9]: Training Loss: 1.463957760, Training Accuracy: 58.368\n",
            "Worker 2, [09/9]: Training Loss: 1.389026732, Training Accuracy: 60.272\n",
            "Time taken for training worker 2: 0:00:23.604647\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.246343475, Training Accuracy: 42.864\n",
            "Worker 3, [02/9]: Training Loss: 2.010827755, Training Accuracy: 47.376\n",
            "Worker 3, [03/9]: Training Loss: 1.844066245, Training Accuracy: 50.576\n",
            "Worker 3, [04/9]: Training Loss: 1.712831147, Training Accuracy: 52.832\n",
            "Worker 3, [05/9]: Training Loss: 1.589319847, Training Accuracy: 55.760\n",
            "Worker 3, [06/9]: Training Loss: 1.481744142, Training Accuracy: 58.736\n",
            "Worker 3, [07/9]: Training Loss: 1.450205089, Training Accuracy: 58.912\n",
            "Worker 3, [08/9]: Training Loss: 1.393882262, Training Accuracy: 60.320\n",
            "Worker 3, [09/9]: Training Loss: 1.368342341, Training Accuracy: 60.336\n",
            "Time taken for training worker 3: 0:00:24.067706\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.332834566, Training Accuracy: 43.104\n",
            "Worker 4, [02/9]: Training Loss: 2.047723220, Training Accuracy: 47.712\n",
            "Worker 4, [03/9]: Training Loss: 1.838706246, Training Accuracy: 51.072\n",
            "Worker 4, [04/9]: Training Loss: 1.698187217, Training Accuracy: 53.872\n",
            "Worker 4, [05/9]: Training Loss: 1.591357378, Training Accuracy: 56.128\n",
            "Worker 4, [06/9]: Training Loss: 1.504974006, Training Accuracy: 57.744\n",
            "Worker 4, [07/9]: Training Loss: 1.478018266, Training Accuracy: 58.304\n",
            "Worker 4, [08/9]: Training Loss: 1.420256520, Training Accuracy: 59.424\n",
            "Worker 4, [09/9]: Training Loss: 1.356851175, Training Accuracy: 61.056\n",
            "Time taken for training worker 4: 0:00:24.983350\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.219997959, Training Accuracy: 43.776\n",
            "Worker 5, [02/9]: Training Loss: 2.006610741, Training Accuracy: 47.136\n",
            "Worker 5, [03/9]: Training Loss: 1.852248383, Training Accuracy: 50.176\n",
            "Worker 5, [04/9]: Training Loss: 1.695650958, Training Accuracy: 53.856\n",
            "Worker 5, [05/9]: Training Loss: 1.597617398, Training Accuracy: 55.296\n",
            "Worker 5, [06/9]: Training Loss: 1.512250607, Training Accuracy: 57.296\n",
            "Worker 5, [07/9]: Training Loss: 1.442449795, Training Accuracy: 58.928\n",
            "Worker 5, [08/9]: Training Loss: 1.460117200, Training Accuracy: 58.768\n",
            "Worker 5, [09/9]: Training Loss: 1.389369111, Training Accuracy: 60.288\n",
            "Time taken for training worker 5: 0:00:24.119723\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.176524538, Training Accuracy: 45.264\n",
            "Worker 6, [02/9]: Training Loss: 2.001540039, Training Accuracy: 47.600\n",
            "Worker 6, [03/9]: Training Loss: 1.821797174, Training Accuracy: 51.408\n",
            "Worker 6, [04/9]: Training Loss: 1.676892766, Training Accuracy: 54.272\n",
            "Worker 6, [05/9]: Training Loss: 1.559271429, Training Accuracy: 56.256\n",
            "Worker 6, [06/9]: Training Loss: 1.489360886, Training Accuracy: 58.560\n",
            "Worker 6, [07/9]: Training Loss: 1.413437014, Training Accuracy: 60.080\n",
            "Worker 6, [08/9]: Training Loss: 1.390895406, Training Accuracy: 60.224\n",
            "Worker 6, [09/9]: Training Loss: 1.362960916, Training Accuracy: 60.656\n",
            "Time taken for training worker 6: 0:00:24.587132\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.130627889, Training Accuracy: 45.008\n",
            "Worker 7, [02/9]: Training Loss: 1.958624122, Training Accuracy: 48.768\n",
            "Worker 7, [03/9]: Training Loss: 1.815744879, Training Accuracy: 50.896\n",
            "Worker 7, [04/9]: Training Loss: 1.675181980, Training Accuracy: 54.672\n",
            "Worker 7, [05/9]: Training Loss: 1.564639161, Training Accuracy: 56.288\n",
            "Worker 7, [06/9]: Training Loss: 1.487364494, Training Accuracy: 57.872\n",
            "Worker 7, [07/9]: Training Loss: 1.439167051, Training Accuracy: 59.360\n",
            "Worker 7, [08/9]: Training Loss: 1.362538183, Training Accuracy: 61.248\n",
            "Worker 7, [09/9]: Training Loss: 1.335558548, Training Accuracy: 62.016\n",
            "Time taken for training worker 7: 0:00:24.488647\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.175106564, Training Accuracy: 43.952\n",
            "Worker 8, [02/9]: Training Loss: 1.964608216, Training Accuracy: 48.096\n",
            "Worker 8, [03/9]: Training Loss: 1.756280818, Training Accuracy: 51.632\n",
            "Worker 8, [04/9]: Training Loss: 1.632130488, Training Accuracy: 54.480\n",
            "Worker 8, [05/9]: Training Loss: 1.546835238, Training Accuracy: 55.920\n",
            "Worker 8, [06/9]: Training Loss: 1.457895967, Training Accuracy: 58.688\n",
            "Worker 8, [07/9]: Training Loss: 1.435629555, Training Accuracy: 58.336\n",
            "Worker 8, [08/9]: Training Loss: 1.359251657, Training Accuracy: 61.344\n",
            "Worker 8, [09/9]: Training Loss: 1.285818087, Training Accuracy: 62.416\n",
            "Time taken for training worker 8: 0:00:25.353544\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000759\n",
            "Local Step 08: Test Loss: 2.419157465, Test Accuracy: 42.680\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.109510660, Training Accuracy: 44.544\n",
            "Worker 1, [02/9]: Training Loss: 1.722947528, Training Accuracy: 52.880\n",
            "Worker 1, [03/9]: Training Loss: 1.495648796, Training Accuracy: 57.728\n",
            "Worker 1, [04/9]: Training Loss: 1.295084690, Training Accuracy: 63.328\n",
            "Worker 1, [05/9]: Training Loss: 1.093726016, Training Accuracy: 68.832\n",
            "Worker 1, [06/9]: Training Loss: 0.933266789, Training Accuracy: 73.216\n",
            "Worker 1, [07/9]: Training Loss: 0.774264017, Training Accuracy: 77.824\n",
            "Worker 1, [08/9]: Training Loss: 0.691770440, Training Accuracy: 80.752\n",
            "Worker 1, [09/9]: Training Loss: 0.621768467, Training Accuracy: 82.400\n",
            "Time taken for training worker 1: 0:00:23.784411\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.128327750, Training Accuracy: 44.352\n",
            "Worker 2, [02/9]: Training Loss: 1.742588715, Training Accuracy: 52.240\n",
            "Worker 2, [03/9]: Training Loss: 1.541213038, Training Accuracy: 56.480\n",
            "Worker 2, [04/9]: Training Loss: 1.322761713, Training Accuracy: 63.216\n",
            "Worker 2, [05/9]: Training Loss: 1.096970814, Training Accuracy: 68.432\n",
            "Worker 2, [06/9]: Training Loss: 0.916047225, Training Accuracy: 73.104\n",
            "Worker 2, [07/9]: Training Loss: 0.768672756, Training Accuracy: 77.696\n",
            "Worker 2, [08/9]: Training Loss: 0.662017298, Training Accuracy: 80.944\n",
            "Worker 2, [09/9]: Training Loss: 0.613002385, Training Accuracy: 82.672\n",
            "Time taken for training worker 2: 0:00:24.038138\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.134771610, Training Accuracy: 43.808\n",
            "Worker 3, [02/9]: Training Loss: 1.728825311, Training Accuracy: 52.672\n",
            "Worker 3, [03/9]: Training Loss: 1.513527388, Training Accuracy: 56.720\n",
            "Worker 3, [04/9]: Training Loss: 1.307020378, Training Accuracy: 62.176\n",
            "Worker 3, [05/9]: Training Loss: 1.078646074, Training Accuracy: 68.000\n",
            "Worker 3, [06/9]: Training Loss: 0.905978882, Training Accuracy: 73.200\n",
            "Worker 3, [07/9]: Training Loss: 0.769980024, Training Accuracy: 77.712\n",
            "Worker 3, [08/9]: Training Loss: 0.662406420, Training Accuracy: 80.896\n",
            "Worker 3, [09/9]: Training Loss: 0.610954830, Training Accuracy: 82.160\n",
            "Time taken for training worker 3: 0:00:24.084479\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.150432495, Training Accuracy: 44.160\n",
            "Worker 4, [02/9]: Training Loss: 1.735467171, Training Accuracy: 52.496\n",
            "Worker 4, [03/9]: Training Loss: 1.498206075, Training Accuracy: 57.760\n",
            "Worker 4, [04/9]: Training Loss: 1.315818860, Training Accuracy: 62.768\n",
            "Worker 4, [05/9]: Training Loss: 1.082495359, Training Accuracy: 68.416\n",
            "Worker 4, [06/9]: Training Loss: 0.929942775, Training Accuracy: 72.816\n",
            "Worker 4, [07/9]: Training Loss: 0.790494954, Training Accuracy: 77.152\n",
            "Worker 4, [08/9]: Training Loss: 0.697148222, Training Accuracy: 79.600\n",
            "Worker 4, [09/9]: Training Loss: 0.610907981, Training Accuracy: 82.800\n",
            "Time taken for training worker 4: 0:00:25.649107\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.164783758, Training Accuracy: 43.696\n",
            "Worker 5, [02/9]: Training Loss: 1.779881035, Training Accuracy: 52.032\n",
            "Worker 5, [03/9]: Training Loss: 1.552390346, Training Accuracy: 56.576\n",
            "Worker 5, [04/9]: Training Loss: 1.345887697, Training Accuracy: 62.304\n",
            "Worker 5, [05/9]: Training Loss: 1.133791306, Training Accuracy: 67.840\n",
            "Worker 5, [06/9]: Training Loss: 0.924199324, Training Accuracy: 72.624\n",
            "Worker 5, [07/9]: Training Loss: 0.803324377, Training Accuracy: 76.688\n",
            "Worker 5, [08/9]: Training Loss: 0.701080476, Training Accuracy: 79.344\n",
            "Worker 5, [09/9]: Training Loss: 0.632117019, Training Accuracy: 81.808\n",
            "Time taken for training worker 5: 0:00:24.048378\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.115787803, Training Accuracy: 45.120\n",
            "Worker 6, [02/9]: Training Loss: 1.732269146, Training Accuracy: 51.600\n",
            "Worker 6, [03/9]: Training Loss: 1.490100744, Training Accuracy: 58.176\n",
            "Worker 6, [04/9]: Training Loss: 1.280087925, Training Accuracy: 62.832\n",
            "Worker 6, [05/9]: Training Loss: 1.081298717, Training Accuracy: 68.816\n",
            "Worker 6, [06/9]: Training Loss: 0.909537007, Training Accuracy: 74.320\n",
            "Worker 6, [07/9]: Training Loss: 0.777743845, Training Accuracy: 77.184\n",
            "Worker 6, [08/9]: Training Loss: 0.668500971, Training Accuracy: 80.864\n",
            "Worker 6, [09/9]: Training Loss: 0.617707030, Training Accuracy: 83.216\n",
            "Time taken for training worker 6: 0:00:25.526898\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.143265367, Training Accuracy: 44.448\n",
            "Worker 7, [02/9]: Training Loss: 1.701663461, Training Accuracy: 53.872\n",
            "Worker 7, [03/9]: Training Loss: 1.519100059, Training Accuracy: 57.232\n",
            "Worker 7, [04/9]: Training Loss: 1.296488787, Training Accuracy: 63.200\n",
            "Worker 7, [05/9]: Training Loss: 1.106823696, Training Accuracy: 68.080\n",
            "Worker 7, [06/9]: Training Loss: 0.941862932, Training Accuracy: 73.168\n",
            "Worker 7, [07/9]: Training Loss: 0.786855177, Training Accuracy: 77.392\n",
            "Worker 7, [08/9]: Training Loss: 0.677700596, Training Accuracy: 80.240\n",
            "Worker 7, [09/9]: Training Loss: 0.621435960, Training Accuracy: 82.400\n",
            "Time taken for training worker 7: 0:00:24.721787\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.109051017, Training Accuracy: 44.544\n",
            "Worker 8, [02/9]: Training Loss: 1.710142493, Training Accuracy: 52.496\n",
            "Worker 8, [03/9]: Training Loss: 1.500971306, Training Accuracy: 57.472\n",
            "Worker 8, [04/9]: Training Loss: 1.304136133, Training Accuracy: 62.992\n",
            "Worker 8, [05/9]: Training Loss: 1.077848153, Training Accuracy: 68.336\n",
            "Worker 8, [06/9]: Training Loss: 0.910265322, Training Accuracy: 73.488\n",
            "Worker 8, [07/9]: Training Loss: 0.756853854, Training Accuracy: 78.000\n",
            "Worker 8, [08/9]: Training Loss: 0.654537259, Training Accuracy: 81.200\n",
            "Worker 8, [09/9]: Training Loss: 0.614950601, Training Accuracy: 82.784\n",
            "Time taken for training worker 8: 0:00:23.667081\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000931\n",
            "Local Step 09: Test Loss: 2.257257449, Test Accuracy: 49.390\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.033523168, Training Accuracy: 50.016\n",
            "Worker 1, [02/9]: Training Loss: 1.914238348, Training Accuracy: 51.408\n",
            "Worker 1, [03/9]: Training Loss: 1.758677214, Training Accuracy: 52.896\n",
            "Worker 1, [04/9]: Training Loss: 1.615106690, Training Accuracy: 55.648\n",
            "Worker 1, [05/9]: Training Loss: 1.519783115, Training Accuracy: 56.976\n",
            "Worker 1, [06/9]: Training Loss: 1.430617219, Training Accuracy: 60.624\n",
            "Worker 1, [07/9]: Training Loss: 1.391357855, Training Accuracy: 60.496\n",
            "Worker 1, [08/9]: Training Loss: 1.336035817, Training Accuracy: 62.272\n",
            "Worker 1, [09/9]: Training Loss: 1.287823923, Training Accuracy: 63.120\n",
            "Time taken for training worker 1: 0:00:23.464535\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.211378299, Training Accuracy: 44.816\n",
            "Worker 2, [02/9]: Training Loss: 1.986469366, Training Accuracy: 47.584\n",
            "Worker 2, [03/9]: Training Loss: 1.828423077, Training Accuracy: 50.176\n",
            "Worker 2, [04/9]: Training Loss: 1.647935074, Training Accuracy: 55.088\n",
            "Worker 2, [05/9]: Training Loss: 1.533387556, Training Accuracy: 56.976\n",
            "Worker 2, [06/9]: Training Loss: 1.445712496, Training Accuracy: 59.328\n",
            "Worker 2, [07/9]: Training Loss: 1.377838743, Training Accuracy: 60.496\n",
            "Worker 2, [08/9]: Training Loss: 1.356595737, Training Accuracy: 61.616\n",
            "Worker 2, [09/9]: Training Loss: 1.307165558, Training Accuracy: 62.096\n",
            "Time taken for training worker 2: 0:00:23.961225\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.155070318, Training Accuracy: 46.320\n",
            "Worker 3, [02/9]: Training Loss: 1.939322989, Training Accuracy: 48.224\n",
            "Worker 3, [03/9]: Training Loss: 1.760213700, Training Accuracy: 52.368\n",
            "Worker 3, [04/9]: Training Loss: 1.629169052, Training Accuracy: 54.976\n",
            "Worker 3, [05/9]: Training Loss: 1.507750109, Training Accuracy: 57.712\n",
            "Worker 3, [06/9]: Training Loss: 1.403686340, Training Accuracy: 60.064\n",
            "Worker 3, [07/9]: Training Loss: 1.361503649, Training Accuracy: 61.120\n",
            "Worker 3, [08/9]: Training Loss: 1.342087836, Training Accuracy: 61.616\n",
            "Worker 3, [09/9]: Training Loss: 1.308233261, Training Accuracy: 62.400\n",
            "Time taken for training worker 3: 0:00:24.860697\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.106937670, Training Accuracy: 45.648\n",
            "Worker 4, [02/9]: Training Loss: 1.940801332, Training Accuracy: 49.696\n",
            "Worker 4, [03/9]: Training Loss: 1.758177731, Training Accuracy: 52.416\n",
            "Worker 4, [04/9]: Training Loss: 1.612658787, Training Accuracy: 55.216\n",
            "Worker 4, [05/9]: Training Loss: 1.508834329, Training Accuracy: 57.632\n",
            "Worker 4, [06/9]: Training Loss: 1.433872147, Training Accuracy: 59.248\n",
            "Worker 4, [07/9]: Training Loss: 1.368274593, Training Accuracy: 61.584\n",
            "Worker 4, [08/9]: Training Loss: 1.344376487, Training Accuracy: 61.696\n",
            "Worker 4, [09/9]: Training Loss: 1.280999895, Training Accuracy: 63.568\n",
            "Time taken for training worker 4: 0:00:24.011347\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.286766653, Training Accuracy: 42.720\n",
            "Worker 5, [02/9]: Training Loss: 1.965081463, Training Accuracy: 48.208\n",
            "Worker 5, [03/9]: Training Loss: 1.780007600, Training Accuracy: 52.176\n",
            "Worker 5, [04/9]: Training Loss: 1.643022630, Training Accuracy: 54.880\n",
            "Worker 5, [05/9]: Training Loss: 1.500244235, Training Accuracy: 57.792\n",
            "Worker 5, [06/9]: Training Loss: 1.432604494, Training Accuracy: 59.744\n",
            "Worker 5, [07/9]: Training Loss: 1.371235199, Training Accuracy: 60.832\n",
            "Worker 5, [08/9]: Training Loss: 1.336374195, Training Accuracy: 61.152\n",
            "Worker 5, [09/9]: Training Loss: 1.301410449, Training Accuracy: 62.800\n",
            "Time taken for training worker 5: 0:00:25.267207\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.150343300, Training Accuracy: 45.248\n",
            "Worker 6, [02/9]: Training Loss: 1.942329694, Training Accuracy: 48.512\n",
            "Worker 6, [03/9]: Training Loss: 1.762026474, Training Accuracy: 52.400\n",
            "Worker 6, [04/9]: Training Loss: 1.582470968, Training Accuracy: 56.080\n",
            "Worker 6, [05/9]: Training Loss: 1.496818905, Training Accuracy: 58.272\n",
            "Worker 6, [06/9]: Training Loss: 1.392198289, Training Accuracy: 60.864\n",
            "Worker 6, [07/9]: Training Loss: 1.362935080, Training Accuracy: 61.776\n",
            "Worker 6, [08/9]: Training Loss: 1.323466185, Training Accuracy: 62.784\n",
            "Worker 6, [09/9]: Training Loss: 1.284119798, Training Accuracy: 62.768\n",
            "Time taken for training worker 6: 0:00:23.836127\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.149825620, Training Accuracy: 46.272\n",
            "Worker 7, [02/9]: Training Loss: 1.961264965, Training Accuracy: 48.800\n",
            "Worker 7, [03/9]: Training Loss: 1.796275121, Training Accuracy: 51.680\n",
            "Worker 7, [04/9]: Training Loss: 1.653901120, Training Accuracy: 55.168\n",
            "Worker 7, [05/9]: Training Loss: 1.515973302, Training Accuracy: 57.520\n",
            "Worker 7, [06/9]: Training Loss: 1.406313272, Training Accuracy: 59.728\n",
            "Worker 7, [07/9]: Training Loss: 1.376866369, Training Accuracy: 61.360\n",
            "Worker 7, [08/9]: Training Loss: 1.299172567, Training Accuracy: 62.992\n",
            "Worker 7, [09/9]: Training Loss: 1.306324640, Training Accuracy: 62.656\n",
            "Time taken for training worker 7: 0:00:24.608716\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.135985029, Training Accuracy: 45.616\n",
            "Worker 8, [02/9]: Training Loss: 1.893835418, Training Accuracy: 49.808\n",
            "Worker 8, [03/9]: Training Loss: 1.724345762, Training Accuracy: 52.736\n",
            "Worker 8, [04/9]: Training Loss: 1.564946347, Training Accuracy: 56.192\n",
            "Worker 8, [05/9]: Training Loss: 1.488071641, Training Accuracy: 57.936\n",
            "Worker 8, [06/9]: Training Loss: 1.392395610, Training Accuracy: 60.704\n",
            "Worker 8, [07/9]: Training Loss: 1.340131380, Training Accuracy: 61.696\n",
            "Worker 8, [08/9]: Training Loss: 1.296567657, Training Accuracy: 62.768\n",
            "Worker 8, [09/9]: Training Loss: 1.284660582, Training Accuracy: 63.024\n",
            "Time taken for training worker 8: 0:00:23.948313\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000864\n",
            "Local Step 10: Test Loss: 2.335398704, Test Accuracy: 44.450\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.065366250, Training Accuracy: 45.648\n",
            "Worker 1, [02/9]: Training Loss: 1.653979188, Training Accuracy: 54.592\n",
            "Worker 1, [03/9]: Training Loss: 1.435240325, Training Accuracy: 60.144\n",
            "Worker 1, [04/9]: Training Loss: 1.198370465, Training Accuracy: 65.568\n",
            "Worker 1, [05/9]: Training Loss: 1.042139311, Training Accuracy: 70.448\n",
            "Worker 1, [06/9]: Training Loss: 0.855613369, Training Accuracy: 75.280\n",
            "Worker 1, [07/9]: Training Loss: 0.716179607, Training Accuracy: 80.336\n",
            "Worker 1, [08/9]: Training Loss: 0.629972024, Training Accuracy: 81.792\n",
            "Worker 1, [09/9]: Training Loss: 0.570316629, Training Accuracy: 84.032\n",
            "Time taken for training worker 1: 0:00:24.413776\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.070367890, Training Accuracy: 45.456\n",
            "Worker 2, [02/9]: Training Loss: 1.665255142, Training Accuracy: 53.056\n",
            "Worker 2, [03/9]: Training Loss: 1.440733391, Training Accuracy: 59.168\n",
            "Worker 2, [04/9]: Training Loss: 1.226043197, Training Accuracy: 64.768\n",
            "Worker 2, [05/9]: Training Loss: 1.053468934, Training Accuracy: 69.648\n",
            "Worker 2, [06/9]: Training Loss: 0.853297373, Training Accuracy: 75.104\n",
            "Worker 2, [07/9]: Training Loss: 0.715202243, Training Accuracy: 79.120\n",
            "Worker 2, [08/9]: Training Loss: 0.607673864, Training Accuracy: 82.320\n",
            "Worker 2, [09/9]: Training Loss: 0.579363841, Training Accuracy: 83.552\n",
            "Time taken for training worker 2: 0:00:26.168570\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.031712418, Training Accuracy: 46.160\n",
            "Worker 3, [02/9]: Training Loss: 1.685221025, Training Accuracy: 53.744\n",
            "Worker 3, [03/9]: Training Loss: 1.441811590, Training Accuracy: 59.360\n",
            "Worker 3, [04/9]: Training Loss: 1.182889015, Training Accuracy: 65.504\n",
            "Worker 3, [05/9]: Training Loss: 1.033429520, Training Accuracy: 69.968\n",
            "Worker 3, [06/9]: Training Loss: 0.848994067, Training Accuracy: 75.424\n",
            "Worker 3, [07/9]: Training Loss: 0.697289390, Training Accuracy: 79.904\n",
            "Worker 3, [08/9]: Training Loss: 0.618174356, Training Accuracy: 82.208\n",
            "Worker 3, [09/9]: Training Loss: 0.535109472, Training Accuracy: 84.768\n",
            "Time taken for training worker 3: 0:00:24.652565\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.111771540, Training Accuracy: 44.544\n",
            "Worker 4, [02/9]: Training Loss: 1.721593410, Training Accuracy: 53.344\n",
            "Worker 4, [03/9]: Training Loss: 1.437855648, Training Accuracy: 59.904\n",
            "Worker 4, [04/9]: Training Loss: 1.227074816, Training Accuracy: 64.608\n",
            "Worker 4, [05/9]: Training Loss: 1.047656087, Training Accuracy: 69.888\n",
            "Worker 4, [06/9]: Training Loss: 0.879628153, Training Accuracy: 74.704\n",
            "Worker 4, [07/9]: Training Loss: 0.726786613, Training Accuracy: 78.784\n",
            "Worker 4, [08/9]: Training Loss: 0.631156473, Training Accuracy: 81.696\n",
            "Worker 4, [09/9]: Training Loss: 0.550269791, Training Accuracy: 84.224\n",
            "Time taken for training worker 4: 0:00:23.889667\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.130545722, Training Accuracy: 44.576\n",
            "Worker 5, [02/9]: Training Loss: 1.727037454, Training Accuracy: 52.256\n",
            "Worker 5, [03/9]: Training Loss: 1.463805362, Training Accuracy: 58.624\n",
            "Worker 5, [04/9]: Training Loss: 1.260998244, Training Accuracy: 63.744\n",
            "Worker 5, [05/9]: Training Loss: 1.076685542, Training Accuracy: 69.088\n",
            "Worker 5, [06/9]: Training Loss: 0.875381696, Training Accuracy: 75.008\n",
            "Worker 5, [07/9]: Training Loss: 0.738201529, Training Accuracy: 78.400\n",
            "Worker 5, [08/9]: Training Loss: 0.644975632, Training Accuracy: 81.024\n",
            "Worker 5, [09/9]: Training Loss: 0.606384971, Training Accuracy: 82.928\n",
            "Time taken for training worker 5: 0:00:24.738724\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.079565759, Training Accuracy: 45.424\n",
            "Worker 6, [02/9]: Training Loss: 1.692918746, Training Accuracy: 53.168\n",
            "Worker 6, [03/9]: Training Loss: 1.440495189, Training Accuracy: 59.968\n",
            "Worker 6, [04/9]: Training Loss: 1.231324959, Training Accuracy: 64.848\n",
            "Worker 6, [05/9]: Training Loss: 1.064653715, Training Accuracy: 68.608\n",
            "Worker 6, [06/9]: Training Loss: 0.868782211, Training Accuracy: 75.488\n",
            "Worker 6, [07/9]: Training Loss: 0.709245222, Training Accuracy: 79.520\n",
            "Worker 6, [08/9]: Training Loss: 0.623985714, Training Accuracy: 81.872\n",
            "Worker 6, [09/9]: Training Loss: 0.567532453, Training Accuracy: 83.776\n",
            "Time taken for training worker 6: 0:00:23.934127\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.096928334, Training Accuracy: 45.248\n",
            "Worker 7, [02/9]: Training Loss: 1.701003660, Training Accuracy: 53.584\n",
            "Worker 7, [03/9]: Training Loss: 1.461299955, Training Accuracy: 59.680\n",
            "Worker 7, [04/9]: Training Loss: 1.279530977, Training Accuracy: 62.336\n",
            "Worker 7, [05/9]: Training Loss: 1.072774992, Training Accuracy: 69.376\n",
            "Worker 7, [06/9]: Training Loss: 0.873360919, Training Accuracy: 74.560\n",
            "Worker 7, [07/9]: Training Loss: 0.740963935, Training Accuracy: 78.144\n",
            "Worker 7, [08/9]: Training Loss: 0.647810830, Training Accuracy: 81.712\n",
            "Worker 7, [09/9]: Training Loss: 0.576601531, Training Accuracy: 83.952\n",
            "Time taken for training worker 7: 0:00:23.978100\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.119882913, Training Accuracy: 44.080\n",
            "Worker 8, [02/9]: Training Loss: 1.677049572, Training Accuracy: 53.728\n",
            "Worker 8, [03/9]: Training Loss: 1.447246548, Training Accuracy: 58.928\n",
            "Worker 8, [04/9]: Training Loss: 1.227057692, Training Accuracy: 64.656\n",
            "Worker 8, [05/9]: Training Loss: 1.036095869, Training Accuracy: 69.664\n",
            "Worker 8, [06/9]: Training Loss: 0.880334636, Training Accuracy: 74.128\n",
            "Worker 8, [07/9]: Training Loss: 0.720958552, Training Accuracy: 79.088\n",
            "Worker 8, [08/9]: Training Loss: 0.617576657, Training Accuracy: 82.144\n",
            "Worker 8, [09/9]: Training Loss: 0.565036034, Training Accuracy: 83.584\n",
            "Time taken for training worker 8: 0:00:25.271494\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001262\n",
            "Local Step 11: Test Loss: 2.250654330, Test Accuracy: 49.540\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.951067665, Training Accuracy: 51.872\n",
            "Worker 1, [02/9]: Training Loss: 1.848615016, Training Accuracy: 52.608\n",
            "Worker 1, [03/9]: Training Loss: 1.700874331, Training Accuracy: 53.728\n",
            "Worker 1, [04/9]: Training Loss: 1.545549575, Training Accuracy: 57.328\n",
            "Worker 1, [05/9]: Training Loss: 1.449194883, Training Accuracy: 59.008\n",
            "Worker 1, [06/9]: Training Loss: 1.362121788, Training Accuracy: 61.376\n",
            "Worker 1, [07/9]: Training Loss: 1.377515192, Training Accuracy: 60.832\n",
            "Worker 1, [08/9]: Training Loss: 1.303770115, Training Accuracy: 62.352\n",
            "Worker 1, [09/9]: Training Loss: 1.225032857, Training Accuracy: 64.176\n",
            "Time taken for training worker 1: 0:00:24.798880\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.160949009, Training Accuracy: 44.480\n",
            "Worker 2, [02/9]: Training Loss: 1.950218484, Training Accuracy: 48.352\n",
            "Worker 2, [03/9]: Training Loss: 1.749547585, Training Accuracy: 52.816\n",
            "Worker 2, [04/9]: Training Loss: 1.570110516, Training Accuracy: 55.808\n",
            "Worker 2, [05/9]: Training Loss: 1.462682151, Training Accuracy: 59.008\n",
            "Worker 2, [06/9]: Training Loss: 1.409192546, Training Accuracy: 60.064\n",
            "Worker 2, [07/9]: Training Loss: 1.352202298, Training Accuracy: 60.880\n",
            "Worker 2, [08/9]: Training Loss: 1.300750799, Training Accuracy: 62.352\n",
            "Worker 2, [09/9]: Training Loss: 1.262014030, Training Accuracy: 64.064\n",
            "Time taken for training worker 2: 0:00:24.902528\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.124285888, Training Accuracy: 45.968\n",
            "Worker 3, [02/9]: Training Loss: 1.917453385, Training Accuracy: 49.280\n",
            "Worker 3, [03/9]: Training Loss: 1.732875261, Training Accuracy: 52.560\n",
            "Worker 3, [04/9]: Training Loss: 1.588007010, Training Accuracy: 56.544\n",
            "Worker 3, [05/9]: Training Loss: 1.465112239, Training Accuracy: 57.968\n",
            "Worker 3, [06/9]: Training Loss: 1.367470996, Training Accuracy: 61.520\n",
            "Worker 3, [07/9]: Training Loss: 1.300130743, Training Accuracy: 62.720\n",
            "Worker 3, [08/9]: Training Loss: 1.285839718, Training Accuracy: 62.912\n",
            "Worker 3, [09/9]: Training Loss: 1.251751232, Training Accuracy: 63.632\n",
            "Time taken for training worker 3: 0:00:24.361947\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.156499751, Training Accuracy: 45.984\n",
            "Worker 4, [02/9]: Training Loss: 1.922393424, Training Accuracy: 49.424\n",
            "Worker 4, [03/9]: Training Loss: 1.721756278, Training Accuracy: 53.696\n",
            "Worker 4, [04/9]: Training Loss: 1.601819243, Training Accuracy: 56.064\n",
            "Worker 4, [05/9]: Training Loss: 1.443829498, Training Accuracy: 60.064\n",
            "Worker 4, [06/9]: Training Loss: 1.385043119, Training Accuracy: 61.280\n",
            "Worker 4, [07/9]: Training Loss: 1.329285577, Training Accuracy: 62.192\n",
            "Worker 4, [08/9]: Training Loss: 1.280469685, Training Accuracy: 63.552\n",
            "Worker 4, [09/9]: Training Loss: 1.261409809, Training Accuracy: 63.920\n",
            "Time taken for training worker 4: 0:00:24.590875\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.152458658, Training Accuracy: 44.464\n",
            "Worker 5, [02/9]: Training Loss: 1.946676907, Training Accuracy: 47.696\n",
            "Worker 5, [03/9]: Training Loss: 1.776605085, Training Accuracy: 52.000\n",
            "Worker 5, [04/9]: Training Loss: 1.588301323, Training Accuracy: 55.456\n",
            "Worker 5, [05/9]: Training Loss: 1.474598318, Training Accuracy: 59.072\n",
            "Worker 5, [06/9]: Training Loss: 1.401676598, Training Accuracy: 60.048\n",
            "Worker 5, [07/9]: Training Loss: 1.308416681, Training Accuracy: 61.968\n",
            "Worker 5, [08/9]: Training Loss: 1.303966387, Training Accuracy: 62.864\n",
            "Worker 5, [09/9]: Training Loss: 1.291722592, Training Accuracy: 62.720\n",
            "Time taken for training worker 5: 0:00:24.683115\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.123399967, Training Accuracy: 45.920\n",
            "Worker 6, [02/9]: Training Loss: 1.920963898, Training Accuracy: 49.120\n",
            "Worker 6, [03/9]: Training Loss: 1.721067407, Training Accuracy: 53.808\n",
            "Worker 6, [04/9]: Training Loss: 1.556282563, Training Accuracy: 56.544\n",
            "Worker 6, [05/9]: Training Loss: 1.443325638, Training Accuracy: 59.184\n",
            "Worker 6, [06/9]: Training Loss: 1.359668465, Training Accuracy: 60.752\n",
            "Worker 6, [07/9]: Training Loss: 1.303005839, Training Accuracy: 62.640\n",
            "Worker 6, [08/9]: Training Loss: 1.294237779, Training Accuracy: 62.688\n",
            "Worker 6, [09/9]: Training Loss: 1.193260594, Training Accuracy: 65.824\n",
            "Time taken for training worker 6: 0:00:25.494425\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.062502923, Training Accuracy: 47.216\n",
            "Worker 7, [02/9]: Training Loss: 1.919784505, Training Accuracy: 49.440\n",
            "Worker 7, [03/9]: Training Loss: 1.719441851, Training Accuracy: 53.008\n",
            "Worker 7, [04/9]: Training Loss: 1.598037403, Training Accuracy: 55.440\n",
            "Worker 7, [05/9]: Training Loss: 1.467507987, Training Accuracy: 58.944\n",
            "Worker 7, [06/9]: Training Loss: 1.386894211, Training Accuracy: 60.528\n",
            "Worker 7, [07/9]: Training Loss: 1.326932435, Training Accuracy: 62.848\n",
            "Worker 7, [08/9]: Training Loss: 1.250421531, Training Accuracy: 63.312\n",
            "Worker 7, [09/9]: Training Loss: 1.207753830, Training Accuracy: 65.040\n",
            "Time taken for training worker 7: 0:00:24.707131\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.128433485, Training Accuracy: 46.208\n",
            "Worker 8, [02/9]: Training Loss: 1.866157711, Training Accuracy: 50.032\n",
            "Worker 8, [03/9]: Training Loss: 1.680359416, Training Accuracy: 53.648\n",
            "Worker 8, [04/9]: Training Loss: 1.539715790, Training Accuracy: 57.264\n",
            "Worker 8, [05/9]: Training Loss: 1.407302017, Training Accuracy: 59.904\n",
            "Worker 8, [06/9]: Training Loss: 1.340158028, Training Accuracy: 61.200\n",
            "Worker 8, [07/9]: Training Loss: 1.287151511, Training Accuracy: 62.784\n",
            "Worker 8, [08/9]: Training Loss: 1.242929067, Training Accuracy: 63.232\n",
            "Worker 8, [09/9]: Training Loss: 1.206353690, Training Accuracy: 63.952\n",
            "Time taken for training worker 8: 0:00:23.894845\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000747\n",
            "Local Step 12: Test Loss: 2.363561377, Test Accuracy: 43.800\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.035180703, Training Accuracy: 46.880\n",
            "Worker 1, [02/9]: Training Loss: 1.618857735, Training Accuracy: 55.872\n",
            "Worker 1, [03/9]: Training Loss: 1.415595039, Training Accuracy: 60.864\n",
            "Worker 1, [04/9]: Training Loss: 1.204048866, Training Accuracy: 66.048\n",
            "Worker 1, [05/9]: Training Loss: 1.023056982, Training Accuracy: 70.400\n",
            "Worker 1, [06/9]: Training Loss: 0.809463231, Training Accuracy: 76.592\n",
            "Worker 1, [07/9]: Training Loss: 0.667761904, Training Accuracy: 80.672\n",
            "Worker 1, [08/9]: Training Loss: 0.571662605, Training Accuracy: 83.440\n",
            "Worker 1, [09/9]: Training Loss: 0.529338824, Training Accuracy: 85.472\n",
            "Time taken for training worker 1: 0:00:24.015836\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.062044719, Training Accuracy: 45.968\n",
            "Worker 2, [02/9]: Training Loss: 1.643481554, Training Accuracy: 54.912\n",
            "Worker 2, [03/9]: Training Loss: 1.435182722, Training Accuracy: 58.928\n",
            "Worker 2, [04/9]: Training Loss: 1.217951627, Training Accuracy: 65.312\n",
            "Worker 2, [05/9]: Training Loss: 1.002804158, Training Accuracy: 70.672\n",
            "Worker 2, [06/9]: Training Loss: 0.833726287, Training Accuracy: 75.648\n",
            "Worker 2, [07/9]: Training Loss: 0.695315858, Training Accuracy: 80.048\n",
            "Worker 2, [08/9]: Training Loss: 0.588119241, Training Accuracy: 83.744\n",
            "Worker 2, [09/9]: Training Loss: 0.527046616, Training Accuracy: 85.200\n",
            "Time taken for training worker 2: 0:00:25.119957\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.052345365, Training Accuracy: 45.536\n",
            "Worker 3, [02/9]: Training Loss: 1.647118314, Training Accuracy: 54.336\n",
            "Worker 3, [03/9]: Training Loss: 1.419934082, Training Accuracy: 60.160\n",
            "Worker 3, [04/9]: Training Loss: 1.169911231, Training Accuracy: 65.616\n",
            "Worker 3, [05/9]: Training Loss: 1.009439244, Training Accuracy: 69.840\n",
            "Worker 3, [06/9]: Training Loss: 0.787154690, Training Accuracy: 76.480\n",
            "Worker 3, [07/9]: Training Loss: 0.684924200, Training Accuracy: 79.568\n",
            "Worker 3, [08/9]: Training Loss: 0.562822055, Training Accuracy: 83.920\n",
            "Worker 3, [09/9]: Training Loss: 0.513798064, Training Accuracy: 85.296\n",
            "Time taken for training worker 3: 0:00:23.753752\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.047049057, Training Accuracy: 46.896\n",
            "Worker 4, [02/9]: Training Loss: 1.644703011, Training Accuracy: 54.864\n",
            "Worker 4, [03/9]: Training Loss: 1.396117248, Training Accuracy: 60.208\n",
            "Worker 4, [04/9]: Training Loss: 1.199257485, Training Accuracy: 65.696\n",
            "Worker 4, [05/9]: Training Loss: 1.004250475, Training Accuracy: 70.288\n",
            "Worker 4, [06/9]: Training Loss: 0.836871126, Training Accuracy: 75.776\n",
            "Worker 4, [07/9]: Training Loss: 0.683816728, Training Accuracy: 80.304\n",
            "Worker 4, [08/9]: Training Loss: 0.582647890, Training Accuracy: 82.784\n",
            "Worker 4, [09/9]: Training Loss: 0.525324643, Training Accuracy: 84.928\n",
            "Time taken for training worker 4: 0:00:24.532142\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.076914459, Training Accuracy: 45.360\n",
            "Worker 5, [02/9]: Training Loss: 1.688627194, Training Accuracy: 53.840\n",
            "Worker 5, [03/9]: Training Loss: 1.438343727, Training Accuracy: 59.696\n",
            "Worker 5, [04/9]: Training Loss: 1.217523838, Training Accuracy: 65.248\n",
            "Worker 5, [05/9]: Training Loss: 1.014698566, Training Accuracy: 70.800\n",
            "Worker 5, [06/9]: Training Loss: 0.841314857, Training Accuracy: 75.440\n",
            "Worker 5, [07/9]: Training Loss: 0.682225646, Training Accuracy: 80.000\n",
            "Worker 5, [08/9]: Training Loss: 0.613044593, Training Accuracy: 82.064\n",
            "Worker 5, [09/9]: Training Loss: 0.561775755, Training Accuracy: 83.824\n",
            "Time taken for training worker 5: 0:00:25.061616\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.049938487, Training Accuracy: 46.912\n",
            "Worker 6, [02/9]: Training Loss: 1.620859391, Training Accuracy: 54.704\n",
            "Worker 6, [03/9]: Training Loss: 1.387407756, Training Accuracy: 61.344\n",
            "Worker 6, [04/9]: Training Loss: 1.176934184, Training Accuracy: 66.160\n",
            "Worker 6, [05/9]: Training Loss: 0.994990642, Training Accuracy: 70.688\n",
            "Worker 6, [06/9]: Training Loss: 0.822183156, Training Accuracy: 76.752\n",
            "Worker 6, [07/9]: Training Loss: 0.703352614, Training Accuracy: 80.112\n",
            "Worker 6, [08/9]: Training Loss: 0.582554256, Training Accuracy: 83.264\n",
            "Worker 6, [09/9]: Training Loss: 0.522262894, Training Accuracy: 85.008\n",
            "Time taken for training worker 6: 0:00:24.703460\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.047809848, Training Accuracy: 46.192\n",
            "Worker 7, [02/9]: Training Loss: 1.639395812, Training Accuracy: 54.960\n",
            "Worker 7, [03/9]: Training Loss: 1.383059418, Training Accuracy: 60.656\n",
            "Worker 7, [04/9]: Training Loss: 1.207840001, Training Accuracy: 65.744\n",
            "Worker 7, [05/9]: Training Loss: 1.008519372, Training Accuracy: 71.040\n",
            "Worker 7, [06/9]: Training Loss: 0.848147297, Training Accuracy: 75.872\n",
            "Worker 7, [07/9]: Training Loss: 0.678263852, Training Accuracy: 80.368\n",
            "Worker 7, [08/9]: Training Loss: 0.585909424, Training Accuracy: 83.248\n",
            "Worker 7, [09/9]: Training Loss: 0.553949493, Training Accuracy: 84.400\n",
            "Time taken for training worker 7: 0:00:23.883627\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.072838263, Training Accuracy: 45.120\n",
            "Worker 8, [02/9]: Training Loss: 1.649718134, Training Accuracy: 54.624\n",
            "Worker 8, [03/9]: Training Loss: 1.343464013, Training Accuracy: 61.264\n",
            "Worker 8, [04/9]: Training Loss: 1.209116298, Training Accuracy: 64.832\n",
            "Worker 8, [05/9]: Training Loss: 0.986811452, Training Accuracy: 71.136\n",
            "Worker 8, [06/9]: Training Loss: 0.819482268, Training Accuracy: 75.888\n",
            "Worker 8, [07/9]: Training Loss: 0.668556768, Training Accuracy: 80.832\n",
            "Worker 8, [08/9]: Training Loss: 0.581423489, Training Accuracy: 82.912\n",
            "Worker 8, [09/9]: Training Loss: 0.529022881, Training Accuracy: 84.592\n",
            "Time taken for training worker 8: 0:00:25.069958\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000826\n",
            "Local Step 13: Test Loss: 2.286141560, Test Accuracy: 50.110\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.936678305, Training Accuracy: 52.928\n",
            "Worker 1, [02/9]: Training Loss: 1.853340305, Training Accuracy: 52.224\n",
            "Worker 1, [03/9]: Training Loss: 1.649010396, Training Accuracy: 55.184\n",
            "Worker 1, [04/9]: Training Loss: 1.517108232, Training Accuracy: 57.664\n",
            "Worker 1, [05/9]: Training Loss: 1.402961465, Training Accuracy: 60.960\n",
            "Worker 1, [06/9]: Training Loss: 1.341653992, Training Accuracy: 61.328\n",
            "Worker 1, [07/9]: Training Loss: 1.310659698, Training Accuracy: 62.800\n",
            "Worker 1, [08/9]: Training Loss: 1.241246343, Training Accuracy: 64.304\n",
            "Worker 1, [09/9]: Training Loss: 1.201377263, Training Accuracy: 65.344\n",
            "Time taken for training worker 1: 0:00:24.028347\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.142674000, Training Accuracy: 45.344\n",
            "Worker 2, [02/9]: Training Loss: 1.946589533, Training Accuracy: 48.848\n",
            "Worker 2, [03/9]: Training Loss: 1.723402336, Training Accuracy: 53.216\n",
            "Worker 2, [04/9]: Training Loss: 1.579500168, Training Accuracy: 56.496\n",
            "Worker 2, [05/9]: Training Loss: 1.449445829, Training Accuracy: 59.808\n",
            "Worker 2, [06/9]: Training Loss: 1.347213443, Training Accuracy: 61.600\n",
            "Worker 2, [07/9]: Training Loss: 1.303636229, Training Accuracy: 62.240\n",
            "Worker 2, [08/9]: Training Loss: 1.262132535, Training Accuracy: 63.376\n",
            "Worker 2, [09/9]: Training Loss: 1.234165054, Training Accuracy: 65.008\n",
            "Time taken for training worker 2: 0:00:24.440513\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.112238292, Training Accuracy: 46.016\n",
            "Worker 3, [02/9]: Training Loss: 1.897028696, Training Accuracy: 49.632\n",
            "Worker 3, [03/9]: Training Loss: 1.696335030, Training Accuracy: 53.488\n",
            "Worker 3, [04/9]: Training Loss: 1.549405675, Training Accuracy: 56.528\n",
            "Worker 3, [05/9]: Training Loss: 1.429791593, Training Accuracy: 59.280\n",
            "Worker 3, [06/9]: Training Loss: 1.326638745, Training Accuracy: 61.952\n",
            "Worker 3, [07/9]: Training Loss: 1.261837481, Training Accuracy: 63.888\n",
            "Worker 3, [08/9]: Training Loss: 1.222665755, Training Accuracy: 64.224\n",
            "Worker 3, [09/9]: Training Loss: 1.206809066, Training Accuracy: 64.400\n",
            "Time taken for training worker 3: 0:00:24.054096\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.256547873, Training Accuracy: 43.904\n",
            "Worker 4, [02/9]: Training Loss: 1.946848671, Training Accuracy: 49.504\n",
            "Worker 4, [03/9]: Training Loss: 1.736960611, Training Accuracy: 53.616\n",
            "Worker 4, [04/9]: Training Loss: 1.570489000, Training Accuracy: 57.088\n",
            "Worker 4, [05/9]: Training Loss: 1.431154160, Training Accuracy: 59.792\n",
            "Worker 4, [06/9]: Training Loss: 1.381615617, Training Accuracy: 60.784\n",
            "Worker 4, [07/9]: Training Loss: 1.300894274, Training Accuracy: 62.256\n",
            "Worker 4, [08/9]: Training Loss: 1.250863713, Training Accuracy: 64.176\n",
            "Worker 4, [09/9]: Training Loss: 1.229481943, Training Accuracy: 64.144\n",
            "Time taken for training worker 4: 0:00:24.402783\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.126943444, Training Accuracy: 46.224\n",
            "Worker 5, [02/9]: Training Loss: 1.909671404, Training Accuracy: 49.488\n",
            "Worker 5, [03/9]: Training Loss: 1.736314651, Training Accuracy: 52.896\n",
            "Worker 5, [04/9]: Training Loss: 1.567085460, Training Accuracy: 56.352\n",
            "Worker 5, [05/9]: Training Loss: 1.443705530, Training Accuracy: 59.696\n",
            "Worker 5, [06/9]: Training Loss: 1.371192494, Training Accuracy: 60.816\n",
            "Worker 5, [07/9]: Training Loss: 1.266070473, Training Accuracy: 63.536\n",
            "Worker 5, [08/9]: Training Loss: 1.280967560, Training Accuracy: 62.880\n",
            "Worker 5, [09/9]: Training Loss: 1.193328024, Training Accuracy: 65.264\n",
            "Time taken for training worker 5: 0:00:26.402206\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.057571116, Training Accuracy: 47.728\n",
            "Worker 6, [02/9]: Training Loss: 1.850355238, Training Accuracy: 50.704\n",
            "Worker 6, [03/9]: Training Loss: 1.675542013, Training Accuracy: 53.696\n",
            "Worker 6, [04/9]: Training Loss: 1.538460334, Training Accuracy: 57.440\n",
            "Worker 6, [05/9]: Training Loss: 1.413306816, Training Accuracy: 59.472\n",
            "Worker 6, [06/9]: Training Loss: 1.329562790, Training Accuracy: 62.352\n",
            "Worker 6, [07/9]: Training Loss: 1.300242913, Training Accuracy: 62.704\n",
            "Worker 6, [08/9]: Training Loss: 1.245686614, Training Accuracy: 63.872\n",
            "Worker 6, [09/9]: Training Loss: 1.201536678, Training Accuracy: 65.168\n",
            "Time taken for training worker 6: 0:00:26.409992\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.119459292, Training Accuracy: 47.008\n",
            "Worker 7, [02/9]: Training Loss: 1.888995866, Training Accuracy: 50.096\n",
            "Worker 7, [03/9]: Training Loss: 1.716107460, Training Accuracy: 53.584\n",
            "Worker 7, [04/9]: Training Loss: 1.571680661, Training Accuracy: 56.928\n",
            "Worker 7, [05/9]: Training Loss: 1.447971788, Training Accuracy: 59.744\n",
            "Worker 7, [06/9]: Training Loss: 1.339970808, Training Accuracy: 62.304\n",
            "Worker 7, [07/9]: Training Loss: 1.262894003, Training Accuracy: 63.968\n",
            "Worker 7, [08/9]: Training Loss: 1.240235730, Training Accuracy: 64.736\n",
            "Worker 7, [09/9]: Training Loss: 1.213545690, Training Accuracy: 64.560\n",
            "Time taken for training worker 7: 0:00:25.505713\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.065810794, Training Accuracy: 46.928\n",
            "Worker 8, [02/9]: Training Loss: 1.852923073, Training Accuracy: 50.800\n",
            "Worker 8, [03/9]: Training Loss: 1.655523342, Training Accuracy: 54.144\n",
            "Worker 8, [04/9]: Training Loss: 1.523135602, Training Accuracy: 57.712\n",
            "Worker 8, [05/9]: Training Loss: 1.368794369, Training Accuracy: 60.528\n",
            "Worker 8, [06/9]: Training Loss: 1.311016922, Training Accuracy: 62.096\n",
            "Worker 8, [07/9]: Training Loss: 1.275751749, Training Accuracy: 62.960\n",
            "Worker 8, [08/9]: Training Loss: 1.237113611, Training Accuracy: 63.568\n",
            "Worker 8, [09/9]: Training Loss: 1.187934815, Training Accuracy: 65.264\n",
            "Time taken for training worker 8: 0:00:24.665164\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000716\n",
            "Local Step 14: Test Loss: 2.372590793, Test Accuracy: 44.450\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 2.031695207, Training Accuracy: 46.144\n",
            "Worker 1, [02/9]: Training Loss: 1.630989717, Training Accuracy: 54.224\n",
            "Worker 1, [03/9]: Training Loss: 1.382163252, Training Accuracy: 61.728\n",
            "Worker 1, [04/9]: Training Loss: 1.166795088, Training Accuracy: 66.464\n",
            "Worker 1, [05/9]: Training Loss: 0.978563517, Training Accuracy: 71.488\n",
            "Worker 1, [06/9]: Training Loss: 0.789639001, Training Accuracy: 77.088\n",
            "Worker 1, [07/9]: Training Loss: 0.656416483, Training Accuracy: 80.816\n",
            "Worker 1, [08/9]: Training Loss: 0.558236159, Training Accuracy: 84.480\n",
            "Worker 1, [09/9]: Training Loss: 0.521468879, Training Accuracy: 85.424\n",
            "Time taken for training worker 1: 0:00:23.862681\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.013706845, Training Accuracy: 46.832\n",
            "Worker 2, [02/9]: Training Loss: 1.622939894, Training Accuracy: 55.536\n",
            "Worker 2, [03/9]: Training Loss: 1.393102312, Training Accuracy: 60.560\n",
            "Worker 2, [04/9]: Training Loss: 1.146826754, Training Accuracy: 66.912\n",
            "Worker 2, [05/9]: Training Loss: 0.971779198, Training Accuracy: 71.696\n",
            "Worker 2, [06/9]: Training Loss: 0.798749475, Training Accuracy: 77.104\n",
            "Worker 2, [07/9]: Training Loss: 0.642605113, Training Accuracy: 81.152\n",
            "Worker 2, [08/9]: Training Loss: 0.547769683, Training Accuracy: 84.128\n",
            "Worker 2, [09/9]: Training Loss: 0.490351081, Training Accuracy: 86.224\n",
            "Time taken for training worker 2: 0:00:24.981904\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.068313555, Training Accuracy: 45.136\n",
            "Worker 3, [02/9]: Training Loss: 1.615974140, Training Accuracy: 55.280\n",
            "Worker 3, [03/9]: Training Loss: 1.402038613, Training Accuracy: 60.176\n",
            "Worker 3, [04/9]: Training Loss: 1.147376984, Training Accuracy: 66.960\n",
            "Worker 3, [05/9]: Training Loss: 0.952030712, Training Accuracy: 71.808\n",
            "Worker 3, [06/9]: Training Loss: 0.783439583, Training Accuracy: 76.784\n",
            "Worker 3, [07/9]: Training Loss: 0.651316859, Training Accuracy: 80.880\n",
            "Worker 3, [08/9]: Training Loss: 0.552562562, Training Accuracy: 84.288\n",
            "Worker 3, [09/9]: Training Loss: 0.503234438, Training Accuracy: 85.520\n",
            "Time taken for training worker 3: 0:00:24.130051\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.040672779, Training Accuracy: 46.288\n",
            "Worker 4, [02/9]: Training Loss: 1.634732159, Training Accuracy: 54.896\n",
            "Worker 4, [03/9]: Training Loss: 1.371905541, Training Accuracy: 61.888\n",
            "Worker 4, [04/9]: Training Loss: 1.182615265, Training Accuracy: 65.600\n",
            "Worker 4, [05/9]: Training Loss: 0.973344071, Training Accuracy: 71.568\n",
            "Worker 4, [06/9]: Training Loss: 0.782027877, Training Accuracy: 76.800\n",
            "Worker 4, [07/9]: Training Loss: 0.662067933, Training Accuracy: 80.624\n",
            "Worker 4, [08/9]: Training Loss: 0.559577706, Training Accuracy: 83.776\n",
            "Worker 4, [09/9]: Training Loss: 0.494379282, Training Accuracy: 85.792\n",
            "Time taken for training worker 4: 0:00:24.715266\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.051643771, Training Accuracy: 46.160\n",
            "Worker 5, [02/9]: Training Loss: 1.631269427, Training Accuracy: 53.792\n",
            "Worker 5, [03/9]: Training Loss: 1.440930610, Training Accuracy: 58.384\n",
            "Worker 5, [04/9]: Training Loss: 1.217956438, Training Accuracy: 65.344\n",
            "Worker 5, [05/9]: Training Loss: 0.984575452, Training Accuracy: 72.032\n",
            "Worker 5, [06/9]: Training Loss: 0.809524841, Training Accuracy: 76.576\n",
            "Worker 5, [07/9]: Training Loss: 0.687330308, Training Accuracy: 80.624\n",
            "Worker 5, [08/9]: Training Loss: 0.585507736, Training Accuracy: 82.992\n",
            "Worker 5, [09/9]: Training Loss: 0.535778522, Training Accuracy: 84.640\n",
            "Time taken for training worker 5: 0:00:24.391977\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.075639295, Training Accuracy: 45.936\n",
            "Worker 6, [02/9]: Training Loss: 1.633350115, Training Accuracy: 54.544\n",
            "Worker 6, [03/9]: Training Loss: 1.363450479, Training Accuracy: 61.488\n",
            "Worker 6, [04/9]: Training Loss: 1.172592585, Training Accuracy: 66.160\n",
            "Worker 6, [05/9]: Training Loss: 0.952298825, Training Accuracy: 72.432\n",
            "Worker 6, [06/9]: Training Loss: 0.795015758, Training Accuracy: 76.832\n",
            "Worker 6, [07/9]: Training Loss: 0.667180781, Training Accuracy: 80.208\n",
            "Worker 6, [08/9]: Training Loss: 0.551547107, Training Accuracy: 84.224\n",
            "Worker 6, [09/9]: Training Loss: 0.535159468, Training Accuracy: 85.312\n",
            "Time taken for training worker 6: 0:00:24.998613\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.003799127, Training Accuracy: 47.712\n",
            "Worker 7, [02/9]: Training Loss: 1.600158938, Training Accuracy: 55.616\n",
            "Worker 7, [03/9]: Training Loss: 1.383705558, Training Accuracy: 60.512\n",
            "Worker 7, [04/9]: Training Loss: 1.198192426, Training Accuracy: 65.632\n",
            "Worker 7, [05/9]: Training Loss: 0.983552686, Training Accuracy: 71.744\n",
            "Worker 7, [06/9]: Training Loss: 0.803961074, Training Accuracy: 77.216\n",
            "Worker 7, [07/9]: Training Loss: 0.659286919, Training Accuracy: 80.752\n",
            "Worker 7, [08/9]: Training Loss: 0.571606911, Training Accuracy: 84.112\n",
            "Worker 7, [09/9]: Training Loss: 0.525775437, Training Accuracy: 85.088\n",
            "Time taken for training worker 7: 0:00:24.085442\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.015322216, Training Accuracy: 46.784\n",
            "Worker 8, [02/9]: Training Loss: 1.631626649, Training Accuracy: 54.672\n",
            "Worker 8, [03/9]: Training Loss: 1.401132620, Training Accuracy: 60.800\n",
            "Worker 8, [04/9]: Training Loss: 1.163997433, Training Accuracy: 65.872\n",
            "Worker 8, [05/9]: Training Loss: 0.973078964, Training Accuracy: 71.632\n",
            "Worker 8, [06/9]: Training Loss: 0.778877177, Training Accuracy: 76.752\n",
            "Worker 8, [07/9]: Training Loss: 0.643169826, Training Accuracy: 81.232\n",
            "Worker 8, [08/9]: Training Loss: 0.541738605, Training Accuracy: 84.624\n",
            "Worker 8, [09/9]: Training Loss: 0.508571789, Training Accuracy: 85.616\n",
            "Time taken for training worker 8: 0:00:24.855236\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000909\n",
            "Local Step 15: Test Loss: 2.264635012, Test Accuracy: 50.440\n",
            "**************************************************\n",
            "Worker 1, [01/9]: Training Loss: 1.924812468, Training Accuracy: 52.896\n",
            "Worker 1, [02/9]: Training Loss: 1.804527915, Training Accuracy: 53.472\n",
            "Worker 1, [03/9]: Training Loss: 1.653359414, Training Accuracy: 54.960\n",
            "Worker 1, [04/9]: Training Loss: 1.496254111, Training Accuracy: 58.480\n",
            "Worker 1, [05/9]: Training Loss: 1.401210188, Training Accuracy: 60.064\n",
            "Worker 1, [06/9]: Training Loss: 1.320406963, Training Accuracy: 62.016\n",
            "Worker 1, [07/9]: Training Loss: 1.274200333, Training Accuracy: 63.200\n",
            "Worker 1, [08/9]: Training Loss: 1.239581678, Training Accuracy: 64.560\n",
            "Worker 1, [09/9]: Training Loss: 1.173608529, Training Accuracy: 66.656\n",
            "Time taken for training worker 1: 0:00:24.449244\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/9]: Training Loss: 2.127974688, Training Accuracy: 46.496\n",
            "Worker 2, [02/9]: Training Loss: 1.897507659, Training Accuracy: 50.576\n",
            "Worker 2, [03/9]: Training Loss: 1.699863182, Training Accuracy: 53.536\n",
            "Worker 2, [04/9]: Training Loss: 1.520979538, Training Accuracy: 57.344\n",
            "Worker 2, [05/9]: Training Loss: 1.419417682, Training Accuracy: 59.584\n",
            "Worker 2, [06/9]: Training Loss: 1.352441977, Training Accuracy: 61.680\n",
            "Worker 2, [07/9]: Training Loss: 1.253136800, Training Accuracy: 64.064\n",
            "Worker 2, [08/9]: Training Loss: 1.263502791, Training Accuracy: 63.184\n",
            "Worker 2, [09/9]: Training Loss: 1.177016765, Training Accuracy: 65.872\n",
            "Time taken for training worker 2: 0:00:24.105708\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/9]: Training Loss: 2.098774061, Training Accuracy: 46.528\n",
            "Worker 3, [02/9]: Training Loss: 1.890005586, Training Accuracy: 49.984\n",
            "Worker 3, [03/9]: Training Loss: 1.703152113, Training Accuracy: 52.752\n",
            "Worker 3, [04/9]: Training Loss: 1.535675914, Training Accuracy: 57.424\n",
            "Worker 3, [05/9]: Training Loss: 1.395497225, Training Accuracy: 60.352\n",
            "Worker 3, [06/9]: Training Loss: 1.316709577, Training Accuracy: 62.368\n",
            "Worker 3, [07/9]: Training Loss: 1.274261166, Training Accuracy: 62.912\n",
            "Worker 3, [08/9]: Training Loss: 1.242720449, Training Accuracy: 64.304\n",
            "Worker 3, [09/9]: Training Loss: 1.202997321, Training Accuracy: 64.480\n",
            "Time taken for training worker 3: 0:00:24.646004\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/9]: Training Loss: 2.072661558, Training Accuracy: 47.680\n",
            "Worker 4, [02/9]: Training Loss: 1.903150563, Training Accuracy: 49.872\n",
            "Worker 4, [03/9]: Training Loss: 1.698224804, Training Accuracy: 54.288\n",
            "Worker 4, [04/9]: Training Loss: 1.537214453, Training Accuracy: 57.936\n",
            "Worker 4, [05/9]: Training Loss: 1.429734971, Training Accuracy: 60.528\n",
            "Worker 4, [06/9]: Training Loss: 1.329148665, Training Accuracy: 62.512\n",
            "Worker 4, [07/9]: Training Loss: 1.287821415, Training Accuracy: 63.072\n",
            "Worker 4, [08/9]: Training Loss: 1.207554981, Training Accuracy: 65.200\n",
            "Worker 4, [09/9]: Training Loss: 1.188771377, Training Accuracy: 66.080\n",
            "Time taken for training worker 4: 0:00:25.131450\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/9]: Training Loss: 2.068049191, Training Accuracy: 47.216\n",
            "Worker 5, [02/9]: Training Loss: 1.883176017, Training Accuracy: 49.744\n",
            "Worker 5, [03/9]: Training Loss: 1.694668683, Training Accuracy: 53.968\n",
            "Worker 5, [04/9]: Training Loss: 1.557781094, Training Accuracy: 56.768\n",
            "Worker 5, [05/9]: Training Loss: 1.431922214, Training Accuracy: 60.000\n",
            "Worker 5, [06/9]: Training Loss: 1.315426283, Training Accuracy: 62.672\n",
            "Worker 5, [07/9]: Training Loss: 1.293196631, Training Accuracy: 62.448\n",
            "Worker 5, [08/9]: Training Loss: 1.292939181, Training Accuracy: 62.416\n",
            "Worker 5, [09/9]: Training Loss: 1.202624570, Training Accuracy: 64.896\n",
            "Time taken for training worker 5: 0:00:23.914942\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/9]: Training Loss: 2.082864163, Training Accuracy: 46.400\n",
            "Worker 6, [02/9]: Training Loss: 1.870862822, Training Accuracy: 50.448\n",
            "Worker 6, [03/9]: Training Loss: 1.695352386, Training Accuracy: 53.328\n",
            "Worker 6, [04/9]: Training Loss: 1.513178934, Training Accuracy: 57.280\n",
            "Worker 6, [05/9]: Training Loss: 1.376934201, Training Accuracy: 61.248\n",
            "Worker 6, [06/9]: Training Loss: 1.294708174, Training Accuracy: 63.184\n",
            "Worker 6, [07/9]: Training Loss: 1.230132264, Training Accuracy: 64.816\n",
            "Worker 6, [08/9]: Training Loss: 1.226979859, Training Accuracy: 64.880\n",
            "Worker 6, [09/9]: Training Loss: 1.159905381, Training Accuracy: 66.592\n",
            "Time taken for training worker 6: 0:00:25.022272\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/9]: Training Loss: 2.167145880, Training Accuracy: 47.088\n",
            "Worker 7, [02/9]: Training Loss: 1.898861409, Training Accuracy: 49.856\n",
            "Worker 7, [03/9]: Training Loss: 1.692972396, Training Accuracy: 53.968\n",
            "Worker 7, [04/9]: Training Loss: 1.536255118, Training Accuracy: 57.296\n",
            "Worker 7, [05/9]: Training Loss: 1.412788491, Training Accuracy: 60.480\n",
            "Worker 7, [06/9]: Training Loss: 1.293353169, Training Accuracy: 63.104\n",
            "Worker 7, [07/9]: Training Loss: 1.247425589, Training Accuracy: 63.664\n",
            "Worker 7, [08/9]: Training Loss: 1.181286465, Training Accuracy: 65.632\n",
            "Worker 7, [09/9]: Training Loss: 1.156195274, Training Accuracy: 65.824\n",
            "Time taken for training worker 7: 0:00:24.619750\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/9]: Training Loss: 2.091841482, Training Accuracy: 45.856\n",
            "Worker 8, [02/9]: Training Loss: 1.854010715, Training Accuracy: 50.128\n",
            "Worker 8, [03/9]: Training Loss: 1.684062652, Training Accuracy: 53.200\n",
            "Worker 8, [04/9]: Training Loss: 1.497859441, Training Accuracy: 57.744\n",
            "Worker 8, [05/9]: Training Loss: 1.367887029, Training Accuracy: 60.864\n",
            "Worker 8, [06/9]: Training Loss: 1.263245493, Training Accuracy: 63.840\n",
            "Worker 8, [07/9]: Training Loss: 1.217354270, Training Accuracy: 64.640\n",
            "Worker 8, [08/9]: Training Loss: 1.208312280, Training Accuracy: 64.912\n",
            "Worker 8, [09/9]: Training Loss: 1.188680302, Training Accuracy: 64.656\n",
            "Time taken for training worker 8: 0:00:24.883223\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000868\n",
            "Local Step 16: Test Loss: 2.443498711, Test Accuracy: 44.290\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:46.076998\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:32\n",
            "==================================================\n",
            "Worker 1, [01/4]: Training Loss: 4.593671088, Training Accuracy: 1.424\n",
            "Worker 1, [02/4]: Training Loss: 4.439842034, Training Accuracy: 3.744\n",
            "Worker 1, [03/4]: Training Loss: 4.202212871, Training Accuracy: 5.552\n",
            "Worker 1, [04/4]: Training Loss: 4.066381459, Training Accuracy: 7.168\n",
            "Time taken for training worker 1: 0:00:10.353798\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 4.593195526, Training Accuracy: 1.264\n",
            "Worker 2, [02/4]: Training Loss: 4.463748951, Training Accuracy: 2.544\n",
            "Worker 2, [03/4]: Training Loss: 4.203347420, Training Accuracy: 5.520\n",
            "Worker 2, [04/4]: Training Loss: 4.067202106, Training Accuracy: 7.600\n",
            "Time taken for training worker 2: 0:00:10.672061\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 4.593965024, Training Accuracy: 1.664\n",
            "Worker 3, [02/4]: Training Loss: 4.465064321, Training Accuracy: 2.992\n",
            "Worker 3, [03/4]: Training Loss: 4.194152192, Training Accuracy: 5.600\n",
            "Worker 3, [04/4]: Training Loss: 4.053369741, Training Accuracy: 7.424\n",
            "Time taken for training worker 3: 0:00:10.530366\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 4.591454248, Training Accuracy: 1.408\n",
            "Worker 4, [02/4]: Training Loss: 4.450567391, Training Accuracy: 3.072\n",
            "Worker 4, [03/4]: Training Loss: 4.199584827, Training Accuracy: 5.728\n",
            "Worker 4, [04/4]: Training Loss: 4.062323127, Training Accuracy: 7.072\n",
            "Time taken for training worker 4: 0:00:11.364277\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 4.596194092, Training Accuracy: 1.616\n",
            "Worker 5, [02/4]: Training Loss: 4.449238602, Training Accuracy: 3.216\n",
            "Worker 5, [03/4]: Training Loss: 4.212119137, Training Accuracy: 5.584\n",
            "Worker 5, [04/4]: Training Loss: 4.072374062, Training Accuracy: 7.456\n",
            "Time taken for training worker 5: 0:00:11.172431\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 4.591653439, Training Accuracy: 1.376\n",
            "Worker 6, [02/4]: Training Loss: 4.435789454, Training Accuracy: 3.392\n",
            "Worker 6, [03/4]: Training Loss: 4.166220310, Training Accuracy: 6.288\n",
            "Worker 6, [04/4]: Training Loss: 4.029072847, Training Accuracy: 8.416\n",
            "Time taken for training worker 6: 0:00:10.917496\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 4.592000168, Training Accuracy: 1.872\n",
            "Worker 7, [02/4]: Training Loss: 4.461949859, Training Accuracy: 3.264\n",
            "Worker 7, [03/4]: Training Loss: 4.203264888, Training Accuracy: 5.648\n",
            "Worker 7, [04/4]: Training Loss: 4.058609289, Training Accuracy: 7.296\n",
            "Time taken for training worker 7: 0:00:10.797557\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 4.592283813, Training Accuracy: 1.568\n",
            "Worker 8, [02/4]: Training Loss: 4.441539983, Training Accuracy: 3.936\n",
            "Worker 8, [03/4]: Training Loss: 4.183607464, Training Accuracy: 6.320\n",
            "Worker 8, [04/4]: Training Loss: 4.043018901, Training Accuracy: 8.016\n",
            "Time taken for training worker 8: 0:00:10.644265\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000798\n",
            "Local Step 01: Test Loss: 4.056192017, Test Accuracy: 8.640\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 4.083124175, Training Accuracy: 8.368\n",
            "Worker 1, [02/4]: Training Loss: 4.063711947, Training Accuracy: 7.696\n",
            "Worker 1, [03/4]: Training Loss: 4.062784051, Training Accuracy: 7.008\n",
            "Worker 1, [04/4]: Training Loss: 4.015756780, Training Accuracy: 7.744\n",
            "Time taken for training worker 1: 0:00:11.189849\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 4.003859693, Training Accuracy: 8.448\n",
            "Worker 2, [02/4]: Training Loss: 3.927417106, Training Accuracy: 9.344\n",
            "Worker 2, [03/4]: Training Loss: 3.880452158, Training Accuracy: 10.144\n",
            "Worker 2, [04/4]: Training Loss: 3.841771087, Training Accuracy: 10.000\n",
            "Time taken for training worker 2: 0:00:10.645465\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 3.889253441, Training Accuracy: 10.752\n",
            "Worker 3, [02/4]: Training Loss: 3.771289769, Training Accuracy: 12.928\n",
            "Worker 3, [03/4]: Training Loss: 3.728410113, Training Accuracy: 12.416\n",
            "Worker 3, [04/4]: Training Loss: 3.719975447, Training Accuracy: 12.432\n",
            "Time taken for training worker 3: 0:00:11.262237\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 3.732993226, Training Accuracy: 13.248\n",
            "Worker 4, [02/4]: Training Loss: 3.628408600, Training Accuracy: 14.640\n",
            "Worker 4, [03/4]: Training Loss: 3.583794484, Training Accuracy: 15.376\n",
            "Worker 4, [04/4]: Training Loss: 3.572212548, Training Accuracy: 14.704\n",
            "Time taken for training worker 4: 0:00:11.323685\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 3.656880398, Training Accuracy: 12.848\n",
            "Worker 5, [02/4]: Training Loss: 3.518833632, Training Accuracy: 15.952\n",
            "Worker 5, [03/4]: Training Loss: 3.501226007, Training Accuracy: 16.320\n",
            "Worker 5, [04/4]: Training Loss: 3.490980688, Training Accuracy: 15.616\n",
            "Time taken for training worker 5: 0:00:12.028311\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 3.526342188, Training Accuracy: 16.016\n",
            "Worker 6, [02/4]: Training Loss: 3.369200315, Training Accuracy: 18.800\n",
            "Worker 6, [03/4]: Training Loss: 3.352427855, Training Accuracy: 18.704\n",
            "Worker 6, [04/4]: Training Loss: 3.360381642, Training Accuracy: 18.672\n",
            "Time taken for training worker 6: 0:00:10.904664\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 3.443489773, Training Accuracy: 17.424\n",
            "Worker 7, [02/4]: Training Loss: 3.301119880, Training Accuracy: 20.624\n",
            "Worker 7, [03/4]: Training Loss: 3.270568636, Training Accuracy: 20.640\n",
            "Worker 7, [04/4]: Training Loss: 3.267610964, Training Accuracy: 20.048\n",
            "Time taken for training worker 7: 0:00:10.693499\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 3.414189052, Training Accuracy: 17.360\n",
            "Worker 8, [02/4]: Training Loss: 3.222525475, Training Accuracy: 21.648\n",
            "Worker 8, [03/4]: Training Loss: 3.190109698, Training Accuracy: 21.872\n",
            "Worker 8, [04/4]: Training Loss: 3.212643767, Training Accuracy: 20.944\n",
            "Time taken for training worker 8: 0:00:10.747545\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000932\n",
            "Local Step 02: Test Loss: 3.164130569, Test Accuracy: 22.450\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 3.338788998, Training Accuracy: 19.232\n",
            "Worker 1, [02/4]: Training Loss: 3.157213391, Training Accuracy: 22.048\n",
            "Worker 1, [03/4]: Training Loss: 2.948475006, Training Accuracy: 26.096\n",
            "Worker 1, [04/4]: Training Loss: 2.769284088, Training Accuracy: 29.440\n",
            "Time taken for training worker 1: 0:00:10.669546\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 3.258172514, Training Accuracy: 20.048\n",
            "Worker 2, [02/4]: Training Loss: 3.050893791, Training Accuracy: 23.744\n",
            "Worker 2, [03/4]: Training Loss: 2.873117269, Training Accuracy: 27.040\n",
            "Worker 2, [04/4]: Training Loss: 2.671962565, Training Accuracy: 31.328\n",
            "Time taken for training worker 2: 0:00:11.047783\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 3.150950283, Training Accuracy: 22.768\n",
            "Worker 3, [02/4]: Training Loss: 2.967420532, Training Accuracy: 25.856\n",
            "Worker 3, [03/4]: Training Loss: 2.792710197, Training Accuracy: 28.624\n",
            "Worker 3, [04/4]: Training Loss: 2.551680066, Training Accuracy: 33.872\n",
            "Time taken for training worker 3: 0:00:11.693105\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 3.068685203, Training Accuracy: 24.336\n",
            "Worker 4, [02/4]: Training Loss: 2.888847675, Training Accuracy: 26.784\n",
            "Worker 4, [03/4]: Training Loss: 2.682879927, Training Accuracy: 31.776\n",
            "Worker 4, [04/4]: Training Loss: 2.459219481, Training Accuracy: 36.464\n",
            "Time taken for training worker 4: 0:00:11.296832\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 3.033030943, Training Accuracy: 24.784\n",
            "Worker 5, [02/4]: Training Loss: 2.865522302, Training Accuracy: 26.736\n",
            "Worker 5, [03/4]: Training Loss: 2.639321731, Training Accuracy: 31.872\n",
            "Worker 5, [04/4]: Training Loss: 2.395717783, Training Accuracy: 37.392\n",
            "Time taken for training worker 5: 0:00:10.957269\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.899069837, Training Accuracy: 27.312\n",
            "Worker 6, [02/4]: Training Loss: 2.713427982, Training Accuracy: 30.672\n",
            "Worker 6, [03/4]: Training Loss: 2.499412147, Training Accuracy: 35.232\n",
            "Worker 6, [04/4]: Training Loss: 2.280487215, Training Accuracy: 39.536\n",
            "Time taken for training worker 6: 0:00:10.505174\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.858965716, Training Accuracy: 28.928\n",
            "Worker 7, [02/4]: Training Loss: 2.695236836, Training Accuracy: 31.264\n",
            "Worker 7, [03/4]: Training Loss: 2.472411423, Training Accuracy: 36.048\n",
            "Worker 7, [04/4]: Training Loss: 2.249815577, Training Accuracy: 40.752\n",
            "Time taken for training worker 7: 0:00:10.744857\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.822096085, Training Accuracy: 29.296\n",
            "Worker 8, [02/4]: Training Loss: 2.606396310, Training Accuracy: 33.296\n",
            "Worker 8, [03/4]: Training Loss: 2.412527319, Training Accuracy: 36.432\n",
            "Worker 8, [04/4]: Training Loss: 2.173149305, Training Accuracy: 41.984\n",
            "Time taken for training worker 8: 0:00:10.427137\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000830\n",
            "Local Step 03: Test Loss: 2.456938487, Test Accuracy: 36.820\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.610269257, Training Accuracy: 34.192\n",
            "Worker 1, [02/4]: Training Loss: 2.561239010, Training Accuracy: 34.736\n",
            "Worker 1, [03/4]: Training Loss: 2.570176054, Training Accuracy: 33.600\n",
            "Worker 1, [04/4]: Training Loss: 2.598356685, Training Accuracy: 33.296\n",
            "Time taken for training worker 1: 0:00:11.592283\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.702691540, Training Accuracy: 31.248\n",
            "Worker 2, [02/4]: Training Loss: 2.552982491, Training Accuracy: 35.072\n",
            "Worker 2, [03/4]: Training Loss: 2.531114909, Training Accuracy: 34.960\n",
            "Worker 2, [04/4]: Training Loss: 2.551012003, Training Accuracy: 34.544\n",
            "Time taken for training worker 2: 0:00:10.678489\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.671043919, Training Accuracy: 32.256\n",
            "Worker 3, [02/4]: Training Loss: 2.516337949, Training Accuracy: 35.264\n",
            "Worker 3, [03/4]: Training Loss: 2.498649247, Training Accuracy: 35.312\n",
            "Worker 3, [04/4]: Training Loss: 2.507108756, Training Accuracy: 34.800\n",
            "Time taken for training worker 3: 0:00:10.557891\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.622700268, Training Accuracy: 32.384\n",
            "Worker 4, [02/4]: Training Loss: 2.476155747, Training Accuracy: 35.920\n",
            "Worker 4, [03/4]: Training Loss: 2.459022597, Training Accuracy: 36.128\n",
            "Worker 4, [04/4]: Training Loss: 2.481992746, Training Accuracy: 35.200\n",
            "Time taken for training worker 4: 0:00:11.648001\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.653190226, Training Accuracy: 31.536\n",
            "Worker 5, [02/4]: Training Loss: 2.474155934, Training Accuracy: 35.504\n",
            "Worker 5, [03/4]: Training Loss: 2.467281967, Training Accuracy: 35.280\n",
            "Worker 5, [04/4]: Training Loss: 2.485814001, Training Accuracy: 35.424\n",
            "Time taken for training worker 5: 0:00:11.378163\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.659095320, Training Accuracy: 32.640\n",
            "Worker 6, [02/4]: Training Loss: 2.403692604, Training Accuracy: 37.040\n",
            "Worker 6, [03/4]: Training Loss: 2.378333362, Training Accuracy: 38.176\n",
            "Worker 6, [04/4]: Training Loss: 2.414948855, Training Accuracy: 36.688\n",
            "Time taken for training worker 6: 0:00:10.306554\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.545094531, Training Accuracy: 35.040\n",
            "Worker 7, [02/4]: Training Loss: 2.380480406, Training Accuracy: 38.064\n",
            "Worker 7, [03/4]: Training Loss: 2.365051684, Training Accuracy: 38.704\n",
            "Worker 7, [04/4]: Training Loss: 2.360389843, Training Accuracy: 38.416\n",
            "Time taken for training worker 7: 0:00:11.352883\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.536485127, Training Accuracy: 34.240\n",
            "Worker 8, [02/4]: Training Loss: 2.339303669, Training Accuracy: 38.672\n",
            "Worker 8, [03/4]: Training Loss: 2.316580178, Training Accuracy: 38.496\n",
            "Worker 8, [04/4]: Training Loss: 2.359149708, Training Accuracy: 37.632\n",
            "Time taken for training worker 8: 0:00:11.185008\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000842\n",
            "Local Step 04: Test Loss: 2.511309331, Test Accuracy: 35.220\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.617053227, Training Accuracy: 32.784\n",
            "Worker 1, [02/4]: Training Loss: 2.374278988, Training Accuracy: 38.096\n",
            "Worker 1, [03/4]: Training Loss: 2.136511076, Training Accuracy: 42.832\n",
            "Worker 1, [04/4]: Training Loss: 1.860649812, Training Accuracy: 49.440\n",
            "Time taken for training worker 1: 0:00:10.727040\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.572284846, Training Accuracy: 33.680\n",
            "Worker 2, [02/4]: Training Loss: 2.366868694, Training Accuracy: 37.856\n",
            "Worker 2, [03/4]: Training Loss: 2.076343137, Training Accuracy: 44.224\n",
            "Worker 2, [04/4]: Training Loss: 1.863031294, Training Accuracy: 48.784\n",
            "Time taken for training worker 2: 0:00:10.685240\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.583031866, Training Accuracy: 34.560\n",
            "Worker 3, [02/4]: Training Loss: 2.317594483, Training Accuracy: 38.976\n",
            "Worker 3, [03/4]: Training Loss: 2.063809177, Training Accuracy: 44.336\n",
            "Worker 3, [04/4]: Training Loss: 1.820873241, Training Accuracy: 50.288\n",
            "Time taken for training worker 3: 0:00:10.545839\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.536759043, Training Accuracy: 34.896\n",
            "Worker 4, [02/4]: Training Loss: 2.303006560, Training Accuracy: 39.808\n",
            "Worker 4, [03/4]: Training Loss: 2.049605360, Training Accuracy: 45.152\n",
            "Worker 4, [04/4]: Training Loss: 1.807271502, Training Accuracy: 50.624\n",
            "Time taken for training worker 4: 0:00:10.261081\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.537123900, Training Accuracy: 34.464\n",
            "Worker 5, [02/4]: Training Loss: 2.318661658, Training Accuracy: 38.544\n",
            "Worker 5, [03/4]: Training Loss: 2.027452777, Training Accuracy: 44.784\n",
            "Worker 5, [04/4]: Training Loss: 1.792542285, Training Accuracy: 50.400\n",
            "Time taken for training worker 5: 0:00:11.190137\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.464882987, Training Accuracy: 36.752\n",
            "Worker 6, [02/4]: Training Loss: 2.244465616, Training Accuracy: 41.328\n",
            "Worker 6, [03/4]: Training Loss: 1.987148840, Training Accuracy: 46.512\n",
            "Worker 6, [04/4]: Training Loss: 1.742234214, Training Accuracy: 52.064\n",
            "Time taken for training worker 6: 0:00:11.843266\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.468644666, Training Accuracy: 37.216\n",
            "Worker 7, [02/4]: Training Loss: 2.231261409, Training Accuracy: 41.440\n",
            "Worker 7, [03/4]: Training Loss: 1.975910873, Training Accuracy: 47.120\n",
            "Worker 7, [04/4]: Training Loss: 1.728809765, Training Accuracy: 52.272\n",
            "Time taken for training worker 7: 0:00:11.414332\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.461062221, Training Accuracy: 35.440\n",
            "Worker 8, [02/4]: Training Loss: 2.206770315, Training Accuracy: 40.880\n",
            "Worker 8, [03/4]: Training Loss: 1.926236111, Training Accuracy: 47.120\n",
            "Worker 8, [04/4]: Training Loss: 1.675081569, Training Accuracy: 53.440\n",
            "Time taken for training worker 8: 0:00:11.246999\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000785\n",
            "Local Step 05: Test Loss: 2.193094416, Test Accuracy: 43.280\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.249869052, Training Accuracy: 42.160\n",
            "Worker 1, [02/4]: Training Loss: 2.199336365, Training Accuracy: 43.168\n",
            "Worker 1, [03/4]: Training Loss: 2.163860927, Training Accuracy: 43.312\n",
            "Worker 1, [04/4]: Training Loss: 2.179847347, Training Accuracy: 42.944\n",
            "Time taken for training worker 1: 0:00:11.094345\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.385401396, Training Accuracy: 38.736\n",
            "Worker 2, [02/4]: Training Loss: 2.196813402, Training Accuracy: 42.704\n",
            "Worker 2, [03/4]: Training Loss: 2.145321941, Training Accuracy: 42.512\n",
            "Worker 2, [04/4]: Training Loss: 2.138490925, Training Accuracy: 43.024\n",
            "Time taken for training worker 2: 0:00:10.847847\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.445147569, Training Accuracy: 36.368\n",
            "Worker 3, [02/4]: Training Loss: 2.193197935, Training Accuracy: 42.304\n",
            "Worker 3, [03/4]: Training Loss: 2.107592929, Training Accuracy: 43.792\n",
            "Worker 3, [04/4]: Training Loss: 2.147842896, Training Accuracy: 42.320\n",
            "Time taken for training worker 3: 0:00:10.750450\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.325821975, Training Accuracy: 39.568\n",
            "Worker 4, [02/4]: Training Loss: 2.101954526, Training Accuracy: 44.624\n",
            "Worker 4, [03/4]: Training Loss: 2.110117968, Training Accuracy: 44.144\n",
            "Worker 4, [04/4]: Training Loss: 2.098371168, Training Accuracy: 44.416\n",
            "Time taken for training worker 4: 0:00:10.659300\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.383338736, Training Accuracy: 38.000\n",
            "Worker 5, [02/4]: Training Loss: 2.160231498, Training Accuracy: 42.992\n",
            "Worker 5, [03/4]: Training Loss: 2.112576924, Training Accuracy: 43.888\n",
            "Worker 5, [04/4]: Training Loss: 2.105899731, Training Accuracy: 43.520\n",
            "Time taken for training worker 5: 0:00:10.733144\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.295965590, Training Accuracy: 40.560\n",
            "Worker 6, [02/4]: Training Loss: 2.087096700, Training Accuracy: 44.896\n",
            "Worker 6, [03/4]: Training Loss: 2.028836598, Training Accuracy: 45.520\n",
            "Worker 6, [04/4]: Training Loss: 2.047314208, Training Accuracy: 45.264\n",
            "Time taken for training worker 6: 0:00:10.493617\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.376549394, Training Accuracy: 37.216\n",
            "Worker 7, [02/4]: Training Loss: 2.086019053, Training Accuracy: 44.736\n",
            "Worker 7, [03/4]: Training Loss: 2.027686652, Training Accuracy: 46.112\n",
            "Worker 7, [04/4]: Training Loss: 2.026909294, Training Accuracy: 45.344\n",
            "Time taken for training worker 7: 0:00:11.278218\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.335553063, Training Accuracy: 39.632\n",
            "Worker 8, [02/4]: Training Loss: 2.068216739, Training Accuracy: 44.880\n",
            "Worker 8, [03/4]: Training Loss: 2.005527485, Training Accuracy: 46.256\n",
            "Worker 8, [04/4]: Training Loss: 1.977970952, Training Accuracy: 46.160\n",
            "Time taken for training worker 8: 0:00:10.698675\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000687\n",
            "Local Step 06: Test Loss: 2.263175278, Test Accuracy: 41.110\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.328561353, Training Accuracy: 39.408\n",
            "Worker 1, [02/4]: Training Loss: 2.041174765, Training Accuracy: 45.136\n",
            "Worker 1, [03/4]: Training Loss: 1.776999292, Training Accuracy: 51.648\n",
            "Worker 1, [04/4]: Training Loss: 1.503514516, Training Accuracy: 58.912\n",
            "Time taken for training worker 1: 0:00:10.522988\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.327548224, Training Accuracy: 39.872\n",
            "Worker 2, [02/4]: Training Loss: 2.054766286, Training Accuracy: 45.488\n",
            "Worker 2, [03/4]: Training Loss: 1.765496006, Training Accuracy: 51.216\n",
            "Worker 2, [04/4]: Training Loss: 1.520703537, Training Accuracy: 57.632\n",
            "Time taken for training worker 2: 0:00:10.776365\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.292713680, Training Accuracy: 40.288\n",
            "Worker 3, [02/4]: Training Loss: 2.028525598, Training Accuracy: 44.928\n",
            "Worker 3, [03/4]: Training Loss: 1.741398723, Training Accuracy: 51.360\n",
            "Worker 3, [04/4]: Training Loss: 1.500551601, Training Accuracy: 58.512\n",
            "Time taken for training worker 3: 0:00:10.649535\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.316115769, Training Accuracy: 39.776\n",
            "Worker 4, [02/4]: Training Loss: 2.010911910, Training Accuracy: 46.576\n",
            "Worker 4, [03/4]: Training Loss: 1.753277348, Training Accuracy: 52.112\n",
            "Worker 4, [04/4]: Training Loss: 1.500939364, Training Accuracy: 58.512\n",
            "Time taken for training worker 4: 0:00:11.277499\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.325983204, Training Accuracy: 39.472\n",
            "Worker 5, [02/4]: Training Loss: 2.053519944, Training Accuracy: 44.672\n",
            "Worker 5, [03/4]: Training Loss: 1.761182111, Training Accuracy: 50.736\n",
            "Worker 5, [04/4]: Training Loss: 1.511822431, Training Accuracy: 57.808\n",
            "Time taken for training worker 5: 0:00:11.071084\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.256616895, Training Accuracy: 40.576\n",
            "Worker 6, [02/4]: Training Loss: 1.951471853, Training Accuracy: 47.312\n",
            "Worker 6, [03/4]: Training Loss: 1.717319006, Training Accuracy: 52.416\n",
            "Worker 6, [04/4]: Training Loss: 1.460287678, Training Accuracy: 59.296\n",
            "Time taken for training worker 6: 0:00:10.416618\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.280539651, Training Accuracy: 40.496\n",
            "Worker 7, [02/4]: Training Loss: 2.013885498, Training Accuracy: 45.824\n",
            "Worker 7, [03/4]: Training Loss: 1.707872892, Training Accuracy: 53.328\n",
            "Worker 7, [04/4]: Training Loss: 1.464230155, Training Accuracy: 58.832\n",
            "Time taken for training worker 7: 0:00:11.113831\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.263592583, Training Accuracy: 40.544\n",
            "Worker 8, [02/4]: Training Loss: 2.001029939, Training Accuracy: 46.160\n",
            "Worker 8, [03/4]: Training Loss: 1.687174203, Training Accuracy: 53.152\n",
            "Worker 8, [04/4]: Training Loss: 1.428889487, Training Accuracy: 59.552\n",
            "Time taken for training worker 8: 0:00:10.786131\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000766\n",
            "Local Step 07: Test Loss: 2.067129592, Test Accuracy: 47.240\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.071667095, Training Accuracy: 46.144\n",
            "Worker 1, [02/4]: Training Loss: 1.971001889, Training Accuracy: 47.360\n",
            "Worker 1, [03/4]: Training Loss: 1.935424457, Training Accuracy: 47.888\n",
            "Worker 1, [04/4]: Training Loss: 1.967460180, Training Accuracy: 46.304\n",
            "Time taken for training worker 1: 0:00:10.667931\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.215223179, Training Accuracy: 41.936\n",
            "Worker 2, [02/4]: Training Loss: 1.979414199, Training Accuracy: 46.304\n",
            "Worker 2, [03/4]: Training Loss: 1.924396573, Training Accuracy: 47.440\n",
            "Worker 2, [04/4]: Training Loss: 1.949195274, Training Accuracy: 47.104\n",
            "Time taken for training worker 2: 0:00:10.318308\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.109830131, Training Accuracy: 44.272\n",
            "Worker 3, [02/4]: Training Loss: 1.953754611, Training Accuracy: 47.456\n",
            "Worker 3, [03/4]: Training Loss: 1.916366665, Training Accuracy: 48.544\n",
            "Worker 3, [04/4]: Training Loss: 1.914361347, Training Accuracy: 48.192\n",
            "Time taken for training worker 3: 0:00:11.632614\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.233619628, Training Accuracy: 41.216\n",
            "Worker 4, [02/4]: Training Loss: 1.942918173, Training Accuracy: 48.320\n",
            "Worker 4, [03/4]: Training Loss: 1.884208215, Training Accuracy: 49.168\n",
            "Worker 4, [04/4]: Training Loss: 1.903972625, Training Accuracy: 48.752\n",
            "Time taken for training worker 4: 0:00:11.321037\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.228589563, Training Accuracy: 40.576\n",
            "Worker 5, [02/4]: Training Loss: 1.973774122, Training Accuracy: 46.672\n",
            "Worker 5, [03/4]: Training Loss: 1.921354535, Training Accuracy: 46.864\n",
            "Worker 5, [04/4]: Training Loss: 1.910577676, Training Accuracy: 47.440\n",
            "Time taken for training worker 5: 0:00:10.371511\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.088782196, Training Accuracy: 45.120\n",
            "Worker 6, [02/4]: Training Loss: 1.898925274, Training Accuracy: 48.816\n",
            "Worker 6, [03/4]: Training Loss: 1.814421775, Training Accuracy: 50.352\n",
            "Worker 6, [04/4]: Training Loss: 1.856649957, Training Accuracy: 49.712\n",
            "Time taken for training worker 6: 0:00:10.886105\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.068335289, Training Accuracy: 44.112\n",
            "Worker 7, [02/4]: Training Loss: 1.880122375, Training Accuracy: 49.744\n",
            "Worker 7, [03/4]: Training Loss: 1.835932700, Training Accuracy: 50.144\n",
            "Worker 7, [04/4]: Training Loss: 1.840031371, Training Accuracy: 49.776\n",
            "Time taken for training worker 7: 0:00:10.551984\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.088922020, Training Accuracy: 43.552\n",
            "Worker 8, [02/4]: Training Loss: 1.867954269, Training Accuracy: 48.496\n",
            "Worker 8, [03/4]: Training Loss: 1.779355228, Training Accuracy: 50.640\n",
            "Worker 8, [04/4]: Training Loss: 1.833056430, Training Accuracy: 48.928\n",
            "Time taken for training worker 8: 0:00:10.737540\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000735\n",
            "Local Step 08: Test Loss: 2.122974199, Test Accuracy: 44.900\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.175400279, Training Accuracy: 42.544\n",
            "Worker 1, [02/4]: Training Loss: 1.847240547, Training Accuracy: 50.000\n",
            "Worker 1, [03/4]: Training Loss: 1.539144169, Training Accuracy: 57.168\n",
            "Worker 1, [04/4]: Training Loss: 1.300433270, Training Accuracy: 63.952\n",
            "Time taken for training worker 1: 0:00:10.996756\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.173773672, Training Accuracy: 42.784\n",
            "Worker 2, [02/4]: Training Loss: 1.827925048, Training Accuracy: 50.432\n",
            "Worker 2, [03/4]: Training Loss: 1.564892551, Training Accuracy: 56.688\n",
            "Worker 2, [04/4]: Training Loss: 1.322246816, Training Accuracy: 62.928\n",
            "Time taken for training worker 2: 0:00:11.320045\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.173616983, Training Accuracy: 42.640\n",
            "Worker 3, [02/4]: Training Loss: 1.861918171, Training Accuracy: 48.928\n",
            "Worker 3, [03/4]: Training Loss: 1.548220329, Training Accuracy: 56.208\n",
            "Worker 3, [04/4]: Training Loss: 1.299825025, Training Accuracy: 63.024\n",
            "Time taken for training worker 3: 0:00:10.959992\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.134410170, Training Accuracy: 43.648\n",
            "Worker 4, [02/4]: Training Loss: 1.860195646, Training Accuracy: 49.824\n",
            "Worker 4, [03/4]: Training Loss: 1.556328528, Training Accuracy: 56.544\n",
            "Worker 4, [04/4]: Training Loss: 1.337423575, Training Accuracy: 62.288\n",
            "Time taken for training worker 4: 0:00:11.166069\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.231952617, Training Accuracy: 41.472\n",
            "Worker 5, [02/4]: Training Loss: 1.938632769, Training Accuracy: 47.104\n",
            "Worker 5, [03/4]: Training Loss: 1.611825438, Training Accuracy: 55.168\n",
            "Worker 5, [04/4]: Training Loss: 1.344429650, Training Accuracy: 62.064\n",
            "Time taken for training worker 5: 0:00:11.307709\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.110379069, Training Accuracy: 44.656\n",
            "Worker 6, [02/4]: Training Loss: 1.795256551, Training Accuracy: 51.328\n",
            "Worker 6, [03/4]: Training Loss: 1.536072360, Training Accuracy: 57.408\n",
            "Worker 6, [04/4]: Training Loss: 1.281264679, Training Accuracy: 63.312\n",
            "Time taken for training worker 6: 0:00:11.856874\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.186525650, Training Accuracy: 42.832\n",
            "Worker 7, [02/4]: Training Loss: 1.856190976, Training Accuracy: 50.032\n",
            "Worker 7, [03/4]: Training Loss: 1.567832935, Training Accuracy: 56.608\n",
            "Worker 7, [04/4]: Training Loss: 1.302607158, Training Accuracy: 64.064\n",
            "Time taken for training worker 7: 0:00:10.891300\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.115926979, Training Accuracy: 42.816\n",
            "Worker 8, [02/4]: Training Loss: 1.817859853, Training Accuracy: 49.696\n",
            "Worker 8, [03/4]: Training Loss: 1.522018309, Training Accuracy: 56.480\n",
            "Worker 8, [04/4]: Training Loss: 1.285985416, Training Accuracy: 63.136\n",
            "Time taken for training worker 8: 0:00:11.071490\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000749\n",
            "Local Step 09: Test Loss: 2.038336172, Test Accuracy: 48.630\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.947654995, Training Accuracy: 49.120\n",
            "Worker 1, [02/4]: Training Loss: 1.839129200, Training Accuracy: 50.864\n",
            "Worker 1, [03/4]: Training Loss: 1.819018978, Training Accuracy: 50.448\n",
            "Worker 1, [04/4]: Training Loss: 1.801888304, Training Accuracy: 50.496\n",
            "Time taken for training worker 1: 0:00:11.215431\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.089290374, Training Accuracy: 44.544\n",
            "Worker 2, [02/4]: Training Loss: 1.851843602, Training Accuracy: 49.664\n",
            "Worker 2, [03/4]: Training Loss: 1.781062040, Training Accuracy: 51.648\n",
            "Worker 2, [04/4]: Training Loss: 1.803768151, Training Accuracy: 50.016\n",
            "Time taken for training worker 2: 0:00:10.614502\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.045635808, Training Accuracy: 45.408\n",
            "Worker 3, [02/4]: Training Loss: 1.834780424, Training Accuracy: 50.064\n",
            "Worker 3, [03/4]: Training Loss: 1.759427586, Training Accuracy: 51.072\n",
            "Worker 3, [04/4]: Training Loss: 1.769093857, Training Accuracy: 51.728\n",
            "Time taken for training worker 3: 0:00:10.890810\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.073007734, Training Accuracy: 44.656\n",
            "Worker 4, [02/4]: Training Loss: 1.850349451, Training Accuracy: 49.920\n",
            "Worker 4, [03/4]: Training Loss: 1.743604077, Training Accuracy: 52.368\n",
            "Worker 4, [04/4]: Training Loss: 1.750723535, Training Accuracy: 51.648\n",
            "Time taken for training worker 4: 0:00:11.540483\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.070045402, Training Accuracy: 44.832\n",
            "Worker 5, [02/4]: Training Loss: 1.835591069, Training Accuracy: 50.080\n",
            "Worker 5, [03/4]: Training Loss: 1.774946805, Training Accuracy: 50.912\n",
            "Worker 5, [04/4]: Training Loss: 1.782597963, Training Accuracy: 50.672\n",
            "Time taken for training worker 5: 0:00:11.217017\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.963095073, Training Accuracy: 47.232\n",
            "Worker 6, [02/4]: Training Loss: 1.755603433, Training Accuracy: 51.632\n",
            "Worker 6, [03/4]: Training Loss: 1.694195999, Training Accuracy: 53.104\n",
            "Worker 6, [04/4]: Training Loss: 1.664274787, Training Accuracy: 52.832\n",
            "Time taken for training worker 6: 0:00:11.783848\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.056416859, Training Accuracy: 45.520\n",
            "Worker 7, [02/4]: Training Loss: 1.797079455, Training Accuracy: 50.768\n",
            "Worker 7, [03/4]: Training Loss: 1.722963028, Training Accuracy: 52.224\n",
            "Worker 7, [04/4]: Training Loss: 1.727562844, Training Accuracy: 52.416\n",
            "Time taken for training worker 7: 0:00:11.169425\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.938740757, Training Accuracy: 46.896\n",
            "Worker 8, [02/4]: Training Loss: 1.735361440, Training Accuracy: 51.888\n",
            "Worker 8, [03/4]: Training Loss: 1.653531690, Training Accuracy: 53.648\n",
            "Worker 8, [04/4]: Training Loss: 1.683650766, Training Accuracy: 52.576\n",
            "Time taken for training worker 8: 0:00:11.213437\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000795\n",
            "Local Step 10: Test Loss: 2.084452353, Test Accuracy: 46.090\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 2.022367369, Training Accuracy: 45.920\n",
            "Worker 1, [02/4]: Training Loss: 1.714209872, Training Accuracy: 52.976\n",
            "Worker 1, [03/4]: Training Loss: 1.432966518, Training Accuracy: 60.016\n",
            "Worker 1, [04/4]: Training Loss: 1.153161302, Training Accuracy: 66.896\n",
            "Time taken for training worker 1: 0:00:11.181396\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 2.071976798, Training Accuracy: 44.784\n",
            "Worker 2, [02/4]: Training Loss: 1.739704215, Training Accuracy: 51.760\n",
            "Worker 2, [03/4]: Training Loss: 1.433455916, Training Accuracy: 59.296\n",
            "Worker 2, [04/4]: Training Loss: 1.176677245, Training Accuracy: 66.320\n",
            "Time taken for training worker 2: 0:00:10.791387\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 2.039355234, Training Accuracy: 45.088\n",
            "Worker 3, [02/4]: Training Loss: 1.730802986, Training Accuracy: 52.480\n",
            "Worker 3, [03/4]: Training Loss: 1.415083888, Training Accuracy: 59.696\n",
            "Worker 3, [04/4]: Training Loss: 1.176115769, Training Accuracy: 66.528\n",
            "Time taken for training worker 3: 0:00:10.562409\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 2.059015922, Training Accuracy: 45.856\n",
            "Worker 4, [02/4]: Training Loss: 1.742497005, Training Accuracy: 51.824\n",
            "Worker 4, [03/4]: Training Loss: 1.447232218, Training Accuracy: 59.920\n",
            "Worker 4, [04/4]: Training Loss: 1.209968726, Training Accuracy: 65.840\n",
            "Time taken for training worker 4: 0:00:11.187042\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.101784254, Training Accuracy: 44.000\n",
            "Worker 5, [02/4]: Training Loss: 1.775813114, Training Accuracy: 51.040\n",
            "Worker 5, [03/4]: Training Loss: 1.453296079, Training Accuracy: 58.832\n",
            "Worker 5, [04/4]: Training Loss: 1.202038438, Training Accuracy: 65.632\n",
            "Time taken for training worker 5: 0:00:10.897064\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 2.026097412, Training Accuracy: 45.568\n",
            "Worker 6, [02/4]: Training Loss: 1.722267918, Training Accuracy: 52.352\n",
            "Worker 6, [03/4]: Training Loss: 1.420687796, Training Accuracy: 59.568\n",
            "Worker 6, [04/4]: Training Loss: 1.167633073, Training Accuracy: 66.528\n",
            "Time taken for training worker 6: 0:00:10.565420\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 2.090034840, Training Accuracy: 44.928\n",
            "Worker 7, [02/4]: Training Loss: 1.764288028, Training Accuracy: 51.536\n",
            "Worker 7, [03/4]: Training Loss: 1.427254973, Training Accuracy: 60.624\n",
            "Worker 7, [04/4]: Training Loss: 1.178345476, Training Accuracy: 66.944\n",
            "Time taken for training worker 7: 0:00:11.168852\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.048714014, Training Accuracy: 45.280\n",
            "Worker 8, [02/4]: Training Loss: 1.748409833, Training Accuracy: 51.840\n",
            "Worker 8, [03/4]: Training Loss: 1.432901268, Training Accuracy: 59.440\n",
            "Worker 8, [04/4]: Training Loss: 1.137477099, Training Accuracy: 67.168\n",
            "Time taken for training worker 8: 0:00:10.314831\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000722\n",
            "Local Step 11: Test Loss: 2.011811356, Test Accuracy: 50.120\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.833432689, Training Accuracy: 51.616\n",
            "Worker 1, [02/4]: Training Loss: 1.755380843, Training Accuracy: 52.240\n",
            "Worker 1, [03/4]: Training Loss: 1.707428232, Training Accuracy: 54.000\n",
            "Worker 1, [04/4]: Training Loss: 1.684945524, Training Accuracy: 53.824\n",
            "Time taken for training worker 1: 0:00:11.695952\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.947537416, Training Accuracy: 47.424\n",
            "Worker 2, [02/4]: Training Loss: 1.762749649, Training Accuracy: 51.920\n",
            "Worker 2, [03/4]: Training Loss: 1.684299769, Training Accuracy: 53.200\n",
            "Worker 2, [04/4]: Training Loss: 1.712368434, Training Accuracy: 52.320\n",
            "Time taken for training worker 2: 0:00:11.849171\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.986557277, Training Accuracy: 46.352\n",
            "Worker 3, [02/4]: Training Loss: 1.740998864, Training Accuracy: 52.352\n",
            "Worker 3, [03/4]: Training Loss: 1.656644370, Training Accuracy: 54.320\n",
            "Worker 3, [04/4]: Training Loss: 1.644668915, Training Accuracy: 54.864\n",
            "Time taken for training worker 3: 0:00:11.756244\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.885113571, Training Accuracy: 49.408\n",
            "Worker 4, [02/4]: Training Loss: 1.733299899, Training Accuracy: 52.704\n",
            "Worker 4, [03/4]: Training Loss: 1.658133496, Training Accuracy: 54.864\n",
            "Worker 4, [04/4]: Training Loss: 1.633188760, Training Accuracy: 54.976\n",
            "Time taken for training worker 4: 0:00:11.075313\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.957345175, Training Accuracy: 46.752\n",
            "Worker 5, [02/4]: Training Loss: 1.769605301, Training Accuracy: 50.640\n",
            "Worker 5, [03/4]: Training Loss: 1.658718096, Training Accuracy: 53.568\n",
            "Worker 5, [04/4]: Training Loss: 1.677473139, Training Accuracy: 52.816\n",
            "Time taken for training worker 5: 0:00:10.619380\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.870651291, Training Accuracy: 49.104\n",
            "Worker 6, [02/4]: Training Loss: 1.689259237, Training Accuracy: 53.392\n",
            "Worker 6, [03/4]: Training Loss: 1.591276979, Training Accuracy: 56.272\n",
            "Worker 6, [04/4]: Training Loss: 1.610772770, Training Accuracy: 53.904\n",
            "Time taken for training worker 6: 0:00:11.457305\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.884169001, Training Accuracy: 48.704\n",
            "Worker 7, [02/4]: Training Loss: 1.695005157, Training Accuracy: 53.632\n",
            "Worker 7, [03/4]: Training Loss: 1.640791071, Training Accuracy: 55.120\n",
            "Worker 7, [04/4]: Training Loss: 1.636784346, Training Accuracy: 54.496\n",
            "Time taken for training worker 7: 0:00:11.054200\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.925841643, Training Accuracy: 47.280\n",
            "Worker 8, [02/4]: Training Loss: 1.675118360, Training Accuracy: 53.504\n",
            "Worker 8, [03/4]: Training Loss: 1.541968906, Training Accuracy: 56.944\n",
            "Worker 8, [04/4]: Training Loss: 1.588854425, Training Accuracy: 55.808\n",
            "Time taken for training worker 8: 0:00:11.312932\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000819\n",
            "Local Step 12: Test Loss: 2.147593690, Test Accuracy: 46.080\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.989385855, Training Accuracy: 46.352\n",
            "Worker 1, [02/4]: Training Loss: 1.628706820, Training Accuracy: 54.560\n",
            "Worker 1, [03/4]: Training Loss: 1.322190785, Training Accuracy: 62.688\n",
            "Worker 1, [04/4]: Training Loss: 1.098825174, Training Accuracy: 68.768\n",
            "Time taken for training worker 1: 0:00:10.963372\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.975291712, Training Accuracy: 47.248\n",
            "Worker 2, [02/4]: Training Loss: 1.652349979, Training Accuracy: 54.080\n",
            "Worker 2, [03/4]: Training Loss: 1.376590648, Training Accuracy: 60.624\n",
            "Worker 2, [04/4]: Training Loss: 1.089609584, Training Accuracy: 69.120\n",
            "Time taken for training worker 2: 0:00:11.517537\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.998421603, Training Accuracy: 45.856\n",
            "Worker 3, [02/4]: Training Loss: 1.662287980, Training Accuracy: 53.344\n",
            "Worker 3, [03/4]: Training Loss: 1.339009378, Training Accuracy: 61.520\n",
            "Worker 3, [04/4]: Training Loss: 1.101293516, Training Accuracy: 68.144\n",
            "Time taken for training worker 3: 0:00:11.662818\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.990894965, Training Accuracy: 47.008\n",
            "Worker 4, [02/4]: Training Loss: 1.682059919, Training Accuracy: 53.008\n",
            "Worker 4, [03/4]: Training Loss: 1.370102196, Training Accuracy: 61.712\n",
            "Worker 4, [04/4]: Training Loss: 1.118990486, Training Accuracy: 68.416\n",
            "Time taken for training worker 4: 0:00:11.225446\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 2.006109132, Training Accuracy: 46.144\n",
            "Worker 5, [02/4]: Training Loss: 1.716611101, Training Accuracy: 52.752\n",
            "Worker 5, [03/4]: Training Loss: 1.380321121, Training Accuracy: 60.912\n",
            "Worker 5, [04/4]: Training Loss: 1.122984974, Training Accuracy: 67.664\n",
            "Time taken for training worker 5: 0:00:10.406111\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.937204564, Training Accuracy: 48.304\n",
            "Worker 6, [02/4]: Training Loss: 1.648483927, Training Accuracy: 53.696\n",
            "Worker 6, [03/4]: Training Loss: 1.342879759, Training Accuracy: 61.968\n",
            "Worker 6, [04/4]: Training Loss: 1.093803290, Training Accuracy: 68.800\n",
            "Time taken for training worker 6: 0:00:10.715060\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.981999363, Training Accuracy: 47.312\n",
            "Worker 7, [02/4]: Training Loss: 1.706536895, Training Accuracy: 52.528\n",
            "Worker 7, [03/4]: Training Loss: 1.369618955, Training Accuracy: 61.808\n",
            "Worker 7, [04/4]: Training Loss: 1.112259764, Training Accuracy: 67.904\n",
            "Time taken for training worker 7: 0:00:10.434873\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 2.004949261, Training Accuracy: 45.872\n",
            "Worker 8, [02/4]: Training Loss: 1.644749112, Training Accuracy: 54.528\n",
            "Worker 8, [03/4]: Training Loss: 1.343543640, Training Accuracy: 61.680\n",
            "Worker 8, [04/4]: Training Loss: 1.083737331, Training Accuracy: 68.960\n",
            "Time taken for training worker 8: 0:00:10.802872\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000833\n",
            "Local Step 13: Test Loss: 1.997897674, Test Accuracy: 50.460\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.765299728, Training Accuracy: 53.216\n",
            "Worker 1, [02/4]: Training Loss: 1.667013938, Training Accuracy: 54.752\n",
            "Worker 1, [03/4]: Training Loss: 1.614655620, Training Accuracy: 55.344\n",
            "Worker 1, [04/4]: Training Loss: 1.632245441, Training Accuracy: 53.888\n",
            "Time taken for training worker 1: 0:00:11.192922\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.968106462, Training Accuracy: 47.376\n",
            "Worker 2, [02/4]: Training Loss: 1.713925907, Training Accuracy: 52.688\n",
            "Worker 2, [03/4]: Training Loss: 1.632367050, Training Accuracy: 54.640\n",
            "Worker 2, [04/4]: Training Loss: 1.604083065, Training Accuracy: 55.536\n",
            "Time taken for training worker 2: 0:00:10.902681\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.930115407, Training Accuracy: 48.336\n",
            "Worker 3, [02/4]: Training Loss: 1.691624331, Training Accuracy: 53.312\n",
            "Worker 3, [03/4]: Training Loss: 1.608500858, Training Accuracy: 54.976\n",
            "Worker 3, [04/4]: Training Loss: 1.582541973, Training Accuracy: 56.016\n",
            "Time taken for training worker 3: 0:00:11.322774\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.909179644, Training Accuracy: 49.232\n",
            "Worker 4, [02/4]: Training Loss: 1.669078619, Training Accuracy: 54.224\n",
            "Worker 4, [03/4]: Training Loss: 1.609567642, Training Accuracy: 55.360\n",
            "Worker 4, [04/4]: Training Loss: 1.609691502, Training Accuracy: 54.832\n",
            "Time taken for training worker 4: 0:00:11.077074\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.928416695, Training Accuracy: 47.712\n",
            "Worker 5, [02/4]: Training Loss: 1.671210701, Training Accuracy: 53.632\n",
            "Worker 5, [03/4]: Training Loss: 1.586108314, Training Accuracy: 55.184\n",
            "Worker 5, [04/4]: Training Loss: 1.604927009, Training Accuracy: 55.296\n",
            "Time taken for training worker 5: 0:00:10.376404\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.828919722, Training Accuracy: 50.448\n",
            "Worker 6, [02/4]: Training Loss: 1.596011699, Training Accuracy: 55.440\n",
            "Worker 6, [03/4]: Training Loss: 1.527635833, Training Accuracy: 57.216\n",
            "Worker 6, [04/4]: Training Loss: 1.557933899, Training Accuracy: 56.624\n",
            "Time taken for training worker 6: 0:00:10.662229\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.816863353, Training Accuracy: 51.344\n",
            "Worker 7, [02/4]: Training Loss: 1.599847043, Training Accuracy: 55.824\n",
            "Worker 7, [03/4]: Training Loss: 1.536522168, Training Accuracy: 57.152\n",
            "Worker 7, [04/4]: Training Loss: 1.567298785, Training Accuracy: 56.624\n",
            "Time taken for training worker 7: 0:00:10.945280\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.848206192, Training Accuracy: 49.328\n",
            "Worker 8, [02/4]: Training Loss: 1.602692795, Training Accuracy: 54.976\n",
            "Worker 8, [03/4]: Training Loss: 1.496237546, Training Accuracy: 57.744\n",
            "Worker 8, [04/4]: Training Loss: 1.522493067, Training Accuracy: 57.392\n",
            "Time taken for training worker 8: 0:00:10.799056\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000794\n",
            "Local Step 14: Test Loss: 2.113357055, Test Accuracy: 45.910\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.912155825, Training Accuracy: 48.048\n",
            "Worker 1, [02/4]: Training Loss: 1.581895838, Training Accuracy: 56.224\n",
            "Worker 1, [03/4]: Training Loss: 1.275542936, Training Accuracy: 63.888\n",
            "Worker 1, [04/4]: Training Loss: 0.996200553, Training Accuracy: 71.568\n",
            "Time taken for training worker 1: 0:00:11.155137\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.944032470, Training Accuracy: 47.520\n",
            "Worker 2, [02/4]: Training Loss: 1.630078870, Training Accuracy: 54.352\n",
            "Worker 2, [03/4]: Training Loss: 1.275268545, Training Accuracy: 64.112\n",
            "Worker 2, [04/4]: Training Loss: 1.026930422, Training Accuracy: 70.880\n",
            "Time taken for training worker 2: 0:00:11.567581\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.915316829, Training Accuracy: 47.552\n",
            "Worker 3, [02/4]: Training Loss: 1.575264015, Training Accuracy: 55.776\n",
            "Worker 3, [03/4]: Training Loss: 1.254665121, Training Accuracy: 64.176\n",
            "Worker 3, [04/4]: Training Loss: 1.021474323, Training Accuracy: 69.824\n",
            "Time taken for training worker 3: 0:00:11.217869\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.947850748, Training Accuracy: 47.792\n",
            "Worker 4, [02/4]: Training Loss: 1.614746122, Training Accuracy: 56.208\n",
            "Worker 4, [03/4]: Training Loss: 1.316086782, Training Accuracy: 62.384\n",
            "Worker 4, [04/4]: Training Loss: 1.046833031, Training Accuracy: 69.536\n",
            "Time taken for training worker 4: 0:00:11.176271\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.982245855, Training Accuracy: 46.992\n",
            "Worker 5, [02/4]: Training Loss: 1.622709335, Training Accuracy: 54.352\n",
            "Worker 5, [03/4]: Training Loss: 1.309423764, Training Accuracy: 62.880\n",
            "Worker 5, [04/4]: Training Loss: 1.050663854, Training Accuracy: 69.744\n",
            "Time taken for training worker 5: 0:00:11.627337\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.942820515, Training Accuracy: 48.192\n",
            "Worker 6, [02/4]: Training Loss: 1.615121221, Training Accuracy: 55.280\n",
            "Worker 6, [03/4]: Training Loss: 1.308658464, Training Accuracy: 62.224\n",
            "Worker 6, [04/4]: Training Loss: 1.038972962, Training Accuracy: 70.096\n",
            "Time taken for training worker 6: 0:00:11.085554\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.940299451, Training Accuracy: 48.000\n",
            "Worker 7, [02/4]: Training Loss: 1.630824928, Training Accuracy: 54.608\n",
            "Worker 7, [03/4]: Training Loss: 1.287191854, Training Accuracy: 63.440\n",
            "Worker 7, [04/4]: Training Loss: 1.080476810, Training Accuracy: 69.504\n",
            "Time taken for training worker 7: 0:00:10.559262\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.919954473, Training Accuracy: 47.600\n",
            "Worker 8, [02/4]: Training Loss: 1.620519159, Training Accuracy: 55.024\n",
            "Worker 8, [03/4]: Training Loss: 1.285253391, Training Accuracy: 62.432\n",
            "Worker 8, [04/4]: Training Loss: 1.015083201, Training Accuracy: 71.104\n",
            "Time taken for training worker 8: 0:00:10.226928\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000749\n",
            "Local Step 15: Test Loss: 1.992243735, Test Accuracy: 50.690\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.748695304, Training Accuracy: 53.280\n",
            "Worker 1, [02/4]: Training Loss: 1.640611978, Training Accuracy: 55.520\n",
            "Worker 1, [03/4]: Training Loss: 1.559027060, Training Accuracy: 56.176\n",
            "Worker 1, [04/4]: Training Loss: 1.585065545, Training Accuracy: 55.984\n",
            "Time taken for training worker 1: 0:00:11.734992\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.856543650, Training Accuracy: 49.792\n",
            "Worker 2, [02/4]: Training Loss: 1.660180549, Training Accuracy: 53.792\n",
            "Worker 2, [03/4]: Training Loss: 1.562372008, Training Accuracy: 56.544\n",
            "Worker 2, [04/4]: Training Loss: 1.572166507, Training Accuracy: 55.120\n",
            "Time taken for training worker 2: 0:00:10.485151\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.876244457, Training Accuracy: 50.240\n",
            "Worker 3, [02/4]: Training Loss: 1.632741943, Training Accuracy: 54.464\n",
            "Worker 3, [03/4]: Training Loss: 1.537636539, Training Accuracy: 57.120\n",
            "Worker 3, [04/4]: Training Loss: 1.521262413, Training Accuracy: 57.248\n",
            "Time taken for training worker 3: 0:00:11.104677\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.862780864, Training Accuracy: 48.752\n",
            "Worker 4, [02/4]: Training Loss: 1.620100026, Training Accuracy: 55.296\n",
            "Worker 4, [03/4]: Training Loss: 1.549035614, Training Accuracy: 56.384\n",
            "Worker 4, [04/4]: Training Loss: 1.533259728, Training Accuracy: 56.784\n",
            "Time taken for training worker 4: 0:00:11.707135\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.850595733, Training Accuracy: 50.144\n",
            "Worker 5, [02/4]: Training Loss: 1.596924380, Training Accuracy: 55.248\n",
            "Worker 5, [03/4]: Training Loss: 1.528526396, Training Accuracy: 57.328\n",
            "Worker 5, [04/4]: Training Loss: 1.525258402, Training Accuracy: 56.240\n",
            "Time taken for training worker 5: 0:00:10.652764\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.729881940, Training Accuracy: 52.480\n",
            "Worker 6, [02/4]: Training Loss: 1.552477587, Training Accuracy: 57.120\n",
            "Worker 6, [03/4]: Training Loss: 1.505519470, Training Accuracy: 57.168\n",
            "Worker 6, [04/4]: Training Loss: 1.495369082, Training Accuracy: 57.088\n",
            "Time taken for training worker 6: 0:00:10.686801\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.805666089, Training Accuracy: 51.072\n",
            "Worker 7, [02/4]: Training Loss: 1.598559322, Training Accuracy: 56.304\n",
            "Worker 7, [03/4]: Training Loss: 1.491995961, Training Accuracy: 58.352\n",
            "Worker 7, [04/4]: Training Loss: 1.497808652, Training Accuracy: 57.600\n",
            "Time taken for training worker 7: 0:00:11.269132\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.730914947, Training Accuracy: 51.728\n",
            "Worker 8, [02/4]: Training Loss: 1.538662820, Training Accuracy: 56.560\n",
            "Worker 8, [03/4]: Training Loss: 1.433800296, Training Accuracy: 58.848\n",
            "Worker 8, [04/4]: Training Loss: 1.453356025, Training Accuracy: 59.056\n",
            "Time taken for training worker 8: 0:00:11.052136\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000956\n",
            "Local Step 16: Test Loss: 2.057335689, Test Accuracy: 48.220\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.866514294, Training Accuracy: 48.560\n",
            "Worker 1, [02/4]: Training Loss: 1.529421000, Training Accuracy: 57.040\n",
            "Worker 1, [03/4]: Training Loss: 1.212194400, Training Accuracy: 65.488\n",
            "Worker 1, [04/4]: Training Loss: 0.942693278, Training Accuracy: 72.784\n",
            "Time taken for training worker 1: 0:00:10.448382\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.870444151, Training Accuracy: 49.312\n",
            "Worker 2, [02/4]: Training Loss: 1.556271597, Training Accuracy: 56.240\n",
            "Worker 2, [03/4]: Training Loss: 1.239948012, Training Accuracy: 64.656\n",
            "Worker 2, [04/4]: Training Loss: 0.956142024, Training Accuracy: 71.840\n",
            "Time taken for training worker 2: 0:00:10.632916\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.879580362, Training Accuracy: 48.720\n",
            "Worker 3, [02/4]: Training Loss: 1.535436998, Training Accuracy: 56.752\n",
            "Worker 3, [03/4]: Training Loss: 1.228143523, Training Accuracy: 64.416\n",
            "Worker 3, [04/4]: Training Loss: 0.983693243, Training Accuracy: 71.712\n",
            "Time taken for training worker 3: 0:00:11.476485\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.961038380, Training Accuracy: 47.744\n",
            "Worker 4, [02/4]: Training Loss: 1.581575216, Training Accuracy: 56.080\n",
            "Worker 4, [03/4]: Training Loss: 1.260566574, Training Accuracy: 64.208\n",
            "Worker 4, [04/4]: Training Loss: 1.009140774, Training Accuracy: 70.464\n",
            "Time taken for training worker 4: 0:00:11.715156\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.946975740, Training Accuracy: 47.152\n",
            "Worker 5, [02/4]: Training Loss: 1.587977480, Training Accuracy: 55.680\n",
            "Worker 5, [03/4]: Training Loss: 1.286018227, Training Accuracy: 63.648\n",
            "Worker 5, [04/4]: Training Loss: 1.032451678, Training Accuracy: 70.096\n",
            "Time taken for training worker 5: 0:00:11.364194\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.884725121, Training Accuracy: 48.992\n",
            "Worker 6, [02/4]: Training Loss: 1.550518499, Training Accuracy: 56.848\n",
            "Worker 6, [03/4]: Training Loss: 1.243355159, Training Accuracy: 63.680\n",
            "Worker 6, [04/4]: Training Loss: 0.981206047, Training Accuracy: 71.504\n",
            "Time taken for training worker 6: 0:00:11.199462\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.918154218, Training Accuracy: 48.416\n",
            "Worker 7, [02/4]: Training Loss: 1.565453063, Training Accuracy: 56.176\n",
            "Worker 7, [03/4]: Training Loss: 1.249007397, Training Accuracy: 64.416\n",
            "Worker 7, [04/4]: Training Loss: 0.994241075, Training Accuracy: 71.280\n",
            "Time taken for training worker 7: 0:00:10.923628\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.920501894, Training Accuracy: 46.912\n",
            "Worker 8, [02/4]: Training Loss: 1.567819007, Training Accuracy: 55.744\n",
            "Worker 8, [03/4]: Training Loss: 1.228352115, Training Accuracy: 64.720\n",
            "Worker 8, [04/4]: Training Loss: 0.991315365, Training Accuracy: 71.520\n",
            "Time taken for training worker 8: 0:00:11.484260\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000798\n",
            "Local Step 17: Test Loss: 1.993101106, Test Accuracy: 51.300\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.691975428, Training Accuracy: 54.688\n",
            "Worker 1, [02/4]: Training Loss: 1.594822631, Training Accuracy: 56.048\n",
            "Worker 1, [03/4]: Training Loss: 1.526080430, Training Accuracy: 58.400\n",
            "Worker 1, [04/4]: Training Loss: 1.537158566, Training Accuracy: 56.864\n",
            "Time taken for training worker 1: 0:00:10.970454\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.840065942, Training Accuracy: 50.016\n",
            "Worker 2, [02/4]: Training Loss: 1.627272072, Training Accuracy: 54.768\n",
            "Worker 2, [03/4]: Training Loss: 1.530309641, Training Accuracy: 56.928\n",
            "Worker 2, [04/4]: Training Loss: 1.534818952, Training Accuracy: 56.768\n",
            "Time taken for training worker 2: 0:00:10.997964\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.807169386, Training Accuracy: 50.320\n",
            "Worker 3, [02/4]: Training Loss: 1.595842486, Training Accuracy: 54.912\n",
            "Worker 3, [03/4]: Training Loss: 1.504053960, Training Accuracy: 58.128\n",
            "Worker 3, [04/4]: Training Loss: 1.478255297, Training Accuracy: 58.304\n",
            "Time taken for training worker 3: 0:00:10.918012\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.817496510, Training Accuracy: 51.504\n",
            "Worker 4, [02/4]: Training Loss: 1.588374297, Training Accuracy: 55.792\n",
            "Worker 4, [03/4]: Training Loss: 1.502278827, Training Accuracy: 57.584\n",
            "Worker 4, [04/4]: Training Loss: 1.507795049, Training Accuracy: 57.040\n",
            "Time taken for training worker 4: 0:00:10.305762\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.798588775, Training Accuracy: 50.368\n",
            "Worker 5, [02/4]: Training Loss: 1.584712284, Training Accuracy: 55.568\n",
            "Worker 5, [03/4]: Training Loss: 1.487726210, Training Accuracy: 58.032\n",
            "Worker 5, [04/4]: Training Loss: 1.506299992, Training Accuracy: 57.872\n",
            "Time taken for training worker 5: 0:00:11.210612\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.800907527, Training Accuracy: 50.800\n",
            "Worker 6, [02/4]: Training Loss: 1.528446491, Training Accuracy: 57.488\n",
            "Worker 6, [03/4]: Training Loss: 1.469798497, Training Accuracy: 58.176\n",
            "Worker 6, [04/4]: Training Loss: 1.431260814, Training Accuracy: 59.568\n",
            "Time taken for training worker 6: 0:00:11.466897\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.732786034, Training Accuracy: 53.152\n",
            "Worker 7, [02/4]: Training Loss: 1.525322929, Training Accuracy: 57.216\n",
            "Worker 7, [03/4]: Training Loss: 1.456360313, Training Accuracy: 59.216\n",
            "Worker 7, [04/4]: Training Loss: 1.462928723, Training Accuracy: 59.248\n",
            "Time taken for training worker 7: 0:00:11.056156\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.771453117, Training Accuracy: 50.944\n",
            "Worker 8, [02/4]: Training Loss: 1.504298104, Training Accuracy: 56.880\n",
            "Worker 8, [03/4]: Training Loss: 1.425982220, Training Accuracy: 58.928\n",
            "Worker 8, [04/4]: Training Loss: 1.423469059, Training Accuracy: 58.656\n",
            "Time taken for training worker 8: 0:00:10.718785\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000907\n",
            "Local Step 18: Test Loss: 2.122088169, Test Accuracy: 46.480\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.812946771, Training Accuracy: 50.400\n",
            "Worker 1, [02/4]: Training Loss: 1.476950650, Training Accuracy: 58.864\n",
            "Worker 1, [03/4]: Training Loss: 1.177745514, Training Accuracy: 66.896\n",
            "Worker 1, [04/4]: Training Loss: 0.922996635, Training Accuracy: 73.440\n",
            "Time taken for training worker 1: 0:00:10.759177\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.858434099, Training Accuracy: 49.680\n",
            "Worker 2, [02/4]: Training Loss: 1.512287754, Training Accuracy: 56.928\n",
            "Worker 2, [03/4]: Training Loss: 1.178327998, Training Accuracy: 66.128\n",
            "Worker 2, [04/4]: Training Loss: 0.946427163, Training Accuracy: 72.736\n",
            "Time taken for training worker 2: 0:00:10.782336\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.812399209, Training Accuracy: 50.320\n",
            "Worker 3, [02/4]: Training Loss: 1.521902487, Training Accuracy: 57.488\n",
            "Worker 3, [03/4]: Training Loss: 1.184024331, Training Accuracy: 66.224\n",
            "Worker 3, [04/4]: Training Loss: 0.923716191, Training Accuracy: 73.664\n",
            "Time taken for training worker 3: 0:00:10.807650\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.880534507, Training Accuracy: 49.760\n",
            "Worker 4, [02/4]: Training Loss: 1.553987190, Training Accuracy: 56.288\n",
            "Worker 4, [03/4]: Training Loss: 1.197292744, Training Accuracy: 66.288\n",
            "Worker 4, [04/4]: Training Loss: 0.951535201, Training Accuracy: 72.800\n",
            "Time taken for training worker 4: 0:00:10.465477\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.939742446, Training Accuracy: 47.392\n",
            "Worker 5, [02/4]: Training Loss: 1.558700397, Training Accuracy: 56.272\n",
            "Worker 5, [03/4]: Training Loss: 1.225997196, Training Accuracy: 65.264\n",
            "Worker 5, [04/4]: Training Loss: 0.998199232, Training Accuracy: 71.216\n",
            "Time taken for training worker 5: 0:00:10.772051\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.842854407, Training Accuracy: 49.664\n",
            "Worker 6, [02/4]: Training Loss: 1.531573290, Training Accuracy: 56.368\n",
            "Worker 6, [03/4]: Training Loss: 1.198923893, Training Accuracy: 65.808\n",
            "Worker 6, [04/4]: Training Loss: 0.955643864, Training Accuracy: 72.224\n",
            "Time taken for training worker 6: 0:00:10.935385\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.913126447, Training Accuracy: 48.608\n",
            "Worker 7, [02/4]: Training Loss: 1.567637158, Training Accuracy: 56.384\n",
            "Worker 7, [03/4]: Training Loss: 1.241154974, Training Accuracy: 64.320\n",
            "Worker 7, [04/4]: Training Loss: 0.970955919, Training Accuracy: 72.144\n",
            "Time taken for training worker 7: 0:00:10.582815\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.882504799, Training Accuracy: 48.160\n",
            "Worker 8, [02/4]: Training Loss: 1.516428409, Training Accuracy: 57.728\n",
            "Worker 8, [03/4]: Training Loss: 1.195436379, Training Accuracy: 65.600\n",
            "Worker 8, [04/4]: Training Loss: 0.956873589, Training Accuracy: 72.144\n",
            "Time taken for training worker 8: 0:00:10.318060\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000998\n",
            "Local Step 19: Test Loss: 2.001717879, Test Accuracy: 50.850\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.685981300, Training Accuracy: 54.640\n",
            "Worker 1, [02/4]: Training Loss: 1.558648753, Training Accuracy: 56.880\n",
            "Worker 1, [03/4]: Training Loss: 1.521956320, Training Accuracy: 57.664\n",
            "Worker 1, [04/4]: Training Loss: 1.503790919, Training Accuracy: 57.232\n",
            "Time taken for training worker 1: 0:00:10.860142\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.845360262, Training Accuracy: 50.448\n",
            "Worker 2, [02/4]: Training Loss: 1.585293258, Training Accuracy: 55.792\n",
            "Worker 2, [03/4]: Training Loss: 1.493834912, Training Accuracy: 57.984\n",
            "Worker 2, [04/4]: Training Loss: 1.484338040, Training Accuracy: 57.840\n",
            "Time taken for training worker 2: 0:00:10.613492\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.766508404, Training Accuracy: 51.056\n",
            "Worker 3, [02/4]: Training Loss: 1.559351074, Training Accuracy: 56.432\n",
            "Worker 3, [03/4]: Training Loss: 1.470833767, Training Accuracy: 58.208\n",
            "Worker 3, [04/4]: Training Loss: 1.454277264, Training Accuracy: 58.928\n",
            "Time taken for training worker 3: 0:00:11.939847\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.782932155, Training Accuracy: 52.288\n",
            "Worker 4, [02/4]: Training Loss: 1.553676746, Training Accuracy: 56.784\n",
            "Worker 4, [03/4]: Training Loss: 1.500642672, Training Accuracy: 58.160\n",
            "Worker 4, [04/4]: Training Loss: 1.468227147, Training Accuracy: 58.672\n",
            "Time taken for training worker 4: 0:00:11.369016\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.816264840, Training Accuracy: 50.384\n",
            "Worker 5, [02/4]: Training Loss: 1.572639864, Training Accuracy: 56.288\n",
            "Worker 5, [03/4]: Training Loss: 1.458912713, Training Accuracy: 59.008\n",
            "Worker 5, [04/4]: Training Loss: 1.466157856, Training Accuracy: 58.960\n",
            "Time taken for training worker 5: 0:00:12.125975\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.706228287, Training Accuracy: 53.584\n",
            "Worker 6, [02/4]: Training Loss: 1.504881100, Training Accuracy: 57.360\n",
            "Worker 6, [03/4]: Training Loss: 1.406760802, Training Accuracy: 59.984\n",
            "Worker 6, [04/4]: Training Loss: 1.411161844, Training Accuracy: 59.952\n",
            "Time taken for training worker 6: 0:00:11.268957\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.763150434, Training Accuracy: 51.008\n",
            "Worker 7, [02/4]: Training Loss: 1.508131365, Training Accuracy: 57.984\n",
            "Worker 7, [03/4]: Training Loss: 1.438354324, Training Accuracy: 59.840\n",
            "Worker 7, [04/4]: Training Loss: 1.412834940, Training Accuracy: 60.144\n",
            "Time taken for training worker 7: 0:00:11.303237\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.700772699, Training Accuracy: 52.944\n",
            "Worker 8, [02/4]: Training Loss: 1.468743645, Training Accuracy: 58.416\n",
            "Worker 8, [03/4]: Training Loss: 1.358633910, Training Accuracy: 61.568\n",
            "Worker 8, [04/4]: Training Loss: 1.389199220, Training Accuracy: 59.760\n",
            "Time taken for training worker 8: 0:00:10.780598\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000826\n",
            "Local Step 20: Test Loss: 2.144848801, Test Accuracy: 47.160\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.824563486, Training Accuracy: 50.864\n",
            "Worker 1, [02/4]: Training Loss: 1.468305433, Training Accuracy: 58.480\n",
            "Worker 1, [03/4]: Training Loss: 1.141562837, Training Accuracy: 67.328\n",
            "Worker 1, [04/4]: Training Loss: 0.901060201, Training Accuracy: 74.256\n",
            "Time taken for training worker 1: 0:00:10.706874\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.823056776, Training Accuracy: 49.872\n",
            "Worker 2, [02/4]: Training Loss: 1.484292451, Training Accuracy: 57.568\n",
            "Worker 2, [03/4]: Training Loss: 1.168689727, Training Accuracy: 66.128\n",
            "Worker 2, [04/4]: Training Loss: 0.915400341, Training Accuracy: 74.272\n",
            "Time taken for training worker 2: 0:00:10.843183\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.850611059, Training Accuracy: 49.232\n",
            "Worker 3, [02/4]: Training Loss: 1.479400072, Training Accuracy: 58.240\n",
            "Worker 3, [03/4]: Training Loss: 1.166003110, Training Accuracy: 66.640\n",
            "Worker 3, [04/4]: Training Loss: 0.909190240, Training Accuracy: 73.616\n",
            "Time taken for training worker 3: 0:00:11.633146\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.832870125, Training Accuracy: 50.400\n",
            "Worker 4, [02/4]: Training Loss: 1.510513088, Training Accuracy: 57.648\n",
            "Worker 4, [03/4]: Training Loss: 1.192985968, Training Accuracy: 66.096\n",
            "Worker 4, [04/4]: Training Loss: 0.935060069, Training Accuracy: 72.928\n",
            "Time taken for training worker 4: 0:00:11.278779\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.863325427, Training Accuracy: 50.000\n",
            "Worker 5, [02/4]: Training Loss: 1.538715363, Training Accuracy: 56.928\n",
            "Worker 5, [03/4]: Training Loss: 1.207163914, Training Accuracy: 65.088\n",
            "Worker 5, [04/4]: Training Loss: 0.952446546, Training Accuracy: 72.608\n",
            "Time taken for training worker 5: 0:00:11.466077\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.824741418, Training Accuracy: 49.920\n",
            "Worker 6, [02/4]: Training Loss: 1.486824206, Training Accuracy: 58.144\n",
            "Worker 6, [03/4]: Training Loss: 1.197324140, Training Accuracy: 65.184\n",
            "Worker 6, [04/4]: Training Loss: 0.911084803, Training Accuracy: 75.216\n",
            "Time taken for training worker 6: 0:00:11.168211\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.879240153, Training Accuracy: 49.072\n",
            "Worker 7, [02/4]: Training Loss: 1.505915870, Training Accuracy: 57.904\n",
            "Worker 7, [03/4]: Training Loss: 1.200578373, Training Accuracy: 65.968\n",
            "Worker 7, [04/4]: Training Loss: 0.943964950, Training Accuracy: 72.800\n",
            "Time taken for training worker 7: 0:00:11.859383\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.842288476, Training Accuracy: 49.168\n",
            "Worker 8, [02/4]: Training Loss: 1.527049645, Training Accuracy: 56.400\n",
            "Worker 8, [03/4]: Training Loss: 1.182151858, Training Accuracy: 65.776\n",
            "Worker 8, [04/4]: Training Loss: 0.916391988, Training Accuracy: 73.344\n",
            "Time taken for training worker 8: 0:00:10.447196\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000731\n",
            "Local Step 21: Test Loss: 2.017290480, Test Accuracy: 51.780\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.667480005, Training Accuracy: 54.880\n",
            "Worker 1, [02/4]: Training Loss: 1.558949624, Training Accuracy: 57.488\n",
            "Worker 1, [03/4]: Training Loss: 1.477708390, Training Accuracy: 58.656\n",
            "Worker 1, [04/4]: Training Loss: 1.461326252, Training Accuracy: 58.816\n",
            "Time taken for training worker 1: 0:00:10.746130\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.840603966, Training Accuracy: 50.256\n",
            "Worker 2, [02/4]: Training Loss: 1.585469807, Training Accuracy: 55.552\n",
            "Worker 2, [03/4]: Training Loss: 1.470128989, Training Accuracy: 58.832\n",
            "Worker 2, [04/4]: Training Loss: 1.472029404, Training Accuracy: 58.096\n",
            "Time taken for training worker 2: 0:00:10.388376\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.761048034, Training Accuracy: 51.760\n",
            "Worker 3, [02/4]: Training Loss: 1.533857878, Training Accuracy: 57.040\n",
            "Worker 3, [03/4]: Training Loss: 1.432673527, Training Accuracy: 60.192\n",
            "Worker 3, [04/4]: Training Loss: 1.417196617, Training Accuracy: 59.200\n",
            "Time taken for training worker 3: 0:00:11.303448\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.797119302, Training Accuracy: 50.448\n",
            "Worker 4, [02/4]: Training Loss: 1.528215858, Training Accuracy: 57.104\n",
            "Worker 4, [03/4]: Training Loss: 1.424429412, Training Accuracy: 60.144\n",
            "Worker 4, [04/4]: Training Loss: 1.437706762, Training Accuracy: 59.600\n",
            "Time taken for training worker 4: 0:00:11.083169\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.804117847, Training Accuracy: 51.040\n",
            "Worker 5, [02/4]: Training Loss: 1.539653182, Training Accuracy: 56.608\n",
            "Worker 5, [03/4]: Training Loss: 1.439882960, Training Accuracy: 58.768\n",
            "Worker 5, [04/4]: Training Loss: 1.432853763, Training Accuracy: 58.736\n",
            "Time taken for training worker 5: 0:00:11.351365\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.685910322, Training Accuracy: 53.376\n",
            "Worker 6, [02/4]: Training Loss: 1.462204454, Training Accuracy: 58.544\n",
            "Worker 6, [03/4]: Training Loss: 1.390123614, Training Accuracy: 59.392\n",
            "Worker 6, [04/4]: Training Loss: 1.425980503, Training Accuracy: 59.536\n",
            "Time taken for training worker 6: 0:00:11.657675\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.768388886, Training Accuracy: 51.504\n",
            "Worker 7, [02/4]: Training Loss: 1.505049986, Training Accuracy: 57.728\n",
            "Worker 7, [03/4]: Training Loss: 1.393186151, Training Accuracy: 60.208\n",
            "Worker 7, [04/4]: Training Loss: 1.393731044, Training Accuracy: 60.704\n",
            "Time taken for training worker 7: 0:00:11.509201\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.677991698, Training Accuracy: 53.536\n",
            "Worker 8, [02/4]: Training Loss: 1.434329562, Training Accuracy: 58.672\n",
            "Worker 8, [03/4]: Training Loss: 1.335679686, Training Accuracy: 61.264\n",
            "Worker 8, [04/4]: Training Loss: 1.404490253, Training Accuracy: 60.160\n",
            "Time taken for training worker 8: 0:00:11.357131\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000737\n",
            "Local Step 22: Test Loss: 2.096643315, Test Accuracy: 48.210\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.778057012, Training Accuracy: 51.136\n",
            "Worker 1, [02/4]: Training Loss: 1.413652599, Training Accuracy: 59.808\n",
            "Worker 1, [03/4]: Training Loss: 1.093967138, Training Accuracy: 68.864\n",
            "Worker 1, [04/4]: Training Loss: 0.866081484, Training Accuracy: 75.248\n",
            "Time taken for training worker 1: 0:00:10.822764\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.844412773, Training Accuracy: 50.288\n",
            "Worker 2, [02/4]: Training Loss: 1.453907104, Training Accuracy: 58.528\n",
            "Worker 2, [03/4]: Training Loss: 1.133302910, Training Accuracy: 67.280\n",
            "Worker 2, [04/4]: Training Loss: 0.877085363, Training Accuracy: 75.008\n",
            "Time taken for training worker 2: 0:00:11.454466\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.812031503, Training Accuracy: 50.736\n",
            "Worker 3, [02/4]: Training Loss: 1.465807009, Training Accuracy: 58.544\n",
            "Worker 3, [03/4]: Training Loss: 1.127348936, Training Accuracy: 67.696\n",
            "Worker 3, [04/4]: Training Loss: 0.887740101, Training Accuracy: 74.336\n",
            "Time taken for training worker 3: 0:00:10.227282\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.859528584, Training Accuracy: 49.520\n",
            "Worker 4, [02/4]: Training Loss: 1.454662828, Training Accuracy: 58.864\n",
            "Worker 4, [03/4]: Training Loss: 1.183790499, Training Accuracy: 66.128\n",
            "Worker 4, [04/4]: Training Loss: 0.887361864, Training Accuracy: 74.624\n",
            "Time taken for training worker 4: 0:00:11.223973\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.859779532, Training Accuracy: 48.608\n",
            "Worker 5, [02/4]: Training Loss: 1.517025572, Training Accuracy: 57.264\n",
            "Worker 5, [03/4]: Training Loss: 1.205956329, Training Accuracy: 65.632\n",
            "Worker 5, [04/4]: Training Loss: 0.920002357, Training Accuracy: 73.520\n",
            "Time taken for training worker 5: 0:00:11.285769\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.760903729, Training Accuracy: 51.248\n",
            "Worker 6, [02/4]: Training Loss: 1.472084037, Training Accuracy: 58.368\n",
            "Worker 6, [03/4]: Training Loss: 1.123869995, Training Accuracy: 67.648\n",
            "Worker 6, [04/4]: Training Loss: 0.866765331, Training Accuracy: 75.280\n",
            "Time taken for training worker 6: 0:00:10.822885\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.895040941, Training Accuracy: 49.088\n",
            "Worker 7, [02/4]: Training Loss: 1.538244952, Training Accuracy: 57.712\n",
            "Worker 7, [03/4]: Training Loss: 1.173304814, Training Accuracy: 66.320\n",
            "Worker 7, [04/4]: Training Loss: 0.923566770, Training Accuracy: 73.536\n",
            "Time taken for training worker 7: 0:00:11.081440\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.823424776, Training Accuracy: 49.856\n",
            "Worker 8, [02/4]: Training Loss: 1.490340021, Training Accuracy: 58.304\n",
            "Worker 8, [03/4]: Training Loss: 1.146005927, Training Accuracy: 66.816\n",
            "Worker 8, [04/4]: Training Loss: 0.882213543, Training Accuracy: 73.968\n",
            "Time taken for training worker 8: 0:00:10.898968\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000771\n",
            "Local Step 23: Test Loss: 1.994370721, Test Accuracy: 51.540\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.618104412, Training Accuracy: 56.496\n",
            "Worker 1, [02/4]: Training Loss: 1.548323429, Training Accuracy: 57.216\n",
            "Worker 1, [03/4]: Training Loss: 1.457913290, Training Accuracy: 59.344\n",
            "Worker 1, [04/4]: Training Loss: 1.441580946, Training Accuracy: 58.704\n",
            "Time taken for training worker 1: 0:00:10.639265\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.760806882, Training Accuracy: 52.160\n",
            "Worker 2, [02/4]: Training Loss: 1.548760729, Training Accuracy: 57.072\n",
            "Worker 2, [03/4]: Training Loss: 1.431628003, Training Accuracy: 59.264\n",
            "Worker 2, [04/4]: Training Loss: 1.427797586, Training Accuracy: 59.776\n",
            "Time taken for training worker 2: 0:00:10.688712\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.785828015, Training Accuracy: 51.040\n",
            "Worker 3, [02/4]: Training Loss: 1.513132904, Training Accuracy: 57.760\n",
            "Worker 3, [03/4]: Training Loss: 1.404399374, Training Accuracy: 59.360\n",
            "Worker 3, [04/4]: Training Loss: 1.428168752, Training Accuracy: 59.680\n",
            "Time taken for training worker 3: 0:00:11.196204\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.827848596, Training Accuracy: 50.048\n",
            "Worker 4, [02/4]: Training Loss: 1.524710092, Training Accuracy: 57.152\n",
            "Worker 4, [03/4]: Training Loss: 1.432064732, Training Accuracy: 59.760\n",
            "Worker 4, [04/4]: Training Loss: 1.423676921, Training Accuracy: 59.568\n",
            "Time taken for training worker 4: 0:00:10.487876\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.789629374, Training Accuracy: 51.264\n",
            "Worker 5, [02/4]: Training Loss: 1.512192773, Training Accuracy: 57.600\n",
            "Worker 5, [03/4]: Training Loss: 1.447022293, Training Accuracy: 58.944\n",
            "Worker 5, [04/4]: Training Loss: 1.396710133, Training Accuracy: 60.160\n",
            "Time taken for training worker 5: 0:00:10.903117\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.694509745, Training Accuracy: 53.696\n",
            "Worker 6, [02/4]: Training Loss: 1.449843337, Training Accuracy: 59.424\n",
            "Worker 6, [03/4]: Training Loss: 1.336698406, Training Accuracy: 61.904\n",
            "Worker 6, [04/4]: Training Loss: 1.352832935, Training Accuracy: 61.296\n",
            "Time taken for training worker 6: 0:00:10.631509\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.753404744, Training Accuracy: 51.744\n",
            "Worker 7, [02/4]: Training Loss: 1.466790072, Training Accuracy: 58.944\n",
            "Worker 7, [03/4]: Training Loss: 1.361420735, Training Accuracy: 61.456\n",
            "Worker 7, [04/4]: Training Loss: 1.401422849, Training Accuracy: 60.224\n",
            "Time taken for training worker 7: 0:00:11.059880\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.693572143, Training Accuracy: 53.344\n",
            "Worker 8, [02/4]: Training Loss: 1.438283706, Training Accuracy: 58.032\n",
            "Worker 8, [03/4]: Training Loss: 1.327060546, Training Accuracy: 61.648\n",
            "Worker 8, [04/4]: Training Loss: 1.336389345, Training Accuracy: 61.648\n",
            "Time taken for training worker 8: 0:00:10.915842\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000809\n",
            "Local Step 24: Test Loss: 2.044873741, Test Accuracy: 48.300\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.768666766, Training Accuracy: 51.792\n",
            "Worker 1, [02/4]: Training Loss: 1.391400828, Training Accuracy: 61.392\n",
            "Worker 1, [03/4]: Training Loss: 1.099642977, Training Accuracy: 68.752\n",
            "Worker 1, [04/4]: Training Loss: 0.847572034, Training Accuracy: 75.920\n",
            "Time taken for training worker 1: 0:00:10.730500\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.784295329, Training Accuracy: 51.616\n",
            "Worker 2, [02/4]: Training Loss: 1.395907383, Training Accuracy: 60.736\n",
            "Worker 2, [03/4]: Training Loss: 1.115203111, Training Accuracy: 67.872\n",
            "Worker 2, [04/4]: Training Loss: 0.847788439, Training Accuracy: 75.504\n",
            "Time taken for training worker 2: 0:00:10.253275\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.811790976, Training Accuracy: 50.624\n",
            "Worker 3, [02/4]: Training Loss: 1.445053105, Training Accuracy: 59.152\n",
            "Worker 3, [03/4]: Training Loss: 1.115655082, Training Accuracy: 68.352\n",
            "Worker 3, [04/4]: Training Loss: 0.860766976, Training Accuracy: 74.928\n",
            "Time taken for training worker 3: 0:00:10.806277\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.821090558, Training Accuracy: 50.640\n",
            "Worker 4, [02/4]: Training Loss: 1.481392041, Training Accuracy: 58.016\n",
            "Worker 4, [03/4]: Training Loss: 1.135096959, Training Accuracy: 67.888\n",
            "Worker 4, [04/4]: Training Loss: 0.906462026, Training Accuracy: 73.776\n",
            "Time taken for training worker 4: 0:00:10.389745\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.847667150, Training Accuracy: 49.408\n",
            "Worker 5, [02/4]: Training Loss: 1.441746715, Training Accuracy: 59.136\n",
            "Worker 5, [03/4]: Training Loss: 1.132276119, Training Accuracy: 66.960\n",
            "Worker 5, [04/4]: Training Loss: 0.887851359, Training Accuracy: 74.400\n",
            "Time taken for training worker 5: 0:00:10.481890\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.771253090, Training Accuracy: 51.280\n",
            "Worker 6, [02/4]: Training Loss: 1.488358334, Training Accuracy: 57.712\n",
            "Worker 6, [03/4]: Training Loss: 1.120728973, Training Accuracy: 68.000\n",
            "Worker 6, [04/4]: Training Loss: 0.860358846, Training Accuracy: 75.040\n",
            "Time taken for training worker 6: 0:00:11.146696\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.849714828, Training Accuracy: 50.416\n",
            "Worker 7, [02/4]: Training Loss: 1.473134912, Training Accuracy: 58.784\n",
            "Worker 7, [03/4]: Training Loss: 1.145118207, Training Accuracy: 67.424\n",
            "Worker 7, [04/4]: Training Loss: 0.889724750, Training Accuracy: 74.752\n",
            "Time taken for training worker 7: 0:00:11.300003\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.815523187, Training Accuracy: 50.112\n",
            "Worker 8, [02/4]: Training Loss: 1.458690567, Training Accuracy: 58.320\n",
            "Worker 8, [03/4]: Training Loss: 1.139459768, Training Accuracy: 66.752\n",
            "Worker 8, [04/4]: Training Loss: 0.878434356, Training Accuracy: 75.008\n",
            "Time taken for training worker 8: 0:00:10.937906\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000815\n",
            "Local Step 25: Test Loss: 1.998735634, Test Accuracy: 52.090\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.590051213, Training Accuracy: 56.816\n",
            "Worker 1, [02/4]: Training Loss: 1.493606284, Training Accuracy: 58.128\n",
            "Worker 1, [03/4]: Training Loss: 1.462646680, Training Accuracy: 58.864\n",
            "Worker 1, [04/4]: Training Loss: 1.405057714, Training Accuracy: 59.856\n",
            "Time taken for training worker 1: 0:00:11.187185\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.726826360, Training Accuracy: 52.672\n",
            "Worker 2, [02/4]: Training Loss: 1.510361740, Training Accuracy: 58.160\n",
            "Worker 2, [03/4]: Training Loss: 1.405548245, Training Accuracy: 59.936\n",
            "Worker 2, [04/4]: Training Loss: 1.452343656, Training Accuracy: 59.312\n",
            "Time taken for training worker 2: 0:00:10.741795\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.817902165, Training Accuracy: 50.560\n",
            "Worker 3, [02/4]: Training Loss: 1.494404565, Training Accuracy: 57.952\n",
            "Worker 3, [03/4]: Training Loss: 1.417015053, Training Accuracy: 60.208\n",
            "Worker 3, [04/4]: Training Loss: 1.396791307, Training Accuracy: 59.824\n",
            "Time taken for training worker 3: 0:00:10.895159\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.736055125, Training Accuracy: 52.768\n",
            "Worker 4, [02/4]: Training Loss: 1.488999069, Training Accuracy: 57.760\n",
            "Worker 4, [03/4]: Training Loss: 1.412936450, Training Accuracy: 60.512\n",
            "Worker 4, [04/4]: Training Loss: 1.410921706, Training Accuracy: 59.488\n",
            "Time taken for training worker 4: 0:00:12.056230\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.694922942, Training Accuracy: 52.944\n",
            "Worker 5, [02/4]: Training Loss: 1.481951591, Training Accuracy: 58.448\n",
            "Worker 5, [03/4]: Training Loss: 1.397519221, Training Accuracy: 60.080\n",
            "Worker 5, [04/4]: Training Loss: 1.415449243, Training Accuracy: 59.680\n",
            "Time taken for training worker 5: 0:00:11.413028\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.672330956, Training Accuracy: 53.696\n",
            "Worker 6, [02/4]: Training Loss: 1.438849924, Training Accuracy: 59.328\n",
            "Worker 6, [03/4]: Training Loss: 1.323969212, Training Accuracy: 61.824\n",
            "Worker 6, [04/4]: Training Loss: 1.345268733, Training Accuracy: 62.704\n",
            "Time taken for training worker 6: 0:00:10.993732\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.831518027, Training Accuracy: 50.992\n",
            "Worker 7, [02/4]: Training Loss: 1.450562697, Training Accuracy: 59.600\n",
            "Worker 7, [03/4]: Training Loss: 1.355276524, Training Accuracy: 61.744\n",
            "Worker 7, [04/4]: Training Loss: 1.354846874, Training Accuracy: 61.824\n",
            "Time taken for training worker 7: 0:00:10.623605\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.566415693, Training Accuracy: 55.104\n",
            "Worker 8, [02/4]: Training Loss: 1.371822511, Training Accuracy: 60.240\n",
            "Worker 8, [03/4]: Training Loss: 1.299076515, Training Accuracy: 62.560\n",
            "Worker 8, [04/4]: Training Loss: 1.316154730, Training Accuracy: 61.504\n",
            "Time taken for training worker 8: 0:00:10.617250\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000745\n",
            "Local Step 26: Test Loss: 2.090499208, Test Accuracy: 47.790\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.742312238, Training Accuracy: 52.128\n",
            "Worker 1, [02/4]: Training Loss: 1.400429230, Training Accuracy: 60.960\n",
            "Worker 1, [03/4]: Training Loss: 1.065924890, Training Accuracy: 69.552\n",
            "Worker 1, [04/4]: Training Loss: 0.827000640, Training Accuracy: 76.080\n",
            "Time taken for training worker 1: 0:00:10.478760\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.777314069, Training Accuracy: 51.296\n",
            "Worker 2, [02/4]: Training Loss: 1.409473869, Training Accuracy: 60.368\n",
            "Worker 2, [03/4]: Training Loss: 1.080885960, Training Accuracy: 68.704\n",
            "Worker 2, [04/4]: Training Loss: 0.818926486, Training Accuracy: 76.352\n",
            "Time taken for training worker 2: 0:00:10.402271\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.810828788, Training Accuracy: 50.688\n",
            "Worker 3, [02/4]: Training Loss: 1.405713934, Training Accuracy: 59.840\n",
            "Worker 3, [03/4]: Training Loss: 1.073910517, Training Accuracy: 68.464\n",
            "Worker 3, [04/4]: Training Loss: 0.841764631, Training Accuracy: 76.240\n",
            "Time taken for training worker 3: 0:00:10.418628\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.786542060, Training Accuracy: 51.584\n",
            "Worker 4, [02/4]: Training Loss: 1.428232299, Training Accuracy: 59.200\n",
            "Worker 4, [03/4]: Training Loss: 1.121565164, Training Accuracy: 68.496\n",
            "Worker 4, [04/4]: Training Loss: 0.872842738, Training Accuracy: 74.976\n",
            "Time taken for training worker 4: 0:00:10.841568\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.842779038, Training Accuracy: 50.656\n",
            "Worker 5, [02/4]: Training Loss: 1.479422951, Training Accuracy: 58.000\n",
            "Worker 5, [03/4]: Training Loss: 1.128803403, Training Accuracy: 67.088\n",
            "Worker 5, [04/4]: Training Loss: 0.878545979, Training Accuracy: 74.384\n",
            "Time taken for training worker 5: 0:00:10.769946\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.774965359, Training Accuracy: 51.456\n",
            "Worker 6, [02/4]: Training Loss: 1.402026668, Training Accuracy: 60.384\n",
            "Worker 6, [03/4]: Training Loss: 1.074579945, Training Accuracy: 69.072\n",
            "Worker 6, [04/4]: Training Loss: 0.846780854, Training Accuracy: 75.888\n",
            "Time taken for training worker 6: 0:00:10.649781\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.831489834, Training Accuracy: 50.736\n",
            "Worker 7, [02/4]: Training Loss: 1.470591311, Training Accuracy: 58.496\n",
            "Worker 7, [03/4]: Training Loss: 1.158790804, Training Accuracy: 66.624\n",
            "Worker 7, [04/4]: Training Loss: 0.876638034, Training Accuracy: 74.672\n",
            "Time taken for training worker 7: 0:00:11.200213\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.802148186, Training Accuracy: 49.984\n",
            "Worker 8, [02/4]: Training Loss: 1.444958607, Training Accuracy: 58.000\n",
            "Worker 8, [03/4]: Training Loss: 1.100339199, Training Accuracy: 67.440\n",
            "Worker 8, [04/4]: Training Loss: 0.854415848, Training Accuracy: 75.568\n",
            "Time taken for training worker 8: 0:00:10.688012\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000898\n",
            "Local Step 27: Test Loss: 2.002588000, Test Accuracy: 52.040\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.594674739, Training Accuracy: 56.768\n",
            "Worker 1, [02/4]: Training Loss: 1.478061916, Training Accuracy: 58.816\n",
            "Worker 1, [03/4]: Training Loss: 1.439009570, Training Accuracy: 59.072\n",
            "Worker 1, [04/4]: Training Loss: 1.445588892, Training Accuracy: 59.104\n",
            "Time taken for training worker 1: 0:00:12.032707\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.776737134, Training Accuracy: 51.312\n",
            "Worker 2, [02/4]: Training Loss: 1.497086231, Training Accuracy: 57.536\n",
            "Worker 2, [03/4]: Training Loss: 1.415706779, Training Accuracy: 59.120\n",
            "Worker 2, [04/4]: Training Loss: 1.399536261, Training Accuracy: 59.792\n",
            "Time taken for training worker 2: 0:00:10.996126\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.696604240, Training Accuracy: 52.624\n",
            "Worker 3, [02/4]: Training Loss: 1.459658297, Training Accuracy: 58.384\n",
            "Worker 3, [03/4]: Training Loss: 1.390644443, Training Accuracy: 60.704\n",
            "Worker 3, [04/4]: Training Loss: 1.388765000, Training Accuracy: 60.400\n",
            "Time taken for training worker 3: 0:00:10.398574\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.706300538, Training Accuracy: 53.072\n",
            "Worker 4, [02/4]: Training Loss: 1.448383466, Training Accuracy: 59.312\n",
            "Worker 4, [03/4]: Training Loss: 1.371696894, Training Accuracy: 61.072\n",
            "Worker 4, [04/4]: Training Loss: 1.380807097, Training Accuracy: 60.832\n",
            "Time taken for training worker 4: 0:00:10.463164\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.807631929, Training Accuracy: 51.472\n",
            "Worker 5, [02/4]: Training Loss: 1.494736746, Training Accuracy: 58.544\n",
            "Worker 5, [03/4]: Training Loss: 1.420016801, Training Accuracy: 60.112\n",
            "Worker 5, [04/4]: Training Loss: 1.416247756, Training Accuracy: 60.208\n",
            "Time taken for training worker 5: 0:00:11.582935\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.710801005, Training Accuracy: 53.120\n",
            "Worker 6, [02/4]: Training Loss: 1.413618568, Training Accuracy: 60.000\n",
            "Worker 6, [03/4]: Training Loss: 1.312175973, Training Accuracy: 62.224\n",
            "Worker 6, [04/4]: Training Loss: 1.360466708, Training Accuracy: 61.328\n",
            "Time taken for training worker 6: 0:00:11.104092\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.721934951, Training Accuracy: 53.568\n",
            "Worker 7, [02/4]: Training Loss: 1.447769601, Training Accuracy: 58.832\n",
            "Worker 7, [03/4]: Training Loss: 1.349854448, Training Accuracy: 62.256\n",
            "Worker 7, [04/4]: Training Loss: 1.328243276, Training Accuracy: 61.904\n",
            "Time taken for training worker 7: 0:00:10.632368\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.603012828, Training Accuracy: 55.152\n",
            "Worker 8, [02/4]: Training Loss: 1.369101897, Training Accuracy: 60.240\n",
            "Worker 8, [03/4]: Training Loss: 1.292925088, Training Accuracy: 62.688\n",
            "Worker 8, [04/4]: Training Loss: 1.312131581, Training Accuracy: 62.304\n",
            "Time taken for training worker 8: 0:00:10.632243\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000759\n",
            "Local Step 28: Test Loss: 2.114713248, Test Accuracy: 47.820\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.750982967, Training Accuracy: 52.368\n",
            "Worker 1, [02/4]: Training Loss: 1.397636730, Training Accuracy: 60.704\n",
            "Worker 1, [03/4]: Training Loss: 1.060029729, Training Accuracy: 69.216\n",
            "Worker 1, [04/4]: Training Loss: 0.816302711, Training Accuracy: 77.360\n",
            "Time taken for training worker 1: 0:00:10.680995\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.714908236, Training Accuracy: 53.024\n",
            "Worker 2, [02/4]: Training Loss: 1.379894700, Training Accuracy: 61.152\n",
            "Worker 2, [03/4]: Training Loss: 1.087400510, Training Accuracy: 68.832\n",
            "Worker 2, [04/4]: Training Loss: 0.814444605, Training Accuracy: 76.064\n",
            "Time taken for training worker 2: 0:00:11.596600\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.727603845, Training Accuracy: 52.672\n",
            "Worker 3, [02/4]: Training Loss: 1.442011235, Training Accuracy: 59.776\n",
            "Worker 3, [03/4]: Training Loss: 1.071930978, Training Accuracy: 69.008\n",
            "Worker 3, [04/4]: Training Loss: 0.825643303, Training Accuracy: 76.688\n",
            "Time taken for training worker 3: 0:00:11.179398\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.791211690, Training Accuracy: 50.912\n",
            "Worker 4, [02/4]: Training Loss: 1.426083053, Training Accuracy: 60.288\n",
            "Worker 4, [03/4]: Training Loss: 1.114162269, Training Accuracy: 68.144\n",
            "Worker 4, [04/4]: Training Loss: 0.840150624, Training Accuracy: 75.872\n",
            "Time taken for training worker 4: 0:00:11.094412\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.825621086, Training Accuracy: 49.808\n",
            "Worker 5, [02/4]: Training Loss: 1.452277728, Training Accuracy: 58.512\n",
            "Worker 5, [03/4]: Training Loss: 1.125048049, Training Accuracy: 67.712\n",
            "Worker 5, [04/4]: Training Loss: 0.868203416, Training Accuracy: 74.992\n",
            "Time taken for training worker 5: 0:00:10.614391\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.775065502, Training Accuracy: 51.008\n",
            "Worker 6, [02/4]: Training Loss: 1.400141358, Training Accuracy: 60.320\n",
            "Worker 6, [03/4]: Training Loss: 1.080489885, Training Accuracy: 68.928\n",
            "Worker 6, [04/4]: Training Loss: 0.838291549, Training Accuracy: 76.000\n",
            "Time taken for training worker 6: 0:00:11.738749\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.760538430, Training Accuracy: 51.840\n",
            "Worker 7, [02/4]: Training Loss: 1.438541158, Training Accuracy: 59.840\n",
            "Worker 7, [03/4]: Training Loss: 1.119213852, Training Accuracy: 68.064\n",
            "Worker 7, [04/4]: Training Loss: 0.847526211, Training Accuracy: 75.680\n",
            "Time taken for training worker 7: 0:00:11.111220\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.801443644, Training Accuracy: 50.736\n",
            "Worker 8, [02/4]: Training Loss: 1.434143008, Training Accuracy: 59.232\n",
            "Worker 8, [03/4]: Training Loss: 1.115130594, Training Accuracy: 67.600\n",
            "Worker 8, [04/4]: Training Loss: 0.844537971, Training Accuracy: 75.408\n",
            "Time taken for training worker 8: 0:00:11.284248\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000784\n",
            "Local Step 29: Test Loss: 2.000583754, Test Accuracy: 51.780\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.617900138, Training Accuracy: 55.888\n",
            "Worker 1, [02/4]: Training Loss: 1.493812540, Training Accuracy: 57.952\n",
            "Worker 1, [03/4]: Training Loss: 1.418569699, Training Accuracy: 59.888\n",
            "Worker 1, [04/4]: Training Loss: 1.393597802, Training Accuracy: 61.040\n",
            "Time taken for training worker 1: 0:00:11.564432\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.774301261, Training Accuracy: 52.016\n",
            "Worker 2, [02/4]: Training Loss: 1.522668070, Training Accuracy: 57.216\n",
            "Worker 2, [03/4]: Training Loss: 1.415227051, Training Accuracy: 59.952\n",
            "Worker 2, [04/4]: Training Loss: 1.357997613, Training Accuracy: 60.992\n",
            "Time taken for training worker 2: 0:00:11.282205\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.689374797, Training Accuracy: 53.248\n",
            "Worker 3, [02/4]: Training Loss: 1.454961010, Training Accuracy: 58.576\n",
            "Worker 3, [03/4]: Training Loss: 1.352464609, Training Accuracy: 60.720\n",
            "Worker 3, [04/4]: Training Loss: 1.377750892, Training Accuracy: 60.688\n",
            "Time taken for training worker 3: 0:00:11.106142\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.752356532, Training Accuracy: 52.848\n",
            "Worker 4, [02/4]: Training Loss: 1.452369336, Training Accuracy: 58.768\n",
            "Worker 4, [03/4]: Training Loss: 1.332735091, Training Accuracy: 61.792\n",
            "Worker 4, [04/4]: Training Loss: 1.331424843, Training Accuracy: 62.096\n",
            "Time taken for training worker 4: 0:00:11.231499\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.737325955, Training Accuracy: 52.656\n",
            "Worker 5, [02/4]: Training Loss: 1.460415954, Training Accuracy: 59.360\n",
            "Worker 5, [03/4]: Training Loss: 1.363433320, Training Accuracy: 60.304\n",
            "Worker 5, [04/4]: Training Loss: 1.324018359, Training Accuracy: 61.776\n",
            "Time taken for training worker 5: 0:00:10.659103\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.686746968, Training Accuracy: 53.536\n",
            "Worker 6, [02/4]: Training Loss: 1.408370054, Training Accuracy: 60.352\n",
            "Worker 6, [03/4]: Training Loss: 1.324166261, Training Accuracy: 63.056\n",
            "Worker 6, [04/4]: Training Loss: 1.303811341, Training Accuracy: 62.816\n",
            "Time taken for training worker 6: 0:00:10.898454\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.719827607, Training Accuracy: 52.816\n",
            "Worker 7, [02/4]: Training Loss: 1.405030305, Training Accuracy: 60.288\n",
            "Worker 7, [03/4]: Training Loss: 1.346068331, Training Accuracy: 61.264\n",
            "Worker 7, [04/4]: Training Loss: 1.325352171, Training Accuracy: 61.728\n",
            "Time taken for training worker 7: 0:00:10.851125\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.750549484, Training Accuracy: 51.152\n",
            "Worker 8, [02/4]: Training Loss: 1.384188894, Training Accuracy: 60.272\n",
            "Worker 8, [03/4]: Training Loss: 1.280442832, Training Accuracy: 63.024\n",
            "Worker 8, [04/4]: Training Loss: 1.314767029, Training Accuracy: 61.584\n",
            "Time taken for training worker 8: 0:00:10.215957\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000730\n",
            "Local Step 30: Test Loss: 2.124984676, Test Accuracy: 47.940\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.769920920, Training Accuracy: 51.632\n",
            "Worker 1, [02/4]: Training Loss: 1.386712860, Training Accuracy: 61.248\n",
            "Worker 1, [03/4]: Training Loss: 1.057169330, Training Accuracy: 69.648\n",
            "Worker 1, [04/4]: Training Loss: 0.808385948, Training Accuracy: 77.056\n",
            "Time taken for training worker 1: 0:00:11.051441\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.708947916, Training Accuracy: 52.848\n",
            "Worker 2, [02/4]: Training Loss: 1.359115242, Training Accuracy: 61.216\n",
            "Worker 2, [03/4]: Training Loss: 1.059126164, Training Accuracy: 69.568\n",
            "Worker 2, [04/4]: Training Loss: 0.791921544, Training Accuracy: 77.168\n",
            "Time taken for training worker 2: 0:00:10.900487\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.727630406, Training Accuracy: 53.200\n",
            "Worker 3, [02/4]: Training Loss: 1.407927749, Training Accuracy: 60.080\n",
            "Worker 3, [03/4]: Training Loss: 1.094858066, Training Accuracy: 68.048\n",
            "Worker 3, [04/4]: Training Loss: 0.812086641, Training Accuracy: 76.896\n",
            "Time taken for training worker 3: 0:00:10.283272\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.753365834, Training Accuracy: 52.176\n",
            "Worker 4, [02/4]: Training Loss: 1.396602199, Training Accuracy: 60.384\n",
            "Worker 4, [03/4]: Training Loss: 1.093535433, Training Accuracy: 68.800\n",
            "Worker 4, [04/4]: Training Loss: 0.868283750, Training Accuracy: 74.736\n",
            "Time taken for training worker 4: 0:00:10.909221\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.796015550, Training Accuracy: 51.136\n",
            "Worker 5, [02/4]: Training Loss: 1.437622632, Training Accuracy: 59.696\n",
            "Worker 5, [03/4]: Training Loss: 1.106617035, Training Accuracy: 68.176\n",
            "Worker 5, [04/4]: Training Loss: 0.845714471, Training Accuracy: 74.928\n",
            "Time taken for training worker 5: 0:00:11.420306\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.787015223, Training Accuracy: 50.928\n",
            "Worker 6, [02/4]: Training Loss: 1.405348821, Training Accuracy: 59.872\n",
            "Worker 6, [03/4]: Training Loss: 1.091754349, Training Accuracy: 68.400\n",
            "Worker 6, [04/4]: Training Loss: 0.869779048, Training Accuracy: 75.088\n",
            "Time taken for training worker 6: 0:00:11.372489\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.808118096, Training Accuracy: 50.672\n",
            "Worker 7, [02/4]: Training Loss: 1.449437520, Training Accuracy: 59.152\n",
            "Worker 7, [03/4]: Training Loss: 1.127833359, Training Accuracy: 67.952\n",
            "Worker 7, [04/4]: Training Loss: 0.844591944, Training Accuracy: 75.216\n",
            "Time taken for training worker 7: 0:00:10.866273\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.799126247, Training Accuracy: 50.656\n",
            "Worker 8, [02/4]: Training Loss: 1.407185681, Training Accuracy: 60.768\n",
            "Worker 8, [03/4]: Training Loss: 1.083672933, Training Accuracy: 68.720\n",
            "Worker 8, [04/4]: Training Loss: 0.845225322, Training Accuracy: 75.872\n",
            "Time taken for training worker 8: 0:00:10.533836\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000734\n",
            "Local Step 31: Test Loss: 1.995053590, Test Accuracy: 52.330\n",
            "**************************************************\n",
            "Worker 1, [01/4]: Training Loss: 1.560958194, Training Accuracy: 57.408\n",
            "Worker 1, [02/4]: Training Loss: 1.464152370, Training Accuracy: 59.392\n",
            "Worker 1, [03/4]: Training Loss: 1.395621199, Training Accuracy: 59.600\n",
            "Worker 1, [04/4]: Training Loss: 1.383007202, Training Accuracy: 60.464\n",
            "Time taken for training worker 1: 0:00:10.593253\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/4]: Training Loss: 1.729634182, Training Accuracy: 51.904\n",
            "Worker 2, [02/4]: Training Loss: 1.478889463, Training Accuracy: 58.208\n",
            "Worker 2, [03/4]: Training Loss: 1.379971744, Training Accuracy: 61.424\n",
            "Worker 2, [04/4]: Training Loss: 1.352531805, Training Accuracy: 60.800\n",
            "Time taken for training worker 2: 0:00:11.316207\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/4]: Training Loss: 1.698814999, Training Accuracy: 52.752\n",
            "Worker 3, [02/4]: Training Loss: 1.447762828, Training Accuracy: 59.536\n",
            "Worker 3, [03/4]: Training Loss: 1.358753484, Training Accuracy: 61.472\n",
            "Worker 3, [04/4]: Training Loss: 1.326571864, Training Accuracy: 61.392\n",
            "Time taken for training worker 3: 0:00:11.145824\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/4]: Training Loss: 1.769637573, Training Accuracy: 52.224\n",
            "Worker 4, [02/4]: Training Loss: 1.458908074, Training Accuracy: 58.832\n",
            "Worker 4, [03/4]: Training Loss: 1.343750608, Training Accuracy: 61.632\n",
            "Worker 4, [04/4]: Training Loss: 1.361284803, Training Accuracy: 61.040\n",
            "Time taken for training worker 4: 0:00:10.609327\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/4]: Training Loss: 1.735351515, Training Accuracy: 51.776\n",
            "Worker 5, [02/4]: Training Loss: 1.468245438, Training Accuracy: 58.576\n",
            "Worker 5, [03/4]: Training Loss: 1.368927822, Training Accuracy: 61.184\n",
            "Worker 5, [04/4]: Training Loss: 1.356123732, Training Accuracy: 61.104\n",
            "Time taken for training worker 5: 0:00:11.309234\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/4]: Training Loss: 1.672117275, Training Accuracy: 54.384\n",
            "Worker 6, [02/4]: Training Loss: 1.410898873, Training Accuracy: 59.744\n",
            "Worker 6, [03/4]: Training Loss: 1.308514372, Training Accuracy: 62.544\n",
            "Worker 6, [04/4]: Training Loss: 1.322493205, Training Accuracy: 61.920\n",
            "Time taken for training worker 6: 0:00:11.147643\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/4]: Training Loss: 1.734973354, Training Accuracy: 52.912\n",
            "Worker 7, [02/4]: Training Loss: 1.420660111, Training Accuracy: 59.600\n",
            "Worker 7, [03/4]: Training Loss: 1.307579595, Training Accuracy: 62.864\n",
            "Worker 7, [04/4]: Training Loss: 1.280914909, Training Accuracy: 63.744\n",
            "Time taken for training worker 7: 0:00:10.682452\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/4]: Training Loss: 1.812595378, Training Accuracy: 51.168\n",
            "Worker 8, [02/4]: Training Loss: 1.383498403, Training Accuracy: 60.000\n",
            "Worker 8, [03/4]: Training Loss: 1.264499269, Training Accuracy: 63.360\n",
            "Worker 8, [04/4]: Training Loss: 1.289440106, Training Accuracy: 62.784\n",
            "Time taken for training worker 8: 0:00:10.651136\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000775\n",
            "Local Step 32: Test Loss: 2.088693818, Test Accuracy: 48.470\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:47:20.163576\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:64\n",
            "==================================================\n",
            "Worker 1, [01/2]: Training Loss: 4.593108182, Training Accuracy: 1.312\n",
            "Worker 1, [02/2]: Training Loss: 4.482436058, Training Accuracy: 3.024\n",
            "Time taken for training worker 1: 0:00:05.418711\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 4.593786366, Training Accuracy: 1.584\n",
            "Worker 2, [02/2]: Training Loss: 4.498022279, Training Accuracy: 2.672\n",
            "Time taken for training worker 2: 0:00:05.303926\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 4.594095692, Training Accuracy: 1.376\n",
            "Worker 3, [02/2]: Training Loss: 4.497140841, Training Accuracy: 2.576\n",
            "Time taken for training worker 3: 0:00:05.727858\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 4.593275678, Training Accuracy: 1.440\n",
            "Worker 4, [02/2]: Training Loss: 4.496938316, Training Accuracy: 2.848\n",
            "Time taken for training worker 4: 0:00:05.220315\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 4.596202364, Training Accuracy: 1.472\n",
            "Worker 5, [02/2]: Training Loss: 4.500370556, Training Accuracy: 2.544\n",
            "Time taken for training worker 5: 0:00:05.412328\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 4.590795196, Training Accuracy: 1.296\n",
            "Worker 6, [02/2]: Training Loss: 4.470049848, Training Accuracy: 2.864\n",
            "Time taken for training worker 6: 0:00:05.527117\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 4.592031990, Training Accuracy: 1.600\n",
            "Worker 7, [02/2]: Training Loss: 4.483091267, Training Accuracy: 2.832\n",
            "Time taken for training worker 7: 0:00:05.827744\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 4.593236875, Training Accuracy: 1.680\n",
            "Worker 8, [02/2]: Training Loss: 4.493981502, Training Accuracy: 2.976\n",
            "Time taken for training worker 8: 0:00:05.406381\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000958\n",
            "Local Step 01: Test Loss: 4.397947542, Test Accuracy: 4.930\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 4.401639744, Training Accuracy: 5.072\n",
            "Worker 1, [02/2]: Training Loss: 4.290110442, Training Accuracy: 4.592\n",
            "Time taken for training worker 1: 0:00:05.833236\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 4.215605188, Training Accuracy: 5.680\n",
            "Worker 2, [02/2]: Training Loss: 4.161220677, Training Accuracy: 6.384\n",
            "Time taken for training worker 2: 0:00:05.166499\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 4.134096579, Training Accuracy: 6.480\n",
            "Worker 3, [02/2]: Training Loss: 4.090221052, Training Accuracy: 7.040\n",
            "Time taken for training worker 3: 0:00:05.399699\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 4.039510447, Training Accuracy: 7.840\n",
            "Worker 4, [02/2]: Training Loss: 4.013139720, Training Accuracy: 8.192\n",
            "Time taken for training worker 4: 0:00:05.128267\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 4.014464804, Training Accuracy: 7.872\n",
            "Worker 5, [02/2]: Training Loss: 3.991906409, Training Accuracy: 8.544\n",
            "Time taken for training worker 5: 0:00:05.489024\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 3.906068376, Training Accuracy: 9.520\n",
            "Worker 6, [02/2]: Training Loss: 3.866384370, Training Accuracy: 10.400\n",
            "Time taken for training worker 6: 0:00:05.492464\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 3.851192207, Training Accuracy: 10.960\n",
            "Worker 7, [02/2]: Training Loss: 3.812317422, Training Accuracy: 10.704\n",
            "Time taken for training worker 7: 0:00:05.264685\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 3.805771434, Training Accuracy: 11.344\n",
            "Worker 8, [02/2]: Training Loss: 3.788990853, Training Accuracy: 11.568\n",
            "Time taken for training worker 8: 0:00:05.057952\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000730\n",
            "Local Step 02: Test Loss: 3.673428027, Test Accuracy: 13.900\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.801161416, Training Accuracy: 11.424\n",
            "Worker 1, [02/2]: Training Loss: 3.620193805, Training Accuracy: 13.776\n",
            "Time taken for training worker 1: 0:00:05.555974\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.704206462, Training Accuracy: 12.352\n",
            "Worker 2, [02/2]: Training Loss: 3.527743712, Training Accuracy: 15.328\n",
            "Time taken for training worker 2: 0:00:05.428337\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 3.628139992, Training Accuracy: 14.304\n",
            "Worker 3, [02/2]: Training Loss: 3.414050657, Training Accuracy: 17.776\n",
            "Time taken for training worker 3: 0:00:05.091552\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 3.519763185, Training Accuracy: 15.664\n",
            "Worker 4, [02/2]: Training Loss: 3.308329001, Training Accuracy: 19.888\n",
            "Time taken for training worker 4: 0:00:05.419840\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 3.495652520, Training Accuracy: 16.496\n",
            "Worker 5, [02/2]: Training Loss: 3.266871542, Training Accuracy: 20.112\n",
            "Time taken for training worker 5: 0:00:05.710369\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 3.336540193, Training Accuracy: 18.912\n",
            "Worker 6, [02/2]: Training Loss: 3.143675991, Training Accuracy: 22.480\n",
            "Time taken for training worker 6: 0:00:05.468151\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 3.339446953, Training Accuracy: 19.568\n",
            "Worker 7, [02/2]: Training Loss: 3.077236027, Training Accuracy: 24.256\n",
            "Time taken for training worker 7: 0:00:05.632590\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 3.255336032, Training Accuracy: 20.432\n",
            "Worker 8, [02/2]: Training Loss: 3.025695791, Training Accuracy: 25.792\n",
            "Time taken for training worker 8: 0:00:05.172605\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000772\n",
            "Local Step 03: Test Loss: 3.009467020, Test Accuracy: 25.370\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.146753827, Training Accuracy: 22.672\n",
            "Worker 1, [02/2]: Training Loss: 3.119158781, Training Accuracy: 23.184\n",
            "Time taken for training worker 1: 0:00:05.852966\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.115500730, Training Accuracy: 22.672\n",
            "Worker 2, [02/2]: Training Loss: 3.107793689, Training Accuracy: 23.200\n",
            "Time taken for training worker 2: 0:00:05.489022\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 3.059765665, Training Accuracy: 24.352\n",
            "Worker 3, [02/2]: Training Loss: 3.084428950, Training Accuracy: 23.552\n",
            "Time taken for training worker 3: 0:00:05.331857\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 3.065520099, Training Accuracy: 24.352\n",
            "Worker 4, [02/2]: Training Loss: 3.062137472, Training Accuracy: 23.920\n",
            "Time taken for training worker 4: 0:00:05.971891\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 3.021260471, Training Accuracy: 25.184\n",
            "Worker 5, [02/2]: Training Loss: 2.997846265, Training Accuracy: 25.056\n",
            "Time taken for training worker 5: 0:00:05.306221\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.969517829, Training Accuracy: 25.632\n",
            "Worker 6, [02/2]: Training Loss: 2.940573451, Training Accuracy: 26.480\n",
            "Time taken for training worker 6: 0:00:05.406057\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.932169374, Training Accuracy: 27.232\n",
            "Worker 7, [02/2]: Training Loss: 2.942921510, Training Accuracy: 26.944\n",
            "Time taken for training worker 7: 0:00:05.857137\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.895909974, Training Accuracy: 27.312\n",
            "Worker 8, [02/2]: Training Loss: 2.878663165, Training Accuracy: 27.600\n",
            "Time taken for training worker 8: 0:00:05.920938\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000705\n",
            "Local Step 04: Test Loss: 2.794245697, Test Accuracy: 29.300\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 3.066229570, Training Accuracy: 24.064\n",
            "Worker 1, [02/2]: Training Loss: 2.792960880, Training Accuracy: 29.760\n",
            "Time taken for training worker 1: 0:00:05.492562\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 3.039728479, Training Accuracy: 24.672\n",
            "Worker 2, [02/2]: Training Loss: 2.768610249, Training Accuracy: 29.536\n",
            "Time taken for training worker 2: 0:00:05.612305\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.981465164, Training Accuracy: 25.600\n",
            "Worker 3, [02/2]: Training Loss: 2.677699218, Training Accuracy: 31.728\n",
            "Time taken for training worker 3: 0:00:05.618513\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.950333184, Training Accuracy: 26.944\n",
            "Worker 4, [02/2]: Training Loss: 2.663659920, Training Accuracy: 31.552\n",
            "Time taken for training worker 4: 0:00:05.185519\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.923933567, Training Accuracy: 25.824\n",
            "Worker 5, [02/2]: Training Loss: 2.638180509, Training Accuracy: 32.304\n",
            "Time taken for training worker 5: 0:00:05.564892\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.889975487, Training Accuracy: 27.600\n",
            "Worker 6, [02/2]: Training Loss: 2.575997593, Training Accuracy: 33.200\n",
            "Time taken for training worker 6: 0:00:05.539818\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.855101804, Training Accuracy: 28.464\n",
            "Worker 7, [02/2]: Training Loss: 2.541076512, Training Accuracy: 35.168\n",
            "Time taken for training worker 7: 0:00:05.311070\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.828276369, Training Accuracy: 27.984\n",
            "Worker 8, [02/2]: Training Loss: 2.527253841, Training Accuracy: 33.984\n",
            "Time taken for training worker 8: 0:00:05.143632\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000800\n",
            "Local Step 05: Test Loss: 2.551478380, Test Accuracy: 34.390\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.687092399, Training Accuracy: 31.360\n",
            "Worker 1, [02/2]: Training Loss: 2.671785350, Training Accuracy: 32.128\n",
            "Time taken for training worker 1: 0:00:05.414498\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.624761752, Training Accuracy: 32.160\n",
            "Worker 2, [02/2]: Training Loss: 2.652559015, Training Accuracy: 32.640\n",
            "Time taken for training worker 2: 0:00:05.498047\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.610096343, Training Accuracy: 34.016\n",
            "Worker 3, [02/2]: Training Loss: 2.588045874, Training Accuracy: 33.584\n",
            "Time taken for training worker 3: 0:00:05.049335\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.593736933, Training Accuracy: 33.888\n",
            "Worker 4, [02/2]: Training Loss: 2.554878488, Training Accuracy: 34.016\n",
            "Time taken for training worker 4: 0:00:05.463450\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.610688321, Training Accuracy: 32.448\n",
            "Worker 5, [02/2]: Training Loss: 2.572366814, Training Accuracy: 33.664\n",
            "Time taken for training worker 5: 0:00:05.467152\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.509964219, Training Accuracy: 35.056\n",
            "Worker 6, [02/2]: Training Loss: 2.491959015, Training Accuracy: 35.712\n",
            "Time taken for training worker 6: 0:00:05.822706\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.504426467, Training Accuracy: 35.824\n",
            "Worker 7, [02/2]: Training Loss: 2.479307351, Training Accuracy: 36.144\n",
            "Time taken for training worker 7: 0:00:05.833699\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.475115569, Training Accuracy: 35.072\n",
            "Worker 8, [02/2]: Training Loss: 2.457582808, Training Accuracy: 35.904\n",
            "Time taken for training worker 8: 0:00:05.580205\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000820\n",
            "Local Step 06: Test Loss: 2.432283642, Test Accuracy: 36.910\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.669992213, Training Accuracy: 31.552\n",
            "Worker 1, [02/2]: Training Loss: 2.378542808, Training Accuracy: 38.352\n",
            "Time taken for training worker 1: 0:00:05.885192\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.675872124, Training Accuracy: 31.344\n",
            "Worker 2, [02/2]: Training Loss: 2.387787618, Training Accuracy: 37.392\n",
            "Time taken for training worker 2: 0:00:05.204772\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.671159499, Training Accuracy: 32.064\n",
            "Worker 3, [02/2]: Training Loss: 2.348210743, Training Accuracy: 38.480\n",
            "Time taken for training worker 3: 0:00:05.127204\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.652832361, Training Accuracy: 32.560\n",
            "Worker 4, [02/2]: Training Loss: 2.309684104, Training Accuracy: 39.520\n",
            "Time taken for training worker 4: 0:00:05.463640\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.659844501, Training Accuracy: 31.984\n",
            "Worker 5, [02/2]: Training Loss: 2.341249748, Training Accuracy: 37.952\n",
            "Time taken for training worker 5: 0:00:05.409161\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.580381515, Training Accuracy: 34.128\n",
            "Worker 6, [02/2]: Training Loss: 2.252852092, Training Accuracy: 41.104\n",
            "Time taken for training worker 6: 0:00:05.744865\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.609082828, Training Accuracy: 33.152\n",
            "Worker 7, [02/2]: Training Loss: 2.265647115, Training Accuracy: 40.640\n",
            "Time taken for training worker 7: 0:00:05.199730\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.600561996, Training Accuracy: 33.984\n",
            "Worker 8, [02/2]: Training Loss: 2.248364765, Training Accuracy: 41.056\n",
            "Time taken for training worker 8: 0:00:05.047209\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001150\n",
            "Local Step 07: Test Loss: 2.332764979, Test Accuracy: 38.760\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.441781044, Training Accuracy: 37.296\n",
            "Worker 1, [02/2]: Training Loss: 2.376947576, Training Accuracy: 38.864\n",
            "Time taken for training worker 1: 0:00:05.747475\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.380285396, Training Accuracy: 38.160\n",
            "Worker 2, [02/2]: Training Loss: 2.378467200, Training Accuracy: 37.744\n",
            "Time taken for training worker 2: 0:00:05.687844\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.337080254, Training Accuracy: 39.168\n",
            "Worker 3, [02/2]: Training Loss: 2.301433759, Training Accuracy: 39.600\n",
            "Time taken for training worker 3: 0:00:05.459268\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.291088168, Training Accuracy: 40.544\n",
            "Worker 4, [02/2]: Training Loss: 2.293088795, Training Accuracy: 39.744\n",
            "Time taken for training worker 4: 0:00:05.064708\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.324455468, Training Accuracy: 39.120\n",
            "Worker 5, [02/2]: Training Loss: 2.320714419, Training Accuracy: 38.688\n",
            "Time taken for training worker 5: 0:00:05.296061\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.267770343, Training Accuracy: 39.616\n",
            "Worker 6, [02/2]: Training Loss: 2.262529340, Training Accuracy: 39.888\n",
            "Time taken for training worker 6: 0:00:05.857571\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.267918571, Training Accuracy: 40.208\n",
            "Worker 7, [02/2]: Training Loss: 2.266666928, Training Accuracy: 40.608\n",
            "Time taken for training worker 7: 0:00:05.844759\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.253668895, Training Accuracy: 39.824\n",
            "Worker 8, [02/2]: Training Loss: 2.224946543, Training Accuracy: 40.704\n",
            "Time taken for training worker 8: 0:00:05.312138\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001009\n",
            "Local Step 08: Test Loss: 2.216124021, Test Accuracy: 41.920\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.465998319, Training Accuracy: 36.384\n",
            "Worker 1, [02/2]: Training Loss: 2.128457412, Training Accuracy: 43.696\n",
            "Time taken for training worker 1: 0:00:05.191138\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.500588123, Training Accuracy: 35.760\n",
            "Worker 2, [02/2]: Training Loss: 2.141155751, Training Accuracy: 43.328\n",
            "Time taken for training worker 2: 0:00:05.515218\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.459300705, Training Accuracy: 36.544\n",
            "Worker 3, [02/2]: Training Loss: 2.132261114, Training Accuracy: 43.280\n",
            "Time taken for training worker 3: 0:00:05.164083\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.437397220, Training Accuracy: 37.200\n",
            "Worker 4, [02/2]: Training Loss: 2.118885937, Training Accuracy: 42.928\n",
            "Time taken for training worker 4: 0:00:05.514896\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.530193460, Training Accuracy: 34.592\n",
            "Worker 5, [02/2]: Training Loss: 2.148354989, Training Accuracy: 42.320\n",
            "Time taken for training worker 5: 0:00:05.618483\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.416015466, Training Accuracy: 37.840\n",
            "Worker 6, [02/2]: Training Loss: 2.059626186, Training Accuracy: 45.024\n",
            "Time taken for training worker 6: 0:00:05.492170\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.418419800, Training Accuracy: 37.248\n",
            "Worker 7, [02/2]: Training Loss: 2.067339183, Training Accuracy: 44.608\n",
            "Time taken for training worker 7: 0:00:05.075823\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.430116141, Training Accuracy: 36.112\n",
            "Worker 8, [02/2]: Training Loss: 2.047312154, Training Accuracy: 45.024\n",
            "Time taken for training worker 8: 0:00:05.098614\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000734\n",
            "Local Step 09: Test Loss: 2.187181867, Test Accuracy: 42.330\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.226485008, Training Accuracy: 41.152\n",
            "Worker 1, [02/2]: Training Loss: 2.245824637, Training Accuracy: 42.080\n",
            "Time taken for training worker 1: 0:00:05.327858\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.230420439, Training Accuracy: 41.248\n",
            "Worker 2, [02/2]: Training Loss: 2.198375895, Training Accuracy: 41.696\n",
            "Time taken for training worker 2: 0:00:05.578278\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.178958421, Training Accuracy: 42.640\n",
            "Worker 3, [02/2]: Training Loss: 2.171187097, Training Accuracy: 42.496\n",
            "Time taken for training worker 3: 0:00:05.569767\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.123545291, Training Accuracy: 43.744\n",
            "Worker 4, [02/2]: Training Loss: 2.119780560, Training Accuracy: 43.104\n",
            "Time taken for training worker 4: 0:00:05.503455\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.170532807, Training Accuracy: 41.984\n",
            "Worker 5, [02/2]: Training Loss: 2.145500525, Training Accuracy: 42.224\n",
            "Time taken for training worker 5: 0:00:05.490341\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.072563485, Training Accuracy: 44.624\n",
            "Worker 6, [02/2]: Training Loss: 2.053431472, Training Accuracy: 45.376\n",
            "Time taken for training worker 6: 0:00:05.457363\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.064695565, Training Accuracy: 45.248\n",
            "Worker 7, [02/2]: Training Loss: 2.082525456, Training Accuracy: 44.992\n",
            "Time taken for training worker 7: 0:00:05.706235\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.039211366, Training Accuracy: 45.056\n",
            "Worker 8, [02/2]: Training Loss: 2.026508937, Training Accuracy: 44.640\n",
            "Time taken for training worker 8: 0:00:05.033033\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000781\n",
            "Local Step 10: Test Loss: 2.110772024, Test Accuracy: 44.140\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.298109613, Training Accuracy: 39.360\n",
            "Worker 1, [02/2]: Training Loss: 1.942598072, Training Accuracy: 47.184\n",
            "Time taken for training worker 1: 0:00:05.826946\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.321684131, Training Accuracy: 39.232\n",
            "Worker 2, [02/2]: Training Loss: 1.961561587, Training Accuracy: 46.704\n",
            "Time taken for training worker 2: 0:00:05.293781\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.299931032, Training Accuracy: 39.280\n",
            "Worker 3, [02/2]: Training Loss: 1.951666609, Training Accuracy: 47.584\n",
            "Time taken for training worker 3: 0:00:05.183842\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.322880642, Training Accuracy: 39.728\n",
            "Worker 4, [02/2]: Training Loss: 1.964867462, Training Accuracy: 46.864\n",
            "Time taken for training worker 4: 0:00:05.332670\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.373284204, Training Accuracy: 38.640\n",
            "Worker 5, [02/2]: Training Loss: 1.987525841, Training Accuracy: 45.840\n",
            "Time taken for training worker 5: 0:00:05.201022\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.282301469, Training Accuracy: 40.080\n",
            "Worker 6, [02/2]: Training Loss: 1.904133511, Training Accuracy: 48.400\n",
            "Time taken for training worker 6: 0:00:05.214799\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.299132620, Training Accuracy: 39.168\n",
            "Worker 7, [02/2]: Training Loss: 1.945001224, Training Accuracy: 47.648\n",
            "Time taken for training worker 7: 0:00:05.444734\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.249561656, Training Accuracy: 40.528\n",
            "Worker 8, [02/2]: Training Loss: 1.909197484, Training Accuracy: 47.840\n",
            "Time taken for training worker 8: 0:00:05.265609\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000856\n",
            "Local Step 11: Test Loss: 2.164859480, Test Accuracy: 43.650\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.153321752, Training Accuracy: 43.600\n",
            "Worker 1, [02/2]: Training Loss: 2.125971516, Training Accuracy: 43.744\n",
            "Time taken for training worker 1: 0:00:05.790184\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.084557628, Training Accuracy: 44.000\n",
            "Worker 2, [02/2]: Training Loss: 2.047225175, Training Accuracy: 44.848\n",
            "Time taken for training worker 2: 0:00:05.641838\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.024639568, Training Accuracy: 45.920\n",
            "Worker 3, [02/2]: Training Loss: 2.007785279, Training Accuracy: 46.384\n",
            "Time taken for training worker 3: 0:00:05.374967\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.016446907, Training Accuracy: 45.584\n",
            "Worker 4, [02/2]: Training Loss: 1.988814642, Training Accuracy: 46.960\n",
            "Time taken for training worker 4: 0:00:06.217967\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.076645975, Training Accuracy: 44.528\n",
            "Worker 5, [02/2]: Training Loss: 2.007969663, Training Accuracy: 46.176\n",
            "Time taken for training worker 5: 0:00:05.831419\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.950827533, Training Accuracy: 47.472\n",
            "Worker 6, [02/2]: Training Loss: 1.935463358, Training Accuracy: 47.472\n",
            "Time taken for training worker 6: 0:00:05.856396\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.945711899, Training Accuracy: 47.312\n",
            "Worker 7, [02/2]: Training Loss: 1.923689914, Training Accuracy: 47.824\n",
            "Time taken for training worker 7: 0:00:05.832818\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.960182938, Training Accuracy: 46.528\n",
            "Worker 8, [02/2]: Training Loss: 1.890193460, Training Accuracy: 47.888\n",
            "Time taken for training worker 8: 0:00:05.579608\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001172\n",
            "Local Step 12: Test Loss: 2.070187011, Test Accuracy: 45.550\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.198069553, Training Accuracy: 42.624\n",
            "Worker 1, [02/2]: Training Loss: 1.810713829, Training Accuracy: 50.832\n",
            "Time taken for training worker 1: 0:00:05.185621\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.214533537, Training Accuracy: 40.704\n",
            "Worker 2, [02/2]: Training Loss: 1.826147907, Training Accuracy: 50.112\n",
            "Time taken for training worker 2: 0:00:05.439668\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.208801677, Training Accuracy: 41.104\n",
            "Worker 3, [02/2]: Training Loss: 1.839189527, Training Accuracy: 49.568\n",
            "Time taken for training worker 3: 0:00:05.424752\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.239279204, Training Accuracy: 40.960\n",
            "Worker 4, [02/2]: Training Loss: 1.835309548, Training Accuracy: 50.224\n",
            "Time taken for training worker 4: 0:00:05.577437\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.252211492, Training Accuracy: 41.072\n",
            "Worker 5, [02/2]: Training Loss: 1.876815371, Training Accuracy: 48.960\n",
            "Time taken for training worker 5: 0:00:05.814301\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.216880772, Training Accuracy: 41.184\n",
            "Worker 6, [02/2]: Training Loss: 1.812015003, Training Accuracy: 51.264\n",
            "Time taken for training worker 6: 0:00:06.068798\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.208437561, Training Accuracy: 42.128\n",
            "Worker 7, [02/2]: Training Loss: 1.823504744, Training Accuracy: 50.000\n",
            "Time taken for training worker 7: 0:00:05.307789\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.189088424, Training Accuracy: 41.776\n",
            "Worker 8, [02/2]: Training Loss: 1.777453041, Training Accuracy: 50.736\n",
            "Time taken for training worker 8: 0:00:05.105470\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000731\n",
            "Local Step 13: Test Loss: 2.114896220, Test Accuracy: 44.970\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.081578288, Training Accuracy: 44.896\n",
            "Worker 1, [02/2]: Training Loss: 2.032310536, Training Accuracy: 45.824\n",
            "Time taken for training worker 1: 0:00:05.143738\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.031986941, Training Accuracy: 45.696\n",
            "Worker 2, [02/2]: Training Loss: 1.992330543, Training Accuracy: 46.912\n",
            "Time taken for training worker 2: 0:00:05.417604\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.954968141, Training Accuracy: 46.640\n",
            "Worker 3, [02/2]: Training Loss: 1.927629901, Training Accuracy: 48.576\n",
            "Time taken for training worker 3: 0:00:05.153208\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.949401148, Training Accuracy: 47.424\n",
            "Worker 4, [02/2]: Training Loss: 1.895845835, Training Accuracy: 48.992\n",
            "Time taken for training worker 4: 0:00:05.264585\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.928415328, Training Accuracy: 47.744\n",
            "Worker 5, [02/2]: Training Loss: 1.907159462, Training Accuracy: 48.336\n",
            "Time taken for training worker 5: 0:00:05.393777\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.885264105, Training Accuracy: 48.848\n",
            "Worker 6, [02/2]: Training Loss: 1.845872614, Training Accuracy: 49.456\n",
            "Time taken for training worker 6: 0:00:05.359652\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.861154993, Training Accuracy: 49.568\n",
            "Worker 7, [02/2]: Training Loss: 1.827642322, Training Accuracy: 50.688\n",
            "Time taken for training worker 7: 0:00:05.942946\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.796745333, Training Accuracy: 50.288\n",
            "Worker 8, [02/2]: Training Loss: 1.783710914, Training Accuracy: 50.928\n",
            "Time taken for training worker 8: 0:00:05.370856\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000741\n",
            "Local Step 14: Test Loss: 2.025105331, Test Accuracy: 46.880\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.086906810, Training Accuracy: 44.112\n",
            "Worker 1, [02/2]: Training Loss: 1.720234013, Training Accuracy: 53.392\n",
            "Time taken for training worker 1: 0:00:05.145604\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.147410815, Training Accuracy: 43.232\n",
            "Worker 2, [02/2]: Training Loss: 1.727336693, Training Accuracy: 52.112\n",
            "Time taken for training worker 2: 0:00:05.549178\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.125196447, Training Accuracy: 43.408\n",
            "Worker 3, [02/2]: Training Loss: 1.727394195, Training Accuracy: 52.384\n",
            "Time taken for training worker 3: 0:00:05.811314\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.130674200, Training Accuracy: 43.600\n",
            "Worker 4, [02/2]: Training Loss: 1.713850301, Training Accuracy: 52.096\n",
            "Time taken for training worker 4: 0:00:05.104727\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.162908363, Training Accuracy: 42.256\n",
            "Worker 5, [02/2]: Training Loss: 1.783998544, Training Accuracy: 50.496\n",
            "Time taken for training worker 5: 0:00:05.525758\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.127095344, Training Accuracy: 43.984\n",
            "Worker 6, [02/2]: Training Loss: 1.758026728, Training Accuracy: 51.840\n",
            "Time taken for training worker 6: 0:00:05.769391\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.111161244, Training Accuracy: 44.240\n",
            "Worker 7, [02/2]: Training Loss: 1.752005668, Training Accuracy: 52.096\n",
            "Time taken for training worker 7: 0:00:05.112283\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.085595194, Training Accuracy: 44.048\n",
            "Worker 8, [02/2]: Training Loss: 1.698061199, Training Accuracy: 52.592\n",
            "Time taken for training worker 8: 0:00:05.155421\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000725\n",
            "Local Step 15: Test Loss: 2.101076857, Test Accuracy: 45.910\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.036254987, Training Accuracy: 45.904\n",
            "Worker 1, [02/2]: Training Loss: 1.957037097, Training Accuracy: 47.488\n",
            "Time taken for training worker 1: 0:00:05.570816\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.914258626, Training Accuracy: 47.824\n",
            "Worker 2, [02/2]: Training Loss: 1.880504864, Training Accuracy: 49.232\n",
            "Time taken for training worker 2: 0:00:05.133952\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.897829469, Training Accuracy: 48.832\n",
            "Worker 3, [02/2]: Training Loss: 1.855158143, Training Accuracy: 49.584\n",
            "Time taken for training worker 3: 0:00:05.096826\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.829894568, Training Accuracy: 50.960\n",
            "Worker 4, [02/2]: Training Loss: 1.840382543, Training Accuracy: 49.824\n",
            "Time taken for training worker 4: 0:00:05.602176\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.861518413, Training Accuracy: 49.264\n",
            "Worker 5, [02/2]: Training Loss: 1.851407721, Training Accuracy: 49.376\n",
            "Time taken for training worker 5: 0:00:05.211555\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.844402638, Training Accuracy: 49.776\n",
            "Worker 6, [02/2]: Training Loss: 1.766439617, Training Accuracy: 51.840\n",
            "Time taken for training worker 6: 0:00:05.550374\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.780250220, Training Accuracy: 51.424\n",
            "Worker 7, [02/2]: Training Loss: 1.740859247, Training Accuracy: 52.544\n",
            "Time taken for training worker 7: 0:00:05.804557\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.716836820, Training Accuracy: 51.328\n",
            "Worker 8, [02/2]: Training Loss: 1.688857377, Training Accuracy: 52.656\n",
            "Time taken for training worker 8: 0:00:05.433539\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000797\n",
            "Local Step 16: Test Loss: 2.008040805, Test Accuracy: 47.310\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 2.053265566, Training Accuracy: 45.104\n",
            "Worker 1, [02/2]: Training Loss: 1.646738662, Training Accuracy: 54.752\n",
            "Time taken for training worker 1: 0:00:05.356397\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 2.067877609, Training Accuracy: 44.992\n",
            "Worker 2, [02/2]: Training Loss: 1.674002623, Training Accuracy: 53.408\n",
            "Time taken for training worker 2: 0:00:05.208190\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 2.057079026, Training Accuracy: 45.616\n",
            "Worker 3, [02/2]: Training Loss: 1.637947523, Training Accuracy: 54.624\n",
            "Time taken for training worker 3: 0:00:05.232925\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.094251465, Training Accuracy: 44.272\n",
            "Worker 4, [02/2]: Training Loss: 1.685797807, Training Accuracy: 53.616\n",
            "Time taken for training worker 4: 0:00:05.277591\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.133703519, Training Accuracy: 43.312\n",
            "Worker 5, [02/2]: Training Loss: 1.705244086, Training Accuracy: 53.072\n",
            "Time taken for training worker 5: 0:00:05.233246\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.095017141, Training Accuracy: 45.008\n",
            "Worker 6, [02/2]: Training Loss: 1.678354987, Training Accuracy: 53.936\n",
            "Time taken for training worker 6: 0:00:05.224727\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.073694858, Training Accuracy: 44.416\n",
            "Worker 7, [02/2]: Training Loss: 1.648090054, Training Accuracy: 54.768\n",
            "Time taken for training worker 7: 0:00:05.152795\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.070149242, Training Accuracy: 44.320\n",
            "Worker 8, [02/2]: Training Loss: 1.658669995, Training Accuracy: 54.176\n",
            "Time taken for training worker 8: 0:00:05.684768\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000747\n",
            "Local Step 17: Test Loss: 2.008926958, Test Accuracy: 47.630\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.908345737, Training Accuracy: 49.408\n",
            "Worker 1, [02/2]: Training Loss: 1.871322606, Training Accuracy: 49.520\n",
            "Time taken for training worker 1: 0:00:05.174284\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.881313564, Training Accuracy: 48.192\n",
            "Worker 2, [02/2]: Training Loss: 1.821362268, Training Accuracy: 49.904\n",
            "Time taken for training worker 2: 0:00:05.763673\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.847259141, Training Accuracy: 49.840\n",
            "Worker 3, [02/2]: Training Loss: 1.815549537, Training Accuracy: 50.992\n",
            "Time taken for training worker 3: 0:00:05.919874\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.784772551, Training Accuracy: 51.488\n",
            "Worker 4, [02/2]: Training Loss: 1.783517290, Training Accuracy: 51.232\n",
            "Time taken for training worker 4: 0:00:05.239761\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.803374225, Training Accuracy: 50.256\n",
            "Worker 5, [02/2]: Training Loss: 1.771197504, Training Accuracy: 51.264\n",
            "Time taken for training worker 5: 0:00:05.194545\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.764549923, Training Accuracy: 51.520\n",
            "Worker 6, [02/2]: Training Loss: 1.728414702, Training Accuracy: 52.192\n",
            "Time taken for training worker 6: 0:00:05.552269\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.698439042, Training Accuracy: 53.232\n",
            "Worker 7, [02/2]: Training Loss: 1.710395163, Training Accuracy: 53.552\n",
            "Time taken for training worker 7: 0:00:05.161553\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.663146018, Training Accuracy: 53.328\n",
            "Worker 8, [02/2]: Training Loss: 1.636243060, Training Accuracy: 54.592\n",
            "Time taken for training worker 8: 0:00:05.445517\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000723\n",
            "Local Step 18: Test Loss: 1.948187685, Test Accuracy: 48.700\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.945878210, Training Accuracy: 46.960\n",
            "Worker 1, [02/2]: Training Loss: 1.578503244, Training Accuracy: 56.528\n",
            "Time taken for training worker 1: 0:00:05.412639\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.993813017, Training Accuracy: 45.696\n",
            "Worker 2, [02/2]: Training Loss: 1.604925387, Training Accuracy: 55.696\n",
            "Time taken for training worker 2: 0:00:05.518344\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.988705329, Training Accuracy: 46.592\n",
            "Worker 3, [02/2]: Training Loss: 1.586985384, Training Accuracy: 55.968\n",
            "Time taken for training worker 3: 0:00:05.096937\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 2.040076145, Training Accuracy: 45.904\n",
            "Worker 4, [02/2]: Training Loss: 1.614728470, Training Accuracy: 55.520\n",
            "Time taken for training worker 4: 0:00:05.801810\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.032691018, Training Accuracy: 45.504\n",
            "Worker 5, [02/2]: Training Loss: 1.643709040, Training Accuracy: 54.640\n",
            "Time taken for training worker 5: 0:00:06.107563\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 2.014870208, Training Accuracy: 45.616\n",
            "Worker 6, [02/2]: Training Loss: 1.600992181, Training Accuracy: 56.032\n",
            "Time taken for training worker 6: 0:00:05.591532\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 2.040274655, Training Accuracy: 45.184\n",
            "Worker 7, [02/2]: Training Loss: 1.642240937, Training Accuracy: 54.352\n",
            "Time taken for training worker 7: 0:00:05.725848\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 2.017625663, Training Accuracy: 45.760\n",
            "Worker 8, [02/2]: Training Loss: 1.609465415, Training Accuracy: 55.296\n",
            "Time taken for training worker 8: 0:00:05.550224\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000805\n",
            "Local Step 19: Test Loss: 2.022578171, Test Accuracy: 47.930\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.857826845, Training Accuracy: 49.408\n",
            "Worker 1, [02/2]: Training Loss: 1.816426303, Training Accuracy: 50.720\n",
            "Time taken for training worker 1: 0:00:05.277956\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.821502673, Training Accuracy: 49.840\n",
            "Worker 2, [02/2]: Training Loss: 1.749626870, Training Accuracy: 52.512\n",
            "Time taken for training worker 2: 0:00:05.440619\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.767543099, Training Accuracy: 52.048\n",
            "Worker 3, [02/2]: Training Loss: 1.702300789, Training Accuracy: 53.696\n",
            "Time taken for training worker 3: 0:00:05.604672\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.746765281, Training Accuracy: 51.792\n",
            "Worker 4, [02/2]: Training Loss: 1.714243956, Training Accuracy: 52.976\n",
            "Time taken for training worker 4: 0:00:05.470906\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.745233502, Training Accuracy: 51.456\n",
            "Worker 5, [02/2]: Training Loss: 1.702059507, Training Accuracy: 53.456\n",
            "Time taken for training worker 5: 0:00:05.215556\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.688016720, Training Accuracy: 53.504\n",
            "Worker 6, [02/2]: Training Loss: 1.643532491, Training Accuracy: 54.448\n",
            "Time taken for training worker 6: 0:00:05.540993\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.733677538, Training Accuracy: 52.112\n",
            "Worker 7, [02/2]: Training Loss: 1.659358300, Training Accuracy: 54.144\n",
            "Time taken for training worker 7: 0:00:05.483566\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.603835797, Training Accuracy: 54.976\n",
            "Worker 8, [02/2]: Training Loss: 1.598867482, Training Accuracy: 55.008\n",
            "Time taken for training worker 8: 0:00:05.842886\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000733\n",
            "Local Step 20: Test Loss: 1.934832480, Test Accuracy: 49.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.922588913, Training Accuracy: 48.144\n",
            "Worker 1, [02/2]: Training Loss: 1.518947256, Training Accuracy: 58.080\n",
            "Time taken for training worker 1: 0:00:05.307761\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.947250443, Training Accuracy: 47.440\n",
            "Worker 2, [02/2]: Training Loss: 1.556856159, Training Accuracy: 57.056\n",
            "Time taken for training worker 2: 0:00:05.270494\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.946544600, Training Accuracy: 46.992\n",
            "Worker 3, [02/2]: Training Loss: 1.547668621, Training Accuracy: 56.512\n",
            "Time taken for training worker 3: 0:00:05.164930\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.983492371, Training Accuracy: 46.304\n",
            "Worker 4, [02/2]: Training Loss: 1.574266457, Training Accuracy: 55.840\n",
            "Time taken for training worker 4: 0:00:05.756498\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 2.005452922, Training Accuracy: 46.064\n",
            "Worker 5, [02/2]: Training Loss: 1.564791485, Training Accuracy: 56.208\n",
            "Time taken for training worker 5: 0:00:05.652407\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.972637706, Training Accuracy: 47.200\n",
            "Worker 6, [02/2]: Training Loss: 1.553305643, Training Accuracy: 56.704\n",
            "Time taken for training worker 6: 0:00:05.457185\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.970256714, Training Accuracy: 47.232\n",
            "Worker 7, [02/2]: Training Loss: 1.555356338, Training Accuracy: 56.816\n",
            "Time taken for training worker 7: 0:00:05.834828\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.966806429, Training Accuracy: 46.400\n",
            "Worker 8, [02/2]: Training Loss: 1.551235925, Training Accuracy: 56.016\n",
            "Time taken for training worker 8: 0:00:05.843857\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000807\n",
            "Local Step 21: Test Loss: 2.027016169, Test Accuracy: 47.760\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.849062528, Training Accuracy: 50.736\n",
            "Worker 1, [02/2]: Training Loss: 1.751475880, Training Accuracy: 51.936\n",
            "Time taken for training worker 1: 0:00:05.203628\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.772136387, Training Accuracy: 50.832\n",
            "Worker 2, [02/2]: Training Loss: 1.725032618, Training Accuracy: 52.080\n",
            "Time taken for training worker 2: 0:00:05.707090\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.734290687, Training Accuracy: 52.240\n",
            "Worker 3, [02/2]: Training Loss: 1.658110212, Training Accuracy: 53.968\n",
            "Time taken for training worker 3: 0:00:05.079964\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.765384840, Training Accuracy: 51.488\n",
            "Worker 4, [02/2]: Training Loss: 1.706028520, Training Accuracy: 53.248\n",
            "Time taken for training worker 4: 0:00:05.084364\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.695555165, Training Accuracy: 53.328\n",
            "Worker 5, [02/2]: Training Loss: 1.655087235, Training Accuracy: 54.144\n",
            "Time taken for training worker 5: 0:00:05.076734\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.683479811, Training Accuracy: 53.488\n",
            "Worker 6, [02/2]: Training Loss: 1.636229648, Training Accuracy: 54.032\n",
            "Time taken for training worker 6: 0:00:05.485994\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.606408895, Training Accuracy: 55.552\n",
            "Worker 7, [02/2]: Training Loss: 1.594089065, Training Accuracy: 55.184\n",
            "Time taken for training worker 7: 0:00:05.288049\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.557067170, Training Accuracy: 56.320\n",
            "Worker 8, [02/2]: Training Loss: 1.524460032, Training Accuracy: 56.672\n",
            "Time taken for training worker 8: 0:00:05.439939\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000900\n",
            "Local Step 22: Test Loss: 1.944587298, Test Accuracy: 49.940\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.874432744, Training Accuracy: 48.720\n",
            "Worker 1, [02/2]: Training Loss: 1.483951415, Training Accuracy: 58.576\n",
            "Time taken for training worker 1: 0:00:05.147114\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.912686356, Training Accuracy: 48.624\n",
            "Worker 2, [02/2]: Training Loss: 1.482254311, Training Accuracy: 58.768\n",
            "Time taken for training worker 2: 0:00:05.209722\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.915164653, Training Accuracy: 47.680\n",
            "Worker 3, [02/2]: Training Loss: 1.514247787, Training Accuracy: 57.872\n",
            "Time taken for training worker 3: 0:00:05.255660\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.942695090, Training Accuracy: 47.616\n",
            "Worker 4, [02/2]: Training Loss: 1.519133213, Training Accuracy: 57.920\n",
            "Time taken for training worker 4: 0:00:05.360083\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.976421676, Training Accuracy: 46.224\n",
            "Worker 5, [02/2]: Training Loss: 1.543454703, Training Accuracy: 56.912\n",
            "Time taken for training worker 5: 0:00:05.533689\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.938972348, Training Accuracy: 48.288\n",
            "Worker 6, [02/2]: Training Loss: 1.508171833, Training Accuracy: 57.936\n",
            "Time taken for training worker 6: 0:00:05.957804\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.951890064, Training Accuracy: 47.568\n",
            "Worker 7, [02/2]: Training Loss: 1.547948607, Training Accuracy: 57.504\n",
            "Time taken for training worker 7: 0:00:05.718313\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.913863700, Training Accuracy: 47.472\n",
            "Worker 8, [02/2]: Training Loss: 1.499134711, Training Accuracy: 58.064\n",
            "Time taken for training worker 8: 0:00:05.370486\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000726\n",
            "Local Step 23: Test Loss: 1.990327714, Test Accuracy: 47.910\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.801982400, Training Accuracy: 51.680\n",
            "Worker 1, [02/2]: Training Loss: 1.742581213, Training Accuracy: 52.288\n",
            "Time taken for training worker 1: 0:00:05.238824\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.710926768, Training Accuracy: 52.432\n",
            "Worker 2, [02/2]: Training Loss: 1.684675100, Training Accuracy: 53.440\n",
            "Time taken for training worker 2: 0:00:05.501465\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.697690786, Training Accuracy: 52.848\n",
            "Worker 3, [02/2]: Training Loss: 1.621542421, Training Accuracy: 55.120\n",
            "Time taken for training worker 3: 0:00:05.945184\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.671125526, Training Accuracy: 53.840\n",
            "Worker 4, [02/2]: Training Loss: 1.626797784, Training Accuracy: 54.128\n",
            "Time taken for training worker 4: 0:00:05.764008\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.635008774, Training Accuracy: 54.800\n",
            "Worker 5, [02/2]: Training Loss: 1.627818491, Training Accuracy: 55.040\n",
            "Time taken for training worker 5: 0:00:05.867490\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.611985230, Training Accuracy: 54.656\n",
            "Worker 6, [02/2]: Training Loss: 1.562899600, Training Accuracy: 56.592\n",
            "Time taken for training worker 6: 0:00:05.411857\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.549073085, Training Accuracy: 56.848\n",
            "Worker 7, [02/2]: Training Loss: 1.539872031, Training Accuracy: 57.424\n",
            "Time taken for training worker 7: 0:00:05.135007\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.506675724, Training Accuracy: 57.856\n",
            "Worker 8, [02/2]: Training Loss: 1.483582520, Training Accuracy: 57.760\n",
            "Time taken for training worker 8: 0:00:05.266498\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001302\n",
            "Local Step 24: Test Loss: 1.926615335, Test Accuracy: 50.090\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.822427941, Training Accuracy: 51.024\n",
            "Worker 1, [02/2]: Training Loss: 1.434156611, Training Accuracy: 60.576\n",
            "Time taken for training worker 1: 0:00:05.710324\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.885038459, Training Accuracy: 48.576\n",
            "Worker 2, [02/2]: Training Loss: 1.435806087, Training Accuracy: 59.248\n",
            "Time taken for training worker 2: 0:00:05.506242\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.864865490, Training Accuracy: 49.040\n",
            "Worker 3, [02/2]: Training Loss: 1.459384076, Training Accuracy: 58.976\n",
            "Time taken for training worker 3: 0:00:05.498255\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.882231245, Training Accuracy: 48.480\n",
            "Worker 4, [02/2]: Training Loss: 1.491467841, Training Accuracy: 58.192\n",
            "Time taken for training worker 4: 0:00:05.783794\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.919729786, Training Accuracy: 48.096\n",
            "Worker 5, [02/2]: Training Loss: 1.514789930, Training Accuracy: 57.760\n",
            "Time taken for training worker 5: 0:00:05.877532\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.891456559, Training Accuracy: 48.864\n",
            "Worker 6, [02/2]: Training Loss: 1.480407866, Training Accuracy: 58.336\n",
            "Time taken for training worker 6: 0:00:06.000410\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.914286819, Training Accuracy: 48.576\n",
            "Worker 7, [02/2]: Training Loss: 1.485764500, Training Accuracy: 57.840\n",
            "Time taken for training worker 7: 0:00:05.615803\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.909704384, Training Accuracy: 47.472\n",
            "Worker 8, [02/2]: Training Loss: 1.470962742, Training Accuracy: 58.976\n",
            "Time taken for training worker 8: 0:00:05.469348\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000725\n",
            "Local Step 25: Test Loss: 1.978563107, Test Accuracy: 48.950\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.783358198, Training Accuracy: 51.728\n",
            "Worker 1, [02/2]: Training Loss: 1.714072852, Training Accuracy: 53.648\n",
            "Time taken for training worker 1: 0:00:05.725183\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.700366540, Training Accuracy: 53.104\n",
            "Worker 2, [02/2]: Training Loss: 1.666653029, Training Accuracy: 54.304\n",
            "Time taken for training worker 2: 0:00:05.037062\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.674949780, Training Accuracy: 53.200\n",
            "Worker 3, [02/2]: Training Loss: 1.605877480, Training Accuracy: 55.472\n",
            "Time taken for training worker 3: 0:00:05.158348\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.604767507, Training Accuracy: 54.992\n",
            "Worker 4, [02/2]: Training Loss: 1.563428975, Training Accuracy: 56.432\n",
            "Time taken for training worker 4: 0:00:05.782074\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.631458374, Training Accuracy: 54.384\n",
            "Worker 5, [02/2]: Training Loss: 1.582656830, Training Accuracy: 56.368\n",
            "Time taken for training worker 5: 0:00:05.366101\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.602200341, Training Accuracy: 55.328\n",
            "Worker 6, [02/2]: Training Loss: 1.551687101, Training Accuracy: 56.512\n",
            "Time taken for training worker 6: 0:00:05.338541\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.532243401, Training Accuracy: 56.848\n",
            "Worker 7, [02/2]: Training Loss: 1.529852688, Training Accuracy: 57.984\n",
            "Time taken for training worker 7: 0:00:05.567128\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.485165176, Training Accuracy: 58.016\n",
            "Worker 8, [02/2]: Training Loss: 1.455935632, Training Accuracy: 58.464\n",
            "Time taken for training worker 8: 0:00:05.121811\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000906\n",
            "Local Step 26: Test Loss: 1.895982288, Test Accuracy: 50.590\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.760771630, Training Accuracy: 51.424\n",
            "Worker 1, [02/2]: Training Loss: 1.384970891, Training Accuracy: 61.104\n",
            "Time taken for training worker 1: 0:00:05.339866\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.817225746, Training Accuracy: 49.760\n",
            "Worker 2, [02/2]: Training Loss: 1.407613461, Training Accuracy: 60.096\n",
            "Time taken for training worker 2: 0:00:05.545475\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.882704759, Training Accuracy: 48.256\n",
            "Worker 3, [02/2]: Training Loss: 1.420174720, Training Accuracy: 59.952\n",
            "Time taken for training worker 3: 0:00:05.166208\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.907094277, Training Accuracy: 48.624\n",
            "Worker 4, [02/2]: Training Loss: 1.461010296, Training Accuracy: 58.832\n",
            "Time taken for training worker 4: 0:00:05.191293\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.902871328, Training Accuracy: 48.448\n",
            "Worker 5, [02/2]: Training Loss: 1.443964551, Training Accuracy: 59.488\n",
            "Time taken for training worker 5: 0:00:05.450478\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.892168293, Training Accuracy: 48.560\n",
            "Worker 6, [02/2]: Training Loss: 1.467961474, Training Accuracy: 58.224\n",
            "Time taken for training worker 6: 0:00:05.413823\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.921773206, Training Accuracy: 47.856\n",
            "Worker 7, [02/2]: Training Loss: 1.471928647, Training Accuracy: 58.640\n",
            "Time taken for training worker 7: 0:00:05.044910\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.879821176, Training Accuracy: 49.216\n",
            "Worker 8, [02/2]: Training Loss: 1.461406109, Training Accuracy: 58.016\n",
            "Time taken for training worker 8: 0:00:05.447245\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001168\n",
            "Local Step 27: Test Loss: 1.975742131, Test Accuracy: 48.860\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.725867230, Training Accuracy: 52.736\n",
            "Worker 1, [02/2]: Training Loss: 1.650836488, Training Accuracy: 54.352\n",
            "Time taken for training worker 1: 0:00:05.286181\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.668527637, Training Accuracy: 53.152\n",
            "Worker 2, [02/2]: Training Loss: 1.633482640, Training Accuracy: 54.624\n",
            "Time taken for training worker 2: 0:00:05.734771\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.645850905, Training Accuracy: 53.840\n",
            "Worker 3, [02/2]: Training Loss: 1.572411490, Training Accuracy: 55.120\n",
            "Time taken for training worker 3: 0:00:05.418602\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.616155649, Training Accuracy: 54.800\n",
            "Worker 4, [02/2]: Training Loss: 1.545924698, Training Accuracy: 56.912\n",
            "Time taken for training worker 4: 0:00:05.470623\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.594576825, Training Accuracy: 55.728\n",
            "Worker 5, [02/2]: Training Loss: 1.569506025, Training Accuracy: 56.272\n",
            "Time taken for training worker 5: 0:00:05.758854\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.528088318, Training Accuracy: 57.088\n",
            "Worker 6, [02/2]: Training Loss: 1.500335875, Training Accuracy: 57.760\n",
            "Time taken for training worker 6: 0:00:05.164620\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.505311922, Training Accuracy: 57.904\n",
            "Worker 7, [02/2]: Training Loss: 1.485683666, Training Accuracy: 58.848\n",
            "Time taken for training worker 7: 0:00:05.528650\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.435685891, Training Accuracy: 59.344\n",
            "Worker 8, [02/2]: Training Loss: 1.401256637, Training Accuracy: 59.632\n",
            "Time taken for training worker 8: 0:00:05.139587\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000811\n",
            "Local Step 28: Test Loss: 1.964846395, Test Accuracy: 49.120\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.810389539, Training Accuracy: 50.192\n",
            "Worker 1, [02/2]: Training Loss: 1.376815525, Training Accuracy: 61.712\n",
            "Time taken for training worker 1: 0:00:05.119777\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.820419291, Training Accuracy: 49.840\n",
            "Worker 2, [02/2]: Training Loss: 1.381610026, Training Accuracy: 60.784\n",
            "Time taken for training worker 2: 0:00:05.430086\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.793961131, Training Accuracy: 50.896\n",
            "Worker 3, [02/2]: Training Loss: 1.418759542, Training Accuracy: 59.712\n",
            "Time taken for training worker 3: 0:00:05.493797\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.844067522, Training Accuracy: 49.616\n",
            "Worker 4, [02/2]: Training Loss: 1.394512072, Training Accuracy: 60.864\n",
            "Time taken for training worker 4: 0:00:05.261502\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.857670462, Training Accuracy: 49.280\n",
            "Worker 5, [02/2]: Training Loss: 1.446534583, Training Accuracy: 58.912\n",
            "Time taken for training worker 5: 0:00:05.576596\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.819294537, Training Accuracy: 49.728\n",
            "Worker 6, [02/2]: Training Loss: 1.401054616, Training Accuracy: 60.272\n",
            "Time taken for training worker 6: 0:00:05.232434\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.854704729, Training Accuracy: 49.808\n",
            "Worker 7, [02/2]: Training Loss: 1.414505927, Training Accuracy: 60.704\n",
            "Time taken for training worker 7: 0:00:05.487567\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.867328785, Training Accuracy: 49.072\n",
            "Worker 8, [02/2]: Training Loss: 1.393936315, Training Accuracy: 60.320\n",
            "Time taken for training worker 8: 0:00:05.079123\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000743\n",
            "Local Step 29: Test Loss: 1.939455056, Test Accuracy: 50.230\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.684587734, Training Accuracy: 54.016\n",
            "Worker 1, [02/2]: Training Loss: 1.621075027, Training Accuracy: 55.456\n",
            "Time taken for training worker 1: 0:00:05.855108\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.641194262, Training Accuracy: 53.792\n",
            "Worker 2, [02/2]: Training Loss: 1.611550711, Training Accuracy: 54.704\n",
            "Time taken for training worker 2: 0:00:05.152957\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.568457607, Training Accuracy: 56.096\n",
            "Worker 3, [02/2]: Training Loss: 1.518307822, Training Accuracy: 56.784\n",
            "Time taken for training worker 3: 0:00:05.348560\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.630139459, Training Accuracy: 54.096\n",
            "Worker 4, [02/2]: Training Loss: 1.562177578, Training Accuracy: 56.624\n",
            "Time taken for training worker 4: 0:00:05.148547\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.574176629, Training Accuracy: 56.432\n",
            "Worker 5, [02/2]: Training Loss: 1.514678942, Training Accuracy: 57.040\n",
            "Time taken for training worker 5: 0:00:05.561539\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.528318976, Training Accuracy: 56.992\n",
            "Worker 6, [02/2]: Training Loss: 1.483160681, Training Accuracy: 57.696\n",
            "Time taken for training worker 6: 0:00:05.406296\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.478620940, Training Accuracy: 58.368\n",
            "Worker 7, [02/2]: Training Loss: 1.450169468, Training Accuracy: 59.184\n",
            "Time taken for training worker 7: 0:00:05.634087\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.454514320, Training Accuracy: 58.688\n",
            "Worker 8, [02/2]: Training Loss: 1.381501366, Training Accuracy: 60.256\n",
            "Time taken for training worker 8: 0:00:05.351135\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000800\n",
            "Local Step 30: Test Loss: 1.899669213, Test Accuracy: 50.920\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.770717244, Training Accuracy: 51.536\n",
            "Worker 1, [02/2]: Training Loss: 1.331982925, Training Accuracy: 62.560\n",
            "Time taken for training worker 1: 0:00:05.069302\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.809607621, Training Accuracy: 50.192\n",
            "Worker 2, [02/2]: Training Loss: 1.401993522, Training Accuracy: 60.272\n",
            "Time taken for training worker 2: 0:00:05.478145\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.801939469, Training Accuracy: 50.464\n",
            "Worker 3, [02/2]: Training Loss: 1.388859816, Training Accuracy: 60.976\n",
            "Time taken for training worker 3: 0:00:05.170421\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.861950816, Training Accuracy: 49.904\n",
            "Worker 4, [02/2]: Training Loss: 1.410451733, Training Accuracy: 60.704\n",
            "Time taken for training worker 4: 0:00:05.181315\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.859727131, Training Accuracy: 49.168\n",
            "Worker 5, [02/2]: Training Loss: 1.434923609, Training Accuracy: 60.160\n",
            "Time taken for training worker 5: 0:00:05.213502\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.870171172, Training Accuracy: 48.672\n",
            "Worker 6, [02/2]: Training Loss: 1.379824699, Training Accuracy: 61.072\n",
            "Time taken for training worker 6: 0:00:05.263904\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.862949453, Training Accuracy: 49.424\n",
            "Worker 7, [02/2]: Training Loss: 1.426735227, Training Accuracy: 60.448\n",
            "Time taken for training worker 7: 0:00:05.277500\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.818896468, Training Accuracy: 49.904\n",
            "Worker 8, [02/2]: Training Loss: 1.402543730, Training Accuracy: 60.080\n",
            "Time taken for training worker 8: 0:00:05.227195\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000706\n",
            "Local Step 31: Test Loss: 1.987878281, Test Accuracy: 48.430\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.734786923, Training Accuracy: 52.144\n",
            "Worker 1, [02/2]: Training Loss: 1.623913520, Training Accuracy: 55.008\n",
            "Time taken for training worker 1: 0:00:05.472628\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.646030481, Training Accuracy: 54.112\n",
            "Worker 2, [02/2]: Training Loss: 1.580093463, Training Accuracy: 55.632\n",
            "Time taken for training worker 2: 0:00:05.184922\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.558409507, Training Accuracy: 56.928\n",
            "Worker 3, [02/2]: Training Loss: 1.510899704, Training Accuracy: 56.944\n",
            "Time taken for training worker 3: 0:00:05.454616\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.570824202, Training Accuracy: 56.192\n",
            "Worker 4, [02/2]: Training Loss: 1.525930699, Training Accuracy: 57.488\n",
            "Time taken for training worker 4: 0:00:05.194665\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.555109997, Training Accuracy: 56.432\n",
            "Worker 5, [02/2]: Training Loss: 1.529296635, Training Accuracy: 57.216\n",
            "Time taken for training worker 5: 0:00:05.208663\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.496251103, Training Accuracy: 57.696\n",
            "Worker 6, [02/2]: Training Loss: 1.450477509, Training Accuracy: 59.536\n",
            "Time taken for training worker 6: 0:00:05.217879\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.480878169, Training Accuracy: 57.888\n",
            "Worker 7, [02/2]: Training Loss: 1.447121700, Training Accuracy: 59.376\n",
            "Time taken for training worker 7: 0:00:05.197861\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.411721204, Training Accuracy: 59.648\n",
            "Worker 8, [02/2]: Training Loss: 1.378065231, Training Accuracy: 60.240\n",
            "Time taken for training worker 8: 0:00:05.482980\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001009\n",
            "Local Step 32: Test Loss: 1.918295379, Test Accuracy: 50.540\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.720140214, Training Accuracy: 52.608\n",
            "Worker 1, [02/2]: Training Loss: 1.310417606, Training Accuracy: 62.992\n",
            "Time taken for training worker 1: 0:00:05.466974\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.776411044, Training Accuracy: 51.200\n",
            "Worker 2, [02/2]: Training Loss: 1.328971902, Training Accuracy: 62.032\n",
            "Time taken for training worker 2: 0:00:05.772397\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.770864820, Training Accuracy: 51.600\n",
            "Worker 3, [02/2]: Training Loss: 1.332528334, Training Accuracy: 62.960\n",
            "Time taken for training worker 3: 0:00:05.104230\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.828809815, Training Accuracy: 50.400\n",
            "Worker 4, [02/2]: Training Loss: 1.403454458, Training Accuracy: 60.896\n",
            "Time taken for training worker 4: 0:00:05.112775\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.851321186, Training Accuracy: 49.040\n",
            "Worker 5, [02/2]: Training Loss: 1.381873013, Training Accuracy: 61.024\n",
            "Time taken for training worker 5: 0:00:05.700710\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.822029160, Training Accuracy: 50.336\n",
            "Worker 6, [02/2]: Training Loss: 1.381280710, Training Accuracy: 60.880\n",
            "Time taken for training worker 6: 0:00:05.126636\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.810057711, Training Accuracy: 51.168\n",
            "Worker 7, [02/2]: Training Loss: 1.387586553, Training Accuracy: 60.688\n",
            "Time taken for training worker 7: 0:00:05.449907\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.821413539, Training Accuracy: 50.384\n",
            "Worker 8, [02/2]: Training Loss: 1.355225026, Training Accuracy: 61.104\n",
            "Time taken for training worker 8: 0:00:05.243142\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000964\n",
            "Local Step 33: Test Loss: 1.970890280, Test Accuracy: 50.130\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.658954119, Training Accuracy: 54.736\n",
            "Worker 1, [02/2]: Training Loss: 1.623055270, Training Accuracy: 55.248\n",
            "Time taken for training worker 1: 0:00:05.414945\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.601843363, Training Accuracy: 54.736\n",
            "Worker 2, [02/2]: Training Loss: 1.552716170, Training Accuracy: 56.896\n",
            "Time taken for training worker 2: 0:00:05.481128\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.530950627, Training Accuracy: 56.544\n",
            "Worker 3, [02/2]: Training Loss: 1.462372543, Training Accuracy: 58.528\n",
            "Time taken for training worker 3: 0:00:05.426386\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.526249283, Training Accuracy: 57.552\n",
            "Worker 4, [02/2]: Training Loss: 1.498076827, Training Accuracy: 57.520\n",
            "Time taken for training worker 4: 0:00:05.170058\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.526987873, Training Accuracy: 57.152\n",
            "Worker 5, [02/2]: Training Loss: 1.462044940, Training Accuracy: 58.256\n",
            "Time taken for training worker 5: 0:00:05.202675\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.450849413, Training Accuracy: 58.880\n",
            "Worker 6, [02/2]: Training Loss: 1.408053254, Training Accuracy: 60.592\n",
            "Time taken for training worker 6: 0:00:05.523994\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.434540349, Training Accuracy: 58.960\n",
            "Worker 7, [02/2]: Training Loss: 1.414505075, Training Accuracy: 60.288\n",
            "Time taken for training worker 7: 0:00:05.611872\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.413064479, Training Accuracy: 59.968\n",
            "Worker 8, [02/2]: Training Loss: 1.358998200, Training Accuracy: 60.768\n",
            "Time taken for training worker 8: 0:00:05.350039\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000702\n",
            "Local Step 34: Test Loss: 1.937229742, Test Accuracy: 50.260\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.741519182, Training Accuracy: 51.424\n",
            "Worker 1, [02/2]: Training Loss: 1.277347658, Training Accuracy: 63.456\n",
            "Time taken for training worker 1: 0:00:05.574757\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.794484297, Training Accuracy: 50.160\n",
            "Worker 2, [02/2]: Training Loss: 1.315851168, Training Accuracy: 61.760\n",
            "Time taken for training worker 2: 0:00:05.216012\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.740167722, Training Accuracy: 51.696\n",
            "Worker 3, [02/2]: Training Loss: 1.310536171, Training Accuracy: 63.136\n",
            "Time taken for training worker 3: 0:00:05.231303\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.769024885, Training Accuracy: 51.232\n",
            "Worker 4, [02/2]: Training Loss: 1.369305606, Training Accuracy: 60.800\n",
            "Time taken for training worker 4: 0:00:05.549151\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.840552522, Training Accuracy: 49.312\n",
            "Worker 5, [02/2]: Training Loss: 1.390647957, Training Accuracy: 60.992\n",
            "Time taken for training worker 5: 0:00:05.492076\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.798376929, Training Accuracy: 51.344\n",
            "Worker 6, [02/2]: Training Loss: 1.372367996, Training Accuracy: 60.816\n",
            "Time taken for training worker 6: 0:00:05.622000\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.787377454, Training Accuracy: 51.920\n",
            "Worker 7, [02/2]: Training Loss: 1.358440743, Training Accuracy: 61.392\n",
            "Time taken for training worker 7: 0:00:05.464727\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.821571084, Training Accuracy: 50.416\n",
            "Worker 8, [02/2]: Training Loss: 1.333228645, Training Accuracy: 61.808\n",
            "Time taken for training worker 8: 0:00:05.113783\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000728\n",
            "Local Step 35: Test Loss: 2.000539754, Test Accuracy: 49.750\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.681529960, Training Accuracy: 53.200\n",
            "Worker 1, [02/2]: Training Loss: 1.585731222, Training Accuracy: 55.872\n",
            "Time taken for training worker 1: 0:00:05.319721\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.604830475, Training Accuracy: 55.536\n",
            "Worker 2, [02/2]: Training Loss: 1.527935410, Training Accuracy: 57.056\n",
            "Time taken for training worker 2: 0:00:05.209508\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.508025961, Training Accuracy: 58.064\n",
            "Worker 3, [02/2]: Training Loss: 1.487642354, Training Accuracy: 57.888\n",
            "Time taken for training worker 3: 0:00:05.773366\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.517297026, Training Accuracy: 57.568\n",
            "Worker 4, [02/2]: Training Loss: 1.464474650, Training Accuracy: 59.216\n",
            "Time taken for training worker 4: 0:00:05.393541\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.499351051, Training Accuracy: 58.128\n",
            "Worker 5, [02/2]: Training Loss: 1.449898171, Training Accuracy: 58.912\n",
            "Time taken for training worker 5: 0:00:05.815029\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.449809442, Training Accuracy: 59.136\n",
            "Worker 6, [02/2]: Training Loss: 1.412695410, Training Accuracy: 59.920\n",
            "Time taken for training worker 6: 0:00:05.202120\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.413343419, Training Accuracy: 59.120\n",
            "Worker 7, [02/2]: Training Loss: 1.416909638, Training Accuracy: 60.832\n",
            "Time taken for training worker 7: 0:00:05.208480\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.386320252, Training Accuracy: 60.448\n",
            "Worker 8, [02/2]: Training Loss: 1.348824852, Training Accuracy: 61.936\n",
            "Time taken for training worker 8: 0:00:05.471879\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000738\n",
            "Local Step 36: Test Loss: 1.874088840, Test Accuracy: 52.300\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.673562510, Training Accuracy: 53.216\n",
            "Worker 1, [02/2]: Training Loss: 1.273178459, Training Accuracy: 63.344\n",
            "Time taken for training worker 1: 0:00:05.460277\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.747382664, Training Accuracy: 52.240\n",
            "Worker 2, [02/2]: Training Loss: 1.305929820, Training Accuracy: 62.400\n",
            "Time taken for training worker 2: 0:00:05.689691\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.762460128, Training Accuracy: 51.456\n",
            "Worker 3, [02/2]: Training Loss: 1.286965857, Training Accuracy: 63.456\n",
            "Time taken for training worker 3: 0:00:06.170069\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.816590410, Training Accuracy: 49.632\n",
            "Worker 4, [02/2]: Training Loss: 1.346356226, Training Accuracy: 62.384\n",
            "Time taken for training worker 4: 0:00:06.072452\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.814030860, Training Accuracy: 49.648\n",
            "Worker 5, [02/2]: Training Loss: 1.365513376, Training Accuracy: 60.880\n",
            "Time taken for training worker 5: 0:00:05.222595\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.807953918, Training Accuracy: 51.136\n",
            "Worker 6, [02/2]: Training Loss: 1.332904226, Training Accuracy: 61.776\n",
            "Time taken for training worker 6: 0:00:05.444055\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.806154680, Training Accuracy: 50.464\n",
            "Worker 7, [02/2]: Training Loss: 1.348880494, Training Accuracy: 62.032\n",
            "Time taken for training worker 7: 0:00:05.431901\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.759402335, Training Accuracy: 52.272\n",
            "Worker 8, [02/2]: Training Loss: 1.334843567, Training Accuracy: 61.776\n",
            "Time taken for training worker 8: 0:00:05.610041\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000923\n",
            "Local Step 37: Test Loss: 1.992233401, Test Accuracy: 50.190\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.673074170, Training Accuracy: 54.656\n",
            "Worker 1, [02/2]: Training Loss: 1.573792756, Training Accuracy: 55.968\n",
            "Time taken for training worker 1: 0:00:05.456074\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.561350627, Training Accuracy: 56.432\n",
            "Worker 2, [02/2]: Training Loss: 1.510401431, Training Accuracy: 57.504\n",
            "Time taken for training worker 2: 0:00:06.012210\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.493548156, Training Accuracy: 57.776\n",
            "Worker 3, [02/2]: Training Loss: 1.418537253, Training Accuracy: 59.248\n",
            "Time taken for training worker 3: 0:00:05.344105\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.523552812, Training Accuracy: 57.056\n",
            "Worker 4, [02/2]: Training Loss: 1.505127561, Training Accuracy: 58.544\n",
            "Time taken for training worker 4: 0:00:05.674149\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.507213561, Training Accuracy: 57.168\n",
            "Worker 5, [02/2]: Training Loss: 1.421902921, Training Accuracy: 59.568\n",
            "Time taken for training worker 5: 0:00:05.151983\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.468631387, Training Accuracy: 58.512\n",
            "Worker 6, [02/2]: Training Loss: 1.386801055, Training Accuracy: 60.384\n",
            "Time taken for training worker 6: 0:00:05.040718\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.402861230, Training Accuracy: 60.784\n",
            "Worker 7, [02/2]: Training Loss: 1.360691079, Training Accuracy: 61.392\n",
            "Time taken for training worker 7: 0:00:05.635156\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.388979886, Training Accuracy: 59.680\n",
            "Worker 8, [02/2]: Training Loss: 1.342774867, Training Accuracy: 61.392\n",
            "Time taken for training worker 8: 0:00:05.680561\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001185\n",
            "Local Step 38: Test Loss: 1.887571505, Test Accuracy: 52.360\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.667024859, Training Accuracy: 53.504\n",
            "Worker 1, [02/2]: Training Loss: 1.243002651, Training Accuracy: 63.792\n",
            "Time taken for training worker 1: 0:00:05.140535\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.751958249, Training Accuracy: 51.456\n",
            "Worker 2, [02/2]: Training Loss: 1.279722439, Training Accuracy: 63.360\n",
            "Time taken for training worker 2: 0:00:05.542624\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.757464522, Training Accuracy: 51.040\n",
            "Worker 3, [02/2]: Training Loss: 1.281233838, Training Accuracy: 64.000\n",
            "Time taken for training worker 3: 0:00:05.078059\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.802159595, Training Accuracy: 50.672\n",
            "Worker 4, [02/2]: Training Loss: 1.324317606, Training Accuracy: 61.984\n",
            "Time taken for training worker 4: 0:00:05.138165\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.776029528, Training Accuracy: 50.752\n",
            "Worker 5, [02/2]: Training Loss: 1.360265322, Training Accuracy: 61.792\n",
            "Time taken for training worker 5: 0:00:05.757731\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.778410852, Training Accuracy: 51.712\n",
            "Worker 6, [02/2]: Training Loss: 1.330748887, Training Accuracy: 61.744\n",
            "Time taken for training worker 6: 0:00:05.699191\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.745202815, Training Accuracy: 52.608\n",
            "Worker 7, [02/2]: Training Loss: 1.332990940, Training Accuracy: 62.208\n",
            "Time taken for training worker 7: 0:00:05.331326\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.745916622, Training Accuracy: 51.328\n",
            "Worker 8, [02/2]: Training Loss: 1.318726374, Training Accuracy: 62.912\n",
            "Time taken for training worker 8: 0:00:05.725259\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000706\n",
            "Local Step 39: Test Loss: 1.938905400, Test Accuracy: 50.130\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.585614832, Training Accuracy: 55.888\n",
            "Worker 1, [02/2]: Training Loss: 1.521833780, Training Accuracy: 57.440\n",
            "Time taken for training worker 1: 0:00:05.577139\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.540836076, Training Accuracy: 56.720\n",
            "Worker 2, [02/2]: Training Loss: 1.488538717, Training Accuracy: 58.448\n",
            "Time taken for training worker 2: 0:00:05.228285\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.474864541, Training Accuracy: 57.760\n",
            "Worker 3, [02/2]: Training Loss: 1.472253607, Training Accuracy: 58.304\n",
            "Time taken for training worker 3: 0:00:05.443840\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.460862588, Training Accuracy: 58.640\n",
            "Worker 4, [02/2]: Training Loss: 1.426736527, Training Accuracy: 59.552\n",
            "Time taken for training worker 4: 0:00:05.689132\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.481313007, Training Accuracy: 58.016\n",
            "Worker 5, [02/2]: Training Loss: 1.402359421, Training Accuracy: 59.840\n",
            "Time taken for training worker 5: 0:00:05.538815\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.403908264, Training Accuracy: 60.000\n",
            "Worker 6, [02/2]: Training Loss: 1.359360799, Training Accuracy: 61.152\n",
            "Time taken for training worker 6: 0:00:05.550818\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.387101599, Training Accuracy: 60.368\n",
            "Worker 7, [02/2]: Training Loss: 1.337403683, Training Accuracy: 62.064\n",
            "Time taken for training worker 7: 0:00:05.153950\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.367143676, Training Accuracy: 60.288\n",
            "Worker 8, [02/2]: Training Loss: 1.299465038, Training Accuracy: 62.784\n",
            "Time taken for training worker 8: 0:00:05.185372\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000753\n",
            "Local Step 40: Test Loss: 1.889048574, Test Accuracy: 52.160\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.633063288, Training Accuracy: 54.384\n",
            "Worker 1, [02/2]: Training Loss: 1.227765404, Training Accuracy: 65.376\n",
            "Time taken for training worker 1: 0:00:05.588282\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.703167232, Training Accuracy: 52.976\n",
            "Worker 2, [02/2]: Training Loss: 1.280138224, Training Accuracy: 63.200\n",
            "Time taken for training worker 2: 0:00:05.634914\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.723877552, Training Accuracy: 52.048\n",
            "Worker 3, [02/2]: Training Loss: 1.236740768, Training Accuracy: 64.528\n",
            "Time taken for training worker 3: 0:00:05.485981\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.800193694, Training Accuracy: 50.688\n",
            "Worker 4, [02/2]: Training Loss: 1.310608215, Training Accuracy: 62.592\n",
            "Time taken for training worker 4: 0:00:05.855519\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.782778674, Training Accuracy: 50.960\n",
            "Worker 5, [02/2]: Training Loss: 1.334317960, Training Accuracy: 61.664\n",
            "Time taken for training worker 5: 0:00:05.683692\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.743417748, Training Accuracy: 52.080\n",
            "Worker 6, [02/2]: Training Loss: 1.317184787, Training Accuracy: 61.840\n",
            "Time taken for training worker 6: 0:00:05.507826\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.757498193, Training Accuracy: 51.968\n",
            "Worker 7, [02/2]: Training Loss: 1.302597334, Training Accuracy: 62.480\n",
            "Time taken for training worker 7: 0:00:06.106742\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.790115749, Training Accuracy: 50.848\n",
            "Worker 8, [02/2]: Training Loss: 1.336970549, Training Accuracy: 62.000\n",
            "Time taken for training worker 8: 0:00:06.052986\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000818\n",
            "Local Step 41: Test Loss: 1.950860339, Test Accuracy: 50.000\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.631321760, Training Accuracy: 55.120\n",
            "Worker 1, [02/2]: Training Loss: 1.500336562, Training Accuracy: 57.712\n",
            "Time taken for training worker 1: 0:00:06.091265\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.550171639, Training Accuracy: 56.752\n",
            "Worker 2, [02/2]: Training Loss: 1.495924599, Training Accuracy: 57.584\n",
            "Time taken for training worker 2: 0:00:05.797619\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.479042511, Training Accuracy: 57.952\n",
            "Worker 3, [02/2]: Training Loss: 1.434171843, Training Accuracy: 59.808\n",
            "Time taken for training worker 3: 0:00:05.939957\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.470311474, Training Accuracy: 58.704\n",
            "Worker 4, [02/2]: Training Loss: 1.435396573, Training Accuracy: 59.664\n",
            "Time taken for training worker 4: 0:00:06.022375\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.468452755, Training Accuracy: 58.480\n",
            "Worker 5, [02/2]: Training Loss: 1.406613706, Training Accuracy: 60.640\n",
            "Time taken for training worker 5: 0:00:05.976833\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.410780437, Training Accuracy: 60.288\n",
            "Worker 6, [02/2]: Training Loss: 1.380078342, Training Accuracy: 60.752\n",
            "Time taken for training worker 6: 0:00:05.368028\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.429326608, Training Accuracy: 59.472\n",
            "Worker 7, [02/2]: Training Loss: 1.360966942, Training Accuracy: 61.920\n",
            "Time taken for training worker 7: 0:00:05.632163\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.344550881, Training Accuracy: 61.616\n",
            "Worker 8, [02/2]: Training Loss: 1.284110103, Training Accuracy: 62.784\n",
            "Time taken for training worker 8: 0:00:05.214561\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001159\n",
            "Local Step 42: Test Loss: 1.885596685, Test Accuracy: 52.310\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.664265627, Training Accuracy: 53.936\n",
            "Worker 1, [02/2]: Training Loss: 1.214311061, Training Accuracy: 65.792\n",
            "Time taken for training worker 1: 0:00:05.649204\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.674531911, Training Accuracy: 53.264\n",
            "Worker 2, [02/2]: Training Loss: 1.254997114, Training Accuracy: 63.520\n",
            "Time taken for training worker 2: 0:00:05.181071\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.701088020, Training Accuracy: 53.536\n",
            "Worker 3, [02/2]: Training Loss: 1.265310249, Training Accuracy: 64.016\n",
            "Time taken for training worker 3: 0:00:05.705796\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.744882934, Training Accuracy: 51.760\n",
            "Worker 4, [02/2]: Training Loss: 1.321832234, Training Accuracy: 62.576\n",
            "Time taken for training worker 4: 0:00:05.389184\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.737860011, Training Accuracy: 52.000\n",
            "Worker 5, [02/2]: Training Loss: 1.294121926, Training Accuracy: 62.640\n",
            "Time taken for training worker 5: 0:00:05.650627\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.728763876, Training Accuracy: 52.096\n",
            "Worker 6, [02/2]: Training Loss: 1.306026159, Training Accuracy: 63.840\n",
            "Time taken for training worker 6: 0:00:05.498610\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.756113336, Training Accuracy: 51.584\n",
            "Worker 7, [02/2]: Training Loss: 1.320376959, Training Accuracy: 62.176\n",
            "Time taken for training worker 7: 0:00:05.694448\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.753435135, Training Accuracy: 51.120\n",
            "Worker 8, [02/2]: Training Loss: 1.308726359, Training Accuracy: 62.512\n",
            "Time taken for training worker 8: 0:00:05.505681\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000806\n",
            "Local Step 43: Test Loss: 1.967792407, Test Accuracy: 50.410\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.591827771, Training Accuracy: 56.256\n",
            "Worker 1, [02/2]: Training Loss: 1.524584787, Training Accuracy: 57.872\n",
            "Time taken for training worker 1: 0:00:05.219560\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.559518320, Training Accuracy: 56.112\n",
            "Worker 2, [02/2]: Training Loss: 1.484688602, Training Accuracy: 58.000\n",
            "Time taken for training worker 2: 0:00:05.233926\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.490819412, Training Accuracy: 57.952\n",
            "Worker 3, [02/2]: Training Loss: 1.405704420, Training Accuracy: 60.448\n",
            "Time taken for training worker 3: 0:00:05.700475\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.442546428, Training Accuracy: 58.944\n",
            "Worker 4, [02/2]: Training Loss: 1.426703466, Training Accuracy: 59.856\n",
            "Time taken for training worker 4: 0:00:05.336535\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.488926777, Training Accuracy: 57.728\n",
            "Worker 5, [02/2]: Training Loss: 1.441466128, Training Accuracy: 58.432\n",
            "Time taken for training worker 5: 0:00:05.570914\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.419654672, Training Accuracy: 59.760\n",
            "Worker 6, [02/2]: Training Loss: 1.375458913, Training Accuracy: 61.472\n",
            "Time taken for training worker 6: 0:00:05.105303\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.383851130, Training Accuracy: 60.928\n",
            "Worker 7, [02/2]: Training Loss: 1.351385176, Training Accuracy: 62.272\n",
            "Time taken for training worker 7: 0:00:05.145060\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.330129127, Training Accuracy: 61.936\n",
            "Worker 8, [02/2]: Training Loss: 1.290458050, Training Accuracy: 63.232\n",
            "Time taken for training worker 8: 0:00:05.178342\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000809\n",
            "Local Step 44: Test Loss: 1.846848320, Test Accuracy: 52.730\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.639098278, Training Accuracy: 54.448\n",
            "Worker 1, [02/2]: Training Loss: 1.220581789, Training Accuracy: 65.840\n",
            "Time taken for training worker 1: 0:00:05.096824\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.657098674, Training Accuracy: 52.848\n",
            "Worker 2, [02/2]: Training Loss: 1.234592505, Training Accuracy: 64.928\n",
            "Time taken for training worker 2: 0:00:05.910093\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.671024573, Training Accuracy: 53.504\n",
            "Worker 3, [02/2]: Training Loss: 1.255595875, Training Accuracy: 64.256\n",
            "Time taken for training worker 3: 0:00:05.487264\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.760776280, Training Accuracy: 51.840\n",
            "Worker 4, [02/2]: Training Loss: 1.299059266, Training Accuracy: 63.328\n",
            "Time taken for training worker 4: 0:00:05.228697\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.727436605, Training Accuracy: 51.520\n",
            "Worker 5, [02/2]: Training Loss: 1.265465599, Training Accuracy: 63.696\n",
            "Time taken for training worker 5: 0:00:05.218039\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.768301212, Training Accuracy: 52.064\n",
            "Worker 6, [02/2]: Training Loss: 1.279520807, Training Accuracy: 63.248\n",
            "Time taken for training worker 6: 0:00:05.150284\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.760409624, Training Accuracy: 52.032\n",
            "Worker 7, [02/2]: Training Loss: 1.292945381, Training Accuracy: 63.680\n",
            "Time taken for training worker 7: 0:00:05.230637\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.737697398, Training Accuracy: 51.888\n",
            "Worker 8, [02/2]: Training Loss: 1.294088393, Training Accuracy: 63.328\n",
            "Time taken for training worker 8: 0:00:05.617406\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000952\n",
            "Local Step 45: Test Loss: 1.951951108, Test Accuracy: 50.750\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.631053651, Training Accuracy: 54.992\n",
            "Worker 1, [02/2]: Training Loss: 1.513193835, Training Accuracy: 57.696\n",
            "Time taken for training worker 1: 0:00:05.652201\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.519206433, Training Accuracy: 57.408\n",
            "Worker 2, [02/2]: Training Loss: 1.453789091, Training Accuracy: 59.280\n",
            "Time taken for training worker 2: 0:00:06.099090\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.499208464, Training Accuracy: 57.360\n",
            "Worker 3, [02/2]: Training Loss: 1.401472274, Training Accuracy: 60.736\n",
            "Time taken for training worker 3: 0:00:05.907326\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.433649597, Training Accuracy: 59.744\n",
            "Worker 4, [02/2]: Training Loss: 1.380752416, Training Accuracy: 60.864\n",
            "Time taken for training worker 4: 0:00:05.933754\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.412986858, Training Accuracy: 59.952\n",
            "Worker 5, [02/2]: Training Loss: 1.371455355, Training Accuracy: 59.904\n",
            "Time taken for training worker 5: 0:00:05.417928\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.410603112, Training Accuracy: 60.336\n",
            "Worker 6, [02/2]: Training Loss: 1.360017539, Training Accuracy: 61.296\n",
            "Time taken for training worker 6: 0:00:05.132635\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.370826675, Training Accuracy: 61.472\n",
            "Worker 7, [02/2]: Training Loss: 1.318358383, Training Accuracy: 62.224\n",
            "Time taken for training worker 7: 0:00:05.584786\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.280381889, Training Accuracy: 62.976\n",
            "Worker 8, [02/2]: Training Loss: 1.250625370, Training Accuracy: 64.176\n",
            "Time taken for training worker 8: 0:00:05.462860\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000712\n",
            "Local Step 46: Test Loss: 1.896392409, Test Accuracy: 51.880\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.608365965, Training Accuracy: 55.408\n",
            "Worker 1, [02/2]: Training Loss: 1.173957431, Training Accuracy: 65.280\n",
            "Time taken for training worker 1: 0:00:05.334124\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.706764908, Training Accuracy: 52.320\n",
            "Worker 2, [02/2]: Training Loss: 1.228866329, Training Accuracy: 64.016\n",
            "Time taken for training worker 2: 0:00:05.837155\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.673425533, Training Accuracy: 53.712\n",
            "Worker 3, [02/2]: Training Loss: 1.238006434, Training Accuracy: 64.576\n",
            "Time taken for training worker 3: 0:00:05.847048\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.720886706, Training Accuracy: 51.808\n",
            "Worker 4, [02/2]: Training Loss: 1.279337987, Training Accuracy: 63.952\n",
            "Time taken for training worker 4: 0:00:05.488295\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.758153289, Training Accuracy: 51.040\n",
            "Worker 5, [02/2]: Training Loss: 1.288809936, Training Accuracy: 63.456\n",
            "Time taken for training worker 5: 0:00:05.816077\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.739226687, Training Accuracy: 52.048\n",
            "Worker 6, [02/2]: Training Loss: 1.276338226, Training Accuracy: 63.344\n",
            "Time taken for training worker 6: 0:00:05.757699\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.743498092, Training Accuracy: 51.616\n",
            "Worker 7, [02/2]: Training Loss: 1.277414931, Training Accuracy: 64.544\n",
            "Time taken for training worker 7: 0:00:05.134768\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.701556618, Training Accuracy: 52.272\n",
            "Worker 8, [02/2]: Training Loss: 1.247865419, Training Accuracy: 64.560\n",
            "Time taken for training worker 8: 0:00:05.490327\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000757\n",
            "Local Step 47: Test Loss: 1.961779274, Test Accuracy: 50.890\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.551043530, Training Accuracy: 57.280\n",
            "Worker 1, [02/2]: Training Loss: 1.517913118, Training Accuracy: 57.408\n",
            "Time taken for training worker 1: 0:00:05.446589\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.529774950, Training Accuracy: 57.232\n",
            "Worker 2, [02/2]: Training Loss: 1.439469864, Training Accuracy: 59.040\n",
            "Time taken for training worker 2: 0:00:05.137252\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.450858340, Training Accuracy: 58.928\n",
            "Worker 3, [02/2]: Training Loss: 1.406540402, Training Accuracy: 59.888\n",
            "Time taken for training worker 3: 0:00:05.522887\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.425734181, Training Accuracy: 59.296\n",
            "Worker 4, [02/2]: Training Loss: 1.407964286, Training Accuracy: 59.696\n",
            "Time taken for training worker 4: 0:00:05.097609\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.418672076, Training Accuracy: 58.960\n",
            "Worker 5, [02/2]: Training Loss: 1.377024562, Training Accuracy: 60.688\n",
            "Time taken for training worker 5: 0:00:05.104939\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.352908946, Training Accuracy: 61.968\n",
            "Worker 6, [02/2]: Training Loss: 1.313273390, Training Accuracy: 62.720\n",
            "Time taken for training worker 6: 0:00:05.536618\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.334865077, Training Accuracy: 62.304\n",
            "Worker 7, [02/2]: Training Loss: 1.293341241, Training Accuracy: 62.848\n",
            "Time taken for training worker 7: 0:00:06.159116\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.325344626, Training Accuracy: 62.000\n",
            "Worker 8, [02/2]: Training Loss: 1.233003478, Training Accuracy: 64.192\n",
            "Time taken for training worker 8: 0:00:06.033071\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000859\n",
            "Local Step 48: Test Loss: 1.888962174, Test Accuracy: 52.400\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.588666813, Training Accuracy: 55.120\n",
            "Worker 1, [02/2]: Training Loss: 1.168897715, Training Accuracy: 66.608\n",
            "Time taken for training worker 1: 0:00:05.101365\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.652432466, Training Accuracy: 54.192\n",
            "Worker 2, [02/2]: Training Loss: 1.199558006, Training Accuracy: 65.072\n",
            "Time taken for training worker 2: 0:00:05.716347\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.688604822, Training Accuracy: 52.944\n",
            "Worker 3, [02/2]: Training Loss: 1.210821185, Training Accuracy: 65.408\n",
            "Time taken for training worker 3: 0:00:05.768086\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.706357668, Training Accuracy: 52.880\n",
            "Worker 4, [02/2]: Training Loss: 1.265019217, Training Accuracy: 64.224\n",
            "Time taken for training worker 4: 0:00:05.643131\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.710049416, Training Accuracy: 52.656\n",
            "Worker 5, [02/2]: Training Loss: 1.255242100, Training Accuracy: 64.576\n",
            "Time taken for training worker 5: 0:00:05.465360\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.718749167, Training Accuracy: 52.640\n",
            "Worker 6, [02/2]: Training Loss: 1.262848500, Training Accuracy: 63.488\n",
            "Time taken for training worker 6: 0:00:05.598666\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.715673791, Training Accuracy: 52.240\n",
            "Worker 7, [02/2]: Training Loss: 1.286020314, Training Accuracy: 63.648\n",
            "Time taken for training worker 7: 0:00:05.645969\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.744907125, Training Accuracy: 50.832\n",
            "Worker 8, [02/2]: Training Loss: 1.250214985, Training Accuracy: 63.936\n",
            "Time taken for training worker 8: 0:00:05.803469\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000911\n",
            "Local Step 49: Test Loss: 1.991228343, Test Accuracy: 50.410\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.599366154, Training Accuracy: 55.680\n",
            "Worker 1, [02/2]: Training Loss: 1.482159545, Training Accuracy: 58.016\n",
            "Time taken for training worker 1: 0:00:05.328468\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.503473160, Training Accuracy: 57.024\n",
            "Worker 2, [02/2]: Training Loss: 1.415854829, Training Accuracy: 59.952\n",
            "Time taken for training worker 2: 0:00:05.710103\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.480001763, Training Accuracy: 58.768\n",
            "Worker 3, [02/2]: Training Loss: 1.411703571, Training Accuracy: 59.600\n",
            "Time taken for training worker 3: 0:00:05.385503\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.420000521, Training Accuracy: 59.696\n",
            "Worker 4, [02/2]: Training Loss: 1.386042650, Training Accuracy: 60.832\n",
            "Time taken for training worker 4: 0:00:05.215977\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.443186618, Training Accuracy: 58.928\n",
            "Worker 5, [02/2]: Training Loss: 1.381404848, Training Accuracy: 60.800\n",
            "Time taken for training worker 5: 0:00:05.432237\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.359214379, Training Accuracy: 60.592\n",
            "Worker 6, [02/2]: Training Loss: 1.328698313, Training Accuracy: 62.240\n",
            "Time taken for training worker 6: 0:00:05.595788\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.286518973, Training Accuracy: 63.296\n",
            "Worker 7, [02/2]: Training Loss: 1.296230025, Training Accuracy: 63.056\n",
            "Time taken for training worker 7: 0:00:05.522129\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.266677343, Training Accuracy: 63.232\n",
            "Worker 8, [02/2]: Training Loss: 1.204538901, Training Accuracy: 64.640\n",
            "Time taken for training worker 8: 0:00:05.192834\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000744\n",
            "Local Step 50: Test Loss: 1.853654801, Test Accuracy: 52.220\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.613537753, Training Accuracy: 55.008\n",
            "Worker 1, [02/2]: Training Loss: 1.165132286, Training Accuracy: 66.880\n",
            "Time taken for training worker 1: 0:00:05.730839\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.686065201, Training Accuracy: 53.232\n",
            "Worker 2, [02/2]: Training Loss: 1.207908529, Training Accuracy: 64.912\n",
            "Time taken for training worker 2: 0:00:05.452794\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.635017417, Training Accuracy: 53.632\n",
            "Worker 3, [02/2]: Training Loss: 1.208118268, Training Accuracy: 65.152\n",
            "Time taken for training worker 3: 0:00:05.727761\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.682376023, Training Accuracy: 52.896\n",
            "Worker 4, [02/2]: Training Loss: 1.262274072, Training Accuracy: 64.272\n",
            "Time taken for training worker 4: 0:00:05.685493\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.715991284, Training Accuracy: 52.608\n",
            "Worker 5, [02/2]: Training Loss: 1.276131969, Training Accuracy: 63.472\n",
            "Time taken for training worker 5: 0:00:05.999875\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.740042026, Training Accuracy: 52.096\n",
            "Worker 6, [02/2]: Training Loss: 1.277893464, Training Accuracy: 63.376\n",
            "Time taken for training worker 6: 0:00:05.295588\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.737405163, Training Accuracy: 52.224\n",
            "Worker 7, [02/2]: Training Loss: 1.288711593, Training Accuracy: 63.120\n",
            "Time taken for training worker 7: 0:00:05.245414\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.707151603, Training Accuracy: 52.384\n",
            "Worker 8, [02/2]: Training Loss: 1.272490421, Training Accuracy: 63.376\n",
            "Time taken for training worker 8: 0:00:05.165754\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000791\n",
            "Local Step 51: Test Loss: 1.972968816, Test Accuracy: 50.410\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.598870842, Training Accuracy: 55.120\n",
            "Worker 1, [02/2]: Training Loss: 1.479298837, Training Accuracy: 58.256\n",
            "Time taken for training worker 1: 0:00:05.453466\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.509426235, Training Accuracy: 56.624\n",
            "Worker 2, [02/2]: Training Loss: 1.429762569, Training Accuracy: 59.392\n",
            "Time taken for training worker 2: 0:00:05.320081\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.442699389, Training Accuracy: 59.072\n",
            "Worker 3, [02/2]: Training Loss: 1.369815006, Training Accuracy: 61.104\n",
            "Time taken for training worker 3: 0:00:05.852404\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.393640911, Training Accuracy: 60.912\n",
            "Worker 4, [02/2]: Training Loss: 1.354561404, Training Accuracy: 61.296\n",
            "Time taken for training worker 4: 0:00:05.612365\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.404098461, Training Accuracy: 59.536\n",
            "Worker 5, [02/2]: Training Loss: 1.339704226, Training Accuracy: 62.288\n",
            "Time taken for training worker 5: 0:00:05.214662\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.349483799, Training Accuracy: 61.632\n",
            "Worker 6, [02/2]: Training Loss: 1.293482381, Training Accuracy: 62.688\n",
            "Time taken for training worker 6: 0:00:05.180240\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.367579914, Training Accuracy: 61.408\n",
            "Worker 7, [02/2]: Training Loss: 1.323972223, Training Accuracy: 61.744\n",
            "Time taken for training worker 7: 0:00:05.311743\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.297698959, Training Accuracy: 62.176\n",
            "Worker 8, [02/2]: Training Loss: 1.236547080, Training Accuracy: 64.320\n",
            "Time taken for training worker 8: 0:00:05.612343\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001281\n",
            "Local Step 52: Test Loss: 1.865506162, Test Accuracy: 52.920\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.621147265, Training Accuracy: 54.816\n",
            "Worker 1, [02/2]: Training Loss: 1.148351627, Training Accuracy: 66.720\n",
            "Time taken for training worker 1: 0:00:05.865360\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.644347916, Training Accuracy: 53.856\n",
            "Worker 2, [02/2]: Training Loss: 1.212539418, Training Accuracy: 65.088\n",
            "Time taken for training worker 2: 0:00:06.118605\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.644707253, Training Accuracy: 53.808\n",
            "Worker 3, [02/2]: Training Loss: 1.186937995, Training Accuracy: 66.272\n",
            "Time taken for training worker 3: 0:00:05.400517\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.704821733, Training Accuracy: 53.488\n",
            "Worker 4, [02/2]: Training Loss: 1.240987140, Training Accuracy: 64.864\n",
            "Time taken for training worker 4: 0:00:05.232056\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.723063507, Training Accuracy: 52.016\n",
            "Worker 5, [02/2]: Training Loss: 1.250667614, Training Accuracy: 64.672\n",
            "Time taken for training worker 5: 0:00:05.188050\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.712601298, Training Accuracy: 53.328\n",
            "Worker 6, [02/2]: Training Loss: 1.270516519, Training Accuracy: 63.856\n",
            "Time taken for training worker 6: 0:00:05.838740\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.714945184, Training Accuracy: 52.736\n",
            "Worker 7, [02/2]: Training Loss: 1.218254052, Training Accuracy: 64.864\n",
            "Time taken for training worker 7: 0:00:05.066385\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.714294235, Training Accuracy: 52.656\n",
            "Worker 8, [02/2]: Training Loss: 1.243698309, Training Accuracy: 64.800\n",
            "Time taken for training worker 8: 0:00:05.872164\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000758\n",
            "Local Step 53: Test Loss: 1.946510477, Test Accuracy: 50.610\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.578843231, Training Accuracy: 56.592\n",
            "Worker 1, [02/2]: Training Loss: 1.479124168, Training Accuracy: 58.272\n",
            "Time taken for training worker 1: 0:00:05.201607\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.491212549, Training Accuracy: 58.064\n",
            "Worker 2, [02/2]: Training Loss: 1.417946398, Training Accuracy: 59.712\n",
            "Time taken for training worker 2: 0:00:05.821826\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.435944558, Training Accuracy: 58.928\n",
            "Worker 3, [02/2]: Training Loss: 1.344441688, Training Accuracy: 62.176\n",
            "Time taken for training worker 3: 0:00:05.236958\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.371508426, Training Accuracy: 60.640\n",
            "Worker 4, [02/2]: Training Loss: 1.354466466, Training Accuracy: 61.376\n",
            "Time taken for training worker 4: 0:00:05.275747\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.379580495, Training Accuracy: 60.880\n",
            "Worker 5, [02/2]: Training Loss: 1.336504658, Training Accuracy: 61.440\n",
            "Time taken for training worker 5: 0:00:05.964142\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.355138731, Training Accuracy: 61.280\n",
            "Worker 6, [02/2]: Training Loss: 1.299106932, Training Accuracy: 62.224\n",
            "Time taken for training worker 6: 0:00:05.646620\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.306879265, Training Accuracy: 61.984\n",
            "Worker 7, [02/2]: Training Loss: 1.294513305, Training Accuracy: 63.600\n",
            "Time taken for training worker 7: 0:00:05.199941\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.299312993, Training Accuracy: 62.624\n",
            "Worker 8, [02/2]: Training Loss: 1.240393963, Training Accuracy: 63.760\n",
            "Time taken for training worker 8: 0:00:05.824100\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000893\n",
            "Local Step 54: Test Loss: 1.886777212, Test Accuracy: 52.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.581821043, Training Accuracy: 55.648\n",
            "Worker 1, [02/2]: Training Loss: 1.162842965, Training Accuracy: 66.736\n",
            "Time taken for training worker 1: 0:00:05.756546\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.641977036, Training Accuracy: 54.400\n",
            "Worker 2, [02/2]: Training Loss: 1.186524462, Training Accuracy: 66.000\n",
            "Time taken for training worker 2: 0:00:05.086830\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.616247255, Training Accuracy: 54.944\n",
            "Worker 3, [02/2]: Training Loss: 1.199007140, Training Accuracy: 65.760\n",
            "Time taken for training worker 3: 0:00:05.375520\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.685301258, Training Accuracy: 52.496\n",
            "Worker 4, [02/2]: Training Loss: 1.244196658, Training Accuracy: 64.544\n",
            "Time taken for training worker 4: 0:00:05.199381\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.702045517, Training Accuracy: 52.960\n",
            "Worker 5, [02/2]: Training Loss: 1.239744019, Training Accuracy: 65.040\n",
            "Time taken for training worker 5: 0:00:05.810058\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.733806578, Training Accuracy: 52.912\n",
            "Worker 6, [02/2]: Training Loss: 1.222183524, Training Accuracy: 65.200\n",
            "Time taken for training worker 6: 0:00:05.483621\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.691630938, Training Accuracy: 53.552\n",
            "Worker 7, [02/2]: Training Loss: 1.235135775, Training Accuracy: 64.896\n",
            "Time taken for training worker 7: 0:00:05.860721\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.727905138, Training Accuracy: 51.776\n",
            "Worker 8, [02/2]: Training Loss: 1.249505400, Training Accuracy: 64.624\n",
            "Time taken for training worker 8: 0:00:05.798407\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000830\n",
            "Local Step 55: Test Loss: 1.960868220, Test Accuracy: 51.380\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.566552240, Training Accuracy: 56.400\n",
            "Worker 1, [02/2]: Training Loss: 1.477759580, Training Accuracy: 58.384\n",
            "Time taken for training worker 1: 0:00:05.263044\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.534339349, Training Accuracy: 57.216\n",
            "Worker 2, [02/2]: Training Loss: 1.408373287, Training Accuracy: 59.952\n",
            "Time taken for training worker 2: 0:00:05.262069\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.398185864, Training Accuracy: 60.496\n",
            "Worker 3, [02/2]: Training Loss: 1.362182118, Training Accuracy: 60.960\n",
            "Time taken for training worker 3: 0:00:05.535466\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.393614903, Training Accuracy: 60.256\n",
            "Worker 4, [02/2]: Training Loss: 1.358930824, Training Accuracy: 61.568\n",
            "Time taken for training worker 4: 0:00:05.245541\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.363808190, Training Accuracy: 60.704\n",
            "Worker 5, [02/2]: Training Loss: 1.320072291, Training Accuracy: 62.512\n",
            "Time taken for training worker 5: 0:00:05.615619\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.317200968, Training Accuracy: 62.064\n",
            "Worker 6, [02/2]: Training Loss: 1.284385867, Training Accuracy: 63.600\n",
            "Time taken for training worker 6: 0:00:05.511258\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.299073405, Training Accuracy: 62.976\n",
            "Worker 7, [02/2]: Training Loss: 1.275060605, Training Accuracy: 63.328\n",
            "Time taken for training worker 7: 0:00:05.809107\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.283364587, Training Accuracy: 63.200\n",
            "Worker 8, [02/2]: Training Loss: 1.225233933, Training Accuracy: 63.984\n",
            "Time taken for training worker 8: 0:00:05.494582\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000825\n",
            "Local Step 56: Test Loss: 1.904630838, Test Accuracy: 52.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.566457910, Training Accuracy: 56.160\n",
            "Worker 1, [02/2]: Training Loss: 1.129087109, Training Accuracy: 67.488\n",
            "Time taken for training worker 1: 0:00:05.932007\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.628127195, Training Accuracy: 54.128\n",
            "Worker 2, [02/2]: Training Loss: 1.160074621, Training Accuracy: 66.496\n",
            "Time taken for training worker 2: 0:00:05.484703\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.605315806, Training Accuracy: 55.152\n",
            "Worker 3, [02/2]: Training Loss: 1.157024329, Training Accuracy: 67.216\n",
            "Time taken for training worker 3: 0:00:05.412965\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.684725150, Training Accuracy: 53.248\n",
            "Worker 4, [02/2]: Training Loss: 1.239961513, Training Accuracy: 64.768\n",
            "Time taken for training worker 4: 0:00:05.851019\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.692859201, Training Accuracy: 53.648\n",
            "Worker 5, [02/2]: Training Loss: 1.220866461, Training Accuracy: 64.784\n",
            "Time taken for training worker 5: 0:00:05.671979\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.666411394, Training Accuracy: 53.744\n",
            "Worker 6, [02/2]: Training Loss: 1.230096243, Training Accuracy: 64.864\n",
            "Time taken for training worker 6: 0:00:05.864246\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.700487511, Training Accuracy: 52.624\n",
            "Worker 7, [02/2]: Training Loss: 1.227306000, Training Accuracy: 65.488\n",
            "Time taken for training worker 7: 0:00:05.957243\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.657987276, Training Accuracy: 53.680\n",
            "Worker 8, [02/2]: Training Loss: 1.231749619, Training Accuracy: 64.128\n",
            "Time taken for training worker 8: 0:00:05.871699\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000893\n",
            "Local Step 57: Test Loss: 1.911025468, Test Accuracy: 52.050\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.507677739, Training Accuracy: 57.520\n",
            "Worker 1, [02/2]: Training Loss: 1.426176778, Training Accuracy: 60.160\n",
            "Time taken for training worker 1: 0:00:05.514569\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.461940213, Training Accuracy: 58.224\n",
            "Worker 2, [02/2]: Training Loss: 1.396641122, Training Accuracy: 60.160\n",
            "Time taken for training worker 2: 0:00:05.979179\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.454157151, Training Accuracy: 59.296\n",
            "Worker 3, [02/2]: Training Loss: 1.380769093, Training Accuracy: 60.656\n",
            "Time taken for training worker 3: 0:00:05.461614\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.395218557, Training Accuracy: 60.960\n",
            "Worker 4, [02/2]: Training Loss: 1.338442003, Training Accuracy: 61.744\n",
            "Time taken for training worker 4: 0:00:05.441902\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.409596388, Training Accuracy: 59.744\n",
            "Worker 5, [02/2]: Training Loss: 1.339098306, Training Accuracy: 61.440\n",
            "Time taken for training worker 5: 0:00:05.355255\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.340206812, Training Accuracy: 61.712\n",
            "Worker 6, [02/2]: Training Loss: 1.275865744, Training Accuracy: 63.904\n",
            "Time taken for training worker 6: 0:00:05.459768\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.278010235, Training Accuracy: 63.360\n",
            "Worker 7, [02/2]: Training Loss: 1.257271415, Training Accuracy: 63.856\n",
            "Time taken for training worker 7: 0:00:05.235861\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.245818879, Training Accuracy: 64.384\n",
            "Worker 8, [02/2]: Training Loss: 1.176708189, Training Accuracy: 65.408\n",
            "Time taken for training worker 8: 0:00:05.212972\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001182\n",
            "Local Step 58: Test Loss: 1.927431927, Test Accuracy: 52.780\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.587397519, Training Accuracy: 56.064\n",
            "Worker 1, [02/2]: Training Loss: 1.129459469, Training Accuracy: 67.536\n",
            "Time taken for training worker 1: 0:00:05.750476\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.623121386, Training Accuracy: 54.256\n",
            "Worker 2, [02/2]: Training Loss: 1.153520050, Training Accuracy: 66.112\n",
            "Time taken for training worker 2: 0:00:05.128033\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.637722270, Training Accuracy: 54.144\n",
            "Worker 3, [02/2]: Training Loss: 1.189963246, Training Accuracy: 65.696\n",
            "Time taken for training worker 3: 0:00:05.476613\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.690613895, Training Accuracy: 53.168\n",
            "Worker 4, [02/2]: Training Loss: 1.228461253, Training Accuracy: 65.216\n",
            "Time taken for training worker 4: 0:00:05.713658\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.681569776, Training Accuracy: 52.576\n",
            "Worker 5, [02/2]: Training Loss: 1.221220226, Training Accuracy: 64.704\n",
            "Time taken for training worker 5: 0:00:05.177233\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.672892035, Training Accuracy: 53.552\n",
            "Worker 6, [02/2]: Training Loss: 1.210810574, Training Accuracy: 64.752\n",
            "Time taken for training worker 6: 0:00:05.560477\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.717138057, Training Accuracy: 53.248\n",
            "Worker 7, [02/2]: Training Loss: 1.225633549, Training Accuracy: 65.136\n",
            "Time taken for training worker 7: 0:00:05.551715\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.698815618, Training Accuracy: 52.384\n",
            "Worker 8, [02/2]: Training Loss: 1.224373501, Training Accuracy: 64.544\n",
            "Time taken for training worker 8: 0:00:05.757356\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001047\n",
            "Local Step 59: Test Loss: 2.000767060, Test Accuracy: 50.150\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.562846852, Training Accuracy: 56.848\n",
            "Worker 1, [02/2]: Training Loss: 1.477862923, Training Accuracy: 58.512\n",
            "Time taken for training worker 1: 0:00:05.514847\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.479664185, Training Accuracy: 57.616\n",
            "Worker 2, [02/2]: Training Loss: 1.398529628, Training Accuracy: 59.824\n",
            "Time taken for training worker 2: 0:00:06.013194\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.401246211, Training Accuracy: 59.728\n",
            "Worker 3, [02/2]: Training Loss: 1.343144798, Training Accuracy: 61.552\n",
            "Time taken for training worker 3: 0:00:05.799171\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.427058882, Training Accuracy: 59.696\n",
            "Worker 4, [02/2]: Training Loss: 1.335328932, Training Accuracy: 62.176\n",
            "Time taken for training worker 4: 0:00:05.786775\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.418140767, Training Accuracy: 59.760\n",
            "Worker 5, [02/2]: Training Loss: 1.331057503, Training Accuracy: 61.248\n",
            "Time taken for training worker 5: 0:00:05.774741\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.316927655, Training Accuracy: 61.552\n",
            "Worker 6, [02/2]: Training Loss: 1.276019284, Training Accuracy: 63.776\n",
            "Time taken for training worker 6: 0:00:05.907116\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.263021636, Training Accuracy: 63.456\n",
            "Worker 7, [02/2]: Training Loss: 1.215534334, Training Accuracy: 64.848\n",
            "Time taken for training worker 7: 0:00:05.795203\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.271381201, Training Accuracy: 63.584\n",
            "Worker 8, [02/2]: Training Loss: 1.200653867, Training Accuracy: 64.992\n",
            "Time taken for training worker 8: 0:00:05.330696\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000796\n",
            "Local Step 60: Test Loss: 1.885889280, Test Accuracy: 52.270\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.551353552, Training Accuracy: 56.720\n",
            "Worker 1, [02/2]: Training Loss: 1.118288729, Training Accuracy: 67.776\n",
            "Time taken for training worker 1: 0:00:05.848431\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.616226391, Training Accuracy: 55.232\n",
            "Worker 2, [02/2]: Training Loss: 1.134553123, Training Accuracy: 66.800\n",
            "Time taken for training worker 2: 0:00:05.463518\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.608593806, Training Accuracy: 55.248\n",
            "Worker 3, [02/2]: Training Loss: 1.158063721, Training Accuracy: 66.064\n",
            "Time taken for training worker 3: 0:00:05.217746\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.676214701, Training Accuracy: 54.112\n",
            "Worker 4, [02/2]: Training Loss: 1.220388964, Training Accuracy: 64.976\n",
            "Time taken for training worker 4: 0:00:06.080004\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.653079292, Training Accuracy: 54.144\n",
            "Worker 5, [02/2]: Training Loss: 1.232066668, Training Accuracy: 64.832\n",
            "Time taken for training worker 5: 0:00:05.629723\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.673751214, Training Accuracy: 53.840\n",
            "Worker 6, [02/2]: Training Loss: 1.224977036, Training Accuracy: 65.072\n",
            "Time taken for training worker 6: 0:00:05.811166\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.696460482, Training Accuracy: 52.896\n",
            "Worker 7, [02/2]: Training Loss: 1.212393612, Training Accuracy: 64.640\n",
            "Time taken for training worker 7: 0:00:05.438578\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.710348915, Training Accuracy: 51.856\n",
            "Worker 8, [02/2]: Training Loss: 1.213314243, Training Accuracy: 64.624\n",
            "Time taken for training worker 8: 0:00:06.049347\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000935\n",
            "Local Step 61: Test Loss: 1.965653562, Test Accuracy: 50.890\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.529400605, Training Accuracy: 56.896\n",
            "Worker 1, [02/2]: Training Loss: 1.448231736, Training Accuracy: 59.184\n",
            "Time taken for training worker 1: 0:00:05.503481\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.445178259, Training Accuracy: 59.504\n",
            "Worker 2, [02/2]: Training Loss: 1.395336337, Training Accuracy: 60.320\n",
            "Time taken for training worker 2: 0:00:05.057927\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.357822394, Training Accuracy: 60.416\n",
            "Worker 3, [02/2]: Training Loss: 1.333817972, Training Accuracy: 61.296\n",
            "Time taken for training worker 3: 0:00:05.462255\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.436788470, Training Accuracy: 59.456\n",
            "Worker 4, [02/2]: Training Loss: 1.328710805, Training Accuracy: 62.528\n",
            "Time taken for training worker 4: 0:00:05.234833\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.366692408, Training Accuracy: 60.784\n",
            "Worker 5, [02/2]: Training Loss: 1.331755073, Training Accuracy: 61.568\n",
            "Time taken for training worker 5: 0:00:05.851876\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.289510448, Training Accuracy: 63.296\n",
            "Worker 6, [02/2]: Training Loss: 1.225753438, Training Accuracy: 65.120\n",
            "Time taken for training worker 6: 0:00:05.478852\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.357478749, Training Accuracy: 61.104\n",
            "Worker 7, [02/2]: Training Loss: 1.280452905, Training Accuracy: 63.248\n",
            "Time taken for training worker 7: 0:00:05.873121\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.266291793, Training Accuracy: 63.232\n",
            "Worker 8, [02/2]: Training Loss: 1.183666995, Training Accuracy: 65.360\n",
            "Time taken for training worker 8: 0:00:05.142245\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000723\n",
            "Local Step 62: Test Loss: 1.931193800, Test Accuracy: 52.550\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.589692430, Training Accuracy: 55.296\n",
            "Worker 1, [02/2]: Training Loss: 1.122358904, Training Accuracy: 66.880\n",
            "Time taken for training worker 1: 0:00:05.217379\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.606521251, Training Accuracy: 55.648\n",
            "Worker 2, [02/2]: Training Loss: 1.133848825, Training Accuracy: 66.960\n",
            "Time taken for training worker 2: 0:00:05.269088\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.619378117, Training Accuracy: 54.624\n",
            "Worker 3, [02/2]: Training Loss: 1.161869901, Training Accuracy: 66.208\n",
            "Time taken for training worker 3: 0:00:05.352218\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.683017481, Training Accuracy: 53.680\n",
            "Worker 4, [02/2]: Training Loss: 1.186331386, Training Accuracy: 66.400\n",
            "Time taken for training worker 4: 0:00:05.273063\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.660097836, Training Accuracy: 53.648\n",
            "Worker 5, [02/2]: Training Loss: 1.205066216, Training Accuracy: 65.424\n",
            "Time taken for training worker 5: 0:00:05.263160\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.697299595, Training Accuracy: 53.200\n",
            "Worker 6, [02/2]: Training Loss: 1.197343205, Training Accuracy: 65.680\n",
            "Time taken for training worker 6: 0:00:05.504884\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.708072439, Training Accuracy: 52.416\n",
            "Worker 7, [02/2]: Training Loss: 1.228070332, Training Accuracy: 64.768\n",
            "Time taken for training worker 7: 0:00:05.326655\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.702524394, Training Accuracy: 52.816\n",
            "Worker 8, [02/2]: Training Loss: 1.206824410, Training Accuracy: 65.584\n",
            "Time taken for training worker 8: 0:00:05.185137\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000798\n",
            "Local Step 63: Test Loss: 1.988045680, Test Accuracy: 51.210\n",
            "**************************************************\n",
            "Worker 1, [01/2]: Training Loss: 1.540477923, Training Accuracy: 57.168\n",
            "Worker 1, [02/2]: Training Loss: 1.456143307, Training Accuracy: 58.992\n",
            "Time taken for training worker 1: 0:00:05.934858\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/2]: Training Loss: 1.433014951, Training Accuracy: 59.056\n",
            "Worker 2, [02/2]: Training Loss: 1.374964457, Training Accuracy: 60.512\n",
            "Time taken for training worker 2: 0:00:05.518955\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/2]: Training Loss: 1.337373008, Training Accuracy: 62.320\n",
            "Worker 3, [02/2]: Training Loss: 1.316796996, Training Accuracy: 61.952\n",
            "Time taken for training worker 3: 0:00:05.539179\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/2]: Training Loss: 1.384950476, Training Accuracy: 61.424\n",
            "Worker 4, [02/2]: Training Loss: 1.322460630, Training Accuracy: 62.080\n",
            "Time taken for training worker 4: 0:00:05.505311\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/2]: Training Loss: 1.327957720, Training Accuracy: 61.472\n",
            "Worker 5, [02/2]: Training Loss: 1.286974284, Training Accuracy: 63.488\n",
            "Time taken for training worker 5: 0:00:05.181748\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/2]: Training Loss: 1.319287081, Training Accuracy: 61.776\n",
            "Worker 6, [02/2]: Training Loss: 1.246869249, Training Accuracy: 64.176\n",
            "Time taken for training worker 6: 0:00:05.230199\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/2]: Training Loss: 1.284041877, Training Accuracy: 62.512\n",
            "Worker 7, [02/2]: Training Loss: 1.219520749, Training Accuracy: 65.488\n",
            "Time taken for training worker 7: 0:00:06.008686\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/2]: Training Loss: 1.275624197, Training Accuracy: 62.768\n",
            "Worker 8, [02/2]: Training Loss: 1.184470031, Training Accuracy: 65.328\n",
            "Time taken for training worker 8: 0:00:05.427388\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000886\n",
            "Local Step 64: Test Loss: 1.914592907, Test Accuracy: 52.070\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:47:38.864924\n",
            "//////////////////////////////////////////////////\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "K = [2, 4, 8]\n",
        "J = [4, 8, 16, 32, 64]\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K:\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    print('='*50)\n",
        "    print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "    print('='*50)\n",
        "    local_SGD(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ0FbYybODg0",
        "outputId": "4232b1b0-122a-4d4a-9517-0ddcc64e8eab"
      },
      "outputs": [],
      "source": [
        "# lr = 1e-02\n",
        "# wd = 1e-03\n",
        "# K = [2, 4, 8]\n",
        "# J = [4, 8, 16, 32, 64]\n",
        "# num_epochs = 150\n",
        "# data = CIFAR100Data()\n",
        "# loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# for k in K:\n",
        "#   shard_loaders = data.iid_shards(num_shards=k)\n",
        "#   for j in J:\n",
        "#     print('='*50)\n",
        "#     print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "#     print('='*50)\n",
        "#     iterations = num_epochs // j\n",
        "#     # Initialize a model with same value of param for each chunk\n",
        "#     models = [LeNet5().to(device) for _ in range(k)]\n",
        "#     for model in models:\n",
        "#       model.load_state_dict(initial_state_dict)\n",
        "#     #Initialize optimizers for each chunk\n",
        "#     optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in models]\n",
        "#     # Initialize a scheduler for each optimizer\n",
        "#     schedulers = [torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations) for optimizer in optimizers] #schedular mikhad ya na?????????\n",
        "    \n",
        "#     for local_step in range(j):\n",
        "#       for i, shard_loader in enumerate(shard_loaders):\n",
        "#           for epoch in range(iterations):\n",
        "#             train_loss, train_accuracy = train(models[i], shard_loader, optimizers[i], loss_fn, device = device,  is_wandb=False)\n",
        "#             schedulers[i].step()\n",
        "#             print(f'Worker {i+1}, [{epoch+1:02}/{iterations}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "#           print('-'*40)\n",
        "#       synchronize(models)\n",
        "#       test_loss, test_accuracy = test(models[0],original_test_loader, loss_fn, is_wandb = False)\n",
        "#       print('*'*40)\n",
        "#       print(f'Local Step {local_step+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "#       print('*'*40)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SlowMo Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "def local_SGD_SLOWMO(shard_loaders, loss_fn, parameters, k, j, t, initial_state_dict, num_epochs):\n",
        "  total_start_time = time.time()\n",
        "\n",
        "  lr = parameters['lr']\n",
        "  wd = parameters['wd']\n",
        "  beta = parameters['beta']\n",
        "  \n",
        "  iterations = num_epochs // j\n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  models = [LeNet5().to(device) for _ in range(k)]\n",
        "  slowmo_models = [LeNet5().to(device) for _ in range(k)]\n",
        "  for model,slow_model in zip(models, slowmo_models):\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "    slow_model.load_state_dict(initial_state_dict)\n",
        "  #Initialize optimizers for each chunk\n",
        "  optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in models]\n",
        "  # Initialize a scheduler for each optimizer\n",
        "  schedulers = [torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=iterations) for optimizer in optimizers]\n",
        "\n",
        "  for local_step in range(j):\n",
        "    for i, shard_loader in enumerate(shard_loaders):\n",
        "      train_start_time = time.time()\n",
        "      for epoch in range(iterations):\n",
        "        train_loss, train_accuracy = train(models[i], shard_loader, optimizers[i], loss_fn, device = device,  is_wandb=False)\n",
        "        schedulers[i].step()\n",
        "        print(f'Worker {i+1}, [{epoch+1:02}/{iterations}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "        if (epoch+1) % t == 0:\n",
        "          for param, slow_param in zip(models[i].parameters(), slowmo_models[i].parameters()):\n",
        "            slow_param.data.copy_(slow_param.data * beta + param.data * (1 - beta))\n",
        "            param.data.copy_(slow_param.data)\n",
        "            \n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {i+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "    synchronize(models) # Synchronize the models after each local step\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(models[0],original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Local Step {local_step+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "    \n",
        "\n",
        "  total_end_time = time.time()\n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for local_SGD: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.342572453, Training Accuracy: 4.428\n",
            "Worker 1, [02/37]: Training Loss: 3.875878685, Training Accuracy: 10.052\n",
            "Worker 1, [03/37]: Training Loss: 4.155894956, Training Accuracy: 6.724\n",
            "Worker 1, [04/37]: Training Loss: 3.683849662, Training Accuracy: 13.232\n",
            "Worker 1, [05/37]: Training Loss: 3.961436072, Training Accuracy: 9.192\n",
            "Worker 1, [06/37]: Training Loss: 3.555038408, Training Accuracy: 15.432\n",
            "Worker 1, [07/37]: Training Loss: 3.860311140, Training Accuracy: 10.972\n",
            "Worker 1, [08/37]: Training Loss: 3.455482852, Training Accuracy: 17.208\n",
            "Worker 1, [09/37]: Training Loss: 3.752010095, Training Accuracy: 12.576\n",
            "Worker 1, [10/37]: Training Loss: 3.364412247, Training Accuracy: 18.252\n",
            "Worker 1, [11/37]: Training Loss: 3.633259985, Training Accuracy: 14.244\n",
            "Worker 1, [12/37]: Training Loss: 3.283295976, Training Accuracy: 20.228\n",
            "Worker 1, [13/37]: Training Loss: 3.542504808, Training Accuracy: 16.032\n",
            "Worker 1, [14/37]: Training Loss: 3.245336103, Training Accuracy: 20.640\n",
            "Worker 1, [15/37]: Training Loss: 3.462906692, Training Accuracy: 17.568\n",
            "Worker 1, [16/37]: Training Loss: 3.162153046, Training Accuracy: 22.068\n",
            "Worker 1, [17/37]: Training Loss: 3.391678278, Training Accuracy: 18.476\n",
            "Worker 1, [18/37]: Training Loss: 3.133920172, Training Accuracy: 22.532\n",
            "Worker 1, [19/37]: Training Loss: 3.325365541, Training Accuracy: 19.532\n",
            "Worker 1, [20/37]: Training Loss: 3.087356412, Training Accuracy: 23.908\n",
            "Worker 1, [21/37]: Training Loss: 3.261947515, Training Accuracy: 20.936\n",
            "Worker 1, [22/37]: Training Loss: 3.049090146, Training Accuracy: 24.064\n",
            "Worker 1, [23/37]: Training Loss: 3.205831438, Training Accuracy: 21.944\n",
            "Worker 1, [24/37]: Training Loss: 3.004743571, Training Accuracy: 25.096\n",
            "Worker 1, [25/37]: Training Loss: 3.155231168, Training Accuracy: 23.240\n",
            "Worker 1, [26/37]: Training Loss: 2.975489371, Training Accuracy: 25.952\n",
            "Worker 1, [27/37]: Training Loss: 3.104003584, Training Accuracy: 24.000\n",
            "Worker 1, [28/37]: Training Loss: 2.947380416, Training Accuracy: 26.644\n",
            "Worker 1, [29/37]: Training Loss: 3.068704442, Training Accuracy: 25.060\n",
            "Worker 1, [30/37]: Training Loss: 2.932877470, Training Accuracy: 26.892\n",
            "Worker 1, [31/37]: Training Loss: 3.041360017, Training Accuracy: 25.352\n",
            "Worker 1, [32/37]: Training Loss: 2.922351046, Training Accuracy: 27.108\n",
            "Worker 1, [33/37]: Training Loss: 3.041917331, Training Accuracy: 25.960\n",
            "Worker 1, [34/37]: Training Loss: 2.934881587, Training Accuracy: 27.076\n",
            "Worker 1, [35/37]: Training Loss: 3.069090434, Training Accuracy: 26.400\n",
            "Worker 1, [36/37]: Training Loss: 2.981047383, Training Accuracy: 26.532\n",
            "Worker 1, [37/37]: Training Loss: 3.179998598, Training Accuracy: 27.048\n",
            "Time taken for training worker 1: 0:07:03.399261\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.337802527, Training Accuracy: 4.144\n",
            "Worker 2, [02/37]: Training Loss: 3.856681174, Training Accuracy: 9.988\n",
            "Worker 2, [03/37]: Training Loss: 4.124099393, Training Accuracy: 6.800\n",
            "Worker 2, [04/37]: Training Loss: 3.670992020, Training Accuracy: 13.248\n",
            "Worker 2, [05/37]: Training Loss: 3.959261997, Training Accuracy: 9.012\n",
            "Worker 2, [06/37]: Training Loss: 3.541682112, Training Accuracy: 15.296\n",
            "Worker 2, [07/37]: Training Loss: 3.836877347, Training Accuracy: 11.220\n",
            "Worker 2, [08/37]: Training Loss: 3.435116282, Training Accuracy: 16.940\n",
            "Worker 2, [09/37]: Training Loss: 3.729741786, Training Accuracy: 12.780\n",
            "Worker 2, [10/37]: Training Loss: 3.372170504, Training Accuracy: 18.152\n",
            "Worker 2, [11/37]: Training Loss: 3.634876462, Training Accuracy: 14.308\n",
            "Worker 2, [12/37]: Training Loss: 3.293989350, Training Accuracy: 19.596\n",
            "Worker 2, [13/37]: Training Loss: 3.538631222, Training Accuracy: 15.744\n",
            "Worker 2, [14/37]: Training Loss: 3.244709255, Training Accuracy: 20.572\n",
            "Worker 2, [15/37]: Training Loss: 3.472270273, Training Accuracy: 16.992\n",
            "Worker 2, [16/37]: Training Loss: 3.182106714, Training Accuracy: 21.684\n",
            "Worker 2, [17/37]: Training Loss: 3.387745845, Training Accuracy: 18.244\n",
            "Worker 2, [18/37]: Training Loss: 3.131510695, Training Accuracy: 22.832\n",
            "Worker 2, [19/37]: Training Loss: 3.315111363, Training Accuracy: 19.680\n",
            "Worker 2, [20/37]: Training Loss: 3.074289823, Training Accuracy: 23.816\n",
            "Worker 2, [21/37]: Training Loss: 3.261232214, Training Accuracy: 20.556\n",
            "Worker 2, [22/37]: Training Loss: 3.050243883, Training Accuracy: 24.232\n",
            "Worker 2, [23/37]: Training Loss: 3.205360725, Training Accuracy: 22.000\n",
            "Worker 2, [24/37]: Training Loss: 3.008536307, Training Accuracy: 25.104\n",
            "Worker 2, [25/37]: Training Loss: 3.147511287, Training Accuracy: 23.316\n",
            "Worker 2, [26/37]: Training Loss: 2.975399811, Training Accuracy: 25.936\n",
            "Worker 2, [27/37]: Training Loss: 3.107593547, Training Accuracy: 23.844\n",
            "Worker 2, [28/37]: Training Loss: 2.948481882, Training Accuracy: 26.576\n",
            "Worker 2, [29/37]: Training Loss: 3.067344034, Training Accuracy: 24.652\n",
            "Worker 2, [30/37]: Training Loss: 2.931926109, Training Accuracy: 26.576\n",
            "Worker 2, [31/37]: Training Loss: 3.040153255, Training Accuracy: 25.704\n",
            "Worker 2, [32/37]: Training Loss: 2.926707870, Training Accuracy: 27.044\n",
            "Worker 2, [33/37]: Training Loss: 3.043952943, Training Accuracy: 26.248\n",
            "Worker 2, [34/37]: Training Loss: 2.933318391, Training Accuracy: 27.112\n",
            "Worker 2, [35/37]: Training Loss: 3.070458069, Training Accuracy: 26.312\n",
            "Worker 2, [36/37]: Training Loss: 2.977952130, Training Accuracy: 26.664\n",
            "Worker 2, [37/37]: Training Loss: 3.169143547, Training Accuracy: 27.012\n",
            "Time taken for training worker 2: 0:06:51.253277\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000553\n",
            "Local Step 01: Test Loss: 3.263815450, Test Accuracy: 26.590\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.334352819, Training Accuracy: 24.532\n",
            "Worker 1, [02/37]: Training Loss: 3.294314661, Training Accuracy: 24.476\n",
            "Worker 1, [03/37]: Training Loss: 3.119564603, Training Accuracy: 26.344\n",
            "Worker 1, [04/37]: Training Loss: 3.009025737, Training Accuracy: 26.308\n",
            "Worker 1, [05/37]: Training Loss: 3.031686273, Training Accuracy: 26.272\n",
            "Worker 1, [06/37]: Training Loss: 2.961550783, Training Accuracy: 26.556\n",
            "Worker 1, [07/37]: Training Loss: 2.996356544, Training Accuracy: 26.048\n",
            "Worker 1, [08/37]: Training Loss: 2.936855803, Training Accuracy: 26.836\n",
            "Worker 1, [09/37]: Training Loss: 2.993457398, Training Accuracy: 25.848\n",
            "Worker 1, [10/37]: Training Loss: 2.926024514, Training Accuracy: 27.196\n",
            "Worker 1, [11/37]: Training Loss: 2.994719169, Training Accuracy: 25.804\n",
            "Worker 1, [12/37]: Training Loss: 2.918188882, Training Accuracy: 27.248\n",
            "Worker 1, [13/37]: Training Loss: 3.002416546, Training Accuracy: 25.504\n",
            "Worker 1, [14/37]: Training Loss: 2.920767673, Training Accuracy: 26.976\n",
            "Worker 1, [15/37]: Training Loss: 3.009404412, Training Accuracy: 25.396\n",
            "Worker 1, [16/37]: Training Loss: 2.912329518, Training Accuracy: 26.804\n",
            "Worker 1, [17/37]: Training Loss: 3.010658069, Training Accuracy: 25.276\n",
            "Worker 1, [18/37]: Training Loss: 2.909705527, Training Accuracy: 26.728\n",
            "Worker 1, [19/37]: Training Loss: 3.009138452, Training Accuracy: 25.064\n",
            "Worker 1, [20/37]: Training Loss: 2.897713819, Training Accuracy: 27.148\n",
            "Worker 1, [21/37]: Training Loss: 3.010657053, Training Accuracy: 25.120\n",
            "Worker 1, [22/37]: Training Loss: 2.902933481, Training Accuracy: 27.300\n",
            "Worker 1, [23/37]: Training Loss: 3.004695775, Training Accuracy: 25.036\n",
            "Worker 1, [24/37]: Training Loss: 2.880406581, Training Accuracy: 27.784\n",
            "Worker 1, [25/37]: Training Loss: 3.001788095, Training Accuracy: 25.252\n",
            "Worker 1, [26/37]: Training Loss: 2.862570657, Training Accuracy: 27.900\n",
            "Worker 1, [27/37]: Training Loss: 2.981970526, Training Accuracy: 25.728\n",
            "Worker 1, [28/37]: Training Loss: 2.863622736, Training Accuracy: 27.940\n",
            "Worker 1, [29/37]: Training Loss: 2.974198921, Training Accuracy: 25.820\n",
            "Worker 1, [30/37]: Training Loss: 2.834116899, Training Accuracy: 28.464\n",
            "Worker 1, [31/37]: Training Loss: 2.948736612, Training Accuracy: 26.420\n",
            "Worker 1, [32/37]: Training Loss: 2.845608003, Training Accuracy: 28.132\n",
            "Worker 1, [33/37]: Training Loss: 2.950397907, Training Accuracy: 26.020\n",
            "Worker 1, [34/37]: Training Loss: 2.812137715, Training Accuracy: 28.792\n",
            "Worker 1, [35/37]: Training Loss: 2.920326167, Training Accuracy: 26.664\n",
            "Worker 1, [36/37]: Training Loss: 2.798551102, Training Accuracy: 29.132\n",
            "Worker 1, [37/37]: Training Loss: 2.876687774, Training Accuracy: 27.496\n",
            "Time taken for training worker 1: 0:06:30.150086\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.935827286, Training Accuracy: 27.152\n",
            "Worker 2, [02/37]: Training Loss: 2.835746062, Training Accuracy: 29.068\n",
            "Worker 2, [03/37]: Training Loss: 3.112678069, Training Accuracy: 26.720\n",
            "Worker 2, [04/37]: Training Loss: 2.985432034, Training Accuracy: 26.624\n",
            "Worker 2, [05/37]: Training Loss: 3.011221028, Training Accuracy: 26.560\n",
            "Worker 2, [06/37]: Training Loss: 2.928252404, Training Accuracy: 27.200\n",
            "Worker 2, [07/37]: Training Loss: 2.981124011, Training Accuracy: 26.400\n",
            "Worker 2, [08/37]: Training Loss: 2.909089587, Training Accuracy: 27.252\n",
            "Worker 2, [09/37]: Training Loss: 2.963669232, Training Accuracy: 26.424\n",
            "Worker 2, [10/37]: Training Loss: 2.897945771, Training Accuracy: 27.588\n",
            "Worker 2, [11/37]: Training Loss: 2.964990301, Training Accuracy: 26.256\n",
            "Worker 2, [12/37]: Training Loss: 2.903162356, Training Accuracy: 27.456\n",
            "Worker 2, [13/37]: Training Loss: 2.962452331, Training Accuracy: 26.304\n",
            "Worker 2, [14/37]: Training Loss: 2.890075279, Training Accuracy: 27.584\n",
            "Worker 2, [15/37]: Training Loss: 2.972935309, Training Accuracy: 25.720\n",
            "Worker 2, [16/37]: Training Loss: 2.884597548, Training Accuracy: 27.748\n",
            "Worker 2, [17/37]: Training Loss: 2.971737437, Training Accuracy: 25.908\n",
            "Worker 2, [18/37]: Training Loss: 2.871585324, Training Accuracy: 27.912\n",
            "Worker 2, [19/37]: Training Loss: 2.983063986, Training Accuracy: 25.360\n",
            "Worker 2, [20/37]: Training Loss: 2.875526054, Training Accuracy: 27.676\n",
            "Worker 2, [21/37]: Training Loss: 2.981143201, Training Accuracy: 25.368\n",
            "Worker 2, [22/37]: Training Loss: 2.870099244, Training Accuracy: 27.892\n",
            "Worker 2, [23/37]: Training Loss: 2.973898377, Training Accuracy: 25.524\n",
            "Worker 2, [24/37]: Training Loss: 2.855082859, Training Accuracy: 28.136\n",
            "Worker 2, [25/37]: Training Loss: 2.975583045, Training Accuracy: 25.320\n",
            "Worker 2, [26/37]: Training Loss: 2.836625929, Training Accuracy: 28.068\n",
            "Worker 2, [27/37]: Training Loss: 2.958846612, Training Accuracy: 25.820\n",
            "Worker 2, [28/37]: Training Loss: 2.836692174, Training Accuracy: 28.704\n",
            "Worker 2, [29/37]: Training Loss: 2.951820117, Training Accuracy: 26.164\n",
            "Worker 2, [30/37]: Training Loss: 2.833550045, Training Accuracy: 28.532\n",
            "Worker 2, [31/37]: Training Loss: 2.933350156, Training Accuracy: 26.540\n",
            "Worker 2, [32/37]: Training Loss: 2.811497612, Training Accuracy: 28.540\n",
            "Worker 2, [33/37]: Training Loss: 2.925247540, Training Accuracy: 26.540\n",
            "Worker 2, [34/37]: Training Loss: 2.790249182, Training Accuracy: 29.628\n",
            "Worker 2, [35/37]: Training Loss: 2.899739047, Training Accuracy: 27.316\n",
            "Worker 2, [36/37]: Training Loss: 2.774946323, Training Accuracy: 29.464\n",
            "Worker 2, [37/37]: Training Loss: 2.872794540, Training Accuracy: 27.584\n",
            "Time taken for training worker 2: 0:06:27.826265\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000633\n",
            "Local Step 02: Test Loss: 2.733741318, Test Accuracy: 30.510\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.872932812, Training Accuracy: 28.032\n",
            "Worker 1, [02/37]: Training Loss: 2.745289665, Training Accuracy: 30.508\n",
            "Worker 1, [03/37]: Training Loss: 2.863213467, Training Accuracy: 27.756\n",
            "Worker 1, [04/37]: Training Loss: 2.766096973, Training Accuracy: 29.872\n",
            "Worker 1, [05/37]: Training Loss: 2.843462937, Training Accuracy: 28.500\n",
            "Worker 1, [06/37]: Training Loss: 2.713940708, Training Accuracy: 30.508\n",
            "Worker 1, [07/37]: Training Loss: 2.798927227, Training Accuracy: 29.108\n",
            "Worker 1, [08/37]: Training Loss: 2.691842016, Training Accuracy: 30.836\n",
            "Worker 1, [09/37]: Training Loss: 2.753158950, Training Accuracy: 30.068\n",
            "Worker 1, [10/37]: Training Loss: 2.636866222, Training Accuracy: 32.132\n",
            "Worker 1, [11/37]: Training Loss: 2.707682777, Training Accuracy: 30.636\n",
            "Worker 1, [12/37]: Training Loss: 2.594756501, Training Accuracy: 33.304\n",
            "Worker 1, [13/37]: Training Loss: 2.644671763, Training Accuracy: 32.324\n",
            "Worker 1, [14/37]: Training Loss: 2.551969368, Training Accuracy: 33.840\n",
            "Worker 1, [15/37]: Training Loss: 2.603093437, Training Accuracy: 33.136\n",
            "Worker 1, [16/37]: Training Loss: 2.503001290, Training Accuracy: 35.240\n",
            "Worker 1, [17/37]: Training Loss: 2.545087810, Training Accuracy: 34.244\n",
            "Worker 1, [18/37]: Training Loss: 2.455918479, Training Accuracy: 35.712\n",
            "Worker 1, [19/37]: Training Loss: 2.483221594, Training Accuracy: 35.464\n",
            "Worker 1, [20/37]: Training Loss: 2.395036196, Training Accuracy: 37.056\n",
            "Worker 1, [21/37]: Training Loss: 2.440719135, Training Accuracy: 36.412\n",
            "Worker 1, [22/37]: Training Loss: 2.351997479, Training Accuracy: 38.332\n",
            "Worker 1, [23/37]: Training Loss: 2.381723540, Training Accuracy: 37.468\n",
            "Worker 1, [24/37]: Training Loss: 2.301384076, Training Accuracy: 39.276\n",
            "Worker 1, [25/37]: Training Loss: 2.324324990, Training Accuracy: 39.116\n",
            "Worker 1, [26/37]: Training Loss: 2.249281470, Training Accuracy: 40.484\n",
            "Worker 1, [27/37]: Training Loss: 2.271337939, Training Accuracy: 40.436\n",
            "Worker 1, [28/37]: Training Loss: 2.220333694, Training Accuracy: 41.228\n",
            "Worker 1, [29/37]: Training Loss: 2.239267134, Training Accuracy: 41.216\n",
            "Worker 1, [30/37]: Training Loss: 2.180376974, Training Accuracy: 42.048\n",
            "Worker 1, [31/37]: Training Loss: 2.207406412, Training Accuracy: 41.660\n",
            "Worker 1, [32/37]: Training Loss: 2.150098252, Training Accuracy: 42.732\n",
            "Worker 1, [33/37]: Training Loss: 2.172966547, Training Accuracy: 42.704\n",
            "Worker 1, [34/37]: Training Loss: 2.141264876, Training Accuracy: 43.256\n",
            "Worker 1, [35/37]: Training Loss: 2.176964726, Training Accuracy: 42.672\n",
            "Worker 1, [36/37]: Training Loss: 2.149340368, Training Accuracy: 43.064\n",
            "Worker 1, [37/37]: Training Loss: 2.185458983, Training Accuracy: 42.780\n",
            "Time taken for training worker 1: 0:06:27.972909\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.796619068, Training Accuracy: 29.448\n",
            "Worker 2, [02/37]: Training Loss: 2.676971009, Training Accuracy: 31.476\n",
            "Worker 2, [03/37]: Training Loss: 2.858831050, Training Accuracy: 27.808\n",
            "Worker 2, [04/37]: Training Loss: 2.725869292, Training Accuracy: 30.712\n",
            "Worker 2, [05/37]: Training Loss: 2.812515074, Training Accuracy: 28.568\n",
            "Worker 2, [06/37]: Training Loss: 2.707848794, Training Accuracy: 30.852\n",
            "Worker 2, [07/37]: Training Loss: 2.769734596, Training Accuracy: 29.416\n",
            "Worker 2, [08/37]: Training Loss: 2.672297116, Training Accuracy: 31.188\n",
            "Worker 2, [09/37]: Training Loss: 2.741394254, Training Accuracy: 30.284\n",
            "Worker 2, [10/37]: Training Loss: 2.628780535, Training Accuracy: 32.484\n",
            "Worker 2, [11/37]: Training Loss: 2.687255910, Training Accuracy: 31.168\n",
            "Worker 2, [12/37]: Training Loss: 2.591226533, Training Accuracy: 33.272\n",
            "Worker 2, [13/37]: Training Loss: 2.640131302, Training Accuracy: 32.128\n",
            "Worker 2, [14/37]: Training Loss: 2.549812300, Training Accuracy: 34.040\n",
            "Worker 2, [15/37]: Training Loss: 2.590245761, Training Accuracy: 33.728\n",
            "Worker 2, [16/37]: Training Loss: 2.493020168, Training Accuracy: 35.428\n",
            "Worker 2, [17/37]: Training Loss: 2.524130980, Training Accuracy: 34.308\n",
            "Worker 2, [18/37]: Training Loss: 2.453630808, Training Accuracy: 36.224\n",
            "Worker 2, [19/37]: Training Loss: 2.476262524, Training Accuracy: 35.652\n",
            "Worker 2, [20/37]: Training Loss: 2.395362276, Training Accuracy: 37.160\n",
            "Worker 2, [21/37]: Training Loss: 2.408811716, Training Accuracy: 37.184\n",
            "Worker 2, [22/37]: Training Loss: 2.339071779, Training Accuracy: 38.708\n",
            "Worker 2, [23/37]: Training Loss: 2.356851429, Training Accuracy: 38.504\n",
            "Worker 2, [24/37]: Training Loss: 2.277802678, Training Accuracy: 39.652\n",
            "Worker 2, [25/37]: Training Loss: 2.313722910, Training Accuracy: 39.128\n",
            "Worker 2, [26/37]: Training Loss: 2.246653975, Training Accuracy: 40.876\n",
            "Worker 2, [27/37]: Training Loss: 2.259396211, Training Accuracy: 40.424\n",
            "Worker 2, [28/37]: Training Loss: 2.194589486, Training Accuracy: 41.892\n",
            "Worker 2, [29/37]: Training Loss: 2.222817809, Training Accuracy: 41.444\n",
            "Worker 2, [30/37]: Training Loss: 2.166903156, Training Accuracy: 42.516\n",
            "Worker 2, [31/37]: Training Loss: 2.184225491, Training Accuracy: 42.552\n",
            "Worker 2, [32/37]: Training Loss: 2.134167457, Training Accuracy: 43.536\n",
            "Worker 2, [33/37]: Training Loss: 2.171183125, Training Accuracy: 42.664\n",
            "Worker 2, [34/37]: Training Loss: 2.130904025, Training Accuracy: 43.896\n",
            "Worker 2, [35/37]: Training Loss: 2.152799478, Training Accuracy: 43.236\n",
            "Worker 2, [36/37]: Training Loss: 2.137464558, Training Accuracy: 43.508\n",
            "Worker 2, [37/37]: Training Loss: 2.164975712, Training Accuracy: 43.500\n",
            "Time taken for training worker 2: 0:06:25.869421\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000529\n",
            "Local Step 03: Test Loss: 2.265983339, Test Accuracy: 40.980\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.431906582, Training Accuracy: 37.576\n",
            "Worker 1, [02/37]: Training Loss: 2.434084714, Training Accuracy: 37.800\n",
            "Worker 1, [03/37]: Training Loss: 2.210299131, Training Accuracy: 42.164\n",
            "Worker 1, [04/37]: Training Loss: 2.182291594, Training Accuracy: 42.672\n",
            "Worker 1, [05/37]: Training Loss: 2.197966558, Training Accuracy: 42.016\n",
            "Worker 1, [06/37]: Training Loss: 2.184635244, Training Accuracy: 42.316\n",
            "Worker 1, [07/37]: Training Loss: 2.206935066, Training Accuracy: 41.592\n",
            "Worker 1, [08/37]: Training Loss: 2.184738167, Training Accuracy: 42.440\n",
            "Worker 1, [09/37]: Training Loss: 2.210031377, Training Accuracy: 41.584\n",
            "Worker 1, [10/37]: Training Loss: 2.204116194, Training Accuracy: 41.692\n",
            "Worker 1, [11/37]: Training Loss: 2.231326930, Training Accuracy: 41.048\n",
            "Worker 1, [12/37]: Training Loss: 2.222232237, Training Accuracy: 41.012\n",
            "Worker 1, [13/37]: Training Loss: 2.270384292, Training Accuracy: 40.156\n",
            "Worker 1, [14/37]: Training Loss: 2.253109109, Training Accuracy: 40.300\n",
            "Worker 1, [15/37]: Training Loss: 2.296759920, Training Accuracy: 39.120\n",
            "Worker 1, [16/37]: Training Loss: 2.292050089, Training Accuracy: 39.396\n",
            "Worker 1, [17/37]: Training Loss: 2.338166265, Training Accuracy: 38.488\n",
            "Worker 1, [18/37]: Training Loss: 2.325066220, Training Accuracy: 38.772\n",
            "Worker 1, [19/37]: Training Loss: 2.376122261, Training Accuracy: 37.892\n",
            "Worker 1, [20/37]: Training Loss: 2.354079636, Training Accuracy: 38.048\n",
            "Worker 1, [21/37]: Training Loss: 2.405521530, Training Accuracy: 37.016\n",
            "Worker 1, [22/37]: Training Loss: 2.385981025, Training Accuracy: 37.680\n",
            "Worker 1, [23/37]: Training Loss: 2.442324481, Training Accuracy: 36.384\n",
            "Worker 1, [24/37]: Training Loss: 2.407859518, Training Accuracy: 37.260\n",
            "Worker 1, [25/37]: Training Loss: 2.455900414, Training Accuracy: 35.916\n",
            "Worker 1, [26/37]: Training Loss: 2.426669152, Training Accuracy: 36.548\n",
            "Worker 1, [27/37]: Training Loss: 2.478257411, Training Accuracy: 35.224\n",
            "Worker 1, [28/37]: Training Loss: 2.450466781, Training Accuracy: 35.960\n",
            "Worker 1, [29/37]: Training Loss: 2.486293494, Training Accuracy: 35.380\n",
            "Worker 1, [30/37]: Training Loss: 2.449842583, Training Accuracy: 36.084\n",
            "Worker 1, [31/37]: Training Loss: 2.505785850, Training Accuracy: 34.524\n",
            "Worker 1, [32/37]: Training Loss: 2.459843417, Training Accuracy: 35.624\n",
            "Worker 1, [33/37]: Training Loss: 2.511676586, Training Accuracy: 34.760\n",
            "Worker 1, [34/37]: Training Loss: 2.448626003, Training Accuracy: 36.260\n",
            "Worker 1, [35/37]: Training Loss: 2.479407196, Training Accuracy: 35.600\n",
            "Worker 1, [36/37]: Training Loss: 2.457908273, Training Accuracy: 35.880\n",
            "Worker 1, [37/37]: Training Loss: 2.475267614, Training Accuracy: 35.512\n",
            "Time taken for training worker 1: 0:06:32.867390\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.734223290, Training Accuracy: 31.516\n",
            "Worker 2, [02/37]: Training Loss: 2.638722764, Training Accuracy: 33.180\n",
            "Worker 2, [03/37]: Training Loss: 2.187731352, Training Accuracy: 43.156\n",
            "Worker 2, [04/37]: Training Loss: 2.159634960, Training Accuracy: 43.104\n",
            "Worker 2, [05/37]: Training Loss: 2.178989034, Training Accuracy: 42.560\n",
            "Worker 2, [06/37]: Training Loss: 2.158095081, Training Accuracy: 42.736\n",
            "Worker 2, [07/37]: Training Loss: 2.171947970, Training Accuracy: 42.768\n",
            "Worker 2, [08/37]: Training Loss: 2.151897198, Training Accuracy: 42.852\n",
            "Worker 2, [09/37]: Training Loss: 2.196846224, Training Accuracy: 41.836\n",
            "Worker 2, [10/37]: Training Loss: 2.180900601, Training Accuracy: 42.060\n",
            "Worker 2, [11/37]: Training Loss: 2.210640371, Training Accuracy: 41.680\n",
            "Worker 2, [12/37]: Training Loss: 2.206371589, Training Accuracy: 41.424\n",
            "Worker 2, [13/37]: Training Loss: 2.246009321, Training Accuracy: 40.988\n",
            "Worker 2, [14/37]: Training Loss: 2.223451425, Training Accuracy: 41.084\n",
            "Worker 2, [15/37]: Training Loss: 2.284994295, Training Accuracy: 39.868\n",
            "Worker 2, [16/37]: Training Loss: 2.261948601, Training Accuracy: 40.072\n",
            "Worker 2, [17/37]: Training Loss: 2.306682233, Training Accuracy: 39.084\n",
            "Worker 2, [18/37]: Training Loss: 2.299558566, Training Accuracy: 39.040\n",
            "Worker 2, [19/37]: Training Loss: 2.335541247, Training Accuracy: 38.896\n",
            "Worker 2, [20/37]: Training Loss: 2.320802718, Training Accuracy: 38.940\n",
            "Worker 2, [21/37]: Training Loss: 2.388614260, Training Accuracy: 37.220\n",
            "Worker 2, [22/37]: Training Loss: 2.356329080, Training Accuracy: 37.940\n",
            "Worker 2, [23/37]: Training Loss: 2.417732543, Training Accuracy: 36.948\n",
            "Worker 2, [24/37]: Training Loss: 2.384359030, Training Accuracy: 38.004\n",
            "Worker 2, [25/37]: Training Loss: 2.436507532, Training Accuracy: 36.468\n",
            "Worker 2, [26/37]: Training Loss: 2.412427199, Training Accuracy: 36.928\n",
            "Worker 2, [27/37]: Training Loss: 2.454320961, Training Accuracy: 36.456\n",
            "Worker 2, [28/37]: Training Loss: 2.421629325, Training Accuracy: 36.616\n",
            "Worker 2, [29/37]: Training Loss: 2.482241636, Training Accuracy: 35.560\n",
            "Worker 2, [30/37]: Training Loss: 2.445601493, Training Accuracy: 36.488\n",
            "Worker 2, [31/37]: Training Loss: 2.487176459, Training Accuracy: 35.328\n",
            "Worker 2, [32/37]: Training Loss: 2.443650975, Training Accuracy: 36.368\n",
            "Worker 2, [33/37]: Training Loss: 2.465322764, Training Accuracy: 35.840\n",
            "Worker 2, [34/37]: Training Loss: 2.449061619, Training Accuracy: 36.120\n",
            "Worker 2, [35/37]: Training Loss: 2.471560535, Training Accuracy: 35.776\n",
            "Worker 2, [36/37]: Training Loss: 2.424135068, Training Accuracy: 36.504\n",
            "Worker 2, [37/37]: Training Loss: 2.466960203, Training Accuracy: 35.576\n",
            "Time taken for training worker 2: 0:06:24.065716\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000571\n",
            "Local Step 04: Test Loss: 2.512199479, Test Accuracy: 35.050\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:46.642638\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.341946330, Training Accuracy: 4.440\n",
            "Worker 1, [02/37]: Training Loss: 3.877821408, Training Accuracy: 9.680\n",
            "Worker 1, [03/37]: Training Loss: 3.617708743, Training Accuracy: 13.892\n",
            "Worker 1, [04/37]: Training Loss: 3.381096393, Training Accuracy: 18.072\n",
            "Worker 1, [05/37]: Training Loss: 4.107402959, Training Accuracy: 7.400\n",
            "Worker 1, [06/37]: Training Loss: 3.577396625, Training Accuracy: 14.892\n",
            "Worker 1, [07/37]: Training Loss: 3.326433452, Training Accuracy: 19.012\n",
            "Worker 1, [08/37]: Training Loss: 3.141195905, Training Accuracy: 22.452\n",
            "Worker 1, [09/37]: Training Loss: 3.890980466, Training Accuracy: 10.804\n",
            "Worker 1, [10/37]: Training Loss: 3.361649480, Training Accuracy: 18.576\n",
            "Worker 1, [11/37]: Training Loss: 3.146739670, Training Accuracy: 22.040\n",
            "Worker 1, [12/37]: Training Loss: 2.989910698, Training Accuracy: 25.704\n",
            "Worker 1, [13/37]: Training Loss: 3.702399402, Training Accuracy: 13.900\n",
            "Worker 1, [14/37]: Training Loss: 3.203601268, Training Accuracy: 21.408\n",
            "Worker 1, [15/37]: Training Loss: 3.013999324, Training Accuracy: 24.768\n",
            "Worker 1, [16/37]: Training Loss: 2.850076376, Training Accuracy: 28.048\n",
            "Worker 1, [17/37]: Training Loss: 3.518157468, Training Accuracy: 16.752\n",
            "Worker 1, [18/37]: Training Loss: 3.073176296, Training Accuracy: 24.040\n",
            "Worker 1, [19/37]: Training Loss: 2.880722689, Training Accuracy: 27.356\n",
            "Worker 1, [20/37]: Training Loss: 2.756843369, Training Accuracy: 29.632\n",
            "Worker 1, [21/37]: Training Loss: 3.397361965, Training Accuracy: 18.984\n",
            "Worker 1, [22/37]: Training Loss: 2.970770083, Training Accuracy: 26.084\n",
            "Worker 1, [23/37]: Training Loss: 2.803520984, Training Accuracy: 29.232\n",
            "Worker 1, [24/37]: Training Loss: 2.696193967, Training Accuracy: 31.360\n",
            "Worker 1, [25/37]: Training Loss: 3.290307746, Training Accuracy: 21.856\n",
            "Worker 1, [26/37]: Training Loss: 2.904516456, Training Accuracy: 27.056\n",
            "Worker 1, [27/37]: Training Loss: 2.768724913, Training Accuracy: 29.840\n",
            "Worker 1, [28/37]: Training Loss: 2.665338920, Training Accuracy: 31.660\n",
            "Worker 1, [29/37]: Training Loss: 3.257380612, Training Accuracy: 23.320\n",
            "Worker 1, [30/37]: Training Loss: 2.903437549, Training Accuracy: 27.980\n",
            "Worker 1, [31/37]: Training Loss: 2.785851563, Training Accuracy: 30.076\n",
            "Worker 1, [32/37]: Training Loss: 2.706641641, Training Accuracy: 31.644\n",
            "Worker 1, [33/37]: Training Loss: 3.360549549, Training Accuracy: 23.992\n",
            "Worker 1, [34/37]: Training Loss: 3.030844893, Training Accuracy: 26.292\n",
            "Worker 1, [35/37]: Training Loss: 2.942913762, Training Accuracy: 27.468\n",
            "Worker 1, [36/37]: Training Loss: 2.904911260, Training Accuracy: 28.644\n",
            "Worker 1, [37/37]: Training Loss: 3.839030709, Training Accuracy: 26.492\n",
            "Time taken for training worker 1: 0:06:23.406263\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.345204992, Training Accuracy: 4.204\n",
            "Worker 2, [02/37]: Training Loss: 3.867725806, Training Accuracy: 9.952\n",
            "Worker 2, [03/37]: Training Loss: 3.594884298, Training Accuracy: 14.488\n",
            "Worker 2, [04/37]: Training Loss: 3.389852826, Training Accuracy: 17.644\n",
            "Worker 2, [05/37]: Training Loss: 4.088973889, Training Accuracy: 7.500\n",
            "Worker 2, [06/37]: Training Loss: 3.582064912, Training Accuracy: 14.532\n",
            "Worker 2, [07/37]: Training Loss: 3.355502044, Training Accuracy: 18.436\n",
            "Worker 2, [08/37]: Training Loss: 3.171613340, Training Accuracy: 21.716\n",
            "Worker 2, [09/37]: Training Loss: 3.858770478, Training Accuracy: 10.780\n",
            "Worker 2, [10/37]: Training Loss: 3.360418929, Training Accuracy: 18.424\n",
            "Worker 2, [11/37]: Training Loss: 3.177247195, Training Accuracy: 21.928\n",
            "Worker 2, [12/37]: Training Loss: 3.012584055, Training Accuracy: 24.816\n",
            "Worker 2, [13/37]: Training Loss: 3.694764702, Training Accuracy: 13.384\n",
            "Worker 2, [14/37]: Training Loss: 3.231801397, Training Accuracy: 20.592\n",
            "Worker 2, [15/37]: Training Loss: 3.045184088, Training Accuracy: 24.072\n",
            "Worker 2, [16/37]: Training Loss: 2.906345483, Training Accuracy: 27.112\n",
            "Worker 2, [17/37]: Training Loss: 3.539786234, Training Accuracy: 16.232\n",
            "Worker 2, [18/37]: Training Loss: 3.113407050, Training Accuracy: 22.992\n",
            "Worker 2, [19/37]: Training Loss: 2.928862366, Training Accuracy: 26.368\n",
            "Worker 2, [20/37]: Training Loss: 2.788207830, Training Accuracy: 29.508\n",
            "Worker 2, [21/37]: Training Loss: 3.408047301, Training Accuracy: 19.084\n",
            "Worker 2, [22/37]: Training Loss: 3.007919299, Training Accuracy: 25.056\n",
            "Worker 2, [23/37]: Training Loss: 2.839188571, Training Accuracy: 28.280\n",
            "Worker 2, [24/37]: Training Loss: 2.731869229, Training Accuracy: 30.212\n",
            "Worker 2, [25/37]: Training Loss: 3.324598852, Training Accuracy: 20.748\n",
            "Worker 2, [26/37]: Training Loss: 2.948958943, Training Accuracy: 26.316\n",
            "Worker 2, [27/37]: Training Loss: 2.810815322, Training Accuracy: 28.780\n",
            "Worker 2, [28/37]: Training Loss: 2.710375520, Training Accuracy: 31.172\n",
            "Worker 2, [29/37]: Training Loss: 3.286999790, Training Accuracy: 22.360\n",
            "Worker 2, [30/37]: Training Loss: 2.948052630, Training Accuracy: 26.848\n",
            "Worker 2, [31/37]: Training Loss: 2.821585326, Training Accuracy: 29.064\n",
            "Worker 2, [32/37]: Training Loss: 2.748294720, Training Accuracy: 30.252\n",
            "Worker 2, [33/37]: Training Loss: 3.377533036, Training Accuracy: 23.748\n",
            "Worker 2, [34/37]: Training Loss: 3.059958371, Training Accuracy: 25.384\n",
            "Worker 2, [35/37]: Training Loss: 2.989346291, Training Accuracy: 26.576\n",
            "Worker 2, [36/37]: Training Loss: 2.947273900, Training Accuracy: 27.296\n",
            "Worker 2, [37/37]: Training Loss: 3.851428133, Training Accuracy: 26.496\n",
            "Time taken for training worker 2: 0:06:19.721994\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000529\n",
            "Local Step 01: Test Loss: 3.921623083, Test Accuracy: 24.540\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.958771507, Training Accuracy: 22.960\n",
            "Worker 1, [02/37]: Training Loss: 3.909494183, Training Accuracy: 22.500\n",
            "Worker 1, [03/37]: Training Loss: 3.695883791, Training Accuracy: 21.528\n",
            "Worker 1, [04/37]: Training Loss: 3.401438087, Training Accuracy: 21.720\n",
            "Worker 1, [05/37]: Training Loss: 3.341868701, Training Accuracy: 24.616\n",
            "Worker 1, [06/37]: Training Loss: 3.046945974, Training Accuracy: 25.764\n",
            "Worker 1, [07/37]: Training Loss: 2.930053785, Training Accuracy: 27.288\n",
            "Worker 1, [08/37]: Training Loss: 2.841291682, Training Accuracy: 29.136\n",
            "Worker 1, [09/37]: Training Loss: 3.088284210, Training Accuracy: 25.636\n",
            "Worker 1, [10/37]: Training Loss: 2.871568650, Training Accuracy: 28.244\n",
            "Worker 1, [11/37]: Training Loss: 2.782771995, Training Accuracy: 29.668\n",
            "Worker 1, [12/37]: Training Loss: 2.723008062, Training Accuracy: 30.976\n",
            "Worker 1, [13/37]: Training Loss: 3.001895551, Training Accuracy: 26.164\n",
            "Worker 1, [14/37]: Training Loss: 2.816236448, Training Accuracy: 28.904\n",
            "Worker 1, [15/37]: Training Loss: 2.748231595, Training Accuracy: 29.920\n",
            "Worker 1, [16/37]: Training Loss: 2.685979575, Training Accuracy: 31.632\n",
            "Worker 1, [17/37]: Training Loss: 2.964237736, Training Accuracy: 26.468\n",
            "Worker 1, [18/37]: Training Loss: 2.804665516, Training Accuracy: 28.976\n",
            "Worker 1, [19/37]: Training Loss: 2.720683564, Training Accuracy: 30.660\n",
            "Worker 1, [20/37]: Training Loss: 2.649252250, Training Accuracy: 31.876\n",
            "Worker 1, [21/37]: Training Loss: 2.959874002, Training Accuracy: 26.288\n",
            "Worker 1, [22/37]: Training Loss: 2.794854385, Training Accuracy: 28.740\n",
            "Worker 1, [23/37]: Training Loss: 2.689116894, Training Accuracy: 31.044\n",
            "Worker 1, [24/37]: Training Loss: 2.644019704, Training Accuracy: 32.512\n",
            "Worker 1, [25/37]: Training Loss: 2.943318572, Training Accuracy: 26.440\n",
            "Worker 1, [26/37]: Training Loss: 2.796745406, Training Accuracy: 29.196\n",
            "Worker 1, [27/37]: Training Loss: 2.691992811, Training Accuracy: 31.128\n",
            "Worker 1, [28/37]: Training Loss: 2.615376943, Training Accuracy: 32.592\n",
            "Worker 1, [29/37]: Training Loss: 2.921140401, Training Accuracy: 26.676\n",
            "Worker 1, [30/37]: Training Loss: 2.764387168, Training Accuracy: 29.896\n",
            "Worker 1, [31/37]: Training Loss: 2.673984523, Training Accuracy: 31.600\n",
            "Worker 1, [32/37]: Training Loss: 2.605719196, Training Accuracy: 32.960\n",
            "Worker 1, [33/37]: Training Loss: 2.888901929, Training Accuracy: 27.076\n",
            "Worker 1, [34/37]: Training Loss: 2.738498725, Training Accuracy: 30.172\n",
            "Worker 1, [35/37]: Training Loss: 2.638727412, Training Accuracy: 32.396\n",
            "Worker 1, [36/37]: Training Loss: 2.567314338, Training Accuracy: 33.704\n",
            "Worker 1, [37/37]: Training Loss: 2.862350068, Training Accuracy: 27.928\n",
            "Time taken for training worker 1: 0:06:19.250914\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.945033612, Training Accuracy: 26.480\n",
            "Worker 2, [02/37]: Training Loss: 2.828923977, Training Accuracy: 28.924\n",
            "Worker 2, [03/37]: Training Loss: 2.710487451, Training Accuracy: 31.192\n",
            "Worker 2, [04/37]: Training Loss: 2.625819713, Training Accuracy: 33.424\n",
            "Worker 2, [05/37]: Training Loss: 3.339203199, Training Accuracy: 24.892\n",
            "Worker 2, [06/37]: Training Loss: 3.036164268, Training Accuracy: 25.852\n",
            "Worker 2, [07/37]: Training Loss: 2.926297863, Training Accuracy: 27.612\n",
            "Worker 2, [08/37]: Training Loss: 2.844186385, Training Accuracy: 28.660\n",
            "Worker 2, [09/37]: Training Loss: 3.081042555, Training Accuracy: 25.484\n",
            "Worker 2, [10/37]: Training Loss: 2.876316221, Training Accuracy: 28.172\n",
            "Worker 2, [11/37]: Training Loss: 2.796635517, Training Accuracy: 29.308\n",
            "Worker 2, [12/37]: Training Loss: 2.729640677, Training Accuracy: 30.700\n",
            "Worker 2, [13/37]: Training Loss: 3.005962200, Training Accuracy: 26.196\n",
            "Worker 2, [14/37]: Training Loss: 2.830676650, Training Accuracy: 28.656\n",
            "Worker 2, [15/37]: Training Loss: 2.748054983, Training Accuracy: 30.220\n",
            "Worker 2, [16/37]: Training Loss: 2.693911083, Training Accuracy: 31.404\n",
            "Worker 2, [17/37]: Training Loss: 2.973164375, Training Accuracy: 26.128\n",
            "Worker 2, [18/37]: Training Loss: 2.817881736, Training Accuracy: 28.856\n",
            "Worker 2, [19/37]: Training Loss: 2.711569292, Training Accuracy: 30.904\n",
            "Worker 2, [20/37]: Training Loss: 2.658989550, Training Accuracy: 31.856\n",
            "Worker 2, [21/37]: Training Loss: 2.961266054, Training Accuracy: 25.808\n",
            "Worker 2, [22/37]: Training Loss: 2.802759976, Training Accuracy: 29.072\n",
            "Worker 2, [23/37]: Training Loss: 2.713072562, Training Accuracy: 30.596\n",
            "Worker 2, [24/37]: Training Loss: 2.649229007, Training Accuracy: 31.904\n",
            "Worker 2, [25/37]: Training Loss: 2.954165884, Training Accuracy: 26.736\n",
            "Worker 2, [26/37]: Training Loss: 2.795656502, Training Accuracy: 29.116\n",
            "Worker 2, [27/37]: Training Loss: 2.702237903, Training Accuracy: 30.892\n",
            "Worker 2, [28/37]: Training Loss: 2.627564292, Training Accuracy: 32.344\n",
            "Worker 2, [29/37]: Training Loss: 2.930956515, Training Accuracy: 26.736\n",
            "Worker 2, [30/37]: Training Loss: 2.787574518, Training Accuracy: 29.196\n",
            "Worker 2, [31/37]: Training Loss: 2.702055712, Training Accuracy: 30.824\n",
            "Worker 2, [32/37]: Training Loss: 2.606662373, Training Accuracy: 32.856\n",
            "Worker 2, [33/37]: Training Loss: 2.909996741, Training Accuracy: 26.748\n",
            "Worker 2, [34/37]: Training Loss: 2.743193254, Training Accuracy: 29.936\n",
            "Worker 2, [35/37]: Training Loss: 2.666534995, Training Accuracy: 31.620\n",
            "Worker 2, [36/37]: Training Loss: 2.576813118, Training Accuracy: 33.580\n",
            "Worker 2, [37/37]: Training Loss: 2.867939625, Training Accuracy: 27.436\n",
            "Time taken for training worker 2: 0:06:15.524322\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000576\n",
            "Local Step 02: Test Loss: 2.808876964, Test Accuracy: 29.730\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.863615417, Training Accuracy: 27.944\n",
            "Worker 1, [02/37]: Training Loss: 2.708054910, Training Accuracy: 31.312\n",
            "Worker 1, [03/37]: Training Loss: 2.611481867, Training Accuracy: 33.484\n",
            "Worker 1, [04/37]: Training Loss: 2.533323985, Training Accuracy: 34.656\n",
            "Worker 1, [05/37]: Training Loss: 2.823488797, Training Accuracy: 28.564\n",
            "Worker 1, [06/37]: Training Loss: 2.692957374, Training Accuracy: 31.348\n",
            "Worker 1, [07/37]: Training Loss: 2.574327067, Training Accuracy: 33.484\n",
            "Worker 1, [08/37]: Training Loss: 2.509317933, Training Accuracy: 34.972\n",
            "Worker 1, [09/37]: Training Loss: 2.744970594, Training Accuracy: 30.376\n",
            "Worker 1, [10/37]: Training Loss: 2.609781433, Training Accuracy: 32.700\n",
            "Worker 1, [11/37]: Training Loss: 2.507917851, Training Accuracy: 35.076\n",
            "Worker 1, [12/37]: Training Loss: 2.414044523, Training Accuracy: 36.872\n",
            "Worker 1, [13/37]: Training Loss: 2.658508037, Training Accuracy: 31.728\n",
            "Worker 1, [14/37]: Training Loss: 2.524609600, Training Accuracy: 34.724\n",
            "Worker 1, [15/37]: Training Loss: 2.429047568, Training Accuracy: 36.336\n",
            "Worker 1, [16/37]: Training Loss: 2.333326237, Training Accuracy: 38.492\n",
            "Worker 1, [17/37]: Training Loss: 2.547748425, Training Accuracy: 34.328\n",
            "Worker 1, [18/37]: Training Loss: 2.423864871, Training Accuracy: 36.956\n",
            "Worker 1, [19/37]: Training Loss: 2.328537859, Training Accuracy: 38.740\n",
            "Worker 1, [20/37]: Training Loss: 2.246380566, Training Accuracy: 40.336\n",
            "Worker 1, [21/37]: Training Loss: 2.417902978, Training Accuracy: 36.868\n",
            "Worker 1, [22/37]: Training Loss: 2.311036432, Training Accuracy: 39.108\n",
            "Worker 1, [23/37]: Training Loss: 2.232484384, Training Accuracy: 41.220\n",
            "Worker 1, [24/37]: Training Loss: 2.149999786, Training Accuracy: 42.580\n",
            "Worker 1, [25/37]: Training Loss: 2.315069100, Training Accuracy: 39.040\n",
            "Worker 1, [26/37]: Training Loss: 2.207335889, Training Accuracy: 41.748\n",
            "Worker 1, [27/37]: Training Loss: 2.140980448, Training Accuracy: 43.044\n",
            "Worker 1, [28/37]: Training Loss: 2.078705690, Training Accuracy: 44.492\n",
            "Worker 1, [29/37]: Training Loss: 2.227920484, Training Accuracy: 41.528\n",
            "Worker 1, [30/37]: Training Loss: 2.142639958, Training Accuracy: 43.044\n",
            "Worker 1, [31/37]: Training Loss: 2.087241782, Training Accuracy: 44.560\n",
            "Worker 1, [32/37]: Training Loss: 2.038715290, Training Accuracy: 45.588\n",
            "Worker 1, [33/37]: Training Loss: 2.184914174, Training Accuracy: 42.888\n",
            "Worker 1, [34/37]: Training Loss: 2.124722608, Training Accuracy: 43.564\n",
            "Worker 1, [35/37]: Training Loss: 2.092757401, Training Accuracy: 44.640\n",
            "Worker 1, [36/37]: Training Loss: 2.080830646, Training Accuracy: 44.532\n",
            "Worker 1, [37/37]: Training Loss: 2.304325525, Training Accuracy: 43.208\n",
            "Time taken for training worker 1: 0:06:16.860386\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.781935250, Training Accuracy: 29.832\n",
            "Worker 2, [02/37]: Training Loss: 2.660907302, Training Accuracy: 32.536\n",
            "Worker 2, [03/37]: Training Loss: 2.549341113, Training Accuracy: 34.072\n",
            "Worker 2, [04/37]: Training Loss: 2.468274607, Training Accuracy: 35.904\n",
            "Worker 2, [05/37]: Training Loss: 2.820293114, Training Accuracy: 29.176\n",
            "Worker 2, [06/37]: Training Loss: 2.691988934, Training Accuracy: 31.080\n",
            "Worker 2, [07/37]: Training Loss: 2.587137458, Training Accuracy: 33.276\n",
            "Worker 2, [08/37]: Training Loss: 2.491640087, Training Accuracy: 35.616\n",
            "Worker 2, [09/37]: Training Loss: 2.744679435, Training Accuracy: 30.348\n",
            "Worker 2, [10/37]: Training Loss: 2.598480878, Training Accuracy: 32.888\n",
            "Worker 2, [11/37]: Training Loss: 2.507409729, Training Accuracy: 35.224\n",
            "Worker 2, [12/37]: Training Loss: 2.406789866, Training Accuracy: 36.800\n",
            "Worker 2, [13/37]: Training Loss: 2.646923506, Training Accuracy: 31.964\n",
            "Worker 2, [14/37]: Training Loss: 2.510398246, Training Accuracy: 34.688\n",
            "Worker 2, [15/37]: Training Loss: 2.417883216, Training Accuracy: 36.516\n",
            "Worker 2, [16/37]: Training Loss: 2.332957618, Training Accuracy: 38.640\n",
            "Worker 2, [17/37]: Training Loss: 2.539675981, Training Accuracy: 34.220\n",
            "Worker 2, [18/37]: Training Loss: 2.416870261, Training Accuracy: 37.004\n",
            "Worker 2, [19/37]: Training Loss: 2.334394941, Training Accuracy: 38.792\n",
            "Worker 2, [20/37]: Training Loss: 2.256462429, Training Accuracy: 40.312\n",
            "Worker 2, [21/37]: Training Loss: 2.422779013, Training Accuracy: 36.988\n",
            "Worker 2, [22/37]: Training Loss: 2.310750821, Training Accuracy: 39.044\n",
            "Worker 2, [23/37]: Training Loss: 2.231869284, Training Accuracy: 40.696\n",
            "Worker 2, [24/37]: Training Loss: 2.139256116, Training Accuracy: 42.908\n",
            "Worker 2, [25/37]: Training Loss: 2.312757293, Training Accuracy: 39.548\n",
            "Worker 2, [26/37]: Training Loss: 2.221423721, Training Accuracy: 41.456\n",
            "Worker 2, [27/37]: Training Loss: 2.140983054, Training Accuracy: 43.004\n",
            "Worker 2, [28/37]: Training Loss: 2.086200829, Training Accuracy: 44.192\n",
            "Worker 2, [29/37]: Training Loss: 2.229470950, Training Accuracy: 41.556\n",
            "Worker 2, [30/37]: Training Loss: 2.144821015, Training Accuracy: 43.464\n",
            "Worker 2, [31/37]: Training Loss: 2.090704212, Training Accuracy: 44.076\n",
            "Worker 2, [32/37]: Training Loss: 2.045971079, Training Accuracy: 45.268\n",
            "Worker 2, [33/37]: Training Loss: 2.188164684, Training Accuracy: 42.836\n",
            "Worker 2, [34/37]: Training Loss: 2.122467259, Training Accuracy: 43.912\n",
            "Worker 2, [35/37]: Training Loss: 2.098002455, Training Accuracy: 44.144\n",
            "Worker 2, [36/37]: Training Loss: 2.077486801, Training Accuracy: 44.772\n",
            "Worker 2, [37/37]: Training Loss: 2.303427675, Training Accuracy: 43.532\n",
            "Time taken for training worker 2: 0:06:18.295502\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000557\n",
            "Local Step 03: Test Loss: 2.335288287, Test Accuracy: 41.200\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.493785415, Training Accuracy: 37.644\n",
            "Worker 1, [02/37]: Training Loss: 2.476346074, Training Accuracy: 37.560\n",
            "Worker 1, [03/37]: Training Loss: 2.432890659, Training Accuracy: 38.044\n",
            "Worker 1, [04/37]: Training Loss: 2.397333447, Training Accuracy: 38.312\n",
            "Worker 1, [05/37]: Training Loss: 2.223191589, Training Accuracy: 42.260\n",
            "Worker 1, [06/37]: Training Loss: 2.159078309, Training Accuracy: 42.688\n",
            "Worker 1, [07/37]: Training Loss: 2.144349919, Training Accuracy: 43.348\n",
            "Worker 1, [08/37]: Training Loss: 2.135504958, Training Accuracy: 43.368\n",
            "Worker 1, [09/37]: Training Loss: 2.205360837, Training Accuracy: 42.004\n",
            "Worker 1, [10/37]: Training Loss: 2.167727116, Training Accuracy: 42.664\n",
            "Worker 1, [11/37]: Training Loss: 2.149499417, Training Accuracy: 42.836\n",
            "Worker 1, [12/37]: Training Loss: 2.136901249, Training Accuracy: 43.524\n",
            "Worker 1, [13/37]: Training Loss: 2.255201642, Training Accuracy: 40.744\n",
            "Worker 1, [14/37]: Training Loss: 2.216065363, Training Accuracy: 41.112\n",
            "Worker 1, [15/37]: Training Loss: 2.205731493, Training Accuracy: 41.392\n",
            "Worker 1, [16/37]: Training Loss: 2.173562329, Training Accuracy: 42.076\n",
            "Worker 1, [17/37]: Training Loss: 2.316748236, Training Accuracy: 39.312\n",
            "Worker 1, [18/37]: Training Loss: 2.279728571, Training Accuracy: 39.648\n",
            "Worker 1, [19/37]: Training Loss: 2.254727792, Training Accuracy: 40.224\n",
            "Worker 1, [20/37]: Training Loss: 2.216571212, Training Accuracy: 41.124\n",
            "Worker 1, [21/37]: Training Loss: 2.369039165, Training Accuracy: 38.004\n",
            "Worker 1, [22/37]: Training Loss: 2.338674577, Training Accuracy: 38.604\n",
            "Worker 1, [23/37]: Training Loss: 2.303724857, Training Accuracy: 39.124\n",
            "Worker 1, [24/37]: Training Loss: 2.269682537, Training Accuracy: 40.136\n",
            "Worker 1, [25/37]: Training Loss: 2.422342985, Training Accuracy: 36.676\n",
            "Worker 1, [26/37]: Training Loss: 2.384597591, Training Accuracy: 37.256\n",
            "Worker 1, [27/37]: Training Loss: 2.333045804, Training Accuracy: 38.604\n",
            "Worker 1, [28/37]: Training Loss: 2.284841943, Training Accuracy: 39.608\n",
            "Worker 1, [29/37]: Training Loss: 2.469834158, Training Accuracy: 36.020\n",
            "Worker 1, [30/37]: Training Loss: 2.417184321, Training Accuracy: 36.784\n",
            "Worker 1, [31/37]: Training Loss: 2.347715413, Training Accuracy: 38.660\n",
            "Worker 1, [32/37]: Training Loss: 2.294257196, Training Accuracy: 39.404\n",
            "Worker 1, [33/37]: Training Loss: 2.459774177, Training Accuracy: 35.896\n",
            "Worker 1, [34/37]: Training Loss: 2.416753384, Training Accuracy: 36.856\n",
            "Worker 1, [35/37]: Training Loss: 2.365907373, Training Accuracy: 37.964\n",
            "Worker 1, [36/37]: Training Loss: 2.285093181, Training Accuracy: 39.244\n",
            "Worker 1, [37/37]: Training Loss: 2.446362711, Training Accuracy: 35.852\n",
            "Time taken for training worker 1: 0:06:16.862110\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.721732450, Training Accuracy: 31.412\n",
            "Worker 2, [02/37]: Training Loss: 2.625226256, Training Accuracy: 33.052\n",
            "Worker 2, [03/37]: Training Loss: 2.505066948, Training Accuracy: 35.508\n",
            "Worker 2, [04/37]: Training Loss: 2.416328882, Training Accuracy: 37.840\n",
            "Worker 2, [05/37]: Training Loss: 2.214417862, Training Accuracy: 42.580\n",
            "Worker 2, [06/37]: Training Loss: 2.147400342, Training Accuracy: 43.220\n",
            "Worker 2, [07/37]: Training Loss: 2.129947473, Training Accuracy: 43.508\n",
            "Worker 2, [08/37]: Training Loss: 2.118474812, Training Accuracy: 43.800\n",
            "Worker 2, [09/37]: Training Loss: 2.195485092, Training Accuracy: 42.144\n",
            "Worker 2, [10/37]: Training Loss: 2.163194697, Training Accuracy: 42.816\n",
            "Worker 2, [11/37]: Training Loss: 2.139099603, Training Accuracy: 42.900\n",
            "Worker 2, [12/37]: Training Loss: 2.113125979, Training Accuracy: 43.924\n",
            "Worker 2, [13/37]: Training Loss: 2.232132306, Training Accuracy: 41.412\n",
            "Worker 2, [14/37]: Training Loss: 2.207616738, Training Accuracy: 41.588\n",
            "Worker 2, [15/37]: Training Loss: 2.191781427, Training Accuracy: 41.516\n",
            "Worker 2, [16/37]: Training Loss: 2.154783451, Training Accuracy: 42.704\n",
            "Worker 2, [17/37]: Training Loss: 2.305965992, Training Accuracy: 39.388\n",
            "Worker 2, [18/37]: Training Loss: 2.267262838, Training Accuracy: 39.848\n",
            "Worker 2, [19/37]: Training Loss: 2.254355387, Training Accuracy: 40.068\n",
            "Worker 2, [20/37]: Training Loss: 2.214843408, Training Accuracy: 41.176\n",
            "Worker 2, [21/37]: Training Loss: 2.365106427, Training Accuracy: 37.976\n",
            "Worker 2, [22/37]: Training Loss: 2.322553986, Training Accuracy: 38.644\n",
            "Worker 2, [23/37]: Training Loss: 2.294407799, Training Accuracy: 39.460\n",
            "Worker 2, [24/37]: Training Loss: 2.260361494, Training Accuracy: 40.260\n",
            "Worker 2, [25/37]: Training Loss: 2.423499913, Training Accuracy: 36.848\n",
            "Worker 2, [26/37]: Training Loss: 2.371887459, Training Accuracy: 37.576\n",
            "Worker 2, [27/37]: Training Loss: 2.315721638, Training Accuracy: 39.220\n",
            "Worker 2, [28/37]: Training Loss: 2.275295915, Training Accuracy: 39.848\n",
            "Worker 2, [29/37]: Training Loss: 2.450435601, Training Accuracy: 35.836\n",
            "Worker 2, [30/37]: Training Loss: 2.412655336, Training Accuracy: 36.812\n",
            "Worker 2, [31/37]: Training Loss: 2.364813335, Training Accuracy: 37.264\n",
            "Worker 2, [32/37]: Training Loss: 2.295554417, Training Accuracy: 39.716\n",
            "Worker 2, [33/37]: Training Loss: 2.458509783, Training Accuracy: 35.972\n",
            "Worker 2, [34/37]: Training Loss: 2.419163641, Training Accuracy: 37.016\n",
            "Worker 2, [35/37]: Training Loss: 2.342202658, Training Accuracy: 38.596\n",
            "Worker 2, [36/37]: Training Loss: 2.297981234, Training Accuracy: 39.716\n",
            "Worker 2, [37/37]: Training Loss: 2.465495065, Training Accuracy: 35.836\n",
            "Time taken for training worker 2: 0:06:18.194177\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000610\n",
            "Local Step 04: Test Loss: 2.441934321, Test Accuracy: 37.100\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:50:31.235520\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.336164176, Training Accuracy: 4.156\n",
            "Worker 1, [02/37]: Training Loss: 3.863825872, Training Accuracy: 10.224\n",
            "Worker 1, [03/37]: Training Loss: 3.599051418, Training Accuracy: 14.760\n",
            "Worker 1, [04/37]: Training Loss: 3.390925595, Training Accuracy: 18.096\n",
            "Worker 1, [05/37]: Training Loss: 3.217999130, Training Accuracy: 20.856\n",
            "Worker 1, [06/37]: Training Loss: 3.068650035, Training Accuracy: 23.604\n",
            "Worker 1, [07/37]: Training Loss: 2.946057629, Training Accuracy: 26.128\n",
            "Worker 1, [08/37]: Training Loss: 2.826742550, Training Accuracy: 28.328\n",
            "Worker 1, [09/37]: Training Loss: 4.064722962, Training Accuracy: 7.820\n",
            "Worker 1, [10/37]: Training Loss: 3.504143975, Training Accuracy: 16.188\n",
            "Worker 1, [11/37]: Training Loss: 3.190454055, Training Accuracy: 21.328\n",
            "Worker 1, [12/37]: Training Loss: 2.986417219, Training Accuracy: 25.552\n",
            "Worker 1, [13/37]: Training Loss: 2.821683412, Training Accuracy: 28.896\n",
            "Worker 1, [14/37]: Training Loss: 2.714264554, Training Accuracy: 30.572\n",
            "Worker 1, [15/37]: Training Loss: 2.612299539, Training Accuracy: 32.844\n",
            "Worker 1, [16/37]: Training Loss: 2.535490089, Training Accuracy: 34.168\n",
            "Worker 1, [17/37]: Training Loss: 3.817127323, Training Accuracy: 11.976\n",
            "Worker 1, [18/37]: Training Loss: 3.178972549, Training Accuracy: 21.812\n",
            "Worker 1, [19/37]: Training Loss: 2.914408004, Training Accuracy: 26.620\n",
            "Worker 1, [20/37]: Training Loss: 2.750498098, Training Accuracy: 29.860\n",
            "Worker 1, [21/37]: Training Loss: 2.629230729, Training Accuracy: 32.660\n",
            "Worker 1, [22/37]: Training Loss: 2.539361228, Training Accuracy: 34.192\n",
            "Worker 1, [23/37]: Training Loss: 2.453463168, Training Accuracy: 35.968\n",
            "Worker 1, [24/37]: Training Loss: 2.376838946, Training Accuracy: 37.608\n",
            "Worker 1, [25/37]: Training Loss: 3.734440022, Training Accuracy: 14.500\n",
            "Worker 1, [26/37]: Training Loss: 3.090622124, Training Accuracy: 23.744\n",
            "Worker 1, [27/37]: Training Loss: 2.857859736, Training Accuracy: 28.248\n",
            "Worker 1, [28/37]: Training Loss: 2.722578358, Training Accuracy: 30.936\n",
            "Worker 1, [29/37]: Training Loss: 2.629856311, Training Accuracy: 32.756\n",
            "Worker 1, [30/37]: Training Loss: 2.547704136, Training Accuracy: 34.536\n",
            "Worker 1, [31/37]: Training Loss: 2.488381404, Training Accuracy: 35.908\n",
            "Worker 1, [32/37]: Training Loss: 2.443828923, Training Accuracy: 36.804\n",
            "Worker 1, [33/37]: Training Loss: 4.065334255, Training Accuracy: 15.384\n",
            "Worker 1, [34/37]: Training Loss: 3.546522464, Training Accuracy: 18.136\n",
            "Worker 1, [35/37]: Training Loss: 3.380266045, Training Accuracy: 20.488\n",
            "Worker 1, [36/37]: Training Loss: 3.309662279, Training Accuracy: 21.792\n",
            "Worker 1, [37/37]: Training Loss: 3.284635519, Training Accuracy: 22.252\n",
            "Time taken for training worker 1: 0:06:15.940494\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.326408117, Training Accuracy: 4.404\n",
            "Worker 2, [02/37]: Training Loss: 3.859819384, Training Accuracy: 9.840\n",
            "Worker 2, [03/37]: Training Loss: 3.597305981, Training Accuracy: 13.908\n",
            "Worker 2, [04/37]: Training Loss: 3.383986790, Training Accuracy: 17.924\n",
            "Worker 2, [05/37]: Training Loss: 3.230997325, Training Accuracy: 20.960\n",
            "Worker 2, [06/37]: Training Loss: 3.092668892, Training Accuracy: 23.452\n",
            "Worker 2, [07/37]: Training Loss: 2.970206077, Training Accuracy: 25.712\n",
            "Worker 2, [08/37]: Training Loss: 2.862808389, Training Accuracy: 28.108\n",
            "Worker 2, [09/37]: Training Loss: 4.089487358, Training Accuracy: 7.492\n",
            "Worker 2, [10/37]: Training Loss: 3.531370977, Training Accuracy: 15.392\n",
            "Worker 2, [11/37]: Training Loss: 3.245755137, Training Accuracy: 20.428\n",
            "Worker 2, [12/37]: Training Loss: 3.052063756, Training Accuracy: 24.084\n",
            "Worker 2, [13/37]: Training Loss: 2.903557662, Training Accuracy: 26.580\n",
            "Worker 2, [14/37]: Training Loss: 2.778715524, Training Accuracy: 29.484\n",
            "Worker 2, [15/37]: Training Loss: 2.667770556, Training Accuracy: 31.768\n",
            "Worker 2, [16/37]: Training Loss: 2.575258632, Training Accuracy: 33.556\n",
            "Worker 2, [17/37]: Training Loss: 3.848159469, Training Accuracy: 11.316\n",
            "Worker 2, [18/37]: Training Loss: 3.233219742, Training Accuracy: 20.808\n",
            "Worker 2, [19/37]: Training Loss: 2.962351069, Training Accuracy: 25.884\n",
            "Worker 2, [20/37]: Training Loss: 2.793918411, Training Accuracy: 28.904\n",
            "Worker 2, [21/37]: Training Loss: 2.674155823, Training Accuracy: 31.536\n",
            "Worker 2, [22/37]: Training Loss: 2.578213275, Training Accuracy: 33.620\n",
            "Worker 2, [23/37]: Training Loss: 2.490336933, Training Accuracy: 35.356\n",
            "Worker 2, [24/37]: Training Loss: 2.405488694, Training Accuracy: 36.864\n",
            "Worker 2, [25/37]: Training Loss: 3.721003470, Training Accuracy: 14.324\n",
            "Worker 2, [26/37]: Training Loss: 3.121023981, Training Accuracy: 23.492\n",
            "Worker 2, [27/37]: Training Loss: 2.891535653, Training Accuracy: 27.452\n",
            "Worker 2, [28/37]: Training Loss: 2.749470577, Training Accuracy: 30.368\n",
            "Worker 2, [29/37]: Training Loss: 2.646190195, Training Accuracy: 32.452\n",
            "Worker 2, [30/37]: Training Loss: 2.573171658, Training Accuracy: 33.968\n",
            "Worker 2, [31/37]: Training Loss: 2.505280525, Training Accuracy: 35.516\n",
            "Worker 2, [32/37]: Training Loss: 2.463769364, Training Accuracy: 36.588\n",
            "Worker 2, [33/37]: Training Loss: 4.067228903, Training Accuracy: 14.764\n",
            "Worker 2, [34/37]: Training Loss: 3.567753356, Training Accuracy: 17.560\n",
            "Worker 2, [35/37]: Training Loss: 3.409169668, Training Accuracy: 19.936\n",
            "Worker 2, [36/37]: Training Loss: 3.334759847, Training Accuracy: 20.768\n",
            "Worker 2, [37/37]: Training Loss: 3.305401920, Training Accuracy: 21.668\n",
            "Time taken for training worker 2: 0:06:25.079754\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000591\n",
            "Local Step 01: Test Loss: 3.411057958, Test Accuracy: 20.730\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.478239785, Training Accuracy: 18.552\n",
            "Worker 1, [02/37]: Training Loss: 3.459080236, Training Accuracy: 19.540\n",
            "Worker 1, [03/37]: Training Loss: 3.435318156, Training Accuracy: 19.964\n",
            "Worker 1, [04/37]: Training Loss: 3.378919648, Training Accuracy: 20.424\n",
            "Worker 1, [05/37]: Training Loss: 3.307896864, Training Accuracy: 21.204\n",
            "Worker 1, [06/37]: Training Loss: 3.208803293, Training Accuracy: 22.220\n",
            "Worker 1, [07/37]: Training Loss: 3.106388399, Training Accuracy: 24.116\n",
            "Worker 1, [08/37]: Training Loss: 3.016822020, Training Accuracy: 25.148\n",
            "Worker 1, [09/37]: Training Loss: 3.605347603, Training Accuracy: 18.444\n",
            "Worker 1, [10/37]: Training Loss: 3.089999498, Training Accuracy: 24.236\n",
            "Worker 1, [11/37]: Training Loss: 2.895856335, Training Accuracy: 27.576\n",
            "Worker 1, [12/37]: Training Loss: 2.794546169, Training Accuracy: 29.200\n",
            "Worker 1, [13/37]: Training Loss: 2.707194486, Training Accuracy: 30.792\n",
            "Worker 1, [14/37]: Training Loss: 2.630132290, Training Accuracy: 32.328\n",
            "Worker 1, [15/37]: Training Loss: 2.581914982, Training Accuracy: 33.504\n",
            "Worker 1, [16/37]: Training Loss: 2.533407784, Training Accuracy: 34.524\n",
            "Worker 1, [17/37]: Training Loss: 3.194995008, Training Accuracy: 22.588\n",
            "Worker 1, [18/37]: Training Loss: 2.818899910, Training Accuracy: 28.696\n",
            "Worker 1, [19/37]: Training Loss: 2.706615270, Training Accuracy: 30.596\n",
            "Worker 1, [20/37]: Training Loss: 2.610618992, Training Accuracy: 32.652\n",
            "Worker 1, [21/37]: Training Loss: 2.552801235, Training Accuracy: 33.864\n",
            "Worker 1, [22/37]: Training Loss: 2.497515383, Training Accuracy: 35.000\n",
            "Worker 1, [23/37]: Training Loss: 2.454350596, Training Accuracy: 35.892\n",
            "Worker 1, [24/37]: Training Loss: 2.393968284, Training Accuracy: 37.168\n",
            "Worker 1, [25/37]: Training Loss: 3.064995944, Training Accuracy: 24.604\n",
            "Worker 1, [26/37]: Training Loss: 2.771887096, Training Accuracy: 29.504\n",
            "Worker 1, [27/37]: Training Loss: 2.656857410, Training Accuracy: 31.632\n",
            "Worker 1, [28/37]: Training Loss: 2.574504027, Training Accuracy: 33.592\n",
            "Worker 1, [29/37]: Training Loss: 2.491804253, Training Accuracy: 35.220\n",
            "Worker 1, [30/37]: Training Loss: 2.430749197, Training Accuracy: 36.580\n",
            "Worker 1, [31/37]: Training Loss: 2.389649196, Training Accuracy: 37.572\n",
            "Worker 1, [32/37]: Training Loss: 2.337056681, Training Accuracy: 38.888\n",
            "Worker 1, [33/37]: Training Loss: 2.982827853, Training Accuracy: 25.928\n",
            "Worker 1, [34/37]: Training Loss: 2.714077447, Training Accuracy: 30.820\n",
            "Worker 1, [35/37]: Training Loss: 2.591209742, Training Accuracy: 33.460\n",
            "Worker 1, [36/37]: Training Loss: 2.513839640, Training Accuracy: 34.696\n",
            "Worker 1, [37/37]: Training Loss: 2.431799531, Training Accuracy: 36.552\n",
            "Time taken for training worker 1: 0:06:27.479056\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.650145328, Training Accuracy: 32.556\n",
            "Worker 2, [02/37]: Training Loss: 2.594502703, Training Accuracy: 33.428\n",
            "Worker 2, [03/37]: Training Loss: 2.496476952, Training Accuracy: 35.412\n",
            "Worker 2, [04/37]: Training Loss: 2.420213169, Training Accuracy: 37.440\n",
            "Worker 2, [05/37]: Training Loss: 2.372828706, Training Accuracy: 38.316\n",
            "Worker 2, [06/37]: Training Loss: 2.331088473, Training Accuracy: 39.604\n",
            "Worker 2, [07/37]: Training Loss: 2.285994681, Training Accuracy: 40.452\n",
            "Worker 2, [08/37]: Training Loss: 2.250194236, Training Accuracy: 41.380\n",
            "Worker 2, [09/37]: Training Loss: 3.627706197, Training Accuracy: 18.040\n",
            "Worker 2, [10/37]: Training Loss: 3.079660881, Training Accuracy: 24.268\n",
            "Worker 2, [11/37]: Training Loss: 2.871942082, Training Accuracy: 28.236\n",
            "Worker 2, [12/37]: Training Loss: 2.765451764, Training Accuracy: 29.952\n",
            "Worker 2, [13/37]: Training Loss: 2.682713735, Training Accuracy: 31.728\n",
            "Worker 2, [14/37]: Training Loss: 2.620014113, Training Accuracy: 32.704\n",
            "Worker 2, [15/37]: Training Loss: 2.577016940, Training Accuracy: 33.848\n",
            "Worker 2, [16/37]: Training Loss: 2.530275843, Training Accuracy: 34.576\n",
            "Worker 2, [17/37]: Training Loss: 3.189249232, Training Accuracy: 22.820\n",
            "Worker 2, [18/37]: Training Loss: 2.811104335, Training Accuracy: 28.520\n",
            "Worker 2, [19/37]: Training Loss: 2.689802809, Training Accuracy: 31.176\n",
            "Worker 2, [20/37]: Training Loss: 2.615174287, Training Accuracy: 32.896\n",
            "Worker 2, [21/37]: Training Loss: 2.553717891, Training Accuracy: 34.176\n",
            "Worker 2, [22/37]: Training Loss: 2.493694761, Training Accuracy: 34.760\n",
            "Worker 2, [23/37]: Training Loss: 2.448649932, Training Accuracy: 36.000\n",
            "Worker 2, [24/37]: Training Loss: 2.387281487, Training Accuracy: 37.824\n",
            "Worker 2, [25/37]: Training Loss: 3.048781050, Training Accuracy: 24.720\n",
            "Worker 2, [26/37]: Training Loss: 2.759965017, Training Accuracy: 29.664\n",
            "Worker 2, [27/37]: Training Loss: 2.636657678, Training Accuracy: 32.520\n",
            "Worker 2, [28/37]: Training Loss: 2.548719845, Training Accuracy: 34.220\n",
            "Worker 2, [29/37]: Training Loss: 2.482661981, Training Accuracy: 35.596\n",
            "Worker 2, [30/37]: Training Loss: 2.444508730, Training Accuracy: 36.624\n",
            "Worker 2, [31/37]: Training Loss: 2.370920229, Training Accuracy: 38.192\n",
            "Worker 2, [32/37]: Training Loss: 2.330910016, Training Accuracy: 38.488\n",
            "Worker 2, [33/37]: Training Loss: 2.979869039, Training Accuracy: 26.016\n",
            "Worker 2, [34/37]: Training Loss: 2.699718901, Training Accuracy: 30.936\n",
            "Worker 2, [35/37]: Training Loss: 2.581330713, Training Accuracy: 33.136\n",
            "Worker 2, [36/37]: Training Loss: 2.507621111, Training Accuracy: 34.700\n",
            "Worker 2, [37/37]: Training Loss: 2.424821655, Training Accuracy: 37.000\n",
            "Time taken for training worker 2: 0:06:34.077289\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000696\n",
            "Local Step 02: Test Loss: 2.468014016, Test Accuracy: 37.000\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.610999773, Training Accuracy: 33.840\n",
            "Worker 1, [02/37]: Training Loss: 2.471710144, Training Accuracy: 36.644\n",
            "Worker 1, [03/37]: Training Loss: 2.374479712, Training Accuracy: 38.256\n",
            "Worker 1, [04/37]: Training Loss: 2.298677284, Training Accuracy: 39.600\n",
            "Worker 1, [05/37]: Training Loss: 2.237709116, Training Accuracy: 40.996\n",
            "Worker 1, [06/37]: Training Loss: 2.175899191, Training Accuracy: 41.912\n",
            "Worker 1, [07/37]: Training Loss: 2.115654554, Training Accuracy: 43.972\n",
            "Worker 1, [08/37]: Training Loss: 2.064448581, Training Accuracy: 44.620\n",
            "Worker 1, [09/37]: Training Loss: 2.921007050, Training Accuracy: 27.268\n",
            "Worker 1, [10/37]: Training Loss: 2.648174172, Training Accuracy: 32.080\n",
            "Worker 1, [11/37]: Training Loss: 2.529572381, Training Accuracy: 34.480\n",
            "Worker 1, [12/37]: Training Loss: 2.411046550, Training Accuracy: 36.936\n",
            "Worker 1, [13/37]: Training Loss: 2.308380522, Training Accuracy: 39.172\n",
            "Worker 1, [14/37]: Training Loss: 2.219781917, Training Accuracy: 41.112\n",
            "Worker 1, [15/37]: Training Loss: 2.138213311, Training Accuracy: 42.928\n",
            "Worker 1, [16/37]: Training Loss: 2.079636285, Training Accuracy: 44.068\n",
            "Worker 1, [17/37]: Training Loss: 2.730844426, Training Accuracy: 31.068\n",
            "Worker 1, [18/37]: Training Loss: 2.484623763, Training Accuracy: 35.468\n",
            "Worker 1, [19/37]: Training Loss: 2.341567340, Training Accuracy: 38.320\n",
            "Worker 1, [20/37]: Training Loss: 2.249780186, Training Accuracy: 40.656\n",
            "Worker 1, [21/37]: Training Loss: 2.153552690, Training Accuracy: 42.644\n",
            "Worker 1, [22/37]: Training Loss: 2.061362932, Training Accuracy: 44.464\n",
            "Worker 1, [23/37]: Training Loss: 1.994419502, Training Accuracy: 46.432\n",
            "Worker 1, [24/37]: Training Loss: 1.922923265, Training Accuracy: 47.792\n",
            "Worker 1, [25/37]: Training Loss: 2.547270188, Training Accuracy: 35.288\n",
            "Worker 1, [26/37]: Training Loss: 2.317467542, Training Accuracy: 39.252\n",
            "Worker 1, [27/37]: Training Loss: 2.207256957, Training Accuracy: 41.848\n",
            "Worker 1, [28/37]: Training Loss: 2.133282467, Training Accuracy: 43.252\n",
            "Worker 1, [29/37]: Training Loss: 2.049117229, Training Accuracy: 45.080\n",
            "Worker 1, [30/37]: Training Loss: 1.992911010, Training Accuracy: 46.448\n",
            "Worker 1, [31/37]: Training Loss: 1.934859732, Training Accuracy: 48.056\n",
            "Worker 1, [32/37]: Training Loss: 1.904542398, Training Accuracy: 48.688\n",
            "Worker 1, [33/37]: Training Loss: 2.600072475, Training Accuracy: 38.012\n",
            "Worker 1, [34/37]: Training Loss: 2.325448027, Training Accuracy: 40.092\n",
            "Worker 1, [35/37]: Training Loss: 2.276858787, Training Accuracy: 40.812\n",
            "Worker 1, [36/37]: Training Loss: 2.249120860, Training Accuracy: 41.672\n",
            "Worker 1, [37/37]: Training Loss: 2.239123703, Training Accuracy: 41.752\n",
            "Time taken for training worker 1: 0:06:26.467477\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.834211292, Training Accuracy: 28.732\n",
            "Worker 2, [02/37]: Training Loss: 2.654310800, Training Accuracy: 32.224\n",
            "Worker 2, [03/37]: Training Loss: 2.527659266, Training Accuracy: 34.976\n",
            "Worker 2, [04/37]: Training Loss: 2.431969121, Training Accuracy: 36.792\n",
            "Worker 2, [05/37]: Training Loss: 2.356795008, Training Accuracy: 38.200\n",
            "Worker 2, [06/37]: Training Loss: 2.272203150, Training Accuracy: 40.208\n",
            "Worker 2, [07/37]: Training Loss: 2.224925661, Training Accuracy: 41.112\n",
            "Worker 2, [08/37]: Training Loss: 2.150608747, Training Accuracy: 42.472\n",
            "Worker 2, [09/37]: Training Loss: 2.866361357, Training Accuracy: 27.752\n",
            "Worker 2, [10/37]: Training Loss: 2.612195558, Training Accuracy: 32.640\n",
            "Worker 2, [11/37]: Training Loss: 2.488581039, Training Accuracy: 35.316\n",
            "Worker 2, [12/37]: Training Loss: 2.394492914, Training Accuracy: 37.508\n",
            "Worker 2, [13/37]: Training Loss: 2.296222232, Training Accuracy: 39.456\n",
            "Worker 2, [14/37]: Training Loss: 2.207814246, Training Accuracy: 41.048\n",
            "Worker 2, [15/37]: Training Loss: 2.138142502, Training Accuracy: 42.924\n",
            "Worker 2, [16/37]: Training Loss: 2.069466802, Training Accuracy: 44.364\n",
            "Worker 2, [17/37]: Training Loss: 2.684330507, Training Accuracy: 31.800\n",
            "Worker 2, [18/37]: Training Loss: 2.438464550, Training Accuracy: 36.416\n",
            "Worker 2, [19/37]: Training Loss: 2.314575927, Training Accuracy: 38.768\n",
            "Worker 2, [20/37]: Training Loss: 2.212624192, Training Accuracy: 41.352\n",
            "Worker 2, [21/37]: Training Loss: 2.123096819, Training Accuracy: 43.276\n",
            "Worker 2, [22/37]: Training Loss: 2.036373067, Training Accuracy: 45.408\n",
            "Worker 2, [23/37]: Training Loss: 1.975592422, Training Accuracy: 46.432\n",
            "Worker 2, [24/37]: Training Loss: 1.896848295, Training Accuracy: 48.104\n",
            "Worker 2, [25/37]: Training Loss: 2.521080091, Training Accuracy: 35.648\n",
            "Worker 2, [26/37]: Training Loss: 2.294512860, Training Accuracy: 39.840\n",
            "Worker 2, [27/37]: Training Loss: 2.174641033, Training Accuracy: 42.504\n",
            "Worker 2, [28/37]: Training Loss: 2.094367994, Training Accuracy: 44.252\n",
            "Worker 2, [29/37]: Training Loss: 2.017360242, Training Accuracy: 45.856\n",
            "Worker 2, [30/37]: Training Loss: 1.960866631, Training Accuracy: 47.200\n",
            "Worker 2, [31/37]: Training Loss: 1.916173412, Training Accuracy: 48.444\n",
            "Worker 2, [32/37]: Training Loss: 1.874580681, Training Accuracy: 49.584\n",
            "Worker 2, [33/37]: Training Loss: 2.571985248, Training Accuracy: 38.172\n",
            "Worker 2, [34/37]: Training Loss: 2.294598523, Training Accuracy: 40.728\n",
            "Worker 2, [35/37]: Training Loss: 2.242068390, Training Accuracy: 41.988\n",
            "Worker 2, [36/37]: Training Loss: 2.218605900, Training Accuracy: 42.152\n",
            "Worker 2, [37/37]: Training Loss: 2.204343269, Training Accuracy: 42.228\n",
            "Time taken for training worker 2: 0:06:20.130886\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000518\n",
            "Local Step 03: Test Loss: 2.237252233, Test Accuracy: 41.950\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.398260711, Training Accuracy: 38.184\n",
            "Worker 1, [02/37]: Training Loss: 2.400962267, Training Accuracy: 38.244\n",
            "Worker 1, [03/37]: Training Loss: 2.390839570, Training Accuracy: 38.672\n",
            "Worker 1, [04/37]: Training Loss: 2.371937371, Training Accuracy: 39.068\n",
            "Worker 1, [05/37]: Training Loss: 2.356780883, Training Accuracy: 39.088\n",
            "Worker 1, [06/37]: Training Loss: 2.338448449, Training Accuracy: 39.536\n",
            "Worker 1, [07/37]: Training Loss: 2.307443863, Training Accuracy: 40.260\n",
            "Worker 1, [08/37]: Training Loss: 2.287733750, Training Accuracy: 40.796\n",
            "Worker 1, [09/37]: Training Loss: 2.468952067, Training Accuracy: 37.680\n",
            "Worker 1, [10/37]: Training Loss: 2.296303340, Training Accuracy: 40.168\n",
            "Worker 1, [11/37]: Training Loss: 2.241172984, Training Accuracy: 40.796\n",
            "Worker 1, [12/37]: Training Loss: 2.197074174, Training Accuracy: 41.696\n",
            "Worker 1, [13/37]: Training Loss: 2.155954251, Training Accuracy: 42.504\n",
            "Worker 1, [14/37]: Training Loss: 2.129963249, Training Accuracy: 43.400\n",
            "Worker 1, [15/37]: Training Loss: 2.107380772, Training Accuracy: 43.840\n",
            "Worker 1, [16/37]: Training Loss: 2.085209373, Training Accuracy: 44.112\n",
            "Worker 1, [17/37]: Training Loss: 2.455004901, Training Accuracy: 36.560\n",
            "Worker 1, [18/37]: Training Loss: 2.304808970, Training Accuracy: 38.984\n",
            "Worker 1, [19/37]: Training Loss: 2.252668523, Training Accuracy: 40.500\n",
            "Worker 1, [20/37]: Training Loss: 2.197571566, Training Accuracy: 41.188\n",
            "Worker 1, [21/37]: Training Loss: 2.148110813, Training Accuracy: 42.692\n",
            "Worker 1, [22/37]: Training Loss: 2.122124451, Training Accuracy: 43.480\n",
            "Worker 1, [23/37]: Training Loss: 2.102887106, Training Accuracy: 43.456\n",
            "Worker 1, [24/37]: Training Loss: 2.083885600, Training Accuracy: 44.100\n",
            "Worker 1, [25/37]: Training Loss: 2.513725900, Training Accuracy: 34.940\n",
            "Worker 1, [26/37]: Training Loss: 2.372797435, Training Accuracy: 37.772\n",
            "Worker 1, [27/37]: Training Loss: 2.310531276, Training Accuracy: 39.528\n",
            "Worker 1, [28/37]: Training Loss: 2.250746642, Training Accuracy: 40.464\n",
            "Worker 1, [29/37]: Training Loss: 2.200894884, Training Accuracy: 41.532\n",
            "Worker 1, [30/37]: Training Loss: 2.154937472, Training Accuracy: 42.600\n",
            "Worker 1, [31/37]: Training Loss: 2.116850511, Training Accuracy: 43.676\n",
            "Worker 1, [32/37]: Training Loss: 2.074563291, Training Accuracy: 44.320\n",
            "Worker 1, [33/37]: Training Loss: 2.508011854, Training Accuracy: 34.972\n",
            "Worker 1, [34/37]: Training Loss: 2.399170131, Training Accuracy: 37.280\n",
            "Worker 1, [35/37]: Training Loss: 2.315539698, Training Accuracy: 39.200\n",
            "Worker 1, [36/37]: Training Loss: 2.243330416, Training Accuracy: 40.664\n",
            "Worker 1, [37/37]: Training Loss: 2.189341619, Training Accuracy: 41.708\n",
            "Time taken for training worker 1: 0:06:15.848096\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.494853282, Training Accuracy: 36.596\n",
            "Worker 2, [02/37]: Training Loss: 2.444473033, Training Accuracy: 37.656\n",
            "Worker 2, [03/37]: Training Loss: 2.373840916, Training Accuracy: 39.264\n",
            "Worker 2, [04/37]: Training Loss: 2.291270579, Training Accuracy: 40.656\n",
            "Worker 2, [05/37]: Training Loss: 2.231477584, Training Accuracy: 41.892\n",
            "Worker 2, [06/37]: Training Loss: 2.187318938, Training Accuracy: 42.536\n",
            "Worker 2, [07/37]: Training Loss: 2.137874264, Training Accuracy: 43.960\n",
            "Worker 2, [08/37]: Training Loss: 2.087274311, Training Accuracy: 44.476\n",
            "Worker 2, [09/37]: Training Loss: 2.407725056, Training Accuracy: 39.152\n",
            "Worker 2, [10/37]: Training Loss: 2.222979937, Training Accuracy: 41.844\n",
            "Worker 2, [11/37]: Training Loss: 2.184502462, Training Accuracy: 42.128\n",
            "Worker 2, [12/37]: Training Loss: 2.139779904, Training Accuracy: 43.116\n",
            "Worker 2, [13/37]: Training Loss: 2.103466608, Training Accuracy: 43.576\n",
            "Worker 2, [14/37]: Training Loss: 2.081239170, Training Accuracy: 44.204\n",
            "Worker 2, [15/37]: Training Loss: 2.062819692, Training Accuracy: 44.584\n",
            "Worker 2, [16/37]: Training Loss: 2.048890491, Training Accuracy: 44.952\n",
            "Worker 2, [17/37]: Training Loss: 2.389867798, Training Accuracy: 37.992\n",
            "Worker 2, [18/37]: Training Loss: 2.268160641, Training Accuracy: 39.932\n",
            "Worker 2, [19/37]: Training Loss: 2.195146112, Training Accuracy: 41.672\n",
            "Worker 2, [20/37]: Training Loss: 2.163974035, Training Accuracy: 41.868\n",
            "Worker 2, [21/37]: Training Loss: 2.115278063, Training Accuracy: 43.248\n",
            "Worker 2, [22/37]: Training Loss: 2.092924359, Training Accuracy: 44.048\n",
            "Worker 2, [23/37]: Training Loss: 2.076867374, Training Accuracy: 44.264\n",
            "Worker 2, [24/37]: Training Loss: 2.040215186, Training Accuracy: 44.796\n",
            "Worker 2, [25/37]: Training Loss: 2.451012343, Training Accuracy: 36.384\n",
            "Worker 2, [26/37]: Training Loss: 2.336750100, Training Accuracy: 38.320\n",
            "Worker 2, [27/37]: Training Loss: 2.267820309, Training Accuracy: 40.064\n",
            "Worker 2, [28/37]: Training Loss: 2.193606758, Training Accuracy: 41.244\n",
            "Worker 2, [29/37]: Training Loss: 2.161754951, Training Accuracy: 41.872\n",
            "Worker 2, [30/37]: Training Loss: 2.121545990, Training Accuracy: 43.140\n",
            "Worker 2, [31/37]: Training Loss: 2.111520250, Training Accuracy: 43.456\n",
            "Worker 2, [32/37]: Training Loss: 2.055298499, Training Accuracy: 44.776\n",
            "Worker 2, [33/37]: Training Loss: 2.461349818, Training Accuracy: 35.708\n",
            "Worker 2, [34/37]: Training Loss: 2.345181097, Training Accuracy: 37.944\n",
            "Worker 2, [35/37]: Training Loss: 2.305298847, Training Accuracy: 39.312\n",
            "Worker 2, [36/37]: Training Loss: 2.215666901, Training Accuracy: 41.204\n",
            "Worker 2, [37/37]: Training Loss: 2.169625684, Training Accuracy: 42.140\n",
            "Time taken for training worker 2: 0:06:16.874230\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000530\n",
            "Local Step 04: Test Loss: 2.320445301, Test Accuracy: 40.200\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:05.149753\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.345931873, Training Accuracy: 4.176\n",
            "Worker 1, [02/18]: Training Loss: 3.875520948, Training Accuracy: 10.192\n",
            "Worker 1, [03/18]: Training Loss: 4.165246489, Training Accuracy: 6.624\n",
            "Worker 1, [04/18]: Training Loss: 3.716226180, Training Accuracy: 12.700\n",
            "Worker 1, [05/18]: Training Loss: 3.973052232, Training Accuracy: 9.092\n",
            "Worker 1, [06/18]: Training Loss: 3.566286869, Training Accuracy: 15.096\n",
            "Worker 1, [07/18]: Training Loss: 3.860940411, Training Accuracy: 10.932\n",
            "Worker 1, [08/18]: Training Loss: 3.471696852, Training Accuracy: 16.916\n",
            "Worker 1, [09/18]: Training Loss: 3.793773617, Training Accuracy: 12.216\n",
            "Worker 1, [10/18]: Training Loss: 3.411800117, Training Accuracy: 17.772\n",
            "Worker 1, [11/18]: Training Loss: 3.702371669, Training Accuracy: 13.920\n",
            "Worker 1, [12/18]: Training Loss: 3.362344399, Training Accuracy: 18.584\n",
            "Worker 1, [13/18]: Training Loss: 3.652976882, Training Accuracy: 14.844\n",
            "Worker 1, [14/18]: Training Loss: 3.353402643, Training Accuracy: 19.116\n",
            "Worker 1, [15/18]: Training Loss: 3.659009985, Training Accuracy: 15.904\n",
            "Worker 1, [16/18]: Training Loss: 3.385847237, Training Accuracy: 18.872\n",
            "Worker 1, [17/18]: Training Loss: 3.801270182, Training Accuracy: 15.888\n",
            "Worker 1, [18/18]: Training Loss: 3.562259556, Training Accuracy: 17.092\n",
            "Time taken for training worker 1: 0:03:01.998007\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.336907384, Training Accuracy: 4.144\n",
            "Worker 2, [02/18]: Training Loss: 3.860733665, Training Accuracy: 10.352\n",
            "Worker 2, [03/18]: Training Loss: 4.135870452, Training Accuracy: 6.916\n",
            "Worker 2, [04/18]: Training Loss: 3.675251466, Training Accuracy: 12.852\n",
            "Worker 2, [05/18]: Training Loss: 3.966637411, Training Accuracy: 8.760\n",
            "Worker 2, [06/18]: Training Loss: 3.547284476, Training Accuracy: 15.316\n",
            "Worker 2, [07/18]: Training Loss: 3.854674342, Training Accuracy: 10.816\n",
            "Worker 2, [08/18]: Training Loss: 3.441492647, Training Accuracy: 17.004\n",
            "Worker 2, [09/18]: Training Loss: 3.748784623, Training Accuracy: 12.844\n",
            "Worker 2, [10/18]: Training Loss: 3.389352861, Training Accuracy: 18.036\n",
            "Worker 2, [11/18]: Training Loss: 3.679526927, Training Accuracy: 14.000\n",
            "Worker 2, [12/18]: Training Loss: 3.341600599, Training Accuracy: 18.600\n",
            "Worker 2, [13/18]: Training Loss: 3.626228603, Training Accuracy: 15.164\n",
            "Worker 2, [14/18]: Training Loss: 3.332682277, Training Accuracy: 19.192\n",
            "Worker 2, [15/18]: Training Loss: 3.642773536, Training Accuracy: 15.660\n",
            "Worker 2, [16/18]: Training Loss: 3.366627436, Training Accuracy: 19.144\n",
            "Worker 2, [17/18]: Training Loss: 3.778120680, Training Accuracy: 16.036\n",
            "Worker 2, [18/18]: Training Loss: 3.535077539, Training Accuracy: 17.152\n",
            "Time taken for training worker 2: 0:03:03.924498\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000416\n",
            "Local Step 01: Test Loss: 4.141214286, Test Accuracy: 18.000\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.165838181, Training Accuracy: 16.672\n",
            "Worker 1, [02/18]: Training Loss: 4.031835076, Training Accuracy: 15.912\n",
            "Worker 1, [03/18]: Training Loss: 3.738045200, Training Accuracy: 16.168\n",
            "Worker 1, [04/18]: Training Loss: 3.491472660, Training Accuracy: 17.424\n",
            "Worker 1, [05/18]: Training Loss: 3.550576635, Training Accuracy: 17.064\n",
            "Worker 1, [06/18]: Training Loss: 3.370743948, Training Accuracy: 19.196\n",
            "Worker 1, [07/18]: Training Loss: 3.486772026, Training Accuracy: 17.548\n",
            "Worker 1, [08/18]: Training Loss: 3.315919927, Training Accuracy: 19.828\n",
            "Worker 1, [09/18]: Training Loss: 3.458939176, Training Accuracy: 17.260\n",
            "Worker 1, [10/18]: Training Loss: 3.280117903, Training Accuracy: 20.328\n",
            "Worker 1, [11/18]: Training Loss: 3.440055378, Training Accuracy: 17.324\n",
            "Worker 1, [12/18]: Training Loss: 3.258992665, Training Accuracy: 20.360\n",
            "Worker 1, [13/18]: Training Loss: 3.404846127, Training Accuracy: 18.120\n",
            "Worker 1, [14/18]: Training Loss: 3.227157316, Training Accuracy: 21.012\n",
            "Worker 1, [15/18]: Training Loss: 3.391132886, Training Accuracy: 18.488\n",
            "Worker 1, [16/18]: Training Loss: 3.192453128, Training Accuracy: 21.656\n",
            "Worker 1, [17/18]: Training Loss: 3.351813608, Training Accuracy: 18.664\n",
            "Worker 1, [18/18]: Training Loss: 3.141288209, Training Accuracy: 22.776\n",
            "Time taken for training worker 1: 0:03:03.768593\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.494778872, Training Accuracy: 21.560\n",
            "Worker 2, [02/18]: Training Loss: 3.355594319, Training Accuracy: 22.012\n",
            "Worker 2, [03/18]: Training Loss: 3.677008892, Training Accuracy: 17.008\n",
            "Worker 2, [04/18]: Training Loss: 3.442285772, Training Accuracy: 17.904\n",
            "Worker 2, [05/18]: Training Loss: 3.509410727, Training Accuracy: 17.140\n",
            "Worker 2, [06/18]: Training Loss: 3.323936322, Training Accuracy: 19.232\n",
            "Worker 2, [07/18]: Training Loss: 3.439044962, Training Accuracy: 17.392\n",
            "Worker 2, [08/18]: Training Loss: 3.271246613, Training Accuracy: 20.200\n",
            "Worker 2, [09/18]: Training Loss: 3.419924795, Training Accuracy: 17.832\n",
            "Worker 2, [10/18]: Training Loss: 3.246450283, Training Accuracy: 20.720\n",
            "Worker 2, [11/18]: Training Loss: 3.403524148, Training Accuracy: 17.892\n",
            "Worker 2, [12/18]: Training Loss: 3.219484745, Training Accuracy: 21.104\n",
            "Worker 2, [13/18]: Training Loss: 3.385490563, Training Accuracy: 18.256\n",
            "Worker 2, [14/18]: Training Loss: 3.189216679, Training Accuracy: 21.356\n",
            "Worker 2, [15/18]: Training Loss: 3.357378986, Training Accuracy: 18.864\n",
            "Worker 2, [16/18]: Training Loss: 3.161208334, Training Accuracy: 22.148\n",
            "Worker 2, [17/18]: Training Loss: 3.316704600, Training Accuracy: 19.092\n",
            "Worker 2, [18/18]: Training Loss: 3.106119564, Training Accuracy: 23.108\n",
            "Time taken for training worker 2: 0:03:06.262484\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000413\n",
            "Local Step 02: Test Loss: 3.349566929, Test Accuracy: 25.390\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.302313266, Training Accuracy: 19.768\n",
            "Worker 1, [02/18]: Training Loss: 3.092847425, Training Accuracy: 23.932\n",
            "Worker 1, [03/18]: Training Loss: 3.268233340, Training Accuracy: 20.112\n",
            "Worker 1, [04/18]: Training Loss: 3.047275126, Training Accuracy: 24.240\n",
            "Worker 1, [05/18]: Training Loss: 3.192864322, Training Accuracy: 21.808\n",
            "Worker 1, [06/18]: Training Loss: 2.972660375, Training Accuracy: 26.052\n",
            "Worker 1, [07/18]: Training Loss: 3.116721274, Training Accuracy: 23.004\n",
            "Worker 1, [08/18]: Training Loss: 2.916771419, Training Accuracy: 26.848\n",
            "Worker 1, [09/18]: Training Loss: 3.023142117, Training Accuracy: 24.628\n",
            "Worker 1, [10/18]: Training Loss: 2.845642882, Training Accuracy: 28.052\n",
            "Worker 1, [11/18]: Training Loss: 2.936458303, Training Accuracy: 26.800\n",
            "Worker 1, [12/18]: Training Loss: 2.769451486, Training Accuracy: 29.952\n",
            "Worker 1, [13/18]: Training Loss: 2.863275974, Training Accuracy: 27.996\n",
            "Worker 1, [14/18]: Training Loss: 2.713379223, Training Accuracy: 31.000\n",
            "Worker 1, [15/18]: Training Loss: 2.804085525, Training Accuracy: 29.768\n",
            "Worker 1, [16/18]: Training Loss: 2.690863172, Training Accuracy: 31.680\n",
            "Worker 1, [17/18]: Training Loss: 2.800697559, Training Accuracy: 30.364\n",
            "Worker 1, [18/18]: Training Loss: 2.730365215, Training Accuracy: 30.956\n",
            "Time taken for training worker 1: 0:03:01.359276\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.142612169, Training Accuracy: 22.616\n",
            "Worker 2, [02/18]: Training Loss: 2.959306483, Training Accuracy: 25.816\n",
            "Worker 2, [03/18]: Training Loss: 3.214957591, Training Accuracy: 21.036\n",
            "Worker 2, [04/18]: Training Loss: 3.001308702, Training Accuracy: 25.044\n",
            "Worker 2, [05/18]: Training Loss: 3.154095024, Training Accuracy: 22.364\n",
            "Worker 2, [06/18]: Training Loss: 2.934974818, Training Accuracy: 26.488\n",
            "Worker 2, [07/18]: Training Loss: 3.073326196, Training Accuracy: 23.848\n",
            "Worker 2, [08/18]: Training Loss: 2.862417318, Training Accuracy: 27.960\n",
            "Worker 2, [09/18]: Training Loss: 2.992680363, Training Accuracy: 25.480\n",
            "Worker 2, [10/18]: Training Loss: 2.800058751, Training Accuracy: 28.972\n",
            "Worker 2, [11/18]: Training Loss: 2.896482060, Training Accuracy: 27.184\n",
            "Worker 2, [12/18]: Training Loss: 2.722670283, Training Accuracy: 30.636\n",
            "Worker 2, [13/18]: Training Loss: 2.818185314, Training Accuracy: 28.776\n",
            "Worker 2, [14/18]: Training Loss: 2.674760739, Training Accuracy: 31.880\n",
            "Worker 2, [15/18]: Training Loss: 2.761109842, Training Accuracy: 30.380\n",
            "Worker 2, [16/18]: Training Loss: 2.650300690, Training Accuracy: 32.420\n",
            "Worker 2, [17/18]: Training Loss: 2.756663948, Training Accuracy: 30.960\n",
            "Worker 2, [18/18]: Training Loss: 2.688291537, Training Accuracy: 31.716\n",
            "Time taken for training worker 2: 0:03:04.238349\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000492\n",
            "Local Step 03: Test Loss: 2.844623288, Test Accuracy: 31.900\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.971269627, Training Accuracy: 28.936\n",
            "Worker 1, [02/18]: Training Loss: 2.902939227, Training Accuracy: 28.756\n",
            "Worker 1, [03/18]: Training Loss: 2.799164317, Training Accuracy: 30.184\n",
            "Worker 1, [04/18]: Training Loss: 2.739800046, Training Accuracy: 30.796\n",
            "Worker 1, [05/18]: Training Loss: 2.783461010, Training Accuracy: 29.940\n",
            "Worker 1, [06/18]: Training Loss: 2.728790490, Training Accuracy: 30.764\n",
            "Worker 1, [07/18]: Training Loss: 2.802114117, Training Accuracy: 29.336\n",
            "Worker 1, [08/18]: Training Loss: 2.754610768, Training Accuracy: 30.096\n",
            "Worker 1, [09/18]: Training Loss: 2.856178667, Training Accuracy: 28.136\n",
            "Worker 1, [10/18]: Training Loss: 2.770759463, Training Accuracy: 29.632\n",
            "Worker 1, [11/18]: Training Loss: 2.892944898, Training Accuracy: 27.368\n",
            "Worker 1, [12/18]: Training Loss: 2.811125734, Training Accuracy: 28.764\n",
            "Worker 1, [13/18]: Training Loss: 2.919124697, Training Accuracy: 26.728\n",
            "Worker 1, [14/18]: Training Loss: 2.830287372, Training Accuracy: 28.544\n",
            "Worker 1, [15/18]: Training Loss: 2.927581463, Training Accuracy: 26.684\n",
            "Worker 1, [16/18]: Training Loss: 2.824009603, Training Accuracy: 28.464\n",
            "Worker 1, [17/18]: Training Loss: 2.930505015, Training Accuracy: 26.636\n",
            "Worker 1, [18/18]: Training Loss: 2.805116994, Training Accuracy: 29.264\n",
            "Time taken for training worker 1: 0:03:01.310941\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.802676753, Training Accuracy: 30.696\n",
            "Worker 2, [02/18]: Training Loss: 2.741854663, Training Accuracy: 31.248\n",
            "Worker 2, [03/18]: Training Loss: 2.741649920, Training Accuracy: 31.300\n",
            "Worker 2, [04/18]: Training Loss: 2.690085032, Training Accuracy: 31.724\n",
            "Worker 2, [05/18]: Training Loss: 2.724432763, Training Accuracy: 31.256\n",
            "Worker 2, [06/18]: Training Loss: 2.685715763, Training Accuracy: 31.348\n",
            "Worker 2, [07/18]: Training Loss: 2.756396346, Training Accuracy: 29.828\n",
            "Worker 2, [08/18]: Training Loss: 2.703570921, Training Accuracy: 31.024\n",
            "Worker 2, [09/18]: Training Loss: 2.810511640, Training Accuracy: 29.008\n",
            "Worker 2, [10/18]: Training Loss: 2.734796066, Training Accuracy: 29.924\n",
            "Worker 2, [11/18]: Training Loss: 2.843583292, Training Accuracy: 28.576\n",
            "Worker 2, [12/18]: Training Loss: 2.771518515, Training Accuracy: 29.408\n",
            "Worker 2, [13/18]: Training Loss: 2.885609404, Training Accuracy: 26.944\n",
            "Worker 2, [14/18]: Training Loss: 2.777117408, Training Accuracy: 29.624\n",
            "Worker 2, [15/18]: Training Loss: 2.878873258, Training Accuracy: 27.540\n",
            "Worker 2, [16/18]: Training Loss: 2.796013927, Training Accuracy: 29.124\n",
            "Worker 2, [17/18]: Training Loss: 2.883951523, Training Accuracy: 27.696\n",
            "Worker 2, [18/18]: Training Loss: 2.777080764, Training Accuracy: 29.572\n",
            "Time taken for training worker 2: 0:03:02.479279\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000372\n",
            "Local Step 04: Test Loss: 2.597833732, Test Accuracy: 35.720\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.944298957, Training Accuracy: 26.364\n",
            "Worker 1, [02/18]: Training Loss: 2.802372850, Training Accuracy: 29.048\n",
            "Worker 1, [03/18]: Training Loss: 2.870842681, Training Accuracy: 27.672\n",
            "Worker 1, [04/18]: Training Loss: 2.743281306, Training Accuracy: 30.100\n",
            "Worker 1, [05/18]: Training Loss: 2.819460557, Training Accuracy: 28.852\n",
            "Worker 1, [06/18]: Training Loss: 2.690783488, Training Accuracy: 31.052\n",
            "Worker 1, [07/18]: Training Loss: 2.746223674, Training Accuracy: 29.916\n",
            "Worker 1, [08/18]: Training Loss: 2.620425695, Training Accuracy: 32.732\n",
            "Worker 1, [09/18]: Training Loss: 2.646859327, Training Accuracy: 32.348\n",
            "Worker 1, [10/18]: Training Loss: 2.531391556, Training Accuracy: 34.688\n",
            "Worker 1, [11/18]: Training Loss: 2.558565812, Training Accuracy: 33.868\n",
            "Worker 1, [12/18]: Training Loss: 2.452807727, Training Accuracy: 36.120\n",
            "Worker 1, [13/18]: Training Loss: 2.458626215, Training Accuracy: 35.960\n",
            "Worker 1, [14/18]: Training Loss: 2.373431780, Training Accuracy: 38.084\n",
            "Worker 1, [15/18]: Training Loss: 2.394253612, Training Accuracy: 37.540\n",
            "Worker 1, [16/18]: Training Loss: 2.319391062, Training Accuracy: 39.424\n",
            "Worker 1, [17/18]: Training Loss: 2.361429232, Training Accuracy: 39.108\n",
            "Worker 1, [18/18]: Training Loss: 2.327172484, Training Accuracy: 39.304\n",
            "Time taken for training worker 1: 0:03:00.058962\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.886308860, Training Accuracy: 27.800\n",
            "Worker 2, [02/18]: Training Loss: 2.742467209, Training Accuracy: 30.548\n",
            "Worker 2, [03/18]: Training Loss: 2.850536060, Training Accuracy: 28.040\n",
            "Worker 2, [04/18]: Training Loss: 2.710620302, Training Accuracy: 30.800\n",
            "Worker 2, [05/18]: Training Loss: 2.789120204, Training Accuracy: 29.424\n",
            "Worker 2, [06/18]: Training Loss: 2.660568151, Training Accuracy: 31.932\n",
            "Worker 2, [07/18]: Training Loss: 2.712528624, Training Accuracy: 30.528\n",
            "Worker 2, [08/18]: Training Loss: 2.580262928, Training Accuracy: 33.624\n",
            "Worker 2, [09/18]: Training Loss: 2.612050176, Training Accuracy: 32.416\n",
            "Worker 2, [10/18]: Training Loss: 2.495646360, Training Accuracy: 35.572\n",
            "Worker 2, [11/18]: Training Loss: 2.510589214, Training Accuracy: 35.160\n",
            "Worker 2, [12/18]: Training Loss: 2.413776871, Training Accuracy: 37.276\n",
            "Worker 2, [13/18]: Training Loss: 2.430011254, Training Accuracy: 37.032\n",
            "Worker 2, [14/18]: Training Loss: 2.335020537, Training Accuracy: 38.812\n",
            "Worker 2, [15/18]: Training Loss: 2.359921497, Training Accuracy: 38.800\n",
            "Worker 2, [16/18]: Training Loss: 2.281818979, Training Accuracy: 40.672\n",
            "Worker 2, [17/18]: Training Loss: 2.327062124, Training Accuracy: 39.560\n",
            "Worker 2, [18/18]: Training Loss: 2.289899677, Training Accuracy: 39.992\n",
            "Time taken for training worker 2: 0:03:02.947225\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000395\n",
            "Local Step 05: Test Loss: 2.398749733, Test Accuracy: 38.770\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.549676851, Training Accuracy: 35.228\n",
            "Worker 1, [02/18]: Training Loss: 2.524030243, Training Accuracy: 35.492\n",
            "Worker 1, [03/18]: Training Loss: 2.360023991, Training Accuracy: 38.712\n",
            "Worker 1, [04/18]: Training Loss: 2.346783784, Training Accuracy: 38.912\n",
            "Worker 1, [05/18]: Training Loss: 2.396216767, Training Accuracy: 37.828\n",
            "Worker 1, [06/18]: Training Loss: 2.381269758, Training Accuracy: 37.668\n",
            "Worker 1, [07/18]: Training Loss: 2.447817790, Training Accuracy: 36.500\n",
            "Worker 1, [08/18]: Training Loss: 2.442423761, Training Accuracy: 36.536\n",
            "Worker 1, [09/18]: Training Loss: 2.500288623, Training Accuracy: 35.408\n",
            "Worker 1, [10/18]: Training Loss: 2.489801995, Training Accuracy: 35.508\n",
            "Worker 1, [11/18]: Training Loss: 2.581723464, Training Accuracy: 33.524\n",
            "Worker 1, [12/18]: Training Loss: 2.550581903, Training Accuracy: 33.788\n",
            "Worker 1, [13/18]: Training Loss: 2.641106090, Training Accuracy: 32.132\n",
            "Worker 1, [14/18]: Training Loss: 2.584689159, Training Accuracy: 33.504\n",
            "Worker 1, [15/18]: Training Loss: 2.660687697, Training Accuracy: 32.004\n",
            "Worker 1, [16/18]: Training Loss: 2.620125488, Training Accuracy: 32.732\n",
            "Worker 1, [17/18]: Training Loss: 2.682706068, Training Accuracy: 31.340\n",
            "Worker 1, [18/18]: Training Loss: 2.608567977, Training Accuracy: 32.852\n",
            "Time taken for training worker 1: 0:03:08.241936\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.501387341, Training Accuracy: 36.228\n",
            "Worker 2, [02/18]: Training Loss: 2.475858010, Training Accuracy: 36.744\n",
            "Worker 2, [03/18]: Training Loss: 2.325334194, Training Accuracy: 39.300\n",
            "Worker 2, [04/18]: Training Loss: 2.311367592, Training Accuracy: 39.656\n",
            "Worker 2, [05/18]: Training Loss: 2.344328277, Training Accuracy: 38.832\n",
            "Worker 2, [06/18]: Training Loss: 2.339606036, Training Accuracy: 38.944\n",
            "Worker 2, [07/18]: Training Loss: 2.395299408, Training Accuracy: 37.480\n",
            "Worker 2, [08/18]: Training Loss: 2.393158815, Training Accuracy: 37.676\n",
            "Worker 2, [09/18]: Training Loss: 2.467109933, Training Accuracy: 36.024\n",
            "Worker 2, [10/18]: Training Loss: 2.462092894, Training Accuracy: 35.924\n",
            "Worker 2, [11/18]: Training Loss: 2.544196477, Training Accuracy: 34.364\n",
            "Worker 2, [12/18]: Training Loss: 2.529020776, Training Accuracy: 34.648\n",
            "Worker 2, [13/18]: Training Loss: 2.602812263, Training Accuracy: 32.784\n",
            "Worker 2, [14/18]: Training Loss: 2.570058584, Training Accuracy: 33.564\n",
            "Worker 2, [15/18]: Training Loss: 2.646794246, Training Accuracy: 32.180\n",
            "Worker 2, [16/18]: Training Loss: 2.602913640, Training Accuracy: 32.856\n",
            "Worker 2, [17/18]: Training Loss: 2.655241231, Training Accuracy: 31.900\n",
            "Worker 2, [18/18]: Training Loss: 2.597342576, Training Accuracy: 33.092\n",
            "Time taken for training worker 2: 0:03:16.370954\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000405\n",
            "Local Step 06: Test Loss: 2.307224133, Test Accuracy: 40.680\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.759193031, Training Accuracy: 30.172\n",
            "Worker 1, [02/18]: Training Loss: 2.631349276, Training Accuracy: 32.692\n",
            "Worker 1, [03/18]: Training Loss: 2.641660167, Training Accuracy: 32.100\n",
            "Worker 1, [04/18]: Training Loss: 2.552326676, Training Accuracy: 34.072\n",
            "Worker 1, [05/18]: Training Loss: 2.575602284, Training Accuracy: 33.572\n",
            "Worker 1, [06/18]: Training Loss: 2.507837982, Training Accuracy: 35.028\n",
            "Worker 1, [07/18]: Training Loss: 2.517752363, Training Accuracy: 34.800\n",
            "Worker 1, [08/18]: Training Loss: 2.411244209, Training Accuracy: 36.640\n",
            "Worker 1, [09/18]: Training Loss: 2.405968418, Training Accuracy: 37.352\n",
            "Worker 1, [10/18]: Training Loss: 2.324030670, Training Accuracy: 38.680\n",
            "Worker 1, [11/18]: Training Loss: 2.314657809, Training Accuracy: 38.992\n",
            "Worker 1, [12/18]: Training Loss: 2.213732519, Training Accuracy: 41.396\n",
            "Worker 1, [13/18]: Training Loss: 2.203700261, Training Accuracy: 41.144\n",
            "Worker 1, [14/18]: Training Loss: 2.129980385, Training Accuracy: 43.172\n",
            "Worker 1, [15/18]: Training Loss: 2.139191630, Training Accuracy: 43.176\n",
            "Worker 1, [16/18]: Training Loss: 2.072363221, Training Accuracy: 44.572\n",
            "Worker 1, [17/18]: Training Loss: 2.103158038, Training Accuracy: 44.288\n",
            "Worker 1, [18/18]: Training Loss: 2.070834739, Training Accuracy: 44.660\n",
            "Time taken for training worker 1: 0:03:19.703986\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.725437058, Training Accuracy: 30.800\n",
            "Worker 2, [02/18]: Training Loss: 2.605791116, Training Accuracy: 33.092\n",
            "Worker 2, [03/18]: Training Loss: 2.609903388, Training Accuracy: 32.664\n",
            "Worker 2, [04/18]: Training Loss: 2.532705739, Training Accuracy: 34.664\n",
            "Worker 2, [05/18]: Training Loss: 2.557474862, Training Accuracy: 33.984\n",
            "Worker 2, [06/18]: Training Loss: 2.474270563, Training Accuracy: 35.672\n",
            "Worker 2, [07/18]: Training Loss: 2.495415318, Training Accuracy: 35.044\n",
            "Worker 2, [08/18]: Training Loss: 2.384812762, Training Accuracy: 37.528\n",
            "Worker 2, [09/18]: Training Loss: 2.378701192, Training Accuracy: 37.844\n",
            "Worker 2, [10/18]: Training Loss: 2.291554364, Training Accuracy: 39.948\n",
            "Worker 2, [11/18]: Training Loss: 2.298419909, Training Accuracy: 39.892\n",
            "Worker 2, [12/18]: Training Loss: 2.191061468, Training Accuracy: 42.024\n",
            "Worker 2, [13/18]: Training Loss: 2.182653216, Training Accuracy: 42.500\n",
            "Worker 2, [14/18]: Training Loss: 2.112774872, Training Accuracy: 43.836\n",
            "Worker 2, [15/18]: Training Loss: 2.115215808, Training Accuracy: 43.616\n",
            "Worker 2, [16/18]: Training Loss: 2.054572962, Training Accuracy: 45.144\n",
            "Worker 2, [17/18]: Training Loss: 2.077732871, Training Accuracy: 45.136\n",
            "Worker 2, [18/18]: Training Loss: 2.048387114, Training Accuracy: 45.352\n",
            "Time taken for training worker 2: 0:03:21.732592\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000454\n",
            "Local Step 07: Test Loss: 2.206696192, Test Accuracy: 42.240\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.350733105, Training Accuracy: 39.220\n",
            "Worker 1, [02/18]: Training Loss: 2.333327036, Training Accuracy: 39.560\n",
            "Worker 1, [03/18]: Training Loss: 2.115796804, Training Accuracy: 44.192\n",
            "Worker 1, [04/18]: Training Loss: 2.105463049, Training Accuracy: 44.144\n",
            "Worker 1, [05/18]: Training Loss: 2.138299104, Training Accuracy: 43.264\n",
            "Worker 1, [06/18]: Training Loss: 2.138754254, Training Accuracy: 43.244\n",
            "Worker 1, [07/18]: Training Loss: 2.201805654, Training Accuracy: 41.676\n",
            "Worker 1, [08/18]: Training Loss: 2.208604353, Training Accuracy: 41.480\n",
            "Worker 1, [09/18]: Training Loss: 2.282663614, Training Accuracy: 39.624\n",
            "Worker 1, [10/18]: Training Loss: 2.283492818, Training Accuracy: 39.880\n",
            "Worker 1, [11/18]: Training Loss: 2.367457545, Training Accuracy: 37.864\n",
            "Worker 1, [12/18]: Training Loss: 2.358166038, Training Accuracy: 37.924\n",
            "Worker 1, [13/18]: Training Loss: 2.436532373, Training Accuracy: 36.324\n",
            "Worker 1, [14/18]: Training Loss: 2.413795255, Training Accuracy: 36.924\n",
            "Worker 1, [15/18]: Training Loss: 2.492908632, Training Accuracy: 35.428\n",
            "Worker 1, [16/18]: Training Loss: 2.456885923, Training Accuracy: 35.680\n",
            "Worker 1, [17/18]: Training Loss: 2.510866339, Training Accuracy: 35.172\n",
            "Worker 1, [18/18]: Training Loss: 2.476576804, Training Accuracy: 35.876\n",
            "Time taken for training worker 1: 0:03:20.947541\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.323242370, Training Accuracy: 39.992\n",
            "Worker 2, [02/18]: Training Loss: 2.312031178, Training Accuracy: 40.392\n",
            "Worker 2, [03/18]: Training Loss: 2.080322620, Training Accuracy: 44.792\n",
            "Worker 2, [04/18]: Training Loss: 2.083656645, Training Accuracy: 44.528\n",
            "Worker 2, [05/18]: Training Loss: 2.110284169, Training Accuracy: 43.916\n",
            "Worker 2, [06/18]: Training Loss: 2.120291211, Training Accuracy: 43.572\n",
            "Worker 2, [07/18]: Training Loss: 2.172238614, Training Accuracy: 42.308\n",
            "Worker 2, [08/18]: Training Loss: 2.184495905, Training Accuracy: 42.052\n",
            "Worker 2, [09/18]: Training Loss: 2.265818205, Training Accuracy: 40.320\n",
            "Worker 2, [10/18]: Training Loss: 2.268416989, Training Accuracy: 40.044\n",
            "Worker 2, [11/18]: Training Loss: 2.342541366, Training Accuracy: 38.480\n",
            "Worker 2, [12/18]: Training Loss: 2.352571951, Training Accuracy: 38.000\n",
            "Worker 2, [13/18]: Training Loss: 2.405132218, Training Accuracy: 36.984\n",
            "Worker 2, [14/18]: Training Loss: 2.406927525, Training Accuracy: 37.156\n",
            "Worker 2, [15/18]: Training Loss: 2.460927765, Training Accuracy: 36.084\n",
            "Worker 2, [16/18]: Training Loss: 2.430488307, Training Accuracy: 36.680\n",
            "Worker 2, [17/18]: Training Loss: 2.488070656, Training Accuracy: 34.952\n",
            "Worker 2, [18/18]: Training Loss: 2.452184791, Training Accuracy: 35.888\n",
            "Time taken for training worker 2: 0:03:24.436228\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000432\n",
            "Local Step 08: Test Loss: 2.162193660, Test Accuracy: 43.350\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:50:26.325716\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.334735887, Training Accuracy: 4.296\n",
            "Worker 1, [02/18]: Training Loss: 3.861569970, Training Accuracy: 10.356\n",
            "Worker 1, [03/18]: Training Loss: 3.599821766, Training Accuracy: 14.548\n",
            "Worker 1, [04/18]: Training Loss: 3.384084789, Training Accuracy: 18.088\n",
            "Worker 1, [05/18]: Training Loss: 4.108420389, Training Accuracy: 7.128\n",
            "Worker 1, [06/18]: Training Loss: 3.592516599, Training Accuracy: 14.512\n",
            "Worker 1, [07/18]: Training Loss: 3.331895224, Training Accuracy: 19.044\n",
            "Worker 1, [08/18]: Training Loss: 3.146257882, Training Accuracy: 22.472\n",
            "Worker 1, [09/18]: Training Loss: 3.926381791, Training Accuracy: 10.616\n",
            "Worker 1, [10/18]: Training Loss: 3.406379586, Training Accuracy: 18.220\n",
            "Worker 1, [11/18]: Training Loss: 3.181632590, Training Accuracy: 22.064\n",
            "Worker 1, [12/18]: Training Loss: 3.037795608, Training Accuracy: 24.472\n",
            "Worker 1, [13/18]: Training Loss: 3.888276757, Training Accuracy: 11.652\n",
            "Worker 1, [14/18]: Training Loss: 3.393812222, Training Accuracy: 18.316\n",
            "Worker 1, [15/18]: Training Loss: 3.213401877, Training Accuracy: 21.508\n",
            "Worker 1, [16/18]: Training Loss: 3.103192848, Training Accuracy: 23.840\n",
            "Worker 1, [17/18]: Training Loss: 4.267614488, Training Accuracy: 12.428\n",
            "Worker 1, [18/18]: Training Loss: 3.967186386, Training Accuracy: 12.148\n",
            "Time taken for training worker 1: 0:03:22.248057\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.340085804, Training Accuracy: 4.200\n",
            "Worker 2, [02/18]: Training Loss: 3.868127905, Training Accuracy: 9.900\n",
            "Worker 2, [03/18]: Training Loss: 3.602842807, Training Accuracy: 14.432\n",
            "Worker 2, [04/18]: Training Loss: 3.380377523, Training Accuracy: 17.788\n",
            "Worker 2, [05/18]: Training Loss: 4.100027798, Training Accuracy: 7.308\n",
            "Worker 2, [06/18]: Training Loss: 3.597587103, Training Accuracy: 14.464\n",
            "Worker 2, [07/18]: Training Loss: 3.342378054, Training Accuracy: 18.668\n",
            "Worker 2, [08/18]: Training Loss: 3.162116587, Training Accuracy: 22.248\n",
            "Worker 2, [09/18]: Training Loss: 3.920774558, Training Accuracy: 10.052\n",
            "Worker 2, [10/18]: Training Loss: 3.416280631, Training Accuracy: 17.736\n",
            "Worker 2, [11/18]: Training Loss: 3.186643274, Training Accuracy: 21.524\n",
            "Worker 2, [12/18]: Training Loss: 3.041897451, Training Accuracy: 24.160\n",
            "Worker 2, [13/18]: Training Loss: 3.890662625, Training Accuracy: 11.640\n",
            "Worker 2, [14/18]: Training Loss: 3.401138414, Training Accuracy: 18.192\n",
            "Worker 2, [15/18]: Training Loss: 3.219026603, Training Accuracy: 21.652\n",
            "Worker 2, [16/18]: Training Loss: 3.109950883, Training Accuracy: 23.796\n",
            "Worker 2, [17/18]: Training Loss: 4.258997444, Training Accuracy: 11.856\n",
            "Worker 2, [18/18]: Training Loss: 3.949002217, Training Accuracy: 11.908\n",
            "Time taken for training worker 2: 0:03:22.870760\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000934\n",
            "Local Step 01: Test Loss: 3.940766246, Test Accuracy: 12.840\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.979501612, Training Accuracy: 11.888\n",
            "Worker 1, [02/18]: Training Loss: 3.934558445, Training Accuracy: 12.324\n",
            "Worker 1, [03/18]: Training Loss: 3.794868684, Training Accuracy: 13.560\n",
            "Worker 1, [04/18]: Training Loss: 3.620325075, Training Accuracy: 15.060\n",
            "Worker 1, [05/18]: Training Loss: 3.822775951, Training Accuracy: 13.708\n",
            "Worker 1, [06/18]: Training Loss: 3.419281995, Training Accuracy: 18.104\n",
            "Worker 1, [07/18]: Training Loss: 3.256159182, Training Accuracy: 20.532\n",
            "Worker 1, [08/18]: Training Loss: 3.151243873, Training Accuracy: 22.484\n",
            "Worker 1, [09/18]: Training Loss: 3.530245177, Training Accuracy: 16.668\n",
            "Worker 1, [10/18]: Training Loss: 3.220131407, Training Accuracy: 20.976\n",
            "Worker 1, [11/18]: Training Loss: 3.088527942, Training Accuracy: 23.708\n",
            "Worker 1, [12/18]: Training Loss: 2.985274326, Training Accuracy: 25.256\n",
            "Worker 1, [13/18]: Training Loss: 3.436446979, Training Accuracy: 17.336\n",
            "Worker 1, [14/18]: Training Loss: 3.150337534, Training Accuracy: 22.356\n",
            "Worker 1, [15/18]: Training Loss: 2.991632623, Training Accuracy: 25.444\n",
            "Worker 1, [16/18]: Training Loss: 2.876577755, Training Accuracy: 27.680\n",
            "Worker 1, [17/18]: Training Loss: 3.356245795, Training Accuracy: 18.968\n",
            "Worker 1, [18/18]: Training Loss: 3.055466880, Training Accuracy: 24.076\n",
            "Time taken for training worker 1: 0:03:21.645298\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.088386984, Training Accuracy: 23.668\n",
            "Worker 2, [02/18]: Training Loss: 2.938917095, Training Accuracy: 26.976\n",
            "Worker 2, [03/18]: Training Loss: 2.811806207, Training Accuracy: 29.436\n",
            "Worker 2, [04/18]: Training Loss: 2.737252027, Training Accuracy: 31.020\n",
            "Worker 2, [05/18]: Training Loss: 3.753184320, Training Accuracy: 14.700\n",
            "Worker 2, [06/18]: Training Loss: 3.340497002, Training Accuracy: 19.152\n",
            "Worker 2, [07/18]: Training Loss: 3.191841702, Training Accuracy: 21.296\n",
            "Worker 2, [08/18]: Training Loss: 3.087266862, Training Accuracy: 23.532\n",
            "Worker 2, [09/18]: Training Loss: 3.474473135, Training Accuracy: 17.204\n",
            "Worker 2, [10/18]: Training Loss: 3.166407967, Training Accuracy: 22.152\n",
            "Worker 2, [11/18]: Training Loss: 3.024494974, Training Accuracy: 24.456\n",
            "Worker 2, [12/18]: Training Loss: 2.913500771, Training Accuracy: 26.688\n",
            "Worker 2, [13/18]: Training Loss: 3.374090325, Training Accuracy: 18.588\n",
            "Worker 2, [14/18]: Training Loss: 3.067189714, Training Accuracy: 23.644\n",
            "Worker 2, [15/18]: Training Loss: 2.921980606, Training Accuracy: 26.576\n",
            "Worker 2, [16/18]: Training Loss: 2.824059227, Training Accuracy: 28.832\n",
            "Worker 2, [17/18]: Training Loss: 3.290350234, Training Accuracy: 20.244\n",
            "Worker 2, [18/18]: Training Loss: 3.002425086, Training Accuracy: 24.968\n",
            "Time taken for training worker 2: 0:03:22.887437\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000763\n",
            "Local Step 02: Test Loss: 2.801773106, Test Accuracy: 29.540\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.939354384, Training Accuracy: 26.492\n",
            "Worker 1, [02/18]: Training Loss: 2.804007671, Training Accuracy: 29.268\n",
            "Worker 1, [03/18]: Training Loss: 2.678073937, Training Accuracy: 31.588\n",
            "Worker 1, [04/18]: Training Loss: 2.573031130, Training Accuracy: 33.512\n",
            "Worker 1, [05/18]: Training Loss: 3.244798463, Training Accuracy: 20.924\n",
            "Worker 1, [06/18]: Training Loss: 2.915540957, Training Accuracy: 26.556\n",
            "Worker 1, [07/18]: Training Loss: 2.753792807, Training Accuracy: 29.984\n",
            "Worker 1, [08/18]: Training Loss: 2.632555394, Training Accuracy: 32.332\n",
            "Worker 1, [09/18]: Training Loss: 3.093651529, Training Accuracy: 23.900\n",
            "Worker 1, [10/18]: Training Loss: 2.789138158, Training Accuracy: 29.284\n",
            "Worker 1, [11/18]: Training Loss: 2.626495165, Training Accuracy: 32.712\n",
            "Worker 1, [12/18]: Training Loss: 2.511681853, Training Accuracy: 34.804\n",
            "Worker 1, [13/18]: Training Loss: 2.959024415, Training Accuracy: 26.864\n",
            "Worker 1, [14/18]: Training Loss: 2.698216235, Training Accuracy: 31.156\n",
            "Worker 1, [15/18]: Training Loss: 2.576219348, Training Accuracy: 34.156\n",
            "Worker 1, [16/18]: Training Loss: 2.492272182, Training Accuracy: 35.996\n",
            "Worker 1, [17/18]: Training Loss: 3.069585745, Training Accuracy: 28.160\n",
            "Worker 1, [18/18]: Training Loss: 2.841148353, Training Accuracy: 29.588\n",
            "Time taken for training worker 1: 0:03:20.912183\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.106378164, Training Accuracy: 23.356\n",
            "Worker 2, [02/18]: Training Loss: 2.870179142, Training Accuracy: 27.412\n",
            "Worker 2, [03/18]: Training Loss: 2.743122312, Training Accuracy: 30.008\n",
            "Worker 2, [04/18]: Training Loss: 2.618806810, Training Accuracy: 32.904\n",
            "Worker 2, [05/18]: Training Loss: 3.188874592, Training Accuracy: 22.056\n",
            "Worker 2, [06/18]: Training Loss: 2.885176099, Training Accuracy: 27.436\n",
            "Worker 2, [07/18]: Training Loss: 2.711314490, Training Accuracy: 30.680\n",
            "Worker 2, [08/18]: Training Loss: 2.586579386, Training Accuracy: 33.148\n",
            "Worker 2, [09/18]: Training Loss: 3.024455342, Training Accuracy: 25.180\n",
            "Worker 2, [10/18]: Training Loss: 2.748706506, Training Accuracy: 29.836\n",
            "Worker 2, [11/18]: Training Loss: 2.582157897, Training Accuracy: 33.896\n",
            "Worker 2, [12/18]: Training Loss: 2.460387251, Training Accuracy: 35.764\n",
            "Worker 2, [13/18]: Training Loss: 2.898428133, Training Accuracy: 28.236\n",
            "Worker 2, [14/18]: Training Loss: 2.638045928, Training Accuracy: 32.716\n",
            "Worker 2, [15/18]: Training Loss: 2.521253010, Training Accuracy: 35.096\n",
            "Worker 2, [16/18]: Training Loss: 2.440194282, Training Accuracy: 37.052\n",
            "Worker 2, [17/18]: Training Loss: 2.999029516, Training Accuracy: 29.676\n",
            "Worker 2, [18/18]: Training Loss: 2.768535830, Training Accuracy: 31.248\n",
            "Time taken for training worker 2: 0:03:25.570715\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000567\n",
            "Local Step 03: Test Loss: 2.704310240, Test Accuracy: 32.650\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.836137451, Training Accuracy: 29.744\n",
            "Worker 1, [02/18]: Training Loss: 2.827089988, Training Accuracy: 29.688\n",
            "Worker 1, [03/18]: Training Loss: 2.791196879, Training Accuracy: 30.332\n",
            "Worker 1, [04/18]: Training Loss: 2.749662151, Training Accuracy: 31.224\n",
            "Worker 1, [05/18]: Training Loss: 2.890762222, Training Accuracy: 29.236\n",
            "Worker 1, [06/18]: Training Loss: 2.731929359, Training Accuracy: 30.956\n",
            "Worker 1, [07/18]: Training Loss: 2.674084457, Training Accuracy: 31.700\n",
            "Worker 1, [08/18]: Training Loss: 2.620487204, Training Accuracy: 32.720\n",
            "Worker 1, [09/18]: Training Loss: 2.864885440, Training Accuracy: 28.300\n",
            "Worker 1, [10/18]: Training Loss: 2.722643302, Training Accuracy: 30.696\n",
            "Worker 1, [11/18]: Training Loss: 2.655559274, Training Accuracy: 31.988\n",
            "Worker 1, [12/18]: Training Loss: 2.596866531, Training Accuracy: 32.936\n",
            "Worker 1, [13/18]: Training Loss: 2.900014032, Training Accuracy: 27.448\n",
            "Worker 1, [14/18]: Training Loss: 2.757908785, Training Accuracy: 29.820\n",
            "Worker 1, [15/18]: Training Loss: 2.658458741, Training Accuracy: 31.916\n",
            "Worker 1, [16/18]: Training Loss: 2.589509572, Training Accuracy: 33.256\n",
            "Worker 1, [17/18]: Training Loss: 2.892763452, Training Accuracy: 27.424\n",
            "Worker 1, [18/18]: Training Loss: 2.736199007, Training Accuracy: 30.256\n",
            "Time taken for training worker 1: 0:03:17.883523\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.853191476, Training Accuracy: 28.472\n",
            "Worker 2, [02/18]: Training Loss: 2.667275500, Training Accuracy: 32.020\n",
            "Worker 2, [03/18]: Training Loss: 2.546512506, Training Accuracy: 34.552\n",
            "Worker 2, [04/18]: Training Loss: 2.477541236, Training Accuracy: 36.436\n",
            "Worker 2, [05/18]: Training Loss: 2.777382045, Training Accuracy: 30.964\n",
            "Worker 2, [06/18]: Training Loss: 2.633784428, Training Accuracy: 33.048\n",
            "Worker 2, [07/18]: Training Loss: 2.582400624, Training Accuracy: 33.576\n",
            "Worker 2, [08/18]: Training Loss: 2.546461665, Training Accuracy: 34.192\n",
            "Worker 2, [09/18]: Training Loss: 2.769578700, Training Accuracy: 30.436\n",
            "Worker 2, [10/18]: Training Loss: 2.652494719, Training Accuracy: 32.016\n",
            "Worker 2, [11/18]: Training Loss: 2.592927943, Training Accuracy: 33.188\n",
            "Worker 2, [12/18]: Training Loss: 2.550050538, Training Accuracy: 34.112\n",
            "Worker 2, [13/18]: Training Loss: 2.834007000, Training Accuracy: 28.560\n",
            "Worker 2, [14/18]: Training Loss: 2.697015606, Training Accuracy: 31.040\n",
            "Worker 2, [15/18]: Training Loss: 2.610367827, Training Accuracy: 32.984\n",
            "Worker 2, [16/18]: Training Loss: 2.542408206, Training Accuracy: 34.112\n",
            "Worker 2, [17/18]: Training Loss: 2.837806349, Training Accuracy: 28.344\n",
            "Worker 2, [18/18]: Training Loss: 2.694587956, Training Accuracy: 30.540\n",
            "Time taken for training worker 2: 0:03:20.517728\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000597\n",
            "Local Step 04: Test Loss: 2.573313535, Test Accuracy: 34.240\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.726550760, Training Accuracy: 31.296\n",
            "Worker 1, [02/18]: Training Loss: 2.584698262, Training Accuracy: 33.592\n",
            "Worker 1, [03/18]: Training Loss: 2.487203008, Training Accuracy: 35.640\n",
            "Worker 1, [04/18]: Training Loss: 2.394608138, Training Accuracy: 37.456\n",
            "Worker 1, [05/18]: Training Loss: 2.809219891, Training Accuracy: 28.836\n",
            "Worker 1, [06/18]: Training Loss: 2.623695003, Training Accuracy: 32.888\n",
            "Worker 1, [07/18]: Training Loss: 2.495287660, Training Accuracy: 35.256\n",
            "Worker 1, [08/18]: Training Loss: 2.389405894, Training Accuracy: 37.260\n",
            "Worker 1, [09/18]: Training Loss: 2.644170662, Training Accuracy: 32.592\n",
            "Worker 1, [10/18]: Training Loss: 2.476048237, Training Accuracy: 35.840\n",
            "Worker 1, [11/18]: Training Loss: 2.333995846, Training Accuracy: 38.528\n",
            "Worker 1, [12/18]: Training Loss: 2.221513645, Training Accuracy: 41.236\n",
            "Worker 1, [13/18]: Training Loss: 2.468635508, Training Accuracy: 36.116\n",
            "Worker 1, [14/18]: Training Loss: 2.315582220, Training Accuracy: 39.128\n",
            "Worker 1, [15/18]: Training Loss: 2.231147809, Training Accuracy: 41.288\n",
            "Worker 1, [16/18]: Training Loss: 2.145998845, Training Accuracy: 43.428\n",
            "Worker 1, [17/18]: Training Loss: 2.424961506, Training Accuracy: 39.012\n",
            "Worker 1, [18/18]: Training Loss: 2.328113610, Training Accuracy: 39.508\n",
            "Time taken for training worker 1: 0:03:23.854669\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.841240221, Training Accuracy: 28.380\n",
            "Worker 2, [02/18]: Training Loss: 2.665968449, Training Accuracy: 31.796\n",
            "Worker 2, [03/18]: Training Loss: 2.554410103, Training Accuracy: 34.320\n",
            "Worker 2, [04/18]: Training Loss: 2.449248960, Training Accuracy: 36.120\n",
            "Worker 2, [05/18]: Training Loss: 2.758503951, Training Accuracy: 29.920\n",
            "Worker 2, [06/18]: Training Loss: 2.578221034, Training Accuracy: 33.384\n",
            "Worker 2, [07/18]: Training Loss: 2.466239508, Training Accuracy: 35.928\n",
            "Worker 2, [08/18]: Training Loss: 2.349894935, Training Accuracy: 38.196\n",
            "Worker 2, [09/18]: Training Loss: 2.586457592, Training Accuracy: 33.332\n",
            "Worker 2, [10/18]: Training Loss: 2.437688814, Training Accuracy: 36.616\n",
            "Worker 2, [11/18]: Training Loss: 2.304864633, Training Accuracy: 39.048\n",
            "Worker 2, [12/18]: Training Loss: 2.201341844, Training Accuracy: 41.348\n",
            "Worker 2, [13/18]: Training Loss: 2.398744991, Training Accuracy: 37.964\n",
            "Worker 2, [14/18]: Training Loss: 2.272910557, Training Accuracy: 40.536\n",
            "Worker 2, [15/18]: Training Loss: 2.170428918, Training Accuracy: 42.944\n",
            "Worker 2, [16/18]: Training Loss: 2.110861253, Training Accuracy: 43.916\n",
            "Worker 2, [17/18]: Training Loss: 2.363568473, Training Accuracy: 40.268\n",
            "Worker 2, [18/18]: Training Loss: 2.257314205, Training Accuracy: 41.280\n",
            "Time taken for training worker 2: 0:03:21.359128\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000859\n",
            "Local Step 05: Test Loss: 2.273204174, Test Accuracy: 40.930\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.427045325, Training Accuracy: 37.700\n",
            "Worker 1, [02/18]: Training Loss: 2.415584902, Training Accuracy: 37.760\n",
            "Worker 1, [03/18]: Training Loss: 2.402208298, Training Accuracy: 38.368\n",
            "Worker 1, [04/18]: Training Loss: 2.381652031, Training Accuracy: 38.584\n",
            "Worker 1, [05/18]: Training Loss: 2.381519017, Training Accuracy: 38.472\n",
            "Worker 1, [06/18]: Training Loss: 2.338144849, Training Accuracy: 39.212\n",
            "Worker 1, [07/18]: Training Loss: 2.322038020, Training Accuracy: 39.404\n",
            "Worker 1, [08/18]: Training Loss: 2.321399034, Training Accuracy: 39.124\n",
            "Worker 1, [09/18]: Training Loss: 2.478278069, Training Accuracy: 35.860\n",
            "Worker 1, [10/18]: Training Loss: 2.441237125, Training Accuracy: 36.156\n",
            "Worker 1, [11/18]: Training Loss: 2.395442930, Training Accuracy: 37.500\n",
            "Worker 1, [12/18]: Training Loss: 2.375324237, Training Accuracy: 37.820\n",
            "Worker 1, [13/18]: Training Loss: 2.589076033, Training Accuracy: 33.100\n",
            "Worker 1, [14/18]: Training Loss: 2.522671023, Training Accuracy: 34.684\n",
            "Worker 1, [15/18]: Training Loss: 2.460807843, Training Accuracy: 36.504\n",
            "Worker 1, [16/18]: Training Loss: 2.410844680, Training Accuracy: 37.076\n",
            "Worker 1, [17/18]: Training Loss: 2.642416633, Training Accuracy: 32.168\n",
            "Worker 1, [18/18]: Training Loss: 2.536099078, Training Accuracy: 34.312\n",
            "Time taken for training worker 1: 0:03:24.102392\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.645927520, Training Accuracy: 33.020\n",
            "Worker 2, [02/18]: Training Loss: 2.499599784, Training Accuracy: 36.048\n",
            "Worker 2, [03/18]: Training Loss: 2.387649526, Training Accuracy: 38.632\n",
            "Worker 2, [04/18]: Training Loss: 2.325278565, Training Accuracy: 39.620\n",
            "Worker 2, [05/18]: Training Loss: 2.306562124, Training Accuracy: 40.016\n",
            "Worker 2, [06/18]: Training Loss: 2.257736661, Training Accuracy: 40.300\n",
            "Worker 2, [07/18]: Training Loss: 2.255405871, Training Accuracy: 40.484\n",
            "Worker 2, [08/18]: Training Loss: 2.247666422, Training Accuracy: 40.700\n",
            "Worker 2, [09/18]: Training Loss: 2.403111988, Training Accuracy: 37.596\n",
            "Worker 2, [10/18]: Training Loss: 2.369203168, Training Accuracy: 37.784\n",
            "Worker 2, [11/18]: Training Loss: 2.342613617, Training Accuracy: 38.256\n",
            "Worker 2, [12/18]: Training Loss: 2.339789023, Training Accuracy: 38.832\n",
            "Worker 2, [13/18]: Training Loss: 2.524860596, Training Accuracy: 34.936\n",
            "Worker 2, [14/18]: Training Loss: 2.479352616, Training Accuracy: 35.612\n",
            "Worker 2, [15/18]: Training Loss: 2.431295038, Training Accuracy: 36.364\n",
            "Worker 2, [16/18]: Training Loss: 2.369852574, Training Accuracy: 37.832\n",
            "Worker 2, [17/18]: Training Loss: 2.572680843, Training Accuracy: 33.456\n",
            "Worker 2, [18/18]: Training Loss: 2.499270358, Training Accuracy: 35.396\n",
            "Time taken for training worker 2: 0:03:13.513487\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000588\n",
            "Local Step 06: Test Loss: 2.451798736, Test Accuracy: 36.910\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.606717552, Training Accuracy: 33.824\n",
            "Worker 1, [02/18]: Training Loss: 2.470772672, Training Accuracy: 36.260\n",
            "Worker 1, [03/18]: Training Loss: 2.374417996, Training Accuracy: 38.068\n",
            "Worker 1, [04/18]: Training Loss: 2.271400313, Training Accuracy: 40.124\n",
            "Worker 1, [05/18]: Training Loss: 2.544741160, Training Accuracy: 34.352\n",
            "Worker 1, [06/18]: Training Loss: 2.422236528, Training Accuracy: 36.880\n",
            "Worker 1, [07/18]: Training Loss: 2.318529846, Training Accuracy: 38.648\n",
            "Worker 1, [08/18]: Training Loss: 2.213324843, Training Accuracy: 41.124\n",
            "Worker 1, [09/18]: Training Loss: 2.365007574, Training Accuracy: 38.332\n",
            "Worker 1, [10/18]: Training Loss: 2.235516596, Training Accuracy: 40.772\n",
            "Worker 1, [11/18]: Training Loss: 2.131035133, Training Accuracy: 42.868\n",
            "Worker 1, [12/18]: Training Loss: 2.025483614, Training Accuracy: 45.112\n",
            "Worker 1, [13/18]: Training Loss: 2.169567220, Training Accuracy: 42.532\n",
            "Worker 1, [14/18]: Training Loss: 2.068268164, Training Accuracy: 44.760\n",
            "Worker 1, [15/18]: Training Loss: 1.976586906, Training Accuracy: 46.844\n",
            "Worker 1, [16/18]: Training Loss: 1.910403489, Training Accuracy: 48.608\n",
            "Worker 1, [17/18]: Training Loss: 2.078146013, Training Accuracy: 45.808\n",
            "Worker 1, [18/18]: Training Loss: 2.015901955, Training Accuracy: 46.236\n",
            "Time taken for training worker 1: 0:03:20.620533\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.662660687, Training Accuracy: 32.036\n",
            "Worker 2, [02/18]: Training Loss: 2.531512514, Training Accuracy: 35.056\n",
            "Worker 2, [03/18]: Training Loss: 2.415504082, Training Accuracy: 37.016\n",
            "Worker 2, [04/18]: Training Loss: 2.338466954, Training Accuracy: 38.732\n",
            "Worker 2, [05/18]: Training Loss: 2.496627259, Training Accuracy: 35.404\n",
            "Worker 2, [06/18]: Training Loss: 2.409646248, Training Accuracy: 37.112\n",
            "Worker 2, [07/18]: Training Loss: 2.304469177, Training Accuracy: 38.892\n",
            "Worker 2, [08/18]: Training Loss: 2.195475515, Training Accuracy: 41.844\n",
            "Worker 2, [09/18]: Training Loss: 2.328636119, Training Accuracy: 38.800\n",
            "Worker 2, [10/18]: Training Loss: 2.217236868, Training Accuracy: 41.168\n",
            "Worker 2, [11/18]: Training Loss: 2.111696109, Training Accuracy: 43.576\n",
            "Worker 2, [12/18]: Training Loss: 2.011892883, Training Accuracy: 45.800\n",
            "Worker 2, [13/18]: Training Loss: 2.131328699, Training Accuracy: 43.428\n",
            "Worker 2, [14/18]: Training Loss: 2.024508139, Training Accuracy: 45.972\n",
            "Worker 2, [15/18]: Training Loss: 1.944944231, Training Accuracy: 47.732\n",
            "Worker 2, [16/18]: Training Loss: 1.883472310, Training Accuracy: 48.968\n",
            "Worker 2, [17/18]: Training Loss: 2.034861973, Training Accuracy: 46.488\n",
            "Worker 2, [18/18]: Training Loss: 1.981533565, Training Accuracy: 46.924\n",
            "Time taken for training worker 2: 0:03:17.339307\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000667\n",
            "Local Step 07: Test Loss: 2.088219351, Test Accuracy: 44.970\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.213739764, Training Accuracy: 42.184\n",
            "Worker 1, [02/18]: Training Loss: 2.203945179, Training Accuracy: 42.496\n",
            "Worker 1, [03/18]: Training Loss: 2.200633359, Training Accuracy: 42.132\n",
            "Worker 1, [04/18]: Training Loss: 2.181881214, Training Accuracy: 42.520\n",
            "Worker 1, [05/18]: Training Loss: 2.087784282, Training Accuracy: 44.380\n",
            "Worker 1, [06/18]: Training Loss: 2.074692311, Training Accuracy: 44.980\n",
            "Worker 1, [07/18]: Training Loss: 2.084129819, Training Accuracy: 44.416\n",
            "Worker 1, [08/18]: Training Loss: 2.100422062, Training Accuracy: 43.684\n",
            "Worker 1, [09/18]: Training Loss: 2.217665838, Training Accuracy: 41.132\n",
            "Worker 1, [10/18]: Training Loss: 2.221581233, Training Accuracy: 40.920\n",
            "Worker 1, [11/18]: Training Loss: 2.217340300, Training Accuracy: 40.980\n",
            "Worker 1, [12/18]: Training Loss: 2.209356312, Training Accuracy: 41.520\n",
            "Worker 1, [13/18]: Training Loss: 2.365659283, Training Accuracy: 37.980\n",
            "Worker 1, [14/18]: Training Loss: 2.355826862, Training Accuracy: 38.300\n",
            "Worker 1, [15/18]: Training Loss: 2.314287054, Training Accuracy: 39.352\n",
            "Worker 1, [16/18]: Training Loss: 2.260700754, Training Accuracy: 40.360\n",
            "Worker 1, [17/18]: Training Loss: 2.444928105, Training Accuracy: 36.360\n",
            "Worker 1, [18/18]: Training Loss: 2.386796331, Training Accuracy: 37.840\n",
            "Time taken for training worker 1: 0:03:22.483341\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.572043675, Training Accuracy: 34.224\n",
            "Worker 2, [02/18]: Training Loss: 2.429827043, Training Accuracy: 37.500\n",
            "Worker 2, [03/18]: Training Loss: 2.317777838, Training Accuracy: 39.908\n",
            "Worker 2, [04/18]: Training Loss: 2.232038587, Training Accuracy: 41.612\n",
            "Worker 2, [05/18]: Training Loss: 2.041541265, Training Accuracy: 45.792\n",
            "Worker 2, [06/18]: Training Loss: 2.027674754, Training Accuracy: 45.840\n",
            "Worker 2, [07/18]: Training Loss: 2.039936010, Training Accuracy: 45.348\n",
            "Worker 2, [08/18]: Training Loss: 2.051095595, Training Accuracy: 44.880\n",
            "Worker 2, [09/18]: Training Loss: 2.168331797, Training Accuracy: 42.312\n",
            "Worker 2, [10/18]: Training Loss: 2.171595407, Training Accuracy: 42.360\n",
            "Worker 2, [11/18]: Training Loss: 2.175072225, Training Accuracy: 42.120\n",
            "Worker 2, [12/18]: Training Loss: 2.177289116, Training Accuracy: 41.748\n",
            "Worker 2, [13/18]: Training Loss: 2.327818070, Training Accuracy: 38.668\n",
            "Worker 2, [14/18]: Training Loss: 2.321225807, Training Accuracy: 38.788\n",
            "Worker 2, [15/18]: Training Loss: 2.280937247, Training Accuracy: 39.820\n",
            "Worker 2, [16/18]: Training Loss: 2.260157052, Training Accuracy: 39.948\n",
            "Worker 2, [17/18]: Training Loss: 2.410994287, Training Accuracy: 37.076\n",
            "Worker 2, [18/18]: Training Loss: 2.369071607, Training Accuracy: 38.164\n",
            "Time taken for training worker 2: 0:03:18.464163\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000618\n",
            "Local Step 08: Test Loss: 2.365585571, Test Accuracy: 38.720\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:53:43.700934\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.341935707, Training Accuracy: 4.024\n",
            "Worker 1, [02/18]: Training Loss: 3.862517026, Training Accuracy: 10.212\n",
            "Worker 1, [03/18]: Training Loss: 3.583920311, Training Accuracy: 14.820\n",
            "Worker 1, [04/18]: Training Loss: 3.377346513, Training Accuracy: 18.500\n",
            "Worker 1, [05/18]: Training Loss: 3.202038759, Training Accuracy: 21.324\n",
            "Worker 1, [06/18]: Training Loss: 3.051926145, Training Accuracy: 23.948\n",
            "Worker 1, [07/18]: Training Loss: 2.920543945, Training Accuracy: 26.612\n",
            "Worker 1, [08/18]: Training Loss: 2.782349334, Training Accuracy: 28.968\n",
            "Worker 1, [09/18]: Training Loss: 4.139983130, Training Accuracy: 7.100\n",
            "Worker 1, [10/18]: Training Loss: 3.586712531, Training Accuracy: 14.992\n",
            "Worker 1, [11/18]: Training Loss: 3.290320354, Training Accuracy: 19.948\n",
            "Worker 1, [12/18]: Training Loss: 3.087034861, Training Accuracy: 23.712\n",
            "Worker 1, [13/18]: Training Loss: 2.934595556, Training Accuracy: 26.520\n",
            "Worker 1, [14/18]: Training Loss: 2.808259824, Training Accuracy: 29.184\n",
            "Worker 1, [15/18]: Training Loss: 2.709660455, Training Accuracy: 31.336\n",
            "Worker 1, [16/18]: Training Loss: 2.626936022, Training Accuracy: 33.044\n",
            "Worker 1, [17/18]: Training Loss: 4.521420386, Training Accuracy: 6.924\n",
            "Worker 1, [18/18]: Training Loss: 4.439966642, Training Accuracy: 7.188\n",
            "Time taken for training worker 1: 0:03:21.208606\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.331792130, Training Accuracy: 4.356\n",
            "Worker 2, [02/18]: Training Loss: 3.859929722, Training Accuracy: 10.076\n",
            "Worker 2, [03/18]: Training Loss: 3.599684978, Training Accuracy: 14.388\n",
            "Worker 2, [04/18]: Training Loss: 3.389081964, Training Accuracy: 17.736\n",
            "Worker 2, [05/18]: Training Loss: 3.224267789, Training Accuracy: 21.056\n",
            "Worker 2, [06/18]: Training Loss: 3.066806021, Training Accuracy: 23.956\n",
            "Worker 2, [07/18]: Training Loss: 2.931435382, Training Accuracy: 26.260\n",
            "Worker 2, [08/18]: Training Loss: 2.800017500, Training Accuracy: 28.972\n",
            "Worker 2, [09/18]: Training Loss: 4.135718215, Training Accuracy: 7.096\n",
            "Worker 2, [10/18]: Training Loss: 3.578644711, Training Accuracy: 15.188\n",
            "Worker 2, [11/18]: Training Loss: 3.287709454, Training Accuracy: 19.792\n",
            "Worker 2, [12/18]: Training Loss: 3.092167684, Training Accuracy: 23.512\n",
            "Worker 2, [13/18]: Training Loss: 2.946485440, Training Accuracy: 26.148\n",
            "Worker 2, [14/18]: Training Loss: 2.823412305, Training Accuracy: 28.940\n",
            "Worker 2, [15/18]: Training Loss: 2.731846696, Training Accuracy: 30.652\n",
            "Worker 2, [16/18]: Training Loss: 2.653424160, Training Accuracy: 32.348\n",
            "Worker 2, [17/18]: Training Loss: 4.522147805, Training Accuracy: 7.624\n",
            "Worker 2, [18/18]: Training Loss: 4.439992281, Training Accuracy: 8.536\n",
            "Time taken for training worker 2: 0:03:21.074366\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000631\n",
            "Local Step 01: Test Loss: 4.432019531, Test Accuracy: 8.080\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.442696158, Training Accuracy: 7.328\n",
            "Worker 1, [02/18]: Training Loss: 4.418171878, Training Accuracy: 7.256\n",
            "Worker 1, [03/18]: Training Loss: 4.262756453, Training Accuracy: 7.528\n",
            "Worker 1, [04/18]: Training Loss: 3.967942976, Training Accuracy: 9.868\n",
            "Worker 1, [05/18]: Training Loss: 3.747542139, Training Accuracy: 13.136\n",
            "Worker 1, [06/18]: Training Loss: 3.530921807, Training Accuracy: 16.340\n",
            "Worker 1, [07/18]: Training Loss: 3.356997296, Training Accuracy: 18.968\n",
            "Worker 1, [08/18]: Training Loss: 3.213129910, Training Accuracy: 21.580\n",
            "Worker 1, [09/18]: Training Loss: 3.768979266, Training Accuracy: 12.840\n",
            "Worker 1, [10/18]: Training Loss: 3.270114838, Training Accuracy: 20.224\n",
            "Worker 1, [11/18]: Training Loss: 3.065657704, Training Accuracy: 23.900\n",
            "Worker 1, [12/18]: Training Loss: 2.936027962, Training Accuracy: 26.288\n",
            "Worker 1, [13/18]: Training Loss: 2.840128941, Training Accuracy: 28.384\n",
            "Worker 1, [14/18]: Training Loss: 2.764551943, Training Accuracy: 29.664\n",
            "Worker 1, [15/18]: Training Loss: 2.694973618, Training Accuracy: 31.116\n",
            "Worker 1, [16/18]: Training Loss: 2.624491978, Training Accuracy: 32.372\n",
            "Worker 1, [17/18]: Training Loss: 3.493326408, Training Accuracy: 16.684\n",
            "Worker 1, [18/18]: Training Loss: 3.041656734, Training Accuracy: 24.184\n",
            "Time taken for training worker 1: 0:03:20.874397\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.039715614, Training Accuracy: 24.288\n",
            "Worker 2, [02/18]: Training Loss: 2.879514392, Training Accuracy: 27.696\n",
            "Worker 2, [03/18]: Training Loss: 2.771541820, Training Accuracy: 30.244\n",
            "Worker 2, [04/18]: Training Loss: 2.703769432, Training Accuracy: 31.084\n",
            "Worker 2, [05/18]: Training Loss: 2.657535457, Training Accuracy: 32.676\n",
            "Worker 2, [06/18]: Training Loss: 2.609252312, Training Accuracy: 33.248\n",
            "Worker 2, [07/18]: Training Loss: 2.589630632, Training Accuracy: 33.680\n",
            "Worker 2, [08/18]: Training Loss: 2.570398404, Training Accuracy: 33.744\n",
            "Worker 2, [09/18]: Training Loss: 3.781927128, Training Accuracy: 12.492\n",
            "Worker 2, [10/18]: Training Loss: 3.242689734, Training Accuracy: 20.528\n",
            "Worker 2, [11/18]: Training Loss: 3.032613259, Training Accuracy: 24.576\n",
            "Worker 2, [12/18]: Training Loss: 2.884665272, Training Accuracy: 27.120\n",
            "Worker 2, [13/18]: Training Loss: 2.813203339, Training Accuracy: 28.900\n",
            "Worker 2, [14/18]: Training Loss: 2.732328181, Training Accuracy: 30.196\n",
            "Worker 2, [15/18]: Training Loss: 2.665264217, Training Accuracy: 31.788\n",
            "Worker 2, [16/18]: Training Loss: 2.611408779, Training Accuracy: 32.456\n",
            "Worker 2, [17/18]: Training Loss: 3.468522449, Training Accuracy: 17.212\n",
            "Worker 2, [18/18]: Training Loss: 3.022090778, Training Accuracy: 24.804\n",
            "Time taken for training worker 2: 0:03:25.023891\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000694\n",
            "Local Step 02: Test Loss: 2.811655978, Test Accuracy: 28.330\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.914487084, Training Accuracy: 26.892\n",
            "Worker 1, [02/18]: Training Loss: 2.760558503, Training Accuracy: 30.068\n",
            "Worker 1, [03/18]: Training Loss: 2.647097063, Training Accuracy: 32.200\n",
            "Worker 1, [04/18]: Training Loss: 2.552799125, Training Accuracy: 34.076\n",
            "Worker 1, [05/18]: Training Loss: 2.452311368, Training Accuracy: 36.456\n",
            "Worker 1, [06/18]: Training Loss: 2.350318405, Training Accuracy: 38.256\n",
            "Worker 1, [07/18]: Training Loss: 2.260285481, Training Accuracy: 40.056\n",
            "Worker 1, [08/18]: Training Loss: 2.170209224, Training Accuracy: 42.248\n",
            "Worker 1, [09/18]: Training Loss: 3.307431639, Training Accuracy: 20.396\n",
            "Worker 1, [10/18]: Training Loss: 2.841039536, Training Accuracy: 28.104\n",
            "Worker 1, [11/18]: Training Loss: 2.637004681, Training Accuracy: 32.652\n",
            "Worker 1, [12/18]: Training Loss: 2.513471099, Training Accuracy: 35.084\n",
            "Worker 1, [13/18]: Training Loss: 2.392294486, Training Accuracy: 37.376\n",
            "Worker 1, [14/18]: Training Loss: 2.290377696, Training Accuracy: 39.772\n",
            "Worker 1, [15/18]: Training Loss: 2.190325678, Training Accuracy: 42.056\n",
            "Worker 1, [16/18]: Training Loss: 2.133569305, Training Accuracy: 43.184\n",
            "Worker 1, [17/18]: Training Loss: 3.771027969, Training Accuracy: 21.308\n",
            "Worker 1, [18/18]: Training Loss: 3.302983409, Training Accuracy: 23.108\n",
            "Time taken for training worker 1: 0:03:18.610283\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.193106701, Training Accuracy: 21.748\n",
            "Worker 2, [02/18]: Training Loss: 2.876631800, Training Accuracy: 27.508\n",
            "Worker 2, [03/18]: Training Loss: 2.728536892, Training Accuracy: 30.220\n",
            "Worker 2, [04/18]: Training Loss: 2.605678895, Training Accuracy: 32.880\n",
            "Worker 2, [05/18]: Training Loss: 2.507988159, Training Accuracy: 34.756\n",
            "Worker 2, [06/18]: Training Loss: 2.406097439, Training Accuracy: 37.288\n",
            "Worker 2, [07/18]: Training Loss: 2.297132623, Training Accuracy: 39.204\n",
            "Worker 2, [08/18]: Training Loss: 2.210587402, Training Accuracy: 40.660\n",
            "Worker 2, [09/18]: Training Loss: 3.250844282, Training Accuracy: 21.304\n",
            "Worker 2, [10/18]: Training Loss: 2.792127635, Training Accuracy: 29.300\n",
            "Worker 2, [11/18]: Training Loss: 2.589690896, Training Accuracy: 33.384\n",
            "Worker 2, [12/18]: Training Loss: 2.460558204, Training Accuracy: 36.276\n",
            "Worker 2, [13/18]: Training Loss: 2.344284241, Training Accuracy: 38.952\n",
            "Worker 2, [14/18]: Training Loss: 2.246469437, Training Accuracy: 40.468\n",
            "Worker 2, [15/18]: Training Loss: 2.166330645, Training Accuracy: 42.704\n",
            "Worker 2, [16/18]: Training Loss: 2.085043206, Training Accuracy: 44.364\n",
            "Worker 2, [17/18]: Training Loss: 3.748342687, Training Accuracy: 22.452\n",
            "Worker 2, [18/18]: Training Loss: 3.264146070, Training Accuracy: 23.768\n",
            "Time taken for training worker 2: 0:03:21.708476\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000557\n",
            "Local Step 03: Test Loss: 3.159711511, Test Accuracy: 26.120\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.271260822, Training Accuracy: 23.164\n",
            "Worker 1, [02/18]: Training Loss: 3.231585434, Training Accuracy: 23.800\n",
            "Worker 1, [03/18]: Training Loss: 3.121819189, Training Accuracy: 25.032\n",
            "Worker 1, [04/18]: Training Loss: 2.978403510, Training Accuracy: 26.832\n",
            "Worker 1, [05/18]: Training Loss: 2.842461541, Training Accuracy: 29.028\n",
            "Worker 1, [06/18]: Training Loss: 2.743468254, Training Accuracy: 30.928\n",
            "Worker 1, [07/18]: Training Loss: 2.670210451, Training Accuracy: 32.096\n",
            "Worker 1, [08/18]: Training Loss: 2.617291690, Training Accuracy: 33.304\n",
            "Worker 1, [09/18]: Training Loss: 3.069571616, Training Accuracy: 24.864\n",
            "Worker 1, [10/18]: Training Loss: 2.747818946, Training Accuracy: 30.316\n",
            "Worker 1, [11/18]: Training Loss: 2.636428032, Training Accuracy: 32.300\n",
            "Worker 1, [12/18]: Training Loss: 2.580660192, Training Accuracy: 33.000\n",
            "Worker 1, [13/18]: Training Loss: 2.510007594, Training Accuracy: 34.780\n",
            "Worker 1, [14/18]: Training Loss: 2.473687799, Training Accuracy: 35.660\n",
            "Worker 1, [15/18]: Training Loss: 2.415810909, Training Accuracy: 36.880\n",
            "Worker 1, [16/18]: Training Loss: 2.382589912, Training Accuracy: 37.724\n",
            "Worker 1, [17/18]: Training Loss: 3.018760839, Training Accuracy: 24.976\n",
            "Worker 1, [18/18]: Training Loss: 2.732934318, Training Accuracy: 30.196\n",
            "Time taken for training worker 1: 0:03:23.401841\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.829403011, Training Accuracy: 29.444\n",
            "Worker 2, [02/18]: Training Loss: 2.637439950, Training Accuracy: 32.956\n",
            "Worker 2, [03/18]: Training Loss: 2.513244566, Training Accuracy: 35.448\n",
            "Worker 2, [04/18]: Training Loss: 2.444706452, Training Accuracy: 36.964\n",
            "Worker 2, [05/18]: Training Loss: 2.397603554, Training Accuracy: 37.732\n",
            "Worker 2, [06/18]: Training Loss: 2.357175968, Training Accuracy: 38.656\n",
            "Worker 2, [07/18]: Training Loss: 2.342131114, Training Accuracy: 38.600\n",
            "Worker 2, [08/18]: Training Loss: 2.332163997, Training Accuracy: 39.168\n",
            "Worker 2, [09/18]: Training Loss: 2.989764265, Training Accuracy: 26.536\n",
            "Worker 2, [10/18]: Training Loss: 2.682292230, Training Accuracy: 31.376\n",
            "Worker 2, [11/18]: Training Loss: 2.573902187, Training Accuracy: 33.716\n",
            "Worker 2, [12/18]: Training Loss: 2.521994393, Training Accuracy: 34.888\n",
            "Worker 2, [13/18]: Training Loss: 2.470965470, Training Accuracy: 35.808\n",
            "Worker 2, [14/18]: Training Loss: 2.432304781, Training Accuracy: 36.520\n",
            "Worker 2, [15/18]: Training Loss: 2.386045927, Training Accuracy: 37.312\n",
            "Worker 2, [16/18]: Training Loss: 2.339371190, Training Accuracy: 38.508\n",
            "Worker 2, [17/18]: Training Loss: 2.943751521, Training Accuracy: 26.536\n",
            "Worker 2, [18/18]: Training Loss: 2.676883991, Training Accuracy: 31.412\n",
            "Time taken for training worker 2: 0:03:18.535065\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 04: Test Loss: 2.576753628, Test Accuracy: 34.820\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.706791299, Training Accuracy: 31.544\n",
            "Worker 1, [02/18]: Training Loss: 2.552852058, Training Accuracy: 34.384\n",
            "Worker 1, [03/18]: Training Loss: 2.448129734, Training Accuracy: 36.556\n",
            "Worker 1, [04/18]: Training Loss: 2.359287508, Training Accuracy: 38.332\n",
            "Worker 1, [05/18]: Training Loss: 2.275535562, Training Accuracy: 39.920\n",
            "Worker 1, [06/18]: Training Loss: 2.174784728, Training Accuracy: 42.404\n",
            "Worker 1, [07/18]: Training Loss: 2.111846438, Training Accuracy: 43.704\n",
            "Worker 1, [08/18]: Training Loss: 2.007199640, Training Accuracy: 45.816\n",
            "Worker 1, [09/18]: Training Loss: 2.800020448, Training Accuracy: 29.760\n",
            "Worker 1, [10/18]: Training Loss: 2.484064243, Training Accuracy: 35.644\n",
            "Worker 1, [11/18]: Training Loss: 2.334556067, Training Accuracy: 38.652\n",
            "Worker 1, [12/18]: Training Loss: 2.204090671, Training Accuracy: 41.500\n",
            "Worker 1, [13/18]: Training Loss: 2.085282993, Training Accuracy: 44.180\n",
            "Worker 1, [14/18]: Training Loss: 2.004870010, Training Accuracy: 46.024\n",
            "Worker 1, [15/18]: Training Loss: 1.903215206, Training Accuracy: 48.744\n",
            "Worker 1, [16/18]: Training Loss: 1.837941980, Training Accuracy: 50.108\n",
            "Worker 1, [17/18]: Training Loss: 2.923178225, Training Accuracy: 33.780\n",
            "Worker 1, [18/18]: Training Loss: 2.573387927, Training Accuracy: 35.564\n",
            "Time taken for training worker 1: 0:03:23.668251\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.905079397, Training Accuracy: 27.308\n",
            "Worker 2, [02/18]: Training Loss: 2.671489060, Training Accuracy: 31.380\n",
            "Worker 2, [03/18]: Training Loss: 2.555199837, Training Accuracy: 34.280\n",
            "Worker 2, [04/18]: Training Loss: 2.429229284, Training Accuracy: 36.664\n",
            "Worker 2, [05/18]: Training Loss: 2.335899339, Training Accuracy: 38.740\n",
            "Worker 2, [06/18]: Training Loss: 2.253426873, Training Accuracy: 40.664\n",
            "Worker 2, [07/18]: Training Loss: 2.149596151, Training Accuracy: 42.396\n",
            "Worker 2, [08/18]: Training Loss: 2.062240050, Training Accuracy: 44.540\n",
            "Worker 2, [09/18]: Training Loss: 2.739081371, Training Accuracy: 30.796\n",
            "Worker 2, [10/18]: Training Loss: 2.435674946, Training Accuracy: 36.828\n",
            "Worker 2, [11/18]: Training Loss: 2.282963313, Training Accuracy: 40.200\n",
            "Worker 2, [12/18]: Training Loss: 2.168141357, Training Accuracy: 42.292\n",
            "Worker 2, [13/18]: Training Loss: 2.049328618, Training Accuracy: 44.960\n",
            "Worker 2, [14/18]: Training Loss: 1.962001920, Training Accuracy: 47.100\n",
            "Worker 2, [15/18]: Training Loss: 1.875076865, Training Accuracy: 49.680\n",
            "Worker 2, [16/18]: Training Loss: 1.809676651, Training Accuracy: 51.168\n",
            "Worker 2, [17/18]: Training Loss: 2.861030693, Training Accuracy: 35.352\n",
            "Worker 2, [18/18]: Training Loss: 2.512450816, Training Accuracy: 36.896\n",
            "Time taken for training worker 2: 0:03:18.856357\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000751\n",
            "Local Step 05: Test Loss: 2.455213486, Test Accuracy: 38.060\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.587530568, Training Accuracy: 35.140\n",
            "Worker 1, [02/18]: Training Loss: 2.578050526, Training Accuracy: 34.960\n",
            "Worker 1, [03/18]: Training Loss: 2.536070364, Training Accuracy: 35.828\n",
            "Worker 1, [04/18]: Training Loss: 2.488171277, Training Accuracy: 36.756\n",
            "Worker 1, [05/18]: Training Loss: 2.430466784, Training Accuracy: 37.320\n",
            "Worker 1, [06/18]: Training Loss: 2.388413926, Training Accuracy: 38.372\n",
            "Worker 1, [07/18]: Training Loss: 2.368454806, Training Accuracy: 38.116\n",
            "Worker 1, [08/18]: Training Loss: 2.343303772, Training Accuracy: 38.712\n",
            "Worker 1, [09/18]: Training Loss: 2.603162070, Training Accuracy: 33.248\n",
            "Worker 1, [10/18]: Training Loss: 2.443795366, Training Accuracy: 36.484\n",
            "Worker 1, [11/18]: Training Loss: 2.390612691, Training Accuracy: 37.376\n",
            "Worker 1, [12/18]: Training Loss: 2.333280787, Training Accuracy: 38.744\n",
            "Worker 1, [13/18]: Training Loss: 2.304170630, Training Accuracy: 39.568\n",
            "Worker 1, [14/18]: Training Loss: 2.283496939, Training Accuracy: 40.008\n",
            "Worker 1, [15/18]: Training Loss: 2.244820247, Training Accuracy: 40.732\n",
            "Worker 1, [16/18]: Training Loss: 2.214340887, Training Accuracy: 41.512\n",
            "Worker 1, [17/18]: Training Loss: 2.690661633, Training Accuracy: 31.432\n",
            "Worker 1, [18/18]: Training Loss: 2.503255167, Training Accuracy: 35.236\n",
            "Time taken for training worker 1: 0:03:22.047297\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.624597503, Training Accuracy: 33.340\n",
            "Worker 2, [02/18]: Training Loss: 2.489337856, Training Accuracy: 36.132\n",
            "Worker 2, [03/18]: Training Loss: 2.370547199, Training Accuracy: 38.616\n",
            "Worker 2, [04/18]: Training Loss: 2.291976544, Training Accuracy: 40.328\n",
            "Worker 2, [05/18]: Training Loss: 2.236232472, Training Accuracy: 41.556\n",
            "Worker 2, [06/18]: Training Loss: 2.194883337, Training Accuracy: 42.468\n",
            "Worker 2, [07/18]: Training Loss: 2.170743271, Training Accuracy: 42.820\n",
            "Worker 2, [08/18]: Training Loss: 2.160413507, Training Accuracy: 43.012\n",
            "Worker 2, [09/18]: Training Loss: 2.517672826, Training Accuracy: 35.724\n",
            "Worker 2, [10/18]: Training Loss: 2.379144019, Training Accuracy: 37.312\n",
            "Worker 2, [11/18]: Training Loss: 2.325105021, Training Accuracy: 38.796\n",
            "Worker 2, [12/18]: Training Loss: 2.313715631, Training Accuracy: 39.096\n",
            "Worker 2, [13/18]: Training Loss: 2.274399442, Training Accuracy: 40.104\n",
            "Worker 2, [14/18]: Training Loss: 2.244347873, Training Accuracy: 40.412\n",
            "Worker 2, [15/18]: Training Loss: 2.222966952, Training Accuracy: 41.132\n",
            "Worker 2, [16/18]: Training Loss: 2.182409714, Training Accuracy: 41.780\n",
            "Worker 2, [17/18]: Training Loss: 2.638512249, Training Accuracy: 32.632\n",
            "Worker 2, [18/18]: Training Loss: 2.482108251, Training Accuracy: 35.616\n",
            "Time taken for training worker 2: 0:03:15.819782\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000579\n",
            "Local Step 06: Test Loss: 2.460819474, Test Accuracy: 36.410\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.548009648, Training Accuracy: 34.464\n",
            "Worker 1, [02/18]: Training Loss: 2.431146747, Training Accuracy: 37.156\n",
            "Worker 1, [03/18]: Training Loss: 2.325776981, Training Accuracy: 39.404\n",
            "Worker 1, [04/18]: Training Loss: 2.235116585, Training Accuracy: 41.112\n",
            "Worker 1, [05/18]: Training Loss: 2.152761584, Training Accuracy: 42.920\n",
            "Worker 1, [06/18]: Training Loss: 2.080777842, Training Accuracy: 44.092\n",
            "Worker 1, [07/18]: Training Loss: 1.971797464, Training Accuracy: 46.572\n",
            "Worker 1, [08/18]: Training Loss: 1.900097046, Training Accuracy: 47.892\n",
            "Worker 1, [09/18]: Training Loss: 2.472846545, Training Accuracy: 35.908\n",
            "Worker 1, [10/18]: Training Loss: 2.264910645, Training Accuracy: 40.184\n",
            "Worker 1, [11/18]: Training Loss: 2.113326189, Training Accuracy: 43.600\n",
            "Worker 1, [12/18]: Training Loss: 1.995580962, Training Accuracy: 46.588\n",
            "Worker 1, [13/18]: Training Loss: 1.896640316, Training Accuracy: 48.640\n",
            "Worker 1, [14/18]: Training Loss: 1.792256617, Training Accuracy: 51.144\n",
            "Worker 1, [15/18]: Training Loss: 1.703697376, Training Accuracy: 53.256\n",
            "Worker 1, [16/18]: Training Loss: 1.642016573, Training Accuracy: 54.668\n",
            "Worker 1, [17/18]: Training Loss: 2.366382598, Training Accuracy: 42.616\n",
            "Worker 1, [18/18]: Training Loss: 2.165312744, Training Accuracy: 43.484\n",
            "Time taken for training worker 1: 0:03:20.233916\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.667003102, Training Accuracy: 31.820\n",
            "Worker 2, [02/18]: Training Loss: 2.497279982, Training Accuracy: 35.292\n",
            "Worker 2, [03/18]: Training Loss: 2.408932494, Training Accuracy: 37.200\n",
            "Worker 2, [04/18]: Training Loss: 2.298644481, Training Accuracy: 39.524\n",
            "Worker 2, [05/18]: Training Loss: 2.214435503, Training Accuracy: 41.700\n",
            "Worker 2, [06/18]: Training Loss: 2.133672889, Training Accuracy: 43.064\n",
            "Worker 2, [07/18]: Training Loss: 2.033556865, Training Accuracy: 45.024\n",
            "Worker 2, [08/18]: Training Loss: 1.939578710, Training Accuracy: 47.624\n",
            "Worker 2, [09/18]: Training Loss: 2.391344087, Training Accuracy: 37.712\n",
            "Worker 2, [10/18]: Training Loss: 2.201305321, Training Accuracy: 41.712\n",
            "Worker 2, [11/18]: Training Loss: 2.078229140, Training Accuracy: 44.288\n",
            "Worker 2, [12/18]: Training Loss: 1.967309163, Training Accuracy: 47.052\n",
            "Worker 2, [13/18]: Training Loss: 1.859719285, Training Accuracy: 48.960\n",
            "Worker 2, [14/18]: Training Loss: 1.759581777, Training Accuracy: 52.108\n",
            "Worker 2, [15/18]: Training Loss: 1.679484181, Training Accuracy: 53.868\n",
            "Worker 2, [16/18]: Training Loss: 1.616117329, Training Accuracy: 55.760\n",
            "Worker 2, [17/18]: Training Loss: 2.311833810, Training Accuracy: 44.360\n",
            "Worker 2, [18/18]: Training Loss: 2.094741378, Training Accuracy: 45.180\n",
            "Time taken for training worker 2: 0:03:14.137244\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000509\n",
            "Local Step 07: Test Loss: 2.133111770, Test Accuracy: 44.540\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.271407661, Training Accuracy: 40.988\n",
            "Worker 1, [02/18]: Training Loss: 2.273497426, Training Accuracy: 40.872\n",
            "Worker 1, [03/18]: Training Loss: 2.232413204, Training Accuracy: 41.768\n",
            "Worker 1, [04/18]: Training Loss: 2.209527620, Training Accuracy: 42.280\n",
            "Worker 1, [05/18]: Training Loss: 2.190051350, Training Accuracy: 42.568\n",
            "Worker 1, [06/18]: Training Loss: 2.166045832, Training Accuracy: 42.620\n",
            "Worker 1, [07/18]: Training Loss: 2.159035977, Training Accuracy: 42.792\n",
            "Worker 1, [08/18]: Training Loss: 2.159448636, Training Accuracy: 42.516\n",
            "Worker 1, [09/18]: Training Loss: 2.295411429, Training Accuracy: 39.984\n",
            "Worker 1, [10/18]: Training Loss: 2.227608683, Training Accuracy: 41.064\n",
            "Worker 1, [11/18]: Training Loss: 2.187178819, Training Accuracy: 41.884\n",
            "Worker 1, [12/18]: Training Loss: 2.163887715, Training Accuracy: 42.392\n",
            "Worker 1, [13/18]: Training Loss: 2.167136985, Training Accuracy: 41.704\n",
            "Worker 1, [14/18]: Training Loss: 2.139807678, Training Accuracy: 42.920\n",
            "Worker 1, [15/18]: Training Loss: 2.115234692, Training Accuracy: 43.392\n",
            "Worker 1, [16/18]: Training Loss: 2.081709561, Training Accuracy: 44.120\n",
            "Worker 1, [17/18]: Training Loss: 2.473873248, Training Accuracy: 36.028\n",
            "Worker 1, [18/18]: Training Loss: 2.368969066, Training Accuracy: 37.936\n",
            "Time taken for training worker 1: 0:03:15.691671\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.522406637, Training Accuracy: 35.344\n",
            "Worker 2, [02/18]: Training Loss: 2.394540412, Training Accuracy: 38.096\n",
            "Worker 2, [03/18]: Training Loss: 2.265349441, Training Accuracy: 40.904\n",
            "Worker 2, [04/18]: Training Loss: 2.192432579, Training Accuracy: 42.296\n",
            "Worker 2, [05/18]: Training Loss: 2.127683120, Training Accuracy: 43.908\n",
            "Worker 2, [06/18]: Training Loss: 2.083064466, Training Accuracy: 44.540\n",
            "Worker 2, [07/18]: Training Loss: 2.053105142, Training Accuracy: 45.484\n",
            "Worker 2, [08/18]: Training Loss: 2.039703580, Training Accuracy: 45.432\n",
            "Worker 2, [09/18]: Training Loss: 2.219810287, Training Accuracy: 41.520\n",
            "Worker 2, [10/18]: Training Loss: 2.160964748, Training Accuracy: 42.636\n",
            "Worker 2, [11/18]: Training Loss: 2.147633065, Training Accuracy: 42.908\n",
            "Worker 2, [12/18]: Training Loss: 2.134763471, Training Accuracy: 42.840\n",
            "Worker 2, [13/18]: Training Loss: 2.123999731, Training Accuracy: 43.660\n",
            "Worker 2, [14/18]: Training Loss: 2.112016649, Training Accuracy: 43.424\n",
            "Worker 2, [15/18]: Training Loss: 2.086013536, Training Accuracy: 43.888\n",
            "Worker 2, [16/18]: Training Loss: 2.076884857, Training Accuracy: 44.388\n",
            "Worker 2, [17/18]: Training Loss: 2.427243868, Training Accuracy: 36.664\n",
            "Worker 2, [18/18]: Training Loss: 2.329892895, Training Accuracy: 38.540\n",
            "Time taken for training worker 2: 0:03:15.153309\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000713\n",
            "Local Step 08: Test Loss: 2.319298720, Test Accuracy: 39.880\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:53:23.061916\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.524084960, Training Accuracy: 2.304\n",
            "Worker 1, [02/37]: Training Loss: 4.151393547, Training Accuracy: 5.920\n",
            "Worker 1, [03/37]: Training Loss: 4.337489149, Training Accuracy: 4.352\n",
            "Worker 1, [04/37]: Training Loss: 4.029090465, Training Accuracy: 7.560\n",
            "Worker 1, [05/37]: Training Loss: 4.242298525, Training Accuracy: 5.408\n",
            "Worker 1, [06/37]: Training Loss: 3.907634436, Training Accuracy: 9.704\n",
            "Worker 1, [07/37]: Training Loss: 4.170222135, Training Accuracy: 6.616\n",
            "Worker 1, [08/37]: Training Loss: 3.836878420, Training Accuracy: 10.920\n",
            "Worker 1, [09/37]: Training Loss: 4.089314587, Training Accuracy: 7.472\n",
            "Worker 1, [10/37]: Training Loss: 3.784922243, Training Accuracy: 12.112\n",
            "Worker 1, [11/37]: Training Loss: 4.010619953, Training Accuracy: 9.056\n",
            "Worker 1, [12/37]: Training Loss: 3.727203609, Training Accuracy: 12.728\n",
            "Worker 1, [13/37]: Training Loss: 3.932130485, Training Accuracy: 10.152\n",
            "Worker 1, [14/37]: Training Loss: 3.682092808, Training Accuracy: 13.112\n",
            "Worker 1, [15/37]: Training Loss: 3.864295326, Training Accuracy: 10.984\n",
            "Worker 1, [16/37]: Training Loss: 3.631401394, Training Accuracy: 14.080\n",
            "Worker 1, [17/37]: Training Loss: 3.814371858, Training Accuracy: 11.936\n",
            "Worker 1, [18/37]: Training Loss: 3.600969361, Training Accuracy: 14.760\n",
            "Worker 1, [19/37]: Training Loss: 3.758540452, Training Accuracy: 12.616\n",
            "Worker 1, [20/37]: Training Loss: 3.548407606, Training Accuracy: 15.648\n",
            "Worker 1, [21/37]: Training Loss: 3.705950589, Training Accuracy: 13.432\n",
            "Worker 1, [22/37]: Training Loss: 3.513421633, Training Accuracy: 15.720\n",
            "Worker 1, [23/37]: Training Loss: 3.671023267, Training Accuracy: 14.176\n",
            "Worker 1, [24/37]: Training Loss: 3.488793189, Training Accuracy: 17.112\n",
            "Worker 1, [25/37]: Training Loss: 3.628217478, Training Accuracy: 14.976\n",
            "Worker 1, [26/37]: Training Loss: 3.475043178, Training Accuracy: 17.144\n",
            "Worker 1, [27/37]: Training Loss: 3.590492497, Training Accuracy: 15.600\n",
            "Worker 1, [28/37]: Training Loss: 3.451524287, Training Accuracy: 17.384\n",
            "Worker 1, [29/37]: Training Loss: 3.564150245, Training Accuracy: 16.632\n",
            "Worker 1, [30/37]: Training Loss: 3.439734238, Training Accuracy: 18.360\n",
            "Worker 1, [31/37]: Training Loss: 3.547837021, Training Accuracy: 16.824\n",
            "Worker 1, [32/37]: Training Loss: 3.441377483, Training Accuracy: 17.904\n",
            "Worker 1, [33/37]: Training Loss: 3.541569945, Training Accuracy: 17.536\n",
            "Worker 1, [34/37]: Training Loss: 3.446675852, Training Accuracy: 17.936\n",
            "Worker 1, [35/37]: Training Loss: 3.570694304, Training Accuracy: 18.160\n",
            "Worker 1, [36/37]: Training Loss: 3.493519747, Training Accuracy: 18.184\n",
            "Worker 1, [37/37]: Training Loss: 3.630367562, Training Accuracy: 18.240\n",
            "Time taken for training worker 1: 0:03:20.235363\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.524461206, Training Accuracy: 2.304\n",
            "Worker 2, [02/37]: Training Loss: 4.141798982, Training Accuracy: 6.152\n",
            "Worker 2, [03/37]: Training Loss: 4.337643245, Training Accuracy: 4.192\n",
            "Worker 2, [04/37]: Training Loss: 3.988340953, Training Accuracy: 8.264\n",
            "Worker 2, [05/37]: Training Loss: 4.229707793, Training Accuracy: 5.856\n",
            "Worker 2, [06/37]: Training Loss: 3.883732944, Training Accuracy: 9.976\n",
            "Worker 2, [07/37]: Training Loss: 4.152560409, Training Accuracy: 6.848\n",
            "Worker 2, [08/37]: Training Loss: 3.831074014, Training Accuracy: 10.632\n",
            "Worker 2, [09/37]: Training Loss: 4.069579210, Training Accuracy: 8.192\n",
            "Worker 2, [10/37]: Training Loss: 3.777487707, Training Accuracy: 11.752\n",
            "Worker 2, [11/37]: Training Loss: 4.000638458, Training Accuracy: 9.120\n",
            "Worker 2, [12/37]: Training Loss: 3.724950237, Training Accuracy: 12.352\n",
            "Worker 2, [13/37]: Training Loss: 3.922712341, Training Accuracy: 10.120\n",
            "Worker 2, [14/37]: Training Loss: 3.670157596, Training Accuracy: 13.384\n",
            "Worker 2, [15/37]: Training Loss: 3.861232547, Training Accuracy: 10.832\n",
            "Worker 2, [16/37]: Training Loss: 3.625514579, Training Accuracy: 14.056\n",
            "Worker 2, [17/37]: Training Loss: 3.804503972, Training Accuracy: 11.848\n",
            "Worker 2, [18/37]: Training Loss: 3.583376801, Training Accuracy: 14.760\n",
            "Worker 2, [19/37]: Training Loss: 3.744126189, Training Accuracy: 12.816\n",
            "Worker 2, [20/37]: Training Loss: 3.545769122, Training Accuracy: 15.400\n",
            "Worker 2, [21/37]: Training Loss: 3.703412333, Training Accuracy: 13.184\n",
            "Worker 2, [22/37]: Training Loss: 3.499410427, Training Accuracy: 16.584\n",
            "Worker 2, [23/37]: Training Loss: 3.645086892, Training Accuracy: 14.560\n",
            "Worker 2, [24/37]: Training Loss: 3.485441196, Training Accuracy: 16.544\n",
            "Worker 2, [25/37]: Training Loss: 3.609304210, Training Accuracy: 14.816\n",
            "Worker 2, [26/37]: Training Loss: 3.452035287, Training Accuracy: 17.176\n",
            "Worker 2, [27/37]: Training Loss: 3.572377081, Training Accuracy: 16.200\n",
            "Worker 2, [28/37]: Training Loss: 3.442032706, Training Accuracy: 17.136\n",
            "Worker 2, [29/37]: Training Loss: 3.545449568, Training Accuracy: 16.264\n",
            "Worker 2, [30/37]: Training Loss: 3.432770322, Training Accuracy: 17.952\n",
            "Worker 2, [31/37]: Training Loss: 3.526636427, Training Accuracy: 17.392\n",
            "Worker 2, [32/37]: Training Loss: 3.422748122, Training Accuracy: 18.176\n",
            "Worker 2, [33/37]: Training Loss: 3.525674687, Training Accuracy: 17.408\n",
            "Worker 2, [34/37]: Training Loss: 3.438082549, Training Accuracy: 17.832\n",
            "Worker 2, [35/37]: Training Loss: 3.561726183, Training Accuracy: 17.824\n",
            "Worker 2, [36/37]: Training Loss: 3.478736385, Training Accuracy: 17.952\n",
            "Worker 2, [37/37]: Training Loss: 3.621178230, Training Accuracy: 18.304\n",
            "Time taken for training worker 2: 0:03:20.960043\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.524940795, Training Accuracy: 2.560\n",
            "Worker 3, [02/37]: Training Loss: 4.137532167, Training Accuracy: 6.608\n",
            "Worker 3, [03/37]: Training Loss: 4.372845905, Training Accuracy: 4.280\n",
            "Worker 3, [04/37]: Training Loss: 3.976731564, Training Accuracy: 8.312\n",
            "Worker 3, [05/37]: Training Loss: 4.241930423, Training Accuracy: 5.552\n",
            "Worker 3, [06/37]: Training Loss: 3.902977690, Training Accuracy: 9.536\n",
            "Worker 3, [07/37]: Training Loss: 4.125058214, Training Accuracy: 7.008\n",
            "Worker 3, [08/37]: Training Loss: 3.821977685, Training Accuracy: 11.016\n",
            "Worker 3, [09/37]: Training Loss: 4.083501722, Training Accuracy: 7.648\n",
            "Worker 3, [10/37]: Training Loss: 3.779117112, Training Accuracy: 11.216\n",
            "Worker 3, [11/37]: Training Loss: 3.971056453, Training Accuracy: 9.144\n",
            "Worker 3, [12/37]: Training Loss: 3.724331141, Training Accuracy: 11.952\n",
            "Worker 3, [13/37]: Training Loss: 3.908966021, Training Accuracy: 9.880\n",
            "Worker 3, [14/37]: Training Loss: 3.668768703, Training Accuracy: 13.208\n",
            "Worker 3, [15/37]: Training Loss: 3.867415303, Training Accuracy: 10.376\n",
            "Worker 3, [16/37]: Training Loss: 3.627989959, Training Accuracy: 13.536\n",
            "Worker 3, [17/37]: Training Loss: 3.800243919, Training Accuracy: 11.600\n",
            "Worker 3, [18/37]: Training Loss: 3.576503377, Training Accuracy: 14.816\n",
            "Worker 3, [19/37]: Training Loss: 3.754703186, Training Accuracy: 12.792\n",
            "Worker 3, [20/37]: Training Loss: 3.553504434, Training Accuracy: 15.264\n",
            "Worker 3, [21/37]: Training Loss: 3.701142685, Training Accuracy: 13.336\n",
            "Worker 3, [22/37]: Training Loss: 3.513239188, Training Accuracy: 15.712\n",
            "Worker 3, [23/37]: Training Loss: 3.659542076, Training Accuracy: 14.152\n",
            "Worker 3, [24/37]: Training Loss: 3.486402655, Training Accuracy: 16.800\n",
            "Worker 3, [25/37]: Training Loss: 3.614125657, Training Accuracy: 14.984\n",
            "Worker 3, [26/37]: Training Loss: 3.460451486, Training Accuracy: 17.072\n",
            "Worker 3, [27/37]: Training Loss: 3.577894251, Training Accuracy: 15.608\n",
            "Worker 3, [28/37]: Training Loss: 3.449261510, Training Accuracy: 16.816\n",
            "Worker 3, [29/37]: Training Loss: 3.556795608, Training Accuracy: 16.432\n",
            "Worker 3, [30/37]: Training Loss: 3.443835904, Training Accuracy: 17.352\n",
            "Worker 3, [31/37]: Training Loss: 3.551077964, Training Accuracy: 16.280\n",
            "Worker 3, [32/37]: Training Loss: 3.441462962, Training Accuracy: 17.880\n",
            "Worker 3, [33/37]: Training Loss: 3.543194711, Training Accuracy: 17.032\n",
            "Worker 3, [34/37]: Training Loss: 3.449079060, Training Accuracy: 17.720\n",
            "Worker 3, [35/37]: Training Loss: 3.574649744, Training Accuracy: 17.480\n",
            "Worker 3, [36/37]: Training Loss: 3.494550912, Training Accuracy: 17.336\n",
            "Worker 3, [37/37]: Training Loss: 3.624034267, Training Accuracy: 18.112\n",
            "Time taken for training worker 3: 0:03:22.641469\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.531819239, Training Accuracy: 2.360\n",
            "Worker 4, [02/37]: Training Loss: 4.157831471, Training Accuracy: 5.800\n",
            "Worker 4, [03/37]: Training Loss: 4.382574165, Training Accuracy: 3.960\n",
            "Worker 4, [04/37]: Training Loss: 4.008262219, Training Accuracy: 7.784\n",
            "Worker 4, [05/37]: Training Loss: 4.295296473, Training Accuracy: 4.856\n",
            "Worker 4, [06/37]: Training Loss: 3.919676159, Training Accuracy: 9.256\n",
            "Worker 4, [07/37]: Training Loss: 4.157040080, Training Accuracy: 6.312\n",
            "Worker 4, [08/37]: Training Loss: 3.837488553, Training Accuracy: 10.416\n",
            "Worker 4, [09/37]: Training Loss: 4.052163189, Training Accuracy: 7.744\n",
            "Worker 4, [10/37]: Training Loss: 3.765742004, Training Accuracy: 11.400\n",
            "Worker 4, [11/37]: Training Loss: 3.985595852, Training Accuracy: 8.816\n",
            "Worker 4, [12/37]: Training Loss: 3.710472965, Training Accuracy: 12.344\n",
            "Worker 4, [13/37]: Training Loss: 3.945251767, Training Accuracy: 9.056\n",
            "Worker 4, [14/37]: Training Loss: 3.665812897, Training Accuracy: 13.384\n",
            "Worker 4, [15/37]: Training Loss: 3.877278287, Training Accuracy: 10.056\n",
            "Worker 4, [16/37]: Training Loss: 3.624949818, Training Accuracy: 13.640\n",
            "Worker 4, [17/37]: Training Loss: 3.814909400, Training Accuracy: 11.680\n",
            "Worker 4, [18/37]: Training Loss: 3.591941601, Training Accuracy: 14.632\n",
            "Worker 4, [19/37]: Training Loss: 3.761587446, Training Accuracy: 11.952\n",
            "Worker 4, [20/37]: Training Loss: 3.544207895, Training Accuracy: 15.144\n",
            "Worker 4, [21/37]: Training Loss: 3.700187047, Training Accuracy: 13.352\n",
            "Worker 4, [22/37]: Training Loss: 3.518479027, Training Accuracy: 16.056\n",
            "Worker 4, [23/37]: Training Loss: 3.672396789, Training Accuracy: 13.896\n",
            "Worker 4, [24/37]: Training Loss: 3.496915520, Training Accuracy: 16.376\n",
            "Worker 4, [25/37]: Training Loss: 3.630298044, Training Accuracy: 14.656\n",
            "Worker 4, [26/37]: Training Loss: 3.475646967, Training Accuracy: 16.960\n",
            "Worker 4, [27/37]: Training Loss: 3.590617031, Training Accuracy: 15.760\n",
            "Worker 4, [28/37]: Training Loss: 3.453853323, Training Accuracy: 17.184\n",
            "Worker 4, [29/37]: Training Loss: 3.567971665, Training Accuracy: 16.200\n",
            "Worker 4, [30/37]: Training Loss: 3.432217283, Training Accuracy: 17.856\n",
            "Worker 4, [31/37]: Training Loss: 3.534732986, Training Accuracy: 16.992\n",
            "Worker 4, [32/37]: Training Loss: 3.443001548, Training Accuracy: 17.832\n",
            "Worker 4, [33/37]: Training Loss: 3.544506047, Training Accuracy: 17.160\n",
            "Worker 4, [34/37]: Training Loss: 3.452123303, Training Accuracy: 17.600\n",
            "Worker 4, [35/37]: Training Loss: 3.567474723, Training Accuracy: 17.840\n",
            "Worker 4, [36/37]: Training Loss: 3.493276499, Training Accuracy: 17.544\n",
            "Worker 4, [37/37]: Training Loss: 3.629048565, Training Accuracy: 18.088\n",
            "Time taken for training worker 4: 0:03:22.389584\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000675\n",
            "Local Step 01: Test Loss: 3.755801875, Test Accuracy: 17.550\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.798541224, Training Accuracy: 16.160\n",
            "Worker 1, [02/37]: Training Loss: 3.780951381, Training Accuracy: 16.176\n",
            "Worker 1, [03/37]: Training Loss: 3.615140852, Training Accuracy: 18.264\n",
            "Worker 1, [04/37]: Training Loss: 3.524363094, Training Accuracy: 17.952\n",
            "Worker 1, [05/37]: Training Loss: 3.540599254, Training Accuracy: 17.264\n",
            "Worker 1, [06/37]: Training Loss: 3.474191888, Training Accuracy: 17.784\n",
            "Worker 1, [07/37]: Training Loss: 3.505169996, Training Accuracy: 17.736\n",
            "Worker 1, [08/37]: Training Loss: 3.448665533, Training Accuracy: 17.848\n",
            "Worker 1, [09/37]: Training Loss: 3.487886287, Training Accuracy: 17.288\n",
            "Worker 1, [10/37]: Training Loss: 3.438025117, Training Accuracy: 17.600\n",
            "Worker 1, [11/37]: Training Loss: 3.485596668, Training Accuracy: 17.328\n",
            "Worker 1, [12/37]: Training Loss: 3.433189475, Training Accuracy: 17.424\n",
            "Worker 1, [13/37]: Training Loss: 3.492631534, Training Accuracy: 16.912\n",
            "Worker 1, [14/37]: Training Loss: 3.419633795, Training Accuracy: 17.752\n",
            "Worker 1, [15/37]: Training Loss: 3.492105783, Training Accuracy: 16.480\n",
            "Worker 1, [16/37]: Training Loss: 3.415659487, Training Accuracy: 18.056\n",
            "Worker 1, [17/37]: Training Loss: 3.487353770, Training Accuracy: 16.384\n",
            "Worker 1, [18/37]: Training Loss: 3.405998297, Training Accuracy: 17.544\n",
            "Worker 1, [19/37]: Training Loss: 3.481433277, Training Accuracy: 16.544\n",
            "Worker 1, [20/37]: Training Loss: 3.400327623, Training Accuracy: 17.920\n",
            "Worker 1, [21/37]: Training Loss: 3.493471901, Training Accuracy: 16.584\n",
            "Worker 1, [22/37]: Training Loss: 3.392912267, Training Accuracy: 17.928\n",
            "Worker 1, [23/37]: Training Loss: 3.479383450, Training Accuracy: 17.376\n",
            "Worker 1, [24/37]: Training Loss: 3.380345393, Training Accuracy: 18.592\n",
            "Worker 1, [25/37]: Training Loss: 3.467395371, Training Accuracy: 16.168\n",
            "Worker 1, [26/37]: Training Loss: 3.365598404, Training Accuracy: 17.952\n",
            "Worker 1, [27/37]: Training Loss: 3.457648401, Training Accuracy: 17.120\n",
            "Worker 1, [28/37]: Training Loss: 3.330598368, Training Accuracy: 19.168\n",
            "Worker 1, [29/37]: Training Loss: 3.429102482, Training Accuracy: 17.032\n",
            "Worker 1, [30/37]: Training Loss: 3.303052476, Training Accuracy: 19.744\n",
            "Worker 1, [31/37]: Training Loss: 3.424955894, Training Accuracy: 17.672\n",
            "Worker 1, [32/37]: Training Loss: 3.312427962, Training Accuracy: 19.656\n",
            "Worker 1, [33/37]: Training Loss: 3.407341672, Training Accuracy: 17.816\n",
            "Worker 1, [34/37]: Training Loss: 3.284205816, Training Accuracy: 19.728\n",
            "Worker 1, [35/37]: Training Loss: 3.376206179, Training Accuracy: 18.512\n",
            "Worker 1, [36/37]: Training Loss: 3.240372796, Training Accuracy: 20.656\n",
            "Worker 1, [37/37]: Training Loss: 3.351759518, Training Accuracy: 18.752\n",
            "Time taken for training worker 1: 0:03:17.554349\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.433386460, Training Accuracy: 16.704\n",
            "Worker 2, [02/37]: Training Loss: 3.370374221, Training Accuracy: 18.096\n",
            "Worker 2, [03/37]: Training Loss: 3.585013747, Training Accuracy: 18.016\n",
            "Worker 2, [04/37]: Training Loss: 3.485488583, Training Accuracy: 17.872\n",
            "Worker 2, [05/37]: Training Loss: 3.503983007, Training Accuracy: 17.904\n",
            "Worker 2, [06/37]: Training Loss: 3.419127069, Training Accuracy: 18.296\n",
            "Worker 2, [07/37]: Training Loss: 3.459136521, Training Accuracy: 17.480\n",
            "Worker 2, [08/37]: Training Loss: 3.404655874, Training Accuracy: 18.576\n",
            "Worker 2, [09/37]: Training Loss: 3.450432582, Training Accuracy: 17.688\n",
            "Worker 2, [10/37]: Training Loss: 3.379765169, Training Accuracy: 18.712\n",
            "Worker 2, [11/37]: Training Loss: 3.440069003, Training Accuracy: 17.760\n",
            "Worker 2, [12/37]: Training Loss: 3.386784938, Training Accuracy: 18.488\n",
            "Worker 2, [13/37]: Training Loss: 3.441396365, Training Accuracy: 17.552\n",
            "Worker 2, [14/37]: Training Loss: 3.376891781, Training Accuracy: 18.448\n",
            "Worker 2, [15/37]: Training Loss: 3.452368449, Training Accuracy: 17.272\n",
            "Worker 2, [16/37]: Training Loss: 3.376707963, Training Accuracy: 18.712\n",
            "Worker 2, [17/37]: Training Loss: 3.463311971, Training Accuracy: 16.592\n",
            "Worker 2, [18/37]: Training Loss: 3.364282815, Training Accuracy: 18.256\n",
            "Worker 2, [19/37]: Training Loss: 3.446837268, Training Accuracy: 17.080\n",
            "Worker 2, [20/37]: Training Loss: 3.354772210, Training Accuracy: 18.496\n",
            "Worker 2, [21/37]: Training Loss: 3.447715573, Training Accuracy: 17.336\n",
            "Worker 2, [22/37]: Training Loss: 3.359140422, Training Accuracy: 18.896\n",
            "Worker 2, [23/37]: Training Loss: 3.440823953, Training Accuracy: 17.256\n",
            "Worker 2, [24/37]: Training Loss: 3.341131758, Training Accuracy: 18.432\n",
            "Worker 2, [25/37]: Training Loss: 3.439961300, Training Accuracy: 16.976\n",
            "Worker 2, [26/37]: Training Loss: 3.310899249, Training Accuracy: 19.312\n",
            "Worker 2, [27/37]: Training Loss: 3.423177098, Training Accuracy: 17.680\n",
            "Worker 2, [28/37]: Training Loss: 3.307439491, Training Accuracy: 19.600\n",
            "Worker 2, [29/37]: Training Loss: 3.405321528, Training Accuracy: 17.480\n",
            "Worker 2, [30/37]: Training Loss: 3.284832336, Training Accuracy: 19.968\n",
            "Worker 2, [31/37]: Training Loss: 3.383237780, Training Accuracy: 18.096\n",
            "Worker 2, [32/37]: Training Loss: 3.270640767, Training Accuracy: 19.392\n",
            "Worker 2, [33/37]: Training Loss: 3.379877106, Training Accuracy: 18.184\n",
            "Worker 2, [34/37]: Training Loss: 3.269870568, Training Accuracy: 19.936\n",
            "Worker 2, [35/37]: Training Loss: 3.348815916, Training Accuracy: 18.072\n",
            "Worker 2, [36/37]: Training Loss: 3.220858322, Training Accuracy: 20.880\n",
            "Worker 2, [37/37]: Training Loss: 3.316977810, Training Accuracy: 19.192\n",
            "Time taken for training worker 2: 0:03:17.849616\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.323172152, Training Accuracy: 19.424\n",
            "Worker 3, [02/37]: Training Loss: 3.303044368, Training Accuracy: 19.920\n",
            "Worker 3, [03/37]: Training Loss: 3.592920054, Training Accuracy: 17.904\n",
            "Worker 3, [04/37]: Training Loss: 3.494906615, Training Accuracy: 17.880\n",
            "Worker 3, [05/37]: Training Loss: 3.510814679, Training Accuracy: 17.464\n",
            "Worker 3, [06/37]: Training Loss: 3.431459528, Training Accuracy: 18.144\n",
            "Worker 3, [07/37]: Training Loss: 3.480172414, Training Accuracy: 17.904\n",
            "Worker 3, [08/37]: Training Loss: 3.408884923, Training Accuracy: 18.528\n",
            "Worker 3, [09/37]: Training Loss: 3.460818952, Training Accuracy: 17.312\n",
            "Worker 3, [10/37]: Training Loss: 3.388453999, Training Accuracy: 18.080\n",
            "Worker 3, [11/37]: Training Loss: 3.448876462, Training Accuracy: 17.192\n",
            "Worker 3, [12/37]: Training Loss: 3.378535488, Training Accuracy: 18.472\n",
            "Worker 3, [13/37]: Training Loss: 3.445591621, Training Accuracy: 17.792\n",
            "Worker 3, [14/37]: Training Loss: 3.377054050, Training Accuracy: 18.472\n",
            "Worker 3, [15/37]: Training Loss: 3.452155243, Training Accuracy: 17.424\n",
            "Worker 3, [16/37]: Training Loss: 3.369531462, Training Accuracy: 18.752\n",
            "Worker 3, [17/37]: Training Loss: 3.444327680, Training Accuracy: 16.960\n",
            "Worker 3, [18/37]: Training Loss: 3.367247679, Training Accuracy: 18.648\n",
            "Worker 3, [19/37]: Training Loss: 3.452611302, Training Accuracy: 16.856\n",
            "Worker 3, [20/37]: Training Loss: 3.346988759, Training Accuracy: 18.672\n",
            "Worker 3, [21/37]: Training Loss: 3.444064109, Training Accuracy: 16.944\n",
            "Worker 3, [22/37]: Training Loss: 3.336009454, Training Accuracy: 18.936\n",
            "Worker 3, [23/37]: Training Loss: 3.446165502, Training Accuracy: 17.000\n",
            "Worker 3, [24/37]: Training Loss: 3.329717148, Training Accuracy: 19.104\n",
            "Worker 3, [25/37]: Training Loss: 3.443853100, Training Accuracy: 16.808\n",
            "Worker 3, [26/37]: Training Loss: 3.305328207, Training Accuracy: 19.320\n",
            "Worker 3, [27/37]: Training Loss: 3.401408693, Training Accuracy: 17.560\n",
            "Worker 3, [28/37]: Training Loss: 3.283529616, Training Accuracy: 19.192\n",
            "Worker 3, [29/37]: Training Loss: 3.382072104, Training Accuracy: 18.328\n",
            "Worker 3, [30/37]: Training Loss: 3.249302343, Training Accuracy: 20.248\n",
            "Worker 3, [31/37]: Training Loss: 3.367011351, Training Accuracy: 18.240\n",
            "Worker 3, [32/37]: Training Loss: 3.257401177, Training Accuracy: 20.344\n",
            "Worker 3, [33/37]: Training Loss: 3.357391238, Training Accuracy: 18.336\n",
            "Worker 3, [34/37]: Training Loss: 3.230681054, Training Accuracy: 20.368\n",
            "Worker 3, [35/37]: Training Loss: 3.340640372, Training Accuracy: 18.304\n",
            "Worker 3, [36/37]: Training Loss: 3.224218918, Training Accuracy: 20.552\n",
            "Worker 3, [37/37]: Training Loss: 3.310024337, Training Accuracy: 19.376\n",
            "Time taken for training worker 3: 0:03:20.916822\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.407180627, Training Accuracy: 18.392\n",
            "Worker 4, [02/37]: Training Loss: 3.378271181, Training Accuracy: 19.064\n",
            "Worker 4, [03/37]: Training Loss: 3.576441677, Training Accuracy: 18.272\n",
            "Worker 4, [04/37]: Training Loss: 3.485475928, Training Accuracy: 18.192\n",
            "Worker 4, [05/37]: Training Loss: 3.505261053, Training Accuracy: 18.024\n",
            "Worker 4, [06/37]: Training Loss: 3.424371435, Training Accuracy: 18.448\n",
            "Worker 4, [07/37]: Training Loss: 3.460960752, Training Accuracy: 17.784\n",
            "Worker 4, [08/37]: Training Loss: 3.404856631, Training Accuracy: 18.312\n",
            "Worker 4, [09/37]: Training Loss: 3.451935397, Training Accuracy: 18.080\n",
            "Worker 4, [10/37]: Training Loss: 3.392563856, Training Accuracy: 17.792\n",
            "Worker 4, [11/37]: Training Loss: 3.437243108, Training Accuracy: 17.672\n",
            "Worker 4, [12/37]: Training Loss: 3.379184416, Training Accuracy: 18.584\n",
            "Worker 4, [13/37]: Training Loss: 3.450835566, Training Accuracy: 17.064\n",
            "Worker 4, [14/37]: Training Loss: 3.375819908, Training Accuracy: 18.392\n",
            "Worker 4, [15/37]: Training Loss: 3.439819823, Training Accuracy: 17.408\n",
            "Worker 4, [16/37]: Training Loss: 3.367536483, Training Accuracy: 18.160\n",
            "Worker 4, [17/37]: Training Loss: 3.447219541, Training Accuracy: 17.112\n",
            "Worker 4, [18/37]: Training Loss: 3.357017296, Training Accuracy: 18.656\n",
            "Worker 4, [19/37]: Training Loss: 3.447676650, Training Accuracy: 17.224\n",
            "Worker 4, [20/37]: Training Loss: 3.350976096, Training Accuracy: 18.904\n",
            "Worker 4, [21/37]: Training Loss: 3.427583563, Training Accuracy: 17.176\n",
            "Worker 4, [22/37]: Training Loss: 3.323716130, Training Accuracy: 19.064\n",
            "Worker 4, [23/37]: Training Loss: 3.427825524, Training Accuracy: 17.384\n",
            "Worker 4, [24/37]: Training Loss: 3.326157880, Training Accuracy: 19.288\n",
            "Worker 4, [25/37]: Training Loss: 3.430068049, Training Accuracy: 17.760\n",
            "Worker 4, [26/37]: Training Loss: 3.301068153, Training Accuracy: 19.680\n",
            "Worker 4, [27/37]: Training Loss: 3.400538519, Training Accuracy: 17.632\n",
            "Worker 4, [28/37]: Training Loss: 3.281758081, Training Accuracy: 19.616\n",
            "Worker 4, [29/37]: Training Loss: 3.393202031, Training Accuracy: 18.448\n",
            "Worker 4, [30/37]: Training Loss: 3.265343120, Training Accuracy: 20.152\n",
            "Worker 4, [31/37]: Training Loss: 3.383951131, Training Accuracy: 17.848\n",
            "Worker 4, [32/37]: Training Loss: 3.245832801, Training Accuracy: 20.032\n",
            "Worker 4, [33/37]: Training Loss: 3.364691222, Training Accuracy: 18.024\n",
            "Worker 4, [34/37]: Training Loss: 3.256920530, Training Accuracy: 19.384\n",
            "Worker 4, [35/37]: Training Loss: 3.331086492, Training Accuracy: 18.768\n",
            "Worker 4, [36/37]: Training Loss: 3.214236885, Training Accuracy: 21.064\n",
            "Worker 4, [37/37]: Training Loss: 3.314041653, Training Accuracy: 19.008\n",
            "Time taken for training worker 4: 0:03:23.544748\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000726\n",
            "Local Step 02: Test Loss: 3.282206455, Test Accuracy: 20.710\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.315020579, Training Accuracy: 19.568\n",
            "Worker 1, [02/37]: Training Loss: 3.162851238, Training Accuracy: 21.920\n",
            "Worker 1, [03/37]: Training Loss: 3.335452299, Training Accuracy: 18.624\n",
            "Worker 1, [04/37]: Training Loss: 3.218379251, Training Accuracy: 20.912\n",
            "Worker 1, [05/37]: Training Loss: 3.301952626, Training Accuracy: 19.568\n",
            "Worker 1, [06/37]: Training Loss: 3.195036372, Training Accuracy: 21.104\n",
            "Worker 1, [07/37]: Training Loss: 3.252497519, Training Accuracy: 20.688\n",
            "Worker 1, [08/37]: Training Loss: 3.156702213, Training Accuracy: 22.272\n",
            "Worker 1, [09/37]: Training Loss: 3.217703799, Training Accuracy: 21.248\n",
            "Worker 1, [10/37]: Training Loss: 3.113490954, Training Accuracy: 22.808\n",
            "Worker 1, [11/37]: Training Loss: 3.171843187, Training Accuracy: 21.760\n",
            "Worker 1, [12/37]: Training Loss: 3.069145063, Training Accuracy: 24.080\n",
            "Worker 1, [13/37]: Training Loss: 3.154401203, Training Accuracy: 22.112\n",
            "Worker 1, [14/37]: Training Loss: 3.045052586, Training Accuracy: 24.240\n",
            "Worker 1, [15/37]: Training Loss: 3.101716269, Training Accuracy: 23.584\n",
            "Worker 1, [16/37]: Training Loss: 2.993719169, Training Accuracy: 25.216\n",
            "Worker 1, [17/37]: Training Loss: 3.051973656, Training Accuracy: 24.216\n",
            "Worker 1, [18/37]: Training Loss: 2.964870481, Training Accuracy: 25.816\n",
            "Worker 1, [19/37]: Training Loss: 3.000283915, Training Accuracy: 25.376\n",
            "Worker 1, [20/37]: Training Loss: 2.907097761, Training Accuracy: 26.384\n",
            "Worker 1, [21/37]: Training Loss: 2.938718015, Training Accuracy: 26.800\n",
            "Worker 1, [22/37]: Training Loss: 2.864258782, Training Accuracy: 27.592\n",
            "Worker 1, [23/37]: Training Loss: 2.910134015, Training Accuracy: 26.744\n",
            "Worker 1, [24/37]: Training Loss: 2.831983100, Training Accuracy: 28.064\n",
            "Worker 1, [25/37]: Training Loss: 2.850090898, Training Accuracy: 28.296\n",
            "Worker 1, [26/37]: Training Loss: 2.768207776, Training Accuracy: 30.104\n",
            "Worker 1, [27/37]: Training Loss: 2.811918088, Training Accuracy: 29.560\n",
            "Worker 1, [28/37]: Training Loss: 2.748223861, Training Accuracy: 30.488\n",
            "Worker 1, [29/37]: Training Loss: 2.773458787, Training Accuracy: 30.440\n",
            "Worker 1, [30/37]: Training Loss: 2.722526253, Training Accuracy: 31.104\n",
            "Worker 1, [31/37]: Training Loss: 2.741426524, Training Accuracy: 30.568\n",
            "Worker 1, [32/37]: Training Loss: 2.691651707, Training Accuracy: 31.416\n",
            "Worker 1, [33/37]: Training Loss: 2.738358451, Training Accuracy: 31.272\n",
            "Worker 1, [34/37]: Training Loss: 2.693240043, Training Accuracy: 32.008\n",
            "Worker 1, [35/37]: Training Loss: 2.718324332, Training Accuracy: 31.744\n",
            "Worker 1, [36/37]: Training Loss: 2.700612383, Training Accuracy: 31.592\n",
            "Worker 1, [37/37]: Training Loss: 2.728826683, Training Accuracy: 31.544\n",
            "Time taken for training worker 1: 0:03:21.136745\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.226516986, Training Accuracy: 21.024\n",
            "Worker 2, [02/37]: Training Loss: 3.124005006, Training Accuracy: 22.952\n",
            "Worker 2, [03/37]: Training Loss: 3.291817768, Training Accuracy: 19.616\n",
            "Worker 2, [04/37]: Training Loss: 3.164440893, Training Accuracy: 21.976\n",
            "Worker 2, [05/37]: Training Loss: 3.251442498, Training Accuracy: 20.712\n",
            "Worker 2, [06/37]: Training Loss: 3.145688473, Training Accuracy: 22.216\n",
            "Worker 2, [07/37]: Training Loss: 3.218516015, Training Accuracy: 20.680\n",
            "Worker 2, [08/37]: Training Loss: 3.111041882, Training Accuracy: 22.696\n",
            "Worker 2, [09/37]: Training Loss: 3.186535170, Training Accuracy: 21.656\n",
            "Worker 2, [10/37]: Training Loss: 3.062179995, Training Accuracy: 23.560\n",
            "Worker 2, [11/37]: Training Loss: 3.124519497, Training Accuracy: 22.656\n",
            "Worker 2, [12/37]: Training Loss: 3.028751590, Training Accuracy: 24.600\n",
            "Worker 2, [13/37]: Training Loss: 3.102707921, Training Accuracy: 23.112\n",
            "Worker 2, [14/37]: Training Loss: 2.998710326, Training Accuracy: 25.248\n",
            "Worker 2, [15/37]: Training Loss: 3.040118346, Training Accuracy: 24.088\n",
            "Worker 2, [16/37]: Training Loss: 2.956952732, Training Accuracy: 25.712\n",
            "Worker 2, [17/37]: Training Loss: 2.984030758, Training Accuracy: 24.984\n",
            "Worker 2, [18/37]: Training Loss: 2.899597116, Training Accuracy: 26.472\n",
            "Worker 2, [19/37]: Training Loss: 2.947836372, Training Accuracy: 25.824\n",
            "Worker 2, [20/37]: Training Loss: 2.842451658, Training Accuracy: 28.288\n",
            "Worker 2, [21/37]: Training Loss: 2.897165234, Training Accuracy: 26.928\n",
            "Worker 2, [22/37]: Training Loss: 2.814399117, Training Accuracy: 28.488\n",
            "Worker 2, [23/37]: Training Loss: 2.840162517, Training Accuracy: 28.240\n",
            "Worker 2, [24/37]: Training Loss: 2.772990311, Training Accuracy: 29.488\n",
            "Worker 2, [25/37]: Training Loss: 2.809886818, Training Accuracy: 29.016\n",
            "Worker 2, [26/37]: Training Loss: 2.721435221, Training Accuracy: 30.328\n",
            "Worker 2, [27/37]: Training Loss: 2.753300136, Training Accuracy: 29.912\n",
            "Worker 2, [28/37]: Training Loss: 2.683643584, Training Accuracy: 31.344\n",
            "Worker 2, [29/37]: Training Loss: 2.716878227, Training Accuracy: 30.896\n",
            "Worker 2, [30/37]: Training Loss: 2.654484165, Training Accuracy: 32.296\n",
            "Worker 2, [31/37]: Training Loss: 2.689361520, Training Accuracy: 31.648\n",
            "Worker 2, [32/37]: Training Loss: 2.637201596, Training Accuracy: 32.480\n",
            "Worker 2, [33/37]: Training Loss: 2.668384388, Training Accuracy: 32.384\n",
            "Worker 2, [34/37]: Training Loss: 2.633979704, Training Accuracy: 32.872\n",
            "Worker 2, [35/37]: Training Loss: 2.655642823, Training Accuracy: 32.888\n",
            "Worker 2, [36/37]: Training Loss: 2.639382514, Training Accuracy: 32.744\n",
            "Worker 2, [37/37]: Training Loss: 2.670151949, Training Accuracy: 32.552\n",
            "Time taken for training worker 2: 0:03:26.214802\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.203612103, Training Accuracy: 21.416\n",
            "Worker 3, [02/37]: Training Loss: 3.074228551, Training Accuracy: 23.488\n",
            "Worker 3, [03/37]: Training Loss: 3.277746330, Training Accuracy: 19.344\n",
            "Worker 3, [04/37]: Training Loss: 3.142789537, Training Accuracy: 22.344\n",
            "Worker 3, [05/37]: Training Loss: 3.254829449, Training Accuracy: 20.456\n",
            "Worker 3, [06/37]: Training Loss: 3.136936674, Training Accuracy: 22.352\n",
            "Worker 3, [07/37]: Training Loss: 3.216606962, Training Accuracy: 20.696\n",
            "Worker 3, [08/37]: Training Loss: 3.101225466, Training Accuracy: 23.432\n",
            "Worker 3, [09/37]: Training Loss: 3.160256265, Training Accuracy: 21.536\n",
            "Worker 3, [10/37]: Training Loss: 3.071499879, Training Accuracy: 23.856\n",
            "Worker 3, [11/37]: Training Loss: 3.121722906, Training Accuracy: 22.280\n",
            "Worker 3, [12/37]: Training Loss: 3.007706168, Training Accuracy: 24.784\n",
            "Worker 3, [13/37]: Training Loss: 3.074819013, Training Accuracy: 23.680\n",
            "Worker 3, [14/37]: Training Loss: 2.977496456, Training Accuracy: 25.000\n",
            "Worker 3, [15/37]: Training Loss: 3.032090276, Training Accuracy: 24.560\n",
            "Worker 3, [16/37]: Training Loss: 2.906579754, Training Accuracy: 26.640\n",
            "Worker 3, [17/37]: Training Loss: 2.966629189, Training Accuracy: 25.448\n",
            "Worker 3, [18/37]: Training Loss: 2.874295272, Training Accuracy: 27.288\n",
            "Worker 3, [19/37]: Training Loss: 2.938014346, Training Accuracy: 25.976\n",
            "Worker 3, [20/37]: Training Loss: 2.842470063, Training Accuracy: 28.064\n",
            "Worker 3, [21/37]: Training Loss: 2.871916142, Training Accuracy: 26.752\n",
            "Worker 3, [22/37]: Training Loss: 2.797989793, Training Accuracy: 28.664\n",
            "Worker 3, [23/37]: Training Loss: 2.826578537, Training Accuracy: 28.112\n",
            "Worker 3, [24/37]: Training Loss: 2.754772560, Training Accuracy: 29.792\n",
            "Worker 3, [25/37]: Training Loss: 2.783829131, Training Accuracy: 29.280\n",
            "Worker 3, [26/37]: Training Loss: 2.704992375, Training Accuracy: 30.688\n",
            "Worker 3, [27/37]: Training Loss: 2.743810093, Training Accuracy: 29.776\n",
            "Worker 3, [28/37]: Training Loss: 2.667721885, Training Accuracy: 31.408\n",
            "Worker 3, [29/37]: Training Loss: 2.696156205, Training Accuracy: 31.248\n",
            "Worker 3, [30/37]: Training Loss: 2.641395895, Training Accuracy: 32.360\n",
            "Worker 3, [31/37]: Training Loss: 2.664105565, Training Accuracy: 31.504\n",
            "Worker 3, [32/37]: Training Loss: 2.621279906, Training Accuracy: 33.024\n",
            "Worker 3, [33/37]: Training Loss: 2.656513865, Training Accuracy: 32.104\n",
            "Worker 3, [34/37]: Training Loss: 2.609892177, Training Accuracy: 33.000\n",
            "Worker 3, [35/37]: Training Loss: 2.644727949, Training Accuracy: 32.224\n",
            "Worker 3, [36/37]: Training Loss: 2.637358979, Training Accuracy: 32.736\n",
            "Worker 3, [37/37]: Training Loss: 2.654703522, Training Accuracy: 32.968\n",
            "Time taken for training worker 3: 0:03:22.280363\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.207586203, Training Accuracy: 21.624\n",
            "Worker 4, [02/37]: Training Loss: 3.072689347, Training Accuracy: 23.616\n",
            "Worker 4, [03/37]: Training Loss: 3.263033309, Training Accuracy: 20.408\n",
            "Worker 4, [04/37]: Training Loss: 3.156130619, Training Accuracy: 22.008\n",
            "Worker 4, [05/37]: Training Loss: 3.232003419, Training Accuracy: 20.272\n",
            "Worker 4, [06/37]: Training Loss: 3.115310917, Training Accuracy: 23.136\n",
            "Worker 4, [07/37]: Training Loss: 3.188076516, Training Accuracy: 21.400\n",
            "Worker 4, [08/37]: Training Loss: 3.083836913, Training Accuracy: 23.288\n",
            "Worker 4, [09/37]: Training Loss: 3.173027429, Training Accuracy: 21.776\n",
            "Worker 4, [10/37]: Training Loss: 3.074798068, Training Accuracy: 23.240\n",
            "Worker 4, [11/37]: Training Loss: 3.146527655, Training Accuracy: 21.912\n",
            "Worker 4, [12/37]: Training Loss: 3.016052873, Training Accuracy: 24.464\n",
            "Worker 4, [13/37]: Training Loss: 3.094431644, Training Accuracy: 23.152\n",
            "Worker 4, [14/37]: Training Loss: 2.981139840, Training Accuracy: 25.096\n",
            "Worker 4, [15/37]: Training Loss: 3.032648507, Training Accuracy: 23.920\n",
            "Worker 4, [16/37]: Training Loss: 2.943674196, Training Accuracy: 26.232\n",
            "Worker 4, [17/37]: Training Loss: 2.975380391, Training Accuracy: 24.728\n",
            "Worker 4, [18/37]: Training Loss: 2.916775167, Training Accuracy: 26.256\n",
            "Worker 4, [19/37]: Training Loss: 2.925927859, Training Accuracy: 26.344\n",
            "Worker 4, [20/37]: Training Loss: 2.849231592, Training Accuracy: 27.568\n",
            "Worker 4, [21/37]: Training Loss: 2.885321404, Training Accuracy: 26.816\n",
            "Worker 4, [22/37]: Training Loss: 2.818028500, Training Accuracy: 28.312\n",
            "Worker 4, [23/37]: Training Loss: 2.833811320, Training Accuracy: 28.304\n",
            "Worker 4, [24/37]: Training Loss: 2.762427367, Training Accuracy: 29.512\n",
            "Worker 4, [25/37]: Training Loss: 2.797562452, Training Accuracy: 28.728\n",
            "Worker 4, [26/37]: Training Loss: 2.718580189, Training Accuracy: 30.376\n",
            "Worker 4, [27/37]: Training Loss: 2.746612628, Training Accuracy: 29.680\n",
            "Worker 4, [28/37]: Training Loss: 2.684822260, Training Accuracy: 31.280\n",
            "Worker 4, [29/37]: Training Loss: 2.702213677, Training Accuracy: 30.856\n",
            "Worker 4, [30/37]: Training Loss: 2.651082838, Training Accuracy: 31.952\n",
            "Worker 4, [31/37]: Training Loss: 2.669499733, Training Accuracy: 31.472\n",
            "Worker 4, [32/37]: Training Loss: 2.627667848, Training Accuracy: 32.672\n",
            "Worker 4, [33/37]: Training Loss: 2.658417263, Training Accuracy: 32.216\n",
            "Worker 4, [34/37]: Training Loss: 2.626087653, Training Accuracy: 32.544\n",
            "Worker 4, [35/37]: Training Loss: 2.649979960, Training Accuracy: 32.976\n",
            "Worker 4, [36/37]: Training Loss: 2.633456163, Training Accuracy: 32.656\n",
            "Worker 4, [37/37]: Training Loss: 2.648975405, Training Accuracy: 32.976\n",
            "Time taken for training worker 4: 0:03:23.927524\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000588\n",
            "Local Step 03: Test Loss: 2.794739617, Test Accuracy: 30.100\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.945244622, Training Accuracy: 27.104\n",
            "Worker 1, [02/37]: Training Loss: 2.941064920, Training Accuracy: 27.288\n",
            "Worker 1, [03/37]: Training Loss: 2.755440207, Training Accuracy: 31.376\n",
            "Worker 1, [04/37]: Training Loss: 2.733855620, Training Accuracy: 31.808\n",
            "Worker 1, [05/37]: Training Loss: 2.738707300, Training Accuracy: 31.408\n",
            "Worker 1, [06/37]: Training Loss: 2.719495912, Training Accuracy: 30.656\n",
            "Worker 1, [07/37]: Training Loss: 2.742577140, Training Accuracy: 31.088\n",
            "Worker 1, [08/37]: Training Loss: 2.721914364, Training Accuracy: 31.232\n",
            "Worker 1, [09/37]: Training Loss: 2.763151751, Training Accuracy: 30.456\n",
            "Worker 1, [10/37]: Training Loss: 2.735725349, Training Accuracy: 30.344\n",
            "Worker 1, [11/37]: Training Loss: 2.783305610, Training Accuracy: 29.768\n",
            "Worker 1, [12/37]: Training Loss: 2.751960832, Training Accuracy: 30.280\n",
            "Worker 1, [13/37]: Training Loss: 2.799274228, Training Accuracy: 29.296\n",
            "Worker 1, [14/37]: Training Loss: 2.784095382, Training Accuracy: 29.496\n",
            "Worker 1, [15/37]: Training Loss: 2.820023971, Training Accuracy: 29.048\n",
            "Worker 1, [16/37]: Training Loss: 2.797828498, Training Accuracy: 29.216\n",
            "Worker 1, [17/37]: Training Loss: 2.855743974, Training Accuracy: 28.088\n",
            "Worker 1, [18/37]: Training Loss: 2.830992539, Training Accuracy: 28.416\n",
            "Worker 1, [19/37]: Training Loss: 2.863548650, Training Accuracy: 27.896\n",
            "Worker 1, [20/37]: Training Loss: 2.841997385, Training Accuracy: 28.480\n",
            "Worker 1, [21/37]: Training Loss: 2.895201296, Training Accuracy: 27.112\n",
            "Worker 1, [22/37]: Training Loss: 2.870153417, Training Accuracy: 27.704\n",
            "Worker 1, [23/37]: Training Loss: 2.912211432, Training Accuracy: 26.760\n",
            "Worker 1, [24/37]: Training Loss: 2.863230671, Training Accuracy: 27.880\n",
            "Worker 1, [25/37]: Training Loss: 2.914486190, Training Accuracy: 27.184\n",
            "Worker 1, [26/37]: Training Loss: 2.875868795, Training Accuracy: 27.072\n",
            "Worker 1, [27/37]: Training Loss: 2.935353771, Training Accuracy: 26.840\n",
            "Worker 1, [28/37]: Training Loss: 2.879836367, Training Accuracy: 27.560\n",
            "Worker 1, [29/37]: Training Loss: 2.930988634, Training Accuracy: 25.968\n",
            "Worker 1, [30/37]: Training Loss: 2.898831348, Training Accuracy: 26.960\n",
            "Worker 1, [31/37]: Training Loss: 2.941892077, Training Accuracy: 26.064\n",
            "Worker 1, [32/37]: Training Loss: 2.879466750, Training Accuracy: 27.232\n",
            "Worker 1, [33/37]: Training Loss: 2.936137264, Training Accuracy: 26.472\n",
            "Worker 1, [34/37]: Training Loss: 2.886148865, Training Accuracy: 27.304\n",
            "Worker 1, [35/37]: Training Loss: 2.908654880, Training Accuracy: 26.320\n",
            "Worker 1, [36/37]: Training Loss: 2.862503660, Training Accuracy: 27.904\n",
            "Worker 1, [37/37]: Training Loss: 2.899347622, Training Accuracy: 26.776\n",
            "Time taken for training worker 1: 0:03:21.242752\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.110197433, Training Accuracy: 23.576\n",
            "Worker 2, [02/37]: Training Loss: 3.077361347, Training Accuracy: 24.488\n",
            "Worker 2, [03/37]: Training Loss: 2.702586206, Training Accuracy: 31.992\n",
            "Worker 2, [04/37]: Training Loss: 2.663236837, Training Accuracy: 32.280\n",
            "Worker 2, [05/37]: Training Loss: 2.681655007, Training Accuracy: 31.664\n",
            "Worker 2, [06/37]: Training Loss: 2.641115909, Training Accuracy: 32.256\n",
            "Worker 2, [07/37]: Training Loss: 2.675095350, Training Accuracy: 31.520\n",
            "Worker 2, [08/37]: Training Loss: 2.660754058, Training Accuracy: 31.352\n",
            "Worker 2, [09/37]: Training Loss: 2.693107595, Training Accuracy: 31.528\n",
            "Worker 2, [10/37]: Training Loss: 2.650742617, Training Accuracy: 32.232\n",
            "Worker 2, [11/37]: Training Loss: 2.712812762, Training Accuracy: 30.752\n",
            "Worker 2, [12/37]: Training Loss: 2.671586026, Training Accuracy: 31.496\n",
            "Worker 2, [13/37]: Training Loss: 2.718216476, Training Accuracy: 30.392\n",
            "Worker 2, [14/37]: Training Loss: 2.703265722, Training Accuracy: 30.896\n",
            "Worker 2, [15/37]: Training Loss: 2.729302179, Training Accuracy: 30.144\n",
            "Worker 2, [16/37]: Training Loss: 2.727743454, Training Accuracy: 30.328\n",
            "Worker 2, [17/37]: Training Loss: 2.770404360, Training Accuracy: 29.384\n",
            "Worker 2, [18/37]: Training Loss: 2.739655315, Training Accuracy: 29.720\n",
            "Worker 2, [19/37]: Training Loss: 2.817840191, Training Accuracy: 27.992\n",
            "Worker 2, [20/37]: Training Loss: 2.760495059, Training Accuracy: 29.240\n",
            "Worker 2, [21/37]: Training Loss: 2.838440102, Training Accuracy: 27.968\n",
            "Worker 2, [22/37]: Training Loss: 2.783808956, Training Accuracy: 29.432\n",
            "Worker 2, [23/37]: Training Loss: 2.838384793, Training Accuracy: 27.944\n",
            "Worker 2, [24/37]: Training Loss: 2.810071522, Training Accuracy: 28.176\n",
            "Worker 2, [25/37]: Training Loss: 2.867011970, Training Accuracy: 27.360\n",
            "Worker 2, [26/37]: Training Loss: 2.820455927, Training Accuracy: 28.600\n",
            "Worker 2, [27/37]: Training Loss: 2.863304306, Training Accuracy: 26.840\n",
            "Worker 2, [28/37]: Training Loss: 2.815138917, Training Accuracy: 28.160\n",
            "Worker 2, [29/37]: Training Loss: 2.873575623, Training Accuracy: 26.976\n",
            "Worker 2, [30/37]: Training Loss: 2.815498649, Training Accuracy: 28.624\n",
            "Worker 2, [31/37]: Training Loss: 2.885568238, Training Accuracy: 27.080\n",
            "Worker 2, [32/37]: Training Loss: 2.806553459, Training Accuracy: 29.160\n",
            "Worker 2, [33/37]: Training Loss: 2.857874363, Training Accuracy: 27.712\n",
            "Worker 2, [34/37]: Training Loss: 2.818685682, Training Accuracy: 28.304\n",
            "Worker 2, [35/37]: Training Loss: 2.844187027, Training Accuracy: 27.808\n",
            "Worker 2, [36/37]: Training Loss: 2.810450205, Training Accuracy: 27.888\n",
            "Worker 2, [37/37]: Training Loss: 2.845819808, Training Accuracy: 27.576\n",
            "Time taken for training worker 2: 0:03:20.833262\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.989926310, Training Accuracy: 25.936\n",
            "Worker 3, [02/37]: Training Loss: 2.967904385, Training Accuracy: 26.680\n",
            "Worker 3, [03/37]: Training Loss: 2.664434474, Training Accuracy: 33.168\n",
            "Worker 3, [04/37]: Training Loss: 2.636291456, Training Accuracy: 32.936\n",
            "Worker 3, [05/37]: Training Loss: 2.649536419, Training Accuracy: 32.504\n",
            "Worker 3, [06/37]: Training Loss: 2.627932550, Training Accuracy: 32.584\n",
            "Worker 3, [07/37]: Training Loss: 2.645186457, Training Accuracy: 32.352\n",
            "Worker 3, [08/37]: Training Loss: 2.619867627, Training Accuracy: 32.520\n",
            "Worker 3, [09/37]: Training Loss: 2.670895776, Training Accuracy: 31.896\n",
            "Worker 3, [10/37]: Training Loss: 2.634865847, Training Accuracy: 32.536\n",
            "Worker 3, [11/37]: Training Loss: 2.682703090, Training Accuracy: 31.216\n",
            "Worker 3, [12/37]: Training Loss: 2.659329149, Training Accuracy: 31.952\n",
            "Worker 3, [13/37]: Training Loss: 2.701228170, Training Accuracy: 30.944\n",
            "Worker 3, [14/37]: Training Loss: 2.685143912, Training Accuracy: 31.264\n",
            "Worker 3, [15/37]: Training Loss: 2.727508196, Training Accuracy: 30.192\n",
            "Worker 3, [16/37]: Training Loss: 2.703117520, Training Accuracy: 30.776\n",
            "Worker 3, [17/37]: Training Loss: 2.757211151, Training Accuracy: 29.632\n",
            "Worker 3, [18/37]: Training Loss: 2.724036616, Training Accuracy: 30.480\n",
            "Worker 3, [19/37]: Training Loss: 2.776729845, Training Accuracy: 28.760\n",
            "Worker 3, [20/37]: Training Loss: 2.742817669, Training Accuracy: 29.512\n",
            "Worker 3, [21/37]: Training Loss: 2.815491069, Training Accuracy: 28.272\n",
            "Worker 3, [22/37]: Training Loss: 2.772737148, Training Accuracy: 29.240\n",
            "Worker 3, [23/37]: Training Loss: 2.814563855, Training Accuracy: 28.248\n",
            "Worker 3, [24/37]: Training Loss: 2.791692723, Training Accuracy: 29.176\n",
            "Worker 3, [25/37]: Training Loss: 2.839128961, Training Accuracy: 27.640\n",
            "Worker 3, [26/37]: Training Loss: 2.801122957, Training Accuracy: 29.024\n",
            "Worker 3, [27/37]: Training Loss: 2.851981772, Training Accuracy: 27.072\n",
            "Worker 3, [28/37]: Training Loss: 2.802630215, Training Accuracy: 28.512\n",
            "Worker 3, [29/37]: Training Loss: 2.860870269, Training Accuracy: 27.544\n",
            "Worker 3, [30/37]: Training Loss: 2.782156903, Training Accuracy: 28.744\n",
            "Worker 3, [31/37]: Training Loss: 2.852576510, Training Accuracy: 27.096\n",
            "Worker 3, [32/37]: Training Loss: 2.796673287, Training Accuracy: 28.872\n",
            "Worker 3, [33/37]: Training Loss: 2.855931141, Training Accuracy: 27.224\n",
            "Worker 3, [34/37]: Training Loss: 2.788798142, Training Accuracy: 28.792\n",
            "Worker 3, [35/37]: Training Loss: 2.833056387, Training Accuracy: 27.680\n",
            "Worker 3, [36/37]: Training Loss: 2.797742327, Training Accuracy: 28.712\n",
            "Worker 3, [37/37]: Training Loss: 2.832385094, Training Accuracy: 28.144\n",
            "Time taken for training worker 3: 0:03:21.663236\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.050381435, Training Accuracy: 25.568\n",
            "Worker 4, [02/37]: Training Loss: 3.000741766, Training Accuracy: 26.480\n",
            "Worker 4, [03/37]: Training Loss: 2.671794457, Training Accuracy: 32.800\n",
            "Worker 4, [04/37]: Training Loss: 2.649457089, Training Accuracy: 32.680\n",
            "Worker 4, [05/37]: Training Loss: 2.658334958, Training Accuracy: 32.424\n",
            "Worker 4, [06/37]: Training Loss: 2.634063437, Training Accuracy: 32.672\n",
            "Worker 4, [07/37]: Training Loss: 2.649571748, Training Accuracy: 32.200\n",
            "Worker 4, [08/37]: Training Loss: 2.652574609, Training Accuracy: 32.088\n",
            "Worker 4, [09/37]: Training Loss: 2.678178129, Training Accuracy: 31.456\n",
            "Worker 4, [10/37]: Training Loss: 2.644016148, Training Accuracy: 32.360\n",
            "Worker 4, [11/37]: Training Loss: 2.679498998, Training Accuracy: 31.168\n",
            "Worker 4, [12/37]: Training Loss: 2.676097256, Training Accuracy: 31.376\n",
            "Worker 4, [13/37]: Training Loss: 2.699444697, Training Accuracy: 30.840\n",
            "Worker 4, [14/37]: Training Loss: 2.707961731, Training Accuracy: 30.880\n",
            "Worker 4, [15/37]: Training Loss: 2.742549231, Training Accuracy: 30.368\n",
            "Worker 4, [16/37]: Training Loss: 2.711193142, Training Accuracy: 30.600\n",
            "Worker 4, [17/37]: Training Loss: 2.775520724, Training Accuracy: 28.992\n",
            "Worker 4, [18/37]: Training Loss: 2.750588697, Training Accuracy: 29.360\n",
            "Worker 4, [19/37]: Training Loss: 2.789495427, Training Accuracy: 29.016\n",
            "Worker 4, [20/37]: Training Loss: 2.755528991, Training Accuracy: 29.560\n",
            "Worker 4, [21/37]: Training Loss: 2.834300598, Training Accuracy: 27.616\n",
            "Worker 4, [22/37]: Training Loss: 2.772856012, Training Accuracy: 29.480\n",
            "Worker 4, [23/37]: Training Loss: 2.830026254, Training Accuracy: 28.176\n",
            "Worker 4, [24/37]: Training Loss: 2.797052629, Training Accuracy: 28.768\n",
            "Worker 4, [25/37]: Training Loss: 2.853611084, Training Accuracy: 27.960\n",
            "Worker 4, [26/37]: Training Loss: 2.807335846, Training Accuracy: 28.264\n",
            "Worker 4, [27/37]: Training Loss: 2.856154971, Training Accuracy: 27.632\n",
            "Worker 4, [28/37]: Training Loss: 2.811471232, Training Accuracy: 28.016\n",
            "Worker 4, [29/37]: Training Loss: 2.882321603, Training Accuracy: 26.880\n",
            "Worker 4, [30/37]: Training Loss: 2.831950689, Training Accuracy: 28.432\n",
            "Worker 4, [31/37]: Training Loss: 2.865193688, Training Accuracy: 27.272\n",
            "Worker 4, [32/37]: Training Loss: 2.822028148, Training Accuracy: 28.056\n",
            "Worker 4, [33/37]: Training Loss: 2.884099424, Training Accuracy: 26.672\n",
            "Worker 4, [34/37]: Training Loss: 2.812425615, Training Accuracy: 28.288\n",
            "Worker 4, [35/37]: Training Loss: 2.846320379, Training Accuracy: 27.656\n",
            "Worker 4, [36/37]: Training Loss: 2.801966886, Training Accuracy: 28.512\n",
            "Worker 4, [37/37]: Training Loss: 2.856987678, Training Accuracy: 27.896\n",
            "Time taken for training worker 4: 0:03:23.614514\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000704\n",
            "Local Step 04: Test Loss: 2.866166059, Test Accuracy: 27.930\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:53:50.657317\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.532135873, Training Accuracy: 2.304\n",
            "Worker 1, [02/37]: Training Loss: 4.157467752, Training Accuracy: 5.888\n",
            "Worker 1, [03/37]: Training Loss: 3.930998605, Training Accuracy: 9.296\n",
            "Worker 1, [04/37]: Training Loss: 3.769882161, Training Accuracy: 11.608\n",
            "Worker 1, [05/37]: Training Loss: 4.349695866, Training Accuracy: 4.408\n",
            "Worker 1, [06/37]: Training Loss: 3.963744292, Training Accuracy: 8.808\n",
            "Worker 1, [07/37]: Training Loss: 3.755762656, Training Accuracy: 12.144\n",
            "Worker 1, [08/37]: Training Loss: 3.615172560, Training Accuracy: 14.248\n",
            "Worker 1, [09/37]: Training Loss: 4.205245411, Training Accuracy: 6.224\n",
            "Worker 1, [10/37]: Training Loss: 3.794000037, Training Accuracy: 11.168\n",
            "Worker 1, [11/37]: Training Loss: 3.602413765, Training Accuracy: 14.232\n",
            "Worker 1, [12/37]: Training Loss: 3.474524328, Training Accuracy: 16.536\n",
            "Worker 1, [13/37]: Training Loss: 4.098590622, Training Accuracy: 7.744\n",
            "Worker 1, [14/37]: Training Loss: 3.700697185, Training Accuracy: 13.000\n",
            "Worker 1, [15/37]: Training Loss: 3.520861049, Training Accuracy: 15.856\n",
            "Worker 1, [16/37]: Training Loss: 3.413348069, Training Accuracy: 17.736\n",
            "Worker 1, [17/37]: Training Loss: 3.919529353, Training Accuracy: 10.712\n",
            "Worker 1, [18/37]: Training Loss: 3.569636030, Training Accuracy: 15.200\n",
            "Worker 1, [19/37]: Training Loss: 3.419908539, Training Accuracy: 17.592\n",
            "Worker 1, [20/37]: Training Loss: 3.301235696, Training Accuracy: 20.152\n",
            "Worker 1, [21/37]: Training Loss: 3.838245556, Training Accuracy: 11.744\n",
            "Worker 1, [22/37]: Training Loss: 3.507358510, Training Accuracy: 15.888\n",
            "Worker 1, [23/37]: Training Loss: 3.373082244, Training Accuracy: 18.576\n",
            "Worker 1, [24/37]: Training Loss: 3.253698091, Training Accuracy: 20.784\n",
            "Worker 1, [25/37]: Training Loss: 3.770366888, Training Accuracy: 13.584\n",
            "Worker 1, [26/37]: Training Loss: 3.463239454, Training Accuracy: 17.336\n",
            "Worker 1, [27/37]: Training Loss: 3.335409683, Training Accuracy: 19.520\n",
            "Worker 1, [28/37]: Training Loss: 3.262858424, Training Accuracy: 20.696\n",
            "Worker 1, [29/37]: Training Loss: 3.759666642, Training Accuracy: 14.800\n",
            "Worker 1, [30/37]: Training Loss: 3.467057031, Training Accuracy: 17.760\n",
            "Worker 1, [31/37]: Training Loss: 3.366450402, Training Accuracy: 19.288\n",
            "Worker 1, [32/37]: Training Loss: 3.299458394, Training Accuracy: 20.288\n",
            "Worker 1, [33/37]: Training Loss: 3.848526281, Training Accuracy: 16.232\n",
            "Worker 1, [34/37]: Training Loss: 3.565529551, Training Accuracy: 16.920\n",
            "Worker 1, [35/37]: Training Loss: 3.505651101, Training Accuracy: 17.888\n",
            "Worker 1, [36/37]: Training Loss: 3.471641204, Training Accuracy: 18.288\n",
            "Worker 1, [37/37]: Training Loss: 4.065639205, Training Accuracy: 18.208\n",
            "Time taken for training worker 1: 0:03:19.244035\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.528014020, Training Accuracy: 2.168\n",
            "Worker 2, [02/37]: Training Loss: 4.158250287, Training Accuracy: 6.048\n",
            "Worker 2, [03/37]: Training Loss: 3.944341928, Training Accuracy: 9.128\n",
            "Worker 2, [04/37]: Training Loss: 3.762768288, Training Accuracy: 12.096\n",
            "Worker 2, [05/37]: Training Loss: 4.295979884, Training Accuracy: 4.864\n",
            "Worker 2, [06/37]: Training Loss: 3.916439560, Training Accuracy: 9.480\n",
            "Worker 2, [07/37]: Training Loss: 3.710589136, Training Accuracy: 12.640\n",
            "Worker 2, [08/37]: Training Loss: 3.574313935, Training Accuracy: 14.856\n",
            "Worker 2, [09/37]: Training Loss: 4.181253177, Training Accuracy: 6.064\n",
            "Worker 2, [10/37]: Training Loss: 3.784687766, Training Accuracy: 11.648\n",
            "Worker 2, [11/37]: Training Loss: 3.580796181, Training Accuracy: 14.720\n",
            "Worker 2, [12/37]: Training Loss: 3.445595727, Training Accuracy: 16.528\n",
            "Worker 2, [13/37]: Training Loss: 4.037454718, Training Accuracy: 8.664\n",
            "Worker 2, [14/37]: Training Loss: 3.639902733, Training Accuracy: 13.528\n",
            "Worker 2, [15/37]: Training Loss: 3.466415066, Training Accuracy: 16.688\n",
            "Worker 2, [16/37]: Training Loss: 3.338803756, Training Accuracy: 18.520\n",
            "Worker 2, [17/37]: Training Loss: 3.910348685, Training Accuracy: 10.744\n",
            "Worker 2, [18/37]: Training Loss: 3.544367697, Training Accuracy: 15.304\n",
            "Worker 2, [19/37]: Training Loss: 3.401611017, Training Accuracy: 17.640\n",
            "Worker 2, [20/37]: Training Loss: 3.287021969, Training Accuracy: 19.936\n",
            "Worker 2, [21/37]: Training Loss: 3.821466312, Training Accuracy: 12.368\n",
            "Worker 2, [22/37]: Training Loss: 3.498959884, Training Accuracy: 16.344\n",
            "Worker 2, [23/37]: Training Loss: 3.348616416, Training Accuracy: 18.600\n",
            "Worker 2, [24/37]: Training Loss: 3.250839327, Training Accuracy: 20.720\n",
            "Worker 2, [25/37]: Training Loss: 3.739767079, Training Accuracy: 14.288\n",
            "Worker 2, [26/37]: Training Loss: 3.435506103, Training Accuracy: 18.008\n",
            "Worker 2, [27/37]: Training Loss: 3.304252572, Training Accuracy: 19.624\n",
            "Worker 2, [28/37]: Training Loss: 3.217730194, Training Accuracy: 21.512\n",
            "Worker 2, [29/37]: Training Loss: 3.728875654, Training Accuracy: 15.456\n",
            "Worker 2, [30/37]: Training Loss: 3.434981025, Training Accuracy: 17.888\n",
            "Worker 2, [31/37]: Training Loss: 3.335946510, Training Accuracy: 19.464\n",
            "Worker 2, [32/37]: Training Loss: 3.265948746, Training Accuracy: 20.928\n",
            "Worker 2, [33/37]: Training Loss: 3.818367040, Training Accuracy: 16.648\n",
            "Worker 2, [34/37]: Training Loss: 3.532753650, Training Accuracy: 17.464\n",
            "Worker 2, [35/37]: Training Loss: 3.464216254, Training Accuracy: 17.824\n",
            "Worker 2, [36/37]: Training Loss: 3.434790969, Training Accuracy: 18.752\n",
            "Worker 2, [37/37]: Training Loss: 4.044030248, Training Accuracy: 18.840\n",
            "Time taken for training worker 2: 0:03:20.299750\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.512064339, Training Accuracy: 2.328\n",
            "Worker 3, [02/37]: Training Loss: 4.130019319, Training Accuracy: 6.272\n",
            "Worker 3, [03/37]: Training Loss: 3.917514052, Training Accuracy: 9.056\n",
            "Worker 3, [04/37]: Training Loss: 3.744563608, Training Accuracy: 11.752\n",
            "Worker 3, [05/37]: Training Loss: 4.307298109, Training Accuracy: 4.856\n",
            "Worker 3, [06/37]: Training Loss: 3.930569232, Training Accuracy: 8.920\n",
            "Worker 3, [07/37]: Training Loss: 3.740403919, Training Accuracy: 11.616\n",
            "Worker 3, [08/37]: Training Loss: 3.598460217, Training Accuracy: 14.000\n",
            "Worker 3, [09/37]: Training Loss: 4.183417808, Training Accuracy: 6.368\n",
            "Worker 3, [10/37]: Training Loss: 3.793500937, Training Accuracy: 11.120\n",
            "Worker 3, [11/37]: Training Loss: 3.593851418, Training Accuracy: 14.088\n",
            "Worker 3, [12/37]: Training Loss: 3.463653079, Training Accuracy: 16.536\n",
            "Worker 3, [13/37]: Training Loss: 4.035026196, Training Accuracy: 8.432\n",
            "Worker 3, [14/37]: Training Loss: 3.657524563, Training Accuracy: 13.456\n",
            "Worker 3, [15/37]: Training Loss: 3.483792585, Training Accuracy: 15.784\n",
            "Worker 3, [16/37]: Training Loss: 3.348968463, Training Accuracy: 18.496\n",
            "Worker 3, [17/37]: Training Loss: 3.914635521, Training Accuracy: 10.528\n",
            "Worker 3, [18/37]: Training Loss: 3.558468552, Training Accuracy: 14.960\n",
            "Worker 3, [19/37]: Training Loss: 3.414693834, Training Accuracy: 17.624\n",
            "Worker 3, [20/37]: Training Loss: 3.280362774, Training Accuracy: 19.848\n",
            "Worker 3, [21/37]: Training Loss: 3.830070750, Training Accuracy: 11.440\n",
            "Worker 3, [22/37]: Training Loss: 3.497961042, Training Accuracy: 16.664\n",
            "Worker 3, [23/37]: Training Loss: 3.354146620, Training Accuracy: 18.576\n",
            "Worker 3, [24/37]: Training Loss: 3.236981320, Training Accuracy: 20.536\n",
            "Worker 3, [25/37]: Training Loss: 3.773990754, Training Accuracy: 13.352\n",
            "Worker 3, [26/37]: Training Loss: 3.456746854, Training Accuracy: 16.960\n",
            "Worker 3, [27/37]: Training Loss: 3.321539322, Training Accuracy: 19.784\n",
            "Worker 3, [28/37]: Training Loss: 3.240544036, Training Accuracy: 20.384\n",
            "Worker 3, [29/37]: Training Loss: 3.743647381, Training Accuracy: 14.712\n",
            "Worker 3, [30/37]: Training Loss: 3.448416856, Training Accuracy: 17.816\n",
            "Worker 3, [31/37]: Training Loss: 3.348289180, Training Accuracy: 19.392\n",
            "Worker 3, [32/37]: Training Loss: 3.283718896, Training Accuracy: 20.456\n",
            "Worker 3, [33/37]: Training Loss: 3.835517720, Training Accuracy: 16.112\n",
            "Worker 3, [34/37]: Training Loss: 3.561366120, Training Accuracy: 16.840\n",
            "Worker 3, [35/37]: Training Loss: 3.493722106, Training Accuracy: 17.488\n",
            "Worker 3, [36/37]: Training Loss: 3.456377417, Training Accuracy: 17.992\n",
            "Worker 3, [37/37]: Training Loss: 4.055796077, Training Accuracy: 17.768\n",
            "Time taken for training worker 3: 0:03:19.639804\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.529753028, Training Accuracy: 2.240\n",
            "Worker 4, [02/37]: Training Loss: 4.161480872, Training Accuracy: 6.480\n",
            "Worker 4, [03/37]: Training Loss: 3.940559750, Training Accuracy: 8.432\n",
            "Worker 4, [04/37]: Training Loss: 3.766634410, Training Accuracy: 11.288\n",
            "Worker 4, [05/37]: Training Loss: 4.315285889, Training Accuracy: 4.432\n",
            "Worker 4, [06/37]: Training Loss: 3.918538996, Training Accuracy: 8.824\n",
            "Worker 4, [07/37]: Training Loss: 3.732819482, Training Accuracy: 11.560\n",
            "Worker 4, [08/37]: Training Loss: 3.594729235, Training Accuracy: 13.984\n",
            "Worker 4, [09/37]: Training Loss: 4.227977716, Training Accuracy: 5.752\n",
            "Worker 4, [10/37]: Training Loss: 3.814492415, Training Accuracy: 10.832\n",
            "Worker 4, [11/37]: Training Loss: 3.638962335, Training Accuracy: 13.416\n",
            "Worker 4, [12/37]: Training Loss: 3.496896486, Training Accuracy: 15.816\n",
            "Worker 4, [13/37]: Training Loss: 4.053151948, Training Accuracy: 8.432\n",
            "Worker 4, [14/37]: Training Loss: 3.665392190, Training Accuracy: 13.392\n",
            "Worker 4, [15/37]: Training Loss: 3.507038772, Training Accuracy: 15.680\n",
            "Worker 4, [16/37]: Training Loss: 3.375641623, Training Accuracy: 18.160\n",
            "Worker 4, [17/37]: Training Loss: 3.935473854, Training Accuracy: 9.792\n",
            "Worker 4, [18/37]: Training Loss: 3.570894996, Training Accuracy: 15.040\n",
            "Worker 4, [19/37]: Training Loss: 3.421647942, Training Accuracy: 17.200\n",
            "Worker 4, [20/37]: Training Loss: 3.309211457, Training Accuracy: 19.040\n",
            "Worker 4, [21/37]: Training Loss: 3.832029441, Training Accuracy: 11.696\n",
            "Worker 4, [22/37]: Training Loss: 3.505936674, Training Accuracy: 16.104\n",
            "Worker 4, [23/37]: Training Loss: 3.376538442, Training Accuracy: 18.168\n",
            "Worker 4, [24/37]: Training Loss: 3.259520169, Training Accuracy: 20.432\n",
            "Worker 4, [25/37]: Training Loss: 3.766936868, Training Accuracy: 13.496\n",
            "Worker 4, [26/37]: Training Loss: 3.468814603, Training Accuracy: 17.256\n",
            "Worker 4, [27/37]: Training Loss: 3.343440656, Training Accuracy: 19.128\n",
            "Worker 4, [28/37]: Training Loss: 3.244166192, Training Accuracy: 21.160\n",
            "Worker 4, [29/37]: Training Loss: 3.752074588, Training Accuracy: 13.992\n",
            "Worker 4, [30/37]: Training Loss: 3.455787303, Training Accuracy: 17.584\n",
            "Worker 4, [31/37]: Training Loss: 3.363524005, Training Accuracy: 19.248\n",
            "Worker 4, [32/37]: Training Loss: 3.297446820, Training Accuracy: 20.216\n",
            "Worker 4, [33/37]: Training Loss: 3.839440227, Training Accuracy: 16.280\n",
            "Worker 4, [34/37]: Training Loss: 3.565158243, Training Accuracy: 16.576\n",
            "Worker 4, [35/37]: Training Loss: 3.495929641, Training Accuracy: 18.144\n",
            "Worker 4, [36/37]: Training Loss: 3.469190022, Training Accuracy: 18.312\n",
            "Worker 4, [37/37]: Training Loss: 4.062375269, Training Accuracy: 18.512\n",
            "Time taken for training worker 4: 0:03:20.553334\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001062\n",
            "Local Step 01: Test Loss: 4.144728190, Test Accuracy: 16.890\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 4.168816990, Training Accuracy: 16.008\n",
            "Worker 1, [02/37]: Training Loss: 4.155159099, Training Accuracy: 15.888\n",
            "Worker 1, [03/37]: Training Loss: 4.081543272, Training Accuracy: 15.680\n",
            "Worker 1, [04/37]: Training Loss: 3.917374553, Training Accuracy: 14.552\n",
            "Worker 1, [05/37]: Training Loss: 3.836045017, Training Accuracy: 16.472\n",
            "Worker 1, [06/37]: Training Loss: 3.581412467, Training Accuracy: 16.848\n",
            "Worker 1, [07/37]: Training Loss: 3.478416499, Training Accuracy: 17.744\n",
            "Worker 1, [08/37]: Training Loss: 3.413148172, Training Accuracy: 18.888\n",
            "Worker 1, [09/37]: Training Loss: 3.613724425, Training Accuracy: 16.688\n",
            "Worker 1, [10/37]: Training Loss: 3.436950119, Training Accuracy: 17.824\n",
            "Worker 1, [11/37]: Training Loss: 3.367332080, Training Accuracy: 19.208\n",
            "Worker 1, [12/37]: Training Loss: 3.305262629, Training Accuracy: 19.544\n",
            "Worker 1, [13/37]: Training Loss: 3.539215615, Training Accuracy: 16.880\n",
            "Worker 1, [14/37]: Training Loss: 3.378459507, Training Accuracy: 18.400\n",
            "Worker 1, [15/37]: Training Loss: 3.318386044, Training Accuracy: 19.912\n",
            "Worker 1, [16/37]: Training Loss: 3.250145444, Training Accuracy: 20.568\n",
            "Worker 1, [17/37]: Training Loss: 3.508508705, Training Accuracy: 16.608\n",
            "Worker 1, [18/37]: Training Loss: 3.346664039, Training Accuracy: 19.024\n",
            "Worker 1, [19/37]: Training Loss: 3.264926476, Training Accuracy: 20.320\n",
            "Worker 1, [20/37]: Training Loss: 3.199186842, Training Accuracy: 21.480\n",
            "Worker 1, [21/37]: Training Loss: 3.477216097, Training Accuracy: 17.064\n",
            "Worker 1, [22/37]: Training Loss: 3.332592042, Training Accuracy: 19.088\n",
            "Worker 1, [23/37]: Training Loss: 3.227228167, Training Accuracy: 21.240\n",
            "Worker 1, [24/37]: Training Loss: 3.138286189, Training Accuracy: 22.656\n",
            "Worker 1, [25/37]: Training Loss: 3.437898551, Training Accuracy: 17.728\n",
            "Worker 1, [26/37]: Training Loss: 3.299972652, Training Accuracy: 19.272\n",
            "Worker 1, [27/37]: Training Loss: 3.214593889, Training Accuracy: 21.376\n",
            "Worker 1, [28/37]: Training Loss: 3.096851256, Training Accuracy: 23.408\n",
            "Worker 1, [29/37]: Training Loss: 3.412331878, Training Accuracy: 17.760\n",
            "Worker 1, [30/37]: Training Loss: 3.255810805, Training Accuracy: 20.304\n",
            "Worker 1, [31/37]: Training Loss: 3.148422180, Training Accuracy: 22.536\n",
            "Worker 1, [32/37]: Training Loss: 3.068723179, Training Accuracy: 24.088\n",
            "Worker 1, [33/37]: Training Loss: 3.386467926, Training Accuracy: 18.600\n",
            "Worker 1, [34/37]: Training Loss: 3.210971314, Training Accuracy: 21.496\n",
            "Worker 1, [35/37]: Training Loss: 3.129063464, Training Accuracy: 22.632\n",
            "Worker 1, [36/37]: Training Loss: 2.997196335, Training Accuracy: 24.896\n",
            "Worker 1, [37/37]: Training Loss: 3.327362436, Training Accuracy: 19.408\n",
            "Time taken for training worker 1: 0:03:19.628814\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.361027575, Training Accuracy: 18.392\n",
            "Worker 2, [02/37]: Training Loss: 3.330406142, Training Accuracy: 19.376\n",
            "Worker 2, [03/37]: Training Loss: 3.261890563, Training Accuracy: 20.808\n",
            "Worker 2, [04/37]: Training Loss: 3.184959904, Training Accuracy: 22.576\n",
            "Worker 2, [05/37]: Training Loss: 3.765807132, Training Accuracy: 17.752\n",
            "Worker 2, [06/37]: Training Loss: 3.486582367, Training Accuracy: 17.904\n",
            "Worker 2, [07/37]: Training Loss: 3.402497197, Training Accuracy: 18.656\n",
            "Worker 2, [08/37]: Training Loss: 3.340384315, Training Accuracy: 19.648\n",
            "Worker 2, [09/37]: Training Loss: 3.534879333, Training Accuracy: 17.808\n",
            "Worker 2, [10/37]: Training Loss: 3.359703063, Training Accuracy: 18.720\n",
            "Worker 2, [11/37]: Training Loss: 3.290587952, Training Accuracy: 20.056\n",
            "Worker 2, [12/37]: Training Loss: 3.229377490, Training Accuracy: 20.792\n",
            "Worker 2, [13/37]: Training Loss: 3.473463899, Training Accuracy: 17.536\n",
            "Worker 2, [14/37]: Training Loss: 3.315146065, Training Accuracy: 19.696\n",
            "Worker 2, [15/37]: Training Loss: 3.244726664, Training Accuracy: 20.632\n",
            "Worker 2, [16/37]: Training Loss: 3.191251464, Training Accuracy: 21.856\n",
            "Worker 2, [17/37]: Training Loss: 3.441468964, Training Accuracy: 17.944\n",
            "Worker 2, [18/37]: Training Loss: 3.287520403, Training Accuracy: 19.744\n",
            "Worker 2, [19/37]: Training Loss: 3.196907761, Training Accuracy: 21.120\n",
            "Worker 2, [20/37]: Training Loss: 3.143381751, Training Accuracy: 22.744\n",
            "Worker 2, [21/37]: Training Loss: 3.415393691, Training Accuracy: 18.160\n",
            "Worker 2, [22/37]: Training Loss: 3.273711354, Training Accuracy: 20.256\n",
            "Worker 2, [23/37]: Training Loss: 3.163725619, Training Accuracy: 22.200\n",
            "Worker 2, [24/37]: Training Loss: 3.097416244, Training Accuracy: 23.256\n",
            "Worker 2, [25/37]: Training Loss: 3.391780039, Training Accuracy: 18.184\n",
            "Worker 2, [26/37]: Training Loss: 3.251714571, Training Accuracy: 20.448\n",
            "Worker 2, [27/37]: Training Loss: 3.139515040, Training Accuracy: 22.304\n",
            "Worker 2, [28/37]: Training Loss: 3.057044265, Training Accuracy: 24.360\n",
            "Worker 2, [29/37]: Training Loss: 3.369542104, Training Accuracy: 18.080\n",
            "Worker 2, [30/37]: Training Loss: 3.218987281, Training Accuracy: 20.904\n",
            "Worker 2, [31/37]: Training Loss: 3.113095835, Training Accuracy: 22.424\n",
            "Worker 2, [32/37]: Training Loss: 3.001427669, Training Accuracy: 24.776\n",
            "Worker 2, [33/37]: Training Loss: 3.328471856, Training Accuracy: 19.272\n",
            "Worker 2, [34/37]: Training Loss: 3.173862050, Training Accuracy: 21.376\n",
            "Worker 2, [35/37]: Training Loss: 3.084912946, Training Accuracy: 23.240\n",
            "Worker 2, [36/37]: Training Loss: 2.968302104, Training Accuracy: 25.584\n",
            "Worker 2, [37/37]: Training Loss: 3.301144507, Training Accuracy: 19.536\n",
            "Time taken for training worker 2: 0:03:20.819119\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.333057255, Training Accuracy: 19.416\n",
            "Worker 3, [02/37]: Training Loss: 3.297537255, Training Accuracy: 19.744\n",
            "Worker 3, [03/37]: Training Loss: 3.206769645, Training Accuracy: 22.264\n",
            "Worker 3, [04/37]: Training Loss: 3.134146793, Training Accuracy: 23.544\n",
            "Worker 3, [05/37]: Training Loss: 3.779498809, Training Accuracy: 17.408\n",
            "Worker 3, [06/37]: Training Loss: 3.510998205, Training Accuracy: 17.072\n",
            "Worker 3, [07/37]: Training Loss: 3.405514991, Training Accuracy: 18.944\n",
            "Worker 3, [08/37]: Training Loss: 3.354834285, Training Accuracy: 18.920\n",
            "Worker 3, [09/37]: Training Loss: 3.547050116, Training Accuracy: 17.648\n",
            "Worker 3, [10/37]: Training Loss: 3.370036214, Training Accuracy: 19.024\n",
            "Worker 3, [11/37]: Training Loss: 3.297228340, Training Accuracy: 19.752\n",
            "Worker 3, [12/37]: Training Loss: 3.239803044, Training Accuracy: 20.512\n",
            "Worker 3, [13/37]: Training Loss: 3.469445253, Training Accuracy: 17.568\n",
            "Worker 3, [14/37]: Training Loss: 3.317986412, Training Accuracy: 19.696\n",
            "Worker 3, [15/37]: Training Loss: 3.241110882, Training Accuracy: 20.328\n",
            "Worker 3, [16/37]: Training Loss: 3.180270680, Training Accuracy: 21.432\n",
            "Worker 3, [17/37]: Training Loss: 3.443075785, Training Accuracy: 17.640\n",
            "Worker 3, [18/37]: Training Loss: 3.279322578, Training Accuracy: 19.752\n",
            "Worker 3, [19/37]: Training Loss: 3.209989197, Training Accuracy: 21.192\n",
            "Worker 3, [20/37]: Training Loss: 3.131662031, Training Accuracy: 22.352\n",
            "Worker 3, [21/37]: Training Loss: 3.409994811, Training Accuracy: 17.704\n",
            "Worker 3, [22/37]: Training Loss: 3.270457397, Training Accuracy: 19.896\n",
            "Worker 3, [23/37]: Training Loss: 3.177372432, Training Accuracy: 21.296\n",
            "Worker 3, [24/37]: Training Loss: 3.075731757, Training Accuracy: 23.376\n",
            "Worker 3, [25/37]: Training Loss: 3.395039878, Training Accuracy: 18.200\n",
            "Worker 3, [26/37]: Training Loss: 3.233713853, Training Accuracy: 20.096\n",
            "Worker 3, [27/37]: Training Loss: 3.126817471, Training Accuracy: 22.536\n",
            "Worker 3, [28/37]: Training Loss: 3.067300355, Training Accuracy: 23.528\n",
            "Worker 3, [29/37]: Training Loss: 3.369539200, Training Accuracy: 18.416\n",
            "Worker 3, [30/37]: Training Loss: 3.221480326, Training Accuracy: 20.840\n",
            "Worker 3, [31/37]: Training Loss: 3.085397409, Training Accuracy: 23.072\n",
            "Worker 3, [32/37]: Training Loss: 3.014217333, Training Accuracy: 24.664\n",
            "Worker 3, [33/37]: Training Loss: 3.317650266, Training Accuracy: 19.320\n",
            "Worker 3, [34/37]: Training Loss: 3.164496172, Training Accuracy: 21.968\n",
            "Worker 3, [35/37]: Training Loss: 3.065072309, Training Accuracy: 23.824\n",
            "Worker 3, [36/37]: Training Loss: 2.967463974, Training Accuracy: 24.984\n",
            "Worker 3, [37/37]: Training Loss: 3.269589110, Training Accuracy: 19.760\n",
            "Time taken for training worker 3: 0:03:13.958851\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.315544634, Training Accuracy: 19.736\n",
            "Worker 4, [02/37]: Training Loss: 3.277081872, Training Accuracy: 20.472\n",
            "Worker 4, [03/37]: Training Loss: 3.191702255, Training Accuracy: 22.152\n",
            "Worker 4, [04/37]: Training Loss: 3.127607370, Training Accuracy: 23.632\n",
            "Worker 4, [05/37]: Training Loss: 3.785277648, Training Accuracy: 18.064\n",
            "Worker 4, [06/37]: Training Loss: 3.518808129, Training Accuracy: 17.592\n",
            "Worker 4, [07/37]: Training Loss: 3.417979905, Training Accuracy: 18.176\n",
            "Worker 4, [08/37]: Training Loss: 3.356368284, Training Accuracy: 19.480\n",
            "Worker 4, [09/37]: Training Loss: 3.557341402, Training Accuracy: 17.448\n",
            "Worker 4, [10/37]: Training Loss: 3.379184866, Training Accuracy: 18.656\n",
            "Worker 4, [11/37]: Training Loss: 3.306778635, Training Accuracy: 19.776\n",
            "Worker 4, [12/37]: Training Loss: 3.253945784, Training Accuracy: 20.536\n",
            "Worker 4, [13/37]: Training Loss: 3.495600686, Training Accuracy: 17.184\n",
            "Worker 4, [14/37]: Training Loss: 3.318986781, Training Accuracy: 19.152\n",
            "Worker 4, [15/37]: Training Loss: 3.232071038, Training Accuracy: 20.720\n",
            "Worker 4, [16/37]: Training Loss: 3.174533700, Training Accuracy: 22.048\n",
            "Worker 4, [17/37]: Training Loss: 3.454255290, Training Accuracy: 17.488\n",
            "Worker 4, [18/37]: Training Loss: 3.293325893, Training Accuracy: 19.192\n",
            "Worker 4, [19/37]: Training Loss: 3.204327831, Training Accuracy: 21.320\n",
            "Worker 4, [20/37]: Training Loss: 3.143889819, Training Accuracy: 21.864\n",
            "Worker 4, [21/37]: Training Loss: 3.422206640, Training Accuracy: 17.672\n",
            "Worker 4, [22/37]: Training Loss: 3.277737173, Training Accuracy: 20.016\n",
            "Worker 4, [23/37]: Training Loss: 3.170872297, Training Accuracy: 21.672\n",
            "Worker 4, [24/37]: Training Loss: 3.115015838, Training Accuracy: 22.640\n",
            "Worker 4, [25/37]: Training Loss: 3.389557334, Training Accuracy: 17.720\n",
            "Worker 4, [26/37]: Training Loss: 3.242271573, Training Accuracy: 20.536\n",
            "Worker 4, [27/37]: Training Loss: 3.145071651, Training Accuracy: 21.880\n",
            "Worker 4, [28/37]: Training Loss: 3.057649863, Training Accuracy: 23.248\n",
            "Worker 4, [29/37]: Training Loss: 3.365409703, Training Accuracy: 18.456\n",
            "Worker 4, [30/37]: Training Loss: 3.214826733, Training Accuracy: 20.656\n",
            "Worker 4, [31/37]: Training Loss: 3.120292064, Training Accuracy: 22.568\n",
            "Worker 4, [32/37]: Training Loss: 3.026677183, Training Accuracy: 24.176\n",
            "Worker 4, [33/37]: Training Loss: 3.334584353, Training Accuracy: 18.672\n",
            "Worker 4, [34/37]: Training Loss: 3.191948922, Training Accuracy: 21.448\n",
            "Worker 4, [35/37]: Training Loss: 3.073684612, Training Accuracy: 23.648\n",
            "Worker 4, [36/37]: Training Loss: 2.968251951, Training Accuracy: 25.528\n",
            "Worker 4, [37/37]: Training Loss: 3.279463427, Training Accuracy: 20.272\n",
            "Time taken for training worker 4: 0:03:06.713206\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000634\n",
            "Local Step 02: Test Loss: 3.161575779, Test Accuracy: 22.580\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.263691066, Training Accuracy: 20.464\n",
            "Worker 1, [02/37]: Training Loss: 3.094926003, Training Accuracy: 23.600\n",
            "Worker 1, [03/37]: Training Loss: 2.973786393, Training Accuracy: 25.776\n",
            "Worker 1, [04/37]: Training Loss: 2.882469271, Training Accuracy: 27.856\n",
            "Worker 1, [05/37]: Training Loss: 3.298054044, Training Accuracy: 19.344\n",
            "Worker 1, [06/37]: Training Loss: 3.124218160, Training Accuracy: 23.024\n",
            "Worker 1, [07/37]: Training Loss: 3.007930303, Training Accuracy: 24.592\n",
            "Worker 1, [08/37]: Training Loss: 2.903901066, Training Accuracy: 27.200\n",
            "Worker 1, [09/37]: Training Loss: 3.204576596, Training Accuracy: 21.800\n",
            "Worker 1, [10/37]: Training Loss: 3.040844400, Training Accuracy: 24.280\n",
            "Worker 1, [11/37]: Training Loss: 2.938896966, Training Accuracy: 26.592\n",
            "Worker 1, [12/37]: Training Loss: 2.812264747, Training Accuracy: 28.640\n",
            "Worker 1, [13/37]: Training Loss: 3.126819128, Training Accuracy: 23.024\n",
            "Worker 1, [14/37]: Training Loss: 2.959002312, Training Accuracy: 25.816\n",
            "Worker 1, [15/37]: Training Loss: 2.837904603, Training Accuracy: 28.184\n",
            "Worker 1, [16/37]: Training Loss: 2.751006727, Training Accuracy: 29.840\n",
            "Worker 1, [17/37]: Training Loss: 3.014321453, Training Accuracy: 24.976\n",
            "Worker 1, [18/37]: Training Loss: 2.873310874, Training Accuracy: 27.488\n",
            "Worker 1, [19/37]: Training Loss: 2.781915351, Training Accuracy: 29.424\n",
            "Worker 1, [20/37]: Training Loss: 2.657081763, Training Accuracy: 31.816\n",
            "Worker 1, [21/37]: Training Loss: 2.901306144, Training Accuracy: 27.544\n",
            "Worker 1, [22/37]: Training Loss: 2.782926557, Training Accuracy: 29.880\n",
            "Worker 1, [23/37]: Training Loss: 2.674859941, Training Accuracy: 31.728\n",
            "Worker 1, [24/37]: Training Loss: 2.590472555, Training Accuracy: 33.680\n",
            "Worker 1, [25/37]: Training Loss: 2.810010737, Training Accuracy: 29.888\n",
            "Worker 1, [26/37]: Training Loss: 2.681592387, Training Accuracy: 31.376\n",
            "Worker 1, [27/37]: Training Loss: 2.608271081, Training Accuracy: 32.992\n",
            "Worker 1, [28/37]: Training Loss: 2.537676844, Training Accuracy: 34.776\n",
            "Worker 1, [29/37]: Training Loss: 2.734362956, Training Accuracy: 31.408\n",
            "Worker 1, [30/37]: Training Loss: 2.639354453, Training Accuracy: 33.120\n",
            "Worker 1, [31/37]: Training Loss: 2.571766681, Training Accuracy: 34.744\n",
            "Worker 1, [32/37]: Training Loss: 2.528164654, Training Accuracy: 35.392\n",
            "Worker 1, [33/37]: Training Loss: 2.707849883, Training Accuracy: 32.720\n",
            "Worker 1, [34/37]: Training Loss: 2.639949345, Training Accuracy: 33.512\n",
            "Worker 1, [35/37]: Training Loss: 2.600532893, Training Accuracy: 34.072\n",
            "Worker 1, [36/37]: Training Loss: 2.594908001, Training Accuracy: 33.984\n",
            "Worker 1, [37/37]: Training Loss: 2.796044123, Training Accuracy: 33.608\n",
            "Time taken for training worker 1: 0:03:05.703050\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.192296106, Training Accuracy: 21.920\n",
            "Worker 2, [02/37]: Training Loss: 3.044039821, Training Accuracy: 23.968\n",
            "Worker 2, [03/37]: Training Loss: 2.924099979, Training Accuracy: 26.504\n",
            "Worker 2, [04/37]: Training Loss: 2.826553125, Training Accuracy: 28.312\n",
            "Worker 2, [05/37]: Training Loss: 3.237872789, Training Accuracy: 20.728\n",
            "Worker 2, [06/37]: Training Loss: 3.075703762, Training Accuracy: 23.872\n",
            "Worker 2, [07/37]: Training Loss: 2.951393552, Training Accuracy: 25.936\n",
            "Worker 2, [08/37]: Training Loss: 2.863929660, Training Accuracy: 27.224\n",
            "Worker 2, [09/37]: Training Loss: 3.153278756, Training Accuracy: 22.048\n",
            "Worker 2, [10/37]: Training Loss: 2.985856927, Training Accuracy: 25.400\n",
            "Worker 2, [11/37]: Training Loss: 2.856862599, Training Accuracy: 27.800\n",
            "Worker 2, [12/37]: Training Loss: 2.763463931, Training Accuracy: 29.496\n",
            "Worker 2, [13/37]: Training Loss: 3.060916105, Training Accuracy: 23.904\n",
            "Worker 2, [14/37]: Training Loss: 2.904417610, Training Accuracy: 26.952\n",
            "Worker 2, [15/37]: Training Loss: 2.795090263, Training Accuracy: 28.424\n",
            "Worker 2, [16/37]: Training Loss: 2.688490005, Training Accuracy: 30.672\n",
            "Worker 2, [17/37]: Training Loss: 2.956568456, Training Accuracy: 25.992\n",
            "Worker 2, [18/37]: Training Loss: 2.801023856, Training Accuracy: 28.888\n",
            "Worker 2, [19/37]: Training Loss: 2.695438918, Training Accuracy: 30.864\n",
            "Worker 2, [20/37]: Training Loss: 2.607231381, Training Accuracy: 32.192\n",
            "Worker 2, [21/37]: Training Loss: 2.854609290, Training Accuracy: 28.080\n",
            "Worker 2, [22/37]: Training Loss: 2.715765796, Training Accuracy: 30.456\n",
            "Worker 2, [23/37]: Training Loss: 2.613561855, Training Accuracy: 32.336\n",
            "Worker 2, [24/37]: Training Loss: 2.526317722, Training Accuracy: 34.056\n",
            "Worker 2, [25/37]: Training Loss: 2.755740418, Training Accuracy: 30.552\n",
            "Worker 2, [26/37]: Training Loss: 2.632906838, Training Accuracy: 32.152\n",
            "Worker 2, [27/37]: Training Loss: 2.549655450, Training Accuracy: 34.168\n",
            "Worker 2, [28/37]: Training Loss: 2.475010106, Training Accuracy: 35.176\n",
            "Worker 2, [29/37]: Training Loss: 2.667938308, Training Accuracy: 32.024\n",
            "Worker 2, [30/37]: Training Loss: 2.563993109, Training Accuracy: 33.672\n",
            "Worker 2, [31/37]: Training Loss: 2.513050877, Training Accuracy: 34.688\n",
            "Worker 2, [32/37]: Training Loss: 2.453848185, Training Accuracy: 36.288\n",
            "Worker 2, [33/37]: Training Loss: 2.648452570, Training Accuracy: 33.328\n",
            "Worker 2, [34/37]: Training Loss: 2.557493702, Training Accuracy: 34.432\n",
            "Worker 2, [35/37]: Training Loss: 2.538997240, Training Accuracy: 34.912\n",
            "Worker 2, [36/37]: Training Loss: 2.519535426, Training Accuracy: 35.040\n",
            "Worker 2, [37/37]: Training Loss: 2.723549381, Training Accuracy: 34.056\n",
            "Time taken for training worker 2: 0:03:09.533964\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.126830687, Training Accuracy: 23.128\n",
            "Worker 3, [02/37]: Training Loss: 2.966644336, Training Accuracy: 26.216\n",
            "Worker 3, [03/37]: Training Loss: 2.883601142, Training Accuracy: 27.352\n",
            "Worker 3, [04/37]: Training Loss: 2.754586878, Training Accuracy: 29.848\n",
            "Worker 3, [05/37]: Training Loss: 3.223402517, Training Accuracy: 20.560\n",
            "Worker 3, [06/37]: Training Loss: 3.077881538, Training Accuracy: 23.344\n",
            "Worker 3, [07/37]: Training Loss: 2.941053361, Training Accuracy: 26.160\n",
            "Worker 3, [08/37]: Training Loss: 2.841329728, Training Accuracy: 28.048\n",
            "Worker 3, [09/37]: Training Loss: 3.126666331, Training Accuracy: 22.576\n",
            "Worker 3, [10/37]: Training Loss: 2.978819263, Training Accuracy: 25.064\n",
            "Worker 3, [11/37]: Training Loss: 2.856819835, Training Accuracy: 27.312\n",
            "Worker 3, [12/37]: Training Loss: 2.752172149, Training Accuracy: 29.480\n",
            "Worker 3, [13/37]: Training Loss: 3.055880686, Training Accuracy: 23.616\n",
            "Worker 3, [14/37]: Training Loss: 2.873889050, Training Accuracy: 27.472\n",
            "Worker 3, [15/37]: Training Loss: 2.788114439, Training Accuracy: 28.816\n",
            "Worker 3, [16/37]: Training Loss: 2.669036532, Training Accuracy: 31.320\n",
            "Worker 3, [17/37]: Training Loss: 2.946581096, Training Accuracy: 26.016\n",
            "Worker 3, [18/37]: Training Loss: 2.810001135, Training Accuracy: 28.656\n",
            "Worker 3, [19/37]: Training Loss: 2.684691953, Training Accuracy: 30.872\n",
            "Worker 3, [20/37]: Training Loss: 2.599323181, Training Accuracy: 32.416\n",
            "Worker 3, [21/37]: Training Loss: 2.835278787, Training Accuracy: 28.080\n",
            "Worker 3, [22/37]: Training Loss: 2.718772868, Training Accuracy: 30.392\n",
            "Worker 3, [23/37]: Training Loss: 2.603090531, Training Accuracy: 32.976\n",
            "Worker 3, [24/37]: Training Loss: 2.516894754, Training Accuracy: 34.456\n",
            "Worker 3, [25/37]: Training Loss: 2.744035576, Training Accuracy: 29.896\n",
            "Worker 3, [26/37]: Training Loss: 2.612494559, Training Accuracy: 32.496\n",
            "Worker 3, [27/37]: Training Loss: 2.555351668, Training Accuracy: 34.320\n",
            "Worker 3, [28/37]: Training Loss: 2.467508862, Training Accuracy: 35.832\n",
            "Worker 3, [29/37]: Training Loss: 2.668337223, Training Accuracy: 31.648\n",
            "Worker 3, [30/37]: Training Loss: 2.564459830, Training Accuracy: 34.152\n",
            "Worker 3, [31/37]: Training Loss: 2.491445082, Training Accuracy: 35.704\n",
            "Worker 3, [32/37]: Training Loss: 2.445865857, Training Accuracy: 36.144\n",
            "Worker 3, [33/37]: Training Loss: 2.635709222, Training Accuracy: 33.672\n",
            "Worker 3, [34/37]: Training Loss: 2.549918687, Training Accuracy: 34.616\n",
            "Worker 3, [35/37]: Training Loss: 2.524911458, Training Accuracy: 35.072\n",
            "Worker 3, [36/37]: Training Loss: 2.510633188, Training Accuracy: 35.128\n",
            "Worker 3, [37/37]: Training Loss: 2.723124353, Training Accuracy: 33.984\n",
            "Time taken for training worker 3: 0:03:06.927427\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.146347882, Training Accuracy: 22.704\n",
            "Worker 4, [02/37]: Training Loss: 3.013197598, Training Accuracy: 24.904\n",
            "Worker 4, [03/37]: Training Loss: 2.880019401, Training Accuracy: 27.480\n",
            "Worker 4, [04/37]: Training Loss: 2.789891390, Training Accuracy: 28.728\n",
            "Worker 4, [05/37]: Training Loss: 3.264503377, Training Accuracy: 20.296\n",
            "Worker 4, [06/37]: Training Loss: 3.083690333, Training Accuracy: 23.272\n",
            "Worker 4, [07/37]: Training Loss: 2.973144650, Training Accuracy: 25.664\n",
            "Worker 4, [08/37]: Training Loss: 2.867876373, Training Accuracy: 27.352\n",
            "Worker 4, [09/37]: Training Loss: 3.162687213, Training Accuracy: 22.160\n",
            "Worker 4, [10/37]: Training Loss: 2.997485656, Training Accuracy: 25.336\n",
            "Worker 4, [11/37]: Training Loss: 2.864573559, Training Accuracy: 26.808\n",
            "Worker 4, [12/37]: Training Loss: 2.770587831, Training Accuracy: 29.744\n",
            "Worker 4, [13/37]: Training Loss: 3.055759047, Training Accuracy: 23.640\n",
            "Worker 4, [14/37]: Training Loss: 2.918244851, Training Accuracy: 25.712\n",
            "Worker 4, [15/37]: Training Loss: 2.789161703, Training Accuracy: 29.424\n",
            "Worker 4, [16/37]: Training Loss: 2.693919991, Training Accuracy: 30.760\n",
            "Worker 4, [17/37]: Training Loss: 2.964031852, Training Accuracy: 25.736\n",
            "Worker 4, [18/37]: Training Loss: 2.807447351, Training Accuracy: 28.264\n",
            "Worker 4, [19/37]: Training Loss: 2.699991058, Training Accuracy: 30.400\n",
            "Worker 4, [20/37]: Training Loss: 2.616800658, Training Accuracy: 32.408\n",
            "Worker 4, [21/37]: Training Loss: 2.843660636, Training Accuracy: 28.008\n",
            "Worker 4, [22/37]: Training Loss: 2.721096437, Training Accuracy: 30.160\n",
            "Worker 4, [23/37]: Training Loss: 2.623082421, Training Accuracy: 32.360\n",
            "Worker 4, [24/37]: Training Loss: 2.539930778, Training Accuracy: 33.960\n",
            "Worker 4, [25/37]: Training Loss: 2.740176394, Training Accuracy: 30.632\n",
            "Worker 4, [26/37]: Training Loss: 2.640060189, Training Accuracy: 32.096\n",
            "Worker 4, [27/37]: Training Loss: 2.546737774, Training Accuracy: 34.008\n",
            "Worker 4, [28/37]: Training Loss: 2.470270229, Training Accuracy: 35.440\n",
            "Worker 4, [29/37]: Training Loss: 2.666045836, Training Accuracy: 31.856\n",
            "Worker 4, [30/37]: Training Loss: 2.576577715, Training Accuracy: 33.752\n",
            "Worker 4, [31/37]: Training Loss: 2.517205856, Training Accuracy: 34.784\n",
            "Worker 4, [32/37]: Training Loss: 2.461867718, Training Accuracy: 36.024\n",
            "Worker 4, [33/37]: Training Loss: 2.645123697, Training Accuracy: 33.112\n",
            "Worker 4, [34/37]: Training Loss: 2.560622336, Training Accuracy: 34.312\n",
            "Worker 4, [35/37]: Training Loss: 2.529296899, Training Accuracy: 34.760\n",
            "Worker 4, [36/37]: Training Loss: 2.523241880, Training Accuracy: 34.912\n",
            "Worker 4, [37/37]: Training Loss: 2.744098229, Training Accuracy: 33.720\n",
            "Time taken for training worker 4: 0:03:08.212711\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000822\n",
            "Local Step 03: Test Loss: 2.822621347, Test Accuracy: 31.390\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.958621240, Training Accuracy: 28.576\n",
            "Worker 1, [02/37]: Training Loss: 2.952189889, Training Accuracy: 27.920\n",
            "Worker 1, [03/37]: Training Loss: 2.914223401, Training Accuracy: 28.584\n",
            "Worker 1, [04/37]: Training Loss: 2.879406293, Training Accuracy: 28.752\n",
            "Worker 1, [05/37]: Training Loss: 2.732179413, Training Accuracy: 32.328\n",
            "Worker 1, [06/37]: Training Loss: 2.661143827, Training Accuracy: 32.832\n",
            "Worker 1, [07/37]: Training Loss: 2.635295616, Training Accuracy: 33.472\n",
            "Worker 1, [08/37]: Training Loss: 2.613066001, Training Accuracy: 33.568\n",
            "Worker 1, [09/37]: Training Loss: 2.709442612, Training Accuracy: 32.096\n",
            "Worker 1, [10/37]: Training Loss: 2.648317414, Training Accuracy: 32.304\n",
            "Worker 1, [11/37]: Training Loss: 2.622049215, Training Accuracy: 33.240\n",
            "Worker 1, [12/37]: Training Loss: 2.590705972, Training Accuracy: 33.216\n",
            "Worker 1, [13/37]: Training Loss: 2.728530541, Training Accuracy: 30.736\n",
            "Worker 1, [14/37]: Training Loss: 2.672595428, Training Accuracy: 31.752\n",
            "Worker 1, [15/37]: Training Loss: 2.638943135, Training Accuracy: 32.488\n",
            "Worker 1, [16/37]: Training Loss: 2.612391988, Training Accuracy: 32.872\n",
            "Worker 1, [17/37]: Training Loss: 2.757571254, Training Accuracy: 30.520\n",
            "Worker 1, [18/37]: Training Loss: 2.711093551, Training Accuracy: 30.704\n",
            "Worker 1, [19/37]: Training Loss: 2.656553029, Training Accuracy: 31.480\n",
            "Worker 1, [20/37]: Training Loss: 2.610736207, Training Accuracy: 33.216\n",
            "Worker 1, [21/37]: Training Loss: 2.821538751, Training Accuracy: 29.072\n",
            "Worker 1, [22/37]: Training Loss: 2.744384098, Training Accuracy: 30.344\n",
            "Worker 1, [23/37]: Training Loss: 2.687814108, Training Accuracy: 30.744\n",
            "Worker 1, [24/37]: Training Loss: 2.635505931, Training Accuracy: 32.408\n",
            "Worker 1, [25/37]: Training Loss: 2.832836947, Training Accuracy: 28.200\n",
            "Worker 1, [26/37]: Training Loss: 2.770186390, Training Accuracy: 30.280\n",
            "Worker 1, [27/37]: Training Loss: 2.690309934, Training Accuracy: 30.624\n",
            "Worker 1, [28/37]: Training Loss: 2.640607681, Training Accuracy: 32.032\n",
            "Worker 1, [29/37]: Training Loss: 2.838885416, Training Accuracy: 28.888\n",
            "Worker 1, [30/37]: Training Loss: 2.775898239, Training Accuracy: 29.528\n",
            "Worker 1, [31/37]: Training Loss: 2.693604284, Training Accuracy: 31.064\n",
            "Worker 1, [32/37]: Training Loss: 2.640064282, Training Accuracy: 32.176\n",
            "Worker 1, [33/37]: Training Loss: 2.851140984, Training Accuracy: 28.256\n",
            "Worker 1, [34/37]: Training Loss: 2.766012332, Training Accuracy: 29.400\n",
            "Worker 1, [35/37]: Training Loss: 2.699153623, Training Accuracy: 31.400\n",
            "Worker 1, [36/37]: Training Loss: 2.618937175, Training Accuracy: 32.840\n",
            "Worker 1, [37/37]: Training Loss: 2.825758582, Training Accuracy: 28.608\n",
            "Time taken for training worker 1: 0:03:08.973511\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.058361058, Training Accuracy: 24.984\n",
            "Worker 2, [02/37]: Training Loss: 3.001531297, Training Accuracy: 26.168\n",
            "Worker 2, [03/37]: Training Loss: 2.915536786, Training Accuracy: 27.632\n",
            "Worker 2, [04/37]: Training Loss: 2.837629762, Training Accuracy: 29.032\n",
            "Worker 2, [05/37]: Training Loss: 2.656916778, Training Accuracy: 33.344\n",
            "Worker 2, [06/37]: Training Loss: 2.584605622, Training Accuracy: 33.984\n",
            "Worker 2, [07/37]: Training Loss: 2.548211879, Training Accuracy: 34.296\n",
            "Worker 2, [08/37]: Training Loss: 2.528961485, Training Accuracy: 34.576\n",
            "Worker 2, [09/37]: Training Loss: 2.632773354, Training Accuracy: 32.432\n",
            "Worker 2, [10/37]: Training Loss: 2.574896441, Training Accuracy: 33.568\n",
            "Worker 2, [11/37]: Training Loss: 2.539710348, Training Accuracy: 34.504\n",
            "Worker 2, [12/37]: Training Loss: 2.520829758, Training Accuracy: 34.392\n",
            "Worker 2, [13/37]: Training Loss: 2.633682593, Training Accuracy: 32.184\n",
            "Worker 2, [14/37]: Training Loss: 2.594668031, Training Accuracy: 33.472\n",
            "Worker 2, [15/37]: Training Loss: 2.590044148, Training Accuracy: 33.352\n",
            "Worker 2, [16/37]: Training Loss: 2.529539498, Training Accuracy: 34.416\n",
            "Worker 2, [17/37]: Training Loss: 2.696475395, Training Accuracy: 31.256\n",
            "Worker 2, [18/37]: Training Loss: 2.645198397, Training Accuracy: 31.760\n",
            "Worker 2, [19/37]: Training Loss: 2.603808673, Training Accuracy: 32.328\n",
            "Worker 2, [20/37]: Training Loss: 2.561711969, Training Accuracy: 33.496\n",
            "Worker 2, [21/37]: Training Loss: 2.736924124, Training Accuracy: 29.696\n",
            "Worker 2, [22/37]: Training Loss: 2.687234387, Training Accuracy: 30.472\n",
            "Worker 2, [23/37]: Training Loss: 2.632653952, Training Accuracy: 32.344\n",
            "Worker 2, [24/37]: Training Loss: 2.587254507, Training Accuracy: 32.480\n",
            "Worker 2, [25/37]: Training Loss: 2.784797443, Training Accuracy: 29.184\n",
            "Worker 2, [26/37]: Training Loss: 2.737596479, Training Accuracy: 29.976\n",
            "Worker 2, [27/37]: Training Loss: 2.654478987, Training Accuracy: 31.800\n",
            "Worker 2, [28/37]: Training Loss: 2.608255599, Training Accuracy: 32.488\n",
            "Worker 2, [29/37]: Training Loss: 2.794590418, Training Accuracy: 28.296\n",
            "Worker 2, [30/37]: Training Loss: 2.723916900, Training Accuracy: 30.112\n",
            "Worker 2, [31/37]: Training Loss: 2.667316369, Training Accuracy: 31.320\n",
            "Worker 2, [32/37]: Training Loss: 2.598114370, Training Accuracy: 32.712\n",
            "Worker 2, [33/37]: Training Loss: 2.801421404, Training Accuracy: 28.560\n",
            "Worker 2, [34/37]: Training Loss: 2.730558077, Training Accuracy: 29.928\n",
            "Worker 2, [35/37]: Training Loss: 2.657333694, Training Accuracy: 31.848\n",
            "Worker 2, [36/37]: Training Loss: 2.563553171, Training Accuracy: 33.056\n",
            "Worker 2, [37/37]: Training Loss: 2.763618585, Training Accuracy: 29.040\n",
            "Time taken for training worker 2: 0:03:06.337414\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.063892666, Training Accuracy: 24.912\n",
            "Worker 3, [02/37]: Training Loss: 2.981050802, Training Accuracy: 26.488\n",
            "Worker 3, [03/37]: Training Loss: 2.875887157, Training Accuracy: 28.328\n",
            "Worker 3, [04/37]: Training Loss: 2.803607332, Training Accuracy: 30.056\n",
            "Worker 3, [05/37]: Training Loss: 2.635434682, Training Accuracy: 34.000\n",
            "Worker 3, [06/37]: Training Loss: 2.565846621, Training Accuracy: 33.816\n",
            "Worker 3, [07/37]: Training Loss: 2.545005748, Training Accuracy: 34.576\n",
            "Worker 3, [08/37]: Training Loss: 2.516442945, Training Accuracy: 34.968\n",
            "Worker 3, [09/37]: Training Loss: 2.603554525, Training Accuracy: 33.720\n",
            "Worker 3, [10/37]: Training Loss: 2.558656095, Training Accuracy: 34.576\n",
            "Worker 3, [11/37]: Training Loss: 2.533487740, Training Accuracy: 34.184\n",
            "Worker 3, [12/37]: Training Loss: 2.511967669, Training Accuracy: 34.576\n",
            "Worker 3, [13/37]: Training Loss: 2.632283167, Training Accuracy: 32.512\n",
            "Worker 3, [14/37]: Training Loss: 2.591047839, Training Accuracy: 33.144\n",
            "Worker 3, [15/37]: Training Loss: 2.551300328, Training Accuracy: 34.264\n",
            "Worker 3, [16/37]: Training Loss: 2.522606284, Training Accuracy: 33.632\n",
            "Worker 3, [17/37]: Training Loss: 2.673478781, Training Accuracy: 31.664\n",
            "Worker 3, [18/37]: Training Loss: 2.635052598, Training Accuracy: 32.408\n",
            "Worker 3, [19/37]: Training Loss: 2.571455645, Training Accuracy: 32.912\n",
            "Worker 3, [20/37]: Training Loss: 2.542003116, Training Accuracy: 33.872\n",
            "Worker 3, [21/37]: Training Loss: 2.725055563, Training Accuracy: 30.096\n",
            "Worker 3, [22/37]: Training Loss: 2.667124063, Training Accuracy: 31.120\n",
            "Worker 3, [23/37]: Training Loss: 2.624932047, Training Accuracy: 31.496\n",
            "Worker 3, [24/37]: Training Loss: 2.564292812, Training Accuracy: 33.208\n",
            "Worker 3, [25/37]: Training Loss: 2.781353792, Training Accuracy: 28.992\n",
            "Worker 3, [26/37]: Training Loss: 2.711005438, Training Accuracy: 30.448\n",
            "Worker 3, [27/37]: Training Loss: 2.646329720, Training Accuracy: 31.616\n",
            "Worker 3, [28/37]: Training Loss: 2.594466703, Training Accuracy: 32.512\n",
            "Worker 3, [29/37]: Training Loss: 2.777173651, Training Accuracy: 28.624\n",
            "Worker 3, [30/37]: Training Loss: 2.712137015, Training Accuracy: 30.016\n",
            "Worker 3, [31/37]: Training Loss: 2.644052824, Training Accuracy: 31.568\n",
            "Worker 3, [32/37]: Training Loss: 2.578562486, Training Accuracy: 32.504\n",
            "Worker 3, [33/37]: Training Loss: 2.773408020, Training Accuracy: 29.040\n",
            "Worker 3, [34/37]: Training Loss: 2.714004192, Training Accuracy: 30.424\n",
            "Worker 3, [35/37]: Training Loss: 2.625369600, Training Accuracy: 31.560\n",
            "Worker 3, [36/37]: Training Loss: 2.555640121, Training Accuracy: 33.056\n",
            "Worker 3, [37/37]: Training Loss: 2.733060250, Training Accuracy: 29.640\n",
            "Time taken for training worker 3: 0:03:07.727913\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.024446101, Training Accuracy: 25.272\n",
            "Worker 4, [02/37]: Training Loss: 2.956392920, Training Accuracy: 27.112\n",
            "Worker 4, [03/37]: Training Loss: 2.864529240, Training Accuracy: 28.328\n",
            "Worker 4, [04/37]: Training Loss: 2.790035526, Training Accuracy: 29.888\n",
            "Worker 4, [05/37]: Training Loss: 2.656365208, Training Accuracy: 33.496\n",
            "Worker 4, [06/37]: Training Loss: 2.577487603, Training Accuracy: 34.192\n",
            "Worker 4, [07/37]: Training Loss: 2.550758519, Training Accuracy: 34.280\n",
            "Worker 4, [08/37]: Training Loss: 2.536221807, Training Accuracy: 34.808\n",
            "Worker 4, [09/37]: Training Loss: 2.620424564, Training Accuracy: 33.464\n",
            "Worker 4, [10/37]: Training Loss: 2.562627373, Training Accuracy: 33.664\n",
            "Worker 4, [11/37]: Training Loss: 2.548171118, Training Accuracy: 34.128\n",
            "Worker 4, [12/37]: Training Loss: 2.530506372, Training Accuracy: 34.184\n",
            "Worker 4, [13/37]: Training Loss: 2.646031022, Training Accuracy: 32.224\n",
            "Worker 4, [14/37]: Training Loss: 2.588506651, Training Accuracy: 32.920\n",
            "Worker 4, [15/37]: Training Loss: 2.553469607, Training Accuracy: 34.240\n",
            "Worker 4, [16/37]: Training Loss: 2.539249926, Training Accuracy: 33.568\n",
            "Worker 4, [17/37]: Training Loss: 2.688498649, Training Accuracy: 30.696\n",
            "Worker 4, [18/37]: Training Loss: 2.643499733, Training Accuracy: 31.504\n",
            "Worker 4, [19/37]: Training Loss: 2.608789386, Training Accuracy: 32.536\n",
            "Worker 4, [20/37]: Training Loss: 2.565584599, Training Accuracy: 32.864\n",
            "Worker 4, [21/37]: Training Loss: 2.739823688, Training Accuracy: 29.632\n",
            "Worker 4, [22/37]: Training Loss: 2.683270297, Training Accuracy: 30.632\n",
            "Worker 4, [23/37]: Training Loss: 2.637994099, Training Accuracy: 31.648\n",
            "Worker 4, [24/37]: Training Loss: 2.578039590, Training Accuracy: 32.984\n",
            "Worker 4, [25/37]: Training Loss: 2.778740546, Training Accuracy: 29.264\n",
            "Worker 4, [26/37]: Training Loss: 2.714381866, Training Accuracy: 30.264\n",
            "Worker 4, [27/37]: Training Loss: 2.627584225, Training Accuracy: 31.520\n",
            "Worker 4, [28/37]: Training Loss: 2.596293895, Training Accuracy: 32.768\n",
            "Worker 4, [29/37]: Training Loss: 2.802371143, Training Accuracy: 28.888\n",
            "Worker 4, [30/37]: Training Loss: 2.741870432, Training Accuracy: 30.152\n",
            "Worker 4, [31/37]: Training Loss: 2.688061527, Training Accuracy: 30.928\n",
            "Worker 4, [32/37]: Training Loss: 2.608292141, Training Accuracy: 32.720\n",
            "Worker 4, [33/37]: Training Loss: 2.773975769, Training Accuracy: 28.288\n",
            "Worker 4, [34/37]: Training Loss: 2.723826430, Training Accuracy: 30.280\n",
            "Worker 4, [35/37]: Training Loss: 2.626538424, Training Accuracy: 31.520\n",
            "Worker 4, [36/37]: Training Loss: 2.544871556, Training Accuracy: 33.272\n",
            "Worker 4, [37/37]: Training Loss: 2.763167102, Training Accuracy: 29.216\n",
            "Time taken for training worker 4: 0:03:04.388162\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000963\n",
            "Local Step 04: Test Loss: 2.805053154, Test Accuracy: 30.000\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:21.921577\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.518978029, Training Accuracy: 2.576\n",
            "Worker 1, [02/37]: Training Loss: 4.146136791, Training Accuracy: 6.032\n",
            "Worker 1, [03/37]: Training Loss: 3.930447087, Training Accuracy: 9.264\n",
            "Worker 1, [04/37]: Training Loss: 3.770826699, Training Accuracy: 11.640\n",
            "Worker 1, [05/37]: Training Loss: 3.625675728, Training Accuracy: 14.008\n",
            "Worker 1, [06/37]: Training Loss: 3.500746137, Training Accuracy: 15.584\n",
            "Worker 1, [07/37]: Training Loss: 3.373856873, Training Accuracy: 18.520\n",
            "Worker 1, [08/37]: Training Loss: 3.268449073, Training Accuracy: 19.968\n",
            "Worker 1, [09/37]: Training Loss: 4.386226379, Training Accuracy: 4.008\n",
            "Worker 1, [10/37]: Training Loss: 3.938317523, Training Accuracy: 9.272\n",
            "Worker 1, [11/37]: Training Loss: 3.692008823, Training Accuracy: 12.984\n",
            "Worker 1, [12/37]: Training Loss: 3.516299534, Training Accuracy: 15.552\n",
            "Worker 1, [13/37]: Training Loss: 3.387142430, Training Accuracy: 18.296\n",
            "Worker 1, [14/37]: Training Loss: 3.251188171, Training Accuracy: 20.648\n",
            "Worker 1, [15/37]: Training Loss: 3.154024625, Training Accuracy: 22.520\n",
            "Worker 1, [16/37]: Training Loss: 3.062540650, Training Accuracy: 24.176\n",
            "Worker 1, [17/37]: Training Loss: 4.176602666, Training Accuracy: 7.232\n",
            "Worker 1, [18/37]: Training Loss: 3.691973537, Training Accuracy: 13.216\n",
            "Worker 1, [19/37]: Training Loss: 3.464058932, Training Accuracy: 16.784\n",
            "Worker 1, [20/37]: Training Loss: 3.325619077, Training Accuracy: 19.432\n",
            "Worker 1, [21/37]: Training Loss: 3.194860110, Training Accuracy: 21.696\n",
            "Worker 1, [22/37]: Training Loss: 3.090776521, Training Accuracy: 23.568\n",
            "Worker 1, [23/37]: Training Loss: 3.024972080, Training Accuracy: 24.720\n",
            "Worker 1, [24/37]: Training Loss: 2.929126587, Training Accuracy: 26.552\n",
            "Worker 1, [25/37]: Training Loss: 4.090946414, Training Accuracy: 9.672\n",
            "Worker 1, [26/37]: Training Loss: 3.611670837, Training Accuracy: 14.888\n",
            "Worker 1, [27/37]: Training Loss: 3.400250407, Training Accuracy: 18.480\n",
            "Worker 1, [28/37]: Training Loss: 3.276035061, Training Accuracy: 20.640\n",
            "Worker 1, [29/37]: Training Loss: 3.185845849, Training Accuracy: 22.504\n",
            "Worker 1, [30/37]: Training Loss: 3.113542029, Training Accuracy: 23.880\n",
            "Worker 1, [31/37]: Training Loss: 3.050371787, Training Accuracy: 24.584\n",
            "Worker 1, [32/37]: Training Loss: 2.996236436, Training Accuracy: 25.592\n",
            "Worker 1, [33/37]: Training Loss: 4.327936781, Training Accuracy: 12.056\n",
            "Worker 1, [34/37]: Training Loss: 4.026946541, Training Accuracy: 11.968\n",
            "Worker 1, [35/37]: Training Loss: 3.860863735, Training Accuracy: 13.128\n",
            "Worker 1, [36/37]: Training Loss: 3.802245000, Training Accuracy: 13.800\n",
            "Worker 1, [37/37]: Training Loss: 3.775015158, Training Accuracy: 14.000\n",
            "Time taken for training worker 1: 0:03:07.785833\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.519642397, Training Accuracy: 2.280\n",
            "Worker 2, [02/37]: Training Loss: 4.137242009, Training Accuracy: 6.448\n",
            "Worker 2, [03/37]: Training Loss: 3.914001343, Training Accuracy: 9.520\n",
            "Worker 2, [04/37]: Training Loss: 3.772468987, Training Accuracy: 11.864\n",
            "Worker 2, [05/37]: Training Loss: 3.629690990, Training Accuracy: 13.376\n",
            "Worker 2, [06/37]: Training Loss: 3.515559631, Training Accuracy: 15.968\n",
            "Worker 2, [07/37]: Training Loss: 3.387331171, Training Accuracy: 18.128\n",
            "Worker 2, [08/37]: Training Loss: 3.270322156, Training Accuracy: 19.576\n",
            "Worker 2, [09/37]: Training Loss: 4.294304629, Training Accuracy: 4.720\n",
            "Worker 2, [10/37]: Training Loss: 3.838319067, Training Accuracy: 11.056\n",
            "Worker 2, [11/37]: Training Loss: 3.598606955, Training Accuracy: 13.952\n",
            "Worker 2, [12/37]: Training Loss: 3.450551281, Training Accuracy: 16.536\n",
            "Worker 2, [13/37]: Training Loss: 3.312965065, Training Accuracy: 19.368\n",
            "Worker 2, [14/37]: Training Loss: 3.217544640, Training Accuracy: 20.648\n",
            "Worker 2, [15/37]: Training Loss: 3.115979779, Training Accuracy: 22.768\n",
            "Worker 2, [16/37]: Training Loss: 3.013527362, Training Accuracy: 24.752\n",
            "Worker 2, [17/37]: Training Loss: 4.144779715, Training Accuracy: 7.584\n",
            "Worker 2, [18/37]: Training Loss: 3.655390360, Training Accuracy: 13.728\n",
            "Worker 2, [19/37]: Training Loss: 3.419989088, Training Accuracy: 17.904\n",
            "Worker 2, [20/37]: Training Loss: 3.287758393, Training Accuracy: 20.024\n",
            "Worker 2, [21/37]: Training Loss: 3.149907404, Training Accuracy: 21.776\n",
            "Worker 2, [22/37]: Training Loss: 3.048324934, Training Accuracy: 24.144\n",
            "Worker 2, [23/37]: Training Loss: 2.963187516, Training Accuracy: 25.944\n",
            "Worker 2, [24/37]: Training Loss: 2.873262182, Training Accuracy: 27.664\n",
            "Worker 2, [25/37]: Training Loss: 4.060469427, Training Accuracy: 10.160\n",
            "Worker 2, [26/37]: Training Loss: 3.587070033, Training Accuracy: 14.952\n",
            "Worker 2, [27/37]: Training Loss: 3.391727866, Training Accuracy: 18.496\n",
            "Worker 2, [28/37]: Training Loss: 3.257236335, Training Accuracy: 20.784\n",
            "Worker 2, [29/37]: Training Loss: 3.165469016, Training Accuracy: 22.264\n",
            "Worker 2, [30/37]: Training Loss: 3.102368652, Training Accuracy: 23.432\n",
            "Worker 2, [31/37]: Training Loss: 3.039623122, Training Accuracy: 24.936\n",
            "Worker 2, [32/37]: Training Loss: 2.990450196, Training Accuracy: 25.944\n",
            "Worker 2, [33/37]: Training Loss: 4.310959640, Training Accuracy: 12.008\n",
            "Worker 2, [34/37]: Training Loss: 3.999778606, Training Accuracy: 12.312\n",
            "Worker 2, [35/37]: Training Loss: 3.838660743, Training Accuracy: 13.400\n",
            "Worker 2, [36/37]: Training Loss: 3.771458847, Training Accuracy: 14.432\n",
            "Worker 2, [37/37]: Training Loss: 3.746597257, Training Accuracy: 14.744\n",
            "Time taken for training worker 2: 0:03:06.686593\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.511140208, Training Accuracy: 2.368\n",
            "Worker 3, [02/37]: Training Loss: 4.122568887, Training Accuracy: 6.480\n",
            "Worker 3, [03/37]: Training Loss: 3.916414918, Training Accuracy: 9.464\n",
            "Worker 3, [04/37]: Training Loss: 3.749753419, Training Accuracy: 11.768\n",
            "Worker 3, [05/37]: Training Loss: 3.602206488, Training Accuracy: 13.776\n",
            "Worker 3, [06/37]: Training Loss: 3.484180531, Training Accuracy: 16.184\n",
            "Worker 3, [07/37]: Training Loss: 3.376523715, Training Accuracy: 17.608\n",
            "Worker 3, [08/37]: Training Loss: 3.273314238, Training Accuracy: 19.720\n",
            "Worker 3, [09/37]: Training Loss: 4.317792357, Training Accuracy: 4.672\n",
            "Worker 3, [10/37]: Training Loss: 3.866161452, Training Accuracy: 10.256\n",
            "Worker 3, [11/37]: Training Loss: 3.636267014, Training Accuracy: 13.664\n",
            "Worker 3, [12/37]: Training Loss: 3.488200841, Training Accuracy: 15.904\n",
            "Worker 3, [13/37]: Training Loss: 3.329517169, Training Accuracy: 18.288\n",
            "Worker 3, [14/37]: Training Loss: 3.216908495, Training Accuracy: 20.624\n",
            "Worker 3, [15/37]: Training Loss: 3.126750314, Training Accuracy: 22.528\n",
            "Worker 3, [16/37]: Training Loss: 3.041037317, Training Accuracy: 24.112\n",
            "Worker 3, [17/37]: Training Loss: 4.150457010, Training Accuracy: 7.624\n",
            "Worker 3, [18/37]: Training Loss: 3.661215331, Training Accuracy: 13.416\n",
            "Worker 3, [19/37]: Training Loss: 3.432524984, Training Accuracy: 17.176\n",
            "Worker 3, [20/37]: Training Loss: 3.291517314, Training Accuracy: 19.536\n",
            "Worker 3, [21/37]: Training Loss: 3.153078978, Training Accuracy: 21.856\n",
            "Worker 3, [22/37]: Training Loss: 3.043275691, Training Accuracy: 24.280\n",
            "Worker 3, [23/37]: Training Loss: 2.971938167, Training Accuracy: 25.560\n",
            "Worker 3, [24/37]: Training Loss: 2.914816800, Training Accuracy: 26.632\n",
            "Worker 3, [25/37]: Training Loss: 4.064521738, Training Accuracy: 10.240\n",
            "Worker 3, [26/37]: Training Loss: 3.609482097, Training Accuracy: 14.576\n",
            "Worker 3, [27/37]: Training Loss: 3.403061437, Training Accuracy: 18.144\n",
            "Worker 3, [28/37]: Training Loss: 3.264962115, Training Accuracy: 20.616\n",
            "Worker 3, [29/37]: Training Loss: 3.163157125, Training Accuracy: 22.192\n",
            "Worker 3, [30/37]: Training Loss: 3.098750787, Training Accuracy: 23.224\n",
            "Worker 3, [31/37]: Training Loss: 3.032355531, Training Accuracy: 24.696\n",
            "Worker 3, [32/37]: Training Loss: 2.985298042, Training Accuracy: 25.808\n",
            "Worker 3, [33/37]: Training Loss: 4.312075065, Training Accuracy: 12.936\n",
            "Worker 3, [34/37]: Training Loss: 3.996873880, Training Accuracy: 11.872\n",
            "Worker 3, [35/37]: Training Loss: 3.831538309, Training Accuracy: 13.560\n",
            "Worker 3, [36/37]: Training Loss: 3.771186944, Training Accuracy: 14.416\n",
            "Worker 3, [37/37]: Training Loss: 3.751852207, Training Accuracy: 14.376\n",
            "Time taken for training worker 3: 0:03:07.996052\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.534632904, Training Accuracy: 2.216\n",
            "Worker 4, [02/37]: Training Loss: 4.162050263, Training Accuracy: 5.824\n",
            "Worker 4, [03/37]: Training Loss: 3.935463443, Training Accuracy: 8.656\n",
            "Worker 4, [04/37]: Training Loss: 3.790892948, Training Accuracy: 10.896\n",
            "Worker 4, [05/37]: Training Loss: 3.639930596, Training Accuracy: 13.464\n",
            "Worker 4, [06/37]: Training Loss: 3.514975617, Training Accuracy: 15.752\n",
            "Worker 4, [07/37]: Training Loss: 3.370039329, Training Accuracy: 17.944\n",
            "Worker 4, [08/37]: Training Loss: 3.290055665, Training Accuracy: 19.216\n",
            "Worker 4, [09/37]: Training Loss: 4.304598317, Training Accuracy: 4.904\n",
            "Worker 4, [10/37]: Training Loss: 3.898199693, Training Accuracy: 9.928\n",
            "Worker 4, [11/37]: Training Loss: 3.664209412, Training Accuracy: 13.640\n",
            "Worker 4, [12/37]: Training Loss: 3.494580959, Training Accuracy: 15.952\n",
            "Worker 4, [13/37]: Training Loss: 3.344737712, Training Accuracy: 18.248\n",
            "Worker 4, [14/37]: Training Loss: 3.228476700, Training Accuracy: 20.472\n",
            "Worker 4, [15/37]: Training Loss: 3.133052703, Training Accuracy: 22.472\n",
            "Worker 4, [16/37]: Training Loss: 3.043569721, Training Accuracy: 24.280\n",
            "Worker 4, [17/37]: Training Loss: 4.135741538, Training Accuracy: 7.096\n",
            "Worker 4, [18/37]: Training Loss: 3.668654556, Training Accuracy: 13.256\n",
            "Worker 4, [19/37]: Training Loss: 3.443305641, Training Accuracy: 17.120\n",
            "Worker 4, [20/37]: Training Loss: 3.292241404, Training Accuracy: 19.776\n",
            "Worker 4, [21/37]: Training Loss: 3.166279765, Training Accuracy: 22.168\n",
            "Worker 4, [22/37]: Training Loss: 3.072531332, Training Accuracy: 23.512\n",
            "Worker 4, [23/37]: Training Loss: 2.975685673, Training Accuracy: 25.024\n",
            "Worker 4, [24/37]: Training Loss: 2.901831430, Training Accuracy: 26.632\n",
            "Worker 4, [25/37]: Training Loss: 4.079381555, Training Accuracy: 8.920\n",
            "Worker 4, [26/37]: Training Loss: 3.604051879, Training Accuracy: 14.656\n",
            "Worker 4, [27/37]: Training Loss: 3.400881573, Training Accuracy: 18.208\n",
            "Worker 4, [28/37]: Training Loss: 3.284366398, Training Accuracy: 20.160\n",
            "Worker 4, [29/37]: Training Loss: 3.171148616, Training Accuracy: 22.016\n",
            "Worker 4, [30/37]: Training Loss: 3.106432607, Training Accuracy: 22.992\n",
            "Worker 4, [31/37]: Training Loss: 3.027483343, Training Accuracy: 24.816\n",
            "Worker 4, [32/37]: Training Loss: 2.992454468, Training Accuracy: 25.296\n",
            "Worker 4, [33/37]: Training Loss: 4.317792211, Training Accuracy: 11.968\n",
            "Worker 4, [34/37]: Training Loss: 4.008946966, Training Accuracy: 11.832\n",
            "Worker 4, [35/37]: Training Loss: 3.848617737, Training Accuracy: 13.040\n",
            "Worker 4, [36/37]: Training Loss: 3.781688815, Training Accuracy: 13.824\n",
            "Worker 4, [37/37]: Training Loss: 3.761932802, Training Accuracy: 14.296\n",
            "Time taken for training worker 4: 0:03:11.342748\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000647\n",
            "Local Step 01: Test Loss: 3.848306905, Test Accuracy: 13.880\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.895815325, Training Accuracy: 12.808\n",
            "Worker 1, [02/37]: Training Loss: 3.885444234, Training Accuracy: 12.992\n",
            "Worker 1, [03/37]: Training Loss: 3.866783281, Training Accuracy: 13.112\n",
            "Worker 1, [04/37]: Training Loss: 3.823951124, Training Accuracy: 13.440\n",
            "Worker 1, [05/37]: Training Loss: 3.762638360, Training Accuracy: 13.632\n",
            "Worker 1, [06/37]: Training Loss: 3.691789519, Training Accuracy: 14.528\n",
            "Worker 1, [07/37]: Training Loss: 3.609753215, Training Accuracy: 15.416\n",
            "Worker 1, [08/37]: Training Loss: 3.532201374, Training Accuracy: 16.616\n",
            "Worker 1, [09/37]: Training Loss: 4.004200224, Training Accuracy: 12.912\n",
            "Worker 1, [10/37]: Training Loss: 3.603010223, Training Accuracy: 15.720\n",
            "Worker 1, [11/37]: Training Loss: 3.433748191, Training Accuracy: 17.560\n",
            "Worker 1, [12/37]: Training Loss: 3.327203256, Training Accuracy: 19.920\n",
            "Worker 1, [13/37]: Training Loss: 3.229753422, Training Accuracy: 21.256\n",
            "Worker 1, [14/37]: Training Loss: 3.162698984, Training Accuracy: 22.096\n",
            "Worker 1, [15/37]: Training Loss: 3.101902068, Training Accuracy: 23.480\n",
            "Worker 1, [16/37]: Training Loss: 3.071475623, Training Accuracy: 24.232\n",
            "Worker 1, [17/37]: Training Loss: 3.683977413, Training Accuracy: 14.296\n",
            "Worker 1, [18/37]: Training Loss: 3.332210048, Training Accuracy: 18.952\n",
            "Worker 1, [19/37]: Training Loss: 3.211033783, Training Accuracy: 21.048\n",
            "Worker 1, [20/37]: Training Loss: 3.127400544, Training Accuracy: 22.616\n",
            "Worker 1, [21/37]: Training Loss: 3.042744110, Training Accuracy: 24.288\n",
            "Worker 1, [22/37]: Training Loss: 2.987661477, Training Accuracy: 25.768\n",
            "Worker 1, [23/37]: Training Loss: 2.921727818, Training Accuracy: 26.712\n",
            "Worker 1, [24/37]: Training Loss: 2.862480514, Training Accuracy: 27.592\n",
            "Worker 1, [25/37]: Training Loss: 3.545452935, Training Accuracy: 15.992\n",
            "Worker 1, [26/37]: Training Loss: 3.256420907, Training Accuracy: 20.712\n",
            "Worker 1, [27/37]: Training Loss: 3.100174837, Training Accuracy: 23.704\n",
            "Worker 1, [28/37]: Training Loss: 3.006170857, Training Accuracy: 24.768\n",
            "Worker 1, [29/37]: Training Loss: 2.927211272, Training Accuracy: 26.568\n",
            "Worker 1, [30/37]: Training Loss: 2.865141291, Training Accuracy: 27.544\n",
            "Worker 1, [31/37]: Training Loss: 2.820794592, Training Accuracy: 28.376\n",
            "Worker 1, [32/37]: Training Loss: 2.708754634, Training Accuracy: 30.880\n",
            "Worker 1, [33/37]: Training Loss: 3.432134126, Training Accuracy: 17.952\n",
            "Worker 1, [34/37]: Training Loss: 3.165979618, Training Accuracy: 21.728\n",
            "Worker 1, [35/37]: Training Loss: 3.033564570, Training Accuracy: 24.752\n",
            "Worker 1, [36/37]: Training Loss: 2.920933304, Training Accuracy: 27.144\n",
            "Worker 1, [37/37]: Training Loss: 2.816051489, Training Accuracy: 28.176\n",
            "Time taken for training worker 1: 0:03:06.898309\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.069441900, Training Accuracy: 24.344\n",
            "Worker 2, [02/37]: Training Loss: 3.016079342, Training Accuracy: 25.152\n",
            "Worker 2, [03/37]: Training Loss: 2.943684684, Training Accuracy: 26.768\n",
            "Worker 2, [04/37]: Training Loss: 2.869496524, Training Accuracy: 28.008\n",
            "Worker 2, [05/37]: Training Loss: 2.809138030, Training Accuracy: 29.704\n",
            "Worker 2, [06/37]: Training Loss: 2.755282701, Training Accuracy: 30.344\n",
            "Worker 2, [07/37]: Training Loss: 2.714986240, Training Accuracy: 31.304\n",
            "Worker 2, [08/37]: Training Loss: 2.673645509, Training Accuracy: 31.896\n",
            "Worker 2, [09/37]: Training Loss: 3.958186834, Training Accuracy: 14.440\n",
            "Worker 2, [10/37]: Training Loss: 3.512029032, Training Accuracy: 16.904\n",
            "Worker 2, [11/37]: Training Loss: 3.332279090, Training Accuracy: 19.480\n",
            "Worker 2, [12/37]: Training Loss: 3.230940292, Training Accuracy: 21.040\n",
            "Worker 2, [13/37]: Training Loss: 3.142043882, Training Accuracy: 22.592\n",
            "Worker 2, [14/37]: Training Loss: 3.076832329, Training Accuracy: 24.032\n",
            "Worker 2, [15/37]: Training Loss: 3.019679516, Training Accuracy: 24.744\n",
            "Worker 2, [16/37]: Training Loss: 2.953203612, Training Accuracy: 26.160\n",
            "Worker 2, [17/37]: Training Loss: 3.625595539, Training Accuracy: 15.056\n",
            "Worker 2, [18/37]: Training Loss: 3.253439125, Training Accuracy: 20.416\n",
            "Worker 2, [19/37]: Training Loss: 3.124728196, Training Accuracy: 22.936\n",
            "Worker 2, [20/37]: Training Loss: 3.023846600, Training Accuracy: 24.648\n",
            "Worker 2, [21/37]: Training Loss: 2.928927355, Training Accuracy: 26.864\n",
            "Worker 2, [22/37]: Training Loss: 2.900548102, Training Accuracy: 26.760\n",
            "Worker 2, [23/37]: Training Loss: 2.803602788, Training Accuracy: 28.296\n",
            "Worker 2, [24/37]: Training Loss: 2.765578945, Training Accuracy: 30.000\n",
            "Worker 2, [25/37]: Training Loss: 3.455546818, Training Accuracy: 18.128\n",
            "Worker 2, [26/37]: Training Loss: 3.155506801, Training Accuracy: 22.112\n",
            "Worker 2, [27/37]: Training Loss: 3.023769605, Training Accuracy: 24.472\n",
            "Worker 2, [28/37]: Training Loss: 2.927289732, Training Accuracy: 25.768\n",
            "Worker 2, [29/37]: Training Loss: 2.835219153, Training Accuracy: 27.664\n",
            "Worker 2, [30/37]: Training Loss: 2.751127503, Training Accuracy: 29.840\n",
            "Worker 2, [31/37]: Training Loss: 2.663533420, Training Accuracy: 31.600\n",
            "Worker 2, [32/37]: Training Loss: 2.627722730, Training Accuracy: 32.464\n",
            "Worker 2, [33/37]: Training Loss: 3.351200077, Training Accuracy: 19.136\n",
            "Worker 2, [34/37]: Training Loss: 3.070873161, Training Accuracy: 23.616\n",
            "Worker 2, [35/37]: Training Loss: 2.924393529, Training Accuracy: 25.952\n",
            "Worker 2, [36/37]: Training Loss: 2.823347121, Training Accuracy: 28.368\n",
            "Worker 2, [37/37]: Training Loss: 2.742129777, Training Accuracy: 29.880\n",
            "Time taken for training worker 2: 0:03:06.269211\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.963875317, Training Accuracy: 25.992\n",
            "Worker 3, [02/37]: Training Loss: 2.925558343, Training Accuracy: 26.776\n",
            "Worker 3, [03/37]: Training Loss: 2.845447010, Training Accuracy: 28.440\n",
            "Worker 3, [04/37]: Training Loss: 2.780291572, Training Accuracy: 30.584\n",
            "Worker 3, [05/37]: Training Loss: 2.711379010, Training Accuracy: 31.472\n",
            "Worker 3, [06/37]: Training Loss: 2.680307646, Training Accuracy: 32.272\n",
            "Worker 3, [07/37]: Training Loss: 2.643025437, Training Accuracy: 32.968\n",
            "Worker 3, [08/37]: Training Loss: 2.587901850, Training Accuracy: 34.264\n",
            "Worker 3, [09/37]: Training Loss: 3.950711955, Training Accuracy: 13.744\n",
            "Worker 3, [10/37]: Training Loss: 3.509180785, Training Accuracy: 17.032\n",
            "Worker 3, [11/37]: Training Loss: 3.336288719, Training Accuracy: 19.216\n",
            "Worker 3, [12/37]: Training Loss: 3.227439250, Training Accuracy: 21.176\n",
            "Worker 3, [13/37]: Training Loss: 3.134530476, Training Accuracy: 22.088\n",
            "Worker 3, [14/37]: Training Loss: 3.079974847, Training Accuracy: 23.552\n",
            "Worker 3, [15/37]: Training Loss: 3.021588728, Training Accuracy: 24.760\n",
            "Worker 3, [16/37]: Training Loss: 2.952840162, Training Accuracy: 25.752\n",
            "Worker 3, [17/37]: Training Loss: 3.596678740, Training Accuracy: 16.312\n",
            "Worker 3, [18/37]: Training Loss: 3.225437887, Training Accuracy: 20.984\n",
            "Worker 3, [19/37]: Training Loss: 3.111471228, Training Accuracy: 23.104\n",
            "Worker 3, [20/37]: Training Loss: 3.022258425, Training Accuracy: 24.392\n",
            "Worker 3, [21/37]: Training Loss: 2.957113254, Training Accuracy: 25.728\n",
            "Worker 3, [22/37]: Training Loss: 2.874755435, Training Accuracy: 27.304\n",
            "Worker 3, [23/37]: Training Loss: 2.816233125, Training Accuracy: 28.488\n",
            "Worker 3, [24/37]: Training Loss: 2.745016141, Training Accuracy: 29.600\n",
            "Worker 3, [25/37]: Training Loss: 3.463621462, Training Accuracy: 17.384\n",
            "Worker 3, [26/37]: Training Loss: 3.150638578, Training Accuracy: 21.736\n",
            "Worker 3, [27/37]: Training Loss: 3.008220596, Training Accuracy: 24.248\n",
            "Worker 3, [28/37]: Training Loss: 2.919539060, Training Accuracy: 26.608\n",
            "Worker 3, [29/37]: Training Loss: 2.830867598, Training Accuracy: 27.896\n",
            "Worker 3, [30/37]: Training Loss: 2.767610894, Training Accuracy: 28.888\n",
            "Worker 3, [31/37]: Training Loss: 2.698755042, Training Accuracy: 30.984\n",
            "Worker 3, [32/37]: Training Loss: 2.629863838, Training Accuracy: 31.880\n",
            "Worker 3, [33/37]: Training Loss: 3.351530352, Training Accuracy: 19.216\n",
            "Worker 3, [34/37]: Training Loss: 3.063649912, Training Accuracy: 23.864\n",
            "Worker 3, [35/37]: Training Loss: 2.930072837, Training Accuracy: 25.776\n",
            "Worker 3, [36/37]: Training Loss: 2.819679495, Training Accuracy: 28.504\n",
            "Worker 3, [37/37]: Training Loss: 2.735912317, Training Accuracy: 29.712\n",
            "Time taken for training worker 3: 0:03:08.826253\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.052726527, Training Accuracy: 24.680\n",
            "Worker 4, [02/37]: Training Loss: 2.981966615, Training Accuracy: 26.208\n",
            "Worker 4, [03/37]: Training Loss: 2.864118302, Training Accuracy: 28.992\n",
            "Worker 4, [04/37]: Training Loss: 2.793048586, Training Accuracy: 29.984\n",
            "Worker 4, [05/37]: Training Loss: 2.735306319, Training Accuracy: 31.408\n",
            "Worker 4, [06/37]: Training Loss: 2.687450386, Training Accuracy: 32.168\n",
            "Worker 4, [07/37]: Training Loss: 2.635336934, Training Accuracy: 33.000\n",
            "Worker 4, [08/37]: Training Loss: 2.605831400, Training Accuracy: 33.352\n",
            "Worker 4, [09/37]: Training Loss: 3.960786295, Training Accuracy: 13.736\n",
            "Worker 4, [10/37]: Training Loss: 3.519014670, Training Accuracy: 16.424\n",
            "Worker 4, [11/37]: Training Loss: 3.349520429, Training Accuracy: 19.520\n",
            "Worker 4, [12/37]: Training Loss: 3.229477831, Training Accuracy: 20.952\n",
            "Worker 4, [13/37]: Training Loss: 3.146519817, Training Accuracy: 22.432\n",
            "Worker 4, [14/37]: Training Loss: 3.065081714, Training Accuracy: 23.952\n",
            "Worker 4, [15/37]: Training Loss: 3.016314078, Training Accuracy: 25.432\n",
            "Worker 4, [16/37]: Training Loss: 2.961471790, Training Accuracy: 26.368\n",
            "Worker 4, [17/37]: Training Loss: 3.591223119, Training Accuracy: 16.112\n",
            "Worker 4, [18/37]: Training Loss: 3.251712973, Training Accuracy: 20.448\n",
            "Worker 4, [19/37]: Training Loss: 3.124993488, Training Accuracy: 22.504\n",
            "Worker 4, [20/37]: Training Loss: 3.020607682, Training Accuracy: 24.296\n",
            "Worker 4, [21/37]: Training Loss: 2.946895352, Training Accuracy: 25.696\n",
            "Worker 4, [22/37]: Training Loss: 2.874317613, Training Accuracy: 27.304\n",
            "Worker 4, [23/37]: Training Loss: 2.815762090, Training Accuracy: 28.296\n",
            "Worker 4, [24/37]: Training Loss: 2.739289193, Training Accuracy: 29.968\n",
            "Worker 4, [25/37]: Training Loss: 3.471338272, Training Accuracy: 16.792\n",
            "Worker 4, [26/37]: Training Loss: 3.150033075, Training Accuracy: 21.976\n",
            "Worker 4, [27/37]: Training Loss: 3.017739611, Training Accuracy: 24.224\n",
            "Worker 4, [28/37]: Training Loss: 2.918806430, Training Accuracy: 26.256\n",
            "Worker 4, [29/37]: Training Loss: 2.842332122, Training Accuracy: 27.784\n",
            "Worker 4, [30/37]: Training Loss: 2.774886873, Training Accuracy: 29.216\n",
            "Worker 4, [31/37]: Training Loss: 2.682560972, Training Accuracy: 30.880\n",
            "Worker 4, [32/37]: Training Loss: 2.623886596, Training Accuracy: 31.824\n",
            "Worker 4, [33/37]: Training Loss: 3.349088631, Training Accuracy: 18.960\n",
            "Worker 4, [34/37]: Training Loss: 3.072937141, Training Accuracy: 22.936\n",
            "Worker 4, [35/37]: Training Loss: 2.915898958, Training Accuracy: 26.104\n",
            "Worker 4, [36/37]: Training Loss: 2.828742157, Training Accuracy: 27.960\n",
            "Worker 4, [37/37]: Training Loss: 2.748545462, Training Accuracy: 29.768\n",
            "Time taken for training worker 4: 0:03:09.697882\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000675\n",
            "Local Step 02: Test Loss: 2.838604216, Test Accuracy: 28.590\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.934847615, Training Accuracy: 27.352\n",
            "Worker 1, [02/37]: Training Loss: 2.788926575, Training Accuracy: 30.008\n",
            "Worker 1, [03/37]: Training Loss: 2.678486698, Training Accuracy: 31.720\n",
            "Worker 1, [04/37]: Training Loss: 2.614332667, Training Accuracy: 32.568\n",
            "Worker 1, [05/37]: Training Loss: 2.531482960, Training Accuracy: 34.688\n",
            "Worker 1, [06/37]: Training Loss: 2.435050856, Training Accuracy: 36.408\n",
            "Worker 1, [07/37]: Training Loss: 2.386703622, Training Accuracy: 37.424\n",
            "Worker 1, [08/37]: Training Loss: 2.303803079, Training Accuracy: 38.928\n",
            "Worker 1, [09/37]: Training Loss: 3.362182572, Training Accuracy: 19.360\n",
            "Worker 1, [10/37]: Training Loss: 3.085422532, Training Accuracy: 23.760\n",
            "Worker 1, [11/37]: Training Loss: 2.914739901, Training Accuracy: 27.112\n",
            "Worker 1, [12/37]: Training Loss: 2.771036293, Training Accuracy: 29.712\n",
            "Worker 1, [13/37]: Training Loss: 2.677041448, Training Accuracy: 31.592\n",
            "Worker 1, [14/37]: Training Loss: 2.598640167, Training Accuracy: 32.504\n",
            "Worker 1, [15/37]: Training Loss: 2.495984453, Training Accuracy: 35.208\n",
            "Worker 1, [16/37]: Training Loss: 2.426288548, Training Accuracy: 36.576\n",
            "Worker 1, [17/37]: Training Loss: 3.193372116, Training Accuracy: 22.544\n",
            "Worker 1, [18/37]: Training Loss: 2.883147122, Training Accuracy: 28.032\n",
            "Worker 1, [19/37]: Training Loss: 2.721372827, Training Accuracy: 30.656\n",
            "Worker 1, [20/37]: Training Loss: 2.623007538, Training Accuracy: 32.800\n",
            "Worker 1, [21/37]: Training Loss: 2.523575972, Training Accuracy: 34.736\n",
            "Worker 1, [22/37]: Training Loss: 2.426765444, Training Accuracy: 37.016\n",
            "Worker 1, [23/37]: Training Loss: 2.362803612, Training Accuracy: 38.136\n",
            "Worker 1, [24/37]: Training Loss: 2.283368643, Training Accuracy: 39.400\n",
            "Worker 1, [25/37]: Training Loss: 3.017371382, Training Accuracy: 26.664\n",
            "Worker 1, [26/37]: Training Loss: 2.750342758, Training Accuracy: 30.352\n",
            "Worker 1, [27/37]: Training Loss: 2.633966030, Training Accuracy: 32.616\n",
            "Worker 1, [28/37]: Training Loss: 2.530254291, Training Accuracy: 34.784\n",
            "Worker 1, [29/37]: Training Loss: 2.458766374, Training Accuracy: 36.880\n",
            "Worker 1, [30/37]: Training Loss: 2.397681197, Training Accuracy: 37.944\n",
            "Worker 1, [31/37]: Training Loss: 2.347797377, Training Accuracy: 39.032\n",
            "Worker 1, [32/37]: Training Loss: 2.304379845, Training Accuracy: 40.032\n",
            "Worker 1, [33/37]: Training Loss: 3.096864278, Training Accuracy: 30.032\n",
            "Worker 1, [34/37]: Training Loss: 2.807577803, Training Accuracy: 30.488\n",
            "Worker 1, [35/37]: Training Loss: 2.753978232, Training Accuracy: 31.288\n",
            "Worker 1, [36/37]: Training Loss: 2.713995964, Training Accuracy: 32.000\n",
            "Worker 1, [37/37]: Training Loss: 2.701986077, Training Accuracy: 32.760\n",
            "Time taken for training worker 1: 0:03:07.763827\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.200048899, Training Accuracy: 21.432\n",
            "Worker 2, [02/37]: Training Loss: 2.967954470, Training Accuracy: 25.736\n",
            "Worker 2, [03/37]: Training Loss: 2.866589058, Training Accuracy: 27.976\n",
            "Worker 2, [04/37]: Training Loss: 2.765306829, Training Accuracy: 29.528\n",
            "Worker 2, [05/37]: Training Loss: 2.647904787, Training Accuracy: 31.664\n",
            "Worker 2, [06/37]: Training Loss: 2.586439210, Training Accuracy: 33.064\n",
            "Worker 2, [07/37]: Training Loss: 2.545432490, Training Accuracy: 33.904\n",
            "Worker 2, [08/37]: Training Loss: 2.449201604, Training Accuracy: 35.616\n",
            "Worker 2, [09/37]: Training Loss: 3.229544812, Training Accuracy: 20.776\n",
            "Worker 2, [10/37]: Training Loss: 2.939940537, Training Accuracy: 26.016\n",
            "Worker 2, [11/37]: Training Loss: 2.819168172, Training Accuracy: 28.584\n",
            "Worker 2, [12/37]: Training Loss: 2.700222122, Training Accuracy: 30.960\n",
            "Worker 2, [13/37]: Training Loss: 2.601459083, Training Accuracy: 32.744\n",
            "Worker 2, [14/37]: Training Loss: 2.512604088, Training Accuracy: 34.000\n",
            "Worker 2, [15/37]: Training Loss: 2.412837975, Training Accuracy: 35.688\n",
            "Worker 2, [16/37]: Training Loss: 2.349386898, Training Accuracy: 38.024\n",
            "Worker 2, [17/37]: Training Loss: 3.080413253, Training Accuracy: 24.648\n",
            "Worker 2, [18/37]: Training Loss: 2.786344635, Training Accuracy: 28.888\n",
            "Worker 2, [19/37]: Training Loss: 2.648338735, Training Accuracy: 31.248\n",
            "Worker 2, [20/37]: Training Loss: 2.523795280, Training Accuracy: 33.888\n",
            "Worker 2, [21/37]: Training Loss: 2.458623029, Training Accuracy: 35.224\n",
            "Worker 2, [22/37]: Training Loss: 2.380149508, Training Accuracy: 37.656\n",
            "Worker 2, [23/37]: Training Loss: 2.280145531, Training Accuracy: 39.616\n",
            "Worker 2, [24/37]: Training Loss: 2.200682844, Training Accuracy: 41.320\n",
            "Worker 2, [25/37]: Training Loss: 2.892476669, Training Accuracy: 28.656\n",
            "Worker 2, [26/37]: Training Loss: 2.647731942, Training Accuracy: 32.072\n",
            "Worker 2, [27/37]: Training Loss: 2.539616962, Training Accuracy: 34.392\n",
            "Worker 2, [28/37]: Training Loss: 2.435988375, Training Accuracy: 36.528\n",
            "Worker 2, [29/37]: Training Loss: 2.371343588, Training Accuracy: 38.096\n",
            "Worker 2, [30/37]: Training Loss: 2.309087799, Training Accuracy: 39.696\n",
            "Worker 2, [31/37]: Training Loss: 2.247814860, Training Accuracy: 40.664\n",
            "Worker 2, [32/37]: Training Loss: 2.205380349, Training Accuracy: 41.664\n",
            "Worker 2, [33/37]: Training Loss: 2.965293452, Training Accuracy: 32.480\n",
            "Worker 2, [34/37]: Training Loss: 2.671057115, Training Accuracy: 33.280\n",
            "Worker 2, [35/37]: Training Loss: 2.607765081, Training Accuracy: 34.008\n",
            "Worker 2, [36/37]: Training Loss: 2.579910899, Training Accuracy: 34.520\n",
            "Worker 2, [37/37]: Training Loss: 2.567534796, Training Accuracy: 34.808\n",
            "Time taken for training worker 2: 0:03:07.070206\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.114028978, Training Accuracy: 22.888\n",
            "Worker 3, [02/37]: Training Loss: 2.940921330, Training Accuracy: 26.488\n",
            "Worker 3, [03/37]: Training Loss: 2.811230803, Training Accuracy: 28.672\n",
            "Worker 3, [04/37]: Training Loss: 2.708273539, Training Accuracy: 30.384\n",
            "Worker 3, [05/37]: Training Loss: 2.614772829, Training Accuracy: 32.216\n",
            "Worker 3, [06/37]: Training Loss: 2.554011929, Training Accuracy: 33.624\n",
            "Worker 3, [07/37]: Training Loss: 2.437020007, Training Accuracy: 35.664\n",
            "Worker 3, [08/37]: Training Loss: 2.397538913, Training Accuracy: 36.752\n",
            "Worker 3, [09/37]: Training Loss: 3.216990866, Training Accuracy: 21.264\n",
            "Worker 3, [10/37]: Training Loss: 2.938306340, Training Accuracy: 25.952\n",
            "Worker 3, [11/37]: Training Loss: 2.801509279, Training Accuracy: 28.488\n",
            "Worker 3, [12/37]: Training Loss: 2.681601333, Training Accuracy: 30.120\n",
            "Worker 3, [13/37]: Training Loss: 2.554770595, Training Accuracy: 33.176\n",
            "Worker 3, [14/37]: Training Loss: 2.513827602, Training Accuracy: 34.688\n",
            "Worker 3, [15/37]: Training Loss: 2.414217561, Training Accuracy: 36.024\n",
            "Worker 3, [16/37]: Training Loss: 2.325326719, Training Accuracy: 38.344\n",
            "Worker 3, [17/37]: Training Loss: 3.051360510, Training Accuracy: 24.840\n",
            "Worker 3, [18/37]: Training Loss: 2.768628201, Training Accuracy: 29.472\n",
            "Worker 3, [19/37]: Training Loss: 2.651788873, Training Accuracy: 31.256\n",
            "Worker 3, [20/37]: Training Loss: 2.523470570, Training Accuracy: 34.176\n",
            "Worker 3, [21/37]: Training Loss: 2.438641132, Training Accuracy: 35.880\n",
            "Worker 3, [22/37]: Training Loss: 2.354276916, Training Accuracy: 37.480\n",
            "Worker 3, [23/37]: Training Loss: 2.261426380, Training Accuracy: 39.920\n",
            "Worker 3, [24/37]: Training Loss: 2.197384493, Training Accuracy: 41.096\n",
            "Worker 3, [25/37]: Training Loss: 2.901221207, Training Accuracy: 27.864\n",
            "Worker 3, [26/37]: Training Loss: 2.624483796, Training Accuracy: 33.088\n",
            "Worker 3, [27/37]: Training Loss: 2.503372482, Training Accuracy: 34.960\n",
            "Worker 3, [28/37]: Training Loss: 2.425800159, Training Accuracy: 36.656\n",
            "Worker 3, [29/37]: Training Loss: 2.354900910, Training Accuracy: 38.056\n",
            "Worker 3, [30/37]: Training Loss: 2.289684945, Training Accuracy: 39.392\n",
            "Worker 3, [31/37]: Training Loss: 2.219633414, Training Accuracy: 41.232\n",
            "Worker 3, [32/37]: Training Loss: 2.194459037, Training Accuracy: 41.912\n",
            "Worker 3, [33/37]: Training Loss: 2.962580879, Training Accuracy: 31.408\n",
            "Worker 3, [34/37]: Training Loss: 2.674581804, Training Accuracy: 33.080\n",
            "Worker 3, [35/37]: Training Loss: 2.600735507, Training Accuracy: 34.688\n",
            "Worker 3, [36/37]: Training Loss: 2.576388497, Training Accuracy: 34.624\n",
            "Worker 3, [37/37]: Training Loss: 2.562773849, Training Accuracy: 34.864\n",
            "Time taken for training worker 3: 0:03:07.962088\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.139143331, Training Accuracy: 22.616\n",
            "Worker 4, [02/37]: Training Loss: 2.937150002, Training Accuracy: 26.752\n",
            "Worker 4, [03/37]: Training Loss: 2.803537636, Training Accuracy: 29.064\n",
            "Worker 4, [04/37]: Training Loss: 2.710968117, Training Accuracy: 30.528\n",
            "Worker 4, [05/37]: Training Loss: 2.623109549, Training Accuracy: 32.256\n",
            "Worker 4, [06/37]: Training Loss: 2.548980971, Training Accuracy: 33.416\n",
            "Worker 4, [07/37]: Training Loss: 2.451198189, Training Accuracy: 35.472\n",
            "Worker 4, [08/37]: Training Loss: 2.384952632, Training Accuracy: 37.032\n",
            "Worker 4, [09/37]: Training Loss: 3.231896752, Training Accuracy: 20.944\n",
            "Worker 4, [10/37]: Training Loss: 2.952507285, Training Accuracy: 25.472\n",
            "Worker 4, [11/37]: Training Loss: 2.798847279, Training Accuracy: 28.584\n",
            "Worker 4, [12/37]: Training Loss: 2.692402504, Training Accuracy: 30.280\n",
            "Worker 4, [13/37]: Training Loss: 2.607624458, Training Accuracy: 32.760\n",
            "Worker 4, [14/37]: Training Loss: 2.501982283, Training Accuracy: 34.392\n",
            "Worker 4, [15/37]: Training Loss: 2.404464601, Training Accuracy: 36.640\n",
            "Worker 4, [16/37]: Training Loss: 2.325542740, Training Accuracy: 38.944\n",
            "Worker 4, [17/37]: Training Loss: 3.052964013, Training Accuracy: 25.056\n",
            "Worker 4, [18/37]: Training Loss: 2.795093193, Training Accuracy: 28.984\n",
            "Worker 4, [19/37]: Training Loss: 2.637722771, Training Accuracy: 31.240\n",
            "Worker 4, [20/37]: Training Loss: 2.525693516, Training Accuracy: 34.640\n",
            "Worker 4, [21/37]: Training Loss: 2.450016898, Training Accuracy: 35.488\n",
            "Worker 4, [22/37]: Training Loss: 2.358540054, Training Accuracy: 37.312\n",
            "Worker 4, [23/37]: Training Loss: 2.268069894, Training Accuracy: 40.040\n",
            "Worker 4, [24/37]: Training Loss: 2.207208177, Training Accuracy: 41.200\n",
            "Worker 4, [25/37]: Training Loss: 2.888814273, Training Accuracy: 28.704\n",
            "Worker 4, [26/37]: Training Loss: 2.632380627, Training Accuracy: 32.472\n",
            "Worker 4, [27/37]: Training Loss: 2.508622926, Training Accuracy: 35.384\n",
            "Worker 4, [28/37]: Training Loss: 2.430171709, Training Accuracy: 37.224\n",
            "Worker 4, [29/37]: Training Loss: 2.344731253, Training Accuracy: 38.880\n",
            "Worker 4, [30/37]: Training Loss: 2.298712911, Training Accuracy: 39.472\n",
            "Worker 4, [31/37]: Training Loss: 2.231677378, Training Accuracy: 41.192\n",
            "Worker 4, [32/37]: Training Loss: 2.186204729, Training Accuracy: 42.136\n",
            "Worker 4, [33/37]: Training Loss: 2.959233398, Training Accuracy: 31.768\n",
            "Worker 4, [34/37]: Training Loss: 2.666682708, Training Accuracy: 32.648\n",
            "Worker 4, [35/37]: Training Loss: 2.616759333, Training Accuracy: 33.544\n",
            "Worker 4, [36/37]: Training Loss: 2.585468194, Training Accuracy: 34.264\n",
            "Worker 4, [37/37]: Training Loss: 2.562582453, Training Accuracy: 34.912\n",
            "Time taken for training worker 4: 0:03:04.171113\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000603\n",
            "Local Step 03: Test Loss: 2.660502993, Test Accuracy: 33.410\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 2.808645478, Training Accuracy: 30.216\n",
            "Worker 1, [02/37]: Training Loss: 2.810886331, Training Accuracy: 30.136\n",
            "Worker 1, [03/37]: Training Loss: 2.805987832, Training Accuracy: 30.768\n",
            "Worker 1, [04/37]: Training Loss: 2.785897985, Training Accuracy: 30.832\n",
            "Worker 1, [05/37]: Training Loss: 2.754182655, Training Accuracy: 31.600\n",
            "Worker 1, [06/37]: Training Loss: 2.736972774, Training Accuracy: 31.600\n",
            "Worker 1, [07/37]: Training Loss: 2.705300799, Training Accuracy: 32.160\n",
            "Worker 1, [08/37]: Training Loss: 2.670135189, Training Accuracy: 32.688\n",
            "Worker 1, [09/37]: Training Loss: 2.931463024, Training Accuracy: 29.432\n",
            "Worker 1, [10/37]: Training Loss: 2.727532134, Training Accuracy: 31.072\n",
            "Worker 1, [11/37]: Training Loss: 2.652313349, Training Accuracy: 32.272\n",
            "Worker 1, [12/37]: Training Loss: 2.603423480, Training Accuracy: 33.600\n",
            "Worker 1, [13/37]: Training Loss: 2.560045844, Training Accuracy: 34.664\n",
            "Worker 1, [14/37]: Training Loss: 2.526759811, Training Accuracy: 35.120\n",
            "Worker 1, [15/37]: Training Loss: 2.489557002, Training Accuracy: 35.888\n",
            "Worker 1, [16/37]: Training Loss: 2.459394112, Training Accuracy: 35.704\n",
            "Worker 1, [17/37]: Training Loss: 2.881328956, Training Accuracy: 28.360\n",
            "Worker 1, [18/37]: Training Loss: 2.709301716, Training Accuracy: 30.888\n",
            "Worker 1, [19/37]: Training Loss: 2.630256206, Training Accuracy: 32.744\n",
            "Worker 1, [20/37]: Training Loss: 2.573962577, Training Accuracy: 33.120\n",
            "Worker 1, [21/37]: Training Loss: 2.504850686, Training Accuracy: 34.928\n",
            "Worker 1, [22/37]: Training Loss: 2.493020015, Training Accuracy: 35.264\n",
            "Worker 1, [23/37]: Training Loss: 2.434644248, Training Accuracy: 36.312\n",
            "Worker 1, [24/37]: Training Loss: 2.388000906, Training Accuracy: 37.304\n",
            "Worker 1, [25/37]: Training Loss: 2.889712228, Training Accuracy: 28.144\n",
            "Worker 1, [26/37]: Training Loss: 2.730705311, Training Accuracy: 30.520\n",
            "Worker 1, [27/37]: Training Loss: 2.662250381, Training Accuracy: 31.536\n",
            "Worker 1, [28/37]: Training Loss: 2.574418039, Training Accuracy: 33.928\n",
            "Worker 1, [29/37]: Training Loss: 2.517456374, Training Accuracy: 34.976\n",
            "Worker 1, [30/37]: Training Loss: 2.435072286, Training Accuracy: 36.512\n",
            "Worker 1, [31/37]: Training Loss: 2.393883162, Training Accuracy: 37.144\n",
            "Worker 1, [32/37]: Training Loss: 2.377249012, Training Accuracy: 37.144\n",
            "Worker 1, [33/37]: Training Loss: 2.877887058, Training Accuracy: 27.832\n",
            "Worker 1, [34/37]: Training Loss: 2.720438406, Training Accuracy: 30.624\n",
            "Worker 1, [35/37]: Training Loss: 2.600223758, Training Accuracy: 32.448\n",
            "Worker 1, [36/37]: Training Loss: 2.548459729, Training Accuracy: 34.136\n",
            "Worker 1, [37/37]: Training Loss: 2.472239419, Training Accuracy: 35.488\n",
            "Time taken for training worker 1: 0:03:06.216537\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 2.928311838, Training Accuracy: 28.952\n",
            "Worker 2, [02/37]: Training Loss: 2.861167674, Training Accuracy: 29.768\n",
            "Worker 2, [03/37]: Training Loss: 2.746295964, Training Accuracy: 31.176\n",
            "Worker 2, [04/37]: Training Loss: 2.667332386, Training Accuracy: 33.152\n",
            "Worker 2, [05/37]: Training Loss: 2.622182106, Training Accuracy: 33.752\n",
            "Worker 2, [06/37]: Training Loss: 2.561514973, Training Accuracy: 35.040\n",
            "Worker 2, [07/37]: Training Loss: 2.509326055, Training Accuracy: 36.160\n",
            "Worker 2, [08/37]: Training Loss: 2.465986804, Training Accuracy: 36.872\n",
            "Worker 2, [09/37]: Training Loss: 2.773765760, Training Accuracy: 32.248\n",
            "Worker 2, [10/37]: Training Loss: 2.559086213, Training Accuracy: 34.368\n",
            "Worker 2, [11/37]: Training Loss: 2.510141347, Training Accuracy: 35.056\n",
            "Worker 2, [12/37]: Training Loss: 2.471544842, Training Accuracy: 35.656\n",
            "Worker 2, [13/37]: Training Loss: 2.442474363, Training Accuracy: 36.112\n",
            "Worker 2, [14/37]: Training Loss: 2.394532474, Training Accuracy: 36.888\n",
            "Worker 2, [15/37]: Training Loss: 2.384934832, Training Accuracy: 37.536\n",
            "Worker 2, [16/37]: Training Loss: 2.358565566, Training Accuracy: 37.880\n",
            "Worker 2, [17/37]: Training Loss: 2.721924570, Training Accuracy: 31.424\n",
            "Worker 2, [18/37]: Training Loss: 2.583181117, Training Accuracy: 33.216\n",
            "Worker 2, [19/37]: Training Loss: 2.531218908, Training Accuracy: 33.992\n",
            "Worker 2, [20/37]: Training Loss: 2.455726950, Training Accuracy: 35.592\n",
            "Worker 2, [21/37]: Training Loss: 2.420125430, Training Accuracy: 36.328\n",
            "Worker 2, [22/37]: Training Loss: 2.390789216, Training Accuracy: 37.192\n",
            "Worker 2, [23/37]: Training Loss: 2.347790344, Training Accuracy: 37.344\n",
            "Worker 2, [24/37]: Training Loss: 2.325307993, Training Accuracy: 38.528\n",
            "Worker 2, [25/37]: Training Loss: 2.785607553, Training Accuracy: 29.112\n",
            "Worker 2, [26/37]: Training Loss: 2.629642550, Training Accuracy: 31.632\n",
            "Worker 2, [27/37]: Training Loss: 2.561806676, Training Accuracy: 33.496\n",
            "Worker 2, [28/37]: Training Loss: 2.497363552, Training Accuracy: 34.920\n",
            "Worker 2, [29/37]: Training Loss: 2.428610130, Training Accuracy: 36.344\n",
            "Worker 2, [30/37]: Training Loss: 2.379262919, Training Accuracy: 37.128\n",
            "Worker 2, [31/37]: Training Loss: 2.323958259, Training Accuracy: 38.264\n",
            "Worker 2, [32/37]: Training Loss: 2.312182796, Training Accuracy: 38.248\n",
            "Worker 2, [33/37]: Training Loss: 2.768413201, Training Accuracy: 29.840\n",
            "Worker 2, [34/37]: Training Loss: 2.640277641, Training Accuracy: 31.664\n",
            "Worker 2, [35/37]: Training Loss: 2.555382010, Training Accuracy: 33.568\n",
            "Worker 2, [36/37]: Training Loss: 2.462616354, Training Accuracy: 35.544\n",
            "Worker 2, [37/37]: Training Loss: 2.419408130, Training Accuracy: 36.576\n",
            "Time taken for training worker 2: 0:03:06.381525\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 2.893520195, Training Accuracy: 28.992\n",
            "Worker 3, [02/37]: Training Loss: 2.839724846, Training Accuracy: 30.400\n",
            "Worker 3, [03/37]: Training Loss: 2.737948431, Training Accuracy: 31.824\n",
            "Worker 3, [04/37]: Training Loss: 2.637729747, Training Accuracy: 33.720\n",
            "Worker 3, [05/37]: Training Loss: 2.565543300, Training Accuracy: 35.064\n",
            "Worker 3, [06/37]: Training Loss: 2.512653420, Training Accuracy: 36.088\n",
            "Worker 3, [07/37]: Training Loss: 2.462759212, Training Accuracy: 37.080\n",
            "Worker 3, [08/37]: Training Loss: 2.431409807, Training Accuracy: 37.296\n",
            "Worker 3, [09/37]: Training Loss: 2.753681028, Training Accuracy: 32.936\n",
            "Worker 3, [10/37]: Training Loss: 2.557139313, Training Accuracy: 34.072\n",
            "Worker 3, [11/37]: Training Loss: 2.485171455, Training Accuracy: 35.560\n",
            "Worker 3, [12/37]: Training Loss: 2.442060545, Training Accuracy: 36.488\n",
            "Worker 3, [13/37]: Training Loss: 2.410019745, Training Accuracy: 36.952\n",
            "Worker 3, [14/37]: Training Loss: 2.384467828, Training Accuracy: 37.208\n",
            "Worker 3, [15/37]: Training Loss: 2.358537912, Training Accuracy: 37.904\n",
            "Worker 3, [16/37]: Training Loss: 2.321424905, Training Accuracy: 39.160\n",
            "Worker 3, [17/37]: Training Loss: 2.713247098, Training Accuracy: 31.080\n",
            "Worker 3, [18/37]: Training Loss: 2.559021596, Training Accuracy: 33.896\n",
            "Worker 3, [19/37]: Training Loss: 2.490717094, Training Accuracy: 34.368\n",
            "Worker 3, [20/37]: Training Loss: 2.461963774, Training Accuracy: 35.136\n",
            "Worker 3, [21/37]: Training Loss: 2.407824027, Training Accuracy: 36.448\n",
            "Worker 3, [22/37]: Training Loss: 2.363981817, Training Accuracy: 37.696\n",
            "Worker 3, [23/37]: Training Loss: 2.331551771, Training Accuracy: 38.440\n",
            "Worker 3, [24/37]: Training Loss: 2.295212381, Training Accuracy: 38.744\n",
            "Worker 3, [25/37]: Training Loss: 2.751274014, Training Accuracy: 29.688\n",
            "Worker 3, [26/37]: Training Loss: 2.607934626, Training Accuracy: 32.232\n",
            "Worker 3, [27/37]: Training Loss: 2.541467857, Training Accuracy: 33.520\n",
            "Worker 3, [28/37]: Training Loss: 2.475036094, Training Accuracy: 34.488\n",
            "Worker 3, [29/37]: Training Loss: 2.413046446, Training Accuracy: 36.168\n",
            "Worker 3, [30/37]: Training Loss: 2.346949000, Training Accuracy: 38.144\n",
            "Worker 3, [31/37]: Training Loss: 2.305763839, Training Accuracy: 38.160\n",
            "Worker 3, [32/37]: Training Loss: 2.283439294, Training Accuracy: 38.720\n",
            "Worker 3, [33/37]: Training Loss: 2.743583938, Training Accuracy: 29.792\n",
            "Worker 3, [34/37]: Training Loss: 2.613092755, Training Accuracy: 32.312\n",
            "Worker 3, [35/37]: Training Loss: 2.538906105, Training Accuracy: 33.584\n",
            "Worker 3, [36/37]: Training Loss: 2.462202838, Training Accuracy: 35.720\n",
            "Worker 3, [37/37]: Training Loss: 2.388554516, Training Accuracy: 36.656\n",
            "Time taken for training worker 3: 0:03:05.170656\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 2.858814523, Training Accuracy: 30.000\n",
            "Worker 4, [02/37]: Training Loss: 2.794293474, Training Accuracy: 30.712\n",
            "Worker 4, [03/37]: Training Loss: 2.682081285, Training Accuracy: 32.648\n",
            "Worker 4, [04/37]: Training Loss: 2.629881533, Training Accuracy: 34.256\n",
            "Worker 4, [05/37]: Training Loss: 2.571955385, Training Accuracy: 35.128\n",
            "Worker 4, [06/37]: Training Loss: 2.512870749, Training Accuracy: 35.896\n",
            "Worker 4, [07/37]: Training Loss: 2.462774014, Training Accuracy: 36.960\n",
            "Worker 4, [08/37]: Training Loss: 2.433242182, Training Accuracy: 37.832\n",
            "Worker 4, [09/37]: Training Loss: 2.764071424, Training Accuracy: 32.416\n",
            "Worker 4, [10/37]: Training Loss: 2.552585756, Training Accuracy: 34.416\n",
            "Worker 4, [11/37]: Training Loss: 2.491196421, Training Accuracy: 35.304\n",
            "Worker 4, [12/37]: Training Loss: 2.461881435, Training Accuracy: 35.912\n",
            "Worker 4, [13/37]: Training Loss: 2.410443512, Training Accuracy: 36.592\n",
            "Worker 4, [14/37]: Training Loss: 2.400413746, Training Accuracy: 36.944\n",
            "Worker 4, [15/37]: Training Loss: 2.358422899, Training Accuracy: 37.640\n",
            "Worker 4, [16/37]: Training Loss: 2.359775909, Training Accuracy: 37.912\n",
            "Worker 4, [17/37]: Training Loss: 2.707724756, Training Accuracy: 30.760\n",
            "Worker 4, [18/37]: Training Loss: 2.567275465, Training Accuracy: 33.504\n",
            "Worker 4, [19/37]: Training Loss: 2.510442022, Training Accuracy: 34.896\n",
            "Worker 4, [20/37]: Training Loss: 2.449484071, Training Accuracy: 35.800\n",
            "Worker 4, [21/37]: Training Loss: 2.420512856, Training Accuracy: 36.104\n",
            "Worker 4, [22/37]: Training Loss: 2.389313095, Training Accuracy: 36.752\n",
            "Worker 4, [23/37]: Training Loss: 2.342796596, Training Accuracy: 37.792\n",
            "Worker 4, [24/37]: Training Loss: 2.287429954, Training Accuracy: 39.168\n",
            "Worker 4, [25/37]: Training Loss: 2.751687598, Training Accuracy: 29.552\n",
            "Worker 4, [26/37]: Training Loss: 2.634520831, Training Accuracy: 31.720\n",
            "Worker 4, [27/37]: Training Loss: 2.533277139, Training Accuracy: 33.688\n",
            "Worker 4, [28/37]: Training Loss: 2.479970483, Training Accuracy: 34.848\n",
            "Worker 4, [29/37]: Training Loss: 2.426694068, Training Accuracy: 36.016\n",
            "Worker 4, [30/37]: Training Loss: 2.342306293, Training Accuracy: 38.136\n",
            "Worker 4, [31/37]: Training Loss: 2.312983724, Training Accuracy: 38.600\n",
            "Worker 4, [32/37]: Training Loss: 2.267815766, Training Accuracy: 39.864\n",
            "Worker 4, [33/37]: Training Loss: 2.753198845, Training Accuracy: 29.744\n",
            "Worker 4, [34/37]: Training Loss: 2.630781706, Training Accuracy: 31.832\n",
            "Worker 4, [35/37]: Training Loss: 2.534647915, Training Accuracy: 34.000\n",
            "Worker 4, [36/37]: Training Loss: 2.449209918, Training Accuracy: 36.304\n",
            "Worker 4, [37/37]: Training Loss: 2.399736381, Training Accuracy: 36.888\n",
            "Time taken for training worker 4: 0:03:05.713418\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000635\n",
            "Local Step 04: Test Loss: 2.684173177, Test Accuracy: 32.760\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:49:59.067784\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.529043587, Training Accuracy: 2.248\n",
            "Worker 1, [02/18]: Training Loss: 4.139002616, Training Accuracy: 6.496\n",
            "Worker 1, [03/18]: Training Loss: 4.370723419, Training Accuracy: 3.832\n",
            "Worker 1, [04/18]: Training Loss: 4.002282049, Training Accuracy: 8.232\n",
            "Worker 1, [05/18]: Training Loss: 4.273648181, Training Accuracy: 5.152\n",
            "Worker 1, [06/18]: Training Loss: 3.916464664, Training Accuracy: 9.592\n",
            "Worker 1, [07/18]: Training Loss: 4.160328134, Training Accuracy: 6.728\n",
            "Worker 1, [08/18]: Training Loss: 3.849205674, Training Accuracy: 11.088\n",
            "Worker 1, [09/18]: Training Loss: 4.105587572, Training Accuracy: 7.696\n",
            "Worker 1, [10/18]: Training Loss: 3.812319928, Training Accuracy: 11.368\n",
            "Worker 1, [11/18]: Training Loss: 4.058071748, Training Accuracy: 8.256\n",
            "Worker 1, [12/18]: Training Loss: 3.778260270, Training Accuracy: 11.968\n",
            "Worker 1, [13/18]: Training Loss: 4.010220497, Training Accuracy: 9.328\n",
            "Worker 1, [14/18]: Training Loss: 3.768566354, Training Accuracy: 12.376\n",
            "Worker 1, [15/18]: Training Loss: 4.034212537, Training Accuracy: 10.096\n",
            "Worker 1, [16/18]: Training Loss: 3.811357897, Training Accuracy: 12.120\n",
            "Worker 1, [17/18]: Training Loss: 4.152205972, Training Accuracy: 11.008\n",
            "Worker 1, [18/18]: Training Loss: 3.981095276, Training Accuracy: 10.960\n",
            "Time taken for training worker 1: 0:01:31.765770\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.525851963, Training Accuracy: 2.344\n",
            "Worker 2, [02/18]: Training Loss: 4.150909915, Training Accuracy: 6.288\n",
            "Worker 2, [03/18]: Training Loss: 4.351548545, Training Accuracy: 4.224\n",
            "Worker 2, [04/18]: Training Loss: 3.996717861, Training Accuracy: 8.680\n",
            "Worker 2, [05/18]: Training Loss: 4.272755628, Training Accuracy: 5.264\n",
            "Worker 2, [06/18]: Training Loss: 3.918253556, Training Accuracy: 9.584\n",
            "Worker 2, [07/18]: Training Loss: 4.175595299, Training Accuracy: 6.424\n",
            "Worker 2, [08/18]: Training Loss: 3.850301174, Training Accuracy: 10.784\n",
            "Worker 2, [09/18]: Training Loss: 4.097119491, Training Accuracy: 7.368\n",
            "Worker 2, [10/18]: Training Loss: 3.815856339, Training Accuracy: 10.976\n",
            "Worker 2, [11/18]: Training Loss: 4.026373547, Training Accuracy: 8.864\n",
            "Worker 2, [12/18]: Training Loss: 3.769385457, Training Accuracy: 12.072\n",
            "Worker 2, [13/18]: Training Loss: 4.005733416, Training Accuracy: 9.872\n",
            "Worker 2, [14/18]: Training Loss: 3.779083218, Training Accuracy: 12.208\n",
            "Worker 2, [15/18]: Training Loss: 4.030719700, Training Accuracy: 10.256\n",
            "Worker 2, [16/18]: Training Loss: 3.810206734, Training Accuracy: 12.040\n",
            "Worker 2, [17/18]: Training Loss: 4.153845221, Training Accuracy: 11.248\n",
            "Worker 2, [18/18]: Training Loss: 3.982266774, Training Accuracy: 11.112\n",
            "Time taken for training worker 2: 0:01:29.886852\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.521173221, Training Accuracy: 2.272\n",
            "Worker 3, [02/18]: Training Loss: 4.118415906, Training Accuracy: 6.640\n",
            "Worker 3, [03/18]: Training Loss: 4.350788795, Training Accuracy: 4.160\n",
            "Worker 3, [04/18]: Training Loss: 3.978497360, Training Accuracy: 8.104\n",
            "Worker 3, [05/18]: Training Loss: 4.245594772, Training Accuracy: 5.688\n",
            "Worker 3, [06/18]: Training Loss: 3.887317445, Training Accuracy: 9.984\n",
            "Worker 3, [07/18]: Training Loss: 4.208654381, Training Accuracy: 5.584\n",
            "Worker 3, [08/18]: Training Loss: 3.851638579, Training Accuracy: 10.072\n",
            "Worker 3, [09/18]: Training Loss: 4.070169906, Training Accuracy: 8.208\n",
            "Worker 3, [10/18]: Training Loss: 3.782775577, Training Accuracy: 11.416\n",
            "Worker 3, [11/18]: Training Loss: 4.032380267, Training Accuracy: 8.904\n",
            "Worker 3, [12/18]: Training Loss: 3.764344350, Training Accuracy: 11.776\n",
            "Worker 3, [13/18]: Training Loss: 3.995687559, Training Accuracy: 9.776\n",
            "Worker 3, [14/18]: Training Loss: 3.761426803, Training Accuracy: 11.976\n",
            "Worker 3, [15/18]: Training Loss: 4.016447909, Training Accuracy: 10.144\n",
            "Worker 3, [16/18]: Training Loss: 3.794701604, Training Accuracy: 12.008\n",
            "Worker 3, [17/18]: Training Loss: 4.134189437, Training Accuracy: 11.152\n",
            "Worker 3, [18/18]: Training Loss: 3.961660360, Training Accuracy: 10.768\n",
            "Time taken for training worker 3: 0:01:31.513016\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.530626005, Training Accuracy: 2.320\n",
            "Worker 4, [02/18]: Training Loss: 4.143111377, Training Accuracy: 6.080\n",
            "Worker 4, [03/18]: Training Loss: 4.358220350, Training Accuracy: 3.792\n",
            "Worker 4, [04/18]: Training Loss: 3.993014712, Training Accuracy: 7.624\n",
            "Worker 4, [05/18]: Training Loss: 4.244975009, Training Accuracy: 5.480\n",
            "Worker 4, [06/18]: Training Loss: 3.908890943, Training Accuracy: 9.424\n",
            "Worker 4, [07/18]: Training Loss: 4.166238804, Training Accuracy: 6.304\n",
            "Worker 4, [08/18]: Training Loss: 3.849753562, Training Accuracy: 10.312\n",
            "Worker 4, [09/18]: Training Loss: 4.107018307, Training Accuracy: 6.976\n",
            "Worker 4, [10/18]: Training Loss: 3.800505742, Training Accuracy: 11.096\n",
            "Worker 4, [11/18]: Training Loss: 4.034476185, Training Accuracy: 8.376\n",
            "Worker 4, [12/18]: Training Loss: 3.782060896, Training Accuracy: 11.368\n",
            "Worker 4, [13/18]: Training Loss: 4.014065226, Training Accuracy: 9.072\n",
            "Worker 4, [14/18]: Training Loss: 3.769326704, Training Accuracy: 11.928\n",
            "Worker 4, [15/18]: Training Loss: 4.024380065, Training Accuracy: 9.648\n",
            "Worker 4, [16/18]: Training Loss: 3.810494154, Training Accuracy: 11.448\n",
            "Worker 4, [17/18]: Training Loss: 4.150662796, Training Accuracy: 10.392\n",
            "Worker 4, [18/18]: Training Loss: 3.979197318, Training Accuracy: 10.272\n",
            "Time taken for training worker 4: 0:01:34.693646\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000457\n",
            "Local Step 01: Test Loss: 4.308216593, Test Accuracy: 11.250\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.323400322, Training Accuracy: 10.496\n",
            "Worker 1, [02/18]: Training Loss: 4.287320412, Training Accuracy: 10.280\n",
            "Worker 1, [03/18]: Training Loss: 4.115860539, Training Accuracy: 10.728\n",
            "Worker 1, [04/18]: Training Loss: 3.892645550, Training Accuracy: 10.768\n",
            "Worker 1, [05/18]: Training Loss: 3.940865511, Training Accuracy: 11.112\n",
            "Worker 1, [06/18]: Training Loss: 3.793852310, Training Accuracy: 11.816\n",
            "Worker 1, [07/18]: Training Loss: 3.880200944, Training Accuracy: 11.104\n",
            "Worker 1, [08/18]: Training Loss: 3.749826183, Training Accuracy: 12.616\n",
            "Worker 1, [09/18]: Training Loss: 3.850854132, Training Accuracy: 11.448\n",
            "Worker 1, [10/18]: Training Loss: 3.702849684, Training Accuracy: 12.936\n",
            "Worker 1, [11/18]: Training Loss: 3.833589014, Training Accuracy: 11.472\n",
            "Worker 1, [12/18]: Training Loss: 3.658488570, Training Accuracy: 13.776\n",
            "Worker 1, [13/18]: Training Loss: 3.812884994, Training Accuracy: 11.408\n",
            "Worker 1, [14/18]: Training Loss: 3.628240697, Training Accuracy: 13.896\n",
            "Worker 1, [15/18]: Training Loss: 3.770592814, Training Accuracy: 11.736\n",
            "Worker 1, [16/18]: Training Loss: 3.593077931, Training Accuracy: 14.568\n",
            "Worker 1, [17/18]: Training Loss: 3.741299628, Training Accuracy: 12.440\n",
            "Worker 1, [18/18]: Training Loss: 3.561252654, Training Accuracy: 14.944\n",
            "Time taken for training worker 1: 0:01:31.710077\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.855357485, Training Accuracy: 14.544\n",
            "Worker 2, [02/18]: Training Loss: 3.800852479, Training Accuracy: 14.280\n",
            "Worker 2, [03/18]: Training Loss: 4.081403338, Training Accuracy: 11.104\n",
            "Worker 2, [04/18]: Training Loss: 3.859352129, Training Accuracy: 11.856\n",
            "Worker 2, [05/18]: Training Loss: 3.920844511, Training Accuracy: 11.104\n",
            "Worker 2, [06/18]: Training Loss: 3.773912267, Training Accuracy: 12.416\n",
            "Worker 2, [07/18]: Training Loss: 3.859947572, Training Accuracy: 10.928\n",
            "Worker 2, [08/18]: Training Loss: 3.730229092, Training Accuracy: 12.552\n",
            "Worker 2, [09/18]: Training Loss: 3.834595207, Training Accuracy: 11.112\n",
            "Worker 2, [10/18]: Training Loss: 3.694161469, Training Accuracy: 12.912\n",
            "Worker 2, [11/18]: Training Loss: 3.808659555, Training Accuracy: 11.496\n",
            "Worker 2, [12/18]: Training Loss: 3.642770886, Training Accuracy: 13.352\n",
            "Worker 2, [13/18]: Training Loss: 3.765921010, Training Accuracy: 12.168\n",
            "Worker 2, [14/18]: Training Loss: 3.612605224, Training Accuracy: 14.408\n",
            "Worker 2, [15/18]: Training Loss: 3.732189262, Training Accuracy: 12.552\n",
            "Worker 2, [16/18]: Training Loss: 3.558995826, Training Accuracy: 14.968\n",
            "Worker 2, [17/18]: Training Loss: 3.718674849, Training Accuracy: 13.032\n",
            "Worker 2, [18/18]: Training Loss: 3.531835335, Training Accuracy: 15.648\n",
            "Time taken for training worker 2: 0:01:31.242956\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.815503017, Training Accuracy: 15.088\n",
            "Worker 3, [02/18]: Training Loss: 3.758322623, Training Accuracy: 14.712\n",
            "Worker 3, [03/18]: Training Loss: 4.057078871, Training Accuracy: 11.336\n",
            "Worker 3, [04/18]: Training Loss: 3.843507913, Training Accuracy: 11.672\n",
            "Worker 3, [05/18]: Training Loss: 3.894977094, Training Accuracy: 11.256\n",
            "Worker 3, [06/18]: Training Loss: 3.758894307, Training Accuracy: 12.312\n",
            "Worker 3, [07/18]: Training Loss: 3.847207534, Training Accuracy: 11.248\n",
            "Worker 3, [08/18]: Training Loss: 3.715115719, Training Accuracy: 12.704\n",
            "Worker 3, [09/18]: Training Loss: 3.817288343, Training Accuracy: 11.480\n",
            "Worker 3, [10/18]: Training Loss: 3.682905641, Training Accuracy: 13.424\n",
            "Worker 3, [11/18]: Training Loss: 3.788395517, Training Accuracy: 11.728\n",
            "Worker 3, [12/18]: Training Loss: 3.641434094, Training Accuracy: 13.296\n",
            "Worker 3, [13/18]: Training Loss: 3.778910620, Training Accuracy: 11.616\n",
            "Worker 3, [14/18]: Training Loss: 3.598006267, Training Accuracy: 14.656\n",
            "Worker 3, [15/18]: Training Loss: 3.743617141, Training Accuracy: 12.160\n",
            "Worker 3, [16/18]: Training Loss: 3.563616374, Training Accuracy: 15.160\n",
            "Worker 3, [17/18]: Training Loss: 3.712635231, Training Accuracy: 12.216\n",
            "Worker 3, [18/18]: Training Loss: 3.530421757, Training Accuracy: 15.272\n",
            "Time taken for training worker 3: 0:01:30.592758\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.816655833, Training Accuracy: 14.576\n",
            "Worker 4, [02/18]: Training Loss: 3.767820089, Training Accuracy: 14.496\n",
            "Worker 4, [03/18]: Training Loss: 4.073816987, Training Accuracy: 10.840\n",
            "Worker 4, [04/18]: Training Loss: 3.853686958, Training Accuracy: 11.256\n",
            "Worker 4, [05/18]: Training Loss: 3.911599941, Training Accuracy: 10.736\n",
            "Worker 4, [06/18]: Training Loss: 3.762491844, Training Accuracy: 12.280\n",
            "Worker 4, [07/18]: Training Loss: 3.859995708, Training Accuracy: 10.824\n",
            "Worker 4, [08/18]: Training Loss: 3.732517149, Training Accuracy: 12.456\n",
            "Worker 4, [09/18]: Training Loss: 3.830295178, Training Accuracy: 11.016\n",
            "Worker 4, [10/18]: Training Loss: 3.677827549, Training Accuracy: 13.056\n",
            "Worker 4, [11/18]: Training Loss: 3.804301846, Training Accuracy: 10.960\n",
            "Worker 4, [12/18]: Training Loss: 3.642183388, Training Accuracy: 13.344\n",
            "Worker 4, [13/18]: Training Loss: 3.790985062, Training Accuracy: 11.576\n",
            "Worker 4, [14/18]: Training Loss: 3.595820102, Training Accuracy: 13.888\n",
            "Worker 4, [15/18]: Training Loss: 3.754533024, Training Accuracy: 11.872\n",
            "Worker 4, [16/18]: Training Loss: 3.571925608, Training Accuracy: 14.264\n",
            "Worker 4, [17/18]: Training Loss: 3.718636061, Training Accuracy: 12.736\n",
            "Worker 4, [18/18]: Training Loss: 3.533744587, Training Accuracy: 14.936\n",
            "Time taken for training worker 4: 0:01:32.076648\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000482\n",
            "Local Step 02: Test Loss: 3.753144776, Test Accuracy: 16.510\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.736501686, Training Accuracy: 12.760\n",
            "Worker 1, [02/18]: Training Loss: 3.512060748, Training Accuracy: 16.016\n",
            "Worker 1, [03/18]: Training Loss: 3.679006023, Training Accuracy: 13.400\n",
            "Worker 1, [04/18]: Training Loss: 3.489520640, Training Accuracy: 16.144\n",
            "Worker 1, [05/18]: Training Loss: 3.623458006, Training Accuracy: 14.160\n",
            "Worker 1, [06/18]: Training Loss: 3.431950797, Training Accuracy: 17.000\n",
            "Worker 1, [07/18]: Training Loss: 3.557053430, Training Accuracy: 15.416\n",
            "Worker 1, [08/18]: Training Loss: 3.398392266, Training Accuracy: 17.752\n",
            "Worker 1, [09/18]: Training Loss: 3.496500182, Training Accuracy: 16.576\n",
            "Worker 1, [10/18]: Training Loss: 3.331561518, Training Accuracy: 19.120\n",
            "Worker 1, [11/18]: Training Loss: 3.421095216, Training Accuracy: 17.864\n",
            "Worker 1, [12/18]: Training Loss: 3.293092758, Training Accuracy: 20.152\n",
            "Worker 1, [13/18]: Training Loss: 3.369745347, Training Accuracy: 18.552\n",
            "Worker 1, [14/18]: Training Loss: 3.258227924, Training Accuracy: 20.512\n",
            "Worker 1, [15/18]: Training Loss: 3.322383817, Training Accuracy: 20.624\n",
            "Worker 1, [16/18]: Training Loss: 3.235818932, Training Accuracy: 21.368\n",
            "Worker 1, [17/18]: Training Loss: 3.331043406, Training Accuracy: 20.712\n",
            "Worker 1, [18/18]: Training Loss: 3.263749036, Training Accuracy: 21.512\n",
            "Time taken for training worker 1: 0:01:29.336657\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.568599857, Training Accuracy: 15.112\n",
            "Worker 2, [02/18]: Training Loss: 3.397478464, Training Accuracy: 17.688\n",
            "Worker 2, [03/18]: Training Loss: 3.641801721, Training Accuracy: 13.864\n",
            "Worker 2, [04/18]: Training Loss: 3.449064171, Training Accuracy: 16.952\n",
            "Worker 2, [05/18]: Training Loss: 3.582207769, Training Accuracy: 14.656\n",
            "Worker 2, [06/18]: Training Loss: 3.408580352, Training Accuracy: 17.728\n",
            "Worker 2, [07/18]: Training Loss: 3.532348831, Training Accuracy: 15.864\n",
            "Worker 2, [08/18]: Training Loss: 3.332112626, Training Accuracy: 19.104\n",
            "Worker 2, [09/18]: Training Loss: 3.458302671, Training Accuracy: 16.696\n",
            "Worker 2, [10/18]: Training Loss: 3.299667911, Training Accuracy: 20.104\n",
            "Worker 2, [11/18]: Training Loss: 3.393539219, Training Accuracy: 17.784\n",
            "Worker 2, [12/18]: Training Loss: 3.235495075, Training Accuracy: 20.928\n",
            "Worker 2, [13/18]: Training Loss: 3.320904244, Training Accuracy: 19.896\n",
            "Worker 2, [14/18]: Training Loss: 3.198224227, Training Accuracy: 21.840\n",
            "Worker 2, [15/18]: Training Loss: 3.277709948, Training Accuracy: 20.328\n",
            "Worker 2, [16/18]: Training Loss: 3.178353803, Training Accuracy: 21.912\n",
            "Worker 2, [17/18]: Training Loss: 3.285956933, Training Accuracy: 21.088\n",
            "Worker 2, [18/18]: Training Loss: 3.220125113, Training Accuracy: 21.912\n",
            "Time taken for training worker 2: 0:01:32.205769\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.525932098, Training Accuracy: 15.768\n",
            "Worker 3, [02/18]: Training Loss: 3.376332238, Training Accuracy: 18.456\n",
            "Worker 3, [03/18]: Training Loss: 3.633107744, Training Accuracy: 14.040\n",
            "Worker 3, [04/18]: Training Loss: 3.437581534, Training Accuracy: 16.608\n",
            "Worker 3, [05/18]: Training Loss: 3.574935369, Training Accuracy: 14.936\n",
            "Worker 3, [06/18]: Training Loss: 3.380488564, Training Accuracy: 18.272\n",
            "Worker 3, [07/18]: Training Loss: 3.498266956, Training Accuracy: 16.152\n",
            "Worker 3, [08/18]: Training Loss: 3.322805774, Training Accuracy: 18.704\n",
            "Worker 3, [09/18]: Training Loss: 3.443096733, Training Accuracy: 17.192\n",
            "Worker 3, [10/18]: Training Loss: 3.264028032, Training Accuracy: 19.984\n",
            "Worker 3, [11/18]: Training Loss: 3.365385720, Training Accuracy: 18.816\n",
            "Worker 3, [12/18]: Training Loss: 3.221582060, Training Accuracy: 21.312\n",
            "Worker 3, [13/18]: Training Loss: 3.311770047, Training Accuracy: 19.432\n",
            "Worker 3, [14/18]: Training Loss: 3.185929002, Training Accuracy: 21.608\n",
            "Worker 3, [15/18]: Training Loss: 3.262401558, Training Accuracy: 20.688\n",
            "Worker 3, [16/18]: Training Loss: 3.173651312, Training Accuracy: 22.464\n",
            "Worker 3, [17/18]: Training Loss: 3.271599254, Training Accuracy: 21.232\n",
            "Worker 3, [18/18]: Training Loss: 3.205801623, Training Accuracy: 22.144\n",
            "Time taken for training worker 3: 0:01:31.675642\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.514061869, Training Accuracy: 15.376\n",
            "Worker 4, [02/18]: Training Loss: 3.349385343, Training Accuracy: 18.712\n",
            "Worker 4, [03/18]: Training Loss: 3.628548799, Training Accuracy: 13.608\n",
            "Worker 4, [04/18]: Training Loss: 3.438619293, Training Accuracy: 16.728\n",
            "Worker 4, [05/18]: Training Loss: 3.586433906, Training Accuracy: 14.952\n",
            "Worker 4, [06/18]: Training Loss: 3.380393667, Training Accuracy: 18.064\n",
            "Worker 4, [07/18]: Training Loss: 3.509876574, Training Accuracy: 16.192\n",
            "Worker 4, [08/18]: Training Loss: 3.332318251, Training Accuracy: 18.904\n",
            "Worker 4, [09/18]: Training Loss: 3.457082268, Training Accuracy: 16.592\n",
            "Worker 4, [10/18]: Training Loss: 3.275460956, Training Accuracy: 19.976\n",
            "Worker 4, [11/18]: Training Loss: 3.360854024, Training Accuracy: 18.808\n",
            "Worker 4, [12/18]: Training Loss: 3.220517002, Training Accuracy: 20.864\n",
            "Worker 4, [13/18]: Training Loss: 3.301970011, Training Accuracy: 20.040\n",
            "Worker 4, [14/18]: Training Loss: 3.182162021, Training Accuracy: 22.040\n",
            "Worker 4, [15/18]: Training Loss: 3.260305861, Training Accuracy: 21.240\n",
            "Worker 4, [16/18]: Training Loss: 3.168869689, Training Accuracy: 22.632\n",
            "Worker 4, [17/18]: Training Loss: 3.277898914, Training Accuracy: 21.304\n",
            "Worker 4, [18/18]: Training Loss: 3.200537939, Training Accuracy: 21.768\n",
            "Time taken for training worker 4: 0:01:31.254191\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000499\n",
            "Local Step 03: Test Loss: 3.350598464, Test Accuracy: 21.460\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.445601376, Training Accuracy: 19.208\n",
            "Worker 1, [02/18]: Training Loss: 3.414934900, Training Accuracy: 19.344\n",
            "Worker 1, [03/18]: Training Loss: 3.325023843, Training Accuracy: 21.080\n",
            "Worker 1, [04/18]: Training Loss: 3.275064119, Training Accuracy: 20.744\n",
            "Worker 1, [05/18]: Training Loss: 3.297350495, Training Accuracy: 20.648\n",
            "Worker 1, [06/18]: Training Loss: 3.263360935, Training Accuracy: 20.600\n",
            "Worker 1, [07/18]: Training Loss: 3.337124882, Training Accuracy: 19.496\n",
            "Worker 1, [08/18]: Training Loss: 3.260626542, Training Accuracy: 20.784\n",
            "Worker 1, [09/18]: Training Loss: 3.357125687, Training Accuracy: 18.944\n",
            "Worker 1, [10/18]: Training Loss: 3.280719131, Training Accuracy: 19.896\n",
            "Worker 1, [11/18]: Training Loss: 3.386248164, Training Accuracy: 18.384\n",
            "Worker 1, [12/18]: Training Loss: 3.287169139, Training Accuracy: 20.192\n",
            "Worker 1, [13/18]: Training Loss: 3.382033358, Training Accuracy: 18.824\n",
            "Worker 1, [14/18]: Training Loss: 3.279666742, Training Accuracy: 19.888\n",
            "Worker 1, [15/18]: Training Loss: 3.381003877, Training Accuracy: 18.216\n",
            "Worker 1, [16/18]: Training Loss: 3.273963493, Training Accuracy: 19.976\n",
            "Worker 1, [17/18]: Training Loss: 3.391914782, Training Accuracy: 17.928\n",
            "Worker 1, [18/18]: Training Loss: 3.257862530, Training Accuracy: 19.992\n",
            "Time taken for training worker 1: 0:01:33.731806\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.331444847, Training Accuracy: 20.336\n",
            "Worker 2, [02/18]: Training Loss: 3.301027712, Training Accuracy: 21.040\n",
            "Worker 2, [03/18]: Training Loss: 3.267089332, Training Accuracy: 21.264\n",
            "Worker 2, [04/18]: Training Loss: 3.225351396, Training Accuracy: 22.136\n",
            "Worker 2, [05/18]: Training Loss: 3.248002875, Training Accuracy: 20.776\n",
            "Worker 2, [06/18]: Training Loss: 3.211024609, Training Accuracy: 21.336\n",
            "Worker 2, [07/18]: Training Loss: 3.260218522, Training Accuracy: 20.304\n",
            "Worker 2, [08/18]: Training Loss: 3.211694904, Training Accuracy: 21.280\n",
            "Worker 2, [09/18]: Training Loss: 3.307653089, Training Accuracy: 19.536\n",
            "Worker 2, [10/18]: Training Loss: 3.253812301, Training Accuracy: 20.176\n",
            "Worker 2, [11/18]: Training Loss: 3.329789409, Training Accuracy: 18.920\n",
            "Worker 2, [12/18]: Training Loss: 3.244991167, Training Accuracy: 20.696\n",
            "Worker 2, [13/18]: Training Loss: 3.344882245, Training Accuracy: 19.320\n",
            "Worker 2, [14/18]: Training Loss: 3.263667444, Training Accuracy: 19.528\n",
            "Worker 2, [15/18]: Training Loss: 3.358349596, Training Accuracy: 18.288\n",
            "Worker 2, [16/18]: Training Loss: 3.240078505, Training Accuracy: 20.872\n",
            "Worker 2, [17/18]: Training Loss: 3.341662796, Training Accuracy: 18.752\n",
            "Worker 2, [18/18]: Training Loss: 3.249966692, Training Accuracy: 20.304\n",
            "Time taken for training worker 2: 0:01:30.158328\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.260208256, Training Accuracy: 21.784\n",
            "Worker 3, [02/18]: Training Loss: 3.236183984, Training Accuracy: 22.016\n",
            "Worker 3, [03/18]: Training Loss: 3.255552519, Training Accuracy: 21.864\n",
            "Worker 3, [04/18]: Training Loss: 3.204569495, Training Accuracy: 21.464\n",
            "Worker 3, [05/18]: Training Loss: 3.231296596, Training Accuracy: 21.704\n",
            "Worker 3, [06/18]: Training Loss: 3.189714604, Training Accuracy: 21.680\n",
            "Worker 3, [07/18]: Training Loss: 3.240889724, Training Accuracy: 20.944\n",
            "Worker 3, [08/18]: Training Loss: 3.195623292, Training Accuracy: 21.416\n",
            "Worker 3, [09/18]: Training Loss: 3.294781507, Training Accuracy: 20.016\n",
            "Worker 3, [10/18]: Training Loss: 3.226628908, Training Accuracy: 20.312\n",
            "Worker 3, [11/18]: Training Loss: 3.304265059, Training Accuracy: 19.408\n",
            "Worker 3, [12/18]: Training Loss: 3.228707880, Training Accuracy: 20.792\n",
            "Worker 3, [13/18]: Training Loss: 3.339176148, Training Accuracy: 18.456\n",
            "Worker 3, [14/18]: Training Loss: 3.226397613, Training Accuracy: 20.552\n",
            "Worker 3, [15/18]: Training Loss: 3.326146143, Training Accuracy: 18.744\n",
            "Worker 3, [16/18]: Training Loss: 3.209577424, Training Accuracy: 21.160\n",
            "Worker 3, [17/18]: Training Loss: 3.308119615, Training Accuracy: 19.288\n",
            "Worker 3, [18/18]: Training Loss: 3.212468054, Training Accuracy: 20.528\n",
            "Time taken for training worker 3: 0:01:32.360091\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.250977587, Training Accuracy: 22.032\n",
            "Worker 4, [02/18]: Training Loss: 3.234022990, Training Accuracy: 21.800\n",
            "Worker 4, [03/18]: Training Loss: 3.258129255, Training Accuracy: 21.704\n",
            "Worker 4, [04/18]: Training Loss: 3.195093995, Training Accuracy: 21.808\n",
            "Worker 4, [05/18]: Training Loss: 3.226493640, Training Accuracy: 20.976\n",
            "Worker 4, [06/18]: Training Loss: 3.186325673, Training Accuracy: 22.208\n",
            "Worker 4, [07/18]: Training Loss: 3.239971843, Training Accuracy: 20.896\n",
            "Worker 4, [08/18]: Training Loss: 3.189246943, Training Accuracy: 21.696\n",
            "Worker 4, [09/18]: Training Loss: 3.267928324, Training Accuracy: 20.264\n",
            "Worker 4, [10/18]: Training Loss: 3.232628286, Training Accuracy: 20.936\n",
            "Worker 4, [11/18]: Training Loss: 3.299394943, Training Accuracy: 19.824\n",
            "Worker 4, [12/18]: Training Loss: 3.206565313, Training Accuracy: 21.208\n",
            "Worker 4, [13/18]: Training Loss: 3.320192687, Training Accuracy: 19.272\n",
            "Worker 4, [14/18]: Training Loss: 3.222941745, Training Accuracy: 21.376\n",
            "Worker 4, [15/18]: Training Loss: 3.332624522, Training Accuracy: 18.952\n",
            "Worker 4, [16/18]: Training Loss: 3.204937805, Training Accuracy: 21.152\n",
            "Worker 4, [17/18]: Training Loss: 3.308444331, Training Accuracy: 19.408\n",
            "Worker 4, [18/18]: Training Loss: 3.208695763, Training Accuracy: 20.944\n",
            "Time taken for training worker 4: 0:01:28.965288\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000474\n",
            "Local Step 04: Test Loss: 3.129669004, Test Accuracy: 24.850\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.373614350, Training Accuracy: 18.480\n",
            "Worker 1, [02/18]: Training Loss: 3.237688170, Training Accuracy: 21.048\n",
            "Worker 1, [03/18]: Training Loss: 3.335215791, Training Accuracy: 18.936\n",
            "Worker 1, [04/18]: Training Loss: 3.205635192, Training Accuracy: 21.816\n",
            "Worker 1, [05/18]: Training Loss: 3.274246341, Training Accuracy: 20.008\n",
            "Worker 1, [06/18]: Training Loss: 3.156335280, Training Accuracy: 22.320\n",
            "Worker 1, [07/18]: Training Loss: 3.217421517, Training Accuracy: 21.064\n",
            "Worker 1, [08/18]: Training Loss: 3.100463445, Training Accuracy: 23.496\n",
            "Worker 1, [09/18]: Training Loss: 3.145323981, Training Accuracy: 22.488\n",
            "Worker 1, [10/18]: Training Loss: 3.033746562, Training Accuracy: 24.912\n",
            "Worker 1, [11/18]: Training Loss: 3.051874177, Training Accuracy: 24.464\n",
            "Worker 1, [12/18]: Training Loss: 2.960290251, Training Accuracy: 26.032\n",
            "Worker 1, [13/18]: Training Loss: 2.996989119, Training Accuracy: 25.872\n",
            "Worker 1, [14/18]: Training Loss: 2.898239069, Training Accuracy: 27.192\n",
            "Worker 1, [15/18]: Training Loss: 2.928783754, Training Accuracy: 27.368\n",
            "Worker 1, [16/18]: Training Loss: 2.859374837, Training Accuracy: 28.520\n",
            "Worker 1, [17/18]: Training Loss: 2.908815194, Training Accuracy: 28.104\n",
            "Worker 1, [18/18]: Training Loss: 2.871019090, Training Accuracy: 28.800\n",
            "Time taken for training worker 1: 0:01:29.623761\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.327353032, Training Accuracy: 18.920\n",
            "Worker 2, [02/18]: Training Loss: 3.180228990, Training Accuracy: 21.904\n",
            "Worker 2, [03/18]: Training Loss: 3.276529884, Training Accuracy: 19.864\n",
            "Worker 2, [04/18]: Training Loss: 3.162727191, Training Accuracy: 21.664\n",
            "Worker 2, [05/18]: Training Loss: 3.242672732, Training Accuracy: 20.416\n",
            "Worker 2, [06/18]: Training Loss: 3.107715972, Training Accuracy: 23.056\n",
            "Worker 2, [07/18]: Training Loss: 3.176032823, Training Accuracy: 21.864\n",
            "Worker 2, [08/18]: Training Loss: 3.055910797, Training Accuracy: 23.624\n",
            "Worker 2, [09/18]: Training Loss: 3.091246304, Training Accuracy: 23.016\n",
            "Worker 2, [10/18]: Training Loss: 2.980668866, Training Accuracy: 25.184\n",
            "Worker 2, [11/18]: Training Loss: 3.025732386, Training Accuracy: 24.560\n",
            "Worker 2, [12/18]: Training Loss: 2.914202054, Training Accuracy: 27.248\n",
            "Worker 2, [13/18]: Training Loss: 2.948092875, Training Accuracy: 26.064\n",
            "Worker 2, [14/18]: Training Loss: 2.849044671, Training Accuracy: 27.968\n",
            "Worker 2, [15/18]: Training Loss: 2.878303371, Training Accuracy: 27.728\n",
            "Worker 2, [16/18]: Training Loss: 2.804900959, Training Accuracy: 29.456\n",
            "Worker 2, [17/18]: Training Loss: 2.865640123, Training Accuracy: 28.680\n",
            "Worker 2, [18/18]: Training Loss: 2.814396167, Training Accuracy: 29.216\n",
            "Time taken for training worker 2: 0:01:32.807349\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.278004825, Training Accuracy: 20.144\n",
            "Worker 3, [02/18]: Training Loss: 3.149171245, Training Accuracy: 22.176\n",
            "Worker 3, [03/18]: Training Loss: 3.259338013, Training Accuracy: 20.264\n",
            "Worker 3, [04/18]: Training Loss: 3.158906310, Training Accuracy: 21.632\n",
            "Worker 3, [05/18]: Training Loss: 3.214548916, Training Accuracy: 20.728\n",
            "Worker 3, [06/18]: Training Loss: 3.090599098, Training Accuracy: 23.200\n",
            "Worker 3, [07/18]: Training Loss: 3.143657201, Training Accuracy: 22.320\n",
            "Worker 3, [08/18]: Training Loss: 3.016161178, Training Accuracy: 24.944\n",
            "Worker 3, [09/18]: Training Loss: 3.054962030, Training Accuracy: 23.240\n",
            "Worker 3, [10/18]: Training Loss: 2.962952920, Training Accuracy: 25.400\n",
            "Worker 3, [11/18]: Training Loss: 2.986009766, Training Accuracy: 25.440\n",
            "Worker 3, [12/18]: Training Loss: 2.888201872, Training Accuracy: 27.024\n",
            "Worker 3, [13/18]: Training Loss: 2.904224984, Training Accuracy: 27.424\n",
            "Worker 3, [14/18]: Training Loss: 2.820728286, Training Accuracy: 28.944\n",
            "Worker 3, [15/18]: Training Loss: 2.854553209, Training Accuracy: 28.000\n",
            "Worker 3, [16/18]: Training Loss: 2.773316942, Training Accuracy: 29.576\n",
            "Worker 3, [17/18]: Training Loss: 2.826502317, Training Accuracy: 29.216\n",
            "Worker 3, [18/18]: Training Loss: 2.791315790, Training Accuracy: 29.832\n",
            "Time taken for training worker 3: 0:01:31.626488\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.294577221, Training Accuracy: 19.760\n",
            "Worker 4, [02/18]: Training Loss: 3.145581458, Training Accuracy: 22.168\n",
            "Worker 4, [03/18]: Training Loss: 3.282288525, Training Accuracy: 19.760\n",
            "Worker 4, [04/18]: Training Loss: 3.143854152, Training Accuracy: 22.048\n",
            "Worker 4, [05/18]: Training Loss: 3.240869224, Training Accuracy: 20.568\n",
            "Worker 4, [06/18]: Training Loss: 3.095349570, Training Accuracy: 23.192\n",
            "Worker 4, [07/18]: Training Loss: 3.149046352, Training Accuracy: 22.176\n",
            "Worker 4, [08/18]: Training Loss: 3.040255216, Training Accuracy: 24.264\n",
            "Worker 4, [09/18]: Training Loss: 3.076140473, Training Accuracy: 23.488\n",
            "Worker 4, [10/18]: Training Loss: 2.959689356, Training Accuracy: 25.488\n",
            "Worker 4, [11/18]: Training Loss: 2.993454713, Training Accuracy: 25.344\n",
            "Worker 4, [12/18]: Training Loss: 2.898986341, Training Accuracy: 27.008\n",
            "Worker 4, [13/18]: Training Loss: 2.913198369, Training Accuracy: 26.544\n",
            "Worker 4, [14/18]: Training Loss: 2.835798986, Training Accuracy: 27.728\n",
            "Worker 4, [15/18]: Training Loss: 2.849446051, Training Accuracy: 28.208\n",
            "Worker 4, [16/18]: Training Loss: 2.794658661, Training Accuracy: 29.632\n",
            "Worker 4, [17/18]: Training Loss: 2.845253766, Training Accuracy: 28.928\n",
            "Worker 4, [18/18]: Training Loss: 2.790687095, Training Accuracy: 29.312\n",
            "Time taken for training worker 4: 0:01:31.629287\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000408\n",
            "Local Step 05: Test Loss: 2.941115953, Test Accuracy: 27.740\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.074088837, Training Accuracy: 24.840\n",
            "Worker 1, [02/18]: Training Loss: 3.055049316, Training Accuracy: 25.120\n",
            "Worker 1, [03/18]: Training Loss: 2.920038599, Training Accuracy: 27.544\n",
            "Worker 1, [04/18]: Training Loss: 2.895092737, Training Accuracy: 27.976\n",
            "Worker 1, [05/18]: Training Loss: 2.930879643, Training Accuracy: 27.064\n",
            "Worker 1, [06/18]: Training Loss: 2.915056851, Training Accuracy: 27.280\n",
            "Worker 1, [07/18]: Training Loss: 2.962207297, Training Accuracy: 26.368\n",
            "Worker 1, [08/18]: Training Loss: 2.940605463, Training Accuracy: 26.384\n",
            "Worker 1, [09/18]: Training Loss: 3.024556064, Training Accuracy: 24.888\n",
            "Worker 1, [10/18]: Training Loss: 2.981868338, Training Accuracy: 25.624\n",
            "Worker 1, [11/18]: Training Loss: 3.071015955, Training Accuracy: 24.392\n",
            "Worker 1, [12/18]: Training Loss: 3.031887725, Training Accuracy: 24.600\n",
            "Worker 1, [13/18]: Training Loss: 3.097466881, Training Accuracy: 23.904\n",
            "Worker 1, [14/18]: Training Loss: 3.051193408, Training Accuracy: 24.456\n",
            "Worker 1, [15/18]: Training Loss: 3.110850098, Training Accuracy: 23.072\n",
            "Worker 1, [16/18]: Training Loss: 3.043256497, Training Accuracy: 24.064\n",
            "Worker 1, [17/18]: Training Loss: 3.126176047, Training Accuracy: 22.880\n",
            "Worker 1, [18/18]: Training Loss: 3.057592798, Training Accuracy: 23.704\n",
            "Time taken for training worker 1: 0:01:32.242942\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.043539427, Training Accuracy: 25.304\n",
            "Worker 2, [02/18]: Training Loss: 3.018693565, Training Accuracy: 25.600\n",
            "Worker 2, [03/18]: Training Loss: 2.866684024, Training Accuracy: 28.624\n",
            "Worker 2, [04/18]: Training Loss: 2.845493258, Training Accuracy: 28.344\n",
            "Worker 2, [05/18]: Training Loss: 2.874310261, Training Accuracy: 27.968\n",
            "Worker 2, [06/18]: Training Loss: 2.867680149, Training Accuracy: 27.792\n",
            "Worker 2, [07/18]: Training Loss: 2.918624168, Training Accuracy: 26.608\n",
            "Worker 2, [08/18]: Training Loss: 2.896846714, Training Accuracy: 26.680\n",
            "Worker 2, [09/18]: Training Loss: 2.984284408, Training Accuracy: 25.544\n",
            "Worker 2, [10/18]: Training Loss: 2.948337292, Training Accuracy: 25.776\n",
            "Worker 2, [11/18]: Training Loss: 3.031093543, Training Accuracy: 24.096\n",
            "Worker 2, [12/18]: Training Loss: 2.977132935, Training Accuracy: 25.512\n",
            "Worker 2, [13/18]: Training Loss: 3.056021839, Training Accuracy: 24.120\n",
            "Worker 2, [14/18]: Training Loss: 3.000400134, Training Accuracy: 24.976\n",
            "Worker 2, [15/18]: Training Loss: 3.090993729, Training Accuracy: 23.168\n",
            "Worker 2, [16/18]: Training Loss: 3.012694804, Training Accuracy: 24.840\n",
            "Worker 2, [17/18]: Training Loss: 3.089166116, Training Accuracy: 23.512\n",
            "Worker 2, [18/18]: Training Loss: 3.017432735, Training Accuracy: 24.520\n",
            "Time taken for training worker 2: 0:01:32.370536\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.003967089, Training Accuracy: 26.112\n",
            "Worker 3, [02/18]: Training Loss: 2.976413272, Training Accuracy: 26.784\n",
            "Worker 3, [03/18]: Training Loss: 2.835931649, Training Accuracy: 28.744\n",
            "Worker 3, [04/18]: Training Loss: 2.812722337, Training Accuracy: 29.400\n",
            "Worker 3, [05/18]: Training Loss: 2.839652678, Training Accuracy: 28.488\n",
            "Worker 3, [06/18]: Training Loss: 2.833077257, Training Accuracy: 28.264\n",
            "Worker 3, [07/18]: Training Loss: 2.884585211, Training Accuracy: 27.808\n",
            "Worker 3, [08/18]: Training Loss: 2.874688600, Training Accuracy: 27.640\n",
            "Worker 3, [09/18]: Training Loss: 2.942414016, Training Accuracy: 25.800\n",
            "Worker 3, [10/18]: Training Loss: 2.917457456, Training Accuracy: 26.192\n",
            "Worker 3, [11/18]: Training Loss: 2.990543898, Training Accuracy: 24.568\n",
            "Worker 3, [12/18]: Training Loss: 2.947033087, Training Accuracy: 25.232\n",
            "Worker 3, [13/18]: Training Loss: 3.022768015, Training Accuracy: 24.320\n",
            "Worker 3, [14/18]: Training Loss: 2.967617414, Training Accuracy: 25.432\n",
            "Worker 3, [15/18]: Training Loss: 3.062295151, Training Accuracy: 23.160\n",
            "Worker 3, [16/18]: Training Loss: 2.980657039, Training Accuracy: 25.104\n",
            "Worker 3, [17/18]: Training Loss: 3.057205947, Training Accuracy: 23.464\n",
            "Worker 3, [18/18]: Training Loss: 2.989005360, Training Accuracy: 24.584\n",
            "Time taken for training worker 3: 0:01:31.277604\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.980385271, Training Accuracy: 26.592\n",
            "Worker 4, [02/18]: Training Loss: 2.971727903, Training Accuracy: 26.936\n",
            "Worker 4, [03/18]: Training Loss: 2.840192694, Training Accuracy: 29.032\n",
            "Worker 4, [04/18]: Training Loss: 2.822454036, Training Accuracy: 28.592\n",
            "Worker 4, [05/18]: Training Loss: 2.852262291, Training Accuracy: 28.440\n",
            "Worker 4, [06/18]: Training Loss: 2.836009642, Training Accuracy: 28.064\n",
            "Worker 4, [07/18]: Training Loss: 2.894293612, Training Accuracy: 27.528\n",
            "Worker 4, [08/18]: Training Loss: 2.882303858, Training Accuracy: 27.056\n",
            "Worker 4, [09/18]: Training Loss: 2.956621395, Training Accuracy: 25.504\n",
            "Worker 4, [10/18]: Training Loss: 2.922866895, Training Accuracy: 26.064\n",
            "Worker 4, [11/18]: Training Loss: 2.998131717, Training Accuracy: 25.032\n",
            "Worker 4, [12/18]: Training Loss: 2.976944168, Training Accuracy: 25.208\n",
            "Worker 4, [13/18]: Training Loss: 3.050451582, Training Accuracy: 23.536\n",
            "Worker 4, [14/18]: Training Loss: 2.987815334, Training Accuracy: 24.752\n",
            "Worker 4, [15/18]: Training Loss: 3.063226884, Training Accuracy: 23.616\n",
            "Worker 4, [16/18]: Training Loss: 2.998791401, Training Accuracy: 24.936\n",
            "Worker 4, [17/18]: Training Loss: 3.078120660, Training Accuracy: 23.032\n",
            "Worker 4, [18/18]: Training Loss: 3.007167954, Training Accuracy: 24.400\n",
            "Time taken for training worker 4: 0:01:32.141721\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000410\n",
            "Local Step 06: Test Loss: 2.834023310, Test Accuracy: 29.920\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.214856847, Training Accuracy: 21.736\n",
            "Worker 1, [02/18]: Training Loss: 3.071550316, Training Accuracy: 24.504\n",
            "Worker 1, [03/18]: Training Loss: 3.098829842, Training Accuracy: 23.888\n",
            "Worker 1, [04/18]: Training Loss: 2.985488457, Training Accuracy: 25.352\n",
            "Worker 1, [05/18]: Training Loss: 3.042126799, Training Accuracy: 24.544\n",
            "Worker 1, [06/18]: Training Loss: 2.935897986, Training Accuracy: 26.704\n",
            "Worker 1, [07/18]: Training Loss: 2.955248965, Training Accuracy: 26.232\n",
            "Worker 1, [08/18]: Training Loss: 2.858093874, Training Accuracy: 27.984\n",
            "Worker 1, [09/18]: Training Loss: 2.887886758, Training Accuracy: 27.416\n",
            "Worker 1, [10/18]: Training Loss: 2.790132619, Training Accuracy: 29.520\n",
            "Worker 1, [11/18]: Training Loss: 2.796708973, Training Accuracy: 29.040\n",
            "Worker 1, [12/18]: Training Loss: 2.712196524, Training Accuracy: 30.936\n",
            "Worker 1, [13/18]: Training Loss: 2.716271641, Training Accuracy: 31.448\n",
            "Worker 1, [14/18]: Training Loss: 2.629758967, Training Accuracy: 33.000\n",
            "Worker 1, [15/18]: Training Loss: 2.646483016, Training Accuracy: 32.704\n",
            "Worker 1, [16/18]: Training Loss: 2.581771343, Training Accuracy: 33.888\n",
            "Worker 1, [17/18]: Training Loss: 2.615588210, Training Accuracy: 33.840\n",
            "Worker 1, [18/18]: Training Loss: 2.580911907, Training Accuracy: 34.160\n",
            "Time taken for training worker 1: 0:01:30.471226\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.182072346, Training Accuracy: 21.784\n",
            "Worker 2, [02/18]: Training Loss: 3.022845732, Training Accuracy: 25.328\n",
            "Worker 2, [03/18]: Training Loss: 3.047721759, Training Accuracy: 24.392\n",
            "Worker 2, [04/18]: Training Loss: 2.952417233, Training Accuracy: 25.832\n",
            "Worker 2, [05/18]: Training Loss: 2.997508313, Training Accuracy: 25.144\n",
            "Worker 2, [06/18]: Training Loss: 2.905479566, Training Accuracy: 27.088\n",
            "Worker 2, [07/18]: Training Loss: 2.914431136, Training Accuracy: 27.008\n",
            "Worker 2, [08/18]: Training Loss: 2.834246207, Training Accuracy: 27.480\n",
            "Worker 2, [09/18]: Training Loss: 2.851140543, Training Accuracy: 27.592\n",
            "Worker 2, [10/18]: Training Loss: 2.733067801, Training Accuracy: 29.984\n",
            "Worker 2, [11/18]: Training Loss: 2.745103820, Training Accuracy: 29.800\n",
            "Worker 2, [12/18]: Training Loss: 2.653793105, Training Accuracy: 31.832\n",
            "Worker 2, [13/18]: Training Loss: 2.672254241, Training Accuracy: 31.816\n",
            "Worker 2, [14/18]: Training Loss: 2.594026505, Training Accuracy: 33.064\n",
            "Worker 2, [15/18]: Training Loss: 2.591063077, Training Accuracy: 33.280\n",
            "Worker 2, [16/18]: Training Loss: 2.537551222, Training Accuracy: 34.800\n",
            "Worker 2, [17/18]: Training Loss: 2.577760740, Training Accuracy: 33.792\n",
            "Worker 2, [18/18]: Training Loss: 2.537016305, Training Accuracy: 34.760\n",
            "Time taken for training worker 2: 0:01:29.983220\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.115880703, Training Accuracy: 23.304\n",
            "Worker 3, [02/18]: Training Loss: 2.971557308, Training Accuracy: 25.392\n",
            "Worker 3, [03/18]: Training Loss: 3.024014001, Training Accuracy: 24.616\n",
            "Worker 3, [04/18]: Training Loss: 2.921104527, Training Accuracy: 26.480\n",
            "Worker 3, [05/18]: Training Loss: 2.975022927, Training Accuracy: 25.344\n",
            "Worker 3, [06/18]: Training Loss: 2.866962587, Training Accuracy: 27.216\n",
            "Worker 3, [07/18]: Training Loss: 2.901214218, Training Accuracy: 27.104\n",
            "Worker 3, [08/18]: Training Loss: 2.809213236, Training Accuracy: 27.968\n",
            "Worker 3, [09/18]: Training Loss: 2.807464459, Training Accuracy: 28.640\n",
            "Worker 3, [10/18]: Training Loss: 2.728204596, Training Accuracy: 30.488\n",
            "Worker 3, [11/18]: Training Loss: 2.724155467, Training Accuracy: 30.320\n",
            "Worker 3, [12/18]: Training Loss: 2.626652247, Training Accuracy: 32.288\n",
            "Worker 3, [13/18]: Training Loss: 2.638898904, Training Accuracy: 32.536\n",
            "Worker 3, [14/18]: Training Loss: 2.552074541, Training Accuracy: 33.552\n",
            "Worker 3, [15/18]: Training Loss: 2.576839293, Training Accuracy: 33.280\n",
            "Worker 3, [16/18]: Training Loss: 2.514097008, Training Accuracy: 34.816\n",
            "Worker 3, [17/18]: Training Loss: 2.548015405, Training Accuracy: 35.136\n",
            "Worker 3, [18/18]: Training Loss: 2.496719997, Training Accuracy: 35.456\n",
            "Time taken for training worker 3: 0:01:31.417997\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.125231953, Training Accuracy: 23.328\n",
            "Worker 4, [02/18]: Training Loss: 2.981531253, Training Accuracy: 25.600\n",
            "Worker 4, [03/18]: Training Loss: 3.038680320, Training Accuracy: 23.976\n",
            "Worker 4, [04/18]: Training Loss: 2.962992855, Training Accuracy: 25.592\n",
            "Worker 4, [05/18]: Training Loss: 2.993267044, Training Accuracy: 25.176\n",
            "Worker 4, [06/18]: Training Loss: 2.889581242, Training Accuracy: 26.632\n",
            "Worker 4, [07/18]: Training Loss: 2.907624622, Training Accuracy: 26.648\n",
            "Worker 4, [08/18]: Training Loss: 2.815836793, Training Accuracy: 28.368\n",
            "Worker 4, [09/18]: Training Loss: 2.827577400, Training Accuracy: 28.352\n",
            "Worker 4, [10/18]: Training Loss: 2.742030291, Training Accuracy: 30.032\n",
            "Worker 4, [11/18]: Training Loss: 2.747201344, Training Accuracy: 29.880\n",
            "Worker 4, [12/18]: Training Loss: 2.652130933, Training Accuracy: 31.728\n",
            "Worker 4, [13/18]: Training Loss: 2.650561304, Training Accuracy: 32.016\n",
            "Worker 4, [14/18]: Training Loss: 2.577927071, Training Accuracy: 33.280\n",
            "Worker 4, [15/18]: Training Loss: 2.587966996, Training Accuracy: 33.208\n",
            "Worker 4, [16/18]: Training Loss: 2.517593123, Training Accuracy: 34.992\n",
            "Worker 4, [17/18]: Training Loss: 2.555533079, Training Accuracy: 34.152\n",
            "Worker 4, [18/18]: Training Loss: 2.522827388, Training Accuracy: 35.016\n",
            "Time taken for training worker 4: 0:01:33.648889\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000407\n",
            "Local Step 07: Test Loss: 2.713472328, Test Accuracy: 32.130\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.865729924, Training Accuracy: 29.088\n",
            "Worker 1, [02/18]: Training Loss: 2.864609575, Training Accuracy: 28.976\n",
            "Worker 1, [03/18]: Training Loss: 2.637204333, Training Accuracy: 33.640\n",
            "Worker 1, [04/18]: Training Loss: 2.628618068, Training Accuracy: 32.936\n",
            "Worker 1, [05/18]: Training Loss: 2.649641538, Training Accuracy: 32.832\n",
            "Worker 1, [06/18]: Training Loss: 2.643696208, Training Accuracy: 32.472\n",
            "Worker 1, [07/18]: Training Loss: 2.695335010, Training Accuracy: 31.136\n",
            "Worker 1, [08/18]: Training Loss: 2.701565494, Training Accuracy: 31.352\n",
            "Worker 1, [09/18]: Training Loss: 2.762063051, Training Accuracy: 30.520\n",
            "Worker 1, [10/18]: Training Loss: 2.759438742, Training Accuracy: 30.304\n",
            "Worker 1, [11/18]: Training Loss: 2.821170426, Training Accuracy: 28.480\n",
            "Worker 1, [12/18]: Training Loss: 2.815136535, Training Accuracy: 28.944\n",
            "Worker 1, [13/18]: Training Loss: 2.873691251, Training Accuracy: 27.104\n",
            "Worker 1, [14/18]: Training Loss: 2.848871202, Training Accuracy: 28.400\n",
            "Worker 1, [15/18]: Training Loss: 2.899138257, Training Accuracy: 27.072\n",
            "Worker 1, [16/18]: Training Loss: 2.846690864, Training Accuracy: 27.624\n",
            "Worker 1, [17/18]: Training Loss: 2.919476986, Training Accuracy: 27.056\n",
            "Worker 1, [18/18]: Training Loss: 2.849250219, Training Accuracy: 27.728\n",
            "Time taken for training worker 1: 0:01:32.498113\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.862956166, Training Accuracy: 28.520\n",
            "Worker 2, [02/18]: Training Loss: 2.841773320, Training Accuracy: 28.824\n",
            "Worker 2, [03/18]: Training Loss: 2.579887615, Training Accuracy: 34.040\n",
            "Worker 2, [04/18]: Training Loss: 2.565758257, Training Accuracy: 34.176\n",
            "Worker 2, [05/18]: Training Loss: 2.600495295, Training Accuracy: 33.512\n",
            "Worker 2, [06/18]: Training Loss: 2.611223789, Training Accuracy: 32.832\n",
            "Worker 2, [07/18]: Training Loss: 2.654347630, Training Accuracy: 31.832\n",
            "Worker 2, [08/18]: Training Loss: 2.660598695, Training Accuracy: 32.024\n",
            "Worker 2, [09/18]: Training Loss: 2.717600691, Training Accuracy: 30.560\n",
            "Worker 2, [10/18]: Training Loss: 2.724544491, Training Accuracy: 30.024\n",
            "Worker 2, [11/18]: Training Loss: 2.777075542, Training Accuracy: 28.976\n",
            "Worker 2, [12/18]: Training Loss: 2.774766948, Training Accuracy: 29.408\n",
            "Worker 2, [13/18]: Training Loss: 2.825380954, Training Accuracy: 28.136\n",
            "Worker 2, [14/18]: Training Loss: 2.792339419, Training Accuracy: 28.936\n",
            "Worker 2, [15/18]: Training Loss: 2.876009112, Training Accuracy: 27.192\n",
            "Worker 2, [16/18]: Training Loss: 2.810990752, Training Accuracy: 28.952\n",
            "Worker 2, [17/18]: Training Loss: 2.872717343, Training Accuracy: 27.440\n",
            "Worker 2, [18/18]: Training Loss: 2.804864210, Training Accuracy: 28.280\n",
            "Time taken for training worker 2: 0:01:31.274201\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.811360025, Training Accuracy: 29.456\n",
            "Worker 3, [02/18]: Training Loss: 2.812716056, Training Accuracy: 29.784\n",
            "Worker 3, [03/18]: Training Loss: 2.554801834, Training Accuracy: 34.192\n",
            "Worker 3, [04/18]: Training Loss: 2.542382464, Training Accuracy: 34.848\n",
            "Worker 3, [05/18]: Training Loss: 2.573389274, Training Accuracy: 34.120\n",
            "Worker 3, [06/18]: Training Loss: 2.567300292, Training Accuracy: 33.784\n",
            "Worker 3, [07/18]: Training Loss: 2.624766604, Training Accuracy: 32.400\n",
            "Worker 3, [08/18]: Training Loss: 2.622916756, Training Accuracy: 32.056\n",
            "Worker 3, [09/18]: Training Loss: 2.686054730, Training Accuracy: 31.032\n",
            "Worker 3, [10/18]: Training Loss: 2.691411039, Training Accuracy: 30.848\n",
            "Worker 3, [11/18]: Training Loss: 2.761589820, Training Accuracy: 29.680\n",
            "Worker 3, [12/18]: Training Loss: 2.735036140, Training Accuracy: 30.072\n",
            "Worker 3, [13/18]: Training Loss: 2.817901239, Training Accuracy: 28.568\n",
            "Worker 3, [14/18]: Training Loss: 2.783196643, Training Accuracy: 28.760\n",
            "Worker 3, [15/18]: Training Loss: 2.838760662, Training Accuracy: 27.760\n",
            "Worker 3, [16/18]: Training Loss: 2.795049714, Training Accuracy: 28.680\n",
            "Worker 3, [17/18]: Training Loss: 2.864262614, Training Accuracy: 27.016\n",
            "Worker 3, [18/18]: Training Loss: 2.797375937, Training Accuracy: 28.984\n",
            "Time taken for training worker 3: 0:01:30.456638\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.818937142, Training Accuracy: 29.440\n",
            "Worker 4, [02/18]: Training Loss: 2.797965197, Training Accuracy: 30.688\n",
            "Worker 4, [03/18]: Training Loss: 2.570882326, Training Accuracy: 34.368\n",
            "Worker 4, [04/18]: Training Loss: 2.552322921, Training Accuracy: 34.032\n",
            "Worker 4, [05/18]: Training Loss: 2.580974977, Training Accuracy: 33.456\n",
            "Worker 4, [06/18]: Training Loss: 2.588846327, Training Accuracy: 33.224\n",
            "Worker 4, [07/18]: Training Loss: 2.647807310, Training Accuracy: 31.632\n",
            "Worker 4, [08/18]: Training Loss: 2.652234339, Training Accuracy: 31.360\n",
            "Worker 4, [09/18]: Training Loss: 2.704754123, Training Accuracy: 30.632\n",
            "Worker 4, [10/18]: Training Loss: 2.692493467, Training Accuracy: 31.240\n",
            "Worker 4, [11/18]: Training Loss: 2.764085952, Training Accuracy: 29.104\n",
            "Worker 4, [12/18]: Training Loss: 2.765114234, Training Accuracy: 29.552\n",
            "Worker 4, [13/18]: Training Loss: 2.830551062, Training Accuracy: 28.144\n",
            "Worker 4, [14/18]: Training Loss: 2.803926596, Training Accuracy: 28.856\n",
            "Worker 4, [15/18]: Training Loss: 2.852701508, Training Accuracy: 27.760\n",
            "Worker 4, [16/18]: Training Loss: 2.816935941, Training Accuracy: 28.408\n",
            "Worker 4, [17/18]: Training Loss: 2.865283734, Training Accuracy: 27.560\n",
            "Worker 4, [18/18]: Training Loss: 2.822270157, Training Accuracy: 28.032\n",
            "Time taken for training worker 4: 0:01:31.703537\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000422\n",
            "Local Step 08: Test Loss: 2.641410029, Test Accuracy: 33.260\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:48:54.538235\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.519829363, Training Accuracy: 2.288\n",
            "Worker 1, [02/18]: Training Loss: 4.151842157, Training Accuracy: 6.208\n",
            "Worker 1, [03/18]: Training Loss: 3.942907692, Training Accuracy: 9.072\n",
            "Worker 1, [04/18]: Training Loss: 3.767482300, Training Accuracy: 12.224\n",
            "Worker 1, [05/18]: Training Loss: 4.333858557, Training Accuracy: 4.528\n",
            "Worker 1, [06/18]: Training Loss: 3.936629118, Training Accuracy: 9.544\n",
            "Worker 1, [07/18]: Training Loss: 3.727116861, Training Accuracy: 12.600\n",
            "Worker 1, [08/18]: Training Loss: 3.571890638, Training Accuracy: 15.288\n",
            "Worker 1, [09/18]: Training Loss: 4.216258020, Training Accuracy: 6.144\n",
            "Worker 1, [10/18]: Training Loss: 3.819509976, Training Accuracy: 11.360\n",
            "Worker 1, [11/18]: Training Loss: 3.629891652, Training Accuracy: 14.072\n",
            "Worker 1, [12/18]: Training Loss: 3.505970154, Training Accuracy: 16.336\n",
            "Worker 1, [13/18]: Training Loss: 4.205272790, Training Accuracy: 7.408\n",
            "Worker 1, [14/18]: Training Loss: 3.824189804, Training Accuracy: 11.800\n",
            "Worker 1, [15/18]: Training Loss: 3.686068889, Training Accuracy: 14.032\n",
            "Worker 1, [16/18]: Training Loss: 3.596156349, Training Accuracy: 15.416\n",
            "Worker 1, [17/18]: Training Loss: 4.432577024, Training Accuracy: 9.560\n",
            "Worker 1, [18/18]: Training Loss: 4.337172348, Training Accuracy: 9.480\n",
            "Time taken for training worker 1: 0:01:31.025756\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.525578645, Training Accuracy: 2.224\n",
            "Worker 2, [02/18]: Training Loss: 4.143785218, Training Accuracy: 6.312\n",
            "Worker 2, [03/18]: Training Loss: 3.931453719, Training Accuracy: 9.152\n",
            "Worker 2, [04/18]: Training Loss: 3.764146017, Training Accuracy: 11.712\n",
            "Worker 2, [05/18]: Training Loss: 4.393577992, Training Accuracy: 3.592\n",
            "Worker 2, [06/18]: Training Loss: 3.983040383, Training Accuracy: 8.424\n",
            "Worker 2, [07/18]: Training Loss: 3.746559658, Training Accuracy: 12.200\n",
            "Worker 2, [08/18]: Training Loss: 3.607094881, Training Accuracy: 14.112\n",
            "Worker 2, [09/18]: Training Loss: 4.225261469, Training Accuracy: 6.352\n",
            "Worker 2, [10/18]: Training Loss: 3.827487088, Training Accuracy: 10.744\n",
            "Worker 2, [11/18]: Training Loss: 3.640118095, Training Accuracy: 13.608\n",
            "Worker 2, [12/18]: Training Loss: 3.510428725, Training Accuracy: 15.840\n",
            "Worker 2, [13/18]: Training Loss: 4.216301080, Training Accuracy: 7.648\n",
            "Worker 2, [14/18]: Training Loss: 3.835477361, Training Accuracy: 11.224\n",
            "Worker 2, [15/18]: Training Loss: 3.693301666, Training Accuracy: 13.712\n",
            "Worker 2, [16/18]: Training Loss: 3.608897945, Training Accuracy: 15.240\n",
            "Worker 2, [17/18]: Training Loss: 4.433377828, Training Accuracy: 9.144\n",
            "Worker 2, [18/18]: Training Loss: 4.336425141, Training Accuracy: 8.776\n",
            "Time taken for training worker 2: 0:01:32.472150\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.526891249, Training Accuracy: 2.128\n",
            "Worker 3, [02/18]: Training Loss: 4.133388379, Training Accuracy: 6.296\n",
            "Worker 3, [03/18]: Training Loss: 3.909776366, Training Accuracy: 9.040\n",
            "Worker 3, [04/18]: Training Loss: 3.745213582, Training Accuracy: 11.920\n",
            "Worker 3, [05/18]: Training Loss: 4.342553024, Training Accuracy: 4.616\n",
            "Worker 3, [06/18]: Training Loss: 3.914319956, Training Accuracy: 9.288\n",
            "Worker 3, [07/18]: Training Loss: 3.717556818, Training Accuracy: 12.440\n",
            "Worker 3, [08/18]: Training Loss: 3.582331493, Training Accuracy: 14.672\n",
            "Worker 3, [09/18]: Training Loss: 4.218538676, Training Accuracy: 6.400\n",
            "Worker 3, [10/18]: Training Loss: 3.810989208, Training Accuracy: 11.104\n",
            "Worker 3, [11/18]: Training Loss: 3.633066728, Training Accuracy: 13.992\n",
            "Worker 3, [12/18]: Training Loss: 3.525082595, Training Accuracy: 15.648\n",
            "Worker 3, [13/18]: Training Loss: 4.214004435, Training Accuracy: 7.328\n",
            "Worker 3, [14/18]: Training Loss: 3.825021943, Training Accuracy: 11.440\n",
            "Worker 3, [15/18]: Training Loss: 3.688822233, Training Accuracy: 13.624\n",
            "Worker 3, [16/18]: Training Loss: 3.601046292, Training Accuracy: 15.288\n",
            "Worker 3, [17/18]: Training Loss: 4.430415842, Training Accuracy: 9.736\n",
            "Worker 3, [18/18]: Training Loss: 4.332939912, Training Accuracy: 9.408\n",
            "Time taken for training worker 3: 0:01:32.392684\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.522670473, Training Accuracy: 2.336\n",
            "Worker 4, [02/18]: Training Loss: 4.147793583, Training Accuracy: 6.112\n",
            "Worker 4, [03/18]: Training Loss: 3.938459153, Training Accuracy: 8.640\n",
            "Worker 4, [04/18]: Training Loss: 3.767389835, Training Accuracy: 11.584\n",
            "Worker 4, [05/18]: Training Loss: 4.344244204, Training Accuracy: 4.184\n",
            "Worker 4, [06/18]: Training Loss: 3.962592764, Training Accuracy: 8.384\n",
            "Worker 4, [07/18]: Training Loss: 3.750297769, Training Accuracy: 11.320\n",
            "Worker 4, [08/18]: Training Loss: 3.608170986, Training Accuracy: 14.024\n",
            "Worker 4, [09/18]: Training Loss: 4.223292932, Training Accuracy: 6.024\n",
            "Worker 4, [10/18]: Training Loss: 3.822320518, Training Accuracy: 10.512\n",
            "Worker 4, [11/18]: Training Loss: 3.655683153, Training Accuracy: 13.616\n",
            "Worker 4, [12/18]: Training Loss: 3.514868543, Training Accuracy: 16.152\n",
            "Worker 4, [13/18]: Training Loss: 4.224428688, Training Accuracy: 6.800\n",
            "Worker 4, [14/18]: Training Loss: 3.836165775, Training Accuracy: 11.000\n",
            "Worker 4, [15/18]: Training Loss: 3.698066755, Training Accuracy: 12.992\n",
            "Worker 4, [16/18]: Training Loss: 3.601789235, Training Accuracy: 14.936\n",
            "Worker 4, [17/18]: Training Loss: 4.436159183, Training Accuracy: 8.360\n",
            "Worker 4, [18/18]: Training Loss: 4.338676898, Training Accuracy: 8.880\n",
            "Time taken for training worker 4: 0:01:32.513023\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000698\n",
            "Local Step 01: Test Loss: 4.346409725, Test Accuracy: 8.780\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.359109514, Training Accuracy: 8.272\n",
            "Worker 1, [02/18]: Training Loss: 4.341403555, Training Accuracy: 8.232\n",
            "Worker 1, [03/18]: Training Loss: 4.230735965, Training Accuracy: 8.856\n",
            "Worker 1, [04/18]: Training Loss: 4.020033733, Training Accuracy: 9.552\n",
            "Worker 1, [05/18]: Training Loss: 4.156664487, Training Accuracy: 9.352\n",
            "Worker 1, [06/18]: Training Loss: 3.837841826, Training Accuracy: 11.752\n",
            "Worker 1, [07/18]: Training Loss: 3.702981990, Training Accuracy: 13.248\n",
            "Worker 1, [08/18]: Training Loss: 3.602413761, Training Accuracy: 15.288\n",
            "Worker 1, [09/18]: Training Loss: 3.930124537, Training Accuracy: 10.304\n",
            "Worker 1, [10/18]: Training Loss: 3.653913817, Training Accuracy: 13.824\n",
            "Worker 1, [11/18]: Training Loss: 3.544688278, Training Accuracy: 16.008\n",
            "Worker 1, [12/18]: Training Loss: 3.455287464, Training Accuracy: 17.064\n",
            "Worker 1, [13/18]: Training Loss: 3.831966592, Training Accuracy: 11.328\n",
            "Worker 1, [14/18]: Training Loss: 3.584938244, Training Accuracy: 14.712\n",
            "Worker 1, [15/18]: Training Loss: 3.438852047, Training Accuracy: 17.024\n",
            "Worker 1, [16/18]: Training Loss: 3.347221696, Training Accuracy: 18.936\n",
            "Worker 1, [17/18]: Training Loss: 3.741685319, Training Accuracy: 12.688\n",
            "Worker 1, [18/18]: Training Loss: 3.510754215, Training Accuracy: 16.392\n",
            "Time taken for training worker 1: 0:01:32.867208\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.481234610, Training Accuracy: 16.376\n",
            "Worker 2, [02/18]: Training Loss: 3.431860118, Training Accuracy: 17.448\n",
            "Worker 2, [03/18]: Training Loss: 3.348359664, Training Accuracy: 19.464\n",
            "Worker 2, [04/18]: Training Loss: 3.287124867, Training Accuracy: 20.216\n",
            "Worker 2, [05/18]: Training Loss: 4.112765678, Training Accuracy: 10.424\n",
            "Worker 2, [06/18]: Training Loss: 3.773911496, Training Accuracy: 12.312\n",
            "Worker 2, [07/18]: Training Loss: 3.638737061, Training Accuracy: 14.400\n",
            "Worker 2, [08/18]: Training Loss: 3.534673860, Training Accuracy: 15.808\n",
            "Worker 2, [09/18]: Training Loss: 3.864337941, Training Accuracy: 11.264\n",
            "Worker 2, [10/18]: Training Loss: 3.590209564, Training Accuracy: 14.864\n",
            "Worker 2, [11/18]: Training Loss: 3.484914761, Training Accuracy: 16.744\n",
            "Worker 2, [12/18]: Training Loss: 3.390354706, Training Accuracy: 17.856\n",
            "Worker 2, [13/18]: Training Loss: 3.783784337, Training Accuracy: 12.176\n",
            "Worker 2, [14/18]: Training Loss: 3.524384276, Training Accuracy: 15.792\n",
            "Worker 2, [15/18]: Training Loss: 3.394852255, Training Accuracy: 17.840\n",
            "Worker 2, [16/18]: Training Loss: 3.287524546, Training Accuracy: 20.224\n",
            "Worker 2, [17/18]: Training Loss: 3.703966213, Training Accuracy: 13.232\n",
            "Worker 2, [18/18]: Training Loss: 3.455186492, Training Accuracy: 16.960\n",
            "Time taken for training worker 2: 0:01:32.388078\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.484019865, Training Accuracy: 16.856\n",
            "Worker 3, [02/18]: Training Loss: 3.398986020, Training Accuracy: 18.504\n",
            "Worker 3, [03/18]: Training Loss: 3.293984272, Training Accuracy: 20.464\n",
            "Worker 3, [04/18]: Training Loss: 3.220344273, Training Accuracy: 21.624\n",
            "Worker 3, [05/18]: Training Loss: 4.098143075, Training Accuracy: 10.856\n",
            "Worker 3, [06/18]: Training Loss: 3.747912404, Training Accuracy: 12.520\n",
            "Worker 3, [07/18]: Training Loss: 3.632803842, Training Accuracy: 14.392\n",
            "Worker 3, [08/18]: Training Loss: 3.537916278, Training Accuracy: 15.576\n",
            "Worker 3, [09/18]: Training Loss: 3.860294411, Training Accuracy: 11.576\n",
            "Worker 3, [10/18]: Training Loss: 3.583258287, Training Accuracy: 14.848\n",
            "Worker 3, [11/18]: Training Loss: 3.470196486, Training Accuracy: 16.792\n",
            "Worker 3, [12/18]: Training Loss: 3.369545540, Training Accuracy: 17.760\n",
            "Worker 3, [13/18]: Training Loss: 3.758212277, Training Accuracy: 13.312\n",
            "Worker 3, [14/18]: Training Loss: 3.506295606, Training Accuracy: 15.680\n",
            "Worker 3, [15/18]: Training Loss: 3.363391514, Training Accuracy: 18.304\n",
            "Worker 3, [16/18]: Training Loss: 3.261669537, Training Accuracy: 20.248\n",
            "Worker 3, [17/18]: Training Loss: 3.688375546, Training Accuracy: 13.360\n",
            "Worker 3, [18/18]: Training Loss: 3.428740804, Training Accuracy: 17.184\n",
            "Time taken for training worker 3: 0:01:30.449468\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.463055760, Training Accuracy: 16.464\n",
            "Worker 4, [02/18]: Training Loss: 3.354649153, Training Accuracy: 18.184\n",
            "Worker 4, [03/18]: Training Loss: 3.254204546, Training Accuracy: 21.008\n",
            "Worker 4, [04/18]: Training Loss: 3.193389967, Training Accuracy: 22.152\n",
            "Worker 4, [05/18]: Training Loss: 4.100702562, Training Accuracy: 10.072\n",
            "Worker 4, [06/18]: Training Loss: 3.757294044, Training Accuracy: 12.576\n",
            "Worker 4, [07/18]: Training Loss: 3.623768791, Training Accuracy: 14.336\n",
            "Worker 4, [08/18]: Training Loss: 3.539255607, Training Accuracy: 15.864\n",
            "Worker 4, [09/18]: Training Loss: 3.874288222, Training Accuracy: 11.120\n",
            "Worker 4, [10/18]: Training Loss: 3.581623890, Training Accuracy: 14.968\n",
            "Worker 4, [11/18]: Training Loss: 3.474252807, Training Accuracy: 16.592\n",
            "Worker 4, [12/18]: Training Loss: 3.368908640, Training Accuracy: 18.504\n",
            "Worker 4, [13/18]: Training Loss: 3.758634593, Training Accuracy: 12.416\n",
            "Worker 4, [14/18]: Training Loss: 3.501787894, Training Accuracy: 16.096\n",
            "Worker 4, [15/18]: Training Loss: 3.374148056, Training Accuracy: 17.752\n",
            "Worker 4, [16/18]: Training Loss: 3.258709477, Training Accuracy: 20.216\n",
            "Worker 4, [17/18]: Training Loss: 3.691342428, Training Accuracy: 13.344\n",
            "Worker 4, [18/18]: Training Loss: 3.428454099, Training Accuracy: 17.328\n",
            "Time taken for training worker 4: 0:01:29.540593\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.001001\n",
            "Local Step 02: Test Loss: 3.323000923, Test Accuracy: 19.210\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.370513099, Training Accuracy: 19.136\n",
            "Worker 1, [02/18]: Training Loss: 3.226527678, Training Accuracy: 20.768\n",
            "Worker 1, [03/18]: Training Loss: 3.121821635, Training Accuracy: 22.944\n",
            "Worker 1, [04/18]: Training Loss: 3.022269941, Training Accuracy: 24.632\n",
            "Worker 1, [05/18]: Training Loss: 3.672422129, Training Accuracy: 13.872\n",
            "Worker 1, [06/18]: Training Loss: 3.400673200, Training Accuracy: 18.424\n",
            "Worker 1, [07/18]: Training Loss: 3.246265843, Training Accuracy: 20.568\n",
            "Worker 1, [08/18]: Training Loss: 3.091631083, Training Accuracy: 23.584\n",
            "Worker 1, [09/18]: Training Loss: 3.539308046, Training Accuracy: 16.280\n",
            "Worker 1, [10/18]: Training Loss: 3.289406978, Training Accuracy: 20.776\n",
            "Worker 1, [11/18]: Training Loss: 3.135174723, Training Accuracy: 22.752\n",
            "Worker 1, [12/18]: Training Loss: 3.013849691, Training Accuracy: 25.160\n",
            "Worker 1, [13/18]: Training Loss: 3.454613952, Training Accuracy: 18.264\n",
            "Worker 1, [14/18]: Training Loss: 3.218707412, Training Accuracy: 21.544\n",
            "Worker 1, [15/18]: Training Loss: 3.104733403, Training Accuracy: 24.072\n",
            "Worker 1, [16/18]: Training Loss: 3.034385081, Training Accuracy: 25.696\n",
            "Worker 1, [17/18]: Training Loss: 3.558972710, Training Accuracy: 19.968\n",
            "Worker 1, [18/18]: Training Loss: 3.362504166, Training Accuracy: 20.136\n",
            "Time taken for training worker 1: 0:01:31.129272\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.529292716, Training Accuracy: 15.776\n",
            "Worker 2, [02/18]: Training Loss: 3.306751306, Training Accuracy: 19.488\n",
            "Worker 2, [03/18]: Training Loss: 3.183418460, Training Accuracy: 21.336\n",
            "Worker 2, [04/18]: Training Loss: 3.054155070, Training Accuracy: 24.056\n",
            "Worker 2, [05/18]: Training Loss: 3.611241364, Training Accuracy: 15.144\n",
            "Worker 2, [06/18]: Training Loss: 3.345555021, Training Accuracy: 18.488\n",
            "Worker 2, [07/18]: Training Loss: 3.200643531, Training Accuracy: 21.512\n",
            "Worker 2, [08/18]: Training Loss: 3.064812332, Training Accuracy: 23.864\n",
            "Worker 2, [09/18]: Training Loss: 3.497551895, Training Accuracy: 16.320\n",
            "Worker 2, [10/18]: Training Loss: 3.236946597, Training Accuracy: 21.016\n",
            "Worker 2, [11/18]: Training Loss: 3.089990730, Training Accuracy: 23.288\n",
            "Worker 2, [12/18]: Training Loss: 2.969910759, Training Accuracy: 25.672\n",
            "Worker 2, [13/18]: Training Loss: 3.385024377, Training Accuracy: 19.176\n",
            "Worker 2, [14/18]: Training Loss: 3.164481221, Training Accuracy: 22.448\n",
            "Worker 2, [15/18]: Training Loss: 3.062295988, Training Accuracy: 24.320\n",
            "Worker 2, [16/18]: Training Loss: 2.981900042, Training Accuracy: 25.608\n",
            "Worker 2, [17/18]: Training Loss: 3.500218225, Training Accuracy: 21.112\n",
            "Worker 2, [18/18]: Training Loss: 3.297316259, Training Accuracy: 21.752\n",
            "Time taken for training worker 2: 0:01:32.301234\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.492564338, Training Accuracy: 16.720\n",
            "Worker 3, [02/18]: Training Loss: 3.272234058, Training Accuracy: 20.048\n",
            "Worker 3, [03/18]: Training Loss: 3.129720063, Training Accuracy: 22.688\n",
            "Worker 3, [04/18]: Training Loss: 3.043792440, Training Accuracy: 23.952\n",
            "Worker 3, [05/18]: Training Loss: 3.590448500, Training Accuracy: 15.048\n",
            "Worker 3, [06/18]: Training Loss: 3.327535205, Training Accuracy: 19.264\n",
            "Worker 3, [07/18]: Training Loss: 3.160798051, Training Accuracy: 21.552\n",
            "Worker 3, [08/18]: Training Loss: 3.038202095, Training Accuracy: 23.888\n",
            "Worker 3, [09/18]: Training Loss: 3.476448874, Training Accuracy: 17.032\n",
            "Worker 3, [10/18]: Training Loss: 3.203280321, Training Accuracy: 21.376\n",
            "Worker 3, [11/18]: Training Loss: 3.053956290, Training Accuracy: 24.584\n",
            "Worker 3, [12/18]: Training Loss: 2.942722560, Training Accuracy: 25.864\n",
            "Worker 3, [13/18]: Training Loss: 3.365187585, Training Accuracy: 19.528\n",
            "Worker 3, [14/18]: Training Loss: 3.133065725, Training Accuracy: 22.952\n",
            "Worker 3, [15/18]: Training Loss: 3.022281000, Training Accuracy: 25.032\n",
            "Worker 3, [16/18]: Training Loss: 2.946420693, Training Accuracy: 26.272\n",
            "Worker 3, [17/18]: Training Loss: 3.481293201, Training Accuracy: 22.184\n",
            "Worker 3, [18/18]: Training Loss: 3.267388176, Training Accuracy: 21.776\n",
            "Time taken for training worker 3: 0:01:28.903244\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.465956699, Training Accuracy: 16.328\n",
            "Worker 4, [02/18]: Training Loss: 3.272824424, Training Accuracy: 20.000\n",
            "Worker 4, [03/18]: Training Loss: 3.143879072, Training Accuracy: 21.936\n",
            "Worker 4, [04/18]: Training Loss: 3.023921765, Training Accuracy: 24.520\n",
            "Worker 4, [05/18]: Training Loss: 3.617096839, Training Accuracy: 14.472\n",
            "Worker 4, [06/18]: Training Loss: 3.323480969, Training Accuracy: 19.000\n",
            "Worker 4, [07/18]: Training Loss: 3.154328453, Training Accuracy: 21.608\n",
            "Worker 4, [08/18]: Training Loss: 3.034311737, Training Accuracy: 24.024\n",
            "Worker 4, [09/18]: Training Loss: 3.462263036, Training Accuracy: 17.080\n",
            "Worker 4, [10/18]: Training Loss: 3.217664181, Training Accuracy: 21.352\n",
            "Worker 4, [11/18]: Training Loss: 3.052420448, Training Accuracy: 23.808\n",
            "Worker 4, [12/18]: Training Loss: 2.936974619, Training Accuracy: 26.120\n",
            "Worker 4, [13/18]: Training Loss: 3.354659314, Training Accuracy: 19.632\n",
            "Worker 4, [14/18]: Training Loss: 3.145432824, Training Accuracy: 22.216\n",
            "Worker 4, [15/18]: Training Loss: 3.021126567, Training Accuracy: 24.928\n",
            "Worker 4, [16/18]: Training Loss: 2.953122324, Training Accuracy: 26.568\n",
            "Worker 4, [17/18]: Training Loss: 3.471394935, Training Accuracy: 21.568\n",
            "Worker 4, [18/18]: Training Loss: 3.261473086, Training Accuracy: 21.912\n",
            "Time taken for training worker 4: 0:01:31.904143\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000544\n",
            "Local Step 03: Test Loss: 3.250769747, Test Accuracy: 22.980\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.354676641, Training Accuracy: 20.352\n",
            "Worker 1, [02/18]: Training Loss: 3.335879338, Training Accuracy: 20.560\n",
            "Worker 1, [03/18]: Training Loss: 3.302750135, Training Accuracy: 21.184\n",
            "Worker 1, [04/18]: Training Loss: 3.258573895, Training Accuracy: 21.472\n",
            "Worker 1, [05/18]: Training Loss: 3.392840999, Training Accuracy: 19.808\n",
            "Worker 1, [06/18]: Training Loss: 3.241970178, Training Accuracy: 20.752\n",
            "Worker 1, [07/18]: Training Loss: 3.182892406, Training Accuracy: 21.936\n",
            "Worker 1, [08/18]: Training Loss: 3.137741410, Training Accuracy: 22.968\n",
            "Worker 1, [09/18]: Training Loss: 3.352138503, Training Accuracy: 19.000\n",
            "Worker 1, [10/18]: Training Loss: 3.209016170, Training Accuracy: 22.048\n",
            "Worker 1, [11/18]: Training Loss: 3.129919801, Training Accuracy: 23.008\n",
            "Worker 1, [12/18]: Training Loss: 3.057607322, Training Accuracy: 24.096\n",
            "Worker 1, [13/18]: Training Loss: 3.389637094, Training Accuracy: 18.160\n",
            "Worker 1, [14/18]: Training Loss: 3.208935249, Training Accuracy: 21.528\n",
            "Worker 1, [15/18]: Training Loss: 3.111711255, Training Accuracy: 23.048\n",
            "Worker 1, [16/18]: Training Loss: 3.001735696, Training Accuracy: 25.112\n",
            "Worker 1, [17/18]: Training Loss: 3.348438348, Training Accuracy: 18.616\n",
            "Worker 1, [18/18]: Training Loss: 3.146699869, Training Accuracy: 22.472\n",
            "Time taken for training worker 1: 0:01:31.056460\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.277868279, Training Accuracy: 20.832\n",
            "Worker 2, [02/18]: Training Loss: 3.123587670, Training Accuracy: 23.376\n",
            "Worker 2, [03/18]: Training Loss: 3.032407860, Training Accuracy: 24.856\n",
            "Worker 2, [04/18]: Training Loss: 2.966264675, Training Accuracy: 26.144\n",
            "Worker 2, [05/18]: Training Loss: 3.292780717, Training Accuracy: 21.584\n",
            "Worker 2, [06/18]: Training Loss: 3.140918892, Training Accuracy: 22.984\n",
            "Worker 2, [07/18]: Training Loss: 3.087277860, Training Accuracy: 23.448\n",
            "Worker 2, [08/18]: Training Loss: 3.049379341, Training Accuracy: 24.448\n",
            "Worker 2, [09/18]: Training Loss: 3.272754106, Training Accuracy: 20.496\n",
            "Worker 2, [10/18]: Training Loss: 3.138574625, Training Accuracy: 22.480\n",
            "Worker 2, [11/18]: Training Loss: 3.039223980, Training Accuracy: 24.168\n",
            "Worker 2, [12/18]: Training Loss: 3.011937085, Training Accuracy: 24.592\n",
            "Worker 2, [13/18]: Training Loss: 3.278572536, Training Accuracy: 20.168\n",
            "Worker 2, [14/18]: Training Loss: 3.117549854, Training Accuracy: 22.800\n",
            "Worker 2, [15/18]: Training Loss: 3.049555770, Training Accuracy: 24.320\n",
            "Worker 2, [16/18]: Training Loss: 2.950352914, Training Accuracy: 25.736\n",
            "Worker 2, [17/18]: Training Loss: 3.282278888, Training Accuracy: 19.920\n",
            "Worker 2, [18/18]: Training Loss: 3.121426265, Training Accuracy: 23.064\n",
            "Time taken for training worker 2: 0:01:31.745061\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.175052024, Training Accuracy: 21.896\n",
            "Worker 3, [02/18]: Training Loss: 3.078095965, Training Accuracy: 24.136\n",
            "Worker 3, [03/18]: Training Loss: 2.979302369, Training Accuracy: 26.352\n",
            "Worker 3, [04/18]: Training Loss: 2.909571856, Training Accuracy: 27.384\n",
            "Worker 3, [05/18]: Training Loss: 3.261038537, Training Accuracy: 22.472\n",
            "Worker 3, [06/18]: Training Loss: 3.126186474, Training Accuracy: 23.224\n",
            "Worker 3, [07/18]: Training Loss: 3.058329673, Training Accuracy: 24.320\n",
            "Worker 3, [08/18]: Training Loss: 3.007786293, Training Accuracy: 25.184\n",
            "Worker 3, [09/18]: Training Loss: 3.238840956, Training Accuracy: 21.200\n",
            "Worker 3, [10/18]: Training Loss: 3.109332815, Training Accuracy: 23.008\n",
            "Worker 3, [11/18]: Training Loss: 3.047509504, Training Accuracy: 23.832\n",
            "Worker 3, [12/18]: Training Loss: 2.974080744, Training Accuracy: 25.320\n",
            "Worker 3, [13/18]: Training Loss: 3.235839633, Training Accuracy: 21.216\n",
            "Worker 3, [14/18]: Training Loss: 3.107835692, Training Accuracy: 23.104\n",
            "Worker 3, [15/18]: Training Loss: 3.004341138, Training Accuracy: 25.056\n",
            "Worker 3, [16/18]: Training Loss: 2.921479985, Training Accuracy: 26.488\n",
            "Worker 3, [17/18]: Training Loss: 3.254272662, Training Accuracy: 20.592\n",
            "Worker 3, [18/18]: Training Loss: 3.102379558, Training Accuracy: 22.896\n",
            "Time taken for training worker 3: 0:01:29.610393\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.203051010, Training Accuracy: 22.232\n",
            "Worker 4, [02/18]: Training Loss: 3.102876259, Training Accuracy: 24.416\n",
            "Worker 4, [03/18]: Training Loss: 2.997899442, Training Accuracy: 26.576\n",
            "Worker 4, [04/18]: Training Loss: 2.916043730, Training Accuracy: 27.472\n",
            "Worker 4, [05/18]: Training Loss: 3.255023509, Training Accuracy: 22.096\n",
            "Worker 4, [06/18]: Training Loss: 3.106955852, Training Accuracy: 23.424\n",
            "Worker 4, [07/18]: Training Loss: 3.055807140, Training Accuracy: 23.992\n",
            "Worker 4, [08/18]: Training Loss: 3.014519457, Training Accuracy: 24.264\n",
            "Worker 4, [09/18]: Training Loss: 3.244075652, Training Accuracy: 21.176\n",
            "Worker 4, [10/18]: Training Loss: 3.093782126, Training Accuracy: 23.152\n",
            "Worker 4, [11/18]: Training Loss: 3.037921661, Training Accuracy: 24.544\n",
            "Worker 4, [12/18]: Training Loss: 2.968376697, Training Accuracy: 25.680\n",
            "Worker 4, [13/18]: Training Loss: 3.256779330, Training Accuracy: 20.376\n",
            "Worker 4, [14/18]: Training Loss: 3.098885851, Training Accuracy: 23.056\n",
            "Worker 4, [15/18]: Training Loss: 3.021416755, Training Accuracy: 24.464\n",
            "Worker 4, [16/18]: Training Loss: 2.941922171, Training Accuracy: 25.664\n",
            "Worker 4, [17/18]: Training Loss: 3.259726225, Training Accuracy: 20.120\n",
            "Worker 4, [18/18]: Training Loss: 3.092148674, Training Accuracy: 22.880\n",
            "Time taken for training worker 4: 0:01:32.775317\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000703\n",
            "Local Step 04: Test Loss: 3.054913626, Test Accuracy: 24.780\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.122581229, Training Accuracy: 23.792\n",
            "Worker 1, [02/18]: Training Loss: 2.956977255, Training Accuracy: 26.512\n",
            "Worker 1, [03/18]: Training Loss: 2.880454593, Training Accuracy: 27.896\n",
            "Worker 1, [04/18]: Training Loss: 2.753700724, Training Accuracy: 29.920\n",
            "Worker 1, [05/18]: Training Loss: 3.258673338, Training Accuracy: 20.864\n",
            "Worker 1, [06/18]: Training Loss: 3.063672249, Training Accuracy: 23.968\n",
            "Worker 1, [07/18]: Training Loss: 2.908075041, Training Accuracy: 27.136\n",
            "Worker 1, [08/18]: Training Loss: 2.790444007, Training Accuracy: 29.368\n",
            "Worker 1, [09/18]: Training Loss: 3.122544561, Training Accuracy: 23.288\n",
            "Worker 1, [10/18]: Training Loss: 2.921318695, Training Accuracy: 26.360\n",
            "Worker 1, [11/18]: Training Loss: 2.788855305, Training Accuracy: 29.192\n",
            "Worker 1, [12/18]: Training Loss: 2.661926215, Training Accuracy: 31.880\n",
            "Worker 1, [13/18]: Training Loss: 2.970511308, Training Accuracy: 26.920\n",
            "Worker 1, [14/18]: Training Loss: 2.805296014, Training Accuracy: 29.320\n",
            "Worker 1, [15/18]: Training Loss: 2.703833640, Training Accuracy: 31.504\n",
            "Worker 1, [16/18]: Training Loss: 2.637071478, Training Accuracy: 32.544\n",
            "Worker 1, [17/18]: Training Loss: 2.955403712, Training Accuracy: 29.448\n",
            "Worker 1, [18/18]: Training Loss: 2.849045689, Training Accuracy: 29.304\n",
            "Time taken for training worker 1: 0:01:31.887619\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.247937029, Training Accuracy: 20.400\n",
            "Worker 2, [02/18]: Training Loss: 3.080714881, Training Accuracy: 24.056\n",
            "Worker 2, [03/18]: Training Loss: 2.931788055, Training Accuracy: 26.424\n",
            "Worker 2, [04/18]: Training Loss: 2.826142119, Training Accuracy: 27.960\n",
            "Worker 2, [05/18]: Training Loss: 3.182984065, Training Accuracy: 21.728\n",
            "Worker 2, [06/18]: Training Loss: 3.003611033, Training Accuracy: 24.600\n",
            "Worker 2, [07/18]: Training Loss: 2.875455455, Training Accuracy: 27.568\n",
            "Worker 2, [08/18]: Training Loss: 2.751068176, Training Accuracy: 29.960\n",
            "Worker 2, [09/18]: Training Loss: 3.053038812, Training Accuracy: 24.408\n",
            "Worker 2, [10/18]: Training Loss: 2.874886165, Training Accuracy: 27.352\n",
            "Worker 2, [11/18]: Training Loss: 2.731186439, Training Accuracy: 30.696\n",
            "Worker 2, [12/18]: Training Loss: 2.613345624, Training Accuracy: 32.592\n",
            "Worker 2, [13/18]: Training Loss: 2.887818436, Training Accuracy: 28.024\n",
            "Worker 2, [14/18]: Training Loss: 2.750867656, Training Accuracy: 30.056\n",
            "Worker 2, [15/18]: Training Loss: 2.642430482, Training Accuracy: 32.400\n",
            "Worker 2, [16/18]: Training Loss: 2.574686120, Training Accuracy: 34.168\n",
            "Worker 2, [17/18]: Training Loss: 2.876771643, Training Accuracy: 30.600\n",
            "Worker 2, [18/18]: Training Loss: 2.760758389, Training Accuracy: 30.848\n",
            "Time taken for training worker 2: 0:01:32.116553\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.213186060, Training Accuracy: 20.920\n",
            "Worker 3, [02/18]: Training Loss: 3.050040836, Training Accuracy: 24.360\n",
            "Worker 3, [03/18]: Training Loss: 2.898618682, Training Accuracy: 27.440\n",
            "Worker 3, [04/18]: Training Loss: 2.802027843, Training Accuracy: 28.752\n",
            "Worker 3, [05/18]: Training Loss: 3.144939671, Training Accuracy: 22.888\n",
            "Worker 3, [06/18]: Training Loss: 2.973285701, Training Accuracy: 25.384\n",
            "Worker 3, [07/18]: Training Loss: 2.841499975, Training Accuracy: 28.072\n",
            "Worker 3, [08/18]: Training Loss: 2.715614640, Training Accuracy: 30.272\n",
            "Worker 3, [09/18]: Training Loss: 3.037362959, Training Accuracy: 24.424\n",
            "Worker 3, [10/18]: Training Loss: 2.854657579, Training Accuracy: 27.488\n",
            "Worker 3, [11/18]: Training Loss: 2.713408204, Training Accuracy: 30.224\n",
            "Worker 3, [12/18]: Training Loss: 2.596278126, Training Accuracy: 33.168\n",
            "Worker 3, [13/18]: Training Loss: 2.869781601, Training Accuracy: 28.256\n",
            "Worker 3, [14/18]: Training Loss: 2.717350681, Training Accuracy: 30.896\n",
            "Worker 3, [15/18]: Training Loss: 2.613966340, Training Accuracy: 32.464\n",
            "Worker 3, [16/18]: Training Loss: 2.547903835, Training Accuracy: 34.456\n",
            "Worker 3, [17/18]: Training Loss: 2.850209586, Training Accuracy: 30.312\n",
            "Worker 3, [18/18]: Training Loss: 2.734991381, Training Accuracy: 31.048\n",
            "Time taken for training worker 3: 0:01:34.972650\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.222034196, Training Accuracy: 21.312\n",
            "Worker 4, [02/18]: Training Loss: 3.050817165, Training Accuracy: 24.424\n",
            "Worker 4, [03/18]: Training Loss: 2.898784770, Training Accuracy: 26.976\n",
            "Worker 4, [04/18]: Training Loss: 2.797034373, Training Accuracy: 28.968\n",
            "Worker 4, [05/18]: Training Loss: 3.163481424, Training Accuracy: 22.000\n",
            "Worker 4, [06/18]: Training Loss: 2.986960150, Training Accuracy: 25.080\n",
            "Worker 4, [07/18]: Training Loss: 2.836118145, Training Accuracy: 27.792\n",
            "Worker 4, [08/18]: Training Loss: 2.722240413, Training Accuracy: 30.176\n",
            "Worker 4, [09/18]: Training Loss: 3.014139999, Training Accuracy: 25.008\n",
            "Worker 4, [10/18]: Training Loss: 2.854183322, Training Accuracy: 28.024\n",
            "Worker 4, [11/18]: Training Loss: 2.706094547, Training Accuracy: 31.000\n",
            "Worker 4, [12/18]: Training Loss: 2.595483976, Training Accuracy: 32.824\n",
            "Worker 4, [13/18]: Training Loss: 2.861994690, Training Accuracy: 28.112\n",
            "Worker 4, [14/18]: Training Loss: 2.714060450, Training Accuracy: 30.592\n",
            "Worker 4, [15/18]: Training Loss: 2.618843509, Training Accuracy: 32.864\n",
            "Worker 4, [16/18]: Training Loss: 2.549149986, Training Accuracy: 34.584\n",
            "Worker 4, [17/18]: Training Loss: 2.850411480, Training Accuracy: 30.176\n",
            "Worker 4, [18/18]: Training Loss: 2.737190829, Training Accuracy: 31.104\n",
            "Time taken for training worker 4: 0:01:34.432633\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000602\n",
            "Local Step 05: Test Loss: 2.788730952, Test Accuracy: 30.780\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.937068285, Training Accuracy: 27.504\n",
            "Worker 1, [02/18]: Training Loss: 2.923878122, Training Accuracy: 27.672\n",
            "Worker 1, [03/18]: Training Loss: 2.900698298, Training Accuracy: 28.360\n",
            "Worker 1, [04/18]: Training Loss: 2.868678421, Training Accuracy: 28.616\n",
            "Worker 1, [05/18]: Training Loss: 2.887917746, Training Accuracy: 28.264\n",
            "Worker 1, [06/18]: Training Loss: 2.823434770, Training Accuracy: 28.856\n",
            "Worker 1, [07/18]: Training Loss: 2.789146217, Training Accuracy: 29.432\n",
            "Worker 1, [08/18]: Training Loss: 2.770658830, Training Accuracy: 30.008\n",
            "Worker 1, [09/18]: Training Loss: 2.944140831, Training Accuracy: 26.600\n",
            "Worker 1, [10/18]: Training Loss: 2.872083630, Training Accuracy: 27.968\n",
            "Worker 1, [11/18]: Training Loss: 2.825285811, Training Accuracy: 28.408\n",
            "Worker 1, [12/18]: Training Loss: 2.762734660, Training Accuracy: 29.952\n",
            "Worker 1, [13/18]: Training Loss: 3.022138525, Training Accuracy: 24.664\n",
            "Worker 1, [14/18]: Training Loss: 2.916806397, Training Accuracy: 26.560\n",
            "Worker 1, [15/18]: Training Loss: 2.826891077, Training Accuracy: 28.056\n",
            "Worker 1, [16/18]: Training Loss: 2.787636919, Training Accuracy: 28.832\n",
            "Worker 1, [17/18]: Training Loss: 3.036571581, Training Accuracy: 24.984\n",
            "Worker 1, [18/18]: Training Loss: 2.915664820, Training Accuracy: 26.664\n",
            "Time taken for training worker 1: 0:01:29.665961\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.092890854, Training Accuracy: 23.560\n",
            "Worker 2, [02/18]: Training Loss: 2.950868163, Training Accuracy: 26.344\n",
            "Worker 2, [03/18]: Training Loss: 2.832321706, Training Accuracy: 29.080\n",
            "Worker 2, [04/18]: Training Loss: 2.754766879, Training Accuracy: 30.208\n",
            "Worker 2, [05/18]: Training Loss: 2.802276069, Training Accuracy: 29.960\n",
            "Worker 2, [06/18]: Training Loss: 2.731338725, Training Accuracy: 30.912\n",
            "Worker 2, [07/18]: Training Loss: 2.716212287, Training Accuracy: 30.624\n",
            "Worker 2, [08/18]: Training Loss: 2.704487885, Training Accuracy: 30.464\n",
            "Worker 2, [09/18]: Training Loss: 2.861111059, Training Accuracy: 27.856\n",
            "Worker 2, [10/18]: Training Loss: 2.803715571, Training Accuracy: 29.160\n",
            "Worker 2, [11/18]: Training Loss: 2.768426252, Training Accuracy: 29.336\n",
            "Worker 2, [12/18]: Training Loss: 2.707006065, Training Accuracy: 30.648\n",
            "Worker 2, [13/18]: Training Loss: 2.945479522, Training Accuracy: 26.360\n",
            "Worker 2, [14/18]: Training Loss: 2.869181218, Training Accuracy: 27.544\n",
            "Worker 2, [15/18]: Training Loss: 2.769348660, Training Accuracy: 29.024\n",
            "Worker 2, [16/18]: Training Loss: 2.723260226, Training Accuracy: 30.584\n",
            "Worker 2, [17/18]: Training Loss: 2.972454870, Training Accuracy: 25.248\n",
            "Worker 2, [18/18]: Training Loss: 2.873541133, Training Accuracy: 27.224\n",
            "Time taken for training worker 2: 0:01:29.755257\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.968239474, Training Accuracy: 25.992\n",
            "Worker 3, [02/18]: Training Loss: 2.897954295, Training Accuracy: 27.760\n",
            "Worker 3, [03/18]: Training Loss: 2.805179218, Training Accuracy: 30.048\n",
            "Worker 3, [04/18]: Training Loss: 2.728528535, Training Accuracy: 31.072\n",
            "Worker 3, [05/18]: Training Loss: 2.773579316, Training Accuracy: 30.232\n",
            "Worker 3, [06/18]: Training Loss: 2.709367723, Training Accuracy: 31.280\n",
            "Worker 3, [07/18]: Training Loss: 2.695300302, Training Accuracy: 31.144\n",
            "Worker 3, [08/18]: Training Loss: 2.666494294, Training Accuracy: 31.344\n",
            "Worker 3, [09/18]: Training Loss: 2.832363941, Training Accuracy: 28.008\n",
            "Worker 3, [10/18]: Training Loss: 2.767345364, Training Accuracy: 29.320\n",
            "Worker 3, [11/18]: Training Loss: 2.723415001, Training Accuracy: 30.256\n",
            "Worker 3, [12/18]: Training Loss: 2.697001881, Training Accuracy: 30.920\n",
            "Worker 3, [13/18]: Training Loss: 2.931666895, Training Accuracy: 26.376\n",
            "Worker 3, [14/18]: Training Loss: 2.822491766, Training Accuracy: 28.552\n",
            "Worker 3, [15/18]: Training Loss: 2.760817827, Training Accuracy: 29.096\n",
            "Worker 3, [16/18]: Training Loss: 2.699351589, Training Accuracy: 30.448\n",
            "Worker 3, [17/18]: Training Loss: 2.927614630, Training Accuracy: 26.104\n",
            "Worker 3, [18/18]: Training Loss: 2.861995797, Training Accuracy: 27.448\n",
            "Time taken for training worker 3: 0:01:31.979285\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.030360564, Training Accuracy: 25.008\n",
            "Worker 4, [02/18]: Training Loss: 2.907032009, Training Accuracy: 27.304\n",
            "Worker 4, [03/18]: Training Loss: 2.803011532, Training Accuracy: 29.440\n",
            "Worker 4, [04/18]: Training Loss: 2.724161731, Training Accuracy: 31.568\n",
            "Worker 4, [05/18]: Training Loss: 2.772394070, Training Accuracy: 30.080\n",
            "Worker 4, [06/18]: Training Loss: 2.702897193, Training Accuracy: 31.240\n",
            "Worker 4, [07/18]: Training Loss: 2.668464185, Training Accuracy: 31.440\n",
            "Worker 4, [08/18]: Training Loss: 2.675905096, Training Accuracy: 31.440\n",
            "Worker 4, [09/18]: Training Loss: 2.831228908, Training Accuracy: 28.440\n",
            "Worker 4, [10/18]: Training Loss: 2.773744322, Training Accuracy: 29.200\n",
            "Worker 4, [11/18]: Training Loss: 2.725989920, Training Accuracy: 30.136\n",
            "Worker 4, [12/18]: Training Loss: 2.709535866, Training Accuracy: 30.832\n",
            "Worker 4, [13/18]: Training Loss: 2.931052421, Training Accuracy: 26.032\n",
            "Worker 4, [14/18]: Training Loss: 2.845243441, Training Accuracy: 27.904\n",
            "Worker 4, [15/18]: Training Loss: 2.786364834, Training Accuracy: 29.008\n",
            "Worker 4, [16/18]: Training Loss: 2.726849013, Training Accuracy: 30.696\n",
            "Worker 4, [17/18]: Training Loss: 2.953282143, Training Accuracy: 25.856\n",
            "Worker 4, [18/18]: Training Loss: 2.863551182, Training Accuracy: 27.112\n",
            "Time taken for training worker 4: 0:01:33.006827\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000594\n",
            "Local Step 06: Test Loss: 3.028976635, Test Accuracy: 25.410\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.980755313, Training Accuracy: 27.048\n",
            "Worker 1, [02/18]: Training Loss: 2.835165824, Training Accuracy: 28.960\n",
            "Worker 1, [03/18]: Training Loss: 2.723661644, Training Accuracy: 31.224\n",
            "Worker 1, [04/18]: Training Loss: 2.622700392, Training Accuracy: 32.752\n",
            "Worker 1, [05/18]: Training Loss: 2.931180872, Training Accuracy: 26.288\n",
            "Worker 1, [06/18]: Training Loss: 2.792246837, Training Accuracy: 29.472\n",
            "Worker 1, [07/18]: Training Loss: 2.662983023, Training Accuracy: 31.920\n",
            "Worker 1, [08/18]: Training Loss: 2.560928593, Training Accuracy: 34.144\n",
            "Worker 1, [09/18]: Training Loss: 2.778373204, Training Accuracy: 30.056\n",
            "Worker 1, [10/18]: Training Loss: 2.632434167, Training Accuracy: 31.712\n",
            "Worker 1, [11/18]: Training Loss: 2.519113501, Training Accuracy: 34.792\n",
            "Worker 1, [12/18]: Training Loss: 2.410637220, Training Accuracy: 37.288\n",
            "Worker 1, [13/18]: Training Loss: 2.610106210, Training Accuracy: 33.512\n",
            "Worker 1, [14/18]: Training Loss: 2.491782935, Training Accuracy: 35.712\n",
            "Worker 1, [15/18]: Training Loss: 2.395813294, Training Accuracy: 38.040\n",
            "Worker 1, [16/18]: Training Loss: 2.328169438, Training Accuracy: 39.312\n",
            "Worker 1, [17/18]: Training Loss: 2.557988447, Training Accuracy: 35.912\n",
            "Worker 1, [18/18]: Training Loss: 2.471736856, Training Accuracy: 36.920\n",
            "Time taken for training worker 1: 0:01:29.366954\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.061051999, Training Accuracy: 24.240\n",
            "Worker 2, [02/18]: Training Loss: 2.892317788, Training Accuracy: 27.168\n",
            "Worker 2, [03/18]: Training Loss: 2.797704222, Training Accuracy: 29.032\n",
            "Worker 2, [04/18]: Training Loss: 2.670202561, Training Accuracy: 31.096\n",
            "Worker 2, [05/18]: Training Loss: 2.892738210, Training Accuracy: 26.520\n",
            "Worker 2, [06/18]: Training Loss: 2.780164509, Training Accuracy: 29.504\n",
            "Worker 2, [07/18]: Training Loss: 2.648376504, Training Accuracy: 31.632\n",
            "Worker 2, [08/18]: Training Loss: 2.546449475, Training Accuracy: 33.864\n",
            "Worker 2, [09/18]: Training Loss: 2.735571606, Training Accuracy: 29.992\n",
            "Worker 2, [10/18]: Training Loss: 2.605614419, Training Accuracy: 32.536\n",
            "Worker 2, [11/18]: Training Loss: 2.485739432, Training Accuracy: 35.136\n",
            "Worker 2, [12/18]: Training Loss: 2.373325912, Training Accuracy: 37.192\n",
            "Worker 2, [13/18]: Training Loss: 2.543618122, Training Accuracy: 34.696\n",
            "Worker 2, [14/18]: Training Loss: 2.452781976, Training Accuracy: 36.224\n",
            "Worker 2, [15/18]: Training Loss: 2.354562325, Training Accuracy: 38.472\n",
            "Worker 2, [16/18]: Training Loss: 2.288636619, Training Accuracy: 39.888\n",
            "Worker 2, [17/18]: Training Loss: 2.482772427, Training Accuracy: 37.072\n",
            "Worker 2, [18/18]: Training Loss: 2.420505260, Training Accuracy: 37.288\n",
            "Time taken for training worker 2: 0:01:31.360288\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.033434993, Training Accuracy: 24.456\n",
            "Worker 3, [02/18]: Training Loss: 2.876851447, Training Accuracy: 27.304\n",
            "Worker 3, [03/18]: Training Loss: 2.777543103, Training Accuracy: 29.336\n",
            "Worker 3, [04/18]: Training Loss: 2.658117727, Training Accuracy: 31.472\n",
            "Worker 3, [05/18]: Training Loss: 2.877542102, Training Accuracy: 27.440\n",
            "Worker 3, [06/18]: Training Loss: 2.764094622, Training Accuracy: 29.464\n",
            "Worker 3, [07/18]: Training Loss: 2.628544334, Training Accuracy: 32.248\n",
            "Worker 3, [08/18]: Training Loss: 2.549528447, Training Accuracy: 33.304\n",
            "Worker 3, [09/18]: Training Loss: 2.708161989, Training Accuracy: 30.568\n",
            "Worker 3, [10/18]: Training Loss: 2.582505658, Training Accuracy: 33.432\n",
            "Worker 3, [11/18]: Training Loss: 2.473165677, Training Accuracy: 35.032\n",
            "Worker 3, [12/18]: Training Loss: 2.368932284, Training Accuracy: 37.152\n",
            "Worker 3, [13/18]: Training Loss: 2.532658396, Training Accuracy: 34.992\n",
            "Worker 3, [14/18]: Training Loss: 2.422836399, Training Accuracy: 36.728\n",
            "Worker 3, [15/18]: Training Loss: 2.332076082, Training Accuracy: 38.424\n",
            "Worker 3, [16/18]: Training Loss: 2.260511223, Training Accuracy: 40.584\n",
            "Worker 3, [17/18]: Training Loss: 2.458309785, Training Accuracy: 37.784\n",
            "Worker 3, [18/18]: Training Loss: 2.393411717, Training Accuracy: 37.576\n",
            "Time taken for training worker 3: 0:01:31.850713\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.997289883, Training Accuracy: 24.880\n",
            "Worker 4, [02/18]: Training Loss: 2.901261156, Training Accuracy: 27.312\n",
            "Worker 4, [03/18]: Training Loss: 2.769333724, Training Accuracy: 29.304\n",
            "Worker 4, [04/18]: Training Loss: 2.664172570, Training Accuracy: 31.784\n",
            "Worker 4, [05/18]: Training Loss: 2.881897738, Training Accuracy: 27.232\n",
            "Worker 4, [06/18]: Training Loss: 2.756335228, Training Accuracy: 29.952\n",
            "Worker 4, [07/18]: Training Loss: 2.626071299, Training Accuracy: 32.472\n",
            "Worker 4, [08/18]: Training Loss: 2.521411511, Training Accuracy: 34.312\n",
            "Worker 4, [09/18]: Training Loss: 2.742832825, Training Accuracy: 30.120\n",
            "Worker 4, [10/18]: Training Loss: 2.600065642, Training Accuracy: 32.728\n",
            "Worker 4, [11/18]: Training Loss: 2.488289891, Training Accuracy: 35.504\n",
            "Worker 4, [12/18]: Training Loss: 2.361998580, Training Accuracy: 37.784\n",
            "Worker 4, [13/18]: Training Loss: 2.531870532, Training Accuracy: 34.976\n",
            "Worker 4, [14/18]: Training Loss: 2.421290584, Training Accuracy: 36.760\n",
            "Worker 4, [15/18]: Training Loss: 2.331217925, Training Accuracy: 38.936\n",
            "Worker 4, [16/18]: Training Loss: 2.277113679, Training Accuracy: 40.232\n",
            "Worker 4, [17/18]: Training Loss: 2.466036804, Training Accuracy: 36.856\n",
            "Worker 4, [18/18]: Training Loss: 2.396617200, Training Accuracy: 37.624\n",
            "Time taken for training worker 4: 0:01:32.933291\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000599\n",
            "Local Step 07: Test Loss: 2.531565110, Test Accuracy: 35.690\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.687373680, Training Accuracy: 32.216\n",
            "Worker 1, [02/18]: Training Loss: 2.689543461, Training Accuracy: 32.584\n",
            "Worker 1, [03/18]: Training Loss: 2.668541732, Training Accuracy: 33.120\n",
            "Worker 1, [04/18]: Training Loss: 2.650129554, Training Accuracy: 32.648\n",
            "Worker 1, [05/18]: Training Loss: 2.537290052, Training Accuracy: 35.272\n",
            "Worker 1, [06/18]: Training Loss: 2.509807964, Training Accuracy: 35.136\n",
            "Worker 1, [07/18]: Training Loss: 2.512726937, Training Accuracy: 34.904\n",
            "Worker 1, [08/18]: Training Loss: 2.497720684, Training Accuracy: 35.480\n",
            "Worker 1, [09/18]: Training Loss: 2.657021446, Training Accuracy: 32.616\n",
            "Worker 1, [10/18]: Training Loss: 2.620691205, Training Accuracy: 32.400\n",
            "Worker 1, [11/18]: Training Loss: 2.590853269, Training Accuracy: 33.424\n",
            "Worker 1, [12/18]: Training Loss: 2.584239578, Training Accuracy: 32.960\n",
            "Worker 1, [13/18]: Training Loss: 2.759289810, Training Accuracy: 29.904\n",
            "Worker 1, [14/18]: Training Loss: 2.685419399, Training Accuracy: 30.896\n",
            "Worker 1, [15/18]: Training Loss: 2.637651075, Training Accuracy: 32.200\n",
            "Worker 1, [16/18]: Training Loss: 2.601661876, Training Accuracy: 32.904\n",
            "Worker 1, [17/18]: Training Loss: 2.811821930, Training Accuracy: 28.752\n",
            "Worker 1, [18/18]: Training Loss: 2.741634146, Training Accuracy: 30.336\n",
            "Time taken for training worker 1: 0:01:31.376142\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.895966579, Training Accuracy: 27.400\n",
            "Worker 2, [02/18]: Training Loss: 2.805464787, Training Accuracy: 29.384\n",
            "Worker 2, [03/18]: Training Loss: 2.708424460, Training Accuracy: 30.872\n",
            "Worker 2, [04/18]: Training Loss: 2.648491557, Training Accuracy: 32.976\n",
            "Worker 2, [05/18]: Training Loss: 2.478298788, Training Accuracy: 35.904\n",
            "Worker 2, [06/18]: Training Loss: 2.444361100, Training Accuracy: 36.032\n",
            "Worker 2, [07/18]: Training Loss: 2.436750757, Training Accuracy: 36.160\n",
            "Worker 2, [08/18]: Training Loss: 2.464391216, Training Accuracy: 35.632\n",
            "Worker 2, [09/18]: Training Loss: 2.584462852, Training Accuracy: 33.104\n",
            "Worker 2, [10/18]: Training Loss: 2.559631396, Training Accuracy: 34.136\n",
            "Worker 2, [11/18]: Training Loss: 2.557018563, Training Accuracy: 33.696\n",
            "Worker 2, [12/18]: Training Loss: 2.542138125, Training Accuracy: 33.824\n",
            "Worker 2, [13/18]: Training Loss: 2.715147516, Training Accuracy: 30.656\n",
            "Worker 2, [14/18]: Training Loss: 2.663156132, Training Accuracy: 31.528\n",
            "Worker 2, [15/18]: Training Loss: 2.637162959, Training Accuracy: 32.472\n",
            "Worker 2, [16/18]: Training Loss: 2.564586695, Training Accuracy: 33.328\n",
            "Worker 2, [17/18]: Training Loss: 2.760348338, Training Accuracy: 29.440\n",
            "Worker 2, [18/18]: Training Loss: 2.693087114, Training Accuracy: 31.112\n",
            "Time taken for training worker 2: 0:01:29.799884\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.905761033, Training Accuracy: 27.288\n",
            "Worker 3, [02/18]: Training Loss: 2.823980464, Training Accuracy: 28.784\n",
            "Worker 3, [03/18]: Training Loss: 2.704214675, Training Accuracy: 32.272\n",
            "Worker 3, [04/18]: Training Loss: 2.618253799, Training Accuracy: 33.680\n",
            "Worker 3, [05/18]: Training Loss: 2.447901114, Training Accuracy: 37.016\n",
            "Worker 3, [06/18]: Training Loss: 2.440572202, Training Accuracy: 36.888\n",
            "Worker 3, [07/18]: Training Loss: 2.435752224, Training Accuracy: 36.440\n",
            "Worker 3, [08/18]: Training Loss: 2.450934656, Training Accuracy: 35.864\n",
            "Worker 3, [09/18]: Training Loss: 2.559213890, Training Accuracy: 33.952\n",
            "Worker 3, [10/18]: Training Loss: 2.551623522, Training Accuracy: 33.992\n",
            "Worker 3, [11/18]: Training Loss: 2.538492177, Training Accuracy: 34.024\n",
            "Worker 3, [12/18]: Training Loss: 2.511240370, Training Accuracy: 34.344\n",
            "Worker 3, [13/18]: Training Loss: 2.677770250, Training Accuracy: 30.888\n",
            "Worker 3, [14/18]: Training Loss: 2.645988478, Training Accuracy: 31.840\n",
            "Worker 3, [15/18]: Training Loss: 2.608707142, Training Accuracy: 32.920\n",
            "Worker 3, [16/18]: Training Loss: 2.543670787, Training Accuracy: 33.400\n",
            "Worker 3, [17/18]: Training Loss: 2.730623290, Training Accuracy: 30.016\n",
            "Worker 3, [18/18]: Training Loss: 2.670841486, Training Accuracy: 31.272\n",
            "Time taken for training worker 3: 0:01:33.154484\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.972612247, Training Accuracy: 26.104\n",
            "Worker 4, [02/18]: Training Loss: 2.857900448, Training Accuracy: 28.248\n",
            "Worker 4, [03/18]: Training Loss: 2.723140310, Training Accuracy: 31.864\n",
            "Worker 4, [04/18]: Training Loss: 2.638902640, Training Accuracy: 33.176\n",
            "Worker 4, [05/18]: Training Loss: 2.458369499, Training Accuracy: 36.480\n",
            "Worker 4, [06/18]: Training Loss: 2.429628007, Training Accuracy: 36.488\n",
            "Worker 4, [07/18]: Training Loss: 2.426546218, Training Accuracy: 36.728\n",
            "Worker 4, [08/18]: Training Loss: 2.431417019, Training Accuracy: 36.192\n",
            "Worker 4, [09/18]: Training Loss: 2.569119640, Training Accuracy: 33.768\n",
            "Worker 4, [10/18]: Training Loss: 2.551847785, Training Accuracy: 33.832\n",
            "Worker 4, [11/18]: Training Loss: 2.519960930, Training Accuracy: 34.208\n",
            "Worker 4, [12/18]: Training Loss: 2.511222325, Training Accuracy: 34.600\n",
            "Worker 4, [13/18]: Training Loss: 2.696225452, Training Accuracy: 30.440\n",
            "Worker 4, [14/18]: Training Loss: 2.653502667, Training Accuracy: 31.600\n",
            "Worker 4, [15/18]: Training Loss: 2.619484387, Training Accuracy: 32.232\n",
            "Worker 4, [16/18]: Training Loss: 2.570525568, Training Accuracy: 33.280\n",
            "Worker 4, [17/18]: Training Loss: 2.752911586, Training Accuracy: 29.392\n",
            "Worker 4, [18/18]: Training Loss: 2.699985691, Training Accuracy: 30.800\n",
            "Time taken for training worker 4: 0:01:32.686440\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000601\n",
            "Local Step 08: Test Loss: 2.760645942, Test Accuracy: 30.950\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:48:59.616662\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.529330526, Training Accuracy: 2.144\n",
            "Worker 1, [02/18]: Training Loss: 4.152751700, Training Accuracy: 6.184\n",
            "Worker 1, [03/18]: Training Loss: 3.935393770, Training Accuracy: 9.168\n",
            "Worker 1, [04/18]: Training Loss: 3.774216945, Training Accuracy: 11.824\n",
            "Worker 1, [05/18]: Training Loss: 3.626770894, Training Accuracy: 14.160\n",
            "Worker 1, [06/18]: Training Loss: 3.491257416, Training Accuracy: 16.216\n",
            "Worker 1, [07/18]: Training Loss: 3.365869514, Training Accuracy: 18.560\n",
            "Worker 1, [08/18]: Training Loss: 3.246171779, Training Accuracy: 20.536\n",
            "Worker 1, [09/18]: Training Loss: 4.391044937, Training Accuracy: 4.312\n",
            "Worker 1, [10/18]: Training Loss: 3.960624745, Training Accuracy: 9.072\n",
            "Worker 1, [11/18]: Training Loss: 3.737633728, Training Accuracy: 12.488\n",
            "Worker 1, [12/18]: Training Loss: 3.575117482, Training Accuracy: 15.264\n",
            "Worker 1, [13/18]: Training Loss: 3.456499118, Training Accuracy: 17.184\n",
            "Worker 1, [14/18]: Training Loss: 3.354645264, Training Accuracy: 18.736\n",
            "Worker 1, [15/18]: Training Loss: 3.267005542, Training Accuracy: 20.824\n",
            "Worker 1, [16/18]: Training Loss: 3.200178723, Training Accuracy: 21.968\n",
            "Worker 1, [17/18]: Training Loss: 4.553776145, Training Accuracy: 5.040\n",
            "Worker 1, [18/18]: Training Loss: 4.529982577, Training Accuracy: 6.792\n",
            "Time taken for training worker 1: 0:01:30.843812\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.527023388, Training Accuracy: 2.280\n",
            "Worker 2, [02/18]: Training Loss: 4.148824525, Training Accuracy: 5.992\n",
            "Worker 2, [03/18]: Training Loss: 3.938661639, Training Accuracy: 9.192\n",
            "Worker 2, [04/18]: Training Loss: 3.769642199, Training Accuracy: 11.616\n",
            "Worker 2, [05/18]: Training Loss: 3.626335888, Training Accuracy: 13.856\n",
            "Worker 2, [06/18]: Training Loss: 3.488458255, Training Accuracy: 16.112\n",
            "Worker 2, [07/18]: Training Loss: 3.376416046, Training Accuracy: 17.744\n",
            "Worker 2, [08/18]: Training Loss: 3.257515287, Training Accuracy: 20.256\n",
            "Worker 2, [09/18]: Training Loss: 4.394969413, Training Accuracy: 4.176\n",
            "Worker 2, [10/18]: Training Loss: 3.960965784, Training Accuracy: 9.120\n",
            "Worker 2, [11/18]: Training Loss: 3.728222601, Training Accuracy: 12.840\n",
            "Worker 2, [12/18]: Training Loss: 3.570082588, Training Accuracy: 15.184\n",
            "Worker 2, [13/18]: Training Loss: 3.449207305, Training Accuracy: 17.008\n",
            "Worker 2, [14/18]: Training Loss: 3.336922742, Training Accuracy: 18.848\n",
            "Worker 2, [15/18]: Training Loss: 3.261631136, Training Accuracy: 20.480\n",
            "Worker 2, [16/18]: Training Loss: 3.193900786, Training Accuracy: 22.120\n",
            "Worker 2, [17/18]: Training Loss: 4.554689519, Training Accuracy: 5.032\n",
            "Worker 2, [18/18]: Training Loss: 4.531610817, Training Accuracy: 5.920\n",
            "Time taken for training worker 2: 0:01:30.224500\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.519269389, Training Accuracy: 2.496\n",
            "Worker 3, [02/18]: Training Loss: 4.140639561, Training Accuracy: 6.136\n",
            "Worker 3, [03/18]: Training Loss: 3.921070020, Training Accuracy: 9.032\n",
            "Worker 3, [04/18]: Training Loss: 3.755150789, Training Accuracy: 11.600\n",
            "Worker 3, [05/18]: Training Loss: 3.624906859, Training Accuracy: 13.936\n",
            "Worker 3, [06/18]: Training Loss: 3.500291193, Training Accuracy: 15.584\n",
            "Worker 3, [07/18]: Training Loss: 3.372745541, Training Accuracy: 18.112\n",
            "Worker 3, [08/18]: Training Loss: 3.245628335, Training Accuracy: 20.408\n",
            "Worker 3, [09/18]: Training Loss: 4.351061676, Training Accuracy: 4.456\n",
            "Worker 3, [10/18]: Training Loss: 3.927070973, Training Accuracy: 9.632\n",
            "Worker 3, [11/18]: Training Loss: 3.713899474, Training Accuracy: 12.840\n",
            "Worker 3, [12/18]: Training Loss: 3.554438669, Training Accuracy: 15.240\n",
            "Worker 3, [13/18]: Training Loss: 3.433292694, Training Accuracy: 17.048\n",
            "Worker 3, [14/18]: Training Loss: 3.331804651, Training Accuracy: 19.256\n",
            "Worker 3, [15/18]: Training Loss: 3.245810285, Training Accuracy: 20.864\n",
            "Worker 3, [16/18]: Training Loss: 3.172225890, Training Accuracy: 22.496\n",
            "Worker 3, [17/18]: Training Loss: 4.549603696, Training Accuracy: 5.448\n",
            "Worker 3, [18/18]: Training Loss: 4.524338851, Training Accuracy: 6.224\n",
            "Time taken for training worker 3: 0:01:30.674976\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.518834231, Training Accuracy: 2.408\n",
            "Worker 4, [02/18]: Training Loss: 4.134919355, Training Accuracy: 5.952\n",
            "Worker 4, [03/18]: Training Loss: 3.929144801, Training Accuracy: 8.848\n",
            "Worker 4, [04/18]: Training Loss: 3.760088033, Training Accuracy: 11.584\n",
            "Worker 4, [05/18]: Training Loss: 3.617791338, Training Accuracy: 13.720\n",
            "Worker 4, [06/18]: Training Loss: 3.482716973, Training Accuracy: 15.952\n",
            "Worker 4, [07/18]: Training Loss: 3.355048217, Training Accuracy: 18.328\n",
            "Worker 4, [08/18]: Training Loss: 3.230708402, Training Accuracy: 20.328\n",
            "Worker 4, [09/18]: Training Loss: 4.344018490, Training Accuracy: 4.696\n",
            "Worker 4, [10/18]: Training Loss: 3.930438874, Training Accuracy: 9.200\n",
            "Worker 4, [11/18]: Training Loss: 3.721482961, Training Accuracy: 12.536\n",
            "Worker 4, [12/18]: Training Loss: 3.561278881, Training Accuracy: 15.160\n",
            "Worker 4, [13/18]: Training Loss: 3.429824796, Training Accuracy: 17.448\n",
            "Worker 4, [14/18]: Training Loss: 3.333237686, Training Accuracy: 19.072\n",
            "Worker 4, [15/18]: Training Loss: 3.240676204, Training Accuracy: 21.208\n",
            "Worker 4, [16/18]: Training Loss: 3.181796328, Training Accuracy: 22.360\n",
            "Worker 4, [17/18]: Training Loss: 4.552557938, Training Accuracy: 4.672\n",
            "Worker 4, [18/18]: Training Loss: 4.527169111, Training Accuracy: 6.168\n",
            "Time taken for training worker 4: 0:01:34.463492\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000610\n",
            "Local Step 01: Test Loss: 4.533346814, Test Accuracy: 6.110\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.538052578, Training Accuracy: 5.488\n",
            "Worker 1, [02/18]: Training Loss: 4.533520499, Training Accuracy: 5.568\n",
            "Worker 1, [03/18]: Training Loss: 4.504171714, Training Accuracy: 5.848\n",
            "Worker 1, [04/18]: Training Loss: 4.376144008, Training Accuracy: 6.208\n",
            "Worker 1, [05/18]: Training Loss: 4.108526680, Training Accuracy: 7.752\n",
            "Worker 1, [06/18]: Training Loss: 3.928150897, Training Accuracy: 10.224\n",
            "Worker 1, [07/18]: Training Loss: 3.790718609, Training Accuracy: 12.152\n",
            "Worker 1, [08/18]: Training Loss: 3.673856644, Training Accuracy: 13.848\n",
            "Worker 1, [09/18]: Training Loss: 4.121012662, Training Accuracy: 8.240\n",
            "Worker 1, [10/18]: Training Loss: 3.719391923, Training Accuracy: 12.728\n",
            "Worker 1, [11/18]: Training Loss: 3.551526053, Training Accuracy: 15.024\n",
            "Worker 1, [12/18]: Training Loss: 3.430103634, Training Accuracy: 17.664\n",
            "Worker 1, [13/18]: Training Loss: 3.337323773, Training Accuracy: 19.144\n",
            "Worker 1, [14/18]: Training Loss: 3.254886704, Training Accuracy: 20.512\n",
            "Worker 1, [15/18]: Training Loss: 3.167410416, Training Accuracy: 22.000\n",
            "Worker 1, [16/18]: Training Loss: 3.100205104, Training Accuracy: 23.104\n",
            "Worker 1, [17/18]: Training Loss: 3.880448582, Training Accuracy: 10.704\n",
            "Worker 1, [18/18]: Training Loss: 3.502749302, Training Accuracy: 16.192\n",
            "Time taken for training worker 1: 0:01:38.582131\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.490179809, Training Accuracy: 16.336\n",
            "Worker 2, [02/18]: Training Loss: 3.430274817, Training Accuracy: 17.736\n",
            "Worker 2, [03/18]: Training Loss: 3.323054373, Training Accuracy: 19.792\n",
            "Worker 2, [04/18]: Training Loss: 3.232953604, Training Accuracy: 20.912\n",
            "Worker 2, [05/18]: Training Loss: 3.193339264, Training Accuracy: 21.688\n",
            "Worker 2, [06/18]: Training Loss: 3.141912584, Training Accuracy: 22.600\n",
            "Worker 2, [07/18]: Training Loss: 3.113396922, Training Accuracy: 23.416\n",
            "Worker 2, [08/18]: Training Loss: 3.073062729, Training Accuracy: 23.904\n",
            "Worker 2, [09/18]: Training Loss: 4.109625248, Training Accuracy: 8.248\n",
            "Worker 2, [10/18]: Training Loss: 3.661443418, Training Accuracy: 13.808\n",
            "Worker 2, [11/18]: Training Loss: 3.478343132, Training Accuracy: 16.432\n",
            "Worker 2, [12/18]: Training Loss: 3.373236728, Training Accuracy: 18.112\n",
            "Worker 2, [13/18]: Training Loss: 3.270720404, Training Accuracy: 19.976\n",
            "Worker 2, [14/18]: Training Loss: 3.191880686, Training Accuracy: 21.688\n",
            "Worker 2, [15/18]: Training Loss: 3.123330428, Training Accuracy: 22.616\n",
            "Worker 2, [16/18]: Training Loss: 3.042916197, Training Accuracy: 24.312\n",
            "Worker 2, [17/18]: Training Loss: 3.843839864, Training Accuracy: 11.808\n",
            "Worker 2, [18/18]: Training Loss: 3.452595905, Training Accuracy: 16.880\n",
            "Time taken for training worker 2: 0:01:29.411588\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.635290001, Training Accuracy: 14.960\n",
            "Worker 3, [02/18]: Training Loss: 3.347047773, Training Accuracy: 19.256\n",
            "Worker 3, [03/18]: Training Loss: 3.253988798, Training Accuracy: 20.832\n",
            "Worker 3, [04/18]: Training Loss: 3.183142189, Training Accuracy: 22.680\n",
            "Worker 3, [05/18]: Training Loss: 3.128794075, Training Accuracy: 23.352\n",
            "Worker 3, [06/18]: Training Loss: 3.088899334, Training Accuracy: 24.304\n",
            "Worker 3, [07/18]: Training Loss: 3.063817613, Training Accuracy: 24.344\n",
            "Worker 3, [08/18]: Training Loss: 3.016546345, Training Accuracy: 24.696\n",
            "Worker 3, [09/18]: Training Loss: 4.098505510, Training Accuracy: 8.144\n",
            "Worker 3, [10/18]: Training Loss: 3.661785964, Training Accuracy: 13.304\n",
            "Worker 3, [11/18]: Training Loss: 3.487034627, Training Accuracy: 16.528\n",
            "Worker 3, [12/18]: Training Loss: 3.336391507, Training Accuracy: 18.536\n",
            "Worker 3, [13/18]: Training Loss: 3.253111898, Training Accuracy: 20.160\n",
            "Worker 3, [14/18]: Training Loss: 3.167749406, Training Accuracy: 21.616\n",
            "Worker 3, [15/18]: Training Loss: 3.102961467, Training Accuracy: 22.896\n",
            "Worker 3, [16/18]: Training Loss: 3.011979450, Training Accuracy: 24.504\n",
            "Worker 3, [17/18]: Training Loss: 3.823729766, Training Accuracy: 11.696\n",
            "Worker 3, [18/18]: Training Loss: 3.406820505, Training Accuracy: 17.352\n",
            "Time taken for training worker 3: 0:01:29.887425\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.419195706, Training Accuracy: 16.848\n",
            "Worker 4, [02/18]: Training Loss: 3.334508160, Training Accuracy: 18.760\n",
            "Worker 4, [03/18]: Training Loss: 3.225482882, Training Accuracy: 21.272\n",
            "Worker 4, [04/18]: Training Loss: 3.152535075, Training Accuracy: 22.720\n",
            "Worker 4, [05/18]: Training Loss: 3.100191228, Training Accuracy: 23.512\n",
            "Worker 4, [06/18]: Training Loss: 3.061787374, Training Accuracy: 24.056\n",
            "Worker 4, [07/18]: Training Loss: 3.029682032, Training Accuracy: 25.088\n",
            "Worker 4, [08/18]: Training Loss: 3.006079557, Training Accuracy: 24.816\n",
            "Worker 4, [09/18]: Training Loss: 4.095991756, Training Accuracy: 8.192\n",
            "Worker 4, [10/18]: Training Loss: 3.669355295, Training Accuracy: 13.032\n",
            "Worker 4, [11/18]: Training Loss: 3.464908054, Training Accuracy: 16.368\n",
            "Worker 4, [12/18]: Training Loss: 3.330448624, Training Accuracy: 18.768\n",
            "Worker 4, [13/18]: Training Loss: 3.247421974, Training Accuracy: 20.016\n",
            "Worker 4, [14/18]: Training Loss: 3.165183596, Training Accuracy: 21.952\n",
            "Worker 4, [15/18]: Training Loss: 3.104018418, Training Accuracy: 22.832\n",
            "Worker 4, [16/18]: Training Loss: 3.025359016, Training Accuracy: 23.720\n",
            "Worker 4, [17/18]: Training Loss: 3.831855385, Training Accuracy: 11.520\n",
            "Worker 4, [18/18]: Training Loss: 3.431762000, Training Accuracy: 16.888\n",
            "Time taken for training worker 4: 0:01:30.062161\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000641\n",
            "Local Step 02: Test Loss: 3.271322363, Test Accuracy: 20.210\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.342353447, Training Accuracy: 18.832\n",
            "Worker 1, [02/18]: Training Loss: 3.172396823, Training Accuracy: 22.720\n",
            "Worker 1, [03/18]: Training Loss: 3.063393059, Training Accuracy: 24.136\n",
            "Worker 1, [04/18]: Training Loss: 2.966901849, Training Accuracy: 25.648\n",
            "Worker 1, [05/18]: Training Loss: 2.839847716, Training Accuracy: 28.192\n",
            "Worker 1, [06/18]: Training Loss: 2.744542409, Training Accuracy: 30.184\n",
            "Worker 1, [07/18]: Training Loss: 2.632476780, Training Accuracy: 32.312\n",
            "Worker 1, [08/18]: Training Loss: 2.528946110, Training Accuracy: 34.224\n",
            "Worker 1, [09/18]: Training Loss: 3.742307234, Training Accuracy: 13.560\n",
            "Worker 1, [10/18]: Training Loss: 3.351175581, Training Accuracy: 18.680\n",
            "Worker 1, [11/18]: Training Loss: 3.162756561, Training Accuracy: 21.904\n",
            "Worker 1, [12/18]: Training Loss: 3.007126668, Training Accuracy: 25.336\n",
            "Worker 1, [13/18]: Training Loss: 2.883235283, Training Accuracy: 27.512\n",
            "Worker 1, [14/18]: Training Loss: 2.780282071, Training Accuracy: 29.112\n",
            "Worker 1, [15/18]: Training Loss: 2.695400997, Training Accuracy: 31.480\n",
            "Worker 1, [16/18]: Training Loss: 2.628083213, Training Accuracy: 32.944\n",
            "Worker 1, [17/18]: Training Loss: 4.120787948, Training Accuracy: 16.608\n",
            "Worker 1, [18/18]: Training Loss: 3.835812160, Training Accuracy: 15.904\n",
            "Time taken for training worker 1: 0:01:31.915800\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.626906442, Training Accuracy: 14.328\n",
            "Worker 2, [02/18]: Training Loss: 3.336940660, Training Accuracy: 18.664\n",
            "Worker 2, [03/18]: Training Loss: 3.146068601, Training Accuracy: 22.416\n",
            "Worker 2, [04/18]: Training Loss: 2.994833579, Training Accuracy: 24.928\n",
            "Worker 2, [05/18]: Training Loss: 2.888316260, Training Accuracy: 27.056\n",
            "Worker 2, [06/18]: Training Loss: 2.769099619, Training Accuracy: 29.200\n",
            "Worker 2, [07/18]: Training Loss: 2.663702437, Training Accuracy: 31.144\n",
            "Worker 2, [08/18]: Training Loss: 2.593381519, Training Accuracy: 32.016\n",
            "Worker 2, [09/18]: Training Loss: 3.677423795, Training Accuracy: 15.008\n",
            "Worker 2, [10/18]: Training Loss: 3.252009226, Training Accuracy: 20.000\n",
            "Worker 2, [11/18]: Training Loss: 3.075864400, Training Accuracy: 23.480\n",
            "Worker 2, [12/18]: Training Loss: 2.924895804, Training Accuracy: 26.432\n",
            "Worker 2, [13/18]: Training Loss: 2.819609732, Training Accuracy: 28.600\n",
            "Worker 2, [14/18]: Training Loss: 2.731440058, Training Accuracy: 30.440\n",
            "Worker 2, [15/18]: Training Loss: 2.622552253, Training Accuracy: 32.808\n",
            "Worker 2, [16/18]: Training Loss: 2.552295965, Training Accuracy: 34.904\n",
            "Worker 2, [17/18]: Training Loss: 4.091695744, Training Accuracy: 18.176\n",
            "Worker 2, [18/18]: Training Loss: 3.783363185, Training Accuracy: 16.664\n",
            "Time taken for training worker 2: 0:01:25.593277\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.560498078, Training Accuracy: 15.808\n",
            "Worker 3, [02/18]: Training Loss: 3.239202290, Training Accuracy: 20.776\n",
            "Worker 3, [03/18]: Training Loss: 3.086613387, Training Accuracy: 23.272\n",
            "Worker 3, [04/18]: Training Loss: 2.950941177, Training Accuracy: 25.656\n",
            "Worker 3, [05/18]: Training Loss: 2.849240366, Training Accuracy: 27.984\n",
            "Worker 3, [06/18]: Training Loss: 2.729104993, Training Accuracy: 29.952\n",
            "Worker 3, [07/18]: Training Loss: 2.621638502, Training Accuracy: 31.896\n",
            "Worker 3, [08/18]: Training Loss: 2.504302431, Training Accuracy: 34.520\n",
            "Worker 3, [09/18]: Training Loss: 3.674575547, Training Accuracy: 14.440\n",
            "Worker 3, [10/18]: Training Loss: 3.241996297, Training Accuracy: 20.408\n",
            "Worker 3, [11/18]: Training Loss: 3.047042625, Training Accuracy: 24.064\n",
            "Worker 3, [12/18]: Training Loss: 2.909694814, Training Accuracy: 26.720\n",
            "Worker 3, [13/18]: Training Loss: 2.793200722, Training Accuracy: 29.240\n",
            "Worker 3, [14/18]: Training Loss: 2.680298775, Training Accuracy: 31.552\n",
            "Worker 3, [15/18]: Training Loss: 2.591240183, Training Accuracy: 33.248\n",
            "Worker 3, [16/18]: Training Loss: 2.521638897, Training Accuracy: 34.712\n",
            "Worker 3, [17/18]: Training Loss: 4.081253098, Training Accuracy: 18.184\n",
            "Worker 3, [18/18]: Training Loss: 3.769231190, Training Accuracy: 16.736\n",
            "Time taken for training worker 3: 0:01:30.766929\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.536000401, Training Accuracy: 15.632\n",
            "Worker 4, [02/18]: Training Loss: 3.254401413, Training Accuracy: 20.768\n",
            "Worker 4, [03/18]: Training Loss: 3.081151898, Training Accuracy: 23.648\n",
            "Worker 4, [04/18]: Training Loss: 2.947933500, Training Accuracy: 25.680\n",
            "Worker 4, [05/18]: Training Loss: 2.799833715, Training Accuracy: 29.168\n",
            "Worker 4, [06/18]: Training Loss: 2.714937789, Training Accuracy: 30.592\n",
            "Worker 4, [07/18]: Training Loss: 2.605931593, Training Accuracy: 33.104\n",
            "Worker 4, [08/18]: Training Loss: 2.524934362, Training Accuracy: 34.288\n",
            "Worker 4, [09/18]: Training Loss: 3.670694900, Training Accuracy: 14.704\n",
            "Worker 4, [10/18]: Training Loss: 3.229848513, Training Accuracy: 20.712\n",
            "Worker 4, [11/18]: Training Loss: 3.052515723, Training Accuracy: 24.000\n",
            "Worker 4, [12/18]: Training Loss: 2.906265463, Training Accuracy: 26.848\n",
            "Worker 4, [13/18]: Training Loss: 2.786769403, Training Accuracy: 28.736\n",
            "Worker 4, [14/18]: Training Loss: 2.668993857, Training Accuracy: 31.576\n",
            "Worker 4, [15/18]: Training Loss: 2.589987007, Training Accuracy: 33.056\n",
            "Worker 4, [16/18]: Training Loss: 2.520448881, Training Accuracy: 34.992\n",
            "Worker 4, [17/18]: Training Loss: 4.078032745, Training Accuracy: 18.296\n",
            "Worker 4, [18/18]: Training Loss: 3.761179863, Training Accuracy: 17.296\n",
            "Time taken for training worker 4: 0:01:27.059202\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000583\n",
            "Local Step 03: Test Loss: 3.693452616, Test Accuracy: 17.760\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.764968924, Training Accuracy: 15.752\n",
            "Worker 1, [02/18]: Training Loss: 3.721240690, Training Accuracy: 16.240\n",
            "Worker 1, [03/18]: Training Loss: 3.597939327, Training Accuracy: 17.632\n",
            "Worker 1, [04/18]: Training Loss: 3.439614266, Training Accuracy: 18.664\n",
            "Worker 1, [05/18]: Training Loss: 3.319029744, Training Accuracy: 20.272\n",
            "Worker 1, [06/18]: Training Loss: 3.223980580, Training Accuracy: 21.640\n",
            "Worker 1, [07/18]: Training Loss: 3.132781810, Training Accuracy: 23.144\n",
            "Worker 1, [08/18]: Training Loss: 3.052571429, Training Accuracy: 24.312\n",
            "Worker 1, [09/18]: Training Loss: 3.548704067, Training Accuracy: 15.880\n",
            "Worker 1, [10/18]: Training Loss: 3.213724943, Training Accuracy: 21.720\n",
            "Worker 1, [11/18]: Training Loss: 3.113323681, Training Accuracy: 22.896\n",
            "Worker 1, [12/18]: Training Loss: 3.011774471, Training Accuracy: 24.824\n",
            "Worker 1, [13/18]: Training Loss: 2.903698200, Training Accuracy: 27.112\n",
            "Worker 1, [14/18]: Training Loss: 2.851668617, Training Accuracy: 28.520\n",
            "Worker 1, [15/18]: Training Loss: 2.790788983, Training Accuracy: 29.280\n",
            "Worker 1, [16/18]: Training Loss: 2.745120433, Training Accuracy: 29.848\n",
            "Worker 1, [17/18]: Training Loss: 3.464265128, Training Accuracy: 17.304\n",
            "Worker 1, [18/18]: Training Loss: 3.132525934, Training Accuracy: 22.544\n",
            "Time taken for training worker 1: 0:01:26.143120\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.165174251, Training Accuracy: 22.376\n",
            "Worker 2, [02/18]: Training Loss: 3.063522671, Training Accuracy: 24.232\n",
            "Worker 2, [03/18]: Training Loss: 2.959861417, Training Accuracy: 26.512\n",
            "Worker 2, [04/18]: Training Loss: 2.881203486, Training Accuracy: 28.352\n",
            "Worker 2, [05/18]: Training Loss: 2.842229610, Training Accuracy: 28.736\n",
            "Worker 2, [06/18]: Training Loss: 2.804938498, Training Accuracy: 29.320\n",
            "Worker 2, [07/18]: Training Loss: 2.766652506, Training Accuracy: 29.744\n",
            "Worker 2, [08/18]: Training Loss: 2.733696138, Training Accuracy: 30.864\n",
            "Worker 2, [09/18]: Training Loss: 3.444610751, Training Accuracy: 18.960\n",
            "Worker 2, [10/18]: Training Loss: 3.134291638, Training Accuracy: 22.880\n",
            "Worker 2, [11/18]: Training Loss: 3.010202437, Training Accuracy: 24.504\n",
            "Worker 2, [12/18]: Training Loss: 2.911830080, Training Accuracy: 26.728\n",
            "Worker 2, [13/18]: Training Loss: 2.844239257, Training Accuracy: 28.304\n",
            "Worker 2, [14/18]: Training Loss: 2.798810883, Training Accuracy: 28.424\n",
            "Worker 2, [15/18]: Training Loss: 2.729102619, Training Accuracy: 29.984\n",
            "Worker 2, [16/18]: Training Loss: 2.671759897, Training Accuracy: 31.232\n",
            "Worker 2, [17/18]: Training Loss: 3.331766601, Training Accuracy: 19.712\n",
            "Worker 2, [18/18]: Training Loss: 3.077081834, Training Accuracy: 23.312\n",
            "Time taken for training worker 2: 0:01:30.707924\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.168886343, Training Accuracy: 22.184\n",
            "Worker 3, [02/18]: Training Loss: 3.014693030, Training Accuracy: 25.120\n",
            "Worker 3, [03/18]: Training Loss: 2.900552124, Training Accuracy: 28.400\n",
            "Worker 3, [04/18]: Training Loss: 2.817470525, Training Accuracy: 29.600\n",
            "Worker 3, [05/18]: Training Loss: 2.774516825, Training Accuracy: 30.320\n",
            "Worker 3, [06/18]: Training Loss: 2.743288026, Training Accuracy: 30.768\n",
            "Worker 3, [07/18]: Training Loss: 2.703228558, Training Accuracy: 31.408\n",
            "Worker 3, [08/18]: Training Loss: 2.679402608, Training Accuracy: 31.368\n",
            "Worker 3, [09/18]: Training Loss: 3.444999920, Training Accuracy: 18.416\n",
            "Worker 3, [10/18]: Training Loss: 3.098673756, Training Accuracy: 23.056\n",
            "Worker 3, [11/18]: Training Loss: 2.976031812, Training Accuracy: 25.568\n",
            "Worker 3, [12/18]: Training Loss: 2.901731680, Training Accuracy: 26.592\n",
            "Worker 3, [13/18]: Training Loss: 2.831306293, Training Accuracy: 28.344\n",
            "Worker 3, [14/18]: Training Loss: 2.746060404, Training Accuracy: 29.368\n",
            "Worker 3, [15/18]: Training Loss: 2.702621766, Training Accuracy: 30.216\n",
            "Worker 3, [16/18]: Training Loss: 2.648341820, Training Accuracy: 31.552\n",
            "Worker 3, [17/18]: Training Loss: 3.334463066, Training Accuracy: 19.608\n",
            "Worker 3, [18/18]: Training Loss: 3.054531736, Training Accuracy: 24.160\n",
            "Time taken for training worker 3: 0:01:29.923097\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.173635786, Training Accuracy: 22.264\n",
            "Worker 4, [02/18]: Training Loss: 3.049020648, Training Accuracy: 24.576\n",
            "Worker 4, [03/18]: Training Loss: 2.913830031, Training Accuracy: 27.168\n",
            "Worker 4, [04/18]: Training Loss: 2.815401598, Training Accuracy: 29.136\n",
            "Worker 4, [05/18]: Training Loss: 2.769071299, Training Accuracy: 30.448\n",
            "Worker 4, [06/18]: Training Loss: 2.714990258, Training Accuracy: 30.840\n",
            "Worker 4, [07/18]: Training Loss: 2.692302141, Training Accuracy: 31.520\n",
            "Worker 4, [08/18]: Training Loss: 2.666906117, Training Accuracy: 31.560\n",
            "Worker 4, [09/18]: Training Loss: 3.415481882, Training Accuracy: 18.904\n",
            "Worker 4, [10/18]: Training Loss: 3.095109092, Training Accuracy: 23.480\n",
            "Worker 4, [11/18]: Training Loss: 2.959375462, Training Accuracy: 25.544\n",
            "Worker 4, [12/18]: Training Loss: 2.885148637, Training Accuracy: 27.280\n",
            "Worker 4, [13/18]: Training Loss: 2.814112578, Training Accuracy: 28.432\n",
            "Worker 4, [14/18]: Training Loss: 2.764767202, Training Accuracy: 28.696\n",
            "Worker 4, [15/18]: Training Loss: 2.699961420, Training Accuracy: 30.480\n",
            "Worker 4, [16/18]: Training Loss: 2.664955330, Training Accuracy: 31.400\n",
            "Worker 4, [17/18]: Training Loss: 3.324802856, Training Accuracy: 19.640\n",
            "Worker 4, [18/18]: Training Loss: 3.006766543, Training Accuracy: 24.840\n",
            "Time taken for training worker 4: 0:01:26.083323\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000626\n",
            "Local Step 04: Test Loss: 2.926013385, Test Accuracy: 26.950\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.056311443, Training Accuracy: 25.080\n",
            "Worker 1, [02/18]: Training Loss: 2.876675035, Training Accuracy: 28.288\n",
            "Worker 1, [03/18]: Training Loss: 2.778006663, Training Accuracy: 29.840\n",
            "Worker 1, [04/18]: Training Loss: 2.703200685, Training Accuracy: 31.136\n",
            "Worker 1, [05/18]: Training Loss: 2.604961912, Training Accuracy: 33.104\n",
            "Worker 1, [06/18]: Training Loss: 2.499790411, Training Accuracy: 35.184\n",
            "Worker 1, [07/18]: Training Loss: 2.399773235, Training Accuracy: 37.312\n",
            "Worker 1, [08/18]: Training Loss: 2.293781061, Training Accuracy: 39.792\n",
            "Worker 1, [09/18]: Training Loss: 3.238757110, Training Accuracy: 22.432\n",
            "Worker 1, [10/18]: Training Loss: 2.926305267, Training Accuracy: 26.616\n",
            "Worker 1, [11/18]: Training Loss: 2.744244606, Training Accuracy: 30.168\n",
            "Worker 1, [12/18]: Training Loss: 2.604458673, Training Accuracy: 33.536\n",
            "Worker 1, [13/18]: Training Loss: 2.495447153, Training Accuracy: 35.728\n",
            "Worker 1, [14/18]: Training Loss: 2.396864055, Training Accuracy: 37.568\n",
            "Worker 1, [15/18]: Training Loss: 2.307095512, Training Accuracy: 40.136\n",
            "Worker 1, [16/18]: Training Loss: 2.247124564, Training Accuracy: 41.184\n",
            "Worker 1, [17/18]: Training Loss: 3.439235763, Training Accuracy: 26.448\n",
            "Worker 1, [18/18]: Training Loss: 3.098134821, Training Accuracy: 26.344\n",
            "Time taken for training worker 1: 0:01:30.657652\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.292806715, Training Accuracy: 19.952\n",
            "Worker 2, [02/18]: Training Loss: 3.046699484, Training Accuracy: 24.344\n",
            "Worker 2, [03/18]: Training Loss: 2.894052912, Training Accuracy: 27.224\n",
            "Worker 2, [04/18]: Training Loss: 2.780233324, Training Accuracy: 28.952\n",
            "Worker 2, [05/18]: Training Loss: 2.672825103, Training Accuracy: 31.528\n",
            "Worker 2, [06/18]: Training Loss: 2.576455536, Training Accuracy: 33.216\n",
            "Worker 2, [07/18]: Training Loss: 2.460832050, Training Accuracy: 35.656\n",
            "Worker 2, [08/18]: Training Loss: 2.370649242, Training Accuracy: 37.392\n",
            "Worker 2, [09/18]: Training Loss: 3.160553561, Training Accuracy: 23.216\n",
            "Worker 2, [10/18]: Training Loss: 2.842599029, Training Accuracy: 28.136\n",
            "Worker 2, [11/18]: Training Loss: 2.668542222, Training Accuracy: 31.496\n",
            "Worker 2, [12/18]: Training Loss: 2.563198644, Training Accuracy: 33.296\n",
            "Worker 2, [13/18]: Training Loss: 2.444983910, Training Accuracy: 35.976\n",
            "Worker 2, [14/18]: Training Loss: 2.339693852, Training Accuracy: 38.424\n",
            "Worker 2, [15/18]: Training Loss: 2.271808707, Training Accuracy: 39.640\n",
            "Worker 2, [16/18]: Training Loss: 2.191906653, Training Accuracy: 41.608\n",
            "Worker 2, [17/18]: Training Loss: 3.357346279, Training Accuracy: 28.480\n",
            "Worker 2, [18/18]: Training Loss: 3.006020795, Training Accuracy: 28.232\n",
            "Time taken for training worker 2: 0:01:31.703089\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.210584417, Training Accuracy: 21.600\n",
            "Worker 3, [02/18]: Training Loss: 3.007265232, Training Accuracy: 24.840\n",
            "Worker 3, [03/18]: Training Loss: 2.866631092, Training Accuracy: 27.472\n",
            "Worker 3, [04/18]: Training Loss: 2.752001385, Training Accuracy: 30.080\n",
            "Worker 3, [05/18]: Training Loss: 2.635155506, Training Accuracy: 32.272\n",
            "Worker 3, [06/18]: Training Loss: 2.567309437, Training Accuracy: 33.320\n",
            "Worker 3, [07/18]: Training Loss: 2.445350084, Training Accuracy: 35.968\n",
            "Worker 3, [08/18]: Training Loss: 2.347975353, Training Accuracy: 37.552\n",
            "Worker 3, [09/18]: Training Loss: 3.129649205, Training Accuracy: 23.584\n",
            "Worker 3, [10/18]: Training Loss: 2.820181011, Training Accuracy: 28.920\n",
            "Worker 3, [11/18]: Training Loss: 2.656585533, Training Accuracy: 32.008\n",
            "Worker 3, [12/18]: Training Loss: 2.522642902, Training Accuracy: 34.352\n",
            "Worker 3, [13/18]: Training Loss: 2.424438508, Training Accuracy: 36.200\n",
            "Worker 3, [14/18]: Training Loss: 2.322719718, Training Accuracy: 39.176\n",
            "Worker 3, [15/18]: Training Loss: 2.231637662, Training Accuracy: 41.208\n",
            "Worker 3, [16/18]: Training Loss: 2.161317400, Training Accuracy: 42.976\n",
            "Worker 3, [17/18]: Training Loss: 3.320111203, Training Accuracy: 28.808\n",
            "Worker 3, [18/18]: Training Loss: 2.968773270, Training Accuracy: 28.696\n",
            "Time taken for training worker 3: 0:01:30.388977\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.212761818, Training Accuracy: 21.064\n",
            "Worker 4, [02/18]: Training Loss: 2.992412228, Training Accuracy: 25.488\n",
            "Worker 4, [03/18]: Training Loss: 2.847990880, Training Accuracy: 27.664\n",
            "Worker 4, [04/18]: Training Loss: 2.739956519, Training Accuracy: 29.760\n",
            "Worker 4, [05/18]: Training Loss: 2.650875009, Training Accuracy: 31.648\n",
            "Worker 4, [06/18]: Training Loss: 2.532690855, Training Accuracy: 34.128\n",
            "Worker 4, [07/18]: Training Loss: 2.442844574, Training Accuracy: 36.224\n",
            "Worker 4, [08/18]: Training Loss: 2.335250479, Training Accuracy: 37.736\n",
            "Worker 4, [09/18]: Training Loss: 3.130510310, Training Accuracy: 23.672\n",
            "Worker 4, [10/18]: Training Loss: 2.815741207, Training Accuracy: 28.696\n",
            "Worker 4, [11/18]: Training Loss: 2.650356740, Training Accuracy: 31.992\n",
            "Worker 4, [12/18]: Training Loss: 2.526160105, Training Accuracy: 34.336\n",
            "Worker 4, [13/18]: Training Loss: 2.421386013, Training Accuracy: 36.192\n",
            "Worker 4, [14/18]: Training Loss: 2.300802728, Training Accuracy: 38.968\n",
            "Worker 4, [15/18]: Training Loss: 2.225299584, Training Accuracy: 41.152\n",
            "Worker 4, [16/18]: Training Loss: 2.153982643, Training Accuracy: 42.976\n",
            "Worker 4, [17/18]: Training Loss: 3.322178738, Training Accuracy: 28.504\n",
            "Worker 4, [18/18]: Training Loss: 2.967869587, Training Accuracy: 28.648\n",
            "Time taken for training worker 4: 0:01:31.674825\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000614\n",
            "Local Step 05: Test Loss: 2.949808236, Test Accuracy: 29.090\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.079890267, Training Accuracy: 25.864\n",
            "Worker 1, [02/18]: Training Loss: 3.051096820, Training Accuracy: 26.304\n",
            "Worker 1, [03/18]: Training Loss: 3.001587731, Training Accuracy: 27.272\n",
            "Worker 1, [04/18]: Training Loss: 2.927449745, Training Accuracy: 28.632\n",
            "Worker 1, [05/18]: Training Loss: 2.864077280, Training Accuracy: 28.848\n",
            "Worker 1, [06/18]: Training Loss: 2.822333274, Training Accuracy: 29.696\n",
            "Worker 1, [07/18]: Training Loss: 2.769826250, Training Accuracy: 30.368\n",
            "Worker 1, [08/18]: Training Loss: 2.723820033, Training Accuracy: 30.952\n",
            "Worker 1, [09/18]: Training Loss: 3.052746300, Training Accuracy: 24.808\n",
            "Worker 1, [10/18]: Training Loss: 2.837417775, Training Accuracy: 28.168\n",
            "Worker 1, [11/18]: Training Loss: 2.765917793, Training Accuracy: 29.704\n",
            "Worker 1, [12/18]: Training Loss: 2.711875379, Training Accuracy: 30.624\n",
            "Worker 1, [13/18]: Training Loss: 2.655060717, Training Accuracy: 32.024\n",
            "Worker 1, [14/18]: Training Loss: 2.599154916, Training Accuracy: 33.112\n",
            "Worker 1, [15/18]: Training Loss: 2.553742200, Training Accuracy: 33.864\n",
            "Worker 1, [16/18]: Training Loss: 2.540480227, Training Accuracy: 34.376\n",
            "Worker 1, [17/18]: Training Loss: 3.080811458, Training Accuracy: 23.968\n",
            "Worker 1, [18/18]: Training Loss: 2.864987704, Training Accuracy: 27.648\n",
            "Time taken for training worker 1: 0:01:30.232112\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.967787147, Training Accuracy: 25.712\n",
            "Worker 2, [02/18]: Training Loss: 2.861461182, Training Accuracy: 27.848\n",
            "Worker 2, [03/18]: Training Loss: 2.752904415, Training Accuracy: 30.168\n",
            "Worker 2, [04/18]: Training Loss: 2.692998125, Training Accuracy: 31.440\n",
            "Worker 2, [05/18]: Training Loss: 2.641302323, Training Accuracy: 32.624\n",
            "Worker 2, [06/18]: Training Loss: 2.599080850, Training Accuracy: 33.576\n",
            "Worker 2, [07/18]: Training Loss: 2.568226719, Training Accuracy: 33.696\n",
            "Worker 2, [08/18]: Training Loss: 2.553000410, Training Accuracy: 33.512\n",
            "Worker 2, [09/18]: Training Loss: 2.951967675, Training Accuracy: 26.760\n",
            "Worker 2, [10/18]: Training Loss: 2.780413101, Training Accuracy: 29.088\n",
            "Worker 2, [11/18]: Training Loss: 2.716144148, Training Accuracy: 30.296\n",
            "Worker 2, [12/18]: Training Loss: 2.644759625, Training Accuracy: 32.064\n",
            "Worker 2, [13/18]: Training Loss: 2.607457852, Training Accuracy: 32.528\n",
            "Worker 2, [14/18]: Training Loss: 2.589953207, Training Accuracy: 32.784\n",
            "Worker 2, [15/18]: Training Loss: 2.537508057, Training Accuracy: 33.584\n",
            "Worker 2, [16/18]: Training Loss: 2.477698029, Training Accuracy: 34.784\n",
            "Worker 2, [17/18]: Training Loss: 3.012366050, Training Accuracy: 25.648\n",
            "Worker 2, [18/18]: Training Loss: 2.814312846, Training Accuracy: 28.448\n",
            "Time taken for training worker 2: 0:01:30.565298\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.957789499, Training Accuracy: 26.544\n",
            "Worker 3, [02/18]: Training Loss: 2.881816825, Training Accuracy: 27.624\n",
            "Worker 3, [03/18]: Training Loss: 2.771012552, Training Accuracy: 30.800\n",
            "Worker 3, [04/18]: Training Loss: 2.676668578, Training Accuracy: 32.752\n",
            "Worker 3, [05/18]: Training Loss: 2.614612612, Training Accuracy: 33.568\n",
            "Worker 3, [06/18]: Training Loss: 2.563233843, Training Accuracy: 34.824\n",
            "Worker 3, [07/18]: Training Loss: 2.544844616, Training Accuracy: 34.536\n",
            "Worker 3, [08/18]: Training Loss: 2.506342843, Training Accuracy: 35.528\n",
            "Worker 3, [09/18]: Training Loss: 2.925042306, Training Accuracy: 28.024\n",
            "Worker 3, [10/18]: Training Loss: 2.757527539, Training Accuracy: 29.304\n",
            "Worker 3, [11/18]: Training Loss: 2.680666573, Training Accuracy: 30.816\n",
            "Worker 3, [12/18]: Training Loss: 2.626303021, Training Accuracy: 32.288\n",
            "Worker 3, [13/18]: Training Loss: 2.578514535, Training Accuracy: 32.856\n",
            "Worker 3, [14/18]: Training Loss: 2.551323117, Training Accuracy: 33.336\n",
            "Worker 3, [15/18]: Training Loss: 2.509230836, Training Accuracy: 34.440\n",
            "Worker 3, [16/18]: Training Loss: 2.470282123, Training Accuracy: 35.376\n",
            "Worker 3, [17/18]: Training Loss: 2.963389951, Training Accuracy: 26.432\n",
            "Worker 3, [18/18]: Training Loss: 2.790984773, Training Accuracy: 28.888\n",
            "Time taken for training worker 3: 0:01:32.604584\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.908207850, Training Accuracy: 27.184\n",
            "Worker 4, [02/18]: Training Loss: 2.824515200, Training Accuracy: 28.720\n",
            "Worker 4, [03/18]: Training Loss: 2.722604771, Training Accuracy: 30.936\n",
            "Worker 4, [04/18]: Training Loss: 2.651087158, Training Accuracy: 32.688\n",
            "Worker 4, [05/18]: Training Loss: 2.589634288, Training Accuracy: 33.816\n",
            "Worker 4, [06/18]: Training Loss: 2.555500259, Training Accuracy: 34.360\n",
            "Worker 4, [07/18]: Training Loss: 2.524022330, Training Accuracy: 35.136\n",
            "Worker 4, [08/18]: Training Loss: 2.502643544, Training Accuracy: 35.840\n",
            "Worker 4, [09/18]: Training Loss: 2.931691793, Training Accuracy: 27.072\n",
            "Worker 4, [10/18]: Training Loss: 2.746042998, Training Accuracy: 29.688\n",
            "Worker 4, [11/18]: Training Loss: 2.677382632, Training Accuracy: 31.240\n",
            "Worker 4, [12/18]: Training Loss: 2.647070156, Training Accuracy: 31.504\n",
            "Worker 4, [13/18]: Training Loss: 2.602013166, Training Accuracy: 32.392\n",
            "Worker 4, [14/18]: Training Loss: 2.562991968, Training Accuracy: 32.880\n",
            "Worker 4, [15/18]: Training Loss: 2.525629948, Training Accuracy: 34.112\n",
            "Worker 4, [16/18]: Training Loss: 2.482738572, Training Accuracy: 34.968\n",
            "Worker 4, [17/18]: Training Loss: 2.977524924, Training Accuracy: 25.840\n",
            "Worker 4, [18/18]: Training Loss: 2.794512304, Training Accuracy: 28.008\n",
            "Time taken for training worker 4: 0:01:30.994331\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000603\n",
            "Local Step 06: Test Loss: 2.806995345, Test Accuracy: 29.370\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.919407004, Training Accuracy: 27.440\n",
            "Worker 1, [02/18]: Training Loss: 2.771286652, Training Accuracy: 29.856\n",
            "Worker 1, [03/18]: Training Loss: 2.645456582, Training Accuracy: 32.400\n",
            "Worker 1, [04/18]: Training Loss: 2.556670359, Training Accuracy: 34.304\n",
            "Worker 1, [05/18]: Training Loss: 2.446902139, Training Accuracy: 36.640\n",
            "Worker 1, [06/18]: Training Loss: 2.346819404, Training Accuracy: 38.944\n",
            "Worker 1, [07/18]: Training Loss: 2.255351059, Training Accuracy: 40.160\n",
            "Worker 1, [08/18]: Training Loss: 2.167931020, Training Accuracy: 42.024\n",
            "Worker 1, [09/18]: Training Loss: 2.863323625, Training Accuracy: 28.384\n",
            "Worker 1, [10/18]: Training Loss: 2.625516919, Training Accuracy: 32.272\n",
            "Worker 1, [11/18]: Training Loss: 2.485507506, Training Accuracy: 35.920\n",
            "Worker 1, [12/18]: Training Loss: 2.362069644, Training Accuracy: 38.136\n",
            "Worker 1, [13/18]: Training Loss: 2.251250789, Training Accuracy: 40.632\n",
            "Worker 1, [14/18]: Training Loss: 2.147729456, Training Accuracy: 42.832\n",
            "Worker 1, [15/18]: Training Loss: 2.073840141, Training Accuracy: 44.784\n",
            "Worker 1, [16/18]: Training Loss: 2.010045815, Training Accuracy: 46.432\n",
            "Worker 1, [17/18]: Training Loss: 2.857818905, Training Accuracy: 34.648\n",
            "Worker 1, [18/18]: Training Loss: 2.612281838, Training Accuracy: 34.936\n",
            "Time taken for training worker 1: 0:01:32.408685\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.052754857, Training Accuracy: 24.248\n",
            "Worker 2, [02/18]: Training Loss: 2.884070328, Training Accuracy: 27.376\n",
            "Worker 2, [03/18]: Training Loss: 2.740513927, Training Accuracy: 30.160\n",
            "Worker 2, [04/18]: Training Loss: 2.645923371, Training Accuracy: 31.680\n",
            "Worker 2, [05/18]: Training Loss: 2.541992005, Training Accuracy: 34.328\n",
            "Worker 2, [06/18]: Training Loss: 2.441051518, Training Accuracy: 35.728\n",
            "Worker 2, [07/18]: Training Loss: 2.337873965, Training Accuracy: 37.968\n",
            "Worker 2, [08/18]: Training Loss: 2.228267670, Training Accuracy: 40.648\n",
            "Worker 2, [09/18]: Training Loss: 2.796208642, Training Accuracy: 29.832\n",
            "Worker 2, [10/18]: Training Loss: 2.589585541, Training Accuracy: 33.104\n",
            "Worker 2, [11/18]: Training Loss: 2.472378567, Training Accuracy: 35.912\n",
            "Worker 2, [12/18]: Training Loss: 2.318998488, Training Accuracy: 38.752\n",
            "Worker 2, [13/18]: Training Loss: 2.219879703, Training Accuracy: 40.848\n",
            "Worker 2, [14/18]: Training Loss: 2.122923315, Training Accuracy: 43.416\n",
            "Worker 2, [15/18]: Training Loss: 2.029410970, Training Accuracy: 45.216\n",
            "Worker 2, [16/18]: Training Loss: 1.957728879, Training Accuracy: 47.440\n",
            "Worker 2, [17/18]: Training Loss: 2.768888191, Training Accuracy: 35.640\n",
            "Worker 2, [18/18]: Training Loss: 2.526854219, Training Accuracy: 35.960\n",
            "Time taken for training worker 2: 0:01:31.366471\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.033391015, Training Accuracy: 25.008\n",
            "Worker 3, [02/18]: Training Loss: 2.842601672, Training Accuracy: 27.808\n",
            "Worker 3, [03/18]: Training Loss: 2.723626917, Training Accuracy: 30.352\n",
            "Worker 3, [04/18]: Training Loss: 2.614479808, Training Accuracy: 32.504\n",
            "Worker 3, [05/18]: Training Loss: 2.514406944, Training Accuracy: 34.432\n",
            "Worker 3, [06/18]: Training Loss: 2.410911145, Training Accuracy: 36.848\n",
            "Worker 3, [07/18]: Training Loss: 2.311731341, Training Accuracy: 38.472\n",
            "Worker 3, [08/18]: Training Loss: 2.211096365, Training Accuracy: 41.008\n",
            "Worker 3, [09/18]: Training Loss: 2.765143420, Training Accuracy: 30.352\n",
            "Worker 3, [10/18]: Training Loss: 2.554201828, Training Accuracy: 33.800\n",
            "Worker 3, [11/18]: Training Loss: 2.405738163, Training Accuracy: 36.880\n",
            "Worker 3, [12/18]: Training Loss: 2.290809791, Training Accuracy: 39.584\n",
            "Worker 3, [13/18]: Training Loss: 2.185957176, Training Accuracy: 41.296\n",
            "Worker 3, [14/18]: Training Loss: 2.087834715, Training Accuracy: 44.432\n",
            "Worker 3, [15/18]: Training Loss: 2.004442543, Training Accuracy: 46.504\n",
            "Worker 3, [16/18]: Training Loss: 1.942891552, Training Accuracy: 47.064\n",
            "Worker 3, [17/18]: Training Loss: 2.741684849, Training Accuracy: 36.192\n",
            "Worker 3, [18/18]: Training Loss: 2.492749416, Training Accuracy: 37.272\n",
            "Time taken for training worker 3: 0:01:31.081378\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.013089985, Training Accuracy: 25.344\n",
            "Worker 4, [02/18]: Training Loss: 2.846139598, Training Accuracy: 28.040\n",
            "Worker 4, [03/18]: Training Loss: 2.720622350, Training Accuracy: 30.640\n",
            "Worker 4, [04/18]: Training Loss: 2.603247102, Training Accuracy: 32.264\n",
            "Worker 4, [05/18]: Training Loss: 2.520659274, Training Accuracy: 34.400\n",
            "Worker 4, [06/18]: Training Loss: 2.419666467, Training Accuracy: 36.720\n",
            "Worker 4, [07/18]: Training Loss: 2.315397546, Training Accuracy: 38.488\n",
            "Worker 4, [08/18]: Training Loss: 2.218916835, Training Accuracy: 40.280\n",
            "Worker 4, [09/18]: Training Loss: 2.768193716, Training Accuracy: 30.080\n",
            "Worker 4, [10/18]: Training Loss: 2.548371128, Training Accuracy: 34.192\n",
            "Worker 4, [11/18]: Training Loss: 2.423955971, Training Accuracy: 36.672\n",
            "Worker 4, [12/18]: Training Loss: 2.298268274, Training Accuracy: 39.552\n",
            "Worker 4, [13/18]: Training Loss: 2.192140774, Training Accuracy: 41.912\n",
            "Worker 4, [14/18]: Training Loss: 2.088420019, Training Accuracy: 44.048\n",
            "Worker 4, [15/18]: Training Loss: 2.004866084, Training Accuracy: 45.896\n",
            "Worker 4, [16/18]: Training Loss: 1.926350351, Training Accuracy: 47.368\n",
            "Worker 4, [17/18]: Training Loss: 2.739224152, Training Accuracy: 36.568\n",
            "Worker 4, [18/18]: Training Loss: 2.491290410, Training Accuracy: 37.184\n",
            "Time taken for training worker 4: 0:01:31.863752\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000611\n",
            "Local Step 07: Test Loss: 2.567143721, Test Accuracy: 35.460\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 2.729250421, Training Accuracy: 31.880\n",
            "Worker 1, [02/18]: Training Loss: 2.708183039, Training Accuracy: 32.816\n",
            "Worker 1, [03/18]: Training Loss: 2.685943548, Training Accuracy: 32.752\n",
            "Worker 1, [04/18]: Training Loss: 2.649652143, Training Accuracy: 33.216\n",
            "Worker 1, [05/18]: Training Loss: 2.617908939, Training Accuracy: 34.096\n",
            "Worker 1, [06/18]: Training Loss: 2.578899465, Training Accuracy: 34.112\n",
            "Worker 1, [07/18]: Training Loss: 2.564709942, Training Accuracy: 35.024\n",
            "Worker 1, [08/18]: Training Loss: 2.553346663, Training Accuracy: 34.248\n",
            "Worker 1, [09/18]: Training Loss: 2.692616097, Training Accuracy: 31.976\n",
            "Worker 1, [10/18]: Training Loss: 2.600514549, Training Accuracy: 33.072\n",
            "Worker 1, [11/18]: Training Loss: 2.540160404, Training Accuracy: 34.136\n",
            "Worker 1, [12/18]: Training Loss: 2.490420118, Training Accuracy: 35.056\n",
            "Worker 1, [13/18]: Training Loss: 2.476078769, Training Accuracy: 35.608\n",
            "Worker 1, [14/18]: Training Loss: 2.445666936, Training Accuracy: 36.432\n",
            "Worker 1, [15/18]: Training Loss: 2.376027082, Training Accuracy: 37.328\n",
            "Worker 1, [16/18]: Training Loss: 2.394974049, Training Accuracy: 37.624\n",
            "Worker 1, [17/18]: Training Loss: 2.848487371, Training Accuracy: 28.448\n",
            "Worker 1, [18/18]: Training Loss: 2.672217825, Training Accuracy: 32.160\n",
            "Time taken for training worker 1: 0:01:33.536568\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 2.964162674, Training Accuracy: 26.976\n",
            "Worker 2, [02/18]: Training Loss: 2.779334546, Training Accuracy: 29.704\n",
            "Worker 2, [03/18]: Training Loss: 2.655910447, Training Accuracy: 32.096\n",
            "Worker 2, [04/18]: Training Loss: 2.580138758, Training Accuracy: 34.152\n",
            "Worker 2, [05/18]: Training Loss: 2.527528310, Training Accuracy: 35.032\n",
            "Worker 2, [06/18]: Training Loss: 2.494754184, Training Accuracy: 35.224\n",
            "Worker 2, [07/18]: Training Loss: 2.466116261, Training Accuracy: 36.376\n",
            "Worker 2, [08/18]: Training Loss: 2.443253973, Training Accuracy: 36.408\n",
            "Worker 2, [09/18]: Training Loss: 2.618305442, Training Accuracy: 33.320\n",
            "Worker 2, [10/18]: Training Loss: 2.539055057, Training Accuracy: 33.760\n",
            "Worker 2, [11/18]: Training Loss: 2.497178146, Training Accuracy: 34.576\n",
            "Worker 2, [12/18]: Training Loss: 2.469770424, Training Accuracy: 35.224\n",
            "Worker 2, [13/18]: Training Loss: 2.439906342, Training Accuracy: 35.880\n",
            "Worker 2, [14/18]: Training Loss: 2.419529035, Training Accuracy: 35.816\n",
            "Worker 2, [15/18]: Training Loss: 2.377381646, Training Accuracy: 37.408\n",
            "Worker 2, [16/18]: Training Loss: 2.333890920, Training Accuracy: 38.160\n",
            "Worker 2, [17/18]: Training Loss: 2.761641585, Training Accuracy: 29.928\n",
            "Worker 2, [18/18]: Training Loss: 2.665019897, Training Accuracy: 31.752\n",
            "Time taken for training worker 2: 0:01:30.950549\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 2.887485156, Training Accuracy: 27.904\n",
            "Worker 3, [02/18]: Training Loss: 2.761979654, Training Accuracy: 30.432\n",
            "Worker 3, [03/18]: Training Loss: 2.649715697, Training Accuracy: 33.032\n",
            "Worker 3, [04/18]: Training Loss: 2.574371174, Training Accuracy: 34.904\n",
            "Worker 3, [05/18]: Training Loss: 2.498828661, Training Accuracy: 35.896\n",
            "Worker 3, [06/18]: Training Loss: 2.462165663, Training Accuracy: 36.080\n",
            "Worker 3, [07/18]: Training Loss: 2.423531742, Training Accuracy: 37.112\n",
            "Worker 3, [08/18]: Training Loss: 2.395884843, Training Accuracy: 37.768\n",
            "Worker 3, [09/18]: Training Loss: 2.583605596, Training Accuracy: 34.280\n",
            "Worker 3, [10/18]: Training Loss: 2.491415338, Training Accuracy: 35.072\n",
            "Worker 3, [11/18]: Training Loss: 2.469227018, Training Accuracy: 35.032\n",
            "Worker 3, [12/18]: Training Loss: 2.455620899, Training Accuracy: 35.304\n",
            "Worker 3, [13/18]: Training Loss: 2.410477479, Training Accuracy: 36.320\n",
            "Worker 3, [14/18]: Training Loss: 2.394580098, Training Accuracy: 36.984\n",
            "Worker 3, [15/18]: Training Loss: 2.361739260, Training Accuracy: 37.384\n",
            "Worker 3, [16/18]: Training Loss: 2.345746330, Training Accuracy: 37.608\n",
            "Worker 3, [17/18]: Training Loss: 2.734394317, Training Accuracy: 30.032\n",
            "Worker 3, [18/18]: Training Loss: 2.630173804, Training Accuracy: 31.920\n",
            "Time taken for training worker 3: 0:01:33.324872\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 2.801215683, Training Accuracy: 29.352\n",
            "Worker 4, [02/18]: Training Loss: 2.730013690, Training Accuracy: 30.696\n",
            "Worker 4, [03/18]: Training Loss: 2.624582310, Training Accuracy: 33.744\n",
            "Worker 4, [04/18]: Training Loss: 2.555014774, Training Accuracy: 34.896\n",
            "Worker 4, [05/18]: Training Loss: 2.495082692, Training Accuracy: 36.168\n",
            "Worker 4, [06/18]: Training Loss: 2.450765562, Training Accuracy: 37.056\n",
            "Worker 4, [07/18]: Training Loss: 2.417648071, Training Accuracy: 37.016\n",
            "Worker 4, [08/18]: Training Loss: 2.404494754, Training Accuracy: 37.656\n",
            "Worker 4, [09/18]: Training Loss: 2.598379181, Training Accuracy: 33.896\n",
            "Worker 4, [10/18]: Training Loss: 2.501388088, Training Accuracy: 34.896\n",
            "Worker 4, [11/18]: Training Loss: 2.470792848, Training Accuracy: 35.280\n",
            "Worker 4, [12/18]: Training Loss: 2.453331523, Training Accuracy: 35.376\n",
            "Worker 4, [13/18]: Training Loss: 2.427027001, Training Accuracy: 35.704\n",
            "Worker 4, [14/18]: Training Loss: 2.401430127, Training Accuracy: 36.104\n",
            "Worker 4, [15/18]: Training Loss: 2.374687426, Training Accuracy: 37.328\n",
            "Worker 4, [16/18]: Training Loss: 2.313274806, Training Accuracy: 38.312\n",
            "Worker 4, [17/18]: Training Loss: 2.735367765, Training Accuracy: 29.544\n",
            "Worker 4, [18/18]: Training Loss: 2.622842384, Training Accuracy: 32.128\n",
            "Time taken for training worker 4: 0:01:30.087445\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000571\n",
            "Local Step 08: Test Loss: 2.701440249, Test Accuracy: 31.880\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:48:32.460759\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.593241701, Training Accuracy: 1.472\n",
            "Worker 1, [02/37]: Training Loss: 4.454843385, Training Accuracy: 3.248\n",
            "Worker 1, [03/37]: Training Loss: 4.525531088, Training Accuracy: 2.496\n",
            "Worker 1, [04/37]: Training Loss: 4.261510019, Training Accuracy: 5.248\n",
            "Worker 1, [05/37]: Training Loss: 4.424268664, Training Accuracy: 3.312\n",
            "Worker 1, [06/37]: Training Loss: 4.169102143, Training Accuracy: 5.648\n",
            "Worker 1, [07/37]: Training Loss: 4.383982780, Training Accuracy: 3.968\n",
            "Worker 1, [08/37]: Training Loss: 4.120740752, Training Accuracy: 6.416\n",
            "Worker 1, [09/37]: Training Loss: 4.310350863, Training Accuracy: 5.232\n",
            "Worker 1, [10/37]: Training Loss: 4.071221833, Training Accuracy: 7.104\n",
            "Worker 1, [11/37]: Training Loss: 4.246572212, Training Accuracy: 5.952\n",
            "Worker 1, [12/37]: Training Loss: 4.023461500, Training Accuracy: 7.856\n",
            "Worker 1, [13/37]: Training Loss: 4.189671762, Training Accuracy: 6.688\n",
            "Worker 1, [14/37]: Training Loss: 3.985058451, Training Accuracy: 8.224\n",
            "Worker 1, [15/37]: Training Loss: 4.148877424, Training Accuracy: 7.216\n",
            "Worker 1, [16/37]: Training Loss: 3.962772304, Training Accuracy: 8.960\n",
            "Worker 1, [17/37]: Training Loss: 4.114856083, Training Accuracy: 7.520\n",
            "Worker 1, [18/37]: Training Loss: 3.932437439, Training Accuracy: 9.600\n",
            "Worker 1, [19/37]: Training Loss: 4.064355726, Training Accuracy: 8.032\n",
            "Worker 1, [20/37]: Training Loss: 3.902969012, Training Accuracy: 10.000\n",
            "Worker 1, [21/37]: Training Loss: 4.025153827, Training Accuracy: 8.912\n",
            "Worker 1, [22/37]: Training Loss: 3.884722968, Training Accuracy: 10.128\n",
            "Worker 1, [23/37]: Training Loss: 3.999648583, Training Accuracy: 9.264\n",
            "Worker 1, [24/37]: Training Loss: 3.855219666, Training Accuracy: 10.992\n",
            "Worker 1, [25/37]: Training Loss: 3.960899234, Training Accuracy: 10.272\n",
            "Worker 1, [26/37]: Training Loss: 3.845059414, Training Accuracy: 11.040\n",
            "Worker 1, [27/37]: Training Loss: 3.937311469, Training Accuracy: 10.272\n",
            "Worker 1, [28/37]: Training Loss: 3.830092221, Training Accuracy: 11.392\n",
            "Worker 1, [29/37]: Training Loss: 3.920138765, Training Accuracy: 10.480\n",
            "Worker 1, [30/37]: Training Loss: 3.824995146, Training Accuracy: 11.712\n",
            "Worker 1, [31/37]: Training Loss: 3.913320836, Training Accuracy: 10.944\n",
            "Worker 1, [32/37]: Training Loss: 3.829230440, Training Accuracy: 11.744\n",
            "Worker 1, [33/37]: Training Loss: 3.916640569, Training Accuracy: 12.080\n",
            "Worker 1, [34/37]: Training Loss: 3.837308266, Training Accuracy: 11.904\n",
            "Worker 1, [35/37]: Training Loss: 3.932162781, Training Accuracy: 12.384\n",
            "Worker 1, [36/37]: Training Loss: 3.882128477, Training Accuracy: 11.824\n",
            "Worker 1, [37/37]: Training Loss: 3.952189562, Training Accuracy: 11.856\n",
            "Time taken for training worker 1: 0:01:36.737411\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.594518301, Training Accuracy: 1.568\n",
            "Worker 2, [02/37]: Training Loss: 4.428802928, Training Accuracy: 3.760\n",
            "Worker 2, [03/37]: Training Loss: 4.517606910, Training Accuracy: 2.656\n",
            "Worker 2, [04/37]: Training Loss: 4.205910853, Training Accuracy: 4.976\n",
            "Worker 2, [05/37]: Training Loss: 4.440367163, Training Accuracy: 3.712\n",
            "Worker 2, [06/37]: Training Loss: 4.151823207, Training Accuracy: 6.176\n",
            "Worker 2, [07/37]: Training Loss: 4.343712067, Training Accuracy: 4.432\n",
            "Worker 2, [08/37]: Training Loss: 4.091139854, Training Accuracy: 6.896\n",
            "Worker 2, [09/37]: Training Loss: 4.305880405, Training Accuracy: 4.896\n",
            "Worker 2, [10/37]: Training Loss: 4.062933752, Training Accuracy: 7.120\n",
            "Worker 2, [11/37]: Training Loss: 4.231326249, Training Accuracy: 5.760\n",
            "Worker 2, [12/37]: Training Loss: 4.014194491, Training Accuracy: 7.568\n",
            "Worker 2, [13/37]: Training Loss: 4.188181391, Training Accuracy: 6.416\n",
            "Worker 2, [14/37]: Training Loss: 3.984476389, Training Accuracy: 8.192\n",
            "Worker 2, [15/37]: Training Loss: 4.140088872, Training Accuracy: 7.248\n",
            "Worker 2, [16/37]: Training Loss: 3.938062529, Training Accuracy: 9.248\n",
            "Worker 2, [17/37]: Training Loss: 4.095032787, Training Accuracy: 7.232\n",
            "Worker 2, [18/37]: Training Loss: 3.926498695, Training Accuracy: 9.216\n",
            "Worker 2, [19/37]: Training Loss: 4.056951623, Training Accuracy: 8.096\n",
            "Worker 2, [20/37]: Training Loss: 3.882228766, Training Accuracy: 9.600\n",
            "Worker 2, [21/37]: Training Loss: 4.022647575, Training Accuracy: 9.040\n",
            "Worker 2, [22/37]: Training Loss: 3.877432867, Training Accuracy: 9.776\n",
            "Worker 2, [23/37]: Training Loss: 3.992873233, Training Accuracy: 9.024\n",
            "Worker 2, [24/37]: Training Loss: 3.840213708, Training Accuracy: 10.544\n",
            "Worker 2, [25/37]: Training Loss: 3.965302492, Training Accuracy: 9.696\n",
            "Worker 2, [26/37]: Training Loss: 3.822774894, Training Accuracy: 11.088\n",
            "Worker 2, [27/37]: Training Loss: 3.927570401, Training Accuracy: 10.240\n",
            "Worker 2, [28/37]: Training Loss: 3.813714290, Training Accuracy: 11.184\n",
            "Worker 2, [29/37]: Training Loss: 3.909644918, Training Accuracy: 10.592\n",
            "Worker 2, [30/37]: Training Loss: 3.802573129, Training Accuracy: 11.440\n",
            "Worker 2, [31/37]: Training Loss: 3.903389250, Training Accuracy: 11.120\n",
            "Worker 2, [32/37]: Training Loss: 3.811024586, Training Accuracy: 11.232\n",
            "Worker 2, [33/37]: Training Loss: 3.903997419, Training Accuracy: 11.120\n",
            "Worker 2, [34/37]: Training Loss: 3.816855372, Training Accuracy: 11.488\n",
            "Worker 2, [35/37]: Training Loss: 3.924285035, Training Accuracy: 11.968\n",
            "Worker 2, [36/37]: Training Loss: 3.872637308, Training Accuracy: 12.112\n",
            "Worker 2, [37/37]: Training Loss: 3.944907624, Training Accuracy: 12.112\n",
            "Time taken for training worker 2: 0:01:37.913704\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.592322496, Training Accuracy: 1.728\n",
            "Worker 3, [02/37]: Training Loss: 4.441091800, Training Accuracy: 3.248\n",
            "Worker 3, [03/37]: Training Loss: 4.536627954, Training Accuracy: 2.256\n",
            "Worker 3, [04/37]: Training Loss: 4.263556052, Training Accuracy: 5.216\n",
            "Worker 3, [05/37]: Training Loss: 4.427201446, Training Accuracy: 3.712\n",
            "Worker 3, [06/37]: Training Loss: 4.174011873, Training Accuracy: 6.096\n",
            "Worker 3, [07/37]: Training Loss: 4.387171351, Training Accuracy: 4.016\n",
            "Worker 3, [08/37]: Training Loss: 4.130983963, Training Accuracy: 6.496\n",
            "Worker 3, [09/37]: Training Loss: 4.326646834, Training Accuracy: 5.408\n",
            "Worker 3, [10/37]: Training Loss: 4.082774367, Training Accuracy: 7.136\n",
            "Worker 3, [11/37]: Training Loss: 4.255709308, Training Accuracy: 5.104\n",
            "Worker 3, [12/37]: Training Loss: 4.048254088, Training Accuracy: 6.944\n",
            "Worker 3, [13/37]: Training Loss: 4.209082961, Training Accuracy: 6.064\n",
            "Worker 3, [14/37]: Training Loss: 4.016436506, Training Accuracy: 8.016\n",
            "Worker 3, [15/37]: Training Loss: 4.177512906, Training Accuracy: 6.640\n",
            "Worker 3, [16/37]: Training Loss: 3.991616884, Training Accuracy: 8.160\n",
            "Worker 3, [17/37]: Training Loss: 4.121167850, Training Accuracy: 7.056\n",
            "Worker 3, [18/37]: Training Loss: 3.949038564, Training Accuracy: 8.560\n",
            "Worker 3, [19/37]: Training Loss: 4.086909873, Training Accuracy: 8.000\n",
            "Worker 3, [20/37]: Training Loss: 3.918375013, Training Accuracy: 9.632\n",
            "Worker 3, [21/37]: Training Loss: 4.041844317, Training Accuracy: 8.608\n",
            "Worker 3, [22/37]: Training Loss: 3.905730423, Training Accuracy: 9.712\n",
            "Worker 3, [23/37]: Training Loss: 4.022950810, Training Accuracy: 9.024\n",
            "Worker 3, [24/37]: Training Loss: 3.881458227, Training Accuracy: 10.448\n",
            "Worker 3, [25/37]: Training Loss: 3.989592572, Training Accuracy: 10.128\n",
            "Worker 3, [26/37]: Training Loss: 3.872110746, Training Accuracy: 10.416\n",
            "Worker 3, [27/37]: Training Loss: 3.967860869, Training Accuracy: 10.096\n",
            "Worker 3, [28/37]: Training Loss: 3.854778365, Training Accuracy: 10.624\n",
            "Worker 3, [29/37]: Training Loss: 3.941850918, Training Accuracy: 10.432\n",
            "Worker 3, [30/37]: Training Loss: 3.839256678, Training Accuracy: 11.408\n",
            "Worker 3, [31/37]: Training Loss: 3.942118253, Training Accuracy: 10.480\n",
            "Worker 3, [32/37]: Training Loss: 3.839579159, Training Accuracy: 11.360\n",
            "Worker 3, [33/37]: Training Loss: 3.942615217, Training Accuracy: 11.024\n",
            "Worker 3, [34/37]: Training Loss: 3.864186248, Training Accuracy: 11.056\n",
            "Worker 3, [35/37]: Training Loss: 3.961463055, Training Accuracy: 11.216\n",
            "Worker 3, [36/37]: Training Loss: 3.907771069, Training Accuracy: 11.248\n",
            "Worker 3, [37/37]: Training Loss: 3.971130648, Training Accuracy: 11.552\n",
            "Time taken for training worker 3: 0:01:36.674250\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.595668146, Training Accuracy: 1.776\n",
            "Worker 4, [02/37]: Training Loss: 4.460203628, Training Accuracy: 3.888\n",
            "Worker 4, [03/37]: Training Loss: 4.500322828, Training Accuracy: 2.752\n",
            "Worker 4, [04/37]: Training Loss: 4.201170656, Training Accuracy: 6.144\n",
            "Worker 4, [05/37]: Training Loss: 4.443720511, Training Accuracy: 3.648\n",
            "Worker 4, [06/37]: Training Loss: 4.176867828, Training Accuracy: 6.096\n",
            "Worker 4, [07/37]: Training Loss: 4.352140845, Training Accuracy: 4.688\n",
            "Worker 4, [08/37]: Training Loss: 4.106003520, Training Accuracy: 7.008\n",
            "Worker 4, [09/37]: Training Loss: 4.293706811, Training Accuracy: 5.232\n",
            "Worker 4, [10/37]: Training Loss: 4.068908764, Training Accuracy: 6.976\n",
            "Worker 4, [11/37]: Training Loss: 4.242622193, Training Accuracy: 6.016\n",
            "Worker 4, [12/37]: Training Loss: 4.037784156, Training Accuracy: 7.968\n",
            "Worker 4, [13/37]: Training Loss: 4.209102679, Training Accuracy: 6.368\n",
            "Worker 4, [14/37]: Training Loss: 4.002823603, Training Accuracy: 8.400\n",
            "Worker 4, [15/37]: Training Loss: 4.141114208, Training Accuracy: 7.216\n",
            "Worker 4, [16/37]: Training Loss: 3.955732993, Training Accuracy: 8.848\n",
            "Worker 4, [17/37]: Training Loss: 4.104036017, Training Accuracy: 7.984\n",
            "Worker 4, [18/37]: Training Loss: 3.924579146, Training Accuracy: 9.872\n",
            "Worker 4, [19/37]: Training Loss: 4.076980214, Training Accuracy: 8.128\n",
            "Worker 4, [20/37]: Training Loss: 3.899694333, Training Accuracy: 10.096\n",
            "Worker 4, [21/37]: Training Loss: 4.037976204, Training Accuracy: 8.768\n",
            "Worker 4, [22/37]: Training Loss: 3.885465354, Training Accuracy: 10.320\n",
            "Worker 4, [23/37]: Training Loss: 4.004412544, Training Accuracy: 8.944\n",
            "Worker 4, [24/37]: Training Loss: 3.848354705, Training Accuracy: 10.576\n",
            "Worker 4, [25/37]: Training Loss: 3.967386849, Training Accuracy: 9.904\n",
            "Worker 4, [26/37]: Training Loss: 3.850537770, Training Accuracy: 10.528\n",
            "Worker 4, [27/37]: Training Loss: 3.937643978, Training Accuracy: 10.304\n",
            "Worker 4, [28/37]: Training Loss: 3.834634039, Training Accuracy: 10.912\n",
            "Worker 4, [29/37]: Training Loss: 3.925620008, Training Accuracy: 10.192\n",
            "Worker 4, [30/37]: Training Loss: 3.823344116, Training Accuracy: 11.408\n",
            "Worker 4, [31/37]: Training Loss: 3.924647492, Training Accuracy: 11.152\n",
            "Worker 4, [32/37]: Training Loss: 3.826359666, Training Accuracy: 11.856\n",
            "Worker 4, [33/37]: Training Loss: 3.919422286, Training Accuracy: 11.392\n",
            "Worker 4, [34/37]: Training Loss: 3.842471468, Training Accuracy: 11.792\n",
            "Worker 4, [35/37]: Training Loss: 3.941557480, Training Accuracy: 11.552\n",
            "Worker 4, [36/37]: Training Loss: 3.891044546, Training Accuracy: 11.920\n",
            "Worker 4, [37/37]: Training Loss: 3.959225715, Training Accuracy: 11.872\n",
            "Time taken for training worker 4: 0:01:37.363639\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 4.594029222, Training Accuracy: 1.648\n",
            "Worker 5, [02/37]: Training Loss: 4.435444165, Training Accuracy: 3.488\n",
            "Worker 5, [03/37]: Training Loss: 4.520361423, Training Accuracy: 2.304\n",
            "Worker 5, [04/37]: Training Loss: 4.221939262, Training Accuracy: 5.184\n",
            "Worker 5, [05/37]: Training Loss: 4.429893372, Training Accuracy: 3.968\n",
            "Worker 5, [06/37]: Training Loss: 4.148869719, Training Accuracy: 6.192\n",
            "Worker 5, [07/37]: Training Loss: 4.357900804, Training Accuracy: 4.672\n",
            "Worker 5, [08/37]: Training Loss: 4.097691563, Training Accuracy: 6.720\n",
            "Worker 5, [09/37]: Training Loss: 4.282301080, Training Accuracy: 5.408\n",
            "Worker 5, [10/37]: Training Loss: 4.053541164, Training Accuracy: 7.456\n",
            "Worker 5, [11/37]: Training Loss: 4.228291794, Training Accuracy: 6.416\n",
            "Worker 5, [12/37]: Training Loss: 4.009898835, Training Accuracy: 8.288\n",
            "Worker 5, [13/37]: Training Loss: 4.193501234, Training Accuracy: 6.272\n",
            "Worker 5, [14/37]: Training Loss: 3.989993365, Training Accuracy: 8.000\n",
            "Worker 5, [15/37]: Training Loss: 4.132989944, Training Accuracy: 7.600\n",
            "Worker 5, [16/37]: Training Loss: 3.948697243, Training Accuracy: 8.848\n",
            "Worker 5, [17/37]: Training Loss: 4.089116678, Training Accuracy: 6.992\n",
            "Worker 5, [18/37]: Training Loss: 3.936438801, Training Accuracy: 9.120\n",
            "Worker 5, [19/37]: Training Loss: 4.062469728, Training Accuracy: 8.400\n",
            "Worker 5, [20/37]: Training Loss: 3.896915908, Training Accuracy: 10.192\n",
            "Worker 5, [21/37]: Training Loss: 4.015002664, Training Accuracy: 8.944\n",
            "Worker 5, [22/37]: Training Loss: 3.883770373, Training Accuracy: 9.744\n",
            "Worker 5, [23/37]: Training Loss: 3.983841804, Training Accuracy: 9.360\n",
            "Worker 5, [24/37]: Training Loss: 3.851042110, Training Accuracy: 10.704\n",
            "Worker 5, [25/37]: Training Loss: 3.955889906, Training Accuracy: 9.680\n",
            "Worker 5, [26/37]: Training Loss: 3.839519708, Training Accuracy: 11.056\n",
            "Worker 5, [27/37]: Training Loss: 3.936638513, Training Accuracy: 9.920\n",
            "Worker 5, [28/37]: Training Loss: 3.827559471, Training Accuracy: 11.104\n",
            "Worker 5, [29/37]: Training Loss: 3.916647274, Training Accuracy: 11.056\n",
            "Worker 5, [30/37]: Training Loss: 3.815487339, Training Accuracy: 11.712\n",
            "Worker 5, [31/37]: Training Loss: 3.912245641, Training Accuracy: 11.072\n",
            "Worker 5, [32/37]: Training Loss: 3.822040709, Training Accuracy: 11.136\n",
            "Worker 5, [33/37]: Training Loss: 3.919470612, Training Accuracy: 11.456\n",
            "Worker 5, [34/37]: Training Loss: 3.830630395, Training Accuracy: 12.016\n",
            "Worker 5, [35/37]: Training Loss: 3.935691512, Training Accuracy: 11.824\n",
            "Worker 5, [36/37]: Training Loss: 3.886728661, Training Accuracy: 11.520\n",
            "Worker 5, [37/37]: Training Loss: 3.948947719, Training Accuracy: 11.872\n",
            "Time taken for training worker 5: 0:01:38.285519\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 4.595737224, Training Accuracy: 1.552\n",
            "Worker 6, [02/37]: Training Loss: 4.455046522, Training Accuracy: 3.232\n",
            "Worker 6, [03/37]: Training Loss: 4.507549412, Training Accuracy: 2.480\n",
            "Worker 6, [04/37]: Training Loss: 4.226083595, Training Accuracy: 5.296\n",
            "Worker 6, [05/37]: Training Loss: 4.436264087, Training Accuracy: 3.792\n",
            "Worker 6, [06/37]: Training Loss: 4.153915335, Training Accuracy: 6.080\n",
            "Worker 6, [07/37]: Training Loss: 4.399896422, Training Accuracy: 3.584\n",
            "Worker 6, [08/37]: Training Loss: 4.111118455, Training Accuracy: 6.352\n",
            "Worker 6, [09/37]: Training Loss: 4.287183404, Training Accuracy: 5.264\n",
            "Worker 6, [10/37]: Training Loss: 4.052689545, Training Accuracy: 7.408\n",
            "Worker 6, [11/37]: Training Loss: 4.240044117, Training Accuracy: 5.680\n",
            "Worker 6, [12/37]: Training Loss: 4.030504662, Training Accuracy: 7.152\n",
            "Worker 6, [13/37]: Training Loss: 4.189594950, Training Accuracy: 5.936\n",
            "Worker 6, [14/37]: Training Loss: 3.998266315, Training Accuracy: 7.968\n",
            "Worker 6, [15/37]: Training Loss: 4.148049637, Training Accuracy: 6.448\n",
            "Worker 6, [16/37]: Training Loss: 3.954351423, Training Accuracy: 8.960\n",
            "Worker 6, [17/37]: Training Loss: 4.112966233, Training Accuracy: 7.200\n",
            "Worker 6, [18/37]: Training Loss: 3.943740144, Training Accuracy: 8.800\n",
            "Worker 6, [19/37]: Training Loss: 4.081498791, Training Accuracy: 8.048\n",
            "Worker 6, [20/37]: Training Loss: 3.903176536, Training Accuracy: 9.488\n",
            "Worker 6, [21/37]: Training Loss: 4.023445947, Training Accuracy: 7.952\n",
            "Worker 6, [22/37]: Training Loss: 3.881704739, Training Accuracy: 9.920\n",
            "Worker 6, [23/37]: Training Loss: 3.988382940, Training Accuracy: 8.528\n",
            "Worker 6, [24/37]: Training Loss: 3.862647911, Training Accuracy: 10.960\n",
            "Worker 6, [25/37]: Training Loss: 3.962791107, Training Accuracy: 9.664\n",
            "Worker 6, [26/37]: Training Loss: 3.853694101, Training Accuracy: 10.608\n",
            "Worker 6, [27/37]: Training Loss: 3.948719983, Training Accuracy: 9.984\n",
            "Worker 6, [28/37]: Training Loss: 3.846567889, Training Accuracy: 10.912\n",
            "Worker 6, [29/37]: Training Loss: 3.920471581, Training Accuracy: 10.672\n",
            "Worker 6, [30/37]: Training Loss: 3.828576025, Training Accuracy: 11.136\n",
            "Worker 6, [31/37]: Training Loss: 3.921936904, Training Accuracy: 10.528\n",
            "Worker 6, [32/37]: Training Loss: 3.834884223, Training Accuracy: 11.136\n",
            "Worker 6, [33/37]: Training Loss: 3.922047978, Training Accuracy: 11.136\n",
            "Worker 6, [34/37]: Training Loss: 3.842403227, Training Accuracy: 11.456\n",
            "Worker 6, [35/37]: Training Loss: 3.933102486, Training Accuracy: 11.584\n",
            "Worker 6, [36/37]: Training Loss: 3.892875309, Training Accuracy: 11.632\n",
            "Worker 6, [37/37]: Training Loss: 3.956457997, Training Accuracy: 12.240\n",
            "Time taken for training worker 6: 0:01:39.433772\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 4.594519197, Training Accuracy: 1.408\n",
            "Worker 7, [02/37]: Training Loss: 4.440331659, Training Accuracy: 3.072\n",
            "Worker 7, [03/37]: Training Loss: 4.512435217, Training Accuracy: 2.512\n",
            "Worker 7, [04/37]: Training Loss: 4.222057780, Training Accuracy: 4.800\n",
            "Worker 7, [05/37]: Training Loss: 4.444152102, Training Accuracy: 3.152\n",
            "Worker 7, [06/37]: Training Loss: 4.170283670, Training Accuracy: 5.488\n",
            "Worker 7, [07/37]: Training Loss: 4.359511288, Training Accuracy: 4.064\n",
            "Worker 7, [08/37]: Training Loss: 4.113047770, Training Accuracy: 5.984\n",
            "Worker 7, [09/37]: Training Loss: 4.300548931, Training Accuracy: 4.832\n",
            "Worker 7, [10/37]: Training Loss: 4.056498423, Training Accuracy: 7.104\n",
            "Worker 7, [11/37]: Training Loss: 4.221628997, Training Accuracy: 6.128\n",
            "Worker 7, [12/37]: Training Loss: 3.997904121, Training Accuracy: 7.840\n",
            "Worker 7, [13/37]: Training Loss: 4.188356971, Training Accuracy: 6.512\n",
            "Worker 7, [14/37]: Training Loss: 3.989970927, Training Accuracy: 8.208\n",
            "Worker 7, [15/37]: Training Loss: 4.142991647, Training Accuracy: 6.768\n",
            "Worker 7, [16/37]: Training Loss: 3.934225725, Training Accuracy: 9.264\n",
            "Worker 7, [17/37]: Training Loss: 4.093209483, Training Accuracy: 7.696\n",
            "Worker 7, [18/37]: Training Loss: 3.903159682, Training Accuracy: 10.176\n",
            "Worker 7, [19/37]: Training Loss: 4.062724082, Training Accuracy: 7.616\n",
            "Worker 7, [20/37]: Training Loss: 3.880357881, Training Accuracy: 10.064\n",
            "Worker 7, [21/37]: Training Loss: 4.020162079, Training Accuracy: 8.880\n",
            "Worker 7, [22/37]: Training Loss: 3.875071752, Training Accuracy: 9.440\n",
            "Worker 7, [23/37]: Training Loss: 3.981590089, Training Accuracy: 9.184\n",
            "Worker 7, [24/37]: Training Loss: 3.836267320, Training Accuracy: 11.088\n",
            "Worker 7, [25/37]: Training Loss: 3.948691139, Training Accuracy: 10.016\n",
            "Worker 7, [26/37]: Training Loss: 3.826548333, Training Accuracy: 11.152\n",
            "Worker 7, [27/37]: Training Loss: 3.924371199, Training Accuracy: 10.448\n",
            "Worker 7, [28/37]: Training Loss: 3.813519908, Training Accuracy: 11.040\n",
            "Worker 7, [29/37]: Training Loss: 3.909465026, Training Accuracy: 10.864\n",
            "Worker 7, [30/37]: Training Loss: 3.809758040, Training Accuracy: 11.456\n",
            "Worker 7, [31/37]: Training Loss: 3.895932599, Training Accuracy: 11.792\n",
            "Worker 7, [32/37]: Training Loss: 3.805507013, Training Accuracy: 11.392\n",
            "Worker 7, [33/37]: Training Loss: 3.903861024, Training Accuracy: 11.568\n",
            "Worker 7, [34/37]: Training Loss: 3.819706245, Training Accuracy: 11.856\n",
            "Worker 7, [35/37]: Training Loss: 3.924322807, Training Accuracy: 11.696\n",
            "Worker 7, [36/37]: Training Loss: 3.876207987, Training Accuracy: 11.600\n",
            "Worker 7, [37/37]: Training Loss: 3.937542305, Training Accuracy: 12.512\n",
            "Time taken for training worker 7: 0:01:38.791274\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 4.591849337, Training Accuracy: 1.728\n",
            "Worker 8, [02/37]: Training Loss: 4.443335266, Training Accuracy: 2.944\n",
            "Worker 8, [03/37]: Training Loss: 4.512972515, Training Accuracy: 2.704\n",
            "Worker 8, [04/37]: Training Loss: 4.205369407, Training Accuracy: 5.136\n",
            "Worker 8, [05/37]: Training Loss: 4.421455524, Training Accuracy: 3.392\n",
            "Worker 8, [06/37]: Training Loss: 4.142578300, Training Accuracy: 6.048\n",
            "Worker 8, [07/37]: Training Loss: 4.359921115, Training Accuracy: 4.256\n",
            "Worker 8, [08/37]: Training Loss: 4.113407641, Training Accuracy: 6.416\n",
            "Worker 8, [09/37]: Training Loss: 4.303193900, Training Accuracy: 5.104\n",
            "Worker 8, [10/37]: Training Loss: 4.068800795, Training Accuracy: 6.912\n",
            "Worker 8, [11/37]: Training Loss: 4.238817650, Training Accuracy: 6.064\n",
            "Worker 8, [12/37]: Training Loss: 4.025690480, Training Accuracy: 7.280\n",
            "Worker 8, [13/37]: Training Loss: 4.183071073, Training Accuracy: 6.320\n",
            "Worker 8, [14/37]: Training Loss: 3.994237287, Training Accuracy: 7.824\n",
            "Worker 8, [15/37]: Training Loss: 4.155636612, Training Accuracy: 6.544\n",
            "Worker 8, [16/37]: Training Loss: 3.961318872, Training Accuracy: 8.192\n",
            "Worker 8, [17/37]: Training Loss: 4.101147674, Training Accuracy: 6.688\n",
            "Worker 8, [18/37]: Training Loss: 3.926869190, Training Accuracy: 9.040\n",
            "Worker 8, [19/37]: Training Loss: 4.053178233, Training Accuracy: 7.568\n",
            "Worker 8, [20/37]: Training Loss: 3.904094134, Training Accuracy: 9.168\n",
            "Worker 8, [21/37]: Training Loss: 4.020043877, Training Accuracy: 8.096\n",
            "Worker 8, [22/37]: Training Loss: 3.882971980, Training Accuracy: 9.264\n",
            "Worker 8, [23/37]: Training Loss: 3.994250395, Training Accuracy: 8.896\n",
            "Worker 8, [24/37]: Training Loss: 3.865312654, Training Accuracy: 9.984\n",
            "Worker 8, [25/37]: Training Loss: 3.968118478, Training Accuracy: 9.072\n",
            "Worker 8, [26/37]: Training Loss: 3.847663802, Training Accuracy: 10.128\n",
            "Worker 8, [27/37]: Training Loss: 3.939355473, Training Accuracy: 9.392\n",
            "Worker 8, [28/37]: Training Loss: 3.833358071, Training Accuracy: 10.288\n",
            "Worker 8, [29/37]: Training Loss: 3.925306688, Training Accuracy: 10.128\n",
            "Worker 8, [30/37]: Training Loss: 3.823803495, Training Accuracy: 10.912\n",
            "Worker 8, [31/37]: Training Loss: 3.923632125, Training Accuracy: 10.512\n",
            "Worker 8, [32/37]: Training Loss: 3.829287483, Training Accuracy: 10.576\n",
            "Worker 8, [33/37]: Training Loss: 3.921535528, Training Accuracy: 11.072\n",
            "Worker 8, [34/37]: Training Loss: 3.844059438, Training Accuracy: 10.832\n",
            "Worker 8, [35/37]: Training Loss: 3.933838409, Training Accuracy: 11.152\n",
            "Worker 8, [36/37]: Training Loss: 3.890866873, Training Accuracy: 10.752\n",
            "Worker 8, [37/37]: Training Loss: 3.955031643, Training Accuracy: 11.072\n",
            "Time taken for training worker 8: 0:01:35.217041\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000770\n",
            "Local Step 01: Test Loss: 4.074596996, Test Accuracy: 11.030\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 4.104657879, Training Accuracy: 10.240\n",
            "Worker 1, [02/37]: Training Loss: 4.104595625, Training Accuracy: 9.872\n",
            "Worker 1, [03/37]: Training Loss: 3.957433460, Training Accuracy: 11.952\n",
            "Worker 1, [04/37]: Training Loss: 3.916078711, Training Accuracy: 11.696\n",
            "Worker 1, [05/37]: Training Loss: 3.918474847, Training Accuracy: 11.968\n",
            "Worker 1, [06/37]: Training Loss: 3.849764931, Training Accuracy: 12.064\n",
            "Worker 1, [07/37]: Training Loss: 3.892802190, Training Accuracy: 11.520\n",
            "Worker 1, [08/37]: Training Loss: 3.828454383, Training Accuracy: 11.680\n",
            "Worker 1, [09/37]: Training Loss: 3.869038319, Training Accuracy: 11.008\n",
            "Worker 1, [10/37]: Training Loss: 3.823076263, Training Accuracy: 11.248\n",
            "Worker 1, [11/37]: Training Loss: 3.857805799, Training Accuracy: 11.264\n",
            "Worker 1, [12/37]: Training Loss: 3.808007564, Training Accuracy: 12.160\n",
            "Worker 1, [13/37]: Training Loss: 3.867860906, Training Accuracy: 11.040\n",
            "Worker 1, [14/37]: Training Loss: 3.806644286, Training Accuracy: 12.144\n",
            "Worker 1, [15/37]: Training Loss: 3.863949871, Training Accuracy: 10.672\n",
            "Worker 1, [16/37]: Training Loss: 3.789586860, Training Accuracy: 12.208\n",
            "Worker 1, [17/37]: Training Loss: 3.867662537, Training Accuracy: 10.640\n",
            "Worker 1, [18/37]: Training Loss: 3.788437539, Training Accuracy: 11.680\n",
            "Worker 1, [19/37]: Training Loss: 3.854826961, Training Accuracy: 10.848\n",
            "Worker 1, [20/37]: Training Loss: 3.784689054, Training Accuracy: 12.320\n",
            "Worker 1, [21/37]: Training Loss: 3.851683748, Training Accuracy: 10.704\n",
            "Worker 1, [22/37]: Training Loss: 3.776253423, Training Accuracy: 11.376\n",
            "Worker 1, [23/37]: Training Loss: 3.833599528, Training Accuracy: 10.896\n",
            "Worker 1, [24/37]: Training Loss: 3.761607384, Training Accuracy: 11.808\n",
            "Worker 1, [25/37]: Training Loss: 3.832676610, Training Accuracy: 10.608\n",
            "Worker 1, [26/37]: Training Loss: 3.740195620, Training Accuracy: 12.288\n",
            "Worker 1, [27/37]: Training Loss: 3.819055582, Training Accuracy: 11.216\n",
            "Worker 1, [28/37]: Training Loss: 3.732322189, Training Accuracy: 12.240\n",
            "Worker 1, [29/37]: Training Loss: 3.803412931, Training Accuracy: 11.008\n",
            "Worker 1, [30/37]: Training Loss: 3.697916787, Training Accuracy: 12.752\n",
            "Worker 1, [31/37]: Training Loss: 3.773378652, Training Accuracy: 12.176\n",
            "Worker 1, [32/37]: Training Loss: 3.680400532, Training Accuracy: 13.392\n",
            "Worker 1, [33/37]: Training Loss: 3.779841530, Training Accuracy: 11.712\n",
            "Worker 1, [34/37]: Training Loss: 3.681568798, Training Accuracy: 13.280\n",
            "Worker 1, [35/37]: Training Loss: 3.757233396, Training Accuracy: 12.112\n",
            "Worker 1, [36/37]: Training Loss: 3.641662230, Training Accuracy: 14.368\n",
            "Worker 1, [37/37]: Training Loss: 3.704347435, Training Accuracy: 13.344\n",
            "Time taken for training worker 1: 0:01:38.351021\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.765234925, Training Accuracy: 12.336\n",
            "Worker 2, [02/37]: Training Loss: 3.758370930, Training Accuracy: 12.384\n",
            "Worker 2, [03/37]: Training Loss: 3.922734630, Training Accuracy: 12.416\n",
            "Worker 2, [04/37]: Training Loss: 3.865038473, Training Accuracy: 12.352\n",
            "Worker 2, [05/37]: Training Loss: 3.873226718, Training Accuracy: 11.872\n",
            "Worker 2, [06/37]: Training Loss: 3.801246585, Training Accuracy: 12.016\n",
            "Worker 2, [07/37]: Training Loss: 3.840175984, Training Accuracy: 11.424\n",
            "Worker 2, [08/37]: Training Loss: 3.784032758, Training Accuracy: 12.352\n",
            "Worker 2, [09/37]: Training Loss: 3.830775052, Training Accuracy: 11.456\n",
            "Worker 2, [10/37]: Training Loss: 3.768814148, Training Accuracy: 12.176\n",
            "Worker 2, [11/37]: Training Loss: 3.819304666, Training Accuracy: 11.216\n",
            "Worker 2, [12/37]: Training Loss: 3.759088387, Training Accuracy: 12.096\n",
            "Worker 2, [13/37]: Training Loss: 3.821275412, Training Accuracy: 10.976\n",
            "Worker 2, [14/37]: Training Loss: 3.753967064, Training Accuracy: 11.488\n",
            "Worker 2, [15/37]: Training Loss: 3.821308751, Training Accuracy: 10.944\n",
            "Worker 2, [16/37]: Training Loss: 3.737599940, Training Accuracy: 11.872\n",
            "Worker 2, [17/37]: Training Loss: 3.811807462, Training Accuracy: 10.880\n",
            "Worker 2, [18/37]: Training Loss: 3.731408861, Training Accuracy: 11.840\n",
            "Worker 2, [19/37]: Training Loss: 3.805775185, Training Accuracy: 11.440\n",
            "Worker 2, [20/37]: Training Loss: 3.716375602, Training Accuracy: 12.720\n",
            "Worker 2, [21/37]: Training Loss: 3.795654314, Training Accuracy: 11.152\n",
            "Worker 2, [22/37]: Training Loss: 3.701115920, Training Accuracy: 13.024\n",
            "Worker 2, [23/37]: Training Loss: 3.789748131, Training Accuracy: 11.024\n",
            "Worker 2, [24/37]: Training Loss: 3.699941518, Training Accuracy: 12.512\n",
            "Worker 2, [25/37]: Training Loss: 3.768076284, Training Accuracy: 11.568\n",
            "Worker 2, [26/37]: Training Loss: 3.678560383, Training Accuracy: 12.320\n",
            "Worker 2, [27/37]: Training Loss: 3.773303227, Training Accuracy: 11.392\n",
            "Worker 2, [28/37]: Training Loss: 3.652828781, Training Accuracy: 13.168\n",
            "Worker 2, [29/37]: Training Loss: 3.736766027, Training Accuracy: 12.144\n",
            "Worker 2, [30/37]: Training Loss: 3.655398354, Training Accuracy: 12.576\n",
            "Worker 2, [31/37]: Training Loss: 3.744310652, Training Accuracy: 11.920\n",
            "Worker 2, [32/37]: Training Loss: 3.617753618, Training Accuracy: 13.904\n",
            "Worker 2, [33/37]: Training Loss: 3.707019154, Training Accuracy: 12.336\n",
            "Worker 2, [34/37]: Training Loss: 3.593849068, Training Accuracy: 14.160\n",
            "Worker 2, [35/37]: Training Loss: 3.685638282, Training Accuracy: 12.608\n",
            "Worker 2, [36/37]: Training Loss: 3.583895798, Training Accuracy: 14.832\n",
            "Worker 2, [37/37]: Training Loss: 3.677733341, Training Accuracy: 13.216\n",
            "Time taken for training worker 2: 0:01:37.088181\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.778459972, Training Accuracy: 12.848\n",
            "Worker 3, [02/37]: Training Loss: 3.768848336, Training Accuracy: 12.944\n",
            "Worker 3, [03/37]: Training Loss: 3.957432878, Training Accuracy: 11.776\n",
            "Worker 3, [04/37]: Training Loss: 3.911114209, Training Accuracy: 11.376\n",
            "Worker 3, [05/37]: Training Loss: 3.911247611, Training Accuracy: 11.360\n",
            "Worker 3, [06/37]: Training Loss: 3.847509039, Training Accuracy: 11.008\n",
            "Worker 3, [07/37]: Training Loss: 3.875295586, Training Accuracy: 11.520\n",
            "Worker 3, [08/37]: Training Loss: 3.808646886, Training Accuracy: 11.920\n",
            "Worker 3, [09/37]: Training Loss: 3.858535793, Training Accuracy: 11.072\n",
            "Worker 3, [10/37]: Training Loss: 3.814984923, Training Accuracy: 11.504\n",
            "Worker 3, [11/37]: Training Loss: 3.856625790, Training Accuracy: 10.880\n",
            "Worker 3, [12/37]: Training Loss: 3.805232853, Training Accuracy: 11.616\n",
            "Worker 3, [13/37]: Training Loss: 3.849564380, Training Accuracy: 11.024\n",
            "Worker 3, [14/37]: Training Loss: 3.792852896, Training Accuracy: 11.072\n",
            "Worker 3, [15/37]: Training Loss: 3.847082145, Training Accuracy: 10.544\n",
            "Worker 3, [16/37]: Training Loss: 3.776155501, Training Accuracy: 11.824\n",
            "Worker 3, [17/37]: Training Loss: 3.850947319, Training Accuracy: 10.944\n",
            "Worker 3, [18/37]: Training Loss: 3.783952531, Training Accuracy: 11.424\n",
            "Worker 3, [19/37]: Training Loss: 3.837525677, Training Accuracy: 10.320\n",
            "Worker 3, [20/37]: Training Loss: 3.756495524, Training Accuracy: 12.512\n",
            "Worker 3, [21/37]: Training Loss: 3.826735781, Training Accuracy: 11.024\n",
            "Worker 3, [22/37]: Training Loss: 3.753309661, Training Accuracy: 11.696\n",
            "Worker 3, [23/37]: Training Loss: 3.829607192, Training Accuracy: 10.432\n",
            "Worker 3, [24/37]: Training Loss: 3.730766754, Training Accuracy: 13.200\n",
            "Worker 3, [25/37]: Training Loss: 3.812845323, Training Accuracy: 11.200\n",
            "Worker 3, [26/37]: Training Loss: 3.707991096, Training Accuracy: 12.304\n",
            "Worker 3, [27/37]: Training Loss: 3.793317503, Training Accuracy: 11.440\n",
            "Worker 3, [28/37]: Training Loss: 3.692829665, Training Accuracy: 13.056\n",
            "Worker 3, [29/37]: Training Loss: 3.768661784, Training Accuracy: 11.744\n",
            "Worker 3, [30/37]: Training Loss: 3.672359106, Training Accuracy: 13.008\n",
            "Worker 3, [31/37]: Training Loss: 3.771379086, Training Accuracy: 12.192\n",
            "Worker 3, [32/37]: Training Loss: 3.651852107, Training Accuracy: 13.776\n",
            "Worker 3, [33/37]: Training Loss: 3.743433361, Training Accuracy: 11.600\n",
            "Worker 3, [34/37]: Training Loss: 3.621774153, Training Accuracy: 14.528\n",
            "Worker 3, [35/37]: Training Loss: 3.706196899, Training Accuracy: 12.512\n",
            "Worker 3, [36/37]: Training Loss: 3.589005534, Training Accuracy: 15.376\n",
            "Worker 3, [37/37]: Training Loss: 3.695123030, Training Accuracy: 13.328\n",
            "Time taken for training worker 3: 0:01:38.257758\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.721555345, Training Accuracy: 12.544\n",
            "Worker 4, [02/37]: Training Loss: 3.704866645, Training Accuracy: 13.056\n",
            "Worker 4, [03/37]: Training Loss: 3.934660710, Training Accuracy: 11.872\n",
            "Worker 4, [04/37]: Training Loss: 3.885875605, Training Accuracy: 11.904\n",
            "Worker 4, [05/37]: Training Loss: 3.884106371, Training Accuracy: 11.872\n",
            "Worker 4, [06/37]: Training Loss: 3.815093313, Training Accuracy: 12.368\n",
            "Worker 4, [07/37]: Training Loss: 3.852903578, Training Accuracy: 11.440\n",
            "Worker 4, [08/37]: Training Loss: 3.806149826, Training Accuracy: 12.032\n",
            "Worker 4, [09/37]: Training Loss: 3.844951970, Training Accuracy: 11.184\n",
            "Worker 4, [10/37]: Training Loss: 3.786548208, Training Accuracy: 12.224\n",
            "Worker 4, [11/37]: Training Loss: 3.835513599, Training Accuracy: 11.616\n",
            "Worker 4, [12/37]: Training Loss: 3.775699837, Training Accuracy: 12.192\n",
            "Worker 4, [13/37]: Training Loss: 3.816089620, Training Accuracy: 11.280\n",
            "Worker 4, [14/37]: Training Loss: 3.766661245, Training Accuracy: 12.352\n",
            "Worker 4, [15/37]: Training Loss: 3.822134818, Training Accuracy: 12.032\n",
            "Worker 4, [16/37]: Training Loss: 3.762279253, Training Accuracy: 11.984\n",
            "Worker 4, [17/37]: Training Loss: 3.819000178, Training Accuracy: 11.792\n",
            "Worker 4, [18/37]: Training Loss: 3.752915020, Training Accuracy: 12.416\n",
            "Worker 4, [19/37]: Training Loss: 3.807383708, Training Accuracy: 11.504\n",
            "Worker 4, [20/37]: Training Loss: 3.731123666, Training Accuracy: 12.544\n",
            "Worker 4, [21/37]: Training Loss: 3.800601156, Training Accuracy: 11.168\n",
            "Worker 4, [22/37]: Training Loss: 3.724371078, Training Accuracy: 12.704\n",
            "Worker 4, [23/37]: Training Loss: 3.802493465, Training Accuracy: 10.976\n",
            "Worker 4, [24/37]: Training Loss: 3.713302948, Training Accuracy: 13.312\n",
            "Worker 4, [25/37]: Training Loss: 3.790771081, Training Accuracy: 11.424\n",
            "Worker 4, [26/37]: Training Loss: 3.691095177, Training Accuracy: 13.008\n",
            "Worker 4, [27/37]: Training Loss: 3.781671977, Training Accuracy: 11.616\n",
            "Worker 4, [28/37]: Training Loss: 3.662748918, Training Accuracy: 13.424\n",
            "Worker 4, [29/37]: Training Loss: 3.747113824, Training Accuracy: 12.512\n",
            "Worker 4, [30/37]: Training Loss: 3.645232663, Training Accuracy: 13.504\n",
            "Worker 4, [31/37]: Training Loss: 3.734894733, Training Accuracy: 12.208\n",
            "Worker 4, [32/37]: Training Loss: 3.637818395, Training Accuracy: 13.728\n",
            "Worker 4, [33/37]: Training Loss: 3.720260031, Training Accuracy: 12.608\n",
            "Worker 4, [34/37]: Training Loss: 3.611407280, Training Accuracy: 15.120\n",
            "Worker 4, [35/37]: Training Loss: 3.691526865, Training Accuracy: 13.280\n",
            "Worker 4, [36/37]: Training Loss: 3.593172205, Training Accuracy: 14.224\n",
            "Worker 4, [37/37]: Training Loss: 3.656748995, Training Accuracy: 13.376\n",
            "Time taken for training worker 4: 0:01:38.844061\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.718175579, Training Accuracy: 13.072\n",
            "Worker 5, [02/37]: Training Loss: 3.708100292, Training Accuracy: 13.040\n",
            "Worker 5, [03/37]: Training Loss: 3.923149396, Training Accuracy: 12.016\n",
            "Worker 5, [04/37]: Training Loss: 3.877858692, Training Accuracy: 11.968\n",
            "Worker 5, [05/37]: Training Loss: 3.880134770, Training Accuracy: 11.968\n",
            "Worker 5, [06/37]: Training Loss: 3.812704081, Training Accuracy: 11.888\n",
            "Worker 5, [07/37]: Training Loss: 3.842249391, Training Accuracy: 12.224\n",
            "Worker 5, [08/37]: Training Loss: 3.790450974, Training Accuracy: 12.336\n",
            "Worker 5, [09/37]: Training Loss: 3.841211891, Training Accuracy: 11.568\n",
            "Worker 5, [10/37]: Training Loss: 3.777623529, Training Accuracy: 12.336\n",
            "Worker 5, [11/37]: Training Loss: 3.831592200, Training Accuracy: 11.808\n",
            "Worker 5, [12/37]: Training Loss: 3.778034797, Training Accuracy: 11.984\n",
            "Worker 5, [13/37]: Training Loss: 3.820086224, Training Accuracy: 11.024\n",
            "Worker 5, [14/37]: Training Loss: 3.763471370, Training Accuracy: 11.568\n",
            "Worker 5, [15/37]: Training Loss: 3.825294079, Training Accuracy: 10.832\n",
            "Worker 5, [16/37]: Training Loss: 3.744851302, Training Accuracy: 12.608\n",
            "Worker 5, [17/37]: Training Loss: 3.814365650, Training Accuracy: 11.248\n",
            "Worker 5, [18/37]: Training Loss: 3.741249247, Training Accuracy: 11.792\n",
            "Worker 5, [19/37]: Training Loss: 3.812546295, Training Accuracy: 11.360\n",
            "Worker 5, [20/37]: Training Loss: 3.726770238, Training Accuracy: 12.464\n",
            "Worker 5, [21/37]: Training Loss: 3.813090081, Training Accuracy: 11.328\n",
            "Worker 5, [22/37]: Training Loss: 3.722634936, Training Accuracy: 12.144\n",
            "Worker 5, [23/37]: Training Loss: 3.786575755, Training Accuracy: 11.600\n",
            "Worker 5, [24/37]: Training Loss: 3.701343707, Training Accuracy: 12.480\n",
            "Worker 5, [25/37]: Training Loss: 3.795902678, Training Accuracy: 11.280\n",
            "Worker 5, [26/37]: Training Loss: 3.694254041, Training Accuracy: 12.128\n",
            "Worker 5, [27/37]: Training Loss: 3.774356837, Training Accuracy: 11.520\n",
            "Worker 5, [28/37]: Training Loss: 3.665644011, Training Accuracy: 12.912\n",
            "Worker 5, [29/37]: Training Loss: 3.769790878, Training Accuracy: 11.760\n",
            "Worker 5, [30/37]: Training Loss: 3.632946486, Training Accuracy: 13.584\n",
            "Worker 5, [31/37]: Training Loss: 3.734742019, Training Accuracy: 12.128\n",
            "Worker 5, [32/37]: Training Loss: 3.614114815, Training Accuracy: 14.352\n",
            "Worker 5, [33/37]: Training Loss: 3.700567044, Training Accuracy: 12.768\n",
            "Worker 5, [34/37]: Training Loss: 3.610365293, Training Accuracy: 13.968\n",
            "Worker 5, [35/37]: Training Loss: 3.688574674, Training Accuracy: 12.512\n",
            "Worker 5, [36/37]: Training Loss: 3.573931821, Training Accuracy: 14.400\n",
            "Worker 5, [37/37]: Training Loss: 3.647091790, Training Accuracy: 13.792\n",
            "Time taken for training worker 5: 0:01:37.447495\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.696414646, Training Accuracy: 13.440\n",
            "Worker 6, [02/37]: Training Loss: 3.692386260, Training Accuracy: 13.520\n",
            "Worker 6, [03/37]: Training Loss: 3.933887671, Training Accuracy: 11.840\n",
            "Worker 6, [04/37]: Training Loss: 3.886632839, Training Accuracy: 11.440\n",
            "Worker 6, [05/37]: Training Loss: 3.889924448, Training Accuracy: 11.920\n",
            "Worker 6, [06/37]: Training Loss: 3.828087775, Training Accuracy: 12.032\n",
            "Worker 6, [07/37]: Training Loss: 3.854082910, Training Accuracy: 11.552\n",
            "Worker 6, [08/37]: Training Loss: 3.800779491, Training Accuracy: 11.392\n",
            "Worker 6, [09/37]: Training Loss: 3.843574775, Training Accuracy: 11.536\n",
            "Worker 6, [10/37]: Training Loss: 3.794311648, Training Accuracy: 11.904\n",
            "Worker 6, [11/37]: Training Loss: 3.833494576, Training Accuracy: 11.200\n",
            "Worker 6, [12/37]: Training Loss: 3.779088376, Training Accuracy: 11.984\n",
            "Worker 6, [13/37]: Training Loss: 3.835891249, Training Accuracy: 11.168\n",
            "Worker 6, [14/37]: Training Loss: 3.776851613, Training Accuracy: 11.840\n",
            "Worker 6, [15/37]: Training Loss: 3.831194269, Training Accuracy: 10.992\n",
            "Worker 6, [16/37]: Training Loss: 3.755382701, Training Accuracy: 12.672\n",
            "Worker 6, [17/37]: Training Loss: 3.837294630, Training Accuracy: 10.896\n",
            "Worker 6, [18/37]: Training Loss: 3.741276466, Training Accuracy: 12.384\n",
            "Worker 6, [19/37]: Training Loss: 3.815443538, Training Accuracy: 11.040\n",
            "Worker 6, [20/37]: Training Loss: 3.760219820, Training Accuracy: 11.840\n",
            "Worker 6, [21/37]: Training Loss: 3.817000467, Training Accuracy: 10.880\n",
            "Worker 6, [22/37]: Training Loss: 3.728588547, Training Accuracy: 12.336\n",
            "Worker 6, [23/37]: Training Loss: 3.819025032, Training Accuracy: 10.736\n",
            "Worker 6, [24/37]: Training Loss: 3.725049780, Training Accuracy: 11.952\n",
            "Worker 6, [25/37]: Training Loss: 3.801794259, Training Accuracy: 11.584\n",
            "Worker 6, [26/37]: Training Loss: 3.696967084, Training Accuracy: 13.072\n",
            "Worker 6, [27/37]: Training Loss: 3.779898894, Training Accuracy: 11.344\n",
            "Worker 6, [28/37]: Training Loss: 3.668961581, Training Accuracy: 13.920\n",
            "Worker 6, [29/37]: Training Loss: 3.776196653, Training Accuracy: 11.968\n",
            "Worker 6, [30/37]: Training Loss: 3.679553122, Training Accuracy: 12.992\n",
            "Worker 6, [31/37]: Training Loss: 3.749485953, Training Accuracy: 11.920\n",
            "Worker 6, [32/37]: Training Loss: 3.643704663, Training Accuracy: 13.552\n",
            "Worker 6, [33/37]: Training Loss: 3.721930010, Training Accuracy: 12.048\n",
            "Worker 6, [34/37]: Training Loss: 3.605482245, Training Accuracy: 14.352\n",
            "Worker 6, [35/37]: Training Loss: 3.700386378, Training Accuracy: 12.656\n",
            "Worker 6, [36/37]: Training Loss: 3.623313897, Training Accuracy: 13.824\n",
            "Worker 6, [37/37]: Training Loss: 3.690019291, Training Accuracy: 12.384\n",
            "Time taken for training worker 6: 0:01:38.535920\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.782130037, Training Accuracy: 11.504\n",
            "Worker 7, [02/37]: Training Loss: 3.774156809, Training Accuracy: 11.568\n",
            "Worker 7, [03/37]: Training Loss: 3.917644206, Training Accuracy: 11.888\n",
            "Worker 7, [04/37]: Training Loss: 3.867664393, Training Accuracy: 11.648\n",
            "Worker 7, [05/37]: Training Loss: 3.868992762, Training Accuracy: 11.968\n",
            "Worker 7, [06/37]: Training Loss: 3.799594059, Training Accuracy: 12.384\n",
            "Worker 7, [07/37]: Training Loss: 3.827563415, Training Accuracy: 12.176\n",
            "Worker 7, [08/37]: Training Loss: 3.778658753, Training Accuracy: 12.304\n",
            "Worker 7, [09/37]: Training Loss: 3.817023997, Training Accuracy: 12.032\n",
            "Worker 7, [10/37]: Training Loss: 3.768419105, Training Accuracy: 11.872\n",
            "Worker 7, [11/37]: Training Loss: 3.818030228, Training Accuracy: 11.200\n",
            "Worker 7, [12/37]: Training Loss: 3.754188292, Training Accuracy: 12.480\n",
            "Worker 7, [13/37]: Training Loss: 3.807808377, Training Accuracy: 11.008\n",
            "Worker 7, [14/37]: Training Loss: 3.762148607, Training Accuracy: 11.840\n",
            "Worker 7, [15/37]: Training Loss: 3.807319619, Training Accuracy: 11.024\n",
            "Worker 7, [16/37]: Training Loss: 3.744894205, Training Accuracy: 12.560\n",
            "Worker 7, [17/37]: Training Loss: 3.802219111, Training Accuracy: 11.360\n",
            "Worker 7, [18/37]: Training Loss: 3.729419511, Training Accuracy: 12.176\n",
            "Worker 7, [19/37]: Training Loss: 3.810734853, Training Accuracy: 10.800\n",
            "Worker 7, [20/37]: Training Loss: 3.741075394, Training Accuracy: 11.760\n",
            "Worker 7, [21/37]: Training Loss: 3.799420644, Training Accuracy: 11.584\n",
            "Worker 7, [22/37]: Training Loss: 3.724602629, Training Accuracy: 11.920\n",
            "Worker 7, [23/37]: Training Loss: 3.791710601, Training Accuracy: 10.944\n",
            "Worker 7, [24/37]: Training Loss: 3.709969722, Training Accuracy: 12.304\n",
            "Worker 7, [25/37]: Training Loss: 3.786095077, Training Accuracy: 10.848\n",
            "Worker 7, [26/37]: Training Loss: 3.689019235, Training Accuracy: 12.416\n",
            "Worker 7, [27/37]: Training Loss: 3.775360986, Training Accuracy: 11.568\n",
            "Worker 7, [28/37]: Training Loss: 3.672034585, Training Accuracy: 12.864\n",
            "Worker 7, [29/37]: Training Loss: 3.770434835, Training Accuracy: 11.232\n",
            "Worker 7, [30/37]: Training Loss: 3.664466875, Training Accuracy: 13.072\n",
            "Worker 7, [31/37]: Training Loss: 3.755807020, Training Accuracy: 11.664\n",
            "Worker 7, [32/37]: Training Loss: 3.645480886, Training Accuracy: 13.552\n",
            "Worker 7, [33/37]: Training Loss: 3.714125867, Training Accuracy: 11.712\n",
            "Worker 7, [34/37]: Training Loss: 3.616485102, Training Accuracy: 14.480\n",
            "Worker 7, [35/37]: Training Loss: 3.702162402, Training Accuracy: 12.768\n",
            "Worker 7, [36/37]: Training Loss: 3.594830948, Training Accuracy: 14.112\n",
            "Worker 7, [37/37]: Training Loss: 3.678417979, Training Accuracy: 13.232\n",
            "Time taken for training worker 7: 0:01:37.351892\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.737634201, Training Accuracy: 12.976\n",
            "Worker 8, [02/37]: Training Loss: 3.723511652, Training Accuracy: 12.848\n",
            "Worker 8, [03/37]: Training Loss: 3.936095063, Training Accuracy: 11.456\n",
            "Worker 8, [04/37]: Training Loss: 3.888537789, Training Accuracy: 11.744\n",
            "Worker 8, [05/37]: Training Loss: 3.887518734, Training Accuracy: 11.632\n",
            "Worker 8, [06/37]: Training Loss: 3.818899308, Training Accuracy: 11.968\n",
            "Worker 8, [07/37]: Training Loss: 3.858989789, Training Accuracy: 11.520\n",
            "Worker 8, [08/37]: Training Loss: 3.814593490, Training Accuracy: 11.440\n",
            "Worker 8, [09/37]: Training Loss: 3.834090303, Training Accuracy: 11.408\n",
            "Worker 8, [10/37]: Training Loss: 3.790997381, Training Accuracy: 11.504\n",
            "Worker 8, [11/37]: Training Loss: 3.829065398, Training Accuracy: 10.736\n",
            "Worker 8, [12/37]: Training Loss: 3.772881518, Training Accuracy: 11.952\n",
            "Worker 8, [13/37]: Training Loss: 3.824486886, Training Accuracy: 11.088\n",
            "Worker 8, [14/37]: Training Loss: 3.776407697, Training Accuracy: 11.648\n",
            "Worker 8, [15/37]: Training Loss: 3.819093490, Training Accuracy: 10.816\n",
            "Worker 8, [16/37]: Training Loss: 3.764702916, Training Accuracy: 11.136\n",
            "Worker 8, [17/37]: Training Loss: 3.831041796, Training Accuracy: 10.688\n",
            "Worker 8, [18/37]: Training Loss: 3.758097885, Training Accuracy: 12.352\n",
            "Worker 8, [19/37]: Training Loss: 3.815674933, Training Accuracy: 11.632\n",
            "Worker 8, [20/37]: Training Loss: 3.744357917, Training Accuracy: 11.728\n",
            "Worker 8, [21/37]: Training Loss: 3.806463030, Training Accuracy: 10.928\n",
            "Worker 8, [22/37]: Training Loss: 3.728351999, Training Accuracy: 11.968\n",
            "Worker 8, [23/37]: Training Loss: 3.802958179, Training Accuracy: 10.800\n",
            "Worker 8, [24/37]: Training Loss: 3.710576121, Training Accuracy: 12.096\n",
            "Worker 8, [25/37]: Training Loss: 3.790765923, Training Accuracy: 11.408\n",
            "Worker 8, [26/37]: Training Loss: 3.690510891, Training Accuracy: 12.096\n",
            "Worker 8, [27/37]: Training Loss: 3.756118524, Training Accuracy: 11.600\n",
            "Worker 8, [28/37]: Training Loss: 3.670239473, Training Accuracy: 12.608\n",
            "Worker 8, [29/37]: Training Loss: 3.756859526, Training Accuracy: 11.024\n",
            "Worker 8, [30/37]: Training Loss: 3.655625161, Training Accuracy: 12.928\n",
            "Worker 8, [31/37]: Training Loss: 3.743534913, Training Accuracy: 11.584\n",
            "Worker 8, [32/37]: Training Loss: 3.651916925, Training Accuracy: 13.424\n",
            "Worker 8, [33/37]: Training Loss: 3.724107553, Training Accuracy: 11.760\n",
            "Worker 8, [34/37]: Training Loss: 3.624137718, Training Accuracy: 13.424\n",
            "Worker 8, [35/37]: Training Loss: 3.706694498, Training Accuracy: 11.856\n",
            "Worker 8, [36/37]: Training Loss: 3.585303842, Training Accuracy: 14.144\n",
            "Worker 8, [37/37]: Training Loss: 3.679368462, Training Accuracy: 11.936\n",
            "Time taken for training worker 8: 0:01:38.489828\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000710\n",
            "Local Step 02: Test Loss: 3.673994016, Test Accuracy: 13.480\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.710913653, Training Accuracy: 12.720\n",
            "Worker 1, [02/37]: Training Loss: 3.566584356, Training Accuracy: 15.744\n",
            "Worker 1, [03/37]: Training Loss: 3.705265381, Training Accuracy: 12.816\n",
            "Worker 1, [04/37]: Training Loss: 3.608885775, Training Accuracy: 14.272\n",
            "Worker 1, [05/37]: Training Loss: 3.671635956, Training Accuracy: 13.872\n",
            "Worker 1, [06/37]: Training Loss: 3.568174316, Training Accuracy: 14.976\n",
            "Worker 1, [07/37]: Training Loss: 3.657669505, Training Accuracy: 13.696\n",
            "Worker 1, [08/37]: Training Loss: 3.548005342, Training Accuracy: 15.472\n",
            "Worker 1, [09/37]: Training Loss: 3.617161719, Training Accuracy: 14.160\n",
            "Worker 1, [10/37]: Training Loss: 3.509722534, Training Accuracy: 15.696\n",
            "Worker 1, [11/37]: Training Loss: 3.571844974, Training Accuracy: 15.040\n",
            "Worker 1, [12/37]: Training Loss: 3.488116133, Training Accuracy: 15.920\n",
            "Worker 1, [13/37]: Training Loss: 3.534659595, Training Accuracy: 15.968\n",
            "Worker 1, [14/37]: Training Loss: 3.470172349, Training Accuracy: 17.376\n",
            "Worker 1, [15/37]: Training Loss: 3.491084977, Training Accuracy: 16.496\n",
            "Worker 1, [16/37]: Training Loss: 3.404516911, Training Accuracy: 17.632\n",
            "Worker 1, [17/37]: Training Loss: 3.465618231, Training Accuracy: 16.720\n",
            "Worker 1, [18/37]: Training Loss: 3.374607918, Training Accuracy: 18.176\n",
            "Worker 1, [19/37]: Training Loss: 3.437470397, Training Accuracy: 17.072\n",
            "Worker 1, [20/37]: Training Loss: 3.338576468, Training Accuracy: 19.424\n",
            "Worker 1, [21/37]: Training Loss: 3.392276248, Training Accuracy: 18.272\n",
            "Worker 1, [22/37]: Training Loss: 3.324045157, Training Accuracy: 19.344\n",
            "Worker 1, [23/37]: Training Loss: 3.337993111, Training Accuracy: 19.552\n",
            "Worker 1, [24/37]: Training Loss: 3.289919410, Training Accuracy: 20.000\n",
            "Worker 1, [25/37]: Training Loss: 3.309264241, Training Accuracy: 19.744\n",
            "Worker 1, [26/37]: Training Loss: 3.244256920, Training Accuracy: 20.528\n",
            "Worker 1, [27/37]: Training Loss: 3.272141508, Training Accuracy: 20.976\n",
            "Worker 1, [28/37]: Training Loss: 3.216080578, Training Accuracy: 21.936\n",
            "Worker 1, [29/37]: Training Loss: 3.238565418, Training Accuracy: 21.152\n",
            "Worker 1, [30/37]: Training Loss: 3.189659374, Training Accuracy: 21.952\n",
            "Worker 1, [31/37]: Training Loss: 3.213256036, Training Accuracy: 21.872\n",
            "Worker 1, [32/37]: Training Loss: 3.161505244, Training Accuracy: 22.944\n",
            "Worker 1, [33/37]: Training Loss: 3.199252956, Training Accuracy: 22.016\n",
            "Worker 1, [34/37]: Training Loss: 3.172567377, Training Accuracy: 22.832\n",
            "Worker 1, [35/37]: Training Loss: 3.202874651, Training Accuracy: 22.032\n",
            "Worker 1, [36/37]: Training Loss: 3.192430204, Training Accuracy: 22.112\n",
            "Worker 1, [37/37]: Training Loss: 3.209420131, Training Accuracy: 22.576\n",
            "Time taken for training worker 1: 0:01:39.284186\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.605843568, Training Accuracy: 13.776\n",
            "Worker 2, [02/37]: Training Loss: 3.468726204, Training Accuracy: 16.256\n",
            "Worker 2, [03/37]: Training Loss: 3.633401316, Training Accuracy: 13.552\n",
            "Worker 2, [04/37]: Training Loss: 3.522184742, Training Accuracy: 14.816\n",
            "Worker 2, [05/37]: Training Loss: 3.596188044, Training Accuracy: 14.672\n",
            "Worker 2, [06/37]: Training Loss: 3.512034830, Training Accuracy: 15.584\n",
            "Worker 2, [07/37]: Training Loss: 3.575946134, Training Accuracy: 14.096\n",
            "Worker 2, [08/37]: Training Loss: 3.462839367, Training Accuracy: 16.112\n",
            "Worker 2, [09/37]: Training Loss: 3.540793519, Training Accuracy: 14.800\n",
            "Worker 2, [10/37]: Training Loss: 3.436213087, Training Accuracy: 16.736\n",
            "Worker 2, [11/37]: Training Loss: 3.502633134, Training Accuracy: 16.176\n",
            "Worker 2, [12/37]: Training Loss: 3.393491487, Training Accuracy: 17.584\n",
            "Worker 2, [13/37]: Training Loss: 3.481453244, Training Accuracy: 15.664\n",
            "Worker 2, [14/37]: Training Loss: 3.354723008, Training Accuracy: 17.888\n",
            "Worker 2, [15/37]: Training Loss: 3.423013561, Training Accuracy: 17.504\n",
            "Worker 2, [16/37]: Training Loss: 3.331689032, Training Accuracy: 18.176\n",
            "Worker 2, [17/37]: Training Loss: 3.359647690, Training Accuracy: 18.192\n",
            "Worker 2, [18/37]: Training Loss: 3.295427529, Training Accuracy: 19.200\n",
            "Worker 2, [19/37]: Training Loss: 3.340786501, Training Accuracy: 18.432\n",
            "Worker 2, [20/37]: Training Loss: 3.256192417, Training Accuracy: 20.192\n",
            "Worker 2, [21/37]: Training Loss: 3.301196826, Training Accuracy: 18.736\n",
            "Worker 2, [22/37]: Training Loss: 3.209365149, Training Accuracy: 20.080\n",
            "Worker 2, [23/37]: Training Loss: 3.252994228, Training Accuracy: 19.984\n",
            "Worker 2, [24/37]: Training Loss: 3.184649767, Training Accuracy: 20.512\n",
            "Worker 2, [25/37]: Training Loss: 3.217212521, Training Accuracy: 20.672\n",
            "Worker 2, [26/37]: Training Loss: 3.145549567, Training Accuracy: 22.352\n",
            "Worker 2, [27/37]: Training Loss: 3.184131525, Training Accuracy: 21.216\n",
            "Worker 2, [28/37]: Training Loss: 3.107962764, Training Accuracy: 22.784\n",
            "Worker 2, [29/37]: Training Loss: 3.142970511, Training Accuracy: 22.448\n",
            "Worker 2, [30/37]: Training Loss: 3.092184079, Training Accuracy: 23.056\n",
            "Worker 2, [31/37]: Training Loss: 3.125750038, Training Accuracy: 22.448\n",
            "Worker 2, [32/37]: Training Loss: 3.078127224, Training Accuracy: 23.456\n",
            "Worker 2, [33/37]: Training Loss: 3.101411418, Training Accuracy: 22.864\n",
            "Worker 2, [34/37]: Training Loss: 3.071642545, Training Accuracy: 23.792\n",
            "Worker 2, [35/37]: Training Loss: 3.110343111, Training Accuracy: 23.088\n",
            "Worker 2, [36/37]: Training Loss: 3.085460738, Training Accuracy: 24.016\n",
            "Worker 2, [37/37]: Training Loss: 3.108556631, Training Accuracy: 23.456\n",
            "Time taken for training worker 2: 0:01:37.388635\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.586854103, Training Accuracy: 14.784\n",
            "Worker 3, [02/37]: Training Loss: 3.444575736, Training Accuracy: 17.280\n",
            "Worker 3, [03/37]: Training Loss: 3.679435993, Training Accuracy: 13.328\n",
            "Worker 3, [04/37]: Training Loss: 3.559692458, Training Accuracy: 15.008\n",
            "Worker 3, [05/37]: Training Loss: 3.621828884, Training Accuracy: 13.744\n",
            "Worker 3, [06/37]: Training Loss: 3.528975032, Training Accuracy: 15.872\n",
            "Worker 3, [07/37]: Training Loss: 3.598675794, Training Accuracy: 14.464\n",
            "Worker 3, [08/37]: Training Loss: 3.471227369, Training Accuracy: 16.832\n",
            "Worker 3, [09/37]: Training Loss: 3.567674114, Training Accuracy: 15.200\n",
            "Worker 3, [10/37]: Training Loss: 3.445297268, Training Accuracy: 17.712\n",
            "Worker 3, [11/37]: Training Loss: 3.535488450, Training Accuracy: 15.456\n",
            "Worker 3, [12/37]: Training Loss: 3.426364497, Training Accuracy: 17.712\n",
            "Worker 3, [13/37]: Training Loss: 3.479751594, Training Accuracy: 16.480\n",
            "Worker 3, [14/37]: Training Loss: 3.382532305, Training Accuracy: 18.320\n",
            "Worker 3, [15/37]: Training Loss: 3.439160444, Training Accuracy: 16.992\n",
            "Worker 3, [16/37]: Training Loss: 3.361242851, Training Accuracy: 19.264\n",
            "Worker 3, [17/37]: Training Loss: 3.405220316, Training Accuracy: 17.536\n",
            "Worker 3, [18/37]: Training Loss: 3.333796219, Training Accuracy: 19.936\n",
            "Worker 3, [19/37]: Training Loss: 3.365660663, Training Accuracy: 19.360\n",
            "Worker 3, [20/37]: Training Loss: 3.289963486, Training Accuracy: 19.728\n",
            "Worker 3, [21/37]: Training Loss: 3.338156381, Training Accuracy: 19.408\n",
            "Worker 3, [22/37]: Training Loss: 3.257120636, Training Accuracy: 20.272\n",
            "Worker 3, [23/37]: Training Loss: 3.285549514, Training Accuracy: 19.776\n",
            "Worker 3, [24/37]: Training Loss: 3.228489316, Training Accuracy: 21.792\n",
            "Worker 3, [25/37]: Training Loss: 3.248550702, Training Accuracy: 21.264\n",
            "Worker 3, [26/37]: Training Loss: 3.180219886, Training Accuracy: 22.096\n",
            "Worker 3, [27/37]: Training Loss: 3.214934320, Training Accuracy: 22.448\n",
            "Worker 3, [28/37]: Training Loss: 3.149984430, Training Accuracy: 22.752\n",
            "Worker 3, [29/37]: Training Loss: 3.184278593, Training Accuracy: 21.968\n",
            "Worker 3, [30/37]: Training Loss: 3.123563849, Training Accuracy: 23.440\n",
            "Worker 3, [31/37]: Training Loss: 3.162025442, Training Accuracy: 22.784\n",
            "Worker 3, [32/37]: Training Loss: 3.117928398, Training Accuracy: 24.160\n",
            "Worker 3, [33/37]: Training Loss: 3.131418659, Training Accuracy: 23.712\n",
            "Worker 3, [34/37]: Training Loss: 3.100744430, Training Accuracy: 24.256\n",
            "Worker 3, [35/37]: Training Loss: 3.135719511, Training Accuracy: 24.096\n",
            "Worker 3, [36/37]: Training Loss: 3.112745813, Training Accuracy: 24.320\n",
            "Worker 3, [37/37]: Training Loss: 3.143644975, Training Accuracy: 23.664\n",
            "Time taken for training worker 3: 0:01:38.362063\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.598105144, Training Accuracy: 14.800\n",
            "Worker 4, [02/37]: Training Loss: 3.459063615, Training Accuracy: 16.800\n",
            "Worker 4, [03/37]: Training Loss: 3.647460743, Training Accuracy: 13.776\n",
            "Worker 4, [04/37]: Training Loss: 3.544458061, Training Accuracy: 15.200\n",
            "Worker 4, [05/37]: Training Loss: 3.618205581, Training Accuracy: 14.080\n",
            "Worker 4, [06/37]: Training Loss: 3.502391905, Training Accuracy: 15.648\n",
            "Worker 4, [07/37]: Training Loss: 3.564460037, Training Accuracy: 15.344\n",
            "Worker 4, [08/37]: Training Loss: 3.483611552, Training Accuracy: 15.920\n",
            "Worker 4, [09/37]: Training Loss: 3.555920611, Training Accuracy: 15.136\n",
            "Worker 4, [10/37]: Training Loss: 3.440618067, Training Accuracy: 17.120\n",
            "Worker 4, [11/37]: Training Loss: 3.506078701, Training Accuracy: 16.496\n",
            "Worker 4, [12/37]: Training Loss: 3.428447524, Training Accuracy: 17.792\n",
            "Worker 4, [13/37]: Training Loss: 3.486737543, Training Accuracy: 15.760\n",
            "Worker 4, [14/37]: Training Loss: 3.379829069, Training Accuracy: 17.936\n",
            "Worker 4, [15/37]: Training Loss: 3.420393404, Training Accuracy: 17.792\n",
            "Worker 4, [16/37]: Training Loss: 3.326492937, Training Accuracy: 18.752\n",
            "Worker 4, [17/37]: Training Loss: 3.393372195, Training Accuracy: 18.000\n",
            "Worker 4, [18/37]: Training Loss: 3.291331026, Training Accuracy: 20.048\n",
            "Worker 4, [19/37]: Training Loss: 3.340149690, Training Accuracy: 17.984\n",
            "Worker 4, [20/37]: Training Loss: 3.258549719, Training Accuracy: 20.016\n",
            "Worker 4, [21/37]: Training Loss: 3.323298921, Training Accuracy: 19.520\n",
            "Worker 4, [22/37]: Training Loss: 3.226022509, Training Accuracy: 21.008\n",
            "Worker 4, [23/37]: Training Loss: 3.253831820, Training Accuracy: 20.944\n",
            "Worker 4, [24/37]: Training Loss: 3.195416616, Training Accuracy: 21.232\n",
            "Worker 4, [25/37]: Training Loss: 3.223635051, Training Accuracy: 21.424\n",
            "Worker 4, [26/37]: Training Loss: 3.150942328, Training Accuracy: 22.784\n",
            "Worker 4, [27/37]: Training Loss: 3.178302432, Training Accuracy: 22.192\n",
            "Worker 4, [28/37]: Training Loss: 3.138862590, Training Accuracy: 22.640\n",
            "Worker 4, [29/37]: Training Loss: 3.157333715, Training Accuracy: 21.968\n",
            "Worker 4, [30/37]: Training Loss: 3.116751929, Training Accuracy: 23.360\n",
            "Worker 4, [31/37]: Training Loss: 3.133667442, Training Accuracy: 22.960\n",
            "Worker 4, [32/37]: Training Loss: 3.085688148, Training Accuracy: 23.552\n",
            "Worker 4, [33/37]: Training Loss: 3.118284600, Training Accuracy: 23.584\n",
            "Worker 4, [34/37]: Training Loss: 3.081298064, Training Accuracy: 24.320\n",
            "Worker 4, [35/37]: Training Loss: 3.113648006, Training Accuracy: 24.432\n",
            "Worker 4, [36/37]: Training Loss: 3.104983914, Training Accuracy: 23.936\n",
            "Worker 4, [37/37]: Training Loss: 3.121908266, Training Accuracy: 23.888\n",
            "Time taken for training worker 4: 0:01:36.544419\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.593704557, Training Accuracy: 15.296\n",
            "Worker 5, [02/37]: Training Loss: 3.461492801, Training Accuracy: 16.560\n",
            "Worker 5, [03/37]: Training Loss: 3.642109749, Training Accuracy: 14.224\n",
            "Worker 5, [04/37]: Training Loss: 3.533252495, Training Accuracy: 15.744\n",
            "Worker 5, [05/37]: Training Loss: 3.609400679, Training Accuracy: 14.512\n",
            "Worker 5, [06/37]: Training Loss: 3.494286462, Training Accuracy: 16.352\n",
            "Worker 5, [07/37]: Training Loss: 3.560850362, Training Accuracy: 15.472\n",
            "Worker 5, [08/37]: Training Loss: 3.483441039, Training Accuracy: 16.176\n",
            "Worker 5, [09/37]: Training Loss: 3.554938326, Training Accuracy: 15.312\n",
            "Worker 5, [10/37]: Training Loss: 3.446689691, Training Accuracy: 16.928\n",
            "Worker 5, [11/37]: Training Loss: 3.505490666, Training Accuracy: 16.080\n",
            "Worker 5, [12/37]: Training Loss: 3.414635726, Training Accuracy: 16.848\n",
            "Worker 5, [13/37]: Training Loss: 3.466317800, Training Accuracy: 16.528\n",
            "Worker 5, [14/37]: Training Loss: 3.368156039, Training Accuracy: 18.096\n",
            "Worker 5, [15/37]: Training Loss: 3.424536861, Training Accuracy: 17.392\n",
            "Worker 5, [16/37]: Training Loss: 3.362697324, Training Accuracy: 18.144\n",
            "Worker 5, [17/37]: Training Loss: 3.398324692, Training Accuracy: 18.048\n",
            "Worker 5, [18/37]: Training Loss: 3.314158396, Training Accuracy: 18.576\n",
            "Worker 5, [19/37]: Training Loss: 3.354694469, Training Accuracy: 18.608\n",
            "Worker 5, [20/37]: Training Loss: 3.263363636, Training Accuracy: 19.712\n",
            "Worker 5, [21/37]: Training Loss: 3.307307058, Training Accuracy: 19.504\n",
            "Worker 5, [22/37]: Training Loss: 3.239040662, Training Accuracy: 20.992\n",
            "Worker 5, [23/37]: Training Loss: 3.258306297, Training Accuracy: 20.528\n",
            "Worker 5, [24/37]: Training Loss: 3.191526182, Training Accuracy: 21.184\n",
            "Worker 5, [25/37]: Training Loss: 3.233913833, Training Accuracy: 20.592\n",
            "Worker 5, [26/37]: Training Loss: 3.160490598, Training Accuracy: 22.048\n",
            "Worker 5, [27/37]: Training Loss: 3.190560737, Training Accuracy: 21.776\n",
            "Worker 5, [28/37]: Training Loss: 3.134047462, Training Accuracy: 22.512\n",
            "Worker 5, [29/37]: Training Loss: 3.168980944, Training Accuracy: 22.560\n",
            "Worker 5, [30/37]: Training Loss: 3.119002500, Training Accuracy: 22.816\n",
            "Worker 5, [31/37]: Training Loss: 3.142983660, Training Accuracy: 22.448\n",
            "Worker 5, [32/37]: Training Loss: 3.092444697, Training Accuracy: 24.176\n",
            "Worker 5, [33/37]: Training Loss: 3.128937806, Training Accuracy: 22.944\n",
            "Worker 5, [34/37]: Training Loss: 3.094996311, Training Accuracy: 23.632\n",
            "Worker 5, [35/37]: Training Loss: 3.122781644, Training Accuracy: 23.152\n",
            "Worker 5, [36/37]: Training Loss: 3.105957552, Training Accuracy: 23.968\n",
            "Worker 5, [37/37]: Training Loss: 3.117515586, Training Accuracy: 23.440\n",
            "Time taken for training worker 5: 0:01:36.591348\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.574273873, Training Accuracy: 14.816\n",
            "Worker 6, [02/37]: Training Loss: 3.448638223, Training Accuracy: 17.104\n",
            "Worker 6, [03/37]: Training Loss: 3.665210434, Training Accuracy: 12.752\n",
            "Worker 6, [04/37]: Training Loss: 3.541041759, Training Accuracy: 15.008\n",
            "Worker 6, [05/37]: Training Loss: 3.623401868, Training Accuracy: 14.064\n",
            "Worker 6, [06/37]: Training Loss: 3.538547737, Training Accuracy: 15.120\n",
            "Worker 6, [07/37]: Training Loss: 3.592433628, Training Accuracy: 14.240\n",
            "Worker 6, [08/37]: Training Loss: 3.490365196, Training Accuracy: 16.304\n",
            "Worker 6, [09/37]: Training Loss: 3.552591630, Training Accuracy: 15.472\n",
            "Worker 6, [10/37]: Training Loss: 3.449091729, Training Accuracy: 16.880\n",
            "Worker 6, [11/37]: Training Loss: 3.528639017, Training Accuracy: 15.328\n",
            "Worker 6, [12/37]: Training Loss: 3.414157743, Training Accuracy: 16.976\n",
            "Worker 6, [13/37]: Training Loss: 3.486459533, Training Accuracy: 16.112\n",
            "Worker 6, [14/37]: Training Loss: 3.396402318, Training Accuracy: 17.776\n",
            "Worker 6, [15/37]: Training Loss: 3.446181020, Training Accuracy: 17.280\n",
            "Worker 6, [16/37]: Training Loss: 3.348317825, Training Accuracy: 18.608\n",
            "Worker 6, [17/37]: Training Loss: 3.392015387, Training Accuracy: 17.456\n",
            "Worker 6, [18/37]: Training Loss: 3.322216781, Training Accuracy: 18.528\n",
            "Worker 6, [19/37]: Training Loss: 3.355493667, Training Accuracy: 18.544\n",
            "Worker 6, [20/37]: Training Loss: 3.285436404, Training Accuracy: 18.976\n",
            "Worker 6, [21/37]: Training Loss: 3.329633676, Training Accuracy: 19.168\n",
            "Worker 6, [22/37]: Training Loss: 3.266029521, Training Accuracy: 19.648\n",
            "Worker 6, [23/37]: Training Loss: 3.290447890, Training Accuracy: 19.456\n",
            "Worker 6, [24/37]: Training Loss: 3.203856193, Training Accuracy: 21.184\n",
            "Worker 6, [25/37]: Training Loss: 3.250238808, Training Accuracy: 20.304\n",
            "Worker 6, [26/37]: Training Loss: 3.185230515, Training Accuracy: 21.376\n",
            "Worker 6, [27/37]: Training Loss: 3.203451575, Training Accuracy: 21.104\n",
            "Worker 6, [28/37]: Training Loss: 3.158000345, Training Accuracy: 22.384\n",
            "Worker 6, [29/37]: Training Loss: 3.180923751, Training Accuracy: 21.888\n",
            "Worker 6, [30/37]: Training Loss: 3.127956159, Training Accuracy: 22.576\n",
            "Worker 6, [31/37]: Training Loss: 3.165247727, Training Accuracy: 22.736\n",
            "Worker 6, [32/37]: Training Loss: 3.119034502, Training Accuracy: 23.584\n",
            "Worker 6, [33/37]: Training Loss: 3.157564779, Training Accuracy: 22.400\n",
            "Worker 6, [34/37]: Training Loss: 3.121243861, Training Accuracy: 23.008\n",
            "Worker 6, [35/37]: Training Loss: 3.147791527, Training Accuracy: 22.864\n",
            "Worker 6, [36/37]: Training Loss: 3.117525787, Training Accuracy: 23.728\n",
            "Worker 6, [37/37]: Training Loss: 3.136865278, Training Accuracy: 23.024\n",
            "Time taken for training worker 6: 0:01:37.474112\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.607691344, Training Accuracy: 14.480\n",
            "Worker 7, [02/37]: Training Loss: 3.479844704, Training Accuracy: 16.688\n",
            "Worker 7, [03/37]: Training Loss: 3.652021471, Training Accuracy: 12.864\n",
            "Worker 7, [04/37]: Training Loss: 3.560072860, Training Accuracy: 14.704\n",
            "Worker 7, [05/37]: Training Loss: 3.634537488, Training Accuracy: 13.520\n",
            "Worker 7, [06/37]: Training Loss: 3.532913680, Training Accuracy: 15.264\n",
            "Worker 7, [07/37]: Training Loss: 3.591140341, Training Accuracy: 14.304\n",
            "Worker 7, [08/37]: Training Loss: 3.493408342, Training Accuracy: 15.792\n",
            "Worker 7, [09/37]: Training Loss: 3.564001254, Training Accuracy: 14.688\n",
            "Worker 7, [10/37]: Training Loss: 3.473870299, Training Accuracy: 16.112\n",
            "Worker 7, [11/37]: Training Loss: 3.522590379, Training Accuracy: 15.680\n",
            "Worker 7, [12/37]: Training Loss: 3.448223386, Training Accuracy: 16.688\n",
            "Worker 7, [13/37]: Training Loss: 3.498766323, Training Accuracy: 15.520\n",
            "Worker 7, [14/37]: Training Loss: 3.396811590, Training Accuracy: 17.488\n",
            "Worker 7, [15/37]: Training Loss: 3.448988092, Training Accuracy: 16.864\n",
            "Worker 7, [16/37]: Training Loss: 3.365163570, Training Accuracy: 18.368\n",
            "Worker 7, [17/37]: Training Loss: 3.403942454, Training Accuracy: 17.488\n",
            "Worker 7, [18/37]: Training Loss: 3.321258878, Training Accuracy: 19.232\n",
            "Worker 7, [19/37]: Training Loss: 3.369941147, Training Accuracy: 18.144\n",
            "Worker 7, [20/37]: Training Loss: 3.282704482, Training Accuracy: 19.664\n",
            "Worker 7, [21/37]: Training Loss: 3.318973184, Training Accuracy: 19.040\n",
            "Worker 7, [22/37]: Training Loss: 3.236587322, Training Accuracy: 20.240\n",
            "Worker 7, [23/37]: Training Loss: 3.281373352, Training Accuracy: 19.856\n",
            "Worker 7, [24/37]: Training Loss: 3.213520505, Training Accuracy: 21.024\n",
            "Worker 7, [25/37]: Training Loss: 3.246780023, Training Accuracy: 20.848\n",
            "Worker 7, [26/37]: Training Loss: 3.178803072, Training Accuracy: 21.408\n",
            "Worker 7, [27/37]: Training Loss: 3.213501064, Training Accuracy: 21.248\n",
            "Worker 7, [28/37]: Training Loss: 3.143927664, Training Accuracy: 22.352\n",
            "Worker 7, [29/37]: Training Loss: 3.172753852, Training Accuracy: 21.920\n",
            "Worker 7, [30/37]: Training Loss: 3.130618234, Training Accuracy: 22.400\n",
            "Worker 7, [31/37]: Training Loss: 3.166888923, Training Accuracy: 21.952\n",
            "Worker 7, [32/37]: Training Loss: 3.110309075, Training Accuracy: 23.008\n",
            "Worker 7, [33/37]: Training Loss: 3.152772548, Training Accuracy: 22.144\n",
            "Worker 7, [34/37]: Training Loss: 3.122367392, Training Accuracy: 23.264\n",
            "Worker 7, [35/37]: Training Loss: 3.133098026, Training Accuracy: 23.088\n",
            "Worker 7, [36/37]: Training Loss: 3.114888432, Training Accuracy: 23.392\n",
            "Worker 7, [37/37]: Training Loss: 3.140679007, Training Accuracy: 23.008\n",
            "Time taken for training worker 7: 0:01:39.820331\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.598582968, Training Accuracy: 14.016\n",
            "Worker 8, [02/37]: Training Loss: 3.457221705, Training Accuracy: 16.576\n",
            "Worker 8, [03/37]: Training Loss: 3.654725802, Training Accuracy: 13.104\n",
            "Worker 8, [04/37]: Training Loss: 3.544738816, Training Accuracy: 15.200\n",
            "Worker 8, [05/37]: Training Loss: 3.634022586, Training Accuracy: 13.728\n",
            "Worker 8, [06/37]: Training Loss: 3.532605663, Training Accuracy: 14.960\n",
            "Worker 8, [07/37]: Training Loss: 3.595962809, Training Accuracy: 13.984\n",
            "Worker 8, [08/37]: Training Loss: 3.472507907, Training Accuracy: 16.144\n",
            "Worker 8, [09/37]: Training Loss: 3.553069852, Training Accuracy: 14.320\n",
            "Worker 8, [10/37]: Training Loss: 3.460549651, Training Accuracy: 16.464\n",
            "Worker 8, [11/37]: Training Loss: 3.540307626, Training Accuracy: 15.056\n",
            "Worker 8, [12/37]: Training Loss: 3.427408569, Training Accuracy: 17.056\n",
            "Worker 8, [13/37]: Training Loss: 3.489034018, Training Accuracy: 15.872\n",
            "Worker 8, [14/37]: Training Loss: 3.394582101, Training Accuracy: 17.136\n",
            "Worker 8, [15/37]: Training Loss: 3.461517682, Training Accuracy: 16.656\n",
            "Worker 8, [16/37]: Training Loss: 3.364688160, Training Accuracy: 17.968\n",
            "Worker 8, [17/37]: Training Loss: 3.389972971, Training Accuracy: 17.968\n",
            "Worker 8, [18/37]: Training Loss: 3.325859569, Training Accuracy: 18.640\n",
            "Worker 8, [19/37]: Training Loss: 3.389029753, Training Accuracy: 17.120\n",
            "Worker 8, [20/37]: Training Loss: 3.285028137, Training Accuracy: 18.944\n",
            "Worker 8, [21/37]: Training Loss: 3.334658122, Training Accuracy: 18.592\n",
            "Worker 8, [22/37]: Training Loss: 3.247839419, Training Accuracy: 19.808\n",
            "Worker 8, [23/37]: Training Loss: 3.296600515, Training Accuracy: 19.040\n",
            "Worker 8, [24/37]: Training Loss: 3.214687379, Training Accuracy: 20.720\n",
            "Worker 8, [25/37]: Training Loss: 3.238801949, Training Accuracy: 19.856\n",
            "Worker 8, [26/37]: Training Loss: 3.187629325, Training Accuracy: 20.784\n",
            "Worker 8, [27/37]: Training Loss: 3.201450832, Training Accuracy: 21.280\n",
            "Worker 8, [28/37]: Training Loss: 3.139693881, Training Accuracy: 22.176\n",
            "Worker 8, [29/37]: Training Loss: 3.177491986, Training Accuracy: 21.792\n",
            "Worker 8, [30/37]: Training Loss: 3.121564126, Training Accuracy: 23.072\n",
            "Worker 8, [31/37]: Training Loss: 3.162055273, Training Accuracy: 21.664\n",
            "Worker 8, [32/37]: Training Loss: 3.118409760, Training Accuracy: 22.928\n",
            "Worker 8, [33/37]: Training Loss: 3.144629870, Training Accuracy: 22.432\n",
            "Worker 8, [34/37]: Training Loss: 3.103534696, Training Accuracy: 23.232\n",
            "Worker 8, [35/37]: Training Loss: 3.140052355, Training Accuracy: 22.400\n",
            "Worker 8, [36/37]: Training Loss: 3.113460205, Training Accuracy: 22.464\n",
            "Worker 8, [37/37]: Training Loss: 3.135699525, Training Accuracy: 23.152\n",
            "Time taken for training worker 8: 0:01:37.650109\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000749\n",
            "Local Step 03: Test Loss: 3.331195871, Test Accuracy: 20.670\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.439759420, Training Accuracy: 18.064\n",
            "Worker 1, [02/37]: Training Loss: 3.443179554, Training Accuracy: 18.064\n",
            "Worker 1, [03/37]: Training Loss: 3.230343079, Training Accuracy: 22.304\n",
            "Worker 1, [04/37]: Training Loss: 3.214097758, Training Accuracy: 21.968\n",
            "Worker 1, [05/37]: Training Loss: 3.211807840, Training Accuracy: 22.176\n",
            "Worker 1, [06/37]: Training Loss: 3.200847755, Training Accuracy: 21.792\n",
            "Worker 1, [07/37]: Training Loss: 3.215161849, Training Accuracy: 22.096\n",
            "Worker 1, [08/37]: Training Loss: 3.196879993, Training Accuracy: 22.000\n",
            "Worker 1, [09/37]: Training Loss: 3.208176391, Training Accuracy: 21.680\n",
            "Worker 1, [10/37]: Training Loss: 3.206491531, Training Accuracy: 22.256\n",
            "Worker 1, [11/37]: Training Loss: 3.233483597, Training Accuracy: 20.656\n",
            "Worker 1, [12/37]: Training Loss: 3.205504938, Training Accuracy: 22.176\n",
            "Worker 1, [13/37]: Training Loss: 3.246639403, Training Accuracy: 21.040\n",
            "Worker 1, [14/37]: Training Loss: 3.225645024, Training Accuracy: 21.440\n",
            "Worker 1, [15/37]: Training Loss: 3.262589596, Training Accuracy: 20.896\n",
            "Worker 1, [16/37]: Training Loss: 3.250775697, Training Accuracy: 20.896\n",
            "Worker 1, [17/37]: Training Loss: 3.306386342, Training Accuracy: 19.392\n",
            "Worker 1, [18/37]: Training Loss: 3.281842745, Training Accuracy: 20.048\n",
            "Worker 1, [19/37]: Training Loss: 3.308946269, Training Accuracy: 19.728\n",
            "Worker 1, [20/37]: Training Loss: 3.284713453, Training Accuracy: 20.064\n",
            "Worker 1, [21/37]: Training Loss: 3.325913811, Training Accuracy: 19.264\n",
            "Worker 1, [22/37]: Training Loss: 3.293119613, Training Accuracy: 19.120\n",
            "Worker 1, [23/37]: Training Loss: 3.350134913, Training Accuracy: 18.352\n",
            "Worker 1, [24/37]: Training Loss: 3.310675682, Training Accuracy: 19.472\n",
            "Worker 1, [25/37]: Training Loss: 3.370813229, Training Accuracy: 18.704\n",
            "Worker 1, [26/37]: Training Loss: 3.308113446, Training Accuracy: 18.944\n",
            "Worker 1, [27/37]: Training Loss: 3.358028745, Training Accuracy: 18.544\n",
            "Worker 1, [28/37]: Training Loss: 3.278657327, Training Accuracy: 19.856\n",
            "Worker 1, [29/37]: Training Loss: 3.365954134, Training Accuracy: 18.208\n",
            "Worker 1, [30/37]: Training Loss: 3.289943946, Training Accuracy: 19.248\n",
            "Worker 1, [31/37]: Training Loss: 3.375215732, Training Accuracy: 18.608\n",
            "Worker 1, [32/37]: Training Loss: 3.284587352, Training Accuracy: 19.376\n",
            "Worker 1, [33/37]: Training Loss: 3.366156795, Training Accuracy: 19.120\n",
            "Worker 1, [34/37]: Training Loss: 3.301039411, Training Accuracy: 19.408\n",
            "Worker 1, [35/37]: Training Loss: 3.344217322, Training Accuracy: 19.040\n",
            "Worker 1, [36/37]: Training Loss: 3.247399695, Training Accuracy: 20.176\n",
            "Worker 1, [37/37]: Training Loss: 3.327925865, Training Accuracy: 18.368\n",
            "Time taken for training worker 1: 0:01:37.465444\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.528395597, Training Accuracy: 16.512\n",
            "Worker 2, [02/37]: Training Loss: 3.514154607, Training Accuracy: 16.752\n",
            "Worker 2, [03/37]: Training Loss: 3.128230893, Training Accuracy: 23.648\n",
            "Worker 2, [04/37]: Training Loss: 3.106557975, Training Accuracy: 23.472\n",
            "Worker 2, [05/37]: Training Loss: 3.114554945, Training Accuracy: 23.280\n",
            "Worker 2, [06/37]: Training Loss: 3.093102810, Training Accuracy: 23.472\n",
            "Worker 2, [07/37]: Training Loss: 3.110824186, Training Accuracy: 22.928\n",
            "Worker 2, [08/37]: Training Loss: 3.082063962, Training Accuracy: 23.600\n",
            "Worker 2, [09/37]: Training Loss: 3.123583660, Training Accuracy: 22.544\n",
            "Worker 2, [10/37]: Training Loss: 3.093113819, Training Accuracy: 23.168\n",
            "Worker 2, [11/37]: Training Loss: 3.136006453, Training Accuracy: 22.304\n",
            "Worker 2, [12/37]: Training Loss: 3.119648700, Training Accuracy: 22.672\n",
            "Worker 2, [13/37]: Training Loss: 3.138168724, Training Accuracy: 22.256\n",
            "Worker 2, [14/37]: Training Loss: 3.118393246, Training Accuracy: 22.464\n",
            "Worker 2, [15/37]: Training Loss: 3.172301781, Training Accuracy: 22.032\n",
            "Worker 2, [16/37]: Training Loss: 3.151185476, Training Accuracy: 22.240\n",
            "Worker 2, [17/37]: Training Loss: 3.189076470, Training Accuracy: 21.152\n",
            "Worker 2, [18/37]: Training Loss: 3.161539080, Training Accuracy: 21.424\n",
            "Worker 2, [19/37]: Training Loss: 3.213379933, Training Accuracy: 20.592\n",
            "Worker 2, [20/37]: Training Loss: 3.176033071, Training Accuracy: 20.720\n",
            "Worker 2, [21/37]: Training Loss: 3.233153022, Training Accuracy: 20.656\n",
            "Worker 2, [22/37]: Training Loss: 3.207554837, Training Accuracy: 20.448\n",
            "Worker 2, [23/37]: Training Loss: 3.240862469, Training Accuracy: 20.176\n",
            "Worker 2, [24/37]: Training Loss: 3.180431249, Training Accuracy: 20.400\n",
            "Worker 2, [25/37]: Training Loss: 3.248359741, Training Accuracy: 19.888\n",
            "Worker 2, [26/37]: Training Loss: 3.212226795, Training Accuracy: 21.056\n",
            "Worker 2, [27/37]: Training Loss: 3.246596684, Training Accuracy: 20.544\n",
            "Worker 2, [28/37]: Training Loss: 3.190809912, Training Accuracy: 20.448\n",
            "Worker 2, [29/37]: Training Loss: 3.257791590, Training Accuracy: 19.216\n",
            "Worker 2, [30/37]: Training Loss: 3.205433777, Training Accuracy: 20.544\n",
            "Worker 2, [31/37]: Training Loss: 3.271052380, Training Accuracy: 19.712\n",
            "Worker 2, [32/37]: Training Loss: 3.192388048, Training Accuracy: 20.512\n",
            "Worker 2, [33/37]: Training Loss: 3.249311790, Training Accuracy: 19.456\n",
            "Worker 2, [34/37]: Training Loss: 3.181053906, Training Accuracy: 20.816\n",
            "Worker 2, [35/37]: Training Loss: 3.224744578, Training Accuracy: 20.304\n",
            "Worker 2, [36/37]: Training Loss: 3.175247246, Training Accuracy: 21.360\n",
            "Worker 2, [37/37]: Training Loss: 3.214050278, Training Accuracy: 20.496\n",
            "Time taken for training worker 2: 0:01:37.058751\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.506489352, Training Accuracy: 17.184\n",
            "Worker 3, [02/37]: Training Loss: 3.494149189, Training Accuracy: 17.264\n",
            "Worker 3, [03/37]: Training Loss: 3.143676373, Training Accuracy: 24.048\n",
            "Worker 3, [04/37]: Training Loss: 3.134869293, Training Accuracy: 23.728\n",
            "Worker 3, [05/37]: Training Loss: 3.146191835, Training Accuracy: 23.728\n",
            "Worker 3, [06/37]: Training Loss: 3.125230699, Training Accuracy: 23.616\n",
            "Worker 3, [07/37]: Training Loss: 3.150273561, Training Accuracy: 23.248\n",
            "Worker 3, [08/37]: Training Loss: 3.120191153, Training Accuracy: 24.112\n",
            "Worker 3, [09/37]: Training Loss: 3.133062445, Training Accuracy: 24.080\n",
            "Worker 3, [10/37]: Training Loss: 3.131571281, Training Accuracy: 23.664\n",
            "Worker 3, [11/37]: Training Loss: 3.152153845, Training Accuracy: 22.896\n",
            "Worker 3, [12/37]: Training Loss: 3.151722093, Training Accuracy: 22.272\n",
            "Worker 3, [13/37]: Training Loss: 3.191528520, Training Accuracy: 22.144\n",
            "Worker 3, [14/37]: Training Loss: 3.162630261, Training Accuracy: 21.904\n",
            "Worker 3, [15/37]: Training Loss: 3.205275674, Training Accuracy: 21.760\n",
            "Worker 3, [16/37]: Training Loss: 3.172020309, Training Accuracy: 21.744\n",
            "Worker 3, [17/37]: Training Loss: 3.192893174, Training Accuracy: 22.304\n",
            "Worker 3, [18/37]: Training Loss: 3.183621312, Training Accuracy: 21.808\n",
            "Worker 3, [19/37]: Training Loss: 3.230018555, Training Accuracy: 21.168\n",
            "Worker 3, [20/37]: Training Loss: 3.217259451, Training Accuracy: 21.264\n",
            "Worker 3, [21/37]: Training Loss: 3.234925586, Training Accuracy: 21.392\n",
            "Worker 3, [22/37]: Training Loss: 3.204997892, Training Accuracy: 21.168\n",
            "Worker 3, [23/37]: Training Loss: 3.273499815, Training Accuracy: 20.528\n",
            "Worker 3, [24/37]: Training Loss: 3.209849654, Training Accuracy: 21.072\n",
            "Worker 3, [25/37]: Training Loss: 3.266487742, Training Accuracy: 20.416\n",
            "Worker 3, [26/37]: Training Loss: 3.240666100, Training Accuracy: 20.192\n",
            "Worker 3, [27/37]: Training Loss: 3.281320178, Training Accuracy: 20.192\n",
            "Worker 3, [28/37]: Training Loss: 3.226042331, Training Accuracy: 21.328\n",
            "Worker 3, [29/37]: Training Loss: 3.295616432, Training Accuracy: 19.632\n",
            "Worker 3, [30/37]: Training Loss: 3.232394598, Training Accuracy: 21.264\n",
            "Worker 3, [31/37]: Training Loss: 3.272168150, Training Accuracy: 19.888\n",
            "Worker 3, [32/37]: Training Loss: 3.241898761, Training Accuracy: 20.752\n",
            "Worker 3, [33/37]: Training Loss: 3.270143095, Training Accuracy: 20.176\n",
            "Worker 3, [34/37]: Training Loss: 3.200628110, Training Accuracy: 21.040\n",
            "Worker 3, [35/37]: Training Loss: 3.259246201, Training Accuracy: 20.528\n",
            "Worker 3, [36/37]: Training Loss: 3.201345726, Training Accuracy: 21.184\n",
            "Worker 3, [37/37]: Training Loss: 3.243405858, Training Accuracy: 20.800\n",
            "Time taken for training worker 3: 0:01:38.985609\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.486782526, Training Accuracy: 16.544\n",
            "Worker 4, [02/37]: Training Loss: 3.459694945, Training Accuracy: 16.848\n",
            "Worker 4, [03/37]: Training Loss: 3.126464542, Training Accuracy: 24.032\n",
            "Worker 4, [04/37]: Training Loss: 3.122279048, Training Accuracy: 23.888\n",
            "Worker 4, [05/37]: Training Loss: 3.118579947, Training Accuracy: 23.376\n",
            "Worker 4, [06/37]: Training Loss: 3.097169582, Training Accuracy: 24.304\n",
            "Worker 4, [07/37]: Training Loss: 3.122938845, Training Accuracy: 23.600\n",
            "Worker 4, [08/37]: Training Loss: 3.095430574, Training Accuracy: 24.112\n",
            "Worker 4, [09/37]: Training Loss: 3.115232949, Training Accuracy: 23.024\n",
            "Worker 4, [10/37]: Training Loss: 3.107977736, Training Accuracy: 23.040\n",
            "Worker 4, [11/37]: Training Loss: 3.135001326, Training Accuracy: 22.336\n",
            "Worker 4, [12/37]: Training Loss: 3.124348446, Training Accuracy: 22.768\n",
            "Worker 4, [13/37]: Training Loss: 3.143742447, Training Accuracy: 22.512\n",
            "Worker 4, [14/37]: Training Loss: 3.165882269, Training Accuracy: 22.288\n",
            "Worker 4, [15/37]: Training Loss: 3.186475635, Training Accuracy: 21.552\n",
            "Worker 4, [16/37]: Training Loss: 3.166623675, Training Accuracy: 21.856\n",
            "Worker 4, [17/37]: Training Loss: 3.207228164, Training Accuracy: 21.488\n",
            "Worker 4, [18/37]: Training Loss: 3.154365956, Training Accuracy: 21.808\n",
            "Worker 4, [19/37]: Training Loss: 3.207751710, Training Accuracy: 21.408\n",
            "Worker 4, [20/37]: Training Loss: 3.152082545, Training Accuracy: 22.416\n",
            "Worker 4, [21/37]: Training Loss: 3.221501406, Training Accuracy: 21.008\n",
            "Worker 4, [22/37]: Training Loss: 3.196691260, Training Accuracy: 20.768\n",
            "Worker 4, [23/37]: Training Loss: 3.257664398, Training Accuracy: 20.112\n",
            "Worker 4, [24/37]: Training Loss: 3.236583846, Training Accuracy: 20.352\n",
            "Worker 4, [25/37]: Training Loss: 3.259541283, Training Accuracy: 20.048\n",
            "Worker 4, [26/37]: Training Loss: 3.182540565, Training Accuracy: 21.264\n",
            "Worker 4, [27/37]: Training Loss: 3.256495111, Training Accuracy: 19.984\n",
            "Worker 4, [28/37]: Training Loss: 3.190613773, Training Accuracy: 21.296\n",
            "Worker 4, [29/37]: Training Loss: 3.260069575, Training Accuracy: 19.776\n",
            "Worker 4, [30/37]: Training Loss: 3.221309596, Training Accuracy: 20.608\n",
            "Worker 4, [31/37]: Training Loss: 3.278314233, Training Accuracy: 19.680\n",
            "Worker 4, [32/37]: Training Loss: 3.222317455, Training Accuracy: 20.944\n",
            "Worker 4, [33/37]: Training Loss: 3.250412136, Training Accuracy: 19.520\n",
            "Worker 4, [34/37]: Training Loss: 3.213797170, Training Accuracy: 20.816\n",
            "Worker 4, [35/37]: Training Loss: 3.253548844, Training Accuracy: 19.456\n",
            "Worker 4, [36/37]: Training Loss: 3.183985102, Training Accuracy: 20.704\n",
            "Worker 4, [37/37]: Training Loss: 3.240578226, Training Accuracy: 20.320\n",
            "Time taken for training worker 4: 0:01:37.611853\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.520384745, Training Accuracy: 16.576\n",
            "Worker 5, [02/37]: Training Loss: 3.494820016, Training Accuracy: 17.152\n",
            "Worker 5, [03/37]: Training Loss: 3.127487190, Training Accuracy: 23.232\n",
            "Worker 5, [04/37]: Training Loss: 3.116043212, Training Accuracy: 23.600\n",
            "Worker 5, [05/37]: Training Loss: 3.120956822, Training Accuracy: 23.712\n",
            "Worker 5, [06/37]: Training Loss: 3.105557181, Training Accuracy: 23.440\n",
            "Worker 5, [07/37]: Training Loss: 3.135097453, Training Accuracy: 22.176\n",
            "Worker 5, [08/37]: Training Loss: 3.106740917, Training Accuracy: 23.472\n",
            "Worker 5, [09/37]: Training Loss: 3.137772991, Training Accuracy: 22.480\n",
            "Worker 5, [10/37]: Training Loss: 3.105155743, Training Accuracy: 23.216\n",
            "Worker 5, [11/37]: Training Loss: 3.132481704, Training Accuracy: 23.312\n",
            "Worker 5, [12/37]: Training Loss: 3.108440971, Training Accuracy: 22.464\n",
            "Worker 5, [13/37]: Training Loss: 3.172311751, Training Accuracy: 21.936\n",
            "Worker 5, [14/37]: Training Loss: 3.136311516, Training Accuracy: 22.336\n",
            "Worker 5, [15/37]: Training Loss: 3.184364891, Training Accuracy: 21.008\n",
            "Worker 5, [16/37]: Training Loss: 3.148339019, Training Accuracy: 22.384\n",
            "Worker 5, [17/37]: Training Loss: 3.193487822, Training Accuracy: 21.616\n",
            "Worker 5, [18/37]: Training Loss: 3.183630245, Training Accuracy: 20.720\n",
            "Worker 5, [19/37]: Training Loss: 3.233114240, Training Accuracy: 20.816\n",
            "Worker 5, [20/37]: Training Loss: 3.194773406, Training Accuracy: 20.896\n",
            "Worker 5, [21/37]: Training Loss: 3.236841625, Training Accuracy: 19.984\n",
            "Worker 5, [22/37]: Training Loss: 3.186510130, Training Accuracy: 21.696\n",
            "Worker 5, [23/37]: Training Loss: 3.266864108, Training Accuracy: 19.616\n",
            "Worker 5, [24/37]: Training Loss: 3.210779613, Training Accuracy: 21.008\n",
            "Worker 5, [25/37]: Training Loss: 3.269609206, Training Accuracy: 19.712\n",
            "Worker 5, [26/37]: Training Loss: 3.224498021, Training Accuracy: 20.272\n",
            "Worker 5, [27/37]: Training Loss: 3.270191348, Training Accuracy: 20.048\n",
            "Worker 5, [28/37]: Training Loss: 3.259261389, Training Accuracy: 20.048\n",
            "Worker 5, [29/37]: Training Loss: 3.317887803, Training Accuracy: 18.928\n",
            "Worker 5, [30/37]: Training Loss: 3.224278051, Training Accuracy: 20.064\n",
            "Worker 5, [31/37]: Training Loss: 3.271183700, Training Accuracy: 19.616\n",
            "Worker 5, [32/37]: Training Loss: 3.229569983, Training Accuracy: 20.544\n",
            "Worker 5, [33/37]: Training Loss: 3.263035093, Training Accuracy: 20.048\n",
            "Worker 5, [34/37]: Training Loss: 3.206911357, Training Accuracy: 21.280\n",
            "Worker 5, [35/37]: Training Loss: 3.268077712, Training Accuracy: 20.048\n",
            "Worker 5, [36/37]: Training Loss: 3.229467533, Training Accuracy: 20.528\n",
            "Worker 5, [37/37]: Training Loss: 3.255946561, Training Accuracy: 19.408\n",
            "Time taken for training worker 5: 0:01:37.779980\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.498009913, Training Accuracy: 16.688\n",
            "Worker 6, [02/37]: Training Loss: 3.478299494, Training Accuracy: 17.248\n",
            "Worker 6, [03/37]: Training Loss: 3.158947864, Training Accuracy: 22.928\n",
            "Worker 6, [04/37]: Training Loss: 3.141312356, Training Accuracy: 23.056\n",
            "Worker 6, [05/37]: Training Loss: 3.138402104, Training Accuracy: 23.120\n",
            "Worker 6, [06/37]: Training Loss: 3.123504865, Training Accuracy: 23.072\n",
            "Worker 6, [07/37]: Training Loss: 3.135343926, Training Accuracy: 22.848\n",
            "Worker 6, [08/37]: Training Loss: 3.126812164, Training Accuracy: 22.960\n",
            "Worker 6, [09/37]: Training Loss: 3.148435279, Training Accuracy: 23.152\n",
            "Worker 6, [10/37]: Training Loss: 3.117941158, Training Accuracy: 22.576\n",
            "Worker 6, [11/37]: Training Loss: 3.160052000, Training Accuracy: 22.016\n",
            "Worker 6, [12/37]: Training Loss: 3.143145483, Training Accuracy: 22.272\n",
            "Worker 6, [13/37]: Training Loss: 3.160545120, Training Accuracy: 22.176\n",
            "Worker 6, [14/37]: Training Loss: 3.154022681, Training Accuracy: 21.776\n",
            "Worker 6, [15/37]: Training Loss: 3.194356514, Training Accuracy: 21.248\n",
            "Worker 6, [16/37]: Training Loss: 3.166071658, Training Accuracy: 22.032\n",
            "Worker 6, [17/37]: Training Loss: 3.223270679, Training Accuracy: 20.496\n",
            "Worker 6, [18/37]: Training Loss: 3.192210752, Training Accuracy: 20.384\n",
            "Worker 6, [19/37]: Training Loss: 3.228370394, Training Accuracy: 20.928\n",
            "Worker 6, [20/37]: Training Loss: 3.200565226, Training Accuracy: 20.992\n",
            "Worker 6, [21/37]: Training Loss: 3.268388142, Training Accuracy: 19.728\n",
            "Worker 6, [22/37]: Training Loss: 3.211941855, Training Accuracy: 20.592\n",
            "Worker 6, [23/37]: Training Loss: 3.275931186, Training Accuracy: 19.824\n",
            "Worker 6, [24/37]: Training Loss: 3.235088246, Training Accuracy: 20.000\n",
            "Worker 6, [25/37]: Training Loss: 3.260857575, Training Accuracy: 19.872\n",
            "Worker 6, [26/37]: Training Loss: 3.209361266, Training Accuracy: 20.512\n",
            "Worker 6, [27/37]: Training Loss: 3.281687732, Training Accuracy: 19.472\n",
            "Worker 6, [28/37]: Training Loss: 3.235440286, Training Accuracy: 19.856\n",
            "Worker 6, [29/37]: Training Loss: 3.272608947, Training Accuracy: 19.200\n",
            "Worker 6, [30/37]: Training Loss: 3.230599150, Training Accuracy: 19.728\n",
            "Worker 6, [31/37]: Training Loss: 3.270280875, Training Accuracy: 19.152\n",
            "Worker 6, [32/37]: Training Loss: 3.229268556, Training Accuracy: 20.112\n",
            "Worker 6, [33/37]: Training Loss: 3.278986306, Training Accuracy: 19.824\n",
            "Worker 6, [34/37]: Training Loss: 3.222348223, Training Accuracy: 20.864\n",
            "Worker 6, [35/37]: Training Loss: 3.256724343, Training Accuracy: 19.936\n",
            "Worker 6, [36/37]: Training Loss: 3.194647448, Training Accuracy: 20.704\n",
            "Worker 6, [37/37]: Training Loss: 3.261264069, Training Accuracy: 19.312\n",
            "Time taken for training worker 6: 0:01:37.245065\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.601797552, Training Accuracy: 14.496\n",
            "Worker 7, [02/37]: Training Loss: 3.547132711, Training Accuracy: 14.720\n",
            "Worker 7, [03/37]: Training Loss: 3.155188592, Training Accuracy: 22.864\n",
            "Worker 7, [04/37]: Training Loss: 3.127349980, Training Accuracy: 23.104\n",
            "Worker 7, [05/37]: Training Loss: 3.134745320, Training Accuracy: 23.616\n",
            "Worker 7, [06/37]: Training Loss: 3.121422262, Training Accuracy: 23.520\n",
            "Worker 7, [07/37]: Training Loss: 3.144220552, Training Accuracy: 22.384\n",
            "Worker 7, [08/37]: Training Loss: 3.119713632, Training Accuracy: 22.784\n",
            "Worker 7, [09/37]: Training Loss: 3.143284805, Training Accuracy: 23.184\n",
            "Worker 7, [10/37]: Training Loss: 3.134101714, Training Accuracy: 22.448\n",
            "Worker 7, [11/37]: Training Loss: 3.148541061, Training Accuracy: 22.896\n",
            "Worker 7, [12/37]: Training Loss: 3.138098167, Training Accuracy: 22.064\n",
            "Worker 7, [13/37]: Training Loss: 3.176525936, Training Accuracy: 22.144\n",
            "Worker 7, [14/37]: Training Loss: 3.139710704, Training Accuracy: 22.256\n",
            "Worker 7, [15/37]: Training Loss: 3.176822224, Training Accuracy: 21.536\n",
            "Worker 7, [16/37]: Training Loss: 3.160985054, Training Accuracy: 21.744\n",
            "Worker 7, [17/37]: Training Loss: 3.221840348, Training Accuracy: 20.672\n",
            "Worker 7, [18/37]: Training Loss: 3.189101392, Training Accuracy: 21.696\n",
            "Worker 7, [19/37]: Training Loss: 3.232553903, Training Accuracy: 19.728\n",
            "Worker 7, [20/37]: Training Loss: 3.231756164, Training Accuracy: 20.288\n",
            "Worker 7, [21/37]: Training Loss: 3.249799580, Training Accuracy: 19.872\n",
            "Worker 7, [22/37]: Training Loss: 3.220369174, Training Accuracy: 19.808\n",
            "Worker 7, [23/37]: Training Loss: 3.278493246, Training Accuracy: 19.792\n",
            "Worker 7, [24/37]: Training Loss: 3.232353879, Training Accuracy: 20.096\n",
            "Worker 7, [25/37]: Training Loss: 3.284653109, Training Accuracy: 18.976\n",
            "Worker 7, [26/37]: Training Loss: 3.241600399, Training Accuracy: 19.568\n",
            "Worker 7, [27/37]: Training Loss: 3.279536398, Training Accuracy: 19.424\n",
            "Worker 7, [28/37]: Training Loss: 3.240350373, Training Accuracy: 20.176\n",
            "Worker 7, [29/37]: Training Loss: 3.281271635, Training Accuracy: 19.232\n",
            "Worker 7, [30/37]: Training Loss: 3.245617149, Training Accuracy: 19.680\n",
            "Worker 7, [31/37]: Training Loss: 3.283651009, Training Accuracy: 19.008\n",
            "Worker 7, [32/37]: Training Loss: 3.263240970, Training Accuracy: 19.504\n",
            "Worker 7, [33/37]: Training Loss: 3.276900479, Training Accuracy: 18.992\n",
            "Worker 7, [34/37]: Training Loss: 3.194178503, Training Accuracy: 20.272\n",
            "Worker 7, [35/37]: Training Loss: 3.265031737, Training Accuracy: 20.064\n",
            "Worker 7, [36/37]: Training Loss: 3.198480832, Training Accuracy: 20.608\n",
            "Worker 7, [37/37]: Training Loss: 3.271866127, Training Accuracy: 19.600\n",
            "Time taken for training worker 7: 0:01:37.839356\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.527848657, Training Accuracy: 16.240\n",
            "Worker 8, [02/37]: Training Loss: 3.498843675, Training Accuracy: 16.512\n",
            "Worker 8, [03/37]: Training Loss: 3.158864887, Training Accuracy: 22.400\n",
            "Worker 8, [04/37]: Training Loss: 3.132237254, Training Accuracy: 22.688\n",
            "Worker 8, [05/37]: Training Loss: 3.134564563, Training Accuracy: 22.832\n",
            "Worker 8, [06/37]: Training Loss: 3.119150809, Training Accuracy: 22.496\n",
            "Worker 8, [07/37]: Training Loss: 3.141952634, Training Accuracy: 22.560\n",
            "Worker 8, [08/37]: Training Loss: 3.112512623, Training Accuracy: 22.800\n",
            "Worker 8, [09/37]: Training Loss: 3.143683531, Training Accuracy: 22.192\n",
            "Worker 8, [10/37]: Training Loss: 3.134266036, Training Accuracy: 22.576\n",
            "Worker 8, [11/37]: Training Loss: 3.160251459, Training Accuracy: 21.376\n",
            "Worker 8, [12/37]: Training Loss: 3.146226759, Training Accuracy: 21.824\n",
            "Worker 8, [13/37]: Training Loss: 3.177275188, Training Accuracy: 21.168\n",
            "Worker 8, [14/37]: Training Loss: 3.146884977, Training Accuracy: 21.936\n",
            "Worker 8, [15/37]: Training Loss: 3.192285749, Training Accuracy: 21.344\n",
            "Worker 8, [16/37]: Training Loss: 3.172295648, Training Accuracy: 21.088\n",
            "Worker 8, [17/37]: Training Loss: 3.230138389, Training Accuracy: 20.048\n",
            "Worker 8, [18/37]: Training Loss: 3.184081793, Training Accuracy: 20.544\n",
            "Worker 8, [19/37]: Training Loss: 3.240656850, Training Accuracy: 20.256\n",
            "Worker 8, [20/37]: Training Loss: 3.221673481, Training Accuracy: 20.336\n",
            "Worker 8, [21/37]: Training Loss: 3.247605295, Training Accuracy: 19.184\n",
            "Worker 8, [22/37]: Training Loss: 3.235573747, Training Accuracy: 20.496\n",
            "Worker 8, [23/37]: Training Loss: 3.269689565, Training Accuracy: 19.184\n",
            "Worker 8, [24/37]: Training Loss: 3.239821940, Training Accuracy: 20.144\n",
            "Worker 8, [25/37]: Training Loss: 3.302337656, Training Accuracy: 18.384\n",
            "Worker 8, [26/37]: Training Loss: 3.215414191, Training Accuracy: 20.752\n",
            "Worker 8, [27/37]: Training Loss: 3.277121539, Training Accuracy: 19.232\n",
            "Worker 8, [28/37]: Training Loss: 3.236665886, Training Accuracy: 19.680\n",
            "Worker 8, [29/37]: Training Loss: 3.278911238, Training Accuracy: 18.832\n",
            "Worker 8, [30/37]: Training Loss: 3.252508555, Training Accuracy: 19.664\n",
            "Worker 8, [31/37]: Training Loss: 3.278953470, Training Accuracy: 19.264\n",
            "Worker 8, [32/37]: Training Loss: 3.238757357, Training Accuracy: 19.616\n",
            "Worker 8, [33/37]: Training Loss: 3.301840770, Training Accuracy: 18.400\n",
            "Worker 8, [34/37]: Training Loss: 3.233701093, Training Accuracy: 19.680\n",
            "Worker 8, [35/37]: Training Loss: 3.268297118, Training Accuracy: 19.184\n",
            "Worker 8, [36/37]: Training Loss: 3.226104306, Training Accuracy: 20.048\n",
            "Worker 8, [37/37]: Training Loss: 3.233660399, Training Accuracy: 19.664\n",
            "Time taken for training worker 8: 0:01:36.651992\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000697\n",
            "Local Step 04: Test Loss: 3.377218511, Test Accuracy: 18.920\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:12.097250\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.592765433, Training Accuracy: 2.080\n",
            "Worker 1, [02/37]: Training Loss: 4.470741408, Training Accuracy: 2.784\n",
            "Worker 1, [03/37]: Training Loss: 4.209794249, Training Accuracy: 5.632\n",
            "Worker 1, [04/37]: Training Loss: 4.050644819, Training Accuracy: 7.392\n",
            "Worker 1, [05/37]: Training Loss: 4.538685779, Training Accuracy: 2.448\n",
            "Worker 1, [06/37]: Training Loss: 4.228837534, Training Accuracy: 5.632\n",
            "Worker 1, [07/37]: Training Loss: 4.044891007, Training Accuracy: 7.760\n",
            "Worker 1, [08/37]: Training Loss: 3.914408910, Training Accuracy: 9.968\n",
            "Worker 1, [09/37]: Training Loss: 4.416377861, Training Accuracy: 3.472\n",
            "Worker 1, [10/37]: Training Loss: 4.103502040, Training Accuracy: 7.008\n",
            "Worker 1, [11/37]: Training Loss: 3.935297370, Training Accuracy: 9.536\n",
            "Worker 1, [12/37]: Training Loss: 3.822743394, Training Accuracy: 11.792\n",
            "Worker 1, [13/37]: Training Loss: 4.283117540, Training Accuracy: 5.840\n",
            "Worker 1, [14/37]: Training Loss: 3.991236801, Training Accuracy: 8.656\n",
            "Worker 1, [15/37]: Training Loss: 3.853124828, Training Accuracy: 10.688\n",
            "Worker 1, [16/37]: Training Loss: 3.760839613, Training Accuracy: 12.176\n",
            "Worker 1, [17/37]: Training Loss: 4.209331598, Training Accuracy: 6.480\n",
            "Worker 1, [18/37]: Training Loss: 3.927572083, Training Accuracy: 9.120\n",
            "Worker 1, [19/37]: Training Loss: 3.802199838, Training Accuracy: 11.504\n",
            "Worker 1, [20/37]: Training Loss: 3.712866781, Training Accuracy: 12.944\n",
            "Worker 1, [21/37]: Training Loss: 4.174595531, Training Accuracy: 7.808\n",
            "Worker 1, [22/37]: Training Loss: 3.891482195, Training Accuracy: 10.176\n",
            "Worker 1, [23/37]: Training Loss: 3.771394649, Training Accuracy: 12.832\n",
            "Worker 1, [24/37]: Training Loss: 3.683641246, Training Accuracy: 13.856\n",
            "Worker 1, [25/37]: Training Loss: 4.102255344, Training Accuracy: 9.904\n",
            "Worker 1, [26/37]: Training Loss: 3.844532867, Training Accuracy: 11.440\n",
            "Worker 1, [27/37]: Training Loss: 3.747825284, Training Accuracy: 12.736\n",
            "Worker 1, [28/37]: Training Loss: 3.693280040, Training Accuracy: 13.744\n",
            "Worker 1, [29/37]: Training Loss: 4.098562854, Training Accuracy: 10.224\n",
            "Worker 1, [30/37]: Training Loss: 3.836685852, Training Accuracy: 11.792\n",
            "Worker 1, [31/37]: Training Loss: 3.774138808, Training Accuracy: 12.944\n",
            "Worker 1, [32/37]: Training Loss: 3.725129451, Training Accuracy: 14.064\n",
            "Worker 1, [33/37]: Training Loss: 4.162637706, Training Accuracy: 11.712\n",
            "Worker 1, [34/37]: Training Loss: 3.967306081, Training Accuracy: 11.680\n",
            "Worker 1, [35/37]: Training Loss: 3.901801640, Training Accuracy: 11.952\n",
            "Worker 1, [36/37]: Training Loss: 3.868499369, Training Accuracy: 11.936\n",
            "Worker 1, [37/37]: Training Loss: 4.224944669, Training Accuracy: 12.784\n",
            "Time taken for training worker 1: 0:01:39.358544\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.593813984, Training Accuracy: 1.296\n",
            "Worker 2, [02/37]: Training Loss: 4.427262637, Training Accuracy: 3.440\n",
            "Worker 2, [03/37]: Training Loss: 4.173500728, Training Accuracy: 5.632\n",
            "Worker 2, [04/37]: Training Loss: 4.045393131, Training Accuracy: 7.072\n",
            "Worker 2, [05/37]: Training Loss: 4.530811684, Training Accuracy: 2.640\n",
            "Worker 2, [06/37]: Training Loss: 4.207100163, Training Accuracy: 6.032\n",
            "Worker 2, [07/37]: Training Loss: 4.030618064, Training Accuracy: 7.776\n",
            "Worker 2, [08/37]: Training Loss: 3.900142993, Training Accuracy: 9.232\n",
            "Worker 2, [09/37]: Training Loss: 4.382240972, Training Accuracy: 4.016\n",
            "Worker 2, [10/37]: Training Loss: 4.053738502, Training Accuracy: 7.632\n",
            "Worker 2, [11/37]: Training Loss: 3.899242148, Training Accuracy: 9.616\n",
            "Worker 2, [12/37]: Training Loss: 3.786028091, Training Accuracy: 10.704\n",
            "Worker 2, [13/37]: Training Loss: 4.294528265, Training Accuracy: 5.440\n",
            "Worker 2, [14/37]: Training Loss: 3.973986224, Training Accuracy: 8.448\n",
            "Worker 2, [15/37]: Training Loss: 3.832247520, Training Accuracy: 10.544\n",
            "Worker 2, [16/37]: Training Loss: 3.711717382, Training Accuracy: 12.400\n",
            "Worker 2, [17/37]: Training Loss: 4.191920188, Training Accuracy: 6.656\n",
            "Worker 2, [18/37]: Training Loss: 3.903713978, Training Accuracy: 9.632\n",
            "Worker 2, [19/37]: Training Loss: 3.775492311, Training Accuracy: 11.616\n",
            "Worker 2, [20/37]: Training Loss: 3.679085050, Training Accuracy: 13.008\n",
            "Worker 2, [21/37]: Training Loss: 4.137869358, Training Accuracy: 7.456\n",
            "Worker 2, [22/37]: Training Loss: 3.847331052, Training Accuracy: 10.064\n",
            "Worker 2, [23/37]: Training Loss: 3.740988911, Training Accuracy: 11.712\n",
            "Worker 2, [24/37]: Training Loss: 3.652646566, Training Accuracy: 13.232\n",
            "Worker 2, [25/37]: Training Loss: 4.083517140, Training Accuracy: 9.120\n",
            "Worker 2, [26/37]: Training Loss: 3.807012818, Training Accuracy: 11.312\n",
            "Worker 2, [27/37]: Training Loss: 3.720676853, Training Accuracy: 12.528\n",
            "Worker 2, [28/37]: Training Loss: 3.649166207, Training Accuracy: 13.584\n",
            "Worker 2, [29/37]: Training Loss: 4.070249363, Training Accuracy: 10.800\n",
            "Worker 2, [30/37]: Training Loss: 3.817021217, Training Accuracy: 11.488\n",
            "Worker 2, [31/37]: Training Loss: 3.741972770, Training Accuracy: 12.704\n",
            "Worker 2, [32/37]: Training Loss: 3.687173914, Training Accuracy: 13.776\n",
            "Worker 2, [33/37]: Training Loss: 4.149643489, Training Accuracy: 11.872\n",
            "Worker 2, [34/37]: Training Loss: 3.954564564, Training Accuracy: 11.200\n",
            "Worker 2, [35/37]: Training Loss: 3.870568156, Training Accuracy: 12.080\n",
            "Worker 2, [36/37]: Training Loss: 3.840973204, Training Accuracy: 12.144\n",
            "Worker 2, [37/37]: Training Loss: 4.213016257, Training Accuracy: 12.416\n",
            "Time taken for training worker 2: 0:01:36.593838\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.594577050, Training Accuracy: 1.600\n",
            "Worker 3, [02/37]: Training Loss: 4.461178196, Training Accuracy: 3.120\n",
            "Worker 3, [03/37]: Training Loss: 4.197829991, Training Accuracy: 5.648\n",
            "Worker 3, [04/37]: Training Loss: 4.071259849, Training Accuracy: 7.472\n",
            "Worker 3, [05/37]: Training Loss: 4.520262514, Training Accuracy: 2.352\n",
            "Worker 3, [06/37]: Training Loss: 4.217571363, Training Accuracy: 5.584\n",
            "Worker 3, [07/37]: Training Loss: 4.032304338, Training Accuracy: 7.744\n",
            "Worker 3, [08/37]: Training Loss: 3.897358821, Training Accuracy: 9.536\n",
            "Worker 3, [09/37]: Training Loss: 4.397175954, Training Accuracy: 4.368\n",
            "Worker 3, [10/37]: Training Loss: 4.095136256, Training Accuracy: 6.576\n",
            "Worker 3, [11/37]: Training Loss: 3.909776033, Training Accuracy: 9.264\n",
            "Worker 3, [12/37]: Training Loss: 3.798671975, Training Accuracy: 11.152\n",
            "Worker 3, [13/37]: Training Loss: 4.269973512, Training Accuracy: 5.664\n",
            "Worker 3, [14/37]: Training Loss: 3.985433153, Training Accuracy: 8.576\n",
            "Worker 3, [15/37]: Training Loss: 3.821171279, Training Accuracy: 11.200\n",
            "Worker 3, [16/37]: Training Loss: 3.740538079, Training Accuracy: 12.112\n",
            "Worker 3, [17/37]: Training Loss: 4.224231620, Training Accuracy: 6.288\n",
            "Worker 3, [18/37]: Training Loss: 3.911060949, Training Accuracy: 9.792\n",
            "Worker 3, [19/37]: Training Loss: 3.772937996, Training Accuracy: 11.952\n",
            "Worker 3, [20/37]: Training Loss: 3.682489106, Training Accuracy: 13.776\n",
            "Worker 3, [21/37]: Training Loss: 4.155876087, Training Accuracy: 7.744\n",
            "Worker 3, [22/37]: Training Loss: 3.860184436, Training Accuracy: 10.224\n",
            "Worker 3, [23/37]: Training Loss: 3.727004105, Training Accuracy: 13.360\n",
            "Worker 3, [24/37]: Training Loss: 3.673328319, Training Accuracy: 13.520\n",
            "Worker 3, [25/37]: Training Loss: 4.094760145, Training Accuracy: 8.928\n",
            "Worker 3, [26/37]: Training Loss: 3.837375035, Training Accuracy: 11.152\n",
            "Worker 3, [27/37]: Training Loss: 3.734323964, Training Accuracy: 12.992\n",
            "Worker 3, [28/37]: Training Loss: 3.667063808, Training Accuracy: 13.664\n",
            "Worker 3, [29/37]: Training Loss: 4.096159704, Training Accuracy: 10.352\n",
            "Worker 3, [30/37]: Training Loss: 3.835435726, Training Accuracy: 11.296\n",
            "Worker 3, [31/37]: Training Loss: 3.752248029, Training Accuracy: 13.024\n",
            "Worker 3, [32/37]: Training Loss: 3.702610434, Training Accuracy: 14.080\n",
            "Worker 3, [33/37]: Training Loss: 4.165840884, Training Accuracy: 11.472\n",
            "Worker 3, [34/37]: Training Loss: 3.972315100, Training Accuracy: 11.216\n",
            "Worker 3, [35/37]: Training Loss: 3.883387057, Training Accuracy: 12.384\n",
            "Worker 3, [36/37]: Training Loss: 3.860155760, Training Accuracy: 12.416\n",
            "Worker 3, [37/37]: Training Loss: 4.230582622, Training Accuracy: 12.416\n",
            "Time taken for training worker 3: 0:01:36.053217\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.594281163, Training Accuracy: 1.472\n",
            "Worker 4, [02/37]: Training Loss: 4.464145227, Training Accuracy: 3.200\n",
            "Worker 4, [03/37]: Training Loss: 4.192853675, Training Accuracy: 6.320\n",
            "Worker 4, [04/37]: Training Loss: 4.044960886, Training Accuracy: 7.616\n",
            "Worker 4, [05/37]: Training Loss: 4.487293939, Training Accuracy: 3.248\n",
            "Worker 4, [06/37]: Training Loss: 4.157277022, Training Accuracy: 6.272\n",
            "Worker 4, [07/37]: Training Loss: 3.998294249, Training Accuracy: 8.608\n",
            "Worker 4, [08/37]: Training Loss: 3.871433859, Training Accuracy: 9.744\n",
            "Worker 4, [09/37]: Training Loss: 4.393437653, Training Accuracy: 3.840\n",
            "Worker 4, [10/37]: Training Loss: 4.079225127, Training Accuracy: 7.488\n",
            "Worker 4, [11/37]: Training Loss: 3.905251155, Training Accuracy: 10.048\n",
            "Worker 4, [12/37]: Training Loss: 3.785171397, Training Accuracy: 11.632\n",
            "Worker 4, [13/37]: Training Loss: 4.277538840, Training Accuracy: 6.016\n",
            "Worker 4, [14/37]: Training Loss: 3.971440982, Training Accuracy: 8.848\n",
            "Worker 4, [15/37]: Training Loss: 3.819445345, Training Accuracy: 10.288\n",
            "Worker 4, [16/37]: Training Loss: 3.721332594, Training Accuracy: 12.576\n",
            "Worker 4, [17/37]: Training Loss: 4.234737311, Training Accuracy: 7.136\n",
            "Worker 4, [18/37]: Training Loss: 3.918477985, Training Accuracy: 9.296\n",
            "Worker 4, [19/37]: Training Loss: 3.761975232, Training Accuracy: 11.824\n",
            "Worker 4, [20/37]: Training Loss: 3.678528399, Training Accuracy: 12.992\n",
            "Worker 4, [21/37]: Training Loss: 4.128096060, Training Accuracy: 8.064\n",
            "Worker 4, [22/37]: Training Loss: 3.850769320, Training Accuracy: 10.480\n",
            "Worker 4, [23/37]: Training Loss: 3.732553066, Training Accuracy: 12.176\n",
            "Worker 4, [24/37]: Training Loss: 3.649730561, Training Accuracy: 13.504\n",
            "Worker 4, [25/37]: Training Loss: 4.085216179, Training Accuracy: 9.504\n",
            "Worker 4, [26/37]: Training Loss: 3.817349032, Training Accuracy: 11.840\n",
            "Worker 4, [27/37]: Training Loss: 3.712859674, Training Accuracy: 12.928\n",
            "Worker 4, [28/37]: Training Loss: 3.643170807, Training Accuracy: 14.768\n",
            "Worker 4, [29/37]: Training Loss: 4.080476172, Training Accuracy: 10.176\n",
            "Worker 4, [30/37]: Training Loss: 3.828906349, Training Accuracy: 11.488\n",
            "Worker 4, [31/37]: Training Loss: 3.751399001, Training Accuracy: 12.736\n",
            "Worker 4, [32/37]: Training Loss: 3.690126509, Training Accuracy: 13.568\n",
            "Worker 4, [33/37]: Training Loss: 4.157631232, Training Accuracy: 12.240\n",
            "Worker 4, [34/37]: Training Loss: 3.957115059, Training Accuracy: 11.984\n",
            "Worker 4, [35/37]: Training Loss: 3.877385772, Training Accuracy: 12.208\n",
            "Worker 4, [36/37]: Training Loss: 3.849729550, Training Accuracy: 12.192\n",
            "Worker 4, [37/37]: Training Loss: 4.217411737, Training Accuracy: 13.072\n",
            "Time taken for training worker 4: 0:01:38.803781\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 4.594368896, Training Accuracy: 1.744\n",
            "Worker 5, [02/37]: Training Loss: 4.469481473, Training Accuracy: 2.960\n",
            "Worker 5, [03/37]: Training Loss: 4.221967614, Training Accuracy: 5.776\n",
            "Worker 5, [04/37]: Training Loss: 4.051858347, Training Accuracy: 7.408\n",
            "Worker 5, [05/37]: Training Loss: 4.532016959, Training Accuracy: 2.512\n",
            "Worker 5, [06/37]: Training Loss: 4.215102806, Training Accuracy: 5.968\n",
            "Worker 5, [07/37]: Training Loss: 4.028984904, Training Accuracy: 7.872\n",
            "Worker 5, [08/37]: Training Loss: 3.915189346, Training Accuracy: 9.408\n",
            "Worker 5, [09/37]: Training Loss: 4.352158688, Training Accuracy: 5.312\n",
            "Worker 5, [10/37]: Training Loss: 4.066559497, Training Accuracy: 7.520\n",
            "Worker 5, [11/37]: Training Loss: 3.916198621, Training Accuracy: 9.552\n",
            "Worker 5, [12/37]: Training Loss: 3.810872066, Training Accuracy: 10.704\n",
            "Worker 5, [13/37]: Training Loss: 4.294283760, Training Accuracy: 5.136\n",
            "Worker 5, [14/37]: Training Loss: 3.979650775, Training Accuracy: 8.464\n",
            "Worker 5, [15/37]: Training Loss: 3.851055121, Training Accuracy: 11.024\n",
            "Worker 5, [16/37]: Training Loss: 3.743505906, Training Accuracy: 11.760\n",
            "Worker 5, [17/37]: Training Loss: 4.226965885, Training Accuracy: 6.688\n",
            "Worker 5, [18/37]: Training Loss: 3.918989488, Training Accuracy: 9.424\n",
            "Worker 5, [19/37]: Training Loss: 3.792320186, Training Accuracy: 11.168\n",
            "Worker 5, [20/37]: Training Loss: 3.687747500, Training Accuracy: 12.992\n",
            "Worker 5, [21/37]: Training Loss: 4.145454239, Training Accuracy: 8.096\n",
            "Worker 5, [22/37]: Training Loss: 3.874144012, Training Accuracy: 10.592\n",
            "Worker 5, [23/37]: Training Loss: 3.759185937, Training Accuracy: 12.448\n",
            "Worker 5, [24/37]: Training Loss: 3.672802465, Training Accuracy: 13.952\n",
            "Worker 5, [25/37]: Training Loss: 4.100918709, Training Accuracy: 9.536\n",
            "Worker 5, [26/37]: Training Loss: 3.839802966, Training Accuracy: 11.328\n",
            "Worker 5, [27/37]: Training Loss: 3.736667032, Training Accuracy: 12.336\n",
            "Worker 5, [28/37]: Training Loss: 3.667268089, Training Accuracy: 14.096\n",
            "Worker 5, [29/37]: Training Loss: 4.094243317, Training Accuracy: 10.736\n",
            "Worker 5, [30/37]: Training Loss: 3.839501133, Training Accuracy: 11.216\n",
            "Worker 5, [31/37]: Training Loss: 3.762803829, Training Accuracy: 12.448\n",
            "Worker 5, [32/37]: Training Loss: 3.713243253, Training Accuracy: 13.488\n",
            "Worker 5, [33/37]: Training Loss: 4.172548824, Training Accuracy: 11.632\n",
            "Worker 5, [34/37]: Training Loss: 3.977841414, Training Accuracy: 11.632\n",
            "Worker 5, [35/37]: Training Loss: 3.898392967, Training Accuracy: 11.712\n",
            "Worker 5, [36/37]: Training Loss: 3.864384717, Training Accuracy: 12.064\n",
            "Worker 5, [37/37]: Training Loss: 4.229090744, Training Accuracy: 11.760\n",
            "Time taken for training worker 5: 0:01:38.324909\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 4.597542169, Training Accuracy: 1.392\n",
            "Worker 6, [02/37]: Training Loss: 4.461768948, Training Accuracy: 3.120\n",
            "Worker 6, [03/37]: Training Loss: 4.199905790, Training Accuracy: 5.200\n",
            "Worker 6, [04/37]: Training Loss: 4.052096523, Training Accuracy: 7.248\n",
            "Worker 6, [05/37]: Training Loss: 4.524981027, Training Accuracy: 2.384\n",
            "Worker 6, [06/37]: Training Loss: 4.196918310, Training Accuracy: 5.104\n",
            "Worker 6, [07/37]: Training Loss: 4.016647993, Training Accuracy: 8.000\n",
            "Worker 6, [08/37]: Training Loss: 3.895288231, Training Accuracy: 9.296\n",
            "Worker 6, [09/37]: Training Loss: 4.404399161, Training Accuracy: 4.048\n",
            "Worker 6, [10/37]: Training Loss: 4.082889253, Training Accuracy: 6.992\n",
            "Worker 6, [11/37]: Training Loss: 3.929058863, Training Accuracy: 9.328\n",
            "Worker 6, [12/37]: Training Loss: 3.802211810, Training Accuracy: 11.024\n",
            "Worker 6, [13/37]: Training Loss: 4.266832235, Training Accuracy: 5.776\n",
            "Worker 6, [14/37]: Training Loss: 3.964044727, Training Accuracy: 8.224\n",
            "Worker 6, [15/37]: Training Loss: 3.822147705, Training Accuracy: 10.432\n",
            "Worker 6, [16/37]: Training Loss: 3.712389408, Training Accuracy: 12.240\n",
            "Worker 6, [17/37]: Training Loss: 4.206845984, Training Accuracy: 7.040\n",
            "Worker 6, [18/37]: Training Loss: 3.915055754, Training Accuracy: 9.584\n",
            "Worker 6, [19/37]: Training Loss: 3.780761349, Training Accuracy: 11.472\n",
            "Worker 6, [20/37]: Training Loss: 3.683207013, Training Accuracy: 12.976\n",
            "Worker 6, [21/37]: Training Loss: 4.143173595, Training Accuracy: 8.272\n",
            "Worker 6, [22/37]: Training Loss: 3.864867821, Training Accuracy: 10.384\n",
            "Worker 6, [23/37]: Training Loss: 3.754342052, Training Accuracy: 11.744\n",
            "Worker 6, [24/37]: Training Loss: 3.663388167, Training Accuracy: 13.664\n",
            "Worker 6, [25/37]: Training Loss: 4.093705182, Training Accuracy: 8.944\n",
            "Worker 6, [26/37]: Training Loss: 3.825823181, Training Accuracy: 11.072\n",
            "Worker 6, [27/37]: Training Loss: 3.742943506, Training Accuracy: 12.864\n",
            "Worker 6, [28/37]: Training Loss: 3.671308444, Training Accuracy: 13.456\n",
            "Worker 6, [29/37]: Training Loss: 4.085903041, Training Accuracy: 11.072\n",
            "Worker 6, [30/37]: Training Loss: 3.830675797, Training Accuracy: 11.296\n",
            "Worker 6, [31/37]: Training Loss: 3.756795214, Training Accuracy: 12.848\n",
            "Worker 6, [32/37]: Training Loss: 3.710598581, Training Accuracy: 13.120\n",
            "Worker 6, [33/37]: Training Loss: 4.152825268, Training Accuracy: 12.128\n",
            "Worker 6, [34/37]: Training Loss: 3.957292900, Training Accuracy: 11.536\n",
            "Worker 6, [35/37]: Training Loss: 3.886014933, Training Accuracy: 11.312\n",
            "Worker 6, [36/37]: Training Loss: 3.850278772, Training Accuracy: 12.048\n",
            "Worker 6, [37/37]: Training Loss: 4.217120253, Training Accuracy: 13.024\n",
            "Time taken for training worker 6: 0:01:38.108107\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 4.595673376, Training Accuracy: 1.488\n",
            "Worker 7, [02/37]: Training Loss: 4.446632366, Training Accuracy: 2.704\n",
            "Worker 7, [03/37]: Training Loss: 4.198059727, Training Accuracy: 5.184\n",
            "Worker 7, [04/37]: Training Loss: 4.053225860, Training Accuracy: 7.040\n",
            "Worker 7, [05/37]: Training Loss: 4.510889409, Training Accuracy: 2.704\n",
            "Worker 7, [06/37]: Training Loss: 4.202921802, Training Accuracy: 5.392\n",
            "Worker 7, [07/37]: Training Loss: 4.015586753, Training Accuracy: 7.872\n",
            "Worker 7, [08/37]: Training Loss: 3.879298845, Training Accuracy: 9.776\n",
            "Worker 7, [09/37]: Training Loss: 4.418524547, Training Accuracy: 4.208\n",
            "Worker 7, [10/37]: Training Loss: 4.091818077, Training Accuracy: 6.496\n",
            "Worker 7, [11/37]: Training Loss: 3.920578069, Training Accuracy: 9.392\n",
            "Worker 7, [12/37]: Training Loss: 3.802800680, Training Accuracy: 11.104\n",
            "Worker 7, [13/37]: Training Loss: 4.293747902, Training Accuracy: 5.136\n",
            "Worker 7, [14/37]: Training Loss: 3.972240711, Training Accuracy: 8.624\n",
            "Worker 7, [15/37]: Training Loss: 3.832558846, Training Accuracy: 10.304\n",
            "Worker 7, [16/37]: Training Loss: 3.728364164, Training Accuracy: 12.128\n",
            "Worker 7, [17/37]: Training Loss: 4.200628517, Training Accuracy: 6.816\n",
            "Worker 7, [18/37]: Training Loss: 3.904517269, Training Accuracy: 9.984\n",
            "Worker 7, [19/37]: Training Loss: 3.764089326, Training Accuracy: 12.160\n",
            "Worker 7, [20/37]: Training Loss: 3.678576949, Training Accuracy: 12.896\n",
            "Worker 7, [21/37]: Training Loss: 4.136618677, Training Accuracy: 8.032\n",
            "Worker 7, [22/37]: Training Loss: 3.856844398, Training Accuracy: 10.688\n",
            "Worker 7, [23/37]: Training Loss: 3.727814798, Training Accuracy: 11.776\n",
            "Worker 7, [24/37]: Training Loss: 3.655639549, Training Accuracy: 13.232\n",
            "Worker 7, [25/37]: Training Loss: 4.081896244, Training Accuracy: 8.944\n",
            "Worker 7, [26/37]: Training Loss: 3.824814176, Training Accuracy: 11.152\n",
            "Worker 7, [27/37]: Training Loss: 3.729838646, Training Accuracy: 12.784\n",
            "Worker 7, [28/37]: Training Loss: 3.656678360, Training Accuracy: 13.616\n",
            "Worker 7, [29/37]: Training Loss: 4.087669112, Training Accuracy: 11.024\n",
            "Worker 7, [30/37]: Training Loss: 3.838933052, Training Accuracy: 11.376\n",
            "Worker 7, [31/37]: Training Loss: 3.751582204, Training Accuracy: 13.008\n",
            "Worker 7, [32/37]: Training Loss: 3.697138760, Training Accuracy: 13.600\n",
            "Worker 7, [33/37]: Training Loss: 4.156404288, Training Accuracy: 12.256\n",
            "Worker 7, [34/37]: Training Loss: 3.960634555, Training Accuracy: 11.776\n",
            "Worker 7, [35/37]: Training Loss: 3.879642701, Training Accuracy: 11.968\n",
            "Worker 7, [36/37]: Training Loss: 3.852156583, Training Accuracy: 12.384\n",
            "Worker 7, [37/37]: Training Loss: 4.219044272, Training Accuracy: 12.960\n",
            "Time taken for training worker 7: 0:01:38.848789\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 4.591422373, Training Accuracy: 1.440\n",
            "Worker 8, [02/37]: Training Loss: 4.443956837, Training Accuracy: 3.136\n",
            "Worker 8, [03/37]: Training Loss: 4.184588537, Training Accuracy: 6.000\n",
            "Worker 8, [04/37]: Training Loss: 4.050035759, Training Accuracy: 6.976\n",
            "Worker 8, [05/37]: Training Loss: 4.495361717, Training Accuracy: 2.624\n",
            "Worker 8, [06/37]: Training Loss: 4.183774822, Training Accuracy: 5.728\n",
            "Worker 8, [07/37]: Training Loss: 4.007237111, Training Accuracy: 7.760\n",
            "Worker 8, [08/37]: Training Loss: 3.908176541, Training Accuracy: 8.736\n",
            "Worker 8, [09/37]: Training Loss: 4.376719757, Training Accuracy: 4.112\n",
            "Worker 8, [10/37]: Training Loss: 4.049868963, Training Accuracy: 7.056\n",
            "Worker 8, [11/37]: Training Loss: 3.900858030, Training Accuracy: 9.216\n",
            "Worker 8, [12/37]: Training Loss: 3.788018151, Training Accuracy: 10.480\n",
            "Worker 8, [13/37]: Training Loss: 4.270868773, Training Accuracy: 5.920\n",
            "Worker 8, [14/37]: Training Loss: 3.975044107, Training Accuracy: 8.576\n",
            "Worker 8, [15/37]: Training Loss: 3.830053334, Training Accuracy: 10.592\n",
            "Worker 8, [16/37]: Training Loss: 3.741525429, Training Accuracy: 11.376\n",
            "Worker 8, [17/37]: Training Loss: 4.205681840, Training Accuracy: 6.608\n",
            "Worker 8, [18/37]: Training Loss: 3.900112566, Training Accuracy: 9.472\n",
            "Worker 8, [19/37]: Training Loss: 3.762641702, Training Accuracy: 11.760\n",
            "Worker 8, [20/37]: Training Loss: 3.687919515, Training Accuracy: 12.320\n",
            "Worker 8, [21/37]: Training Loss: 4.129873081, Training Accuracy: 8.080\n",
            "Worker 8, [22/37]: Training Loss: 3.853623458, Training Accuracy: 10.208\n",
            "Worker 8, [23/37]: Training Loss: 3.752580324, Training Accuracy: 11.344\n",
            "Worker 8, [24/37]: Training Loss: 3.668284039, Training Accuracy: 12.800\n",
            "Worker 8, [25/37]: Training Loss: 4.085308192, Training Accuracy: 9.136\n",
            "Worker 8, [26/37]: Training Loss: 3.829512479, Training Accuracy: 10.944\n",
            "Worker 8, [27/37]: Training Loss: 3.730592742, Training Accuracy: 11.968\n",
            "Worker 8, [28/37]: Training Loss: 3.657344850, Training Accuracy: 13.776\n",
            "Worker 8, [29/37]: Training Loss: 4.080833973, Training Accuracy: 10.448\n",
            "Worker 8, [30/37]: Training Loss: 3.824959400, Training Accuracy: 11.216\n",
            "Worker 8, [31/37]: Training Loss: 3.753612985, Training Accuracy: 12.400\n",
            "Worker 8, [32/37]: Training Loss: 3.699498938, Training Accuracy: 13.424\n",
            "Worker 8, [33/37]: Training Loss: 4.152825745, Training Accuracy: 11.888\n",
            "Worker 8, [34/37]: Training Loss: 3.960153731, Training Accuracy: 11.456\n",
            "Worker 8, [35/37]: Training Loss: 3.886657644, Training Accuracy: 11.568\n",
            "Worker 8, [36/37]: Training Loss: 3.847318571, Training Accuracy: 12.528\n",
            "Worker 8, [37/37]: Training Loss: 4.219674461, Training Accuracy: 12.512\n",
            "Time taken for training worker 8: 0:01:38.594936\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000711\n",
            "Local Step 01: Test Loss: 4.307251778, Test Accuracy: 11.210\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 4.323965856, Training Accuracy: 10.288\n",
            "Worker 1, [02/37]: Training Loss: 4.320653594, Training Accuracy: 10.432\n",
            "Worker 1, [03/37]: Training Loss: 4.296906170, Training Accuracy: 10.544\n",
            "Worker 1, [04/37]: Training Loss: 4.245047428, Training Accuracy: 9.936\n",
            "Worker 1, [05/37]: Training Loss: 4.152986157, Training Accuracy: 11.568\n",
            "Worker 1, [06/37]: Training Loss: 3.978029232, Training Accuracy: 11.296\n",
            "Worker 1, [07/37]: Training Loss: 3.869250497, Training Accuracy: 11.792\n",
            "Worker 1, [08/37]: Training Loss: 3.809549582, Training Accuracy: 12.368\n",
            "Worker 1, [09/37]: Training Loss: 3.988035139, Training Accuracy: 10.880\n",
            "Worker 1, [10/37]: Training Loss: 3.823949228, Training Accuracy: 11.456\n",
            "Worker 1, [11/37]: Training Loss: 3.756369593, Training Accuracy: 12.688\n",
            "Worker 1, [12/37]: Training Loss: 3.714911957, Training Accuracy: 13.232\n",
            "Worker 1, [13/37]: Training Loss: 3.899936557, Training Accuracy: 11.488\n",
            "Worker 1, [14/37]: Training Loss: 3.778048574, Training Accuracy: 12.192\n",
            "Worker 1, [15/37]: Training Loss: 3.729344675, Training Accuracy: 13.280\n",
            "Worker 1, [16/37]: Training Loss: 3.658534276, Training Accuracy: 14.144\n",
            "Worker 1, [17/37]: Training Loss: 3.880043353, Training Accuracy: 11.024\n",
            "Worker 1, [18/37]: Training Loss: 3.738914431, Training Accuracy: 13.088\n",
            "Worker 1, [19/37]: Training Loss: 3.678340323, Training Accuracy: 13.520\n",
            "Worker 1, [20/37]: Training Loss: 3.618966380, Training Accuracy: 13.840\n",
            "Worker 1, [21/37]: Training Loss: 3.850799157, Training Accuracy: 10.848\n",
            "Worker 1, [22/37]: Training Loss: 3.711904300, Training Accuracy: 13.056\n",
            "Worker 1, [23/37]: Training Loss: 3.626532693, Training Accuracy: 14.640\n",
            "Worker 1, [24/37]: Training Loss: 3.556187129, Training Accuracy: 15.840\n",
            "Worker 1, [25/37]: Training Loss: 3.818252126, Training Accuracy: 11.632\n",
            "Worker 1, [26/37]: Training Loss: 3.679684427, Training Accuracy: 13.440\n",
            "Worker 1, [27/37]: Training Loss: 3.596198357, Training Accuracy: 14.288\n",
            "Worker 1, [28/37]: Training Loss: 3.511546911, Training Accuracy: 15.424\n",
            "Worker 1, [29/37]: Training Loss: 3.786047130, Training Accuracy: 11.888\n",
            "Worker 1, [30/37]: Training Loss: 3.643103278, Training Accuracy: 14.288\n",
            "Worker 1, [31/37]: Training Loss: 3.542148687, Training Accuracy: 16.416\n",
            "Worker 1, [32/37]: Training Loss: 3.442962262, Training Accuracy: 16.736\n",
            "Worker 1, [33/37]: Training Loss: 3.762130309, Training Accuracy: 12.704\n",
            "Worker 1, [34/37]: Training Loss: 3.621485936, Training Accuracy: 13.936\n",
            "Worker 1, [35/37]: Training Loss: 3.493584604, Training Accuracy: 16.288\n",
            "Worker 1, [36/37]: Training Loss: 3.403530992, Training Accuracy: 17.856\n",
            "Worker 1, [37/37]: Training Loss: 3.710893694, Training Accuracy: 13.472\n",
            "Time taken for training worker 1: 0:01:37.145843\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.729470866, Training Accuracy: 13.792\n",
            "Worker 2, [02/37]: Training Loss: 3.700151366, Training Accuracy: 13.856\n",
            "Worker 2, [03/37]: Training Loss: 3.658998808, Training Accuracy: 14.784\n",
            "Worker 2, [04/37]: Training Loss: 3.607657328, Training Accuracy: 14.880\n",
            "Worker 2, [05/37]: Training Loss: 4.097363479, Training Accuracy: 12.960\n",
            "Worker 2, [06/37]: Training Loss: 3.899514245, Training Accuracy: 12.240\n",
            "Worker 2, [07/37]: Training Loss: 3.781265877, Training Accuracy: 12.272\n",
            "Worker 2, [08/37]: Training Loss: 3.736502514, Training Accuracy: 12.816\n",
            "Worker 2, [09/37]: Training Loss: 3.912132387, Training Accuracy: 12.000\n",
            "Worker 2, [10/37]: Training Loss: 3.750938316, Training Accuracy: 12.208\n",
            "Worker 2, [11/37]: Training Loss: 3.693476217, Training Accuracy: 13.216\n",
            "Worker 2, [12/37]: Training Loss: 3.652888515, Training Accuracy: 13.248\n",
            "Worker 2, [13/37]: Training Loss: 3.854118700, Training Accuracy: 11.168\n",
            "Worker 2, [14/37]: Training Loss: 3.711868342, Training Accuracy: 12.176\n",
            "Worker 2, [15/37]: Training Loss: 3.649997081, Training Accuracy: 13.552\n",
            "Worker 2, [16/37]: Training Loss: 3.585495543, Training Accuracy: 14.656\n",
            "Worker 2, [17/37]: Training Loss: 3.813172469, Training Accuracy: 11.616\n",
            "Worker 2, [18/37]: Training Loss: 3.681921095, Training Accuracy: 12.768\n",
            "Worker 2, [19/37]: Training Loss: 3.602578251, Training Accuracy: 13.936\n",
            "Worker 2, [20/37]: Training Loss: 3.525091624, Training Accuracy: 15.696\n",
            "Worker 2, [21/37]: Training Loss: 3.788970811, Training Accuracy: 11.712\n",
            "Worker 2, [22/37]: Training Loss: 3.665125793, Training Accuracy: 12.832\n",
            "Worker 2, [23/37]: Training Loss: 3.557873295, Training Accuracy: 14.864\n",
            "Worker 2, [24/37]: Training Loss: 3.492881259, Training Accuracy: 15.536\n",
            "Worker 2, [25/37]: Training Loss: 3.754445499, Training Accuracy: 11.472\n",
            "Worker 2, [26/37]: Training Loss: 3.607754335, Training Accuracy: 14.192\n",
            "Worker 2, [27/37]: Training Loss: 3.512349082, Training Accuracy: 15.808\n",
            "Worker 2, [28/37]: Training Loss: 3.438073419, Training Accuracy: 16.608\n",
            "Worker 2, [29/37]: Training Loss: 3.709180973, Training Accuracy: 12.912\n",
            "Worker 2, [30/37]: Training Loss: 3.582130179, Training Accuracy: 14.272\n",
            "Worker 2, [31/37]: Training Loss: 3.464092303, Training Accuracy: 15.808\n",
            "Worker 2, [32/37]: Training Loss: 3.374733504, Training Accuracy: 16.960\n",
            "Worker 2, [33/37]: Training Loss: 3.689797620, Training Accuracy: 12.960\n",
            "Worker 2, [34/37]: Training Loss: 3.531722487, Training Accuracy: 15.104\n",
            "Worker 2, [35/37]: Training Loss: 3.414681211, Training Accuracy: 17.088\n",
            "Worker 2, [36/37]: Training Loss: 3.332202846, Training Accuracy: 17.984\n",
            "Worker 2, [37/37]: Training Loss: 3.672809954, Training Accuracy: 13.120\n",
            "Time taken for training worker 2: 0:01:37.006765\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.706636188, Training Accuracy: 13.616\n",
            "Worker 3, [02/37]: Training Loss: 3.695470233, Training Accuracy: 13.920\n",
            "Worker 3, [03/37]: Training Loss: 3.628002624, Training Accuracy: 14.656\n",
            "Worker 3, [04/37]: Training Loss: 3.575138856, Training Accuracy: 15.664\n",
            "Worker 3, [05/37]: Training Loss: 4.110835650, Training Accuracy: 12.800\n",
            "Worker 3, [06/37]: Training Loss: 3.911327576, Training Accuracy: 11.952\n",
            "Worker 3, [07/37]: Training Loss: 3.800791259, Training Accuracy: 12.368\n",
            "Worker 3, [08/37]: Training Loss: 3.753029064, Training Accuracy: 13.008\n",
            "Worker 3, [09/37]: Training Loss: 3.929515951, Training Accuracy: 12.304\n",
            "Worker 3, [10/37]: Training Loss: 3.766046585, Training Accuracy: 12.448\n",
            "Worker 3, [11/37]: Training Loss: 3.702958379, Training Accuracy: 13.808\n",
            "Worker 3, [12/37]: Training Loss: 3.655483421, Training Accuracy: 14.016\n",
            "Worker 3, [13/37]: Training Loss: 3.844120429, Training Accuracy: 12.000\n",
            "Worker 3, [14/37]: Training Loss: 3.716871794, Training Accuracy: 12.816\n",
            "Worker 3, [15/37]: Training Loss: 3.654542161, Training Accuracy: 14.432\n",
            "Worker 3, [16/37]: Training Loss: 3.588090748, Training Accuracy: 15.328\n",
            "Worker 3, [17/37]: Training Loss: 3.816246458, Training Accuracy: 11.376\n",
            "Worker 3, [18/37]: Training Loss: 3.704559949, Training Accuracy: 13.248\n",
            "Worker 3, [19/37]: Training Loss: 3.615587928, Training Accuracy: 14.592\n",
            "Worker 3, [20/37]: Training Loss: 3.543438478, Training Accuracy: 15.120\n",
            "Worker 3, [21/37]: Training Loss: 3.792458216, Training Accuracy: 11.504\n",
            "Worker 3, [22/37]: Training Loss: 3.660722054, Training Accuracy: 14.000\n",
            "Worker 3, [23/37]: Training Loss: 3.573876084, Training Accuracy: 15.008\n",
            "Worker 3, [24/37]: Training Loss: 3.492603380, Training Accuracy: 16.496\n",
            "Worker 3, [25/37]: Training Loss: 3.759127313, Training Accuracy: 12.096\n",
            "Worker 3, [26/37]: Training Loss: 3.630620051, Training Accuracy: 14.080\n",
            "Worker 3, [27/37]: Training Loss: 3.520962742, Training Accuracy: 16.128\n",
            "Worker 3, [28/37]: Training Loss: 3.443738816, Training Accuracy: 17.440\n",
            "Worker 3, [29/37]: Training Loss: 3.743961366, Training Accuracy: 12.496\n",
            "Worker 3, [30/37]: Training Loss: 3.615332910, Training Accuracy: 14.080\n",
            "Worker 3, [31/37]: Training Loss: 3.484567817, Training Accuracy: 16.416\n",
            "Worker 3, [32/37]: Training Loss: 3.397337814, Training Accuracy: 18.560\n",
            "Worker 3, [33/37]: Training Loss: 3.705384702, Training Accuracy: 13.456\n",
            "Worker 3, [34/37]: Training Loss: 3.546308454, Training Accuracy: 15.696\n",
            "Worker 3, [35/37]: Training Loss: 3.440141955, Training Accuracy: 17.392\n",
            "Worker 3, [36/37]: Training Loss: 3.333658681, Training Accuracy: 18.944\n",
            "Worker 3, [37/37]: Training Loss: 3.647002055, Training Accuracy: 14.096\n",
            "Time taken for training worker 3: 0:01:40.004369\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.674006941, Training Accuracy: 13.808\n",
            "Worker 4, [02/37]: Training Loss: 3.660712230, Training Accuracy: 13.840\n",
            "Worker 4, [03/37]: Training Loss: 3.620060045, Training Accuracy: 15.232\n",
            "Worker 4, [04/37]: Training Loss: 3.580632740, Training Accuracy: 16.160\n",
            "Worker 4, [05/37]: Training Loss: 4.092884913, Training Accuracy: 12.928\n",
            "Worker 4, [06/37]: Training Loss: 3.903270948, Training Accuracy: 12.416\n",
            "Worker 4, [07/37]: Training Loss: 3.793060536, Training Accuracy: 11.952\n",
            "Worker 4, [08/37]: Training Loss: 3.722306436, Training Accuracy: 13.360\n",
            "Worker 4, [09/37]: Training Loss: 3.907979216, Training Accuracy: 12.160\n",
            "Worker 4, [10/37]: Training Loss: 3.745489863, Training Accuracy: 12.528\n",
            "Worker 4, [11/37]: Training Loss: 3.674702491, Training Accuracy: 14.192\n",
            "Worker 4, [12/37]: Training Loss: 3.636131542, Training Accuracy: 14.608\n",
            "Worker 4, [13/37]: Training Loss: 3.827869131, Training Accuracy: 12.144\n",
            "Worker 4, [14/37]: Training Loss: 3.699701844, Training Accuracy: 13.456\n",
            "Worker 4, [15/37]: Training Loss: 3.619486811, Training Accuracy: 14.576\n",
            "Worker 4, [16/37]: Training Loss: 3.589926021, Training Accuracy: 14.800\n",
            "Worker 4, [17/37]: Training Loss: 3.787920901, Training Accuracy: 12.000\n",
            "Worker 4, [18/37]: Training Loss: 3.671822920, Training Accuracy: 13.120\n",
            "Worker 4, [19/37]: Training Loss: 3.597823228, Training Accuracy: 14.704\n",
            "Worker 4, [20/37]: Training Loss: 3.528156709, Training Accuracy: 15.424\n",
            "Worker 4, [21/37]: Training Loss: 3.764933929, Training Accuracy: 13.072\n",
            "Worker 4, [22/37]: Training Loss: 3.630323198, Training Accuracy: 14.592\n",
            "Worker 4, [23/37]: Training Loss: 3.560860074, Training Accuracy: 14.944\n",
            "Worker 4, [24/37]: Training Loss: 3.482346080, Training Accuracy: 15.648\n",
            "Worker 4, [25/37]: Training Loss: 3.745352439, Training Accuracy: 13.056\n",
            "Worker 4, [26/37]: Training Loss: 3.627671152, Training Accuracy: 14.368\n",
            "Worker 4, [27/37]: Training Loss: 3.516825321, Training Accuracy: 15.952\n",
            "Worker 4, [28/37]: Training Loss: 3.438368306, Training Accuracy: 17.184\n",
            "Worker 4, [29/37]: Training Loss: 3.730289700, Training Accuracy: 12.912\n",
            "Worker 4, [30/37]: Training Loss: 3.590274779, Training Accuracy: 14.272\n",
            "Worker 4, [31/37]: Training Loss: 3.495984829, Training Accuracy: 16.768\n",
            "Worker 4, [32/37]: Training Loss: 3.408065304, Training Accuracy: 17.520\n",
            "Worker 4, [33/37]: Training Loss: 3.702182128, Training Accuracy: 12.832\n",
            "Worker 4, [34/37]: Training Loss: 3.554106836, Training Accuracy: 15.216\n",
            "Worker 4, [35/37]: Training Loss: 3.428552462, Training Accuracy: 16.992\n",
            "Worker 4, [36/37]: Training Loss: 3.368043853, Training Accuracy: 17.680\n",
            "Worker 4, [37/37]: Training Loss: 3.633974679, Training Accuracy: 14.544\n",
            "Time taken for training worker 4: 0:01:38.027003\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.659539527, Training Accuracy: 13.984\n",
            "Worker 5, [02/37]: Training Loss: 3.644429075, Training Accuracy: 14.000\n",
            "Worker 5, [03/37]: Training Loss: 3.620058072, Training Accuracy: 14.944\n",
            "Worker 5, [04/37]: Training Loss: 3.572207728, Training Accuracy: 15.440\n",
            "Worker 5, [05/37]: Training Loss: 4.108049169, Training Accuracy: 12.528\n",
            "Worker 5, [06/37]: Training Loss: 3.916433334, Training Accuracy: 12.368\n",
            "Worker 5, [07/37]: Training Loss: 3.803042280, Training Accuracy: 11.888\n",
            "Worker 5, [08/37]: Training Loss: 3.759282801, Training Accuracy: 12.560\n",
            "Worker 5, [09/37]: Training Loss: 3.922367130, Training Accuracy: 12.240\n",
            "Worker 5, [10/37]: Training Loss: 3.769707711, Training Accuracy: 12.720\n",
            "Worker 5, [11/37]: Training Loss: 3.699927498, Training Accuracy: 13.088\n",
            "Worker 5, [12/37]: Training Loss: 3.659156456, Training Accuracy: 14.144\n",
            "Worker 5, [13/37]: Training Loss: 3.863401870, Training Accuracy: 12.048\n",
            "Worker 5, [14/37]: Training Loss: 3.732660556, Training Accuracy: 12.592\n",
            "Worker 5, [15/37]: Training Loss: 3.653009831, Training Accuracy: 13.648\n",
            "Worker 5, [16/37]: Training Loss: 3.594384412, Training Accuracy: 14.976\n",
            "Worker 5, [17/37]: Training Loss: 3.816369779, Training Accuracy: 11.216\n",
            "Worker 5, [18/37]: Training Loss: 3.696275037, Training Accuracy: 13.328\n",
            "Worker 5, [19/37]: Training Loss: 3.599037275, Training Accuracy: 14.816\n",
            "Worker 5, [20/37]: Training Loss: 3.540374717, Training Accuracy: 15.824\n",
            "Worker 5, [21/37]: Training Loss: 3.784834718, Training Accuracy: 12.032\n",
            "Worker 5, [22/37]: Training Loss: 3.650766991, Training Accuracy: 14.288\n",
            "Worker 5, [23/37]: Training Loss: 3.572519830, Training Accuracy: 15.184\n",
            "Worker 5, [24/37]: Training Loss: 3.510886231, Training Accuracy: 15.936\n",
            "Worker 5, [25/37]: Training Loss: 3.765867297, Training Accuracy: 12.352\n",
            "Worker 5, [26/37]: Training Loss: 3.620514972, Training Accuracy: 14.288\n",
            "Worker 5, [27/37]: Training Loss: 3.522960969, Training Accuracy: 16.032\n",
            "Worker 5, [28/37]: Training Loss: 3.445280927, Training Accuracy: 17.216\n",
            "Worker 5, [29/37]: Training Loss: 3.730233188, Training Accuracy: 12.688\n",
            "Worker 5, [30/37]: Training Loss: 3.604426805, Training Accuracy: 14.272\n",
            "Worker 5, [31/37]: Training Loss: 3.478168867, Training Accuracy: 15.632\n",
            "Worker 5, [32/37]: Training Loss: 3.390285404, Training Accuracy: 18.064\n",
            "Worker 5, [33/37]: Training Loss: 3.685922049, Training Accuracy: 13.584\n",
            "Worker 5, [34/37]: Training Loss: 3.540921153, Training Accuracy: 15.744\n",
            "Worker 5, [35/37]: Training Loss: 3.438646428, Training Accuracy: 17.504\n",
            "Worker 5, [36/37]: Training Loss: 3.366970379, Training Accuracy: 18.704\n",
            "Worker 5, [37/37]: Training Loss: 3.639722294, Training Accuracy: 14.640\n",
            "Time taken for training worker 5: 0:01:38.206280\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.674473072, Training Accuracy: 13.104\n",
            "Worker 6, [02/37]: Training Loss: 3.668191056, Training Accuracy: 13.216\n",
            "Worker 6, [03/37]: Training Loss: 3.615639061, Training Accuracy: 14.208\n",
            "Worker 6, [04/37]: Training Loss: 3.562078184, Training Accuracy: 15.440\n",
            "Worker 6, [05/37]: Training Loss: 4.101089804, Training Accuracy: 12.864\n",
            "Worker 6, [06/37]: Training Loss: 3.900780824, Training Accuracy: 12.176\n",
            "Worker 6, [07/37]: Training Loss: 3.793638806, Training Accuracy: 12.256\n",
            "Worker 6, [08/37]: Training Loss: 3.741743385, Training Accuracy: 12.816\n",
            "Worker 6, [09/37]: Training Loss: 3.922511624, Training Accuracy: 12.256\n",
            "Worker 6, [10/37]: Training Loss: 3.757337271, Training Accuracy: 12.896\n",
            "Worker 6, [11/37]: Training Loss: 3.698727744, Training Accuracy: 13.328\n",
            "Worker 6, [12/37]: Training Loss: 3.656500437, Training Accuracy: 13.840\n",
            "Worker 6, [13/37]: Training Loss: 3.855636891, Training Accuracy: 11.776\n",
            "Worker 6, [14/37]: Training Loss: 3.717404317, Training Accuracy: 12.832\n",
            "Worker 6, [15/37]: Training Loss: 3.658034989, Training Accuracy: 13.840\n",
            "Worker 6, [16/37]: Training Loss: 3.596888255, Training Accuracy: 14.656\n",
            "Worker 6, [17/37]: Training Loss: 3.817000139, Training Accuracy: 11.920\n",
            "Worker 6, [18/37]: Training Loss: 3.698589911, Training Accuracy: 13.344\n",
            "Worker 6, [19/37]: Training Loss: 3.620806784, Training Accuracy: 13.808\n",
            "Worker 6, [20/37]: Training Loss: 3.564163794, Training Accuracy: 15.104\n",
            "Worker 6, [21/37]: Training Loss: 3.784730884, Training Accuracy: 11.824\n",
            "Worker 6, [22/37]: Training Loss: 3.666352836, Training Accuracy: 13.408\n",
            "Worker 6, [23/37]: Training Loss: 3.568053104, Training Accuracy: 14.480\n",
            "Worker 6, [24/37]: Training Loss: 3.511179472, Training Accuracy: 15.520\n",
            "Worker 6, [25/37]: Training Loss: 3.788751420, Training Accuracy: 11.920\n",
            "Worker 6, [26/37]: Training Loss: 3.645264562, Training Accuracy: 13.776\n",
            "Worker 6, [27/37]: Training Loss: 3.532879382, Training Accuracy: 15.168\n",
            "Worker 6, [28/37]: Training Loss: 3.467111626, Training Accuracy: 16.160\n",
            "Worker 6, [29/37]: Training Loss: 3.739436532, Training Accuracy: 12.576\n",
            "Worker 6, [30/37]: Training Loss: 3.579313157, Training Accuracy: 13.776\n",
            "Worker 6, [31/37]: Training Loss: 3.511973478, Training Accuracy: 15.184\n",
            "Worker 6, [32/37]: Training Loss: 3.413173201, Training Accuracy: 17.184\n",
            "Worker 6, [33/37]: Training Loss: 3.702623192, Training Accuracy: 12.608\n",
            "Worker 6, [34/37]: Training Loss: 3.574318497, Training Accuracy: 14.016\n",
            "Worker 6, [35/37]: Training Loss: 3.473493552, Training Accuracy: 16.640\n",
            "Worker 6, [36/37]: Training Loss: 3.386820817, Training Accuracy: 17.696\n",
            "Worker 6, [37/37]: Training Loss: 3.644980126, Training Accuracy: 13.344\n",
            "Time taken for training worker 6: 0:01:37.822037\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.668433652, Training Accuracy: 13.280\n",
            "Worker 7, [02/37]: Training Loss: 3.666372071, Training Accuracy: 13.328\n",
            "Worker 7, [03/37]: Training Loss: 3.629228592, Training Accuracy: 13.888\n",
            "Worker 7, [04/37]: Training Loss: 3.585632419, Training Accuracy: 15.136\n",
            "Worker 7, [05/37]: Training Loss: 4.098045517, Training Accuracy: 12.992\n",
            "Worker 7, [06/37]: Training Loss: 3.904577367, Training Accuracy: 11.952\n",
            "Worker 7, [07/37]: Training Loss: 3.795220285, Training Accuracy: 12.288\n",
            "Worker 7, [08/37]: Training Loss: 3.734484646, Training Accuracy: 13.088\n",
            "Worker 7, [09/37]: Training Loss: 3.912824560, Training Accuracy: 12.528\n",
            "Worker 7, [10/37]: Training Loss: 3.751357974, Training Accuracy: 12.752\n",
            "Worker 7, [11/37]: Training Loss: 3.694288524, Training Accuracy: 13.232\n",
            "Worker 7, [12/37]: Training Loss: 3.653403620, Training Accuracy: 13.632\n",
            "Worker 7, [13/37]: Training Loss: 3.846659797, Training Accuracy: 11.760\n",
            "Worker 7, [14/37]: Training Loss: 3.702799274, Training Accuracy: 12.928\n",
            "Worker 7, [15/37]: Training Loss: 3.652111703, Training Accuracy: 13.328\n",
            "Worker 7, [16/37]: Training Loss: 3.593990735, Training Accuracy: 14.544\n",
            "Worker 7, [17/37]: Training Loss: 3.802323502, Training Accuracy: 11.856\n",
            "Worker 7, [18/37]: Training Loss: 3.705616182, Training Accuracy: 12.144\n",
            "Worker 7, [19/37]: Training Loss: 3.635204561, Training Accuracy: 13.968\n",
            "Worker 7, [20/37]: Training Loss: 3.564902235, Training Accuracy: 15.088\n",
            "Worker 7, [21/37]: Training Loss: 3.788232609, Training Accuracy: 11.312\n",
            "Worker 7, [22/37]: Training Loss: 3.666530449, Training Accuracy: 13.104\n",
            "Worker 7, [23/37]: Training Loss: 3.575786902, Training Accuracy: 15.120\n",
            "Worker 7, [24/37]: Training Loss: 3.505389459, Training Accuracy: 16.096\n",
            "Worker 7, [25/37]: Training Loss: 3.778253570, Training Accuracy: 12.032\n",
            "Worker 7, [26/37]: Training Loss: 3.643284897, Training Accuracy: 13.888\n",
            "Worker 7, [27/37]: Training Loss: 3.538875867, Training Accuracy: 15.232\n",
            "Worker 7, [28/37]: Training Loss: 3.455894013, Training Accuracy: 16.752\n",
            "Worker 7, [29/37]: Training Loss: 3.721905764, Training Accuracy: 12.528\n",
            "Worker 7, [30/37]: Training Loss: 3.600064095, Training Accuracy: 14.512\n",
            "Worker 7, [31/37]: Training Loss: 3.513003203, Training Accuracy: 15.472\n",
            "Worker 7, [32/37]: Training Loss: 3.424560523, Training Accuracy: 16.896\n",
            "Worker 7, [33/37]: Training Loss: 3.695230761, Training Accuracy: 12.832\n",
            "Worker 7, [34/37]: Training Loss: 3.575028157, Training Accuracy: 14.416\n",
            "Worker 7, [35/37]: Training Loss: 3.489934298, Training Accuracy: 16.096\n",
            "Worker 7, [36/37]: Training Loss: 3.375716587, Training Accuracy: 18.064\n",
            "Worker 7, [37/37]: Training Loss: 3.664343498, Training Accuracy: 12.928\n",
            "Time taken for training worker 7: 0:01:37.278200\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.713534168, Training Accuracy: 12.240\n",
            "Worker 8, [02/37]: Training Loss: 3.697949643, Training Accuracy: 12.720\n",
            "Worker 8, [03/37]: Training Loss: 3.660360769, Training Accuracy: 13.136\n",
            "Worker 8, [04/37]: Training Loss: 3.603344307, Training Accuracy: 14.336\n",
            "Worker 8, [05/37]: Training Loss: 4.101265589, Training Accuracy: 12.144\n",
            "Worker 8, [06/37]: Training Loss: 3.911030808, Training Accuracy: 11.456\n",
            "Worker 8, [07/37]: Training Loss: 3.802104159, Training Accuracy: 11.824\n",
            "Worker 8, [08/37]: Training Loss: 3.746962107, Training Accuracy: 12.544\n",
            "Worker 8, [09/37]: Training Loss: 3.911028142, Training Accuracy: 11.792\n",
            "Worker 8, [10/37]: Training Loss: 3.769789971, Training Accuracy: 12.160\n",
            "Worker 8, [11/37]: Training Loss: 3.702838735, Training Accuracy: 12.800\n",
            "Worker 8, [12/37]: Training Loss: 3.657895611, Training Accuracy: 13.488\n",
            "Worker 8, [13/37]: Training Loss: 3.854043472, Training Accuracy: 11.344\n",
            "Worker 8, [14/37]: Training Loss: 3.711806091, Training Accuracy: 12.448\n",
            "Worker 8, [15/37]: Training Loss: 3.656442180, Training Accuracy: 12.880\n",
            "Worker 8, [16/37]: Training Loss: 3.605581882, Training Accuracy: 14.208\n",
            "Worker 8, [17/37]: Training Loss: 3.821831494, Training Accuracy: 11.168\n",
            "Worker 8, [18/37]: Training Loss: 3.693122095, Training Accuracy: 12.512\n",
            "Worker 8, [19/37]: Training Loss: 3.611032418, Training Accuracy: 14.064\n",
            "Worker 8, [20/37]: Training Loss: 3.539001494, Training Accuracy: 14.864\n",
            "Worker 8, [21/37]: Training Loss: 3.791082431, Training Accuracy: 10.752\n",
            "Worker 8, [22/37]: Training Loss: 3.670733766, Training Accuracy: 12.848\n",
            "Worker 8, [23/37]: Training Loss: 3.568206288, Training Accuracy: 14.544\n",
            "Worker 8, [24/37]: Training Loss: 3.504339286, Training Accuracy: 15.536\n",
            "Worker 8, [25/37]: Training Loss: 3.761833261, Training Accuracy: 12.448\n",
            "Worker 8, [26/37]: Training Loss: 3.620041976, Training Accuracy: 13.376\n",
            "Worker 8, [27/37]: Training Loss: 3.539475891, Training Accuracy: 14.160\n",
            "Worker 8, [28/37]: Training Loss: 3.447733650, Training Accuracy: 15.856\n",
            "Worker 8, [29/37]: Training Loss: 3.746895306, Training Accuracy: 12.320\n",
            "Worker 8, [30/37]: Training Loss: 3.616003426, Training Accuracy: 13.776\n",
            "Worker 8, [31/37]: Training Loss: 3.517368489, Training Accuracy: 14.704\n",
            "Worker 8, [32/37]: Training Loss: 3.425860943, Training Accuracy: 16.976\n",
            "Worker 8, [33/37]: Training Loss: 3.705384203, Training Accuracy: 13.184\n",
            "Worker 8, [34/37]: Training Loss: 3.564648945, Training Accuracy: 14.368\n",
            "Worker 8, [35/37]: Training Loss: 3.460564151, Training Accuracy: 15.808\n",
            "Worker 8, [36/37]: Training Loss: 3.364981333, Training Accuracy: 17.808\n",
            "Worker 8, [37/37]: Training Loss: 3.676785053, Training Accuracy: 13.168\n",
            "Time taken for training worker 8: 0:01:40.119183\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000805\n",
            "Local Step 02: Test Loss: 3.685551422, Test Accuracy: 13.410\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.669032382, Training Accuracy: 14.496\n",
            "Worker 1, [02/37]: Training Loss: 3.518251351, Training Accuracy: 16.256\n",
            "Worker 1, [03/37]: Training Loss: 3.413944634, Training Accuracy: 18.064\n",
            "Worker 1, [04/37]: Training Loss: 3.332993449, Training Accuracy: 19.040\n",
            "Worker 1, [05/37]: Training Loss: 3.670703883, Training Accuracy: 14.128\n",
            "Worker 1, [06/37]: Training Loss: 3.524355280, Training Accuracy: 15.760\n",
            "Worker 1, [07/37]: Training Loss: 3.425097320, Training Accuracy: 17.696\n",
            "Worker 1, [08/37]: Training Loss: 3.334117680, Training Accuracy: 18.544\n",
            "Worker 1, [09/37]: Training Loss: 3.629337206, Training Accuracy: 14.016\n",
            "Worker 1, [10/37]: Training Loss: 3.464266181, Training Accuracy: 16.688\n",
            "Worker 1, [11/37]: Training Loss: 3.355855436, Training Accuracy: 18.896\n",
            "Worker 1, [12/37]: Training Loss: 3.266291253, Training Accuracy: 20.496\n",
            "Worker 1, [13/37]: Training Loss: 3.527711530, Training Accuracy: 16.064\n",
            "Worker 1, [14/37]: Training Loss: 3.392846275, Training Accuracy: 17.664\n",
            "Worker 1, [15/37]: Training Loss: 3.300483947, Training Accuracy: 20.032\n",
            "Worker 1, [16/37]: Training Loss: 3.194636377, Training Accuracy: 21.936\n",
            "Worker 1, [17/37]: Training Loss: 3.430845886, Training Accuracy: 17.888\n",
            "Worker 1, [18/37]: Training Loss: 3.328861567, Training Accuracy: 19.328\n",
            "Worker 1, [19/37]: Training Loss: 3.245584977, Training Accuracy: 20.784\n",
            "Worker 1, [20/37]: Training Loss: 3.149029549, Training Accuracy: 22.224\n",
            "Worker 1, [21/37]: Training Loss: 3.354986437, Training Accuracy: 18.176\n",
            "Worker 1, [22/37]: Training Loss: 3.261359891, Training Accuracy: 20.736\n",
            "Worker 1, [23/37]: Training Loss: 3.166010029, Training Accuracy: 22.320\n",
            "Worker 1, [24/37]: Training Loss: 3.086198641, Training Accuracy: 23.456\n",
            "Worker 1, [25/37]: Training Loss: 3.282054023, Training Accuracy: 20.960\n",
            "Worker 1, [26/37]: Training Loss: 3.186737031, Training Accuracy: 21.872\n",
            "Worker 1, [27/37]: Training Loss: 3.118792483, Training Accuracy: 23.248\n",
            "Worker 1, [28/37]: Training Loss: 3.064360623, Training Accuracy: 24.480\n",
            "Worker 1, [29/37]: Training Loss: 3.219612562, Training Accuracy: 22.064\n",
            "Worker 1, [30/37]: Training Loss: 3.139684208, Training Accuracy: 23.280\n",
            "Worker 1, [31/37]: Training Loss: 3.084936923, Training Accuracy: 24.288\n",
            "Worker 1, [32/37]: Training Loss: 3.060658365, Training Accuracy: 24.304\n",
            "Worker 1, [33/37]: Training Loss: 3.203911835, Training Accuracy: 23.072\n",
            "Worker 1, [34/37]: Training Loss: 3.149038137, Training Accuracy: 23.008\n",
            "Worker 1, [35/37]: Training Loss: 3.106200554, Training Accuracy: 23.696\n",
            "Worker 1, [36/37]: Training Loss: 3.095318563, Training Accuracy: 24.096\n",
            "Worker 1, [37/37]: Training Loss: 3.252512319, Training Accuracy: 23.584\n",
            "Time taken for training worker 1: 0:01:37.732251\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.583184203, Training Accuracy: 14.400\n",
            "Worker 2, [02/37]: Training Loss: 3.427565207, Training Accuracy: 17.008\n",
            "Worker 2, [03/37]: Training Loss: 3.313629812, Training Accuracy: 18.768\n",
            "Worker 2, [04/37]: Training Loss: 3.223042157, Training Accuracy: 20.016\n",
            "Worker 2, [05/37]: Training Loss: 3.579887346, Training Accuracy: 14.528\n",
            "Worker 2, [06/37]: Training Loss: 3.440822356, Training Accuracy: 16.720\n",
            "Worker 2, [07/37]: Training Loss: 3.343911183, Training Accuracy: 17.792\n",
            "Worker 2, [08/37]: Training Loss: 3.225091185, Training Accuracy: 19.936\n",
            "Worker 2, [09/37]: Training Loss: 3.511492688, Training Accuracy: 15.712\n",
            "Worker 2, [10/37]: Training Loss: 3.358259717, Training Accuracy: 18.112\n",
            "Worker 2, [11/37]: Training Loss: 3.272765719, Training Accuracy: 19.744\n",
            "Worker 2, [12/37]: Training Loss: 3.177694260, Training Accuracy: 20.912\n",
            "Worker 2, [13/37]: Training Loss: 3.447289284, Training Accuracy: 16.160\n",
            "Worker 2, [14/37]: Training Loss: 3.300079331, Training Accuracy: 18.896\n",
            "Worker 2, [15/37]: Training Loss: 3.204757350, Training Accuracy: 20.464\n",
            "Worker 2, [16/37]: Training Loss: 3.103197852, Training Accuracy: 22.208\n",
            "Worker 2, [17/37]: Training Loss: 3.359604685, Training Accuracy: 17.920\n",
            "Worker 2, [18/37]: Training Loss: 3.239098274, Training Accuracy: 20.272\n",
            "Worker 2, [19/37]: Training Loss: 3.146003998, Training Accuracy: 21.824\n",
            "Worker 2, [20/37]: Training Loss: 3.050962940, Training Accuracy: 23.280\n",
            "Worker 2, [21/37]: Training Loss: 3.264704069, Training Accuracy: 20.960\n",
            "Worker 2, [22/37]: Training Loss: 3.155318185, Training Accuracy: 21.744\n",
            "Worker 2, [23/37]: Training Loss: 3.059315134, Training Accuracy: 23.440\n",
            "Worker 2, [24/37]: Training Loss: 2.981007352, Training Accuracy: 24.096\n",
            "Worker 2, [25/37]: Training Loss: 3.168574766, Training Accuracy: 22.144\n",
            "Worker 2, [26/37]: Training Loss: 3.076381554, Training Accuracy: 23.296\n",
            "Worker 2, [27/37]: Training Loss: 3.005595054, Training Accuracy: 24.816\n",
            "Worker 2, [28/37]: Training Loss: 2.928996125, Training Accuracy: 25.952\n",
            "Worker 2, [29/37]: Training Loss: 3.120450652, Training Accuracy: 23.216\n",
            "Worker 2, [30/37]: Training Loss: 3.031853194, Training Accuracy: 23.616\n",
            "Worker 2, [31/37]: Training Loss: 2.965712810, Training Accuracy: 25.568\n",
            "Worker 2, [32/37]: Training Loss: 2.923143654, Training Accuracy: 26.656\n",
            "Worker 2, [33/37]: Training Loss: 3.096016113, Training Accuracy: 24.320\n",
            "Worker 2, [34/37]: Training Loss: 3.003821319, Training Accuracy: 25.088\n",
            "Worker 2, [35/37]: Training Loss: 3.003705171, Training Accuracy: 24.976\n",
            "Worker 2, [36/37]: Training Loss: 2.968516240, Training Accuracy: 25.168\n",
            "Worker 2, [37/37]: Training Loss: 3.139172114, Training Accuracy: 25.056\n",
            "Time taken for training worker 2: 0:01:37.398595\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.564944197, Training Accuracy: 15.136\n",
            "Worker 3, [02/37]: Training Loss: 3.413612487, Training Accuracy: 17.872\n",
            "Worker 3, [03/37]: Training Loss: 3.299127399, Training Accuracy: 19.984\n",
            "Worker 3, [04/37]: Training Loss: 3.218850345, Training Accuracy: 21.424\n",
            "Worker 3, [05/37]: Training Loss: 3.605483058, Training Accuracy: 14.736\n",
            "Worker 3, [06/37]: Training Loss: 3.451063528, Training Accuracy: 17.264\n",
            "Worker 3, [07/37]: Training Loss: 3.347636590, Training Accuracy: 18.976\n",
            "Worker 3, [08/37]: Training Loss: 3.237277661, Training Accuracy: 20.688\n",
            "Worker 3, [09/37]: Training Loss: 3.523449528, Training Accuracy: 16.224\n",
            "Worker 3, [10/37]: Training Loss: 3.408207166, Training Accuracy: 17.616\n",
            "Worker 3, [11/37]: Training Loss: 3.261860195, Training Accuracy: 20.016\n",
            "Worker 3, [12/37]: Training Loss: 3.197215170, Training Accuracy: 20.640\n",
            "Worker 3, [13/37]: Training Loss: 3.462804244, Training Accuracy: 16.608\n",
            "Worker 3, [14/37]: Training Loss: 3.331910214, Training Accuracy: 18.768\n",
            "Worker 3, [15/37]: Training Loss: 3.215062068, Training Accuracy: 20.560\n",
            "Worker 3, [16/37]: Training Loss: 3.141093906, Training Accuracy: 22.528\n",
            "Worker 3, [17/37]: Training Loss: 3.356518998, Training Accuracy: 19.184\n",
            "Worker 3, [18/37]: Training Loss: 3.233975505, Training Accuracy: 21.216\n",
            "Worker 3, [19/37]: Training Loss: 3.144624194, Training Accuracy: 23.120\n",
            "Worker 3, [20/37]: Training Loss: 3.070138182, Training Accuracy: 23.792\n",
            "Worker 3, [21/37]: Training Loss: 3.292640275, Training Accuracy: 20.608\n",
            "Worker 3, [22/37]: Training Loss: 3.164219822, Training Accuracy: 22.288\n",
            "Worker 3, [23/37]: Training Loss: 3.078431684, Training Accuracy: 23.648\n",
            "Worker 3, [24/37]: Training Loss: 2.998623412, Training Accuracy: 24.992\n",
            "Worker 3, [25/37]: Training Loss: 3.200746699, Training Accuracy: 21.936\n",
            "Worker 3, [26/37]: Training Loss: 3.097328921, Training Accuracy: 24.128\n",
            "Worker 3, [27/37]: Training Loss: 3.031686622, Training Accuracy: 24.832\n",
            "Worker 3, [28/37]: Training Loss: 2.955769819, Training Accuracy: 26.784\n",
            "Worker 3, [29/37]: Training Loss: 3.147248112, Training Accuracy: 23.680\n",
            "Worker 3, [30/37]: Training Loss: 3.046087126, Training Accuracy: 25.360\n",
            "Worker 3, [31/37]: Training Loss: 2.990064930, Training Accuracy: 26.224\n",
            "Worker 3, [32/37]: Training Loss: 2.969066785, Training Accuracy: 27.200\n",
            "Worker 3, [33/37]: Training Loss: 3.116628749, Training Accuracy: 25.040\n",
            "Worker 3, [34/37]: Training Loss: 3.041102857, Training Accuracy: 25.936\n",
            "Worker 3, [35/37]: Training Loss: 3.025692239, Training Accuracy: 25.984\n",
            "Worker 3, [36/37]: Training Loss: 2.988946640, Training Accuracy: 26.352\n",
            "Worker 3, [37/37]: Training Loss: 3.164137278, Training Accuracy: 25.840\n",
            "Time taken for training worker 3: 0:01:37.044105\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.545808804, Training Accuracy: 16.016\n",
            "Worker 4, [02/37]: Training Loss: 3.388352353, Training Accuracy: 18.320\n",
            "Worker 4, [03/37]: Training Loss: 3.307122943, Training Accuracy: 19.088\n",
            "Worker 4, [04/37]: Training Loss: 3.214529908, Training Accuracy: 21.136\n",
            "Worker 4, [05/37]: Training Loss: 3.611058079, Training Accuracy: 14.512\n",
            "Worker 4, [06/37]: Training Loss: 3.465034840, Training Accuracy: 17.024\n",
            "Worker 4, [07/37]: Training Loss: 3.343433173, Training Accuracy: 18.736\n",
            "Worker 4, [08/37]: Training Loss: 3.231535576, Training Accuracy: 20.384\n",
            "Worker 4, [09/37]: Training Loss: 3.525891435, Training Accuracy: 15.744\n",
            "Worker 4, [10/37]: Training Loss: 3.368562718, Training Accuracy: 18.384\n",
            "Worker 4, [11/37]: Training Loss: 3.291131445, Training Accuracy: 19.664\n",
            "Worker 4, [12/37]: Training Loss: 3.191095773, Training Accuracy: 20.720\n",
            "Worker 4, [13/37]: Training Loss: 3.432048041, Training Accuracy: 17.104\n",
            "Worker 4, [14/37]: Training Loss: 3.306328284, Training Accuracy: 18.672\n",
            "Worker 4, [15/37]: Training Loss: 3.215705550, Training Accuracy: 21.168\n",
            "Worker 4, [16/37]: Training Loss: 3.107058484, Training Accuracy: 23.104\n",
            "Worker 4, [17/37]: Training Loss: 3.351742195, Training Accuracy: 18.656\n",
            "Worker 4, [18/37]: Training Loss: 3.238230428, Training Accuracy: 20.064\n",
            "Worker 4, [19/37]: Training Loss: 3.140272428, Training Accuracy: 22.272\n",
            "Worker 4, [20/37]: Training Loss: 3.052689725, Training Accuracy: 23.552\n",
            "Worker 4, [21/37]: Training Loss: 3.269405523, Training Accuracy: 20.224\n",
            "Worker 4, [22/37]: Training Loss: 3.164968084, Training Accuracy: 21.600\n",
            "Worker 4, [23/37]: Training Loss: 3.069675584, Training Accuracy: 23.376\n",
            "Worker 4, [24/37]: Training Loss: 2.986718102, Training Accuracy: 25.408\n",
            "Worker 4, [25/37]: Training Loss: 3.188043706, Training Accuracy: 22.096\n",
            "Worker 4, [26/37]: Training Loss: 3.078454947, Training Accuracy: 23.984\n",
            "Worker 4, [27/37]: Training Loss: 3.017499033, Training Accuracy: 24.704\n",
            "Worker 4, [28/37]: Training Loss: 2.937955112, Training Accuracy: 25.984\n",
            "Worker 4, [29/37]: Training Loss: 3.117292465, Training Accuracy: 23.968\n",
            "Worker 4, [30/37]: Training Loss: 3.039921593, Training Accuracy: 25.056\n",
            "Worker 4, [31/37]: Training Loss: 2.967026071, Training Accuracy: 26.224\n",
            "Worker 4, [32/37]: Training Loss: 2.936090499, Training Accuracy: 27.104\n",
            "Worker 4, [33/37]: Training Loss: 3.096034575, Training Accuracy: 25.104\n",
            "Worker 4, [34/37]: Training Loss: 3.023586704, Training Accuracy: 25.344\n",
            "Worker 4, [35/37]: Training Loss: 2.992442279, Training Accuracy: 25.952\n",
            "Worker 4, [36/37]: Training Loss: 2.987550385, Training Accuracy: 25.968\n",
            "Worker 4, [37/37]: Training Loss: 3.139156697, Training Accuracy: 25.760\n",
            "Time taken for training worker 4: 0:01:38.592516\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.556601918, Training Accuracy: 15.104\n",
            "Worker 5, [02/37]: Training Loss: 3.401970944, Training Accuracy: 18.208\n",
            "Worker 5, [03/37]: Training Loss: 3.294682972, Training Accuracy: 19.584\n",
            "Worker 5, [04/37]: Training Loss: 3.210508872, Training Accuracy: 20.928\n",
            "Worker 5, [05/37]: Training Loss: 3.592932244, Training Accuracy: 14.784\n",
            "Worker 5, [06/37]: Training Loss: 3.456782049, Training Accuracy: 17.120\n",
            "Worker 5, [07/37]: Training Loss: 3.356945923, Training Accuracy: 18.080\n",
            "Worker 5, [08/37]: Training Loss: 3.251147280, Training Accuracy: 20.096\n",
            "Worker 5, [09/37]: Training Loss: 3.525703639, Training Accuracy: 16.304\n",
            "Worker 5, [10/37]: Training Loss: 3.413955859, Training Accuracy: 17.824\n",
            "Worker 5, [11/37]: Training Loss: 3.283469524, Training Accuracy: 20.384\n",
            "Worker 5, [12/37]: Training Loss: 3.185938957, Training Accuracy: 21.232\n",
            "Worker 5, [13/37]: Training Loss: 3.456445740, Training Accuracy: 17.264\n",
            "Worker 5, [14/37]: Training Loss: 3.315212011, Training Accuracy: 19.424\n",
            "Worker 5, [15/37]: Training Loss: 3.204305537, Training Accuracy: 21.168\n",
            "Worker 5, [16/37]: Training Loss: 3.128517898, Training Accuracy: 21.936\n",
            "Worker 5, [17/37]: Training Loss: 3.361475645, Training Accuracy: 18.672\n",
            "Worker 5, [18/37]: Training Loss: 3.256457455, Training Accuracy: 20.080\n",
            "Worker 5, [19/37]: Training Loss: 3.149422456, Training Accuracy: 21.968\n",
            "Worker 5, [20/37]: Training Loss: 3.072811214, Training Accuracy: 23.632\n",
            "Worker 5, [21/37]: Training Loss: 3.275716463, Training Accuracy: 20.960\n",
            "Worker 5, [22/37]: Training Loss: 3.170149837, Training Accuracy: 22.016\n",
            "Worker 5, [23/37]: Training Loss: 3.084259668, Training Accuracy: 23.440\n",
            "Worker 5, [24/37]: Training Loss: 3.007642223, Training Accuracy: 24.112\n",
            "Worker 5, [25/37]: Training Loss: 3.196399689, Training Accuracy: 21.968\n",
            "Worker 5, [26/37]: Training Loss: 3.093725346, Training Accuracy: 22.992\n",
            "Worker 5, [27/37]: Training Loss: 3.025706493, Training Accuracy: 23.680\n",
            "Worker 5, [28/37]: Training Loss: 2.961761667, Training Accuracy: 25.424\n",
            "Worker 5, [29/37]: Training Loss: 3.139759531, Training Accuracy: 23.168\n",
            "Worker 5, [30/37]: Training Loss: 3.043578980, Training Accuracy: 24.608\n",
            "Worker 5, [31/37]: Training Loss: 3.004543166, Training Accuracy: 25.248\n",
            "Worker 5, [32/37]: Training Loss: 2.960971793, Training Accuracy: 25.968\n",
            "Worker 5, [33/37]: Training Loss: 3.117022201, Training Accuracy: 24.800\n",
            "Worker 5, [34/37]: Training Loss: 3.059583073, Training Accuracy: 24.800\n",
            "Worker 5, [35/37]: Training Loss: 3.017214636, Training Accuracy: 25.072\n",
            "Worker 5, [36/37]: Training Loss: 3.009393174, Training Accuracy: 25.456\n",
            "Worker 5, [37/37]: Training Loss: 3.158974290, Training Accuracy: 25.232\n",
            "Time taken for training worker 5: 0:01:36.847588\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.538139071, Training Accuracy: 15.968\n",
            "Worker 6, [02/37]: Training Loss: 3.385756948, Training Accuracy: 17.776\n",
            "Worker 6, [03/37]: Training Loss: 3.280524478, Training Accuracy: 19.360\n",
            "Worker 6, [04/37]: Training Loss: 3.195233527, Training Accuracy: 20.768\n",
            "Worker 6, [05/37]: Training Loss: 3.616261346, Training Accuracy: 14.960\n",
            "Worker 6, [06/37]: Training Loss: 3.458594872, Training Accuracy: 16.704\n",
            "Worker 6, [07/37]: Training Loss: 3.358861310, Training Accuracy: 18.032\n",
            "Worker 6, [08/37]: Training Loss: 3.245827093, Training Accuracy: 19.904\n",
            "Worker 6, [09/37]: Training Loss: 3.534991773, Training Accuracy: 14.960\n",
            "Worker 6, [10/37]: Training Loss: 3.410848564, Training Accuracy: 17.824\n",
            "Worker 6, [11/37]: Training Loss: 3.280456881, Training Accuracy: 19.600\n",
            "Worker 6, [12/37]: Training Loss: 3.204798472, Training Accuracy: 20.368\n",
            "Worker 6, [13/37]: Training Loss: 3.468285916, Training Accuracy: 16.240\n",
            "Worker 6, [14/37]: Training Loss: 3.340591596, Training Accuracy: 18.864\n",
            "Worker 6, [15/37]: Training Loss: 3.218111391, Training Accuracy: 20.272\n",
            "Worker 6, [16/37]: Training Loss: 3.139628739, Training Accuracy: 21.552\n",
            "Worker 6, [17/37]: Training Loss: 3.389608653, Training Accuracy: 17.744\n",
            "Worker 6, [18/37]: Training Loss: 3.278662161, Training Accuracy: 19.040\n",
            "Worker 6, [19/37]: Training Loss: 3.171980179, Training Accuracy: 21.600\n",
            "Worker 6, [20/37]: Training Loss: 3.069042216, Training Accuracy: 23.120\n",
            "Worker 6, [21/37]: Training Loss: 3.287066124, Training Accuracy: 19.744\n",
            "Worker 6, [22/37]: Training Loss: 3.183260815, Training Accuracy: 21.456\n",
            "Worker 6, [23/37]: Training Loss: 3.105531340, Training Accuracy: 22.608\n",
            "Worker 6, [24/37]: Training Loss: 3.019811312, Training Accuracy: 24.272\n",
            "Worker 6, [25/37]: Training Loss: 3.216555213, Training Accuracy: 21.520\n",
            "Worker 6, [26/37]: Training Loss: 3.118944005, Training Accuracy: 22.832\n",
            "Worker 6, [27/37]: Training Loss: 3.039457708, Training Accuracy: 24.816\n",
            "Worker 6, [28/37]: Training Loss: 2.987997890, Training Accuracy: 25.104\n",
            "Worker 6, [29/37]: Training Loss: 3.165614432, Training Accuracy: 22.592\n",
            "Worker 6, [30/37]: Training Loss: 3.060562170, Training Accuracy: 24.464\n",
            "Worker 6, [31/37]: Training Loss: 3.020325079, Training Accuracy: 25.200\n",
            "Worker 6, [32/37]: Training Loss: 2.960305204, Training Accuracy: 26.448\n",
            "Worker 6, [33/37]: Training Loss: 3.150167409, Training Accuracy: 23.680\n",
            "Worker 6, [34/37]: Training Loss: 3.063708113, Training Accuracy: 24.144\n",
            "Worker 6, [35/37]: Training Loss: 3.038541339, Training Accuracy: 24.880\n",
            "Worker 6, [36/37]: Training Loss: 3.021425797, Training Accuracy: 24.624\n",
            "Worker 6, [37/37]: Training Loss: 3.180247978, Training Accuracy: 23.968\n",
            "Time taken for training worker 6: 0:01:38.922293\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.581925125, Training Accuracy: 14.896\n",
            "Worker 7, [02/37]: Training Loss: 3.428884292, Training Accuracy: 17.008\n",
            "Worker 7, [03/37]: Training Loss: 3.318107410, Training Accuracy: 19.296\n",
            "Worker 7, [04/37]: Training Loss: 3.224744617, Training Accuracy: 19.840\n",
            "Worker 7, [05/37]: Training Loss: 3.594427067, Training Accuracy: 14.736\n",
            "Worker 7, [06/37]: Training Loss: 3.472816192, Training Accuracy: 16.512\n",
            "Worker 7, [07/37]: Training Loss: 3.369904272, Training Accuracy: 18.208\n",
            "Worker 7, [08/37]: Training Loss: 3.280065264, Training Accuracy: 18.528\n",
            "Worker 7, [09/37]: Training Loss: 3.551595581, Training Accuracy: 14.592\n",
            "Worker 7, [10/37]: Training Loss: 3.423277770, Training Accuracy: 16.464\n",
            "Worker 7, [11/37]: Training Loss: 3.311983262, Training Accuracy: 18.688\n",
            "Worker 7, [12/37]: Training Loss: 3.202717170, Training Accuracy: 21.008\n",
            "Worker 7, [13/37]: Training Loss: 3.467289749, Training Accuracy: 17.376\n",
            "Worker 7, [14/37]: Training Loss: 3.330991991, Training Accuracy: 18.272\n",
            "Worker 7, [15/37]: Training Loss: 3.233197745, Training Accuracy: 20.560\n",
            "Worker 7, [16/37]: Training Loss: 3.135993469, Training Accuracy: 21.760\n",
            "Worker 7, [17/37]: Training Loss: 3.382625290, Training Accuracy: 17.968\n",
            "Worker 7, [18/37]: Training Loss: 3.277705407, Training Accuracy: 19.616\n",
            "Worker 7, [19/37]: Training Loss: 3.172665044, Training Accuracy: 21.440\n",
            "Worker 7, [20/37]: Training Loss: 3.095579627, Training Accuracy: 22.976\n",
            "Worker 7, [21/37]: Training Loss: 3.304144227, Training Accuracy: 20.016\n",
            "Worker 7, [22/37]: Training Loss: 3.197458999, Training Accuracy: 21.280\n",
            "Worker 7, [23/37]: Training Loss: 3.097940209, Training Accuracy: 22.096\n",
            "Worker 7, [24/37]: Training Loss: 3.037591912, Training Accuracy: 24.272\n",
            "Worker 7, [25/37]: Training Loss: 3.230218116, Training Accuracy: 21.472\n",
            "Worker 7, [26/37]: Training Loss: 3.118730309, Training Accuracy: 22.848\n",
            "Worker 7, [27/37]: Training Loss: 3.055089024, Training Accuracy: 24.160\n",
            "Worker 7, [28/37]: Training Loss: 2.980424725, Training Accuracy: 25.264\n",
            "Worker 7, [29/37]: Training Loss: 3.167393295, Training Accuracy: 22.640\n",
            "Worker 7, [30/37]: Training Loss: 3.066908457, Training Accuracy: 23.808\n",
            "Worker 7, [31/37]: Training Loss: 3.025637286, Training Accuracy: 25.120\n",
            "Worker 7, [32/37]: Training Loss: 2.963520631, Training Accuracy: 25.856\n",
            "Worker 7, [33/37]: Training Loss: 3.146958222, Training Accuracy: 23.296\n",
            "Worker 7, [34/37]: Training Loss: 3.058682911, Training Accuracy: 24.464\n",
            "Worker 7, [35/37]: Training Loss: 3.039848308, Training Accuracy: 25.088\n",
            "Worker 7, [36/37]: Training Loss: 3.029774364, Training Accuracy: 24.720\n",
            "Worker 7, [37/37]: Training Loss: 3.184630778, Training Accuracy: 23.984\n",
            "Time taken for training worker 7: 0:01:39.852982\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.583621103, Training Accuracy: 14.992\n",
            "Worker 8, [02/37]: Training Loss: 3.423625647, Training Accuracy: 16.848\n",
            "Worker 8, [03/37]: Training Loss: 3.310062248, Training Accuracy: 19.632\n",
            "Worker 8, [04/37]: Training Loss: 3.214841823, Training Accuracy: 20.352\n",
            "Worker 8, [05/37]: Training Loss: 3.606429674, Training Accuracy: 13.872\n",
            "Worker 8, [06/37]: Training Loss: 3.461471638, Training Accuracy: 15.760\n",
            "Worker 8, [07/37]: Training Loss: 3.359889797, Training Accuracy: 17.456\n",
            "Worker 8, [08/37]: Training Loss: 3.280419211, Training Accuracy: 18.944\n",
            "Worker 8, [09/37]: Training Loss: 3.543000029, Training Accuracy: 14.704\n",
            "Worker 8, [10/37]: Training Loss: 3.414640833, Training Accuracy: 16.912\n",
            "Worker 8, [11/37]: Training Loss: 3.301983045, Training Accuracy: 18.976\n",
            "Worker 8, [12/37]: Training Loss: 3.198213842, Training Accuracy: 19.872\n",
            "Worker 8, [13/37]: Training Loss: 3.474153694, Training Accuracy: 16.320\n",
            "Worker 8, [14/37]: Training Loss: 3.333835376, Training Accuracy: 18.288\n",
            "Worker 8, [15/37]: Training Loss: 3.230356615, Training Accuracy: 19.536\n",
            "Worker 8, [16/37]: Training Loss: 3.130452611, Training Accuracy: 21.472\n",
            "Worker 8, [17/37]: Training Loss: 3.377973853, Training Accuracy: 17.744\n",
            "Worker 8, [18/37]: Training Loss: 3.271795959, Training Accuracy: 18.496\n",
            "Worker 8, [19/37]: Training Loss: 3.150058569, Training Accuracy: 21.472\n",
            "Worker 8, [20/37]: Training Loss: 3.078510464, Training Accuracy: 22.832\n",
            "Worker 8, [21/37]: Training Loss: 3.297363780, Training Accuracy: 19.040\n",
            "Worker 8, [22/37]: Training Loss: 3.166498841, Training Accuracy: 20.816\n",
            "Worker 8, [23/37]: Training Loss: 3.088956234, Training Accuracy: 22.432\n",
            "Worker 8, [24/37]: Training Loss: 3.018712136, Training Accuracy: 22.992\n",
            "Worker 8, [25/37]: Training Loss: 3.214405004, Training Accuracy: 20.368\n",
            "Worker 8, [26/37]: Training Loss: 3.123047456, Training Accuracy: 22.432\n",
            "Worker 8, [27/37]: Training Loss: 3.010794545, Training Accuracy: 24.704\n",
            "Worker 8, [28/37]: Training Loss: 2.952542188, Training Accuracy: 25.376\n",
            "Worker 8, [29/37]: Training Loss: 3.147714262, Training Accuracy: 22.624\n",
            "Worker 8, [30/37]: Training Loss: 3.064391868, Training Accuracy: 23.456\n",
            "Worker 8, [31/37]: Training Loss: 3.008818254, Training Accuracy: 24.560\n",
            "Worker 8, [32/37]: Training Loss: 2.969887035, Training Accuracy: 25.376\n",
            "Worker 8, [33/37]: Training Loss: 3.134133531, Training Accuracy: 23.472\n",
            "Worker 8, [34/37]: Training Loss: 3.066301419, Training Accuracy: 23.472\n",
            "Worker 8, [35/37]: Training Loss: 3.016263047, Training Accuracy: 25.376\n",
            "Worker 8, [36/37]: Training Loss: 3.012320173, Training Accuracy: 24.736\n",
            "Worker 8, [37/37]: Training Loss: 3.177324974, Training Accuracy: 24.240\n",
            "Time taken for training worker 8: 0:01:38.966975\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000644\n",
            "Local Step 03: Test Loss: 3.338844544, Test Accuracy: 21.570\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.457130561, Training Accuracy: 18.896\n",
            "Worker 1, [02/37]: Training Loss: 3.444001256, Training Accuracy: 19.120\n",
            "Worker 1, [03/37]: Training Loss: 3.427259693, Training Accuracy: 19.360\n",
            "Worker 1, [04/37]: Training Loss: 3.399476557, Training Accuracy: 19.680\n",
            "Worker 1, [05/37]: Training Loss: 3.235176724, Training Accuracy: 23.200\n",
            "Worker 1, [06/37]: Training Loss: 3.169165497, Training Accuracy: 23.312\n",
            "Worker 1, [07/37]: Training Loss: 3.131279449, Training Accuracy: 23.232\n",
            "Worker 1, [08/37]: Training Loss: 3.123779905, Training Accuracy: 23.008\n",
            "Worker 1, [09/37]: Training Loss: 3.198495904, Training Accuracy: 22.080\n",
            "Worker 1, [10/37]: Training Loss: 3.154238788, Training Accuracy: 22.896\n",
            "Worker 1, [11/37]: Training Loss: 3.111139161, Training Accuracy: 23.264\n",
            "Worker 1, [12/37]: Training Loss: 3.117567413, Training Accuracy: 22.640\n",
            "Worker 1, [13/37]: Training Loss: 3.219205085, Training Accuracy: 21.568\n",
            "Worker 1, [14/37]: Training Loss: 3.167153023, Training Accuracy: 22.480\n",
            "Worker 1, [15/37]: Training Loss: 3.137945976, Training Accuracy: 22.480\n",
            "Worker 1, [16/37]: Training Loss: 3.109675478, Training Accuracy: 23.216\n",
            "Worker 1, [17/37]: Training Loss: 3.243772290, Training Accuracy: 21.104\n",
            "Worker 1, [18/37]: Training Loss: 3.192617448, Training Accuracy: 20.992\n",
            "Worker 1, [19/37]: Training Loss: 3.157114949, Training Accuracy: 21.696\n",
            "Worker 1, [20/37]: Training Loss: 3.106151109, Training Accuracy: 22.784\n",
            "Worker 1, [21/37]: Training Loss: 3.273066530, Training Accuracy: 20.336\n",
            "Worker 1, [22/37]: Training Loss: 3.214363157, Training Accuracy: 20.912\n",
            "Worker 1, [23/37]: Training Loss: 3.174747990, Training Accuracy: 21.616\n",
            "Worker 1, [24/37]: Training Loss: 3.123711642, Training Accuracy: 22.768\n",
            "Worker 1, [25/37]: Training Loss: 3.274155009, Training Accuracy: 19.920\n",
            "Worker 1, [26/37]: Training Loss: 3.257027254, Training Accuracy: 20.064\n",
            "Worker 1, [27/37]: Training Loss: 3.151968036, Training Accuracy: 22.240\n",
            "Worker 1, [28/37]: Training Loss: 3.109333941, Training Accuracy: 22.928\n",
            "Worker 1, [29/37]: Training Loss: 3.284652435, Training Accuracy: 20.192\n",
            "Worker 1, [30/37]: Training Loss: 3.243007820, Training Accuracy: 20.496\n",
            "Worker 1, [31/37]: Training Loss: 3.148143695, Training Accuracy: 22.432\n",
            "Worker 1, [32/37]: Training Loss: 3.105377645, Training Accuracy: 22.656\n",
            "Worker 1, [33/37]: Training Loss: 3.280490848, Training Accuracy: 20.144\n",
            "Worker 1, [34/37]: Training Loss: 3.225381820, Training Accuracy: 20.128\n",
            "Worker 1, [35/37]: Training Loss: 3.133163975, Training Accuracy: 22.640\n",
            "Worker 1, [36/37]: Training Loss: 3.069031433, Training Accuracy: 22.672\n",
            "Worker 1, [37/37]: Training Loss: 3.289279471, Training Accuracy: 19.888\n",
            "Time taken for training worker 1: 0:01:39.930296\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.449417049, Training Accuracy: 16.912\n",
            "Worker 2, [02/37]: Training Loss: 3.438737954, Training Accuracy: 16.976\n",
            "Worker 2, [03/37]: Training Loss: 3.389502394, Training Accuracy: 17.776\n",
            "Worker 2, [04/37]: Training Loss: 3.343455840, Training Accuracy: 19.392\n",
            "Worker 2, [05/37]: Training Loss: 3.113012550, Training Accuracy: 24.960\n",
            "Worker 2, [06/37]: Training Loss: 3.040561460, Training Accuracy: 24.608\n",
            "Worker 2, [07/37]: Training Loss: 3.003833669, Training Accuracy: 24.576\n",
            "Worker 2, [08/37]: Training Loss: 2.992314650, Training Accuracy: 24.928\n",
            "Worker 2, [09/37]: Training Loss: 3.070860799, Training Accuracy: 23.888\n",
            "Worker 2, [10/37]: Training Loss: 3.031625991, Training Accuracy: 24.752\n",
            "Worker 2, [11/37]: Training Loss: 2.997404529, Training Accuracy: 24.688\n",
            "Worker 2, [12/37]: Training Loss: 2.976557610, Training Accuracy: 24.752\n",
            "Worker 2, [13/37]: Training Loss: 3.084319927, Training Accuracy: 23.776\n",
            "Worker 2, [14/37]: Training Loss: 3.059190940, Training Accuracy: 23.632\n",
            "Worker 2, [15/37]: Training Loss: 3.014121070, Training Accuracy: 24.208\n",
            "Worker 2, [16/37]: Training Loss: 2.989349796, Training Accuracy: 24.752\n",
            "Worker 2, [17/37]: Training Loss: 3.118584239, Training Accuracy: 22.528\n",
            "Worker 2, [18/37]: Training Loss: 3.080195215, Training Accuracy: 22.352\n",
            "Worker 2, [19/37]: Training Loss: 3.029792294, Training Accuracy: 23.648\n",
            "Worker 2, [20/37]: Training Loss: 3.006644614, Training Accuracy: 23.264\n",
            "Worker 2, [21/37]: Training Loss: 3.176850808, Training Accuracy: 21.488\n",
            "Worker 2, [22/37]: Training Loss: 3.084384449, Training Accuracy: 23.088\n",
            "Worker 2, [23/37]: Training Loss: 3.042430540, Training Accuracy: 24.192\n",
            "Worker 2, [24/37]: Training Loss: 2.973921041, Training Accuracy: 24.176\n",
            "Worker 2, [25/37]: Training Loss: 3.165476952, Training Accuracy: 21.312\n",
            "Worker 2, [26/37]: Training Loss: 3.114617287, Training Accuracy: 22.224\n",
            "Worker 2, [27/37]: Training Loss: 3.030052934, Training Accuracy: 23.712\n",
            "Worker 2, [28/37]: Training Loss: 2.983052580, Training Accuracy: 23.968\n",
            "Worker 2, [29/37]: Training Loss: 3.171386196, Training Accuracy: 21.888\n",
            "Worker 2, [30/37]: Training Loss: 3.107496782, Training Accuracy: 22.400\n",
            "Worker 2, [31/37]: Training Loss: 3.041816940, Training Accuracy: 23.232\n",
            "Worker 2, [32/37]: Training Loss: 2.962947050, Training Accuracy: 25.168\n",
            "Worker 2, [33/37]: Training Loss: 3.185278627, Training Accuracy: 21.168\n",
            "Worker 2, [34/37]: Training Loss: 3.096264180, Training Accuracy: 22.464\n",
            "Worker 2, [35/37]: Training Loss: 3.014987179, Training Accuracy: 24.416\n",
            "Worker 2, [36/37]: Training Loss: 2.950359279, Training Accuracy: 24.768\n",
            "Worker 2, [37/37]: Training Loss: 3.152936485, Training Accuracy: 21.824\n",
            "Time taken for training worker 2: 0:01:38.083676\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.451116859, Training Accuracy: 18.192\n",
            "Worker 3, [02/37]: Training Loss: 3.423399397, Training Accuracy: 18.928\n",
            "Worker 3, [03/37]: Training Loss: 3.372650687, Training Accuracy: 18.688\n",
            "Worker 3, [04/37]: Training Loss: 3.324028657, Training Accuracy: 19.952\n",
            "Worker 3, [05/37]: Training Loss: 3.131893226, Training Accuracy: 25.344\n",
            "Worker 3, [06/37]: Training Loss: 3.054206238, Training Accuracy: 25.664\n",
            "Worker 3, [07/37]: Training Loss: 3.044195895, Training Accuracy: 24.880\n",
            "Worker 3, [08/37]: Training Loss: 3.005021404, Training Accuracy: 25.424\n",
            "Worker 3, [09/37]: Training Loss: 3.093903118, Training Accuracy: 24.672\n",
            "Worker 3, [10/37]: Training Loss: 3.041100619, Training Accuracy: 24.544\n",
            "Worker 3, [11/37]: Training Loss: 3.017577767, Training Accuracy: 25.632\n",
            "Worker 3, [12/37]: Training Loss: 2.984449314, Training Accuracy: 25.968\n",
            "Worker 3, [13/37]: Training Loss: 3.100852122, Training Accuracy: 23.904\n",
            "Worker 3, [14/37]: Training Loss: 3.061988882, Training Accuracy: 23.984\n",
            "Worker 3, [15/37]: Training Loss: 3.022845134, Training Accuracy: 24.768\n",
            "Worker 3, [16/37]: Training Loss: 3.010465330, Training Accuracy: 24.464\n",
            "Worker 3, [17/37]: Training Loss: 3.157805231, Training Accuracy: 23.056\n",
            "Worker 3, [18/37]: Training Loss: 3.081283676, Training Accuracy: 23.952\n",
            "Worker 3, [19/37]: Training Loss: 3.044627975, Training Accuracy: 23.568\n",
            "Worker 3, [20/37]: Training Loss: 2.998703555, Training Accuracy: 25.168\n",
            "Worker 3, [21/37]: Training Loss: 3.164388119, Training Accuracy: 22.432\n",
            "Worker 3, [22/37]: Training Loss: 3.131873345, Training Accuracy: 22.208\n",
            "Worker 3, [23/37]: Training Loss: 3.068772457, Training Accuracy: 23.680\n",
            "Worker 3, [24/37]: Training Loss: 3.012502344, Training Accuracy: 24.576\n",
            "Worker 3, [25/37]: Training Loss: 3.188533503, Training Accuracy: 21.488\n",
            "Worker 3, [26/37]: Training Loss: 3.136004759, Training Accuracy: 21.888\n",
            "Worker 3, [27/37]: Training Loss: 3.075842704, Training Accuracy: 23.088\n",
            "Worker 3, [28/37]: Training Loss: 3.011487000, Training Accuracy: 24.720\n",
            "Worker 3, [29/37]: Training Loss: 3.205744374, Training Accuracy: 21.200\n",
            "Worker 3, [30/37]: Training Loss: 3.147487694, Training Accuracy: 22.544\n",
            "Worker 3, [31/37]: Training Loss: 3.056782304, Training Accuracy: 24.080\n",
            "Worker 3, [32/37]: Training Loss: 3.023703760, Training Accuracy: 24.192\n",
            "Worker 3, [33/37]: Training Loss: 3.201671654, Training Accuracy: 21.136\n",
            "Worker 3, [34/37]: Training Loss: 3.131954862, Training Accuracy: 22.032\n",
            "Worker 3, [35/37]: Training Loss: 3.034838202, Training Accuracy: 24.160\n",
            "Worker 3, [36/37]: Training Loss: 2.935167729, Training Accuracy: 25.632\n",
            "Worker 3, [37/37]: Training Loss: 3.161901318, Training Accuracy: 22.576\n",
            "Time taken for training worker 3: 0:01:39.757439\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.423143024, Training Accuracy: 18.544\n",
            "Worker 4, [02/37]: Training Loss: 3.402847278, Training Accuracy: 19.152\n",
            "Worker 4, [03/37]: Training Loss: 3.335738133, Training Accuracy: 19.616\n",
            "Worker 4, [04/37]: Training Loss: 3.270512878, Training Accuracy: 21.568\n",
            "Worker 4, [05/37]: Training Loss: 3.106475565, Training Accuracy: 25.152\n",
            "Worker 4, [06/37]: Training Loss: 3.044731276, Training Accuracy: 24.608\n",
            "Worker 4, [07/37]: Training Loss: 3.011057603, Training Accuracy: 25.584\n",
            "Worker 4, [08/37]: Training Loss: 2.996921386, Training Accuracy: 26.320\n",
            "Worker 4, [09/37]: Training Loss: 3.067263063, Training Accuracy: 24.880\n",
            "Worker 4, [10/37]: Training Loss: 3.022854805, Training Accuracy: 24.800\n",
            "Worker 4, [11/37]: Training Loss: 2.998392207, Training Accuracy: 25.152\n",
            "Worker 4, [12/37]: Training Loss: 2.984935276, Training Accuracy: 25.392\n",
            "Worker 4, [13/37]: Training Loss: 3.089564739, Training Accuracy: 23.648\n",
            "Worker 4, [14/37]: Training Loss: 3.051779336, Training Accuracy: 24.176\n",
            "Worker 4, [15/37]: Training Loss: 3.032537305, Training Accuracy: 24.144\n",
            "Worker 4, [16/37]: Training Loss: 2.987190860, Training Accuracy: 24.912\n",
            "Worker 4, [17/37]: Training Loss: 3.100740112, Training Accuracy: 22.640\n",
            "Worker 4, [18/37]: Training Loss: 3.083373637, Training Accuracy: 23.808\n",
            "Worker 4, [19/37]: Training Loss: 3.020970199, Training Accuracy: 24.816\n",
            "Worker 4, [20/37]: Training Loss: 2.992250827, Training Accuracy: 24.592\n",
            "Worker 4, [21/37]: Training Loss: 3.181725300, Training Accuracy: 21.520\n",
            "Worker 4, [22/37]: Training Loss: 3.097971566, Training Accuracy: 22.688\n",
            "Worker 4, [23/37]: Training Loss: 3.055012691, Training Accuracy: 23.840\n",
            "Worker 4, [24/37]: Training Loss: 2.996228425, Training Accuracy: 24.592\n",
            "Worker 4, [25/37]: Training Loss: 3.200273042, Training Accuracy: 21.376\n",
            "Worker 4, [26/37]: Training Loss: 3.143690391, Training Accuracy: 22.640\n",
            "Worker 4, [27/37]: Training Loss: 3.069194122, Training Accuracy: 23.616\n",
            "Worker 4, [28/37]: Training Loss: 3.000620951, Training Accuracy: 24.512\n",
            "Worker 4, [29/37]: Training Loss: 3.194085902, Training Accuracy: 21.344\n",
            "Worker 4, [30/37]: Training Loss: 3.110967480, Training Accuracy: 22.864\n",
            "Worker 4, [31/37]: Training Loss: 3.060342696, Training Accuracy: 23.936\n",
            "Worker 4, [32/37]: Training Loss: 2.983382697, Training Accuracy: 24.464\n",
            "Worker 4, [33/37]: Training Loss: 3.178967109, Training Accuracy: 22.032\n",
            "Worker 4, [34/37]: Training Loss: 3.075860610, Training Accuracy: 23.520\n",
            "Worker 4, [35/37]: Training Loss: 3.024544061, Training Accuracy: 24.144\n",
            "Worker 4, [36/37]: Training Loss: 2.935084491, Training Accuracy: 25.792\n",
            "Worker 4, [37/37]: Training Loss: 3.155196316, Training Accuracy: 21.456\n",
            "Time taken for training worker 4: 0:01:38.346811\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.477895155, Training Accuracy: 18.176\n",
            "Worker 5, [02/37]: Training Loss: 3.435072578, Training Accuracy: 18.400\n",
            "Worker 5, [03/37]: Training Loss: 3.355966592, Training Accuracy: 19.040\n",
            "Worker 5, [04/37]: Training Loss: 3.293391539, Training Accuracy: 20.608\n",
            "Worker 5, [05/37]: Training Loss: 3.124414179, Training Accuracy: 24.368\n",
            "Worker 5, [06/37]: Training Loss: 3.057006889, Training Accuracy: 24.512\n",
            "Worker 5, [07/37]: Training Loss: 3.027348312, Training Accuracy: 24.928\n",
            "Worker 5, [08/37]: Training Loss: 3.002827114, Training Accuracy: 24.784\n",
            "Worker 5, [09/37]: Training Loss: 3.084243120, Training Accuracy: 23.616\n",
            "Worker 5, [10/37]: Training Loss: 3.047769666, Training Accuracy: 24.080\n",
            "Worker 5, [11/37]: Training Loss: 3.015108196, Training Accuracy: 25.424\n",
            "Worker 5, [12/37]: Training Loss: 2.981009666, Training Accuracy: 25.424\n",
            "Worker 5, [13/37]: Training Loss: 3.115050231, Training Accuracy: 23.280\n",
            "Worker 5, [14/37]: Training Loss: 3.061643907, Training Accuracy: 24.560\n",
            "Worker 5, [15/37]: Training Loss: 3.029940221, Training Accuracy: 24.112\n",
            "Worker 5, [16/37]: Training Loss: 3.002455558, Training Accuracy: 25.136\n",
            "Worker 5, [17/37]: Training Loss: 3.149773062, Training Accuracy: 22.288\n",
            "Worker 5, [18/37]: Training Loss: 3.106685354, Training Accuracy: 22.624\n",
            "Worker 5, [19/37]: Training Loss: 3.057575885, Training Accuracy: 23.808\n",
            "Worker 5, [20/37]: Training Loss: 3.001730812, Training Accuracy: 24.672\n",
            "Worker 5, [21/37]: Training Loss: 3.178361956, Training Accuracy: 22.000\n",
            "Worker 5, [22/37]: Training Loss: 3.121843340, Training Accuracy: 22.320\n",
            "Worker 5, [23/37]: Training Loss: 3.071477416, Training Accuracy: 23.296\n",
            "Worker 5, [24/37]: Training Loss: 3.004859849, Training Accuracy: 24.304\n",
            "Worker 5, [25/37]: Training Loss: 3.200580410, Training Accuracy: 21.024\n",
            "Worker 5, [26/37]: Training Loss: 3.134082169, Training Accuracy: 21.520\n",
            "Worker 5, [27/37]: Training Loss: 3.085946786, Training Accuracy: 23.440\n",
            "Worker 5, [28/37]: Training Loss: 3.039602747, Training Accuracy: 23.344\n",
            "Worker 5, [29/37]: Training Loss: 3.188354266, Training Accuracy: 20.672\n",
            "Worker 5, [30/37]: Training Loss: 3.134334323, Training Accuracy: 22.272\n",
            "Worker 5, [31/37]: Training Loss: 3.059652141, Training Accuracy: 23.120\n",
            "Worker 5, [32/37]: Training Loss: 2.982234342, Training Accuracy: 24.160\n",
            "Worker 5, [33/37]: Training Loss: 3.185901581, Training Accuracy: 21.376\n",
            "Worker 5, [34/37]: Training Loss: 3.124302003, Training Accuracy: 22.208\n",
            "Worker 5, [35/37]: Training Loss: 3.034430927, Training Accuracy: 24.032\n",
            "Worker 5, [36/37]: Training Loss: 2.982327469, Training Accuracy: 24.688\n",
            "Worker 5, [37/37]: Training Loss: 3.167094537, Training Accuracy: 21.488\n",
            "Time taken for training worker 5: 0:01:36.950792\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.424423120, Training Accuracy: 18.656\n",
            "Worker 6, [02/37]: Training Loss: 3.408349096, Training Accuracy: 17.824\n",
            "Worker 6, [03/37]: Training Loss: 3.361378920, Training Accuracy: 18.784\n",
            "Worker 6, [04/37]: Training Loss: 3.291503113, Training Accuracy: 20.544\n",
            "Worker 6, [05/37]: Training Loss: 3.145478494, Training Accuracy: 24.368\n",
            "Worker 6, [06/37]: Training Loss: 3.073019826, Training Accuracy: 24.560\n",
            "Worker 6, [07/37]: Training Loss: 3.035902838, Training Accuracy: 24.288\n",
            "Worker 6, [08/37]: Training Loss: 3.029919666, Training Accuracy: 24.304\n",
            "Worker 6, [09/37]: Training Loss: 3.103468627, Training Accuracy: 23.696\n",
            "Worker 6, [10/37]: Training Loss: 3.048521677, Training Accuracy: 23.984\n",
            "Worker 6, [11/37]: Training Loss: 3.027160778, Training Accuracy: 24.048\n",
            "Worker 6, [12/37]: Training Loss: 3.012819091, Training Accuracy: 24.544\n",
            "Worker 6, [13/37]: Training Loss: 3.122908943, Training Accuracy: 22.528\n",
            "Worker 6, [14/37]: Training Loss: 3.054345776, Training Accuracy: 23.664\n",
            "Worker 6, [15/37]: Training Loss: 3.037629419, Training Accuracy: 23.856\n",
            "Worker 6, [16/37]: Training Loss: 3.013999956, Training Accuracy: 24.352\n",
            "Worker 6, [17/37]: Training Loss: 3.142048994, Training Accuracy: 22.384\n",
            "Worker 6, [18/37]: Training Loss: 3.113689688, Training Accuracy: 22.608\n",
            "Worker 6, [19/37]: Training Loss: 3.055640654, Training Accuracy: 23.792\n",
            "Worker 6, [20/37]: Training Loss: 3.012633837, Training Accuracy: 24.256\n",
            "Worker 6, [21/37]: Training Loss: 3.166898900, Training Accuracy: 21.712\n",
            "Worker 6, [22/37]: Training Loss: 3.130695129, Training Accuracy: 22.080\n",
            "Worker 6, [23/37]: Training Loss: 3.076520886, Training Accuracy: 22.784\n",
            "Worker 6, [24/37]: Training Loss: 3.017176813, Training Accuracy: 23.856\n",
            "Worker 6, [25/37]: Training Loss: 3.205739231, Training Accuracy: 21.008\n",
            "Worker 6, [26/37]: Training Loss: 3.165154917, Training Accuracy: 20.912\n",
            "Worker 6, [27/37]: Training Loss: 3.087595845, Training Accuracy: 22.784\n",
            "Worker 6, [28/37]: Training Loss: 3.028553043, Training Accuracy: 24.160\n",
            "Worker 6, [29/37]: Training Loss: 3.224382147, Training Accuracy: 20.640\n",
            "Worker 6, [30/37]: Training Loss: 3.169748975, Training Accuracy: 20.896\n",
            "Worker 6, [31/37]: Training Loss: 3.082634505, Training Accuracy: 22.432\n",
            "Worker 6, [32/37]: Training Loss: 3.009766245, Training Accuracy: 24.176\n",
            "Worker 6, [33/37]: Training Loss: 3.193586079, Training Accuracy: 20.976\n",
            "Worker 6, [34/37]: Training Loss: 3.138436495, Training Accuracy: 22.528\n",
            "Worker 6, [35/37]: Training Loss: 3.073483180, Training Accuracy: 22.800\n",
            "Worker 6, [36/37]: Training Loss: 2.976312752, Training Accuracy: 24.816\n",
            "Worker 6, [37/37]: Training Loss: 3.181745704, Training Accuracy: 21.312\n",
            "Time taken for training worker 6: 0:01:38.952345\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.418975334, Training Accuracy: 17.824\n",
            "Worker 7, [02/37]: Training Loss: 3.411318594, Training Accuracy: 18.128\n",
            "Worker 7, [03/37]: Training Loss: 3.356376147, Training Accuracy: 18.432\n",
            "Worker 7, [04/37]: Training Loss: 3.291715495, Training Accuracy: 20.192\n",
            "Worker 7, [05/37]: Training Loss: 3.151149869, Training Accuracy: 23.792\n",
            "Worker 7, [06/37]: Training Loss: 3.069067858, Training Accuracy: 24.176\n",
            "Worker 7, [07/37]: Training Loss: 3.046523364, Training Accuracy: 24.304\n",
            "Worker 7, [08/37]: Training Loss: 3.029671484, Training Accuracy: 24.848\n",
            "Worker 7, [09/37]: Training Loss: 3.114581711, Training Accuracy: 23.488\n",
            "Worker 7, [10/37]: Training Loss: 3.047902574, Training Accuracy: 23.936\n",
            "Worker 7, [11/37]: Training Loss: 3.040135800, Training Accuracy: 24.480\n",
            "Worker 7, [12/37]: Training Loss: 3.014688840, Training Accuracy: 24.448\n",
            "Worker 7, [13/37]: Training Loss: 3.124047386, Training Accuracy: 22.368\n",
            "Worker 7, [14/37]: Training Loss: 3.090843055, Training Accuracy: 23.072\n",
            "Worker 7, [15/37]: Training Loss: 3.053928161, Training Accuracy: 24.176\n",
            "Worker 7, [16/37]: Training Loss: 3.019143457, Training Accuracy: 24.032\n",
            "Worker 7, [17/37]: Training Loss: 3.171432583, Training Accuracy: 21.792\n",
            "Worker 7, [18/37]: Training Loss: 3.107743789, Training Accuracy: 23.136\n",
            "Worker 7, [19/37]: Training Loss: 3.084441129, Training Accuracy: 23.376\n",
            "Worker 7, [20/37]: Training Loss: 3.032225220, Training Accuracy: 23.552\n",
            "Worker 7, [21/37]: Training Loss: 3.175622239, Training Accuracy: 21.904\n",
            "Worker 7, [22/37]: Training Loss: 3.125659417, Training Accuracy: 21.936\n",
            "Worker 7, [23/37]: Training Loss: 3.087045215, Training Accuracy: 22.880\n",
            "Worker 7, [24/37]: Training Loss: 3.037475041, Training Accuracy: 23.616\n",
            "Worker 7, [25/37]: Training Loss: 3.217002226, Training Accuracy: 21.456\n",
            "Worker 7, [26/37]: Training Loss: 3.152135859, Training Accuracy: 21.344\n",
            "Worker 7, [27/37]: Training Loss: 3.104556672, Training Accuracy: 21.776\n",
            "Worker 7, [28/37]: Training Loss: 3.034096874, Training Accuracy: 23.456\n",
            "Worker 7, [29/37]: Training Loss: 3.213661513, Training Accuracy: 20.208\n",
            "Worker 7, [30/37]: Training Loss: 3.167823105, Training Accuracy: 21.456\n",
            "Worker 7, [31/37]: Training Loss: 3.093950517, Training Accuracy: 22.608\n",
            "Worker 7, [32/37]: Training Loss: 3.023456243, Training Accuracy: 23.952\n",
            "Worker 7, [33/37]: Training Loss: 3.217083843, Training Accuracy: 20.336\n",
            "Worker 7, [34/37]: Training Loss: 3.137875255, Training Accuracy: 21.712\n",
            "Worker 7, [35/37]: Training Loss: 3.063959068, Training Accuracy: 22.752\n",
            "Worker 7, [36/37]: Training Loss: 2.998906355, Training Accuracy: 24.112\n",
            "Worker 7, [37/37]: Training Loss: 3.185600750, Training Accuracy: 20.896\n",
            "Time taken for training worker 7: 0:01:38.535185\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.409987727, Training Accuracy: 18.560\n",
            "Worker 8, [02/37]: Training Loss: 3.403406216, Training Accuracy: 18.544\n",
            "Worker 8, [03/37]: Training Loss: 3.359508604, Training Accuracy: 18.976\n",
            "Worker 8, [04/37]: Training Loss: 3.304481706, Training Accuracy: 20.288\n",
            "Worker 8, [05/37]: Training Loss: 3.148810861, Training Accuracy: 23.280\n",
            "Worker 8, [06/37]: Training Loss: 3.074736028, Training Accuracy: 23.568\n",
            "Worker 8, [07/37]: Training Loss: 3.034102885, Training Accuracy: 24.464\n",
            "Worker 8, [08/37]: Training Loss: 3.021905999, Training Accuracy: 24.640\n",
            "Worker 8, [09/37]: Training Loss: 3.104371947, Training Accuracy: 23.472\n",
            "Worker 8, [10/37]: Training Loss: 3.048335343, Training Accuracy: 24.336\n",
            "Worker 8, [11/37]: Training Loss: 3.029954307, Training Accuracy: 24.336\n",
            "Worker 8, [12/37]: Training Loss: 2.996124253, Training Accuracy: 24.720\n",
            "Worker 8, [13/37]: Training Loss: 3.118463429, Training Accuracy: 22.272\n",
            "Worker 8, [14/37]: Training Loss: 3.075749091, Training Accuracy: 22.752\n",
            "Worker 8, [15/37]: Training Loss: 3.027316200, Training Accuracy: 23.904\n",
            "Worker 8, [16/37]: Training Loss: 3.021860524, Training Accuracy: 24.064\n",
            "Worker 8, [17/37]: Training Loss: 3.168711426, Training Accuracy: 21.120\n",
            "Worker 8, [18/37]: Training Loss: 3.120701948, Training Accuracy: 21.984\n",
            "Worker 8, [19/37]: Training Loss: 3.066182879, Training Accuracy: 23.920\n",
            "Worker 8, [20/37]: Training Loss: 3.019051627, Training Accuracy: 23.376\n",
            "Worker 8, [21/37]: Training Loss: 3.172374784, Training Accuracy: 21.072\n",
            "Worker 8, [22/37]: Training Loss: 3.135095453, Training Accuracy: 21.808\n",
            "Worker 8, [23/37]: Training Loss: 3.079988494, Training Accuracy: 22.336\n",
            "Worker 8, [24/37]: Training Loss: 3.046263948, Training Accuracy: 23.296\n",
            "Worker 8, [25/37]: Training Loss: 3.207875651, Training Accuracy: 20.784\n",
            "Worker 8, [26/37]: Training Loss: 3.146907714, Training Accuracy: 22.224\n",
            "Worker 8, [27/37]: Training Loss: 3.086309097, Training Accuracy: 22.512\n",
            "Worker 8, [28/37]: Training Loss: 3.012445866, Training Accuracy: 23.424\n",
            "Worker 8, [29/37]: Training Loss: 3.213108411, Training Accuracy: 19.968\n",
            "Worker 8, [30/37]: Training Loss: 3.159065008, Training Accuracy: 20.992\n",
            "Worker 8, [31/37]: Training Loss: 3.110543010, Training Accuracy: 21.968\n",
            "Worker 8, [32/37]: Training Loss: 3.007555295, Training Accuracy: 23.680\n",
            "Worker 8, [33/37]: Training Loss: 3.215712907, Training Accuracy: 20.176\n",
            "Worker 8, [34/37]: Training Loss: 3.151488664, Training Accuracy: 21.872\n",
            "Worker 8, [35/37]: Training Loss: 3.027868098, Training Accuracy: 24.144\n",
            "Worker 8, [36/37]: Training Loss: 2.989669272, Training Accuracy: 24.656\n",
            "Worker 8, [37/37]: Training Loss: 3.193301931, Training Accuracy: 20.400\n",
            "Time taken for training worker 8: 0:01:39.285473\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000769\n",
            "Local Step 04: Test Loss: 3.333771075, Test Accuracy: 19.870\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:29.008060\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/37]: Training Loss: 4.591671905, Training Accuracy: 1.680\n",
            "Worker 1, [02/37]: Training Loss: 4.452550762, Training Accuracy: 2.864\n",
            "Worker 1, [03/37]: Training Loss: 4.204601006, Training Accuracy: 5.984\n",
            "Worker 1, [04/37]: Training Loss: 4.056448776, Training Accuracy: 6.768\n",
            "Worker 1, [05/37]: Training Loss: 3.957221221, Training Accuracy: 8.208\n",
            "Worker 1, [06/37]: Training Loss: 3.844621889, Training Accuracy: 10.784\n",
            "Worker 1, [07/37]: Training Loss: 3.760972899, Training Accuracy: 11.680\n",
            "Worker 1, [08/37]: Training Loss: 3.684328417, Training Accuracy: 13.072\n",
            "Worker 1, [09/37]: Training Loss: 4.537259720, Training Accuracy: 2.368\n",
            "Worker 1, [10/37]: Training Loss: 4.218370596, Training Accuracy: 5.472\n",
            "Worker 1, [11/37]: Training Loss: 4.020152562, Training Accuracy: 7.696\n",
            "Worker 1, [12/37]: Training Loss: 3.871592806, Training Accuracy: 10.528\n",
            "Worker 1, [13/37]: Training Loss: 3.756746550, Training Accuracy: 12.176\n",
            "Worker 1, [14/37]: Training Loss: 3.672160718, Training Accuracy: 13.088\n",
            "Worker 1, [15/37]: Training Loss: 3.580910629, Training Accuracy: 14.800\n",
            "Worker 1, [16/37]: Training Loss: 3.487095076, Training Accuracy: 17.008\n",
            "Worker 1, [17/37]: Training Loss: 4.370426514, Training Accuracy: 4.928\n",
            "Worker 1, [18/37]: Training Loss: 4.018559089, Training Accuracy: 8.064\n",
            "Worker 1, [19/37]: Training Loss: 3.840467027, Training Accuracy: 10.592\n",
            "Worker 1, [20/37]: Training Loss: 3.705912427, Training Accuracy: 13.152\n",
            "Worker 1, [21/37]: Training Loss: 3.610055700, Training Accuracy: 14.432\n",
            "Worker 1, [22/37]: Training Loss: 3.520175450, Training Accuracy: 16.144\n",
            "Worker 1, [23/37]: Training Loss: 3.454016308, Training Accuracy: 17.360\n",
            "Worker 1, [24/37]: Training Loss: 3.368867400, Training Accuracy: 18.672\n",
            "Worker 1, [25/37]: Training Loss: 4.357818492, Training Accuracy: 6.688\n",
            "Worker 1, [26/37]: Training Loss: 3.984944431, Training Accuracy: 8.720\n",
            "Worker 1, [27/37]: Training Loss: 3.814049378, Training Accuracy: 11.216\n",
            "Worker 1, [28/37]: Training Loss: 3.715218809, Training Accuracy: 13.088\n",
            "Worker 1, [29/37]: Training Loss: 3.639202549, Training Accuracy: 15.120\n",
            "Worker 1, [30/37]: Training Loss: 3.567638478, Training Accuracy: 15.920\n",
            "Worker 1, [31/37]: Training Loss: 3.524197926, Training Accuracy: 16.304\n",
            "Worker 1, [32/37]: Training Loss: 3.488589856, Training Accuracy: 17.568\n",
            "Worker 1, [33/37]: Training Loss: 4.440717537, Training Accuracy: 9.504\n",
            "Worker 1, [34/37]: Training Loss: 4.343665687, Training Accuracy: 9.312\n",
            "Worker 1, [35/37]: Training Loss: 4.268994852, Training Accuracy: 9.728\n",
            "Worker 1, [36/37]: Training Loss: 4.224327861, Training Accuracy: 9.952\n",
            "Worker 1, [37/37]: Training Loss: 4.208201243, Training Accuracy: 9.472\n",
            "Time taken for training worker 1: 0:01:37.901261\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 4.593634090, Training Accuracy: 1.360\n",
            "Worker 2, [02/37]: Training Loss: 4.441893724, Training Accuracy: 3.392\n",
            "Worker 2, [03/37]: Training Loss: 4.190536825, Training Accuracy: 5.360\n",
            "Worker 2, [04/37]: Training Loss: 4.044831524, Training Accuracy: 7.472\n",
            "Worker 2, [05/37]: Training Loss: 3.936333639, Training Accuracy: 8.656\n",
            "Worker 2, [06/37]: Training Loss: 3.828938959, Training Accuracy: 10.048\n",
            "Worker 2, [07/37]: Training Loss: 3.723874703, Training Accuracy: 11.584\n",
            "Worker 2, [08/37]: Training Loss: 3.621791059, Training Accuracy: 12.992\n",
            "Worker 2, [09/37]: Training Loss: 4.510080756, Training Accuracy: 2.736\n",
            "Worker 2, [10/37]: Training Loss: 4.170819436, Training Accuracy: 6.080\n",
            "Worker 2, [11/37]: Training Loss: 3.972441595, Training Accuracy: 8.816\n",
            "Worker 2, [12/37]: Training Loss: 3.823938474, Training Accuracy: 10.912\n",
            "Worker 2, [13/37]: Training Loss: 3.691806037, Training Accuracy: 12.512\n",
            "Worker 2, [14/37]: Training Loss: 3.586911077, Training Accuracy: 13.952\n",
            "Worker 2, [15/37]: Training Loss: 3.494691944, Training Accuracy: 15.552\n",
            "Worker 2, [16/37]: Training Loss: 3.443653683, Training Accuracy: 15.744\n",
            "Worker 2, [17/37]: Training Loss: 4.355868269, Training Accuracy: 4.752\n",
            "Worker 2, [18/37]: Training Loss: 3.989825896, Training Accuracy: 8.672\n",
            "Worker 2, [19/37]: Training Loss: 3.776361794, Training Accuracy: 11.376\n",
            "Worker 2, [20/37]: Training Loss: 3.672071240, Training Accuracy: 13.264\n",
            "Worker 2, [21/37]: Training Loss: 3.566933153, Training Accuracy: 14.368\n",
            "Worker 2, [22/37]: Training Loss: 3.466006323, Training Accuracy: 16.000\n",
            "Worker 2, [23/37]: Training Loss: 3.380360869, Training Accuracy: 17.376\n",
            "Worker 2, [24/37]: Training Loss: 3.306544888, Training Accuracy: 18.272\n",
            "Worker 2, [25/37]: Training Loss: 4.341385007, Training Accuracy: 7.536\n",
            "Worker 2, [26/37]: Training Loss: 3.947170985, Training Accuracy: 8.912\n",
            "Worker 2, [27/37]: Training Loss: 3.779954540, Training Accuracy: 11.808\n",
            "Worker 2, [28/37]: Training Loss: 3.669855123, Training Accuracy: 13.088\n",
            "Worker 2, [29/37]: Training Loss: 3.589655599, Training Accuracy: 14.832\n",
            "Worker 2, [30/37]: Training Loss: 3.513074418, Training Accuracy: 15.744\n",
            "Worker 2, [31/37]: Training Loss: 3.465967616, Training Accuracy: 16.304\n",
            "Worker 2, [32/37]: Training Loss: 3.414482847, Training Accuracy: 17.632\n",
            "Worker 2, [33/37]: Training Loss: 4.434448057, Training Accuracy: 10.832\n",
            "Worker 2, [34/37]: Training Loss: 4.328013517, Training Accuracy: 10.208\n",
            "Worker 2, [35/37]: Training Loss: 4.245539227, Training Accuracy: 9.952\n",
            "Worker 2, [36/37]: Training Loss: 4.196018472, Training Accuracy: 9.808\n",
            "Worker 2, [37/37]: Training Loss: 4.177490356, Training Accuracy: 10.176\n",
            "Time taken for training worker 2: 0:01:38.528848\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 4.593640313, Training Accuracy: 1.696\n",
            "Worker 3, [02/37]: Training Loss: 4.452961888, Training Accuracy: 3.520\n",
            "Worker 3, [03/37]: Training Loss: 4.212184848, Training Accuracy: 5.360\n",
            "Worker 3, [04/37]: Training Loss: 4.068266078, Training Accuracy: 7.088\n",
            "Worker 3, [05/37]: Training Loss: 3.954835196, Training Accuracy: 8.256\n",
            "Worker 3, [06/37]: Training Loss: 3.848823348, Training Accuracy: 9.792\n",
            "Worker 3, [07/37]: Training Loss: 3.742683902, Training Accuracy: 11.888\n",
            "Worker 3, [08/37]: Training Loss: 3.649887287, Training Accuracy: 13.728\n",
            "Worker 3, [09/37]: Training Loss: 4.484914867, Training Accuracy: 3.136\n",
            "Worker 3, [10/37]: Training Loss: 4.171607879, Training Accuracy: 6.048\n",
            "Worker 3, [11/37]: Training Loss: 3.982228926, Training Accuracy: 8.528\n",
            "Worker 3, [12/37]: Training Loss: 3.815967538, Training Accuracy: 10.880\n",
            "Worker 3, [13/37]: Training Loss: 3.711995881, Training Accuracy: 13.008\n",
            "Worker 3, [14/37]: Training Loss: 3.626860731, Training Accuracy: 14.704\n",
            "Worker 3, [15/37]: Training Loss: 3.527529821, Training Accuracy: 15.664\n",
            "Worker 3, [16/37]: Training Loss: 3.454581599, Training Accuracy: 17.024\n",
            "Worker 3, [17/37]: Training Loss: 4.349390504, Training Accuracy: 5.808\n",
            "Worker 3, [18/37]: Training Loss: 3.996764745, Training Accuracy: 8.592\n",
            "Worker 3, [19/37]: Training Loss: 3.812412841, Training Accuracy: 11.152\n",
            "Worker 3, [20/37]: Training Loss: 3.689660530, Training Accuracy: 13.424\n",
            "Worker 3, [21/37]: Training Loss: 3.577770999, Training Accuracy: 15.504\n",
            "Worker 3, [22/37]: Training Loss: 3.492890013, Training Accuracy: 16.080\n",
            "Worker 3, [23/37]: Training Loss: 3.440100127, Training Accuracy: 17.232\n",
            "Worker 3, [24/37]: Training Loss: 3.340949372, Training Accuracy: 19.200\n",
            "Worker 3, [25/37]: Training Loss: 4.364603982, Training Accuracy: 6.784\n",
            "Worker 3, [26/37]: Training Loss: 3.984363086, Training Accuracy: 9.088\n",
            "Worker 3, [27/37]: Training Loss: 3.802753772, Training Accuracy: 11.200\n",
            "Worker 3, [28/37]: Training Loss: 3.696334287, Training Accuracy: 13.296\n",
            "Worker 3, [29/37]: Training Loss: 3.612696205, Training Accuracy: 15.536\n",
            "Worker 3, [30/37]: Training Loss: 3.557629524, Training Accuracy: 16.496\n",
            "Worker 3, [31/37]: Training Loss: 3.512681187, Training Accuracy: 17.120\n",
            "Worker 3, [32/37]: Training Loss: 3.480364376, Training Accuracy: 17.184\n",
            "Worker 3, [33/37]: Training Loss: 4.442759105, Training Accuracy: 9.568\n",
            "Worker 3, [34/37]: Training Loss: 4.340919246, Training Accuracy: 9.840\n",
            "Worker 3, [35/37]: Training Loss: 4.260643940, Training Accuracy: 9.504\n",
            "Worker 3, [36/37]: Training Loss: 4.212247975, Training Accuracy: 9.408\n",
            "Worker 3, [37/37]: Training Loss: 4.194974466, Training Accuracy: 9.328\n",
            "Time taken for training worker 3: 0:01:38.368585\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 4.594193390, Training Accuracy: 1.392\n",
            "Worker 4, [02/37]: Training Loss: 4.451369592, Training Accuracy: 3.792\n",
            "Worker 4, [03/37]: Training Loss: 4.201888904, Training Accuracy: 5.600\n",
            "Worker 4, [04/37]: Training Loss: 4.061704312, Training Accuracy: 7.584\n",
            "Worker 4, [05/37]: Training Loss: 3.937704468, Training Accuracy: 8.448\n",
            "Worker 4, [06/37]: Training Loss: 3.836970709, Training Accuracy: 10.208\n",
            "Worker 4, [07/37]: Training Loss: 3.734730913, Training Accuracy: 11.872\n",
            "Worker 4, [08/37]: Training Loss: 3.657561623, Training Accuracy: 12.704\n",
            "Worker 4, [09/37]: Training Loss: 4.482940732, Training Accuracy: 2.928\n",
            "Worker 4, [10/37]: Training Loss: 4.143645389, Training Accuracy: 6.832\n",
            "Worker 4, [11/37]: Training Loss: 3.930182209, Training Accuracy: 9.744\n",
            "Worker 4, [12/37]: Training Loss: 3.792537521, Training Accuracy: 11.680\n",
            "Worker 4, [13/37]: Training Loss: 3.674404254, Training Accuracy: 13.488\n",
            "Worker 4, [14/37]: Training Loss: 3.601424818, Training Accuracy: 14.048\n",
            "Worker 4, [15/37]: Training Loss: 3.492627976, Training Accuracy: 16.080\n",
            "Worker 4, [16/37]: Training Loss: 3.406839497, Training Accuracy: 17.264\n",
            "Worker 4, [17/37]: Training Loss: 4.389146885, Training Accuracy: 5.216\n",
            "Worker 4, [18/37]: Training Loss: 4.008424465, Training Accuracy: 8.400\n",
            "Worker 4, [19/37]: Training Loss: 3.804563474, Training Accuracy: 10.656\n",
            "Worker 4, [20/37]: Training Loss: 3.676887055, Training Accuracy: 13.328\n",
            "Worker 4, [21/37]: Training Loss: 3.570748665, Training Accuracy: 14.800\n",
            "Worker 4, [22/37]: Training Loss: 3.498392232, Training Accuracy: 15.952\n",
            "Worker 4, [23/37]: Training Loss: 3.397256250, Training Accuracy: 17.856\n",
            "Worker 4, [24/37]: Training Loss: 3.342465014, Training Accuracy: 18.640\n",
            "Worker 4, [25/37]: Training Loss: 4.362779615, Training Accuracy: 6.976\n",
            "Worker 4, [26/37]: Training Loss: 3.978982427, Training Accuracy: 9.440\n",
            "Worker 4, [27/37]: Training Loss: 3.805942930, Training Accuracy: 11.536\n",
            "Worker 4, [28/37]: Training Loss: 3.689909950, Training Accuracy: 13.360\n",
            "Worker 4, [29/37]: Training Loss: 3.614699006, Training Accuracy: 14.352\n",
            "Worker 4, [30/37]: Training Loss: 3.557426156, Training Accuracy: 15.920\n",
            "Worker 4, [31/37]: Training Loss: 3.499263063, Training Accuracy: 16.896\n",
            "Worker 4, [32/37]: Training Loss: 3.463165789, Training Accuracy: 17.584\n",
            "Worker 4, [33/37]: Training Loss: 4.439192465, Training Accuracy: 10.192\n",
            "Worker 4, [34/37]: Training Loss: 4.338411565, Training Accuracy: 10.032\n",
            "Worker 4, [35/37]: Training Loss: 4.259787229, Training Accuracy: 9.872\n",
            "Worker 4, [36/37]: Training Loss: 4.213371403, Training Accuracy: 9.616\n",
            "Worker 4, [37/37]: Training Loss: 4.194995661, Training Accuracy: 10.128\n",
            "Time taken for training worker 4: 0:01:39.354671\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 4.593233580, Training Accuracy: 1.616\n",
            "Worker 5, [02/37]: Training Loss: 4.445561789, Training Accuracy: 2.976\n",
            "Worker 5, [03/37]: Training Loss: 4.209887612, Training Accuracy: 5.936\n",
            "Worker 5, [04/37]: Training Loss: 4.049997038, Training Accuracy: 7.184\n",
            "Worker 5, [05/37]: Training Loss: 3.936712659, Training Accuracy: 8.848\n",
            "Worker 5, [06/37]: Training Loss: 3.845965181, Training Accuracy: 10.176\n",
            "Worker 5, [07/37]: Training Loss: 3.731680590, Training Accuracy: 11.216\n",
            "Worker 5, [08/37]: Training Loss: 3.644529491, Training Accuracy: 13.808\n",
            "Worker 5, [09/37]: Training Loss: 4.475151154, Training Accuracy: 3.728\n",
            "Worker 5, [10/37]: Training Loss: 4.140575175, Training Accuracy: 6.432\n",
            "Worker 5, [11/37]: Training Loss: 3.958388676, Training Accuracy: 8.912\n",
            "Worker 5, [12/37]: Training Loss: 3.803164339, Training Accuracy: 10.992\n",
            "Worker 5, [13/37]: Training Loss: 3.697627513, Training Accuracy: 12.832\n",
            "Worker 5, [14/37]: Training Loss: 3.592499672, Training Accuracy: 14.256\n",
            "Worker 5, [15/37]: Training Loss: 3.502991000, Training Accuracy: 15.600\n",
            "Worker 5, [16/37]: Training Loss: 3.444034370, Training Accuracy: 17.152\n",
            "Worker 5, [17/37]: Training Loss: 4.365150109, Training Accuracy: 5.024\n",
            "Worker 5, [18/37]: Training Loss: 3.997082538, Training Accuracy: 8.880\n",
            "Worker 5, [19/37]: Training Loss: 3.811790393, Training Accuracy: 11.568\n",
            "Worker 5, [20/37]: Training Loss: 3.686478289, Training Accuracy: 13.056\n",
            "Worker 5, [21/37]: Training Loss: 3.584656613, Training Accuracy: 15.216\n",
            "Worker 5, [22/37]: Training Loss: 3.499834362, Training Accuracy: 16.176\n",
            "Worker 5, [23/37]: Training Loss: 3.426646235, Training Accuracy: 16.960\n",
            "Worker 5, [24/37]: Training Loss: 3.346140849, Training Accuracy: 18.240\n",
            "Worker 5, [25/37]: Training Loss: 4.345744486, Training Accuracy: 7.200\n",
            "Worker 5, [26/37]: Training Loss: 3.968579275, Training Accuracy: 9.264\n",
            "Worker 5, [27/37]: Training Loss: 3.806007171, Training Accuracy: 11.584\n",
            "Worker 5, [28/37]: Training Loss: 3.698489583, Training Accuracy: 13.376\n",
            "Worker 5, [29/37]: Training Loss: 3.605424591, Training Accuracy: 14.816\n",
            "Worker 5, [30/37]: Training Loss: 3.547990672, Training Accuracy: 15.920\n",
            "Worker 5, [31/37]: Training Loss: 3.491852454, Training Accuracy: 17.136\n",
            "Worker 5, [32/37]: Training Loss: 3.447872490, Training Accuracy: 17.472\n",
            "Worker 5, [33/37]: Training Loss: 4.438494604, Training Accuracy: 9.840\n",
            "Worker 5, [34/37]: Training Loss: 4.340797692, Training Accuracy: 10.160\n",
            "Worker 5, [35/37]: Training Loss: 4.265579233, Training Accuracy: 9.600\n",
            "Worker 5, [36/37]: Training Loss: 4.220601909, Training Accuracy: 9.952\n",
            "Worker 5, [37/37]: Training Loss: 4.202190059, Training Accuracy: 10.112\n",
            "Time taken for training worker 5: 0:01:37.991361\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 4.594600527, Training Accuracy: 1.584\n",
            "Worker 6, [02/37]: Training Loss: 4.432497968, Training Accuracy: 3.440\n",
            "Worker 6, [03/37]: Training Loss: 4.189644553, Training Accuracy: 5.504\n",
            "Worker 6, [04/37]: Training Loss: 4.057459289, Training Accuracy: 7.008\n",
            "Worker 6, [05/37]: Training Loss: 3.930366701, Training Accuracy: 8.768\n",
            "Worker 6, [06/37]: Training Loss: 3.818895761, Training Accuracy: 10.640\n",
            "Worker 6, [07/37]: Training Loss: 3.731938060, Training Accuracy: 11.648\n",
            "Worker 6, [08/37]: Training Loss: 3.656056827, Training Accuracy: 13.616\n",
            "Worker 6, [09/37]: Training Loss: 4.494487329, Training Accuracy: 3.072\n",
            "Worker 6, [10/37]: Training Loss: 4.176761111, Training Accuracy: 5.952\n",
            "Worker 6, [11/37]: Training Loss: 3.972355633, Training Accuracy: 8.368\n",
            "Worker 6, [12/37]: Training Loss: 3.851663906, Training Accuracy: 10.336\n",
            "Worker 6, [13/37]: Training Loss: 3.740012123, Training Accuracy: 12.160\n",
            "Worker 6, [14/37]: Training Loss: 3.608128282, Training Accuracy: 14.304\n",
            "Worker 6, [15/37]: Training Loss: 3.518363695, Training Accuracy: 15.344\n",
            "Worker 6, [16/37]: Training Loss: 3.458360601, Training Accuracy: 16.592\n",
            "Worker 6, [17/37]: Training Loss: 4.393586241, Training Accuracy: 4.720\n",
            "Worker 6, [18/37]: Training Loss: 4.009689599, Training Accuracy: 8.256\n",
            "Worker 6, [19/37]: Training Loss: 3.816900725, Training Accuracy: 10.704\n",
            "Worker 6, [20/37]: Training Loss: 3.693671229, Training Accuracy: 12.832\n",
            "Worker 6, [21/37]: Training Loss: 3.593510102, Training Accuracy: 14.192\n",
            "Worker 6, [22/37]: Training Loss: 3.511342440, Training Accuracy: 16.176\n",
            "Worker 6, [23/37]: Training Loss: 3.433664536, Training Accuracy: 17.728\n",
            "Worker 6, [24/37]: Training Loss: 3.361837351, Training Accuracy: 18.160\n",
            "Worker 6, [25/37]: Training Loss: 4.351859922, Training Accuracy: 6.912\n",
            "Worker 6, [26/37]: Training Loss: 3.964101222, Training Accuracy: 9.408\n",
            "Worker 6, [27/37]: Training Loss: 3.804923096, Training Accuracy: 11.760\n",
            "Worker 6, [28/37]: Training Loss: 3.701445509, Training Accuracy: 13.216\n",
            "Worker 6, [29/37]: Training Loss: 3.623714647, Training Accuracy: 15.216\n",
            "Worker 6, [30/37]: Training Loss: 3.569563031, Training Accuracy: 14.672\n",
            "Worker 6, [31/37]: Training Loss: 3.522438181, Training Accuracy: 16.528\n",
            "Worker 6, [32/37]: Training Loss: 3.473525317, Training Accuracy: 17.504\n",
            "Worker 6, [33/37]: Training Loss: 4.437507080, Training Accuracy: 10.016\n",
            "Worker 6, [34/37]: Training Loss: 4.336910097, Training Accuracy: 9.248\n",
            "Worker 6, [35/37]: Training Loss: 4.258487010, Training Accuracy: 9.360\n",
            "Worker 6, [36/37]: Training Loss: 4.211487444, Training Accuracy: 9.280\n",
            "Worker 6, [37/37]: Training Loss: 4.192564833, Training Accuracy: 9.264\n",
            "Time taken for training worker 6: 0:01:39.551406\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 4.595788304, Training Accuracy: 1.296\n",
            "Worker 7, [02/37]: Training Loss: 4.440935816, Training Accuracy: 3.296\n",
            "Worker 7, [03/37]: Training Loss: 4.206436551, Training Accuracy: 4.768\n",
            "Worker 7, [04/37]: Training Loss: 4.058922717, Training Accuracy: 6.992\n",
            "Worker 7, [05/37]: Training Loss: 3.950813138, Training Accuracy: 8.288\n",
            "Worker 7, [06/37]: Training Loss: 3.837264268, Training Accuracy: 10.160\n",
            "Worker 7, [07/37]: Training Loss: 3.746540267, Training Accuracy: 11.632\n",
            "Worker 7, [08/37]: Training Loss: 3.678254870, Training Accuracy: 12.688\n",
            "Worker 7, [09/37]: Training Loss: 4.494803000, Training Accuracy: 2.576\n",
            "Worker 7, [10/37]: Training Loss: 4.188060517, Training Accuracy: 5.456\n",
            "Worker 7, [11/37]: Training Loss: 4.000626357, Training Accuracy: 7.808\n",
            "Worker 7, [12/37]: Training Loss: 3.869006590, Training Accuracy: 10.288\n",
            "Worker 7, [13/37]: Training Loss: 3.738106900, Training Accuracy: 11.552\n",
            "Worker 7, [14/37]: Training Loss: 3.679753625, Training Accuracy: 12.752\n",
            "Worker 7, [15/37]: Training Loss: 3.591078676, Training Accuracy: 14.080\n",
            "Worker 7, [16/37]: Training Loss: 3.498306150, Training Accuracy: 15.488\n",
            "Worker 7, [17/37]: Training Loss: 4.387447260, Training Accuracy: 4.352\n",
            "Worker 7, [18/37]: Training Loss: 4.009754414, Training Accuracy: 8.464\n",
            "Worker 7, [19/37]: Training Loss: 3.818625251, Training Accuracy: 11.184\n",
            "Worker 7, [20/37]: Training Loss: 3.709767848, Training Accuracy: 12.736\n",
            "Worker 7, [21/37]: Training Loss: 3.607732272, Training Accuracy: 14.768\n",
            "Worker 7, [22/37]: Training Loss: 3.537232735, Training Accuracy: 15.296\n",
            "Worker 7, [23/37]: Training Loss: 3.467373449, Training Accuracy: 16.224\n",
            "Worker 7, [24/37]: Training Loss: 3.383745476, Training Accuracy: 18.064\n",
            "Worker 7, [25/37]: Training Loss: 4.357489143, Training Accuracy: 6.832\n",
            "Worker 7, [26/37]: Training Loss: 3.980649221, Training Accuracy: 8.960\n",
            "Worker 7, [27/37]: Training Loss: 3.823580299, Training Accuracy: 10.768\n",
            "Worker 7, [28/37]: Training Loss: 3.722206045, Training Accuracy: 13.296\n",
            "Worker 7, [29/37]: Training Loss: 3.633987714, Training Accuracy: 14.240\n",
            "Worker 7, [30/37]: Training Loss: 3.576682779, Training Accuracy: 15.616\n",
            "Worker 7, [31/37]: Training Loss: 3.524697282, Training Accuracy: 16.624\n",
            "Worker 7, [32/37]: Training Loss: 3.488113459, Training Accuracy: 16.736\n",
            "Worker 7, [33/37]: Training Loss: 4.442569699, Training Accuracy: 9.536\n",
            "Worker 7, [34/37]: Training Loss: 4.343436270, Training Accuracy: 9.872\n",
            "Worker 7, [35/37]: Training Loss: 4.273241539, Training Accuracy: 9.600\n",
            "Worker 7, [36/37]: Training Loss: 4.226741883, Training Accuracy: 9.680\n",
            "Worker 7, [37/37]: Training Loss: 4.212814832, Training Accuracy: 9.568\n",
            "Time taken for training worker 7: 0:01:40.126488\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 4.593214215, Training Accuracy: 1.392\n",
            "Worker 8, [02/37]: Training Loss: 4.439671784, Training Accuracy: 3.200\n",
            "Worker 8, [03/37]: Training Loss: 4.180694814, Training Accuracy: 5.424\n",
            "Worker 8, [04/37]: Training Loss: 4.049027662, Training Accuracy: 7.200\n",
            "Worker 8, [05/37]: Training Loss: 3.935490365, Training Accuracy: 8.656\n",
            "Worker 8, [06/37]: Training Loss: 3.832968096, Training Accuracy: 10.192\n",
            "Worker 8, [07/37]: Training Loss: 3.729567306, Training Accuracy: 11.696\n",
            "Worker 8, [08/37]: Training Loss: 3.663322670, Training Accuracy: 12.688\n",
            "Worker 8, [09/37]: Training Loss: 4.499997762, Training Accuracy: 3.296\n",
            "Worker 8, [10/37]: Training Loss: 4.162650551, Training Accuracy: 6.256\n",
            "Worker 8, [11/37]: Training Loss: 3.964640703, Training Accuracy: 8.160\n",
            "Worker 8, [12/37]: Training Loss: 3.815138578, Training Accuracy: 10.336\n",
            "Worker 8, [13/37]: Training Loss: 3.724686793, Training Accuracy: 11.664\n",
            "Worker 8, [14/37]: Training Loss: 3.616301950, Training Accuracy: 13.264\n",
            "Worker 8, [15/37]: Training Loss: 3.556412889, Training Accuracy: 14.400\n",
            "Worker 8, [16/37]: Training Loss: 3.459321856, Training Accuracy: 16.032\n",
            "Worker 8, [17/37]: Training Loss: 4.385244104, Training Accuracy: 4.960\n",
            "Worker 8, [18/37]: Training Loss: 4.015946108, Training Accuracy: 8.560\n",
            "Worker 8, [19/37]: Training Loss: 3.814598517, Training Accuracy: 10.752\n",
            "Worker 8, [20/37]: Training Loss: 3.698074433, Training Accuracy: 13.008\n",
            "Worker 8, [21/37]: Training Loss: 3.607295138, Training Accuracy: 13.936\n",
            "Worker 8, [22/37]: Training Loss: 3.520998821, Training Accuracy: 15.328\n",
            "Worker 8, [23/37]: Training Loss: 3.442063896, Training Accuracy: 16.448\n",
            "Worker 8, [24/37]: Training Loss: 3.372687595, Training Accuracy: 17.488\n",
            "Worker 8, [25/37]: Training Loss: 4.345001535, Training Accuracy: 6.928\n",
            "Worker 8, [26/37]: Training Loss: 3.972278880, Training Accuracy: 8.800\n",
            "Worker 8, [27/37]: Training Loss: 3.805606543, Training Accuracy: 10.976\n",
            "Worker 8, [28/37]: Training Loss: 3.704076662, Training Accuracy: 12.400\n",
            "Worker 8, [29/37]: Training Loss: 3.626769947, Training Accuracy: 13.904\n",
            "Worker 8, [30/37]: Training Loss: 3.569902539, Training Accuracy: 15.632\n",
            "Worker 8, [31/37]: Training Loss: 3.517471503, Training Accuracy: 15.712\n",
            "Worker 8, [32/37]: Training Loss: 3.473048981, Training Accuracy: 16.640\n",
            "Worker 8, [33/37]: Training Loss: 4.436142946, Training Accuracy: 9.360\n",
            "Worker 8, [34/37]: Training Loss: 4.335335099, Training Accuracy: 9.360\n",
            "Worker 8, [35/37]: Training Loss: 4.255176121, Training Accuracy: 9.440\n",
            "Worker 8, [36/37]: Training Loss: 4.211393332, Training Accuracy: 9.232\n",
            "Worker 8, [37/37]: Training Loss: 4.193599212, Training Accuracy: 9.264\n",
            "Time taken for training worker 8: 0:01:36.594586\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000726\n",
            "Local Step 01: Test Loss: 4.290870208, Test Accuracy: 8.510\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 4.308895821, Training Accuracy: 7.824\n",
            "Worker 1, [02/37]: Training Loss: 4.306849514, Training Accuracy: 7.600\n",
            "Worker 1, [03/37]: Training Loss: 4.295265908, Training Accuracy: 7.600\n",
            "Worker 1, [04/37]: Training Loss: 4.258110003, Training Accuracy: 7.920\n",
            "Worker 1, [05/37]: Training Loss: 4.192129291, Training Accuracy: 8.240\n",
            "Worker 1, [06/37]: Training Loss: 4.097129603, Training Accuracy: 8.832\n",
            "Worker 1, [07/37]: Training Loss: 4.010652316, Training Accuracy: 9.056\n",
            "Worker 1, [08/37]: Training Loss: 3.931148913, Training Accuracy: 10.208\n",
            "Worker 1, [09/37]: Training Loss: 4.295497814, Training Accuracy: 9.344\n",
            "Worker 1, [10/37]: Training Loss: 3.979241430, Training Accuracy: 9.664\n",
            "Worker 1, [11/37]: Training Loss: 3.842549494, Training Accuracy: 11.648\n",
            "Worker 1, [12/37]: Training Loss: 3.742665422, Training Accuracy: 13.200\n",
            "Worker 1, [13/37]: Training Loss: 3.672179774, Training Accuracy: 13.792\n",
            "Worker 1, [14/37]: Training Loss: 3.598878286, Training Accuracy: 14.768\n",
            "Worker 1, [15/37]: Training Loss: 3.559046714, Training Accuracy: 15.280\n",
            "Worker 1, [16/37]: Training Loss: 3.512675733, Training Accuracy: 16.528\n",
            "Worker 1, [17/37]: Training Loss: 4.041087119, Training Accuracy: 10.016\n",
            "Worker 1, [18/37]: Training Loss: 3.753247585, Training Accuracy: 12.384\n",
            "Worker 1, [19/37]: Training Loss: 3.623190498, Training Accuracy: 14.304\n",
            "Worker 1, [20/37]: Training Loss: 3.548870079, Training Accuracy: 15.568\n",
            "Worker 1, [21/37]: Training Loss: 3.483415730, Training Accuracy: 16.384\n",
            "Worker 1, [22/37]: Training Loss: 3.444058153, Training Accuracy: 17.136\n",
            "Worker 1, [23/37]: Training Loss: 3.370534196, Training Accuracy: 18.704\n",
            "Worker 1, [24/37]: Training Loss: 3.329673300, Training Accuracy: 19.312\n",
            "Worker 1, [25/37]: Training Loss: 3.903923424, Training Accuracy: 10.800\n",
            "Worker 1, [26/37]: Training Loss: 3.670928549, Training Accuracy: 13.328\n",
            "Worker 1, [27/37]: Training Loss: 3.537919614, Training Accuracy: 15.552\n",
            "Worker 1, [28/37]: Training Loss: 3.450700127, Training Accuracy: 16.688\n",
            "Worker 1, [29/37]: Training Loss: 3.376301982, Training Accuracy: 17.360\n",
            "Worker 1, [30/37]: Training Loss: 3.297066144, Training Accuracy: 20.064\n",
            "Worker 1, [31/37]: Training Loss: 3.255139791, Training Accuracy: 20.368\n",
            "Worker 1, [32/37]: Training Loss: 3.160201686, Training Accuracy: 22.016\n",
            "Worker 1, [33/37]: Training Loss: 3.826186479, Training Accuracy: 11.760\n",
            "Worker 1, [34/37]: Training Loss: 3.580623902, Training Accuracy: 15.008\n",
            "Worker 1, [35/37]: Training Loss: 3.482326748, Training Accuracy: 16.592\n",
            "Worker 1, [36/37]: Training Loss: 3.353502874, Training Accuracy: 18.992\n",
            "Worker 1, [37/37]: Training Loss: 3.286938533, Training Accuracy: 20.080\n",
            "Time taken for training worker 1: 0:01:38.094317\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.579194704, Training Accuracy: 16.448\n",
            "Worker 2, [02/37]: Training Loss: 3.544871865, Training Accuracy: 16.080\n",
            "Worker 2, [03/37]: Training Loss: 3.459231318, Training Accuracy: 17.344\n",
            "Worker 2, [04/37]: Training Loss: 3.385185521, Training Accuracy: 18.960\n",
            "Worker 2, [05/37]: Training Loss: 3.325587985, Training Accuracy: 20.096\n",
            "Worker 2, [06/37]: Training Loss: 3.279408231, Training Accuracy: 20.272\n",
            "Worker 2, [07/37]: Training Loss: 3.229507373, Training Accuracy: 21.632\n",
            "Worker 2, [08/37]: Training Loss: 3.188362630, Training Accuracy: 22.240\n",
            "Worker 2, [09/37]: Training Loss: 4.242080744, Training Accuracy: 11.568\n",
            "Worker 2, [10/37]: Training Loss: 3.871125856, Training Accuracy: 11.280\n",
            "Worker 2, [11/37]: Training Loss: 3.705427189, Training Accuracy: 12.912\n",
            "Worker 2, [12/37]: Training Loss: 3.633687435, Training Accuracy: 13.968\n",
            "Worker 2, [13/37]: Training Loss: 3.556521005, Training Accuracy: 15.024\n",
            "Worker 2, [14/37]: Training Loss: 3.484245891, Training Accuracy: 16.288\n",
            "Worker 2, [15/37]: Training Loss: 3.420814069, Training Accuracy: 16.848\n",
            "Worker 2, [16/37]: Training Loss: 3.372008988, Training Accuracy: 17.648\n",
            "Worker 2, [17/37]: Training Loss: 3.929346503, Training Accuracy: 11.328\n",
            "Worker 2, [18/37]: Training Loss: 3.634438354, Training Accuracy: 13.968\n",
            "Worker 2, [19/37]: Training Loss: 3.520135094, Training Accuracy: 15.024\n",
            "Worker 2, [20/37]: Training Loss: 3.424074000, Training Accuracy: 16.656\n",
            "Worker 2, [21/37]: Training Loss: 3.348908420, Training Accuracy: 18.240\n",
            "Worker 2, [22/37]: Training Loss: 3.296375316, Training Accuracy: 19.152\n",
            "Worker 2, [23/37]: Training Loss: 3.231398295, Training Accuracy: 20.256\n",
            "Worker 2, [24/37]: Training Loss: 3.173333574, Training Accuracy: 21.504\n",
            "Worker 2, [25/37]: Training Loss: 3.814563578, Training Accuracy: 12.432\n",
            "Worker 2, [26/37]: Training Loss: 3.524842150, Training Accuracy: 15.808\n",
            "Worker 2, [27/37]: Training Loss: 3.424265891, Training Accuracy: 16.720\n",
            "Worker 2, [28/37]: Training Loss: 3.344608441, Training Accuracy: 18.272\n",
            "Worker 2, [29/37]: Training Loss: 3.263231005, Training Accuracy: 19.360\n",
            "Worker 2, [30/37]: Training Loss: 3.152597160, Training Accuracy: 21.504\n",
            "Worker 2, [31/37]: Training Loss: 3.091742005, Training Accuracy: 22.144\n",
            "Worker 2, [32/37]: Training Loss: 3.043404183, Training Accuracy: 23.360\n",
            "Worker 2, [33/37]: Training Loss: 3.713130749, Training Accuracy: 12.928\n",
            "Worker 2, [34/37]: Training Loss: 3.455970587, Training Accuracy: 16.544\n",
            "Worker 2, [35/37]: Training Loss: 3.344728132, Training Accuracy: 18.432\n",
            "Worker 2, [36/37]: Training Loss: 3.232447456, Training Accuracy: 19.680\n",
            "Worker 2, [37/37]: Training Loss: 3.155598066, Training Accuracy: 22.000\n",
            "Time taken for training worker 2: 0:01:39.248844\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.447704607, Training Accuracy: 18.064\n",
            "Worker 3, [02/37]: Training Loss: 3.424875184, Training Accuracy: 18.688\n",
            "Worker 3, [03/37]: Training Loss: 3.367284926, Training Accuracy: 19.504\n",
            "Worker 3, [04/37]: Training Loss: 3.297228957, Training Accuracy: 20.832\n",
            "Worker 3, [05/37]: Training Loss: 3.255948872, Training Accuracy: 21.392\n",
            "Worker 3, [06/37]: Training Loss: 3.223591109, Training Accuracy: 22.432\n",
            "Worker 3, [07/37]: Training Loss: 3.173197457, Training Accuracy: 23.152\n",
            "Worker 3, [08/37]: Training Loss: 3.134642601, Training Accuracy: 23.952\n",
            "Worker 3, [09/37]: Training Loss: 4.271776907, Training Accuracy: 11.616\n",
            "Worker 3, [10/37]: Training Loss: 3.898034327, Training Accuracy: 10.832\n",
            "Worker 3, [11/37]: Training Loss: 3.740878981, Training Accuracy: 12.464\n",
            "Worker 3, [12/37]: Training Loss: 3.651723451, Training Accuracy: 13.728\n",
            "Worker 3, [13/37]: Training Loss: 3.583878091, Training Accuracy: 15.088\n",
            "Worker 3, [14/37]: Training Loss: 3.508886262, Training Accuracy: 16.512\n",
            "Worker 3, [15/37]: Training Loss: 3.481886470, Training Accuracy: 16.592\n",
            "Worker 3, [16/37]: Training Loss: 3.388128592, Training Accuracy: 18.464\n",
            "Worker 3, [17/37]: Training Loss: 3.952748620, Training Accuracy: 11.296\n",
            "Worker 3, [18/37]: Training Loss: 3.661560141, Training Accuracy: 13.888\n",
            "Worker 3, [19/37]: Training Loss: 3.546558937, Training Accuracy: 15.856\n",
            "Worker 3, [20/37]: Training Loss: 3.437246186, Training Accuracy: 17.056\n",
            "Worker 3, [21/37]: Training Loss: 3.400101041, Training Accuracy: 18.512\n",
            "Worker 3, [22/37]: Training Loss: 3.332299875, Training Accuracy: 19.296\n",
            "Worker 3, [23/37]: Training Loss: 3.272626339, Training Accuracy: 19.808\n",
            "Worker 3, [24/37]: Training Loss: 3.203633863, Training Accuracy: 21.152\n",
            "Worker 3, [25/37]: Training Loss: 3.844004157, Training Accuracy: 12.224\n",
            "Worker 3, [26/37]: Training Loss: 3.572972590, Training Accuracy: 15.552\n",
            "Worker 3, [27/37]: Training Loss: 3.418412272, Training Accuracy: 17.888\n",
            "Worker 3, [28/37]: Training Loss: 3.350694077, Training Accuracy: 18.448\n",
            "Worker 3, [29/37]: Training Loss: 3.251168567, Training Accuracy: 20.496\n",
            "Worker 3, [30/37]: Training Loss: 3.191107368, Training Accuracy: 21.216\n",
            "Worker 3, [31/37]: Training Loss: 3.113608268, Training Accuracy: 22.720\n",
            "Worker 3, [32/37]: Training Loss: 3.045911015, Training Accuracy: 24.208\n",
            "Worker 3, [33/37]: Training Loss: 3.740534773, Training Accuracy: 13.408\n",
            "Worker 3, [34/37]: Training Loss: 3.466064825, Training Accuracy: 16.144\n",
            "Worker 3, [35/37]: Training Loss: 3.383183601, Training Accuracy: 18.064\n",
            "Worker 3, [36/37]: Training Loss: 3.261101647, Training Accuracy: 19.728\n",
            "Worker 3, [37/37]: Training Loss: 3.167781046, Training Accuracy: 21.904\n",
            "Time taken for training worker 3: 0:01:38.830417\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.487221234, Training Accuracy: 16.864\n",
            "Worker 4, [02/37]: Training Loss: 3.448797175, Training Accuracy: 17.008\n",
            "Worker 4, [03/37]: Training Loss: 3.360491286, Training Accuracy: 18.336\n",
            "Worker 4, [04/37]: Training Loss: 3.309839691, Training Accuracy: 19.616\n",
            "Worker 4, [05/37]: Training Loss: 3.251438353, Training Accuracy: 21.008\n",
            "Worker 4, [06/37]: Training Loss: 3.207911776, Training Accuracy: 22.768\n",
            "Worker 4, [07/37]: Training Loss: 3.163375791, Training Accuracy: 22.832\n",
            "Worker 4, [08/37]: Training Loss: 3.124835820, Training Accuracy: 23.648\n",
            "Worker 4, [09/37]: Training Loss: 4.262446172, Training Accuracy: 11.504\n",
            "Worker 4, [10/37]: Training Loss: 3.887482181, Training Accuracy: 11.360\n",
            "Worker 4, [11/37]: Training Loss: 3.739613212, Training Accuracy: 12.816\n",
            "Worker 4, [12/37]: Training Loss: 3.641846399, Training Accuracy: 14.784\n",
            "Worker 4, [13/37]: Training Loss: 3.567419714, Training Accuracy: 15.088\n",
            "Worker 4, [14/37]: Training Loss: 3.503809827, Training Accuracy: 16.128\n",
            "Worker 4, [15/37]: Training Loss: 3.450496725, Training Accuracy: 17.088\n",
            "Worker 4, [16/37]: Training Loss: 3.381043585, Training Accuracy: 18.336\n",
            "Worker 4, [17/37]: Training Loss: 3.942657405, Training Accuracy: 11.712\n",
            "Worker 4, [18/37]: Training Loss: 3.647277567, Training Accuracy: 14.016\n",
            "Worker 4, [19/37]: Training Loss: 3.515194377, Training Accuracy: 15.920\n",
            "Worker 4, [20/37]: Training Loss: 3.433362479, Training Accuracy: 17.008\n",
            "Worker 4, [21/37]: Training Loss: 3.365314622, Training Accuracy: 18.384\n",
            "Worker 4, [22/37]: Training Loss: 3.298983915, Training Accuracy: 20.032\n",
            "Worker 4, [23/37]: Training Loss: 3.243922647, Training Accuracy: 20.352\n",
            "Worker 4, [24/37]: Training Loss: 3.196755886, Training Accuracy: 21.312\n",
            "Worker 4, [25/37]: Training Loss: 3.826085794, Training Accuracy: 12.880\n",
            "Worker 4, [26/37]: Training Loss: 3.555858444, Training Accuracy: 15.296\n",
            "Worker 4, [27/37]: Training Loss: 3.425727474, Training Accuracy: 17.344\n",
            "Worker 4, [28/37]: Training Loss: 3.344899384, Training Accuracy: 18.496\n",
            "Worker 4, [29/37]: Training Loss: 3.274993135, Training Accuracy: 19.440\n",
            "Worker 4, [30/37]: Training Loss: 3.178336000, Training Accuracy: 21.824\n",
            "Worker 4, [31/37]: Training Loss: 3.124157779, Training Accuracy: 22.848\n",
            "Worker 4, [32/37]: Training Loss: 3.033379253, Training Accuracy: 23.888\n",
            "Worker 4, [33/37]: Training Loss: 3.725108932, Training Accuracy: 14.160\n",
            "Worker 4, [34/37]: Training Loss: 3.466414121, Training Accuracy: 16.432\n",
            "Worker 4, [35/37]: Training Loss: 3.333521262, Training Accuracy: 18.624\n",
            "Worker 4, [36/37]: Training Loss: 3.259407858, Training Accuracy: 20.272\n",
            "Worker 4, [37/37]: Training Loss: 3.150172409, Training Accuracy: 22.128\n",
            "Time taken for training worker 4: 0:01:37.827465\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.465620087, Training Accuracy: 17.840\n",
            "Worker 5, [02/37]: Training Loss: 3.440260347, Training Accuracy: 18.368\n",
            "Worker 5, [03/37]: Training Loss: 3.367455448, Training Accuracy: 19.536\n",
            "Worker 5, [04/37]: Training Loss: 3.314569595, Training Accuracy: 20.768\n",
            "Worker 5, [05/37]: Training Loss: 3.254627306, Training Accuracy: 21.968\n",
            "Worker 5, [06/37]: Training Loss: 3.208033593, Training Accuracy: 22.704\n",
            "Worker 5, [07/37]: Training Loss: 3.183753787, Training Accuracy: 22.848\n",
            "Worker 5, [08/37]: Training Loss: 3.125489077, Training Accuracy: 23.600\n",
            "Worker 5, [09/37]: Training Loss: 4.255423419, Training Accuracy: 11.120\n",
            "Worker 5, [10/37]: Training Loss: 3.881160106, Training Accuracy: 11.120\n",
            "Worker 5, [11/37]: Training Loss: 3.731857986, Training Accuracy: 13.184\n",
            "Worker 5, [12/37]: Training Loss: 3.639255782, Training Accuracy: 13.744\n",
            "Worker 5, [13/37]: Training Loss: 3.558011001, Training Accuracy: 15.952\n",
            "Worker 5, [14/37]: Training Loss: 3.496174328, Training Accuracy: 16.496\n",
            "Worker 5, [15/37]: Training Loss: 3.435104047, Training Accuracy: 17.504\n",
            "Worker 5, [16/37]: Training Loss: 3.412176346, Training Accuracy: 17.536\n",
            "Worker 5, [17/37]: Training Loss: 3.954533450, Training Accuracy: 11.056\n",
            "Worker 5, [18/37]: Training Loss: 3.645324345, Training Accuracy: 13.936\n",
            "Worker 5, [19/37]: Training Loss: 3.511252464, Training Accuracy: 15.680\n",
            "Worker 5, [20/37]: Training Loss: 3.449417195, Training Accuracy: 16.752\n",
            "Worker 5, [21/37]: Training Loss: 3.363463772, Training Accuracy: 18.944\n",
            "Worker 5, [22/37]: Training Loss: 3.330604327, Training Accuracy: 19.072\n",
            "Worker 5, [23/37]: Training Loss: 3.241667064, Training Accuracy: 20.496\n",
            "Worker 5, [24/37]: Training Loss: 3.217672462, Training Accuracy: 20.640\n",
            "Worker 5, [25/37]: Training Loss: 3.826553442, Training Accuracy: 11.792\n",
            "Worker 5, [26/37]: Training Loss: 3.563827592, Training Accuracy: 15.472\n",
            "Worker 5, [27/37]: Training Loss: 3.450199830, Training Accuracy: 17.120\n",
            "Worker 5, [28/37]: Training Loss: 3.339942343, Training Accuracy: 19.344\n",
            "Worker 5, [29/37]: Training Loss: 3.267715766, Training Accuracy: 20.544\n",
            "Worker 5, [30/37]: Training Loss: 3.193752848, Training Accuracy: 21.936\n",
            "Worker 5, [31/37]: Training Loss: 3.132042036, Training Accuracy: 22.240\n",
            "Worker 5, [32/37]: Training Loss: 3.054316876, Training Accuracy: 24.272\n",
            "Worker 5, [33/37]: Training Loss: 3.729019279, Training Accuracy: 13.840\n",
            "Worker 5, [34/37]: Training Loss: 3.494764742, Training Accuracy: 16.464\n",
            "Worker 5, [35/37]: Training Loss: 3.375317311, Training Accuracy: 18.352\n",
            "Worker 5, [36/37]: Training Loss: 3.248753835, Training Accuracy: 19.680\n",
            "Worker 5, [37/37]: Training Loss: 3.158184382, Training Accuracy: 21.552\n",
            "Time taken for training worker 5: 0:01:37.715130\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.389673075, Training Accuracy: 19.232\n",
            "Worker 6, [02/37]: Training Loss: 3.374328304, Training Accuracy: 19.568\n",
            "Worker 6, [03/37]: Training Loss: 3.344435247, Training Accuracy: 19.888\n",
            "Worker 6, [04/37]: Training Loss: 3.284912980, Training Accuracy: 21.264\n",
            "Worker 6, [05/37]: Training Loss: 3.241156186, Training Accuracy: 21.856\n",
            "Worker 6, [06/37]: Training Loss: 3.204105419, Training Accuracy: 22.496\n",
            "Worker 6, [07/37]: Training Loss: 3.161960254, Training Accuracy: 23.312\n",
            "Worker 6, [08/37]: Training Loss: 3.114408342, Training Accuracy: 23.936\n",
            "Worker 6, [09/37]: Training Loss: 4.265149416, Training Accuracy: 10.944\n",
            "Worker 6, [10/37]: Training Loss: 3.885011225, Training Accuracy: 11.280\n",
            "Worker 6, [11/37]: Training Loss: 3.761593030, Training Accuracy: 12.016\n",
            "Worker 6, [12/37]: Training Loss: 3.647274523, Training Accuracy: 14.176\n",
            "Worker 6, [13/37]: Training Loss: 3.579888570, Training Accuracy: 15.216\n",
            "Worker 6, [14/37]: Training Loss: 3.522924241, Training Accuracy: 16.336\n",
            "Worker 6, [15/37]: Training Loss: 3.462772703, Training Accuracy: 16.944\n",
            "Worker 6, [16/37]: Training Loss: 3.413809363, Training Accuracy: 16.976\n",
            "Worker 6, [17/37]: Training Loss: 3.962208821, Training Accuracy: 10.720\n",
            "Worker 6, [18/37]: Training Loss: 3.666679467, Training Accuracy: 13.232\n",
            "Worker 6, [19/37]: Training Loss: 3.539755770, Training Accuracy: 15.424\n",
            "Worker 6, [20/37]: Training Loss: 3.445941261, Training Accuracy: 17.040\n",
            "Worker 6, [21/37]: Training Loss: 3.411417100, Training Accuracy: 17.392\n",
            "Worker 6, [22/37]: Training Loss: 3.324758705, Training Accuracy: 19.168\n",
            "Worker 6, [23/37]: Training Loss: 3.256155145, Training Accuracy: 19.536\n",
            "Worker 6, [24/37]: Training Loss: 3.211736190, Training Accuracy: 20.416\n",
            "Worker 6, [25/37]: Training Loss: 3.818767136, Training Accuracy: 12.112\n",
            "Worker 6, [26/37]: Training Loss: 3.562018195, Training Accuracy: 15.024\n",
            "Worker 6, [27/37]: Training Loss: 3.443787660, Training Accuracy: 16.560\n",
            "Worker 6, [28/37]: Training Loss: 3.335862457, Training Accuracy: 18.448\n",
            "Worker 6, [29/37]: Training Loss: 3.281004675, Training Accuracy: 19.552\n",
            "Worker 6, [30/37]: Training Loss: 3.223894586, Training Accuracy: 20.832\n",
            "Worker 6, [31/37]: Training Loss: 3.122566335, Training Accuracy: 22.800\n",
            "Worker 6, [32/37]: Training Loss: 3.067983306, Training Accuracy: 22.992\n",
            "Worker 6, [33/37]: Training Loss: 3.732676363, Training Accuracy: 12.672\n",
            "Worker 6, [34/37]: Training Loss: 3.470326837, Training Accuracy: 15.984\n",
            "Worker 6, [35/37]: Training Loss: 3.345679115, Training Accuracy: 18.752\n",
            "Worker 6, [36/37]: Training Loss: 3.257440419, Training Accuracy: 20.400\n",
            "Worker 6, [37/37]: Training Loss: 3.144006697, Training Accuracy: 21.376\n",
            "Time taken for training worker 6: 0:01:37.928379\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.530934088, Training Accuracy: 16.688\n",
            "Worker 7, [02/37]: Training Loss: 3.482337596, Training Accuracy: 16.944\n",
            "Worker 7, [03/37]: Training Loss: 3.393504454, Training Accuracy: 18.880\n",
            "Worker 7, [04/37]: Training Loss: 3.300576375, Training Accuracy: 20.592\n",
            "Worker 7, [05/37]: Training Loss: 3.243684433, Training Accuracy: 21.360\n",
            "Worker 7, [06/37]: Training Loss: 3.213860485, Training Accuracy: 21.856\n",
            "Worker 7, [07/37]: Training Loss: 3.158350584, Training Accuracy: 22.528\n",
            "Worker 7, [08/37]: Training Loss: 3.118973744, Training Accuracy: 23.360\n",
            "Worker 7, [09/37]: Training Loss: 4.269106242, Training Accuracy: 10.192\n",
            "Worker 7, [10/37]: Training Loss: 3.907534444, Training Accuracy: 10.976\n",
            "Worker 7, [11/37]: Training Loss: 3.770826753, Training Accuracy: 11.872\n",
            "Worker 7, [12/37]: Training Loss: 3.673183536, Training Accuracy: 13.632\n",
            "Worker 7, [13/37]: Training Loss: 3.610434053, Training Accuracy: 14.576\n",
            "Worker 7, [14/37]: Training Loss: 3.543127281, Training Accuracy: 15.824\n",
            "Worker 7, [15/37]: Training Loss: 3.480578126, Training Accuracy: 16.272\n",
            "Worker 7, [16/37]: Training Loss: 3.453116378, Training Accuracy: 16.592\n",
            "Worker 7, [17/37]: Training Loss: 3.967175189, Training Accuracy: 10.512\n",
            "Worker 7, [18/37]: Training Loss: 3.673475319, Training Accuracy: 12.944\n",
            "Worker 7, [19/37]: Training Loss: 3.555163583, Training Accuracy: 15.296\n",
            "Worker 7, [20/37]: Training Loss: 3.489380975, Training Accuracy: 15.856\n",
            "Worker 7, [21/37]: Training Loss: 3.425379882, Training Accuracy: 17.600\n",
            "Worker 7, [22/37]: Training Loss: 3.337280512, Training Accuracy: 18.000\n",
            "Worker 7, [23/37]: Training Loss: 3.301540895, Training Accuracy: 18.608\n",
            "Worker 7, [24/37]: Training Loss: 3.250420473, Training Accuracy: 19.792\n",
            "Worker 7, [25/37]: Training Loss: 3.842713745, Training Accuracy: 12.144\n",
            "Worker 7, [26/37]: Training Loss: 3.590410612, Training Accuracy: 14.096\n",
            "Worker 7, [27/37]: Training Loss: 3.467950417, Training Accuracy: 16.832\n",
            "Worker 7, [28/37]: Training Loss: 3.367307836, Training Accuracy: 17.888\n",
            "Worker 7, [29/37]: Training Loss: 3.284480238, Training Accuracy: 19.376\n",
            "Worker 7, [30/37]: Training Loss: 3.232899026, Training Accuracy: 19.424\n",
            "Worker 7, [31/37]: Training Loss: 3.146559508, Training Accuracy: 22.112\n",
            "Worker 7, [32/37]: Training Loss: 3.091729174, Training Accuracy: 22.608\n",
            "Worker 7, [33/37]: Training Loss: 3.773711910, Training Accuracy: 12.544\n",
            "Worker 7, [34/37]: Training Loss: 3.503924260, Training Accuracy: 16.256\n",
            "Worker 7, [35/37]: Training Loss: 3.389027360, Training Accuracy: 17.568\n",
            "Worker 7, [36/37]: Training Loss: 3.264617351, Training Accuracy: 19.728\n",
            "Worker 7, [37/37]: Training Loss: 3.184679581, Training Accuracy: 20.864\n",
            "Time taken for training worker 7: 0:01:37.369361\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.388247373, Training Accuracy: 19.744\n",
            "Worker 8, [02/37]: Training Loss: 3.375387875, Training Accuracy: 19.168\n",
            "Worker 8, [03/37]: Training Loss: 3.342468135, Training Accuracy: 19.664\n",
            "Worker 8, [04/37]: Training Loss: 3.303384941, Training Accuracy: 20.784\n",
            "Worker 8, [05/37]: Training Loss: 3.254499596, Training Accuracy: 21.232\n",
            "Worker 8, [06/37]: Training Loss: 3.223192453, Training Accuracy: 21.456\n",
            "Worker 8, [07/37]: Training Loss: 3.188286901, Training Accuracy: 22.512\n",
            "Worker 8, [08/37]: Training Loss: 3.139327803, Training Accuracy: 23.376\n",
            "Worker 8, [09/37]: Training Loss: 4.261817429, Training Accuracy: 10.688\n",
            "Worker 8, [10/37]: Training Loss: 3.898837987, Training Accuracy: 10.416\n",
            "Worker 8, [11/37]: Training Loss: 3.738567260, Training Accuracy: 12.544\n",
            "Worker 8, [12/37]: Training Loss: 3.651860449, Training Accuracy: 13.728\n",
            "Worker 8, [13/37]: Training Loss: 3.593485484, Training Accuracy: 14.480\n",
            "Worker 8, [14/37]: Training Loss: 3.530044872, Training Accuracy: 15.648\n",
            "Worker 8, [15/37]: Training Loss: 3.459586431, Training Accuracy: 16.096\n",
            "Worker 8, [16/37]: Training Loss: 3.411007536, Training Accuracy: 16.896\n",
            "Worker 8, [17/37]: Training Loss: 3.966384292, Training Accuracy: 10.496\n",
            "Worker 8, [18/37]: Training Loss: 3.668320177, Training Accuracy: 13.312\n",
            "Worker 8, [19/37]: Training Loss: 3.549118777, Training Accuracy: 15.376\n",
            "Worker 8, [20/37]: Training Loss: 3.479549425, Training Accuracy: 16.576\n",
            "Worker 8, [21/37]: Training Loss: 3.411869124, Training Accuracy: 16.992\n",
            "Worker 8, [22/37]: Training Loss: 3.329263726, Training Accuracy: 17.648\n",
            "Worker 8, [23/37]: Training Loss: 3.277061370, Training Accuracy: 19.584\n",
            "Worker 8, [24/37]: Training Loss: 3.214450985, Training Accuracy: 20.432\n",
            "Worker 8, [25/37]: Training Loss: 3.832358049, Training Accuracy: 11.536\n",
            "Worker 8, [26/37]: Training Loss: 3.578629499, Training Accuracy: 14.592\n",
            "Worker 8, [27/37]: Training Loss: 3.443507980, Training Accuracy: 16.256\n",
            "Worker 8, [28/37]: Training Loss: 3.354456940, Training Accuracy: 18.032\n",
            "Worker 8, [29/37]: Training Loss: 3.289603503, Training Accuracy: 19.296\n",
            "Worker 8, [30/37]: Training Loss: 3.197495903, Training Accuracy: 20.224\n",
            "Worker 8, [31/37]: Training Loss: 3.160017741, Training Accuracy: 20.656\n",
            "Worker 8, [32/37]: Training Loss: 3.055080545, Training Accuracy: 23.216\n",
            "Worker 8, [33/37]: Training Loss: 3.729058348, Training Accuracy: 13.024\n",
            "Worker 8, [34/37]: Training Loss: 3.491433037, Training Accuracy: 15.616\n",
            "Worker 8, [35/37]: Training Loss: 3.353684666, Training Accuracy: 18.128\n",
            "Worker 8, [36/37]: Training Loss: 3.283479703, Training Accuracy: 19.008\n",
            "Worker 8, [37/37]: Training Loss: 3.178696338, Training Accuracy: 20.896\n",
            "Time taken for training worker 8: 0:01:38.025915\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000685\n",
            "Local Step 02: Test Loss: 3.352401021, Test Accuracy: 19.600\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.424983514, Training Accuracy: 18.064\n",
            "Worker 1, [02/37]: Training Loss: 3.229455026, Training Accuracy: 21.280\n",
            "Worker 1, [03/37]: Training Loss: 3.139876239, Training Accuracy: 22.192\n",
            "Worker 1, [04/37]: Training Loss: 3.031459134, Training Accuracy: 24.016\n",
            "Worker 1, [05/37]: Training Loss: 2.944960383, Training Accuracy: 25.584\n",
            "Worker 1, [06/37]: Training Loss: 2.880658432, Training Accuracy: 26.832\n",
            "Worker 1, [07/37]: Training Loss: 2.796314784, Training Accuracy: 28.160\n",
            "Worker 1, [08/37]: Training Loss: 2.713827520, Training Accuracy: 29.936\n",
            "Worker 1, [09/37]: Training Loss: 3.740370507, Training Accuracy: 13.296\n",
            "Worker 1, [10/37]: Training Loss: 3.508494158, Training Accuracy: 15.728\n",
            "Worker 1, [11/37]: Training Loss: 3.363565462, Training Accuracy: 18.064\n",
            "Worker 1, [12/37]: Training Loss: 3.244960225, Training Accuracy: 20.848\n",
            "Worker 1, [13/37]: Training Loss: 3.146094451, Training Accuracy: 22.448\n",
            "Worker 1, [14/37]: Training Loss: 3.081632612, Training Accuracy: 22.944\n",
            "Worker 1, [15/37]: Training Loss: 2.973706277, Training Accuracy: 25.040\n",
            "Worker 1, [16/37]: Training Loss: 2.882869492, Training Accuracy: 27.040\n",
            "Worker 1, [17/37]: Training Loss: 3.627727783, Training Accuracy: 14.576\n",
            "Worker 1, [18/37]: Training Loss: 3.357374612, Training Accuracy: 18.848\n",
            "Worker 1, [19/37]: Training Loss: 3.245572742, Training Accuracy: 20.416\n",
            "Worker 1, [20/37]: Training Loss: 3.115962887, Training Accuracy: 22.352\n",
            "Worker 1, [21/37]: Training Loss: 3.040045069, Training Accuracy: 24.336\n",
            "Worker 1, [22/37]: Training Loss: 2.936501338, Training Accuracy: 26.032\n",
            "Worker 1, [23/37]: Training Loss: 2.851715022, Training Accuracy: 27.904\n",
            "Worker 1, [24/37]: Training Loss: 2.796717014, Training Accuracy: 28.720\n",
            "Worker 1, [25/37]: Training Loss: 3.491978558, Training Accuracy: 18.816\n",
            "Worker 1, [26/37]: Training Loss: 3.258518956, Training Accuracy: 20.752\n",
            "Worker 1, [27/37]: Training Loss: 3.137430607, Training Accuracy: 22.832\n",
            "Worker 1, [28/37]: Training Loss: 3.072582267, Training Accuracy: 24.512\n",
            "Worker 1, [29/37]: Training Loss: 2.997041929, Training Accuracy: 25.024\n",
            "Worker 1, [30/37]: Training Loss: 2.932076160, Training Accuracy: 26.512\n",
            "Worker 1, [31/37]: Training Loss: 2.873544377, Training Accuracy: 28.224\n",
            "Worker 1, [32/37]: Training Loss: 2.833006299, Training Accuracy: 28.048\n",
            "Worker 1, [33/37]: Training Loss: 3.567494716, Training Accuracy: 21.904\n",
            "Worker 1, [34/37]: Training Loss: 3.316847341, Training Accuracy: 21.552\n",
            "Worker 1, [35/37]: Training Loss: 3.247410592, Training Accuracy: 22.480\n",
            "Worker 1, [36/37]: Training Loss: 3.222655043, Training Accuracy: 22.496\n",
            "Worker 1, [37/37]: Training Loss: 3.210923572, Training Accuracy: 23.040\n",
            "Time taken for training worker 1: 0:01:38.159301\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.621006949, Training Accuracy: 14.240\n",
            "Worker 2, [02/37]: Training Loss: 3.405699338, Training Accuracy: 17.280\n",
            "Worker 2, [03/37]: Training Loss: 3.263956766, Training Accuracy: 20.064\n",
            "Worker 2, [04/37]: Training Loss: 3.160805782, Training Accuracy: 21.456\n",
            "Worker 2, [05/37]: Training Loss: 3.049273167, Training Accuracy: 23.264\n",
            "Worker 2, [06/37]: Training Loss: 2.958265584, Training Accuracy: 25.104\n",
            "Worker 2, [07/37]: Training Loss: 2.884420624, Training Accuracy: 26.304\n",
            "Worker 2, [08/37]: Training Loss: 2.797894950, Training Accuracy: 28.016\n",
            "Worker 2, [09/37]: Training Loss: 3.604189841, Training Accuracy: 14.960\n",
            "Worker 2, [10/37]: Training Loss: 3.364347219, Training Accuracy: 18.048\n",
            "Worker 2, [11/37]: Training Loss: 3.223641111, Training Accuracy: 20.224\n",
            "Worker 2, [12/37]: Training Loss: 3.127364983, Training Accuracy: 21.408\n",
            "Worker 2, [13/37]: Training Loss: 2.998203613, Training Accuracy: 25.008\n",
            "Worker 2, [14/37]: Training Loss: 2.912616401, Training Accuracy: 25.584\n",
            "Worker 2, [15/37]: Training Loss: 2.829282430, Training Accuracy: 27.632\n",
            "Worker 2, [16/37]: Training Loss: 2.764478859, Training Accuracy: 29.072\n",
            "Worker 2, [17/37]: Training Loss: 3.453484331, Training Accuracy: 17.520\n",
            "Worker 2, [18/37]: Training Loss: 3.217785181, Training Accuracy: 20.400\n",
            "Worker 2, [19/37]: Training Loss: 3.082629858, Training Accuracy: 22.048\n",
            "Worker 2, [20/37]: Training Loss: 2.982252055, Training Accuracy: 25.184\n",
            "Worker 2, [21/37]: Training Loss: 2.880208110, Training Accuracy: 26.512\n",
            "Worker 2, [22/37]: Training Loss: 2.785812573, Training Accuracy: 28.464\n",
            "Worker 2, [23/37]: Training Loss: 2.705159735, Training Accuracy: 29.568\n",
            "Worker 2, [24/37]: Training Loss: 2.620195763, Training Accuracy: 31.744\n",
            "Worker 2, [25/37]: Training Loss: 3.332373483, Training Accuracy: 20.576\n",
            "Worker 2, [26/37]: Training Loss: 3.093188819, Training Accuracy: 23.968\n",
            "Worker 2, [27/37]: Training Loss: 2.968907441, Training Accuracy: 25.264\n",
            "Worker 2, [28/37]: Training Loss: 2.895723917, Training Accuracy: 27.088\n",
            "Worker 2, [29/37]: Training Loss: 2.827905954, Training Accuracy: 28.320\n",
            "Worker 2, [30/37]: Training Loss: 2.764733967, Training Accuracy: 29.248\n",
            "Worker 2, [31/37]: Training Loss: 2.708192404, Training Accuracy: 30.832\n",
            "Worker 2, [32/37]: Training Loss: 2.669500458, Training Accuracy: 31.152\n",
            "Worker 2, [33/37]: Training Loss: 3.400958699, Training Accuracy: 24.160\n",
            "Worker 2, [34/37]: Training Loss: 3.149097800, Training Accuracy: 23.760\n",
            "Worker 2, [35/37]: Training Loss: 3.074633467, Training Accuracy: 25.168\n",
            "Worker 2, [36/37]: Training Loss: 3.048398120, Training Accuracy: 25.232\n",
            "Worker 2, [37/37]: Training Loss: 3.038610587, Training Accuracy: 25.520\n",
            "Time taken for training worker 2: 0:01:38.757583\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.545786249, Training Accuracy: 15.504\n",
            "Worker 3, [02/37]: Training Loss: 3.372145490, Training Accuracy: 18.816\n",
            "Worker 3, [03/37]: Training Loss: 3.222547826, Training Accuracy: 21.760\n",
            "Worker 3, [04/37]: Training Loss: 3.126299128, Training Accuracy: 23.024\n",
            "Worker 3, [05/37]: Training Loss: 3.044881047, Training Accuracy: 24.176\n",
            "Worker 3, [06/37]: Training Loss: 2.944591890, Training Accuracy: 26.256\n",
            "Worker 3, [07/37]: Training Loss: 2.877602132, Training Accuracy: 27.232\n",
            "Worker 3, [08/37]: Training Loss: 2.763146838, Training Accuracy: 29.680\n",
            "Worker 3, [09/37]: Training Loss: 3.642173319, Training Accuracy: 14.960\n",
            "Worker 3, [10/37]: Training Loss: 3.379305324, Training Accuracy: 19.120\n",
            "Worker 3, [11/37]: Training Loss: 3.221935958, Training Accuracy: 20.784\n",
            "Worker 3, [12/37]: Training Loss: 3.131542649, Training Accuracy: 22.752\n",
            "Worker 3, [13/37]: Training Loss: 3.007293088, Training Accuracy: 24.960\n",
            "Worker 3, [14/37]: Training Loss: 2.935378262, Training Accuracy: 25.808\n",
            "Worker 3, [15/37]: Training Loss: 2.842051414, Training Accuracy: 27.984\n",
            "Worker 3, [16/37]: Training Loss: 2.759616862, Training Accuracy: 29.632\n",
            "Worker 3, [17/37]: Training Loss: 3.477468678, Training Accuracy: 18.016\n",
            "Worker 3, [18/37]: Training Loss: 3.219875927, Training Accuracy: 21.296\n",
            "Worker 3, [19/37]: Training Loss: 3.100918935, Training Accuracy: 23.888\n",
            "Worker 3, [20/37]: Training Loss: 2.990534396, Training Accuracy: 25.040\n",
            "Worker 3, [21/37]: Training Loss: 2.884909691, Training Accuracy: 27.248\n",
            "Worker 3, [22/37]: Training Loss: 2.809508713, Training Accuracy: 29.712\n",
            "Worker 3, [23/37]: Training Loss: 2.726772248, Training Accuracy: 30.480\n",
            "Worker 3, [24/37]: Training Loss: 2.644068248, Training Accuracy: 31.984\n",
            "Worker 3, [25/37]: Training Loss: 3.335336899, Training Accuracy: 20.672\n",
            "Worker 3, [26/37]: Training Loss: 3.106252218, Training Accuracy: 22.864\n",
            "Worker 3, [27/37]: Training Loss: 2.986327368, Training Accuracy: 26.336\n",
            "Worker 3, [28/37]: Training Loss: 2.920710780, Training Accuracy: 27.584\n",
            "Worker 3, [29/37]: Training Loss: 2.845217333, Training Accuracy: 28.448\n",
            "Worker 3, [30/37]: Training Loss: 2.793958048, Training Accuracy: 29.728\n",
            "Worker 3, [31/37]: Training Loss: 2.732504353, Training Accuracy: 30.912\n",
            "Worker 3, [32/37]: Training Loss: 2.679064014, Training Accuracy: 32.512\n",
            "Worker 3, [33/37]: Training Loss: 3.432365795, Training Accuracy: 24.880\n",
            "Worker 3, [34/37]: Training Loss: 3.164370471, Training Accuracy: 24.752\n",
            "Worker 3, [35/37]: Training Loss: 3.096491383, Training Accuracy: 25.104\n",
            "Worker 3, [36/37]: Training Loss: 3.079990808, Training Accuracy: 25.680\n",
            "Worker 3, [37/37]: Training Loss: 3.053395519, Training Accuracy: 25.808\n",
            "Time taken for training worker 3: 0:01:37.285514\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.551298776, Training Accuracy: 15.904\n",
            "Worker 4, [02/37]: Training Loss: 3.343193662, Training Accuracy: 18.912\n",
            "Worker 4, [03/37]: Training Loss: 3.186049963, Training Accuracy: 21.360\n",
            "Worker 4, [04/37]: Training Loss: 3.096523497, Training Accuracy: 23.344\n",
            "Worker 4, [05/37]: Training Loss: 3.022338646, Training Accuracy: 24.896\n",
            "Worker 4, [06/37]: Training Loss: 2.916084696, Training Accuracy: 25.520\n",
            "Worker 4, [07/37]: Training Loss: 2.814997741, Training Accuracy: 28.448\n",
            "Worker 4, [08/37]: Training Loss: 2.757222623, Training Accuracy: 28.256\n",
            "Worker 4, [09/37]: Training Loss: 3.633359870, Training Accuracy: 14.912\n",
            "Worker 4, [10/37]: Training Loss: 3.366304400, Training Accuracy: 18.608\n",
            "Worker 4, [11/37]: Training Loss: 3.243575313, Training Accuracy: 20.016\n",
            "Worker 4, [12/37]: Training Loss: 3.153474584, Training Accuracy: 21.456\n",
            "Worker 4, [13/37]: Training Loss: 3.015808504, Training Accuracy: 24.048\n",
            "Worker 4, [14/37]: Training Loss: 2.919789772, Training Accuracy: 26.544\n",
            "Worker 4, [15/37]: Training Loss: 2.832784915, Training Accuracy: 27.472\n",
            "Worker 4, [16/37]: Training Loss: 2.778948054, Training Accuracy: 29.488\n",
            "Worker 4, [17/37]: Training Loss: 3.463008795, Training Accuracy: 17.552\n",
            "Worker 4, [18/37]: Training Loss: 3.221239428, Training Accuracy: 21.120\n",
            "Worker 4, [19/37]: Training Loss: 3.092087809, Training Accuracy: 23.408\n",
            "Worker 4, [20/37]: Training Loss: 2.981548504, Training Accuracy: 24.928\n",
            "Worker 4, [21/37]: Training Loss: 2.860754181, Training Accuracy: 27.136\n",
            "Worker 4, [22/37]: Training Loss: 2.788016757, Training Accuracy: 28.240\n",
            "Worker 4, [23/37]: Training Loss: 2.711106502, Training Accuracy: 29.552\n",
            "Worker 4, [24/37]: Training Loss: 2.634155473, Training Accuracy: 31.920\n",
            "Worker 4, [25/37]: Training Loss: 3.337767141, Training Accuracy: 21.184\n",
            "Worker 4, [26/37]: Training Loss: 3.104787449, Training Accuracy: 23.536\n",
            "Worker 4, [27/37]: Training Loss: 2.976833198, Training Accuracy: 26.000\n",
            "Worker 4, [28/37]: Training Loss: 2.906955641, Training Accuracy: 27.392\n",
            "Worker 4, [29/37]: Training Loss: 2.821346125, Training Accuracy: 28.720\n",
            "Worker 4, [30/37]: Training Loss: 2.762923119, Training Accuracy: 29.216\n",
            "Worker 4, [31/37]: Training Loss: 2.713254274, Training Accuracy: 30.832\n",
            "Worker 4, [32/37]: Training Loss: 2.660369258, Training Accuracy: 31.584\n",
            "Worker 4, [33/37]: Training Loss: 3.445872523, Training Accuracy: 24.736\n",
            "Worker 4, [34/37]: Training Loss: 3.155410844, Training Accuracy: 24.832\n",
            "Worker 4, [35/37]: Training Loss: 3.095411670, Training Accuracy: 25.072\n",
            "Worker 4, [36/37]: Training Loss: 3.068625698, Training Accuracy: 25.776\n",
            "Worker 4, [37/37]: Training Loss: 3.051846052, Training Accuracy: 25.824\n",
            "Time taken for training worker 4: 0:01:38.414824\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.558433968, Training Accuracy: 15.792\n",
            "Worker 5, [02/37]: Training Loss: 3.361113334, Training Accuracy: 18.960\n",
            "Worker 5, [03/37]: Training Loss: 3.229806944, Training Accuracy: 20.000\n",
            "Worker 5, [04/37]: Training Loss: 3.132142347, Training Accuracy: 22.416\n",
            "Worker 5, [05/37]: Training Loss: 3.029500051, Training Accuracy: 23.328\n",
            "Worker 5, [06/37]: Training Loss: 2.925104129, Training Accuracy: 26.176\n",
            "Worker 5, [07/37]: Training Loss: 2.841110040, Training Accuracy: 27.600\n",
            "Worker 5, [08/37]: Training Loss: 2.724787532, Training Accuracy: 29.136\n",
            "Worker 5, [09/37]: Training Loss: 3.632934685, Training Accuracy: 15.200\n",
            "Worker 5, [10/37]: Training Loss: 3.366683184, Training Accuracy: 17.920\n",
            "Worker 5, [11/37]: Training Loss: 3.238734372, Training Accuracy: 20.608\n",
            "Worker 5, [12/37]: Training Loss: 3.109749154, Training Accuracy: 22.512\n",
            "Worker 5, [13/37]: Training Loss: 3.038363963, Training Accuracy: 23.456\n",
            "Worker 5, [14/37]: Training Loss: 2.936115012, Training Accuracy: 25.392\n",
            "Worker 5, [15/37]: Training Loss: 2.836849969, Training Accuracy: 27.520\n",
            "Worker 5, [16/37]: Training Loss: 2.744256686, Training Accuracy: 28.976\n",
            "Worker 5, [17/37]: Training Loss: 3.471766842, Training Accuracy: 17.792\n",
            "Worker 5, [18/37]: Training Loss: 3.223019848, Training Accuracy: 20.656\n",
            "Worker 5, [19/37]: Training Loss: 3.104323981, Training Accuracy: 22.896\n",
            "Worker 5, [20/37]: Training Loss: 2.999721904, Training Accuracy: 25.072\n",
            "Worker 5, [21/37]: Training Loss: 2.874752298, Training Accuracy: 26.912\n",
            "Worker 5, [22/37]: Training Loss: 2.794778970, Training Accuracy: 28.048\n",
            "Worker 5, [23/37]: Training Loss: 2.741810524, Training Accuracy: 29.440\n",
            "Worker 5, [24/37]: Training Loss: 2.625319325, Training Accuracy: 31.776\n",
            "Worker 5, [25/37]: Training Loss: 3.331119109, Training Accuracy: 21.184\n",
            "Worker 5, [26/37]: Training Loss: 3.106448125, Training Accuracy: 23.408\n",
            "Worker 5, [27/37]: Training Loss: 2.997797981, Training Accuracy: 24.864\n",
            "Worker 5, [28/37]: Training Loss: 2.905023239, Training Accuracy: 27.184\n",
            "Worker 5, [29/37]: Training Loss: 2.827132719, Training Accuracy: 28.928\n",
            "Worker 5, [30/37]: Training Loss: 2.788382119, Training Accuracy: 28.624\n",
            "Worker 5, [31/37]: Training Loss: 2.743393908, Training Accuracy: 29.952\n",
            "Worker 5, [32/37]: Training Loss: 2.662599836, Training Accuracy: 31.840\n",
            "Worker 5, [33/37]: Training Loss: 3.427148573, Training Accuracy: 24.160\n",
            "Worker 5, [34/37]: Training Loss: 3.154754770, Training Accuracy: 24.128\n",
            "Worker 5, [35/37]: Training Loss: 3.088729632, Training Accuracy: 24.272\n",
            "Worker 5, [36/37]: Training Loss: 3.072253215, Training Accuracy: 24.352\n",
            "Worker 5, [37/37]: Training Loss: 3.052498552, Training Accuracy: 24.688\n",
            "Time taken for training worker 5: 0:01:37.101680\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.516309994, Training Accuracy: 16.304\n",
            "Worker 6, [02/37]: Training Loss: 3.345541740, Training Accuracy: 19.168\n",
            "Worker 6, [03/37]: Training Loss: 3.238056604, Training Accuracy: 20.416\n",
            "Worker 6, [04/37]: Training Loss: 3.108479203, Training Accuracy: 23.200\n",
            "Worker 6, [05/37]: Training Loss: 3.016438158, Training Accuracy: 24.992\n",
            "Worker 6, [06/37]: Training Loss: 2.920307583, Training Accuracy: 26.416\n",
            "Worker 6, [07/37]: Training Loss: 2.849071899, Training Accuracy: 27.456\n",
            "Worker 6, [08/37]: Training Loss: 2.763037755, Training Accuracy: 29.200\n",
            "Worker 6, [09/37]: Training Loss: 3.625406387, Training Accuracy: 15.392\n",
            "Worker 6, [10/37]: Training Loss: 3.382557942, Training Accuracy: 17.696\n",
            "Worker 6, [11/37]: Training Loss: 3.246079854, Training Accuracy: 19.792\n",
            "Worker 6, [12/37]: Training Loss: 3.132437460, Training Accuracy: 21.968\n",
            "Worker 6, [13/37]: Training Loss: 3.036618435, Training Accuracy: 23.600\n",
            "Worker 6, [14/37]: Training Loss: 2.945623386, Training Accuracy: 26.368\n",
            "Worker 6, [15/37]: Training Loss: 2.840562448, Training Accuracy: 28.096\n",
            "Worker 6, [16/37]: Training Loss: 2.783257265, Training Accuracy: 28.528\n",
            "Worker 6, [17/37]: Training Loss: 3.478528684, Training Accuracy: 17.776\n",
            "Worker 6, [18/37]: Training Loss: 3.244852300, Training Accuracy: 20.944\n",
            "Worker 6, [19/37]: Training Loss: 3.116112322, Training Accuracy: 23.184\n",
            "Worker 6, [20/37]: Training Loss: 3.003137640, Training Accuracy: 24.512\n",
            "Worker 6, [21/37]: Training Loss: 2.905085955, Training Accuracy: 26.400\n",
            "Worker 6, [22/37]: Training Loss: 2.809122939, Training Accuracy: 28.832\n",
            "Worker 6, [23/37]: Training Loss: 2.755168973, Training Accuracy: 29.184\n",
            "Worker 6, [24/37]: Training Loss: 2.683004377, Training Accuracy: 30.752\n",
            "Worker 6, [25/37]: Training Loss: 3.364019975, Training Accuracy: 20.432\n",
            "Worker 6, [26/37]: Training Loss: 3.118816072, Training Accuracy: 22.768\n",
            "Worker 6, [27/37]: Training Loss: 3.000853585, Training Accuracy: 25.744\n",
            "Worker 6, [28/37]: Training Loss: 2.920718200, Training Accuracy: 26.976\n",
            "Worker 6, [29/37]: Training Loss: 2.852604968, Training Accuracy: 28.032\n",
            "Worker 6, [30/37]: Training Loss: 2.786460833, Training Accuracy: 29.264\n",
            "Worker 6, [31/37]: Training Loss: 2.746627477, Training Accuracy: 30.496\n",
            "Worker 6, [32/37]: Training Loss: 2.686948543, Training Accuracy: 31.840\n",
            "Worker 6, [33/37]: Training Loss: 3.444482455, Training Accuracy: 23.392\n",
            "Worker 6, [34/37]: Training Loss: 3.173107991, Training Accuracy: 23.600\n",
            "Worker 6, [35/37]: Training Loss: 3.115851288, Training Accuracy: 24.192\n",
            "Worker 6, [36/37]: Training Loss: 3.084978984, Training Accuracy: 24.528\n",
            "Worker 6, [37/37]: Training Loss: 3.067496319, Training Accuracy: 25.344\n",
            "Time taken for training worker 6: 0:01:38.348380\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.543041224, Training Accuracy: 15.344\n",
            "Worker 7, [02/37]: Training Loss: 3.364789912, Training Accuracy: 18.000\n",
            "Worker 7, [03/37]: Training Loss: 3.229078945, Training Accuracy: 20.464\n",
            "Worker 7, [04/37]: Training Loss: 3.092475526, Training Accuracy: 22.720\n",
            "Worker 7, [05/37]: Training Loss: 3.015727544, Training Accuracy: 24.832\n",
            "Worker 7, [06/37]: Training Loss: 2.956559008, Training Accuracy: 25.792\n",
            "Worker 7, [07/37]: Training Loss: 2.826956382, Training Accuracy: 27.856\n",
            "Worker 7, [08/37]: Training Loss: 2.747422381, Training Accuracy: 28.864\n",
            "Worker 7, [09/37]: Training Loss: 3.651892767, Training Accuracy: 13.760\n",
            "Worker 7, [10/37]: Training Loss: 3.380125274, Training Accuracy: 18.496\n",
            "Worker 7, [11/37]: Training Loss: 3.267578101, Training Accuracy: 19.296\n",
            "Worker 7, [12/37]: Training Loss: 3.130631070, Training Accuracy: 21.744\n",
            "Worker 7, [13/37]: Training Loss: 3.059920019, Training Accuracy: 22.720\n",
            "Worker 7, [14/37]: Training Loss: 2.955732801, Training Accuracy: 25.344\n",
            "Worker 7, [15/37]: Training Loss: 2.868946148, Training Accuracy: 27.344\n",
            "Worker 7, [16/37]: Training Loss: 2.792159784, Training Accuracy: 27.840\n",
            "Worker 7, [17/37]: Training Loss: 3.509323140, Training Accuracy: 16.736\n",
            "Worker 7, [18/37]: Training Loss: 3.258940057, Training Accuracy: 19.680\n",
            "Worker 7, [19/37]: Training Loss: 3.129320619, Training Accuracy: 22.016\n",
            "Worker 7, [20/37]: Training Loss: 3.004878120, Training Accuracy: 24.464\n",
            "Worker 7, [21/37]: Training Loss: 2.922391232, Training Accuracy: 26.032\n",
            "Worker 7, [22/37]: Training Loss: 2.832300322, Training Accuracy: 27.248\n",
            "Worker 7, [23/37]: Training Loss: 2.757606516, Training Accuracy: 28.608\n",
            "Worker 7, [24/37]: Training Loss: 2.684915440, Training Accuracy: 30.448\n",
            "Worker 7, [25/37]: Training Loss: 3.366287302, Training Accuracy: 20.176\n",
            "Worker 7, [26/37]: Training Loss: 3.130184373, Training Accuracy: 21.952\n",
            "Worker 7, [27/37]: Training Loss: 3.023622167, Training Accuracy: 24.576\n",
            "Worker 7, [28/37]: Training Loss: 2.941244724, Training Accuracy: 25.840\n",
            "Worker 7, [29/37]: Training Loss: 2.866850045, Training Accuracy: 27.744\n",
            "Worker 7, [30/37]: Training Loss: 2.813849138, Training Accuracy: 28.688\n",
            "Worker 7, [31/37]: Training Loss: 2.773428029, Training Accuracy: 29.408\n",
            "Worker 7, [32/37]: Training Loss: 2.717522823, Training Accuracy: 30.976\n",
            "Worker 7, [33/37]: Training Loss: 3.468435633, Training Accuracy: 23.184\n",
            "Worker 7, [34/37]: Training Loss: 3.201424088, Training Accuracy: 23.248\n",
            "Worker 7, [35/37]: Training Loss: 3.135343690, Training Accuracy: 23.696\n",
            "Worker 7, [36/37]: Training Loss: 3.118499617, Training Accuracy: 23.824\n",
            "Worker 7, [37/37]: Training Loss: 3.091804042, Training Accuracy: 24.448\n",
            "Time taken for training worker 7: 0:01:40.700113\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.553246595, Training Accuracy: 15.520\n",
            "Worker 8, [02/37]: Training Loss: 3.371533528, Training Accuracy: 17.952\n",
            "Worker 8, [03/37]: Training Loss: 3.207250023, Training Accuracy: 20.592\n",
            "Worker 8, [04/37]: Training Loss: 3.138564981, Training Accuracy: 21.424\n",
            "Worker 8, [05/37]: Training Loss: 3.063212701, Training Accuracy: 23.152\n",
            "Worker 8, [06/37]: Training Loss: 2.957735485, Training Accuracy: 25.152\n",
            "Worker 8, [07/37]: Training Loss: 2.883895353, Training Accuracy: 26.448\n",
            "Worker 8, [08/37]: Training Loss: 2.775492062, Training Accuracy: 29.104\n",
            "Worker 8, [09/37]: Training Loss: 3.670176151, Training Accuracy: 13.504\n",
            "Worker 8, [10/37]: Training Loss: 3.402919370, Training Accuracy: 17.120\n",
            "Worker 8, [11/37]: Training Loss: 3.245512415, Training Accuracy: 19.888\n",
            "Worker 8, [12/37]: Training Loss: 3.152655893, Training Accuracy: 21.840\n",
            "Worker 8, [13/37]: Training Loss: 3.043885676, Training Accuracy: 23.488\n",
            "Worker 8, [14/37]: Training Loss: 2.954632810, Training Accuracy: 25.344\n",
            "Worker 8, [15/37]: Training Loss: 2.857943948, Training Accuracy: 26.608\n",
            "Worker 8, [16/37]: Training Loss: 2.787320273, Training Accuracy: 27.936\n",
            "Worker 8, [17/37]: Training Loss: 3.496795691, Training Accuracy: 16.736\n",
            "Worker 8, [18/37]: Training Loss: 3.231963559, Training Accuracy: 20.224\n",
            "Worker 8, [19/37]: Training Loss: 3.093112323, Training Accuracy: 23.104\n",
            "Worker 8, [20/37]: Training Loss: 3.014600982, Training Accuracy: 24.192\n",
            "Worker 8, [21/37]: Training Loss: 2.910637347, Training Accuracy: 26.512\n",
            "Worker 8, [22/37]: Training Loss: 2.811204801, Training Accuracy: 28.560\n",
            "Worker 8, [23/37]: Training Loss: 2.734417893, Training Accuracy: 29.888\n",
            "Worker 8, [24/37]: Training Loss: 2.657413945, Training Accuracy: 30.544\n",
            "Worker 8, [25/37]: Training Loss: 3.382219490, Training Accuracy: 19.104\n",
            "Worker 8, [26/37]: Training Loss: 3.122155618, Training Accuracy: 22.496\n",
            "Worker 8, [27/37]: Training Loss: 3.008793692, Training Accuracy: 24.432\n",
            "Worker 8, [28/37]: Training Loss: 2.922094386, Training Accuracy: 26.560\n",
            "Worker 8, [29/37]: Training Loss: 2.872860028, Training Accuracy: 27.280\n",
            "Worker 8, [30/37]: Training Loss: 2.790837062, Training Accuracy: 28.720\n",
            "Worker 8, [31/37]: Training Loss: 2.739632371, Training Accuracy: 30.432\n",
            "Worker 8, [32/37]: Training Loss: 2.684617699, Training Accuracy: 31.600\n",
            "Worker 8, [33/37]: Training Loss: 3.448781948, Training Accuracy: 22.944\n",
            "Worker 8, [34/37]: Training Loss: 3.183068981, Training Accuracy: 23.328\n",
            "Worker 8, [35/37]: Training Loss: 3.124354813, Training Accuracy: 23.920\n",
            "Worker 8, [36/37]: Training Loss: 3.080918268, Training Accuracy: 24.496\n",
            "Worker 8, [37/37]: Training Loss: 3.069570836, Training Accuracy: 24.528\n",
            "Time taken for training worker 8: 0:01:39.877954\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000705\n",
            "Local Step 03: Test Loss: 3.235627987, Test Accuracy: 22.690\n",
            "**************************************************\n",
            "Worker 1, [01/37]: Training Loss: 3.345579619, Training Accuracy: 20.144\n",
            "Worker 1, [02/37]: Training Loss: 3.345091980, Training Accuracy: 20.112\n",
            "Worker 1, [03/37]: Training Loss: 3.342427852, Training Accuracy: 20.736\n",
            "Worker 1, [04/37]: Training Loss: 3.318379390, Training Accuracy: 21.344\n",
            "Worker 1, [05/37]: Training Loss: 3.300554881, Training Accuracy: 21.552\n",
            "Worker 1, [06/37]: Training Loss: 3.261174136, Training Accuracy: 22.192\n",
            "Worker 1, [07/37]: Training Loss: 3.233711705, Training Accuracy: 21.936\n",
            "Worker 1, [08/37]: Training Loss: 3.218323352, Training Accuracy: 22.432\n",
            "Worker 1, [09/37]: Training Loss: 3.419692901, Training Accuracy: 20.704\n",
            "Worker 1, [10/37]: Training Loss: 3.237435467, Training Accuracy: 21.296\n",
            "Worker 1, [11/37]: Training Loss: 3.170394284, Training Accuracy: 21.824\n",
            "Worker 1, [12/37]: Training Loss: 3.121216935, Training Accuracy: 23.328\n",
            "Worker 1, [13/37]: Training Loss: 3.087069397, Training Accuracy: 23.744\n",
            "Worker 1, [14/37]: Training Loss: 3.032270777, Training Accuracy: 24.736\n",
            "Worker 1, [15/37]: Training Loss: 3.008609930, Training Accuracy: 24.464\n",
            "Worker 1, [16/37]: Training Loss: 2.984047673, Training Accuracy: 25.888\n",
            "Worker 1, [17/37]: Training Loss: 3.344463183, Training Accuracy: 19.632\n",
            "Worker 1, [18/37]: Training Loss: 3.197590473, Training Accuracy: 21.088\n",
            "Worker 1, [19/37]: Training Loss: 3.120494188, Training Accuracy: 22.704\n",
            "Worker 1, [20/37]: Training Loss: 3.074637150, Training Accuracy: 23.488\n",
            "Worker 1, [21/37]: Training Loss: 2.988899399, Training Accuracy: 24.736\n",
            "Worker 1, [22/37]: Training Loss: 2.941998547, Training Accuracy: 26.080\n",
            "Worker 1, [23/37]: Training Loss: 2.885985197, Training Accuracy: 26.736\n",
            "Worker 1, [24/37]: Training Loss: 2.846754831, Training Accuracy: 27.632\n",
            "Worker 1, [25/37]: Training Loss: 3.341975263, Training Accuracy: 19.296\n",
            "Worker 1, [26/37]: Training Loss: 3.177161810, Training Accuracy: 22.016\n",
            "Worker 1, [27/37]: Training Loss: 3.090079035, Training Accuracy: 22.768\n",
            "Worker 1, [28/37]: Training Loss: 3.004164625, Training Accuracy: 23.936\n",
            "Worker 1, [29/37]: Training Loss: 2.956543774, Training Accuracy: 25.488\n",
            "Worker 1, [30/37]: Training Loss: 2.850981004, Training Accuracy: 28.128\n",
            "Worker 1, [31/37]: Training Loss: 2.794484593, Training Accuracy: 28.784\n",
            "Worker 1, [32/37]: Training Loss: 2.734931381, Training Accuracy: 29.984\n",
            "Worker 1, [33/37]: Training Loss: 3.289440007, Training Accuracy: 19.824\n",
            "Worker 1, [34/37]: Training Loss: 3.150931203, Training Accuracy: 22.112\n",
            "Worker 1, [35/37]: Training Loss: 3.030995031, Training Accuracy: 24.544\n",
            "Worker 1, [36/37]: Training Loss: 2.944526896, Training Accuracy: 25.168\n",
            "Worker 1, [37/37]: Training Loss: 2.856365053, Training Accuracy: 26.384\n",
            "Time taken for training worker 1: 0:01:37.003613\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/37]: Training Loss: 3.335030548, Training Accuracy: 20.816\n",
            "Worker 2, [02/37]: Training Loss: 3.280940837, Training Accuracy: 21.760\n",
            "Worker 2, [03/37]: Training Loss: 3.182609329, Training Accuracy: 23.216\n",
            "Worker 2, [04/37]: Training Loss: 3.111398449, Training Accuracy: 23.616\n",
            "Worker 2, [05/37]: Training Loss: 3.050666748, Training Accuracy: 24.752\n",
            "Worker 2, [06/37]: Training Loss: 2.993528410, Training Accuracy: 25.760\n",
            "Worker 2, [07/37]: Training Loss: 2.945502955, Training Accuracy: 27.248\n",
            "Worker 2, [08/37]: Training Loss: 2.897738430, Training Accuracy: 28.016\n",
            "Worker 2, [09/37]: Training Loss: 3.221888934, Training Accuracy: 24.480\n",
            "Worker 2, [10/37]: Training Loss: 3.025501643, Training Accuracy: 24.816\n",
            "Worker 2, [11/37]: Training Loss: 2.949647473, Training Accuracy: 26.000\n",
            "Worker 2, [12/37]: Training Loss: 2.920009990, Training Accuracy: 26.672\n",
            "Worker 2, [13/37]: Training Loss: 2.868522848, Training Accuracy: 27.008\n",
            "Worker 2, [14/37]: Training Loss: 2.861011770, Training Accuracy: 27.136\n",
            "Worker 2, [15/37]: Training Loss: 2.810793154, Training Accuracy: 28.096\n",
            "Worker 2, [16/37]: Training Loss: 2.789561148, Training Accuracy: 28.496\n",
            "Worker 2, [17/37]: Training Loss: 3.155755080, Training Accuracy: 23.056\n",
            "Worker 2, [18/37]: Training Loss: 3.027977486, Training Accuracy: 24.624\n",
            "Worker 2, [19/37]: Training Loss: 2.945704630, Training Accuracy: 25.728\n",
            "Worker 2, [20/37]: Training Loss: 2.858003225, Training Accuracy: 26.320\n",
            "Worker 2, [21/37]: Training Loss: 2.814013226, Training Accuracy: 27.760\n",
            "Worker 2, [22/37]: Training Loss: 2.784985805, Training Accuracy: 28.016\n",
            "Worker 2, [23/37]: Training Loss: 2.723186194, Training Accuracy: 29.840\n",
            "Worker 2, [24/37]: Training Loss: 2.687551910, Training Accuracy: 29.952\n",
            "Worker 2, [25/37]: Training Loss: 3.180827732, Training Accuracy: 21.536\n",
            "Worker 2, [26/37]: Training Loss: 3.034346157, Training Accuracy: 23.088\n",
            "Worker 2, [27/37]: Training Loss: 2.970585684, Training Accuracy: 24.624\n",
            "Worker 2, [28/37]: Training Loss: 2.852003596, Training Accuracy: 27.424\n",
            "Worker 2, [29/37]: Training Loss: 2.814573295, Training Accuracy: 27.568\n",
            "Worker 2, [30/37]: Training Loss: 2.696923229, Training Accuracy: 29.648\n",
            "Worker 2, [31/37]: Training Loss: 2.658663543, Training Accuracy: 31.424\n",
            "Worker 2, [32/37]: Training Loss: 2.625583498, Training Accuracy: 31.504\n",
            "Worker 2, [33/37]: Training Loss: 3.144429258, Training Accuracy: 22.064\n",
            "Worker 2, [34/37]: Training Loss: 3.031957113, Training Accuracy: 23.568\n",
            "Worker 2, [35/37]: Training Loss: 2.887283009, Training Accuracy: 26.160\n",
            "Worker 2, [36/37]: Training Loss: 2.837775642, Training Accuracy: 27.232\n",
            "Worker 2, [37/37]: Training Loss: 2.709757316, Training Accuracy: 29.472\n",
            "Time taken for training worker 2: 0:01:39.412292\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/37]: Training Loss: 3.281907563, Training Accuracy: 22.192\n",
            "Worker 3, [02/37]: Training Loss: 3.268388376, Training Accuracy: 22.320\n",
            "Worker 3, [03/37]: Training Loss: 3.184139042, Training Accuracy: 23.040\n",
            "Worker 3, [04/37]: Training Loss: 3.104971998, Training Accuracy: 24.816\n",
            "Worker 3, [05/37]: Training Loss: 3.046488832, Training Accuracy: 26.288\n",
            "Worker 3, [06/37]: Training Loss: 2.980959656, Training Accuracy: 26.928\n",
            "Worker 3, [07/37]: Training Loss: 2.923857891, Training Accuracy: 27.632\n",
            "Worker 3, [08/37]: Training Loss: 2.867381784, Training Accuracy: 29.024\n",
            "Worker 3, [09/37]: Training Loss: 3.229919660, Training Accuracy: 24.704\n",
            "Worker 3, [10/37]: Training Loss: 3.043400764, Training Accuracy: 24.896\n",
            "Worker 3, [11/37]: Training Loss: 2.976295379, Training Accuracy: 25.920\n",
            "Worker 3, [12/37]: Training Loss: 2.915600891, Training Accuracy: 27.408\n",
            "Worker 3, [13/37]: Training Loss: 2.887468117, Training Accuracy: 27.616\n",
            "Worker 3, [14/37]: Training Loss: 2.874221850, Training Accuracy: 27.024\n",
            "Worker 3, [15/37]: Training Loss: 2.813525786, Training Accuracy: 28.464\n",
            "Worker 3, [16/37]: Training Loss: 2.806883333, Training Accuracy: 28.128\n",
            "Worker 3, [17/37]: Training Loss: 3.161032312, Training Accuracy: 23.712\n",
            "Worker 3, [18/37]: Training Loss: 3.017665895, Training Accuracy: 25.344\n",
            "Worker 3, [19/37]: Training Loss: 2.950403294, Training Accuracy: 26.416\n",
            "Worker 3, [20/37]: Training Loss: 2.863599500, Training Accuracy: 27.680\n",
            "Worker 3, [21/37]: Training Loss: 2.817489850, Training Accuracy: 27.744\n",
            "Worker 3, [22/37]: Training Loss: 2.777253689, Training Accuracy: 28.720\n",
            "Worker 3, [23/37]: Training Loss: 2.747981582, Training Accuracy: 29.504\n",
            "Worker 3, [24/37]: Training Loss: 2.676678808, Training Accuracy: 30.688\n",
            "Worker 3, [25/37]: Training Loss: 3.149563373, Training Accuracy: 22.992\n",
            "Worker 3, [26/37]: Training Loss: 3.025532343, Training Accuracy: 24.240\n",
            "Worker 3, [27/37]: Training Loss: 2.946153940, Training Accuracy: 26.016\n",
            "Worker 3, [28/37]: Training Loss: 2.832846534, Training Accuracy: 27.856\n",
            "Worker 3, [29/37]: Training Loss: 2.786786040, Training Accuracy: 28.848\n",
            "Worker 3, [30/37]: Training Loss: 2.745382871, Training Accuracy: 30.032\n",
            "Worker 3, [31/37]: Training Loss: 2.653840136, Training Accuracy: 31.104\n",
            "Worker 3, [32/37]: Training Loss: 2.611155746, Training Accuracy: 32.128\n",
            "Worker 3, [33/37]: Training Loss: 3.173421276, Training Accuracy: 22.432\n",
            "Worker 3, [34/37]: Training Loss: 2.982618395, Training Accuracy: 25.008\n",
            "Worker 3, [35/37]: Training Loss: 2.877412575, Training Accuracy: 27.664\n",
            "Worker 3, [36/37]: Training Loss: 2.832222817, Training Accuracy: 27.328\n",
            "Worker 3, [37/37]: Training Loss: 2.715173977, Training Accuracy: 29.456\n",
            "Time taken for training worker 3: 0:01:38.672778\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/37]: Training Loss: 3.258210019, Training Accuracy: 21.744\n",
            "Worker 4, [02/37]: Training Loss: 3.232319744, Training Accuracy: 22.352\n",
            "Worker 4, [03/37]: Training Loss: 3.160190816, Training Accuracy: 22.592\n",
            "Worker 4, [04/37]: Training Loss: 3.066421431, Training Accuracy: 25.040\n",
            "Worker 4, [05/37]: Training Loss: 3.006820861, Training Accuracy: 26.080\n",
            "Worker 4, [06/37]: Training Loss: 2.942072306, Training Accuracy: 27.216\n",
            "Worker 4, [07/37]: Training Loss: 2.898408204, Training Accuracy: 27.824\n",
            "Worker 4, [08/37]: Training Loss: 2.844828876, Training Accuracy: 28.736\n",
            "Worker 4, [09/37]: Training Loss: 3.236832804, Training Accuracy: 25.232\n",
            "Worker 4, [10/37]: Training Loss: 3.022981084, Training Accuracy: 25.168\n",
            "Worker 4, [11/37]: Training Loss: 2.945610489, Training Accuracy: 26.912\n",
            "Worker 4, [12/37]: Training Loss: 2.904660454, Training Accuracy: 27.104\n",
            "Worker 4, [13/37]: Training Loss: 2.869046798, Training Accuracy: 27.680\n",
            "Worker 4, [14/37]: Training Loss: 2.832900711, Training Accuracy: 27.664\n",
            "Worker 4, [15/37]: Training Loss: 2.811908666, Training Accuracy: 28.688\n",
            "Worker 4, [16/37]: Training Loss: 2.762540474, Training Accuracy: 28.720\n",
            "Worker 4, [17/37]: Training Loss: 3.145483696, Training Accuracy: 23.456\n",
            "Worker 4, [18/37]: Training Loss: 3.018306340, Training Accuracy: 24.208\n",
            "Worker 4, [19/37]: Training Loss: 2.935163121, Training Accuracy: 25.472\n",
            "Worker 4, [20/37]: Training Loss: 2.865076982, Training Accuracy: 26.832\n",
            "Worker 4, [21/37]: Training Loss: 2.833093556, Training Accuracy: 27.424\n",
            "Worker 4, [22/37]: Training Loss: 2.777176565, Training Accuracy: 28.624\n",
            "Worker 4, [23/37]: Training Loss: 2.740448331, Training Accuracy: 29.888\n",
            "Worker 4, [24/37]: Training Loss: 2.659038179, Training Accuracy: 29.872\n",
            "Worker 4, [25/37]: Training Loss: 3.180357519, Training Accuracy: 22.128\n",
            "Worker 4, [26/37]: Training Loss: 3.046570892, Training Accuracy: 24.112\n",
            "Worker 4, [27/37]: Training Loss: 2.915006139, Training Accuracy: 26.176\n",
            "Worker 4, [28/37]: Training Loss: 2.877768565, Training Accuracy: 26.112\n",
            "Worker 4, [29/37]: Training Loss: 2.764808998, Training Accuracy: 29.232\n",
            "Worker 4, [30/37]: Training Loss: 2.713092726, Training Accuracy: 29.920\n",
            "Worker 4, [31/37]: Training Loss: 2.661994331, Training Accuracy: 30.928\n",
            "Worker 4, [32/37]: Training Loss: 2.576207010, Training Accuracy: 32.480\n",
            "Worker 4, [33/37]: Training Loss: 3.129015944, Training Accuracy: 23.008\n",
            "Worker 4, [34/37]: Training Loss: 2.971947434, Training Accuracy: 25.232\n",
            "Worker 4, [35/37]: Training Loss: 2.879894896, Training Accuracy: 27.152\n",
            "Worker 4, [36/37]: Training Loss: 2.771210649, Training Accuracy: 29.232\n",
            "Worker 4, [37/37]: Training Loss: 2.690981950, Training Accuracy: 30.304\n",
            "Time taken for training worker 4: 0:01:38.617324\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/37]: Training Loss: 3.197000375, Training Accuracy: 22.688\n",
            "Worker 5, [02/37]: Training Loss: 3.163509824, Training Accuracy: 23.408\n",
            "Worker 5, [03/37]: Training Loss: 3.129175395, Training Accuracy: 23.744\n",
            "Worker 5, [04/37]: Training Loss: 3.061353005, Training Accuracy: 24.624\n",
            "Worker 5, [05/37]: Training Loss: 2.996794642, Training Accuracy: 26.448\n",
            "Worker 5, [06/37]: Training Loss: 2.954238673, Training Accuracy: 26.736\n",
            "Worker 5, [07/37]: Training Loss: 2.892281017, Training Accuracy: 28.256\n",
            "Worker 5, [08/37]: Training Loss: 2.851129707, Training Accuracy: 29.280\n",
            "Worker 5, [09/37]: Training Loss: 3.222659045, Training Accuracy: 24.976\n",
            "Worker 5, [10/37]: Training Loss: 3.039137424, Training Accuracy: 24.832\n",
            "Worker 5, [11/37]: Training Loss: 2.951879803, Training Accuracy: 25.904\n",
            "Worker 5, [12/37]: Training Loss: 2.920390088, Training Accuracy: 26.864\n",
            "Worker 5, [13/37]: Training Loss: 2.878765335, Training Accuracy: 26.848\n",
            "Worker 5, [14/37]: Training Loss: 2.849997209, Training Accuracy: 27.200\n",
            "Worker 5, [15/37]: Training Loss: 2.809317465, Training Accuracy: 28.192\n",
            "Worker 5, [16/37]: Training Loss: 2.777447263, Training Accuracy: 28.720\n",
            "Worker 5, [17/37]: Training Loss: 3.160548028, Training Accuracy: 23.184\n",
            "Worker 5, [18/37]: Training Loss: 3.012007677, Training Accuracy: 24.400\n",
            "Worker 5, [19/37]: Training Loss: 2.932050980, Training Accuracy: 27.008\n",
            "Worker 5, [20/37]: Training Loss: 2.875258752, Training Accuracy: 26.752\n",
            "Worker 5, [21/37]: Training Loss: 2.806107073, Training Accuracy: 28.208\n",
            "Worker 5, [22/37]: Training Loss: 2.778356606, Training Accuracy: 28.640\n",
            "Worker 5, [23/37]: Training Loss: 2.724251139, Training Accuracy: 29.520\n",
            "Worker 5, [24/37]: Training Loss: 2.698408706, Training Accuracy: 30.432\n",
            "Worker 5, [25/37]: Training Loss: 3.156817692, Training Accuracy: 23.152\n",
            "Worker 5, [26/37]: Training Loss: 3.005134787, Training Accuracy: 24.336\n",
            "Worker 5, [27/37]: Training Loss: 2.962044650, Training Accuracy: 25.056\n",
            "Worker 5, [28/37]: Training Loss: 2.863408673, Training Accuracy: 26.960\n",
            "Worker 5, [29/37]: Training Loss: 2.757451006, Training Accuracy: 29.264\n",
            "Worker 5, [30/37]: Training Loss: 2.716739878, Training Accuracy: 30.256\n",
            "Worker 5, [31/37]: Training Loss: 2.664413535, Training Accuracy: 31.520\n",
            "Worker 5, [32/37]: Training Loss: 2.594919888, Training Accuracy: 32.880\n",
            "Worker 5, [33/37]: Training Loss: 3.142457281, Training Accuracy: 22.288\n",
            "Worker 5, [34/37]: Training Loss: 2.993559487, Training Accuracy: 24.352\n",
            "Worker 5, [35/37]: Training Loss: 2.901944710, Training Accuracy: 26.832\n",
            "Worker 5, [36/37]: Training Loss: 2.800969679, Training Accuracy: 28.736\n",
            "Worker 5, [37/37]: Training Loss: 2.724745269, Training Accuracy: 30.336\n",
            "Time taken for training worker 5: 0:01:37.029457\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/37]: Training Loss: 3.246254337, Training Accuracy: 21.440\n",
            "Worker 6, [02/37]: Training Loss: 3.227632931, Training Accuracy: 22.240\n",
            "Worker 6, [03/37]: Training Loss: 3.154102766, Training Accuracy: 22.896\n",
            "Worker 6, [04/37]: Training Loss: 3.086217545, Training Accuracy: 25.248\n",
            "Worker 6, [05/37]: Training Loss: 3.007699047, Training Accuracy: 26.768\n",
            "Worker 6, [06/37]: Training Loss: 2.956111891, Training Accuracy: 27.776\n",
            "Worker 6, [07/37]: Training Loss: 2.910703027, Training Accuracy: 28.560\n",
            "Worker 6, [08/37]: Training Loss: 2.846122713, Training Accuracy: 29.248\n",
            "Worker 6, [09/37]: Training Loss: 3.240570261, Training Accuracy: 24.160\n",
            "Worker 6, [10/37]: Training Loss: 3.034416026, Training Accuracy: 25.056\n",
            "Worker 6, [11/37]: Training Loss: 2.986102189, Training Accuracy: 26.128\n",
            "Worker 6, [12/37]: Training Loss: 2.918055371, Training Accuracy: 26.640\n",
            "Worker 6, [13/37]: Training Loss: 2.888503442, Training Accuracy: 26.816\n",
            "Worker 6, [14/37]: Training Loss: 2.848614123, Training Accuracy: 27.792\n",
            "Worker 6, [15/37]: Training Loss: 2.837712626, Training Accuracy: 28.128\n",
            "Worker 6, [16/37]: Training Loss: 2.770086125, Training Accuracy: 29.264\n",
            "Worker 6, [17/37]: Training Loss: 3.163606315, Training Accuracy: 21.888\n",
            "Worker 6, [18/37]: Training Loss: 3.031872727, Training Accuracy: 23.472\n",
            "Worker 6, [19/37]: Training Loss: 2.945411412, Training Accuracy: 25.472\n",
            "Worker 6, [20/37]: Training Loss: 2.898355486, Training Accuracy: 26.448\n",
            "Worker 6, [21/37]: Training Loss: 2.835730173, Training Accuracy: 27.456\n",
            "Worker 6, [22/37]: Training Loss: 2.772406194, Training Accuracy: 28.944\n",
            "Worker 6, [23/37]: Training Loss: 2.749942269, Training Accuracy: 29.296\n",
            "Worker 6, [24/37]: Training Loss: 2.671457568, Training Accuracy: 31.440\n",
            "Worker 6, [25/37]: Training Loss: 3.182179826, Training Accuracy: 21.328\n",
            "Worker 6, [26/37]: Training Loss: 3.035918997, Training Accuracy: 23.152\n",
            "Worker 6, [27/37]: Training Loss: 2.959512226, Training Accuracy: 25.408\n",
            "Worker 6, [28/37]: Training Loss: 2.878826268, Training Accuracy: 26.448\n",
            "Worker 6, [29/37]: Training Loss: 2.816029089, Training Accuracy: 27.744\n",
            "Worker 6, [30/37]: Training Loss: 2.757331980, Training Accuracy: 29.504\n",
            "Worker 6, [31/37]: Training Loss: 2.692785789, Training Accuracy: 30.352\n",
            "Worker 6, [32/37]: Training Loss: 2.602822433, Training Accuracy: 31.440\n",
            "Worker 6, [33/37]: Training Loss: 3.156761308, Training Accuracy: 22.288\n",
            "Worker 6, [34/37]: Training Loss: 3.021651755, Training Accuracy: 24.240\n",
            "Worker 6, [35/37]: Training Loss: 2.897703898, Training Accuracy: 26.544\n",
            "Worker 6, [36/37]: Training Loss: 2.838072490, Training Accuracy: 27.472\n",
            "Worker 6, [37/37]: Training Loss: 2.722765791, Training Accuracy: 30.192\n",
            "Time taken for training worker 6: 0:01:38.623292\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/37]: Training Loss: 3.222338847, Training Accuracy: 22.768\n",
            "Worker 7, [02/37]: Training Loss: 3.204710126, Training Accuracy: 23.392\n",
            "Worker 7, [03/37]: Training Loss: 3.140310003, Training Accuracy: 24.720\n",
            "Worker 7, [04/37]: Training Loss: 3.062343590, Training Accuracy: 25.584\n",
            "Worker 7, [05/37]: Training Loss: 3.009639480, Training Accuracy: 26.448\n",
            "Worker 7, [06/37]: Training Loss: 2.962346899, Training Accuracy: 26.768\n",
            "Worker 7, [07/37]: Training Loss: 2.909975952, Training Accuracy: 27.776\n",
            "Worker 7, [08/37]: Training Loss: 2.865455382, Training Accuracy: 28.576\n",
            "Worker 7, [09/37]: Training Loss: 3.274765178, Training Accuracy: 23.264\n",
            "Worker 7, [10/37]: Training Loss: 3.046269519, Training Accuracy: 23.584\n",
            "Worker 7, [11/37]: Training Loss: 2.988279688, Training Accuracy: 24.864\n",
            "Worker 7, [12/37]: Training Loss: 2.939671767, Training Accuracy: 25.584\n",
            "Worker 7, [13/37]: Training Loss: 2.923676462, Training Accuracy: 25.696\n",
            "Worker 7, [14/37]: Training Loss: 2.877535367, Training Accuracy: 27.456\n",
            "Worker 7, [15/37]: Training Loss: 2.848612394, Training Accuracy: 27.296\n",
            "Worker 7, [16/37]: Training Loss: 2.802072474, Training Accuracy: 28.752\n",
            "Worker 7, [17/37]: Training Loss: 3.196511191, Training Accuracy: 21.568\n",
            "Worker 7, [18/37]: Training Loss: 3.050396742, Training Accuracy: 23.504\n",
            "Worker 7, [19/37]: Training Loss: 2.959330678, Training Accuracy: 25.616\n",
            "Worker 7, [20/37]: Training Loss: 2.911239001, Training Accuracy: 26.864\n",
            "Worker 7, [21/37]: Training Loss: 2.874569881, Training Accuracy: 26.720\n",
            "Worker 7, [22/37]: Training Loss: 2.830737087, Training Accuracy: 27.136\n",
            "Worker 7, [23/37]: Training Loss: 2.763714771, Training Accuracy: 28.624\n",
            "Worker 7, [24/37]: Training Loss: 2.681945718, Training Accuracy: 30.368\n",
            "Worker 7, [25/37]: Training Loss: 3.208735461, Training Accuracy: 20.384\n",
            "Worker 7, [26/37]: Training Loss: 3.051444954, Training Accuracy: 23.488\n",
            "Worker 7, [27/37]: Training Loss: 2.971804699, Training Accuracy: 24.336\n",
            "Worker 7, [28/37]: Training Loss: 2.916915217, Training Accuracy: 26.256\n",
            "Worker 7, [29/37]: Training Loss: 2.787907948, Training Accuracy: 28.512\n",
            "Worker 7, [30/37]: Training Loss: 2.742292689, Training Accuracy: 29.024\n",
            "Worker 7, [31/37]: Training Loss: 2.694658362, Training Accuracy: 29.584\n",
            "Worker 7, [32/37]: Training Loss: 2.651767339, Training Accuracy: 31.216\n",
            "Worker 7, [33/37]: Training Loss: 3.193557287, Training Accuracy: 21.680\n",
            "Worker 7, [34/37]: Training Loss: 3.021620023, Training Accuracy: 24.096\n",
            "Worker 7, [35/37]: Training Loss: 2.907630655, Training Accuracy: 26.272\n",
            "Worker 7, [36/37]: Training Loss: 2.842647085, Training Accuracy: 27.520\n",
            "Worker 7, [37/37]: Training Loss: 2.726739195, Training Accuracy: 29.424\n",
            "Time taken for training worker 7: 0:01:37.586651\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/37]: Training Loss: 3.244085224, Training Accuracy: 22.432\n",
            "Worker 8, [02/37]: Training Loss: 3.197714981, Training Accuracy: 22.448\n",
            "Worker 8, [03/37]: Training Loss: 3.126089938, Training Accuracy: 23.760\n",
            "Worker 8, [04/37]: Training Loss: 3.062557629, Training Accuracy: 25.312\n",
            "Worker 8, [05/37]: Training Loss: 3.012004366, Training Accuracy: 25.648\n",
            "Worker 8, [06/37]: Training Loss: 2.963497921, Training Accuracy: 26.128\n",
            "Worker 8, [07/37]: Training Loss: 2.907127969, Training Accuracy: 28.208\n",
            "Worker 8, [08/37]: Training Loss: 2.862711838, Training Accuracy: 28.576\n",
            "Worker 8, [09/37]: Training Loss: 3.249772729, Training Accuracy: 23.904\n",
            "Worker 8, [10/37]: Training Loss: 3.050360643, Training Accuracy: 23.984\n",
            "Worker 8, [11/37]: Training Loss: 2.994574406, Training Accuracy: 25.536\n",
            "Worker 8, [12/37]: Training Loss: 2.918526350, Training Accuracy: 25.744\n",
            "Worker 8, [13/37]: Training Loss: 2.918889574, Training Accuracy: 26.208\n",
            "Worker 8, [14/37]: Training Loss: 2.874402100, Training Accuracy: 27.088\n",
            "Worker 8, [15/37]: Training Loss: 2.842241114, Training Accuracy: 27.568\n",
            "Worker 8, [16/37]: Training Loss: 2.811022700, Training Accuracy: 27.600\n",
            "Worker 8, [17/37]: Training Loss: 3.167586322, Training Accuracy: 22.960\n",
            "Worker 8, [18/37]: Training Loss: 3.034417882, Training Accuracy: 24.048\n",
            "Worker 8, [19/37]: Training Loss: 2.952695997, Training Accuracy: 25.024\n",
            "Worker 8, [20/37]: Training Loss: 2.897696967, Training Accuracy: 26.384\n",
            "Worker 8, [21/37]: Training Loss: 2.847158009, Training Accuracy: 27.776\n",
            "Worker 8, [22/37]: Training Loss: 2.791651300, Training Accuracy: 28.304\n",
            "Worker 8, [23/37]: Training Loss: 2.759456298, Training Accuracy: 28.240\n",
            "Worker 8, [24/37]: Training Loss: 2.711863754, Training Accuracy: 29.520\n",
            "Worker 8, [25/37]: Training Loss: 3.203386949, Training Accuracy: 21.744\n",
            "Worker 8, [26/37]: Training Loss: 3.038773420, Training Accuracy: 23.632\n",
            "Worker 8, [27/37]: Training Loss: 2.932079524, Training Accuracy: 25.440\n",
            "Worker 8, [28/37]: Training Loss: 2.875764338, Training Accuracy: 25.936\n",
            "Worker 8, [29/37]: Training Loss: 2.811921239, Training Accuracy: 28.544\n",
            "Worker 8, [30/37]: Training Loss: 2.775867608, Training Accuracy: 28.128\n",
            "Worker 8, [31/37]: Training Loss: 2.684819307, Training Accuracy: 30.176\n",
            "Worker 8, [32/37]: Training Loss: 2.632395666, Training Accuracy: 31.664\n",
            "Worker 8, [33/37]: Training Loss: 3.172770615, Training Accuracy: 21.280\n",
            "Worker 8, [34/37]: Training Loss: 3.034547716, Training Accuracy: 23.856\n",
            "Worker 8, [35/37]: Training Loss: 2.919433910, Training Accuracy: 25.952\n",
            "Worker 8, [36/37]: Training Loss: 2.841818822, Training Accuracy: 26.608\n",
            "Worker 8, [37/37]: Training Loss: 2.760560143, Training Accuracy: 28.256\n",
            "Time taken for training worker 8: 0:01:37.747951\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000647\n",
            "Local Step 04: Test Loss: 3.130159062, Test Accuracy: 24.290\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:52:31.035522\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8, Update Slow Model every 2 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.592582576, Training Accuracy: 1.616\n",
            "Worker 1, [02/18]: Training Loss: 4.462799136, Training Accuracy: 3.152\n",
            "Worker 1, [03/18]: Training Loss: 4.555783739, Training Accuracy: 2.384\n",
            "Worker 1, [04/18]: Training Loss: 4.277603471, Training Accuracy: 4.992\n",
            "Worker 1, [05/18]: Training Loss: 4.486395247, Training Accuracy: 2.928\n",
            "Worker 1, [06/18]: Training Loss: 4.194835702, Training Accuracy: 5.696\n",
            "Worker 1, [07/18]: Training Loss: 4.392452488, Training Accuracy: 4.192\n",
            "Worker 1, [08/18]: Training Loss: 4.132230391, Training Accuracy: 6.464\n",
            "Worker 1, [09/18]: Training Loss: 4.321365150, Training Accuracy: 4.864\n",
            "Worker 1, [10/18]: Training Loss: 4.109236381, Training Accuracy: 6.864\n",
            "Worker 1, [11/18]: Training Loss: 4.304924824, Training Accuracy: 6.112\n",
            "Worker 1, [12/18]: Training Loss: 4.087538036, Training Accuracy: 7.360\n",
            "Worker 1, [13/18]: Training Loss: 4.302370616, Training Accuracy: 6.224\n",
            "Worker 1, [14/18]: Training Loss: 4.088067398, Training Accuracy: 7.440\n",
            "Worker 1, [15/18]: Training Loss: 4.316854642, Training Accuracy: 6.448\n",
            "Worker 1, [16/18]: Training Loss: 4.127612739, Training Accuracy: 7.344\n",
            "Worker 1, [17/18]: Training Loss: 4.362392537, Training Accuracy: 7.216\n",
            "Worker 1, [18/18]: Training Loss: 4.302446740, Training Accuracy: 7.168\n",
            "Time taken for training worker 1: 0:00:48.646323\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.593892803, Training Accuracy: 1.664\n",
            "Worker 2, [02/18]: Training Loss: 4.437423200, Training Accuracy: 3.440\n",
            "Worker 2, [03/18]: Training Loss: 4.540839949, Training Accuracy: 2.880\n",
            "Worker 2, [04/18]: Training Loss: 4.253498868, Training Accuracy: 4.800\n",
            "Worker 2, [05/18]: Training Loss: 4.471698960, Training Accuracy: 3.312\n",
            "Worker 2, [06/18]: Training Loss: 4.172300526, Training Accuracy: 5.552\n",
            "Worker 2, [07/18]: Training Loss: 4.369232496, Training Accuracy: 4.592\n",
            "Worker 2, [08/18]: Training Loss: 4.126932424, Training Accuracy: 6.256\n",
            "Worker 2, [09/18]: Training Loss: 4.313575720, Training Accuracy: 5.312\n",
            "Worker 2, [10/18]: Training Loss: 4.098143218, Training Accuracy: 6.896\n",
            "Worker 2, [11/18]: Training Loss: 4.292794811, Training Accuracy: 5.360\n",
            "Worker 2, [12/18]: Training Loss: 4.072581902, Training Accuracy: 7.104\n",
            "Worker 2, [13/18]: Training Loss: 4.268725828, Training Accuracy: 6.016\n",
            "Worker 2, [14/18]: Training Loss: 4.069317806, Training Accuracy: 7.616\n",
            "Worker 2, [15/18]: Training Loss: 4.299152827, Training Accuracy: 7.200\n",
            "Worker 2, [16/18]: Training Loss: 4.094952768, Training Accuracy: 6.832\n",
            "Worker 2, [17/18]: Training Loss: 4.353619902, Training Accuracy: 7.504\n",
            "Worker 2, [18/18]: Training Loss: 4.287606103, Training Accuracy: 7.392\n",
            "Time taken for training worker 2: 0:00:48.680411\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.592560432, Training Accuracy: 1.536\n",
            "Worker 3, [02/18]: Training Loss: 4.448524519, Training Accuracy: 3.696\n",
            "Worker 3, [03/18]: Training Loss: 4.476144985, Training Accuracy: 2.896\n",
            "Worker 3, [04/18]: Training Loss: 4.212908280, Training Accuracy: 5.552\n",
            "Worker 3, [05/18]: Training Loss: 4.462063123, Training Accuracy: 3.232\n",
            "Worker 3, [06/18]: Training Loss: 4.192928166, Training Accuracy: 5.632\n",
            "Worker 3, [07/18]: Training Loss: 4.368100762, Training Accuracy: 4.272\n",
            "Worker 3, [08/18]: Training Loss: 4.135293948, Training Accuracy: 6.768\n",
            "Worker 3, [09/18]: Training Loss: 4.335596352, Training Accuracy: 5.120\n",
            "Worker 3, [10/18]: Training Loss: 4.115793841, Training Accuracy: 7.200\n",
            "Worker 3, [11/18]: Training Loss: 4.299329208, Training Accuracy: 5.584\n",
            "Worker 3, [12/18]: Training Loss: 4.094702183, Training Accuracy: 7.088\n",
            "Worker 3, [13/18]: Training Loss: 4.282481014, Training Accuracy: 6.288\n",
            "Worker 3, [14/18]: Training Loss: 4.084010878, Training Accuracy: 7.824\n",
            "Worker 3, [15/18]: Training Loss: 4.305744872, Training Accuracy: 6.992\n",
            "Worker 3, [16/18]: Training Loss: 4.110424842, Training Accuracy: 7.600\n",
            "Worker 3, [17/18]: Training Loss: 4.357304471, Training Accuracy: 8.000\n",
            "Worker 3, [18/18]: Training Loss: 4.294007983, Training Accuracy: 7.632\n",
            "Time taken for training worker 3: 0:00:48.463863\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.595285883, Training Accuracy: 1.424\n",
            "Worker 4, [02/18]: Training Loss: 4.468258264, Training Accuracy: 3.312\n",
            "Worker 4, [03/18]: Training Loss: 4.549341683, Training Accuracy: 2.480\n",
            "Worker 4, [04/18]: Training Loss: 4.259276748, Training Accuracy: 5.008\n",
            "Worker 4, [05/18]: Training Loss: 4.460280525, Training Accuracy: 3.360\n",
            "Worker 4, [06/18]: Training Loss: 4.176466438, Training Accuracy: 6.048\n",
            "Worker 4, [07/18]: Training Loss: 4.386028436, Training Accuracy: 4.576\n",
            "Worker 4, [08/18]: Training Loss: 4.125533948, Training Accuracy: 6.768\n",
            "Worker 4, [09/18]: Training Loss: 4.323742093, Training Accuracy: 5.488\n",
            "Worker 4, [10/18]: Training Loss: 4.106381825, Training Accuracy: 7.392\n",
            "Worker 4, [11/18]: Training Loss: 4.298421950, Training Accuracy: 5.360\n",
            "Worker 4, [12/18]: Training Loss: 4.092108556, Training Accuracy: 7.232\n",
            "Worker 4, [13/18]: Training Loss: 4.284779933, Training Accuracy: 6.688\n",
            "Worker 4, [14/18]: Training Loss: 4.078187378, Training Accuracy: 7.616\n",
            "Worker 4, [15/18]: Training Loss: 4.312472047, Training Accuracy: 7.136\n",
            "Worker 4, [16/18]: Training Loss: 4.113415845, Training Accuracy: 7.568\n",
            "Worker 4, [17/18]: Training Loss: 4.363323032, Training Accuracy: 7.552\n",
            "Worker 4, [18/18]: Training Loss: 4.299297420, Training Accuracy: 7.456\n",
            "Time taken for training worker 4: 0:00:47.029563\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 4.594555436, Training Accuracy: 1.408\n",
            "Worker 5, [02/18]: Training Loss: 4.446695483, Training Accuracy: 3.184\n",
            "Worker 5, [03/18]: Training Loss: 4.488114644, Training Accuracy: 2.464\n",
            "Worker 5, [04/18]: Training Loss: 4.209999213, Training Accuracy: 5.456\n",
            "Worker 5, [05/18]: Training Loss: 4.452884494, Training Accuracy: 3.680\n",
            "Worker 5, [06/18]: Training Loss: 4.158204405, Training Accuracy: 6.320\n",
            "Worker 5, [07/18]: Training Loss: 4.368457536, Training Accuracy: 4.720\n",
            "Worker 5, [08/18]: Training Loss: 4.120536206, Training Accuracy: 6.960\n",
            "Worker 5, [09/18]: Training Loss: 4.335727891, Training Accuracy: 5.136\n",
            "Worker 5, [10/18]: Training Loss: 4.097519950, Training Accuracy: 6.704\n",
            "Worker 5, [11/18]: Training Loss: 4.286407677, Training Accuracy: 5.648\n",
            "Worker 5, [12/18]: Training Loss: 4.067036101, Training Accuracy: 7.248\n",
            "Worker 5, [13/18]: Training Loss: 4.273334367, Training Accuracy: 6.640\n",
            "Worker 5, [14/18]: Training Loss: 4.063781646, Training Accuracy: 8.032\n",
            "Worker 5, [15/18]: Training Loss: 4.294640921, Training Accuracy: 7.264\n",
            "Worker 5, [16/18]: Training Loss: 4.106703860, Training Accuracy: 8.032\n",
            "Worker 5, [17/18]: Training Loss: 4.348510747, Training Accuracy: 7.712\n",
            "Worker 5, [18/18]: Training Loss: 4.284305208, Training Accuracy: 7.968\n",
            "Time taken for training worker 5: 0:00:49.219468\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 4.594696098, Training Accuracy: 1.520\n",
            "Worker 6, [02/18]: Training Loss: 4.450126974, Training Accuracy: 3.328\n",
            "Worker 6, [03/18]: Training Loss: 4.509484028, Training Accuracy: 3.056\n",
            "Worker 6, [04/18]: Training Loss: 4.216863686, Training Accuracy: 5.456\n",
            "Worker 6, [05/18]: Training Loss: 4.436565545, Training Accuracy: 3.616\n",
            "Worker 6, [06/18]: Training Loss: 4.161119626, Training Accuracy: 5.888\n",
            "Worker 6, [07/18]: Training Loss: 4.364770315, Training Accuracy: 4.672\n",
            "Worker 6, [08/18]: Training Loss: 4.105100089, Training Accuracy: 6.496\n",
            "Worker 6, [09/18]: Training Loss: 4.305798560, Training Accuracy: 5.008\n",
            "Worker 6, [10/18]: Training Loss: 4.086394045, Training Accuracy: 6.656\n",
            "Worker 6, [11/18]: Training Loss: 4.289241842, Training Accuracy: 5.568\n",
            "Worker 6, [12/18]: Training Loss: 4.061499627, Training Accuracy: 7.392\n",
            "Worker 6, [13/18]: Training Loss: 4.270293946, Training Accuracy: 5.760\n",
            "Worker 6, [14/18]: Training Loss: 4.060547325, Training Accuracy: 7.328\n",
            "Worker 6, [15/18]: Training Loss: 4.295935312, Training Accuracy: 6.800\n",
            "Worker 6, [16/18]: Training Loss: 4.096261669, Training Accuracy: 7.392\n",
            "Worker 6, [17/18]: Training Loss: 4.347824024, Training Accuracy: 7.232\n",
            "Worker 6, [18/18]: Training Loss: 4.281916477, Training Accuracy: 6.640\n",
            "Time taken for training worker 6: 0:00:48.612054\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 4.595373027, Training Accuracy: 1.264\n",
            "Worker 7, [02/18]: Training Loss: 4.445909495, Training Accuracy: 2.976\n",
            "Worker 7, [03/18]: Training Loss: 4.527464054, Training Accuracy: 2.704\n",
            "Worker 7, [04/18]: Training Loss: 4.229778757, Training Accuracy: 5.056\n",
            "Worker 7, [05/18]: Training Loss: 4.448253383, Training Accuracy: 3.328\n",
            "Worker 7, [06/18]: Training Loss: 4.163817987, Training Accuracy: 5.376\n",
            "Worker 7, [07/18]: Training Loss: 4.365750004, Training Accuracy: 4.176\n",
            "Worker 7, [08/18]: Training Loss: 4.118681307, Training Accuracy: 6.512\n",
            "Worker 7, [09/18]: Training Loss: 4.329115313, Training Accuracy: 4.736\n",
            "Worker 7, [10/18]: Training Loss: 4.095188705, Training Accuracy: 6.944\n",
            "Worker 7, [11/18]: Training Loss: 4.292316101, Training Accuracy: 5.824\n",
            "Worker 7, [12/18]: Training Loss: 4.088419720, Training Accuracy: 6.208\n",
            "Worker 7, [13/18]: Training Loss: 4.272593683, Training Accuracy: 5.248\n",
            "Worker 7, [14/18]: Training Loss: 4.072589332, Training Accuracy: 6.912\n",
            "Worker 7, [15/18]: Training Loss: 4.305287118, Training Accuracy: 6.544\n",
            "Worker 7, [16/18]: Training Loss: 4.108900068, Training Accuracy: 7.328\n",
            "Worker 7, [17/18]: Training Loss: 4.356136663, Training Accuracy: 7.376\n",
            "Worker 7, [18/18]: Training Loss: 4.291792081, Training Accuracy: 7.024\n",
            "Time taken for training worker 7: 0:00:48.777759\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 4.592720640, Training Accuracy: 1.376\n",
            "Worker 8, [02/18]: Training Loss: 4.452975064, Training Accuracy: 3.024\n",
            "Worker 8, [03/18]: Training Loss: 4.546211632, Training Accuracy: 2.496\n",
            "Worker 8, [04/18]: Training Loss: 4.245116375, Training Accuracy: 4.560\n",
            "Worker 8, [05/18]: Training Loss: 4.456805940, Training Accuracy: 3.216\n",
            "Worker 8, [06/18]: Training Loss: 4.156483305, Training Accuracy: 6.032\n",
            "Worker 8, [07/18]: Training Loss: 4.371123873, Training Accuracy: 4.272\n",
            "Worker 8, [08/18]: Training Loss: 4.113889577, Training Accuracy: 6.832\n",
            "Worker 8, [09/18]: Training Loss: 4.328523612, Training Accuracy: 5.312\n",
            "Worker 8, [10/18]: Training Loss: 4.082555065, Training Accuracy: 6.928\n",
            "Worker 8, [11/18]: Training Loss: 4.276643775, Training Accuracy: 5.552\n",
            "Worker 8, [12/18]: Training Loss: 4.056967927, Training Accuracy: 7.120\n",
            "Worker 8, [13/18]: Training Loss: 4.264594017, Training Accuracy: 6.720\n",
            "Worker 8, [14/18]: Training Loss: 4.062287438, Training Accuracy: 7.344\n",
            "Worker 8, [15/18]: Training Loss: 4.304609780, Training Accuracy: 6.464\n",
            "Worker 8, [16/18]: Training Loss: 4.097753153, Training Accuracy: 7.712\n",
            "Worker 8, [17/18]: Training Loss: 4.353786396, Training Accuracy: 7.888\n",
            "Worker 8, [18/18]: Training Loss: 4.285623263, Training Accuracy: 7.520\n",
            "Time taken for training worker 8: 0:00:48.256021\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000595\n",
            "Local Step 01: Test Loss: 4.427868655, Test Accuracy: 7.110\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.437317629, Training Accuracy: 6.592\n",
            "Worker 1, [02/18]: Training Loss: 4.428822532, Training Accuracy: 6.256\n",
            "Worker 1, [03/18]: Training Loss: 4.356791039, Training Accuracy: 7.088\n",
            "Worker 1, [04/18]: Training Loss: 4.225342264, Training Accuracy: 6.608\n",
            "Worker 1, [05/18]: Training Loss: 4.229957824, Training Accuracy: 6.976\n",
            "Worker 1, [06/18]: Training Loss: 4.096222279, Training Accuracy: 7.536\n",
            "Worker 1, [07/18]: Training Loss: 4.180374496, Training Accuracy: 7.184\n",
            "Worker 1, [08/18]: Training Loss: 4.064456086, Training Accuracy: 7.536\n",
            "Worker 1, [09/18]: Training Loss: 4.153243235, Training Accuracy: 6.784\n",
            "Worker 1, [10/18]: Training Loss: 4.039302600, Training Accuracy: 8.096\n",
            "Worker 1, [11/18]: Training Loss: 4.131918754, Training Accuracy: 6.672\n",
            "Worker 1, [12/18]: Training Loss: 4.014096085, Training Accuracy: 8.560\n",
            "Worker 1, [13/18]: Training Loss: 4.113329223, Training Accuracy: 7.232\n",
            "Worker 1, [14/18]: Training Loss: 3.971347639, Training Accuracy: 9.008\n",
            "Worker 1, [15/18]: Training Loss: 4.099915329, Training Accuracy: 7.344\n",
            "Worker 1, [16/18]: Training Loss: 3.940605227, Training Accuracy: 9.600\n",
            "Worker 1, [17/18]: Training Loss: 4.062879565, Training Accuracy: 8.128\n",
            "Worker 1, [18/18]: Training Loss: 3.915083783, Training Accuracy: 9.600\n",
            "Time taken for training worker 1: 0:00:48.707144\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.120814379, Training Accuracy: 9.408\n",
            "Worker 2, [02/18]: Training Loss: 4.100298896, Training Accuracy: 9.456\n",
            "Worker 2, [03/18]: Training Loss: 4.315698322, Training Accuracy: 7.424\n",
            "Worker 2, [04/18]: Training Loss: 4.168036305, Training Accuracy: 7.344\n",
            "Worker 2, [05/18]: Training Loss: 4.189697905, Training Accuracy: 7.328\n",
            "Worker 2, [06/18]: Training Loss: 4.067203456, Training Accuracy: 7.008\n",
            "Worker 2, [07/18]: Training Loss: 4.134527749, Training Accuracy: 7.056\n",
            "Worker 2, [08/18]: Training Loss: 4.042632186, Training Accuracy: 7.152\n",
            "Worker 2, [09/18]: Training Loss: 4.127402936, Training Accuracy: 6.912\n",
            "Worker 2, [10/18]: Training Loss: 4.024210460, Training Accuracy: 7.520\n",
            "Worker 2, [11/18]: Training Loss: 4.097415746, Training Accuracy: 7.216\n",
            "Worker 2, [12/18]: Training Loss: 3.976658298, Training Accuracy: 8.080\n",
            "Worker 2, [13/18]: Training Loss: 4.076759027, Training Accuracy: 7.264\n",
            "Worker 2, [14/18]: Training Loss: 3.928697771, Training Accuracy: 9.040\n",
            "Worker 2, [15/18]: Training Loss: 4.049196601, Training Accuracy: 8.128\n",
            "Worker 2, [16/18]: Training Loss: 3.911791604, Training Accuracy: 9.008\n",
            "Worker 2, [17/18]: Training Loss: 4.030369316, Training Accuracy: 7.648\n",
            "Worker 2, [18/18]: Training Loss: 3.873031519, Training Accuracy: 9.360\n",
            "Time taken for training worker 2: 0:00:49.003030\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.112423301, Training Accuracy: 9.232\n",
            "Worker 3, [02/18]: Training Loss: 4.094949992, Training Accuracy: 9.632\n",
            "Worker 3, [03/18]: Training Loss: 4.319154063, Training Accuracy: 7.920\n",
            "Worker 3, [04/18]: Training Loss: 4.178050710, Training Accuracy: 7.744\n",
            "Worker 3, [05/18]: Training Loss: 4.195136282, Training Accuracy: 7.936\n",
            "Worker 3, [06/18]: Training Loss: 4.076995195, Training Accuracy: 7.536\n",
            "Worker 3, [07/18]: Training Loss: 4.142761751, Training Accuracy: 7.280\n",
            "Worker 3, [08/18]: Training Loss: 4.045110785, Training Accuracy: 8.080\n",
            "Worker 3, [09/18]: Training Loss: 4.128364291, Training Accuracy: 6.752\n",
            "Worker 3, [10/18]: Training Loss: 4.031323238, Training Accuracy: 7.648\n",
            "Worker 3, [11/18]: Training Loss: 4.120234521, Training Accuracy: 6.592\n",
            "Worker 3, [12/18]: Training Loss: 3.992542084, Training Accuracy: 8.272\n",
            "Worker 3, [13/18]: Training Loss: 4.092695784, Training Accuracy: 7.136\n",
            "Worker 3, [14/18]: Training Loss: 3.953905945, Training Accuracy: 8.768\n",
            "Worker 3, [15/18]: Training Loss: 4.081908569, Training Accuracy: 7.232\n",
            "Worker 3, [16/18]: Training Loss: 3.918028199, Training Accuracy: 9.408\n",
            "Worker 3, [17/18]: Training Loss: 4.031009068, Training Accuracy: 8.112\n",
            "Worker 3, [18/18]: Training Loss: 3.873675762, Training Accuracy: 10.368\n",
            "Time taken for training worker 3: 0:00:48.196311\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.110796415, Training Accuracy: 9.312\n",
            "Worker 4, [02/18]: Training Loss: 4.090416103, Training Accuracy: 9.232\n",
            "Worker 4, [03/18]: Training Loss: 4.321157528, Training Accuracy: 7.920\n",
            "Worker 4, [04/18]: Training Loss: 4.186221417, Training Accuracy: 7.824\n",
            "Worker 4, [05/18]: Training Loss: 4.192943086, Training Accuracy: 7.392\n",
            "Worker 4, [06/18]: Training Loss: 4.073417009, Training Accuracy: 7.792\n",
            "Worker 4, [07/18]: Training Loss: 4.156147971, Training Accuracy: 7.120\n",
            "Worker 4, [08/18]: Training Loss: 4.046670201, Training Accuracy: 8.032\n",
            "Worker 4, [09/18]: Training Loss: 4.126469318, Training Accuracy: 6.720\n",
            "Worker 4, [10/18]: Training Loss: 4.026257661, Training Accuracy: 8.224\n",
            "Worker 4, [11/18]: Training Loss: 4.113280909, Training Accuracy: 7.248\n",
            "Worker 4, [12/18]: Training Loss: 3.990030050, Training Accuracy: 8.320\n",
            "Worker 4, [13/18]: Training Loss: 4.097909923, Training Accuracy: 7.088\n",
            "Worker 4, [14/18]: Training Loss: 3.944174584, Training Accuracy: 9.328\n",
            "Worker 4, [15/18]: Training Loss: 4.055012725, Training Accuracy: 7.584\n",
            "Worker 4, [16/18]: Training Loss: 3.892317662, Training Accuracy: 10.048\n",
            "Worker 4, [17/18]: Training Loss: 4.019988011, Training Accuracy: 8.224\n",
            "Worker 4, [18/18]: Training Loss: 3.866064984, Training Accuracy: 10.544\n",
            "Time taken for training worker 4: 0:00:47.995381\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 4.108992725, Training Accuracy: 8.800\n",
            "Worker 5, [02/18]: Training Loss: 4.086774943, Training Accuracy: 9.376\n",
            "Worker 5, [03/18]: Training Loss: 4.314127051, Training Accuracy: 8.048\n",
            "Worker 5, [04/18]: Training Loss: 4.171970572, Training Accuracy: 7.872\n",
            "Worker 5, [05/18]: Training Loss: 4.187935520, Training Accuracy: 7.760\n",
            "Worker 5, [06/18]: Training Loss: 4.060256396, Training Accuracy: 7.696\n",
            "Worker 5, [07/18]: Training Loss: 4.133056032, Training Accuracy: 7.632\n",
            "Worker 5, [08/18]: Training Loss: 4.029571964, Training Accuracy: 7.824\n",
            "Worker 5, [09/18]: Training Loss: 4.118819996, Training Accuracy: 7.136\n",
            "Worker 5, [10/18]: Training Loss: 4.014072146, Training Accuracy: 7.760\n",
            "Worker 5, [11/18]: Training Loss: 4.096303217, Training Accuracy: 7.120\n",
            "Worker 5, [12/18]: Training Loss: 3.976381380, Training Accuracy: 8.992\n",
            "Worker 5, [13/18]: Training Loss: 4.087682065, Training Accuracy: 7.520\n",
            "Worker 5, [14/18]: Training Loss: 3.936709314, Training Accuracy: 8.864\n",
            "Worker 5, [15/18]: Training Loss: 4.051875470, Training Accuracy: 8.160\n",
            "Worker 5, [16/18]: Training Loss: 3.891882609, Training Accuracy: 10.048\n",
            "Worker 5, [17/18]: Training Loss: 4.015456348, Training Accuracy: 8.576\n",
            "Worker 5, [18/18]: Training Loss: 3.861489055, Training Accuracy: 10.576\n",
            "Time taken for training worker 5: 0:00:49.134951\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 4.102960236, Training Accuracy: 9.712\n",
            "Worker 6, [02/18]: Training Loss: 4.084917789, Training Accuracy: 9.744\n",
            "Worker 6, [03/18]: Training Loss: 4.309005217, Training Accuracy: 7.616\n",
            "Worker 6, [04/18]: Training Loss: 4.163013916, Training Accuracy: 6.800\n",
            "Worker 6, [05/18]: Training Loss: 4.175411862, Training Accuracy: 6.768\n",
            "Worker 6, [06/18]: Training Loss: 4.052923825, Training Accuracy: 7.552\n",
            "Worker 6, [07/18]: Training Loss: 4.139252782, Training Accuracy: 6.688\n",
            "Worker 6, [08/18]: Training Loss: 4.027347664, Training Accuracy: 6.976\n",
            "Worker 6, [09/18]: Training Loss: 4.121387017, Training Accuracy: 6.496\n",
            "Worker 6, [10/18]: Training Loss: 4.008879452, Training Accuracy: 8.160\n",
            "Worker 6, [11/18]: Training Loss: 4.094368789, Training Accuracy: 6.480\n",
            "Worker 6, [12/18]: Training Loss: 3.970708110, Training Accuracy: 8.432\n",
            "Worker 6, [13/18]: Training Loss: 4.085330085, Training Accuracy: 7.216\n",
            "Worker 6, [14/18]: Training Loss: 3.935577789, Training Accuracy: 8.896\n",
            "Worker 6, [15/18]: Training Loss: 4.055529687, Training Accuracy: 7.488\n",
            "Worker 6, [16/18]: Training Loss: 3.924550570, Training Accuracy: 9.264\n",
            "Worker 6, [17/18]: Training Loss: 4.032717432, Training Accuracy: 7.120\n",
            "Worker 6, [18/18]: Training Loss: 3.853638051, Training Accuracy: 10.464\n",
            "Time taken for training worker 6: 0:00:49.374176\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 4.099387843, Training Accuracy: 9.296\n",
            "Worker 7, [02/18]: Training Loss: 4.082165042, Training Accuracy: 9.200\n",
            "Worker 7, [03/18]: Training Loss: 4.320178231, Training Accuracy: 7.200\n",
            "Worker 7, [04/18]: Training Loss: 4.171643985, Training Accuracy: 6.848\n",
            "Worker 7, [05/18]: Training Loss: 4.187399893, Training Accuracy: 6.992\n",
            "Worker 7, [06/18]: Training Loss: 4.061179672, Training Accuracy: 6.592\n",
            "Worker 7, [07/18]: Training Loss: 4.135335402, Training Accuracy: 7.088\n",
            "Worker 7, [08/18]: Training Loss: 4.032224604, Training Accuracy: 7.920\n",
            "Worker 7, [09/18]: Training Loss: 4.128926265, Training Accuracy: 6.128\n",
            "Worker 7, [10/18]: Training Loss: 4.008337763, Training Accuracy: 7.536\n",
            "Worker 7, [11/18]: Training Loss: 4.107400313, Training Accuracy: 6.816\n",
            "Worker 7, [12/18]: Training Loss: 3.982898644, Training Accuracy: 8.400\n",
            "Worker 7, [13/18]: Training Loss: 4.081853601, Training Accuracy: 6.992\n",
            "Worker 7, [14/18]: Training Loss: 3.924775885, Training Accuracy: 9.120\n",
            "Worker 7, [15/18]: Training Loss: 4.057894081, Training Accuracy: 7.472\n",
            "Worker 7, [16/18]: Training Loss: 3.909177882, Training Accuracy: 9.600\n",
            "Worker 7, [17/18]: Training Loss: 4.031197840, Training Accuracy: 7.376\n",
            "Worker 7, [18/18]: Training Loss: 3.883206482, Training Accuracy: 10.048\n",
            "Time taken for training worker 7: 0:00:47.085587\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 4.101727508, Training Accuracy: 9.408\n",
            "Worker 8, [02/18]: Training Loss: 4.079785692, Training Accuracy: 9.568\n",
            "Worker 8, [03/18]: Training Loss: 4.314686396, Training Accuracy: 8.032\n",
            "Worker 8, [04/18]: Training Loss: 4.169495787, Training Accuracy: 7.680\n",
            "Worker 8, [05/18]: Training Loss: 4.181601977, Training Accuracy: 7.296\n",
            "Worker 8, [06/18]: Training Loss: 4.057281660, Training Accuracy: 7.120\n",
            "Worker 8, [07/18]: Training Loss: 4.132790765, Training Accuracy: 6.928\n",
            "Worker 8, [08/18]: Training Loss: 4.040209916, Training Accuracy: 7.568\n",
            "Worker 8, [09/18]: Training Loss: 4.113273119, Training Accuracy: 6.896\n",
            "Worker 8, [10/18]: Training Loss: 4.003446932, Training Accuracy: 8.304\n",
            "Worker 8, [11/18]: Training Loss: 4.099653551, Training Accuracy: 6.736\n",
            "Worker 8, [12/18]: Training Loss: 3.968374510, Training Accuracy: 8.064\n",
            "Worker 8, [13/18]: Training Loss: 4.069018376, Training Accuracy: 6.848\n",
            "Worker 8, [14/18]: Training Loss: 3.928554005, Training Accuracy: 9.504\n",
            "Worker 8, [15/18]: Training Loss: 4.057309516, Training Accuracy: 7.840\n",
            "Worker 8, [16/18]: Training Loss: 3.894176685, Training Accuracy: 9.472\n",
            "Worker 8, [17/18]: Training Loss: 4.011710632, Training Accuracy: 7.728\n",
            "Worker 8, [18/18]: Training Loss: 3.876701727, Training Accuracy: 9.568\n",
            "Time taken for training worker 8: 0:00:48.607610\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000589\n",
            "Local Step 02: Test Loss: 4.071524704, Test Accuracy: 9.870\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.051714102, Training Accuracy: 7.312\n",
            "Worker 1, [02/18]: Training Loss: 3.890805570, Training Accuracy: 9.904\n",
            "Worker 1, [03/18]: Training Loss: 3.987407475, Training Accuracy: 8.496\n",
            "Worker 1, [04/18]: Training Loss: 3.851613142, Training Accuracy: 10.352\n",
            "Worker 1, [05/18]: Training Loss: 3.974430921, Training Accuracy: 8.640\n",
            "Worker 1, [06/18]: Training Loss: 3.812464787, Training Accuracy: 11.072\n",
            "Worker 1, [07/18]: Training Loss: 3.921208902, Training Accuracy: 9.472\n",
            "Worker 1, [08/18]: Training Loss: 3.776711746, Training Accuracy: 12.272\n",
            "Worker 1, [09/18]: Training Loss: 3.863659737, Training Accuracy: 10.368\n",
            "Worker 1, [10/18]: Training Loss: 3.758458208, Training Accuracy: 12.352\n",
            "Worker 1, [11/18]: Training Loss: 3.822683252, Training Accuracy: 11.408\n",
            "Worker 1, [12/18]: Training Loss: 3.702987651, Training Accuracy: 13.072\n",
            "Worker 1, [13/18]: Training Loss: 3.779008710, Training Accuracy: 12.016\n",
            "Worker 1, [14/18]: Training Loss: 3.683879249, Training Accuracy: 13.600\n",
            "Worker 1, [15/18]: Training Loss: 3.758921073, Training Accuracy: 12.992\n",
            "Worker 1, [16/18]: Training Loss: 3.679488221, Training Accuracy: 13.936\n",
            "Worker 1, [17/18]: Training Loss: 3.767274976, Training Accuracy: 13.104\n",
            "Worker 1, [18/18]: Training Loss: 3.711188920, Training Accuracy: 13.728\n",
            "Time taken for training worker 1: 0:00:48.323985\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.906781073, Training Accuracy: 9.536\n",
            "Worker 2, [02/18]: Training Loss: 3.740316486, Training Accuracy: 11.664\n",
            "Worker 2, [03/18]: Training Loss: 3.949548116, Training Accuracy: 8.384\n",
            "Worker 2, [04/18]: Training Loss: 3.794487313, Training Accuracy: 10.800\n",
            "Worker 2, [05/18]: Training Loss: 3.928534060, Training Accuracy: 8.912\n",
            "Worker 2, [06/18]: Training Loss: 3.752317755, Training Accuracy: 11.472\n",
            "Worker 2, [07/18]: Training Loss: 3.860279638, Training Accuracy: 9.952\n",
            "Worker 2, [08/18]: Training Loss: 3.711626145, Training Accuracy: 11.728\n",
            "Worker 2, [09/18]: Training Loss: 3.807989685, Training Accuracy: 11.584\n",
            "Worker 2, [10/18]: Training Loss: 3.676482050, Training Accuracy: 12.496\n",
            "Worker 2, [11/18]: Training Loss: 3.767366687, Training Accuracy: 11.712\n",
            "Worker 2, [12/18]: Training Loss: 3.659318267, Training Accuracy: 13.168\n",
            "Worker 2, [13/18]: Training Loss: 3.730283202, Training Accuracy: 12.320\n",
            "Worker 2, [14/18]: Training Loss: 3.612461796, Training Accuracy: 14.208\n",
            "Worker 2, [15/18]: Training Loss: 3.696310136, Training Accuracy: 13.184\n",
            "Worker 2, [16/18]: Training Loss: 3.614498309, Training Accuracy: 14.080\n",
            "Worker 2, [17/18]: Training Loss: 3.707458932, Training Accuracy: 14.096\n",
            "Worker 2, [18/18]: Training Loss: 3.649854451, Training Accuracy: 14.192\n",
            "Time taken for training worker 2: 0:00:47.566636\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.874325441, Training Accuracy: 10.480\n",
            "Worker 3, [02/18]: Training Loss: 3.721584780, Training Accuracy: 12.880\n",
            "Worker 3, [03/18]: Training Loss: 3.965417748, Training Accuracy: 8.992\n",
            "Worker 3, [04/18]: Training Loss: 3.807609904, Training Accuracy: 10.864\n",
            "Worker 3, [05/18]: Training Loss: 3.930913426, Training Accuracy: 9.328\n",
            "Worker 3, [06/18]: Training Loss: 3.769342398, Training Accuracy: 11.920\n",
            "Worker 3, [07/18]: Training Loss: 3.877878284, Training Accuracy: 9.920\n",
            "Worker 3, [08/18]: Training Loss: 3.724704112, Training Accuracy: 12.240\n",
            "Worker 3, [09/18]: Training Loss: 3.817628741, Training Accuracy: 11.264\n",
            "Worker 3, [10/18]: Training Loss: 3.698867409, Training Accuracy: 12.896\n",
            "Worker 3, [11/18]: Training Loss: 3.781936227, Training Accuracy: 11.904\n",
            "Worker 3, [12/18]: Training Loss: 3.664875359, Training Accuracy: 13.968\n",
            "Worker 3, [13/18]: Training Loss: 3.734661467, Training Accuracy: 13.280\n",
            "Worker 3, [14/18]: Training Loss: 3.641417559, Training Accuracy: 14.416\n",
            "Worker 3, [15/18]: Training Loss: 3.713176479, Training Accuracy: 13.648\n",
            "Worker 3, [16/18]: Training Loss: 3.631054577, Training Accuracy: 14.912\n",
            "Worker 3, [17/18]: Training Loss: 3.720955379, Training Accuracy: 14.464\n",
            "Worker 3, [18/18]: Training Loss: 3.675032701, Training Accuracy: 14.064\n",
            "Time taken for training worker 3: 0:00:49.244924\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.871324544, Training Accuracy: 10.048\n",
            "Worker 4, [02/18]: Training Loss: 3.722923717, Training Accuracy: 12.464\n",
            "Worker 4, [03/18]: Training Loss: 3.966236888, Training Accuracy: 8.976\n",
            "Worker 4, [04/18]: Training Loss: 3.808146579, Training Accuracy: 11.792\n",
            "Worker 4, [05/18]: Training Loss: 3.912571445, Training Accuracy: 9.728\n",
            "Worker 4, [06/18]: Training Loss: 3.758379192, Training Accuracy: 11.632\n",
            "Worker 4, [07/18]: Training Loss: 3.862960762, Training Accuracy: 10.032\n",
            "Worker 4, [08/18]: Training Loss: 3.709628098, Training Accuracy: 12.416\n",
            "Worker 4, [09/18]: Training Loss: 3.815620634, Training Accuracy: 11.680\n",
            "Worker 4, [10/18]: Training Loss: 3.678991814, Training Accuracy: 13.472\n",
            "Worker 4, [11/18]: Training Loss: 3.766350296, Training Accuracy: 12.160\n",
            "Worker 4, [12/18]: Training Loss: 3.659197557, Training Accuracy: 13.760\n",
            "Worker 4, [13/18]: Training Loss: 3.719466433, Training Accuracy: 13.120\n",
            "Worker 4, [14/18]: Training Loss: 3.620209093, Training Accuracy: 14.576\n",
            "Worker 4, [15/18]: Training Loss: 3.698935183, Training Accuracy: 14.096\n",
            "Worker 4, [16/18]: Training Loss: 3.618574780, Training Accuracy: 14.784\n",
            "Worker 4, [17/18]: Training Loss: 3.709682017, Training Accuracy: 14.016\n",
            "Worker 4, [18/18]: Training Loss: 3.653899954, Training Accuracy: 14.832\n",
            "Time taken for training worker 4: 0:00:46.457802\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.880438702, Training Accuracy: 11.232\n",
            "Worker 5, [02/18]: Training Loss: 3.737039077, Training Accuracy: 12.048\n",
            "Worker 5, [03/18]: Training Loss: 3.965575668, Training Accuracy: 8.976\n",
            "Worker 5, [04/18]: Training Loss: 3.811694649, Training Accuracy: 10.784\n",
            "Worker 5, [05/18]: Training Loss: 3.918817992, Training Accuracy: 9.328\n",
            "Worker 5, [06/18]: Training Loss: 3.758489721, Training Accuracy: 12.096\n",
            "Worker 5, [07/18]: Training Loss: 3.867170516, Training Accuracy: 10.384\n",
            "Worker 5, [08/18]: Training Loss: 3.703877237, Training Accuracy: 12.080\n",
            "Worker 5, [09/18]: Training Loss: 3.813675435, Training Accuracy: 11.056\n",
            "Worker 5, [10/18]: Training Loss: 3.680618610, Training Accuracy: 13.344\n",
            "Worker 5, [11/18]: Training Loss: 3.777724799, Training Accuracy: 11.776\n",
            "Worker 5, [12/18]: Training Loss: 3.650206590, Training Accuracy: 14.448\n",
            "Worker 5, [13/18]: Training Loss: 3.720160027, Training Accuracy: 12.880\n",
            "Worker 5, [14/18]: Training Loss: 3.628205555, Training Accuracy: 14.160\n",
            "Worker 5, [15/18]: Training Loss: 3.704778443, Training Accuracy: 13.520\n",
            "Worker 5, [16/18]: Training Loss: 3.616010919, Training Accuracy: 14.064\n",
            "Worker 5, [17/18]: Training Loss: 3.709687532, Training Accuracy: 14.432\n",
            "Worker 5, [18/18]: Training Loss: 3.650888852, Training Accuracy: 14.352\n",
            "Time taken for training worker 5: 0:00:48.288501\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.866703077, Training Accuracy: 10.080\n",
            "Worker 6, [02/18]: Training Loss: 3.715628904, Training Accuracy: 12.224\n",
            "Worker 6, [03/18]: Training Loss: 3.949522756, Training Accuracy: 9.440\n",
            "Worker 6, [04/18]: Training Loss: 3.815230834, Training Accuracy: 10.864\n",
            "Worker 6, [05/18]: Training Loss: 3.899067886, Training Accuracy: 9.696\n",
            "Worker 6, [06/18]: Training Loss: 3.750466515, Training Accuracy: 12.000\n",
            "Worker 6, [07/18]: Training Loss: 3.861017663, Training Accuracy: 10.624\n",
            "Worker 6, [08/18]: Training Loss: 3.725804390, Training Accuracy: 12.128\n",
            "Worker 6, [09/18]: Training Loss: 3.812996543, Training Accuracy: 11.472\n",
            "Worker 6, [10/18]: Training Loss: 3.670953719, Training Accuracy: 13.360\n",
            "Worker 6, [11/18]: Training Loss: 3.772903092, Training Accuracy: 12.112\n",
            "Worker 6, [12/18]: Training Loss: 3.659896853, Training Accuracy: 14.144\n",
            "Worker 6, [13/18]: Training Loss: 3.733116741, Training Accuracy: 12.736\n",
            "Worker 6, [14/18]: Training Loss: 3.627525235, Training Accuracy: 13.776\n",
            "Worker 6, [15/18]: Training Loss: 3.693057211, Training Accuracy: 13.824\n",
            "Worker 6, [16/18]: Training Loss: 3.623820818, Training Accuracy: 14.336\n",
            "Worker 6, [17/18]: Training Loss: 3.703601071, Training Accuracy: 13.824\n",
            "Worker 6, [18/18]: Training Loss: 3.653303543, Training Accuracy: 14.496\n",
            "Time taken for training worker 6: 0:00:47.315025\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.880805874, Training Accuracy: 9.696\n",
            "Worker 7, [02/18]: Training Loss: 3.747081749, Training Accuracy: 11.408\n",
            "Worker 7, [03/18]: Training Loss: 3.968870778, Training Accuracy: 8.960\n",
            "Worker 7, [04/18]: Training Loss: 3.799046986, Training Accuracy: 10.848\n",
            "Worker 7, [05/18]: Training Loss: 3.923072246, Training Accuracy: 8.992\n",
            "Worker 7, [06/18]: Training Loss: 3.784788557, Training Accuracy: 11.296\n",
            "Worker 7, [07/18]: Training Loss: 3.872716558, Training Accuracy: 10.320\n",
            "Worker 7, [08/18]: Training Loss: 3.725907917, Training Accuracy: 11.904\n",
            "Worker 7, [09/18]: Training Loss: 3.825554517, Training Accuracy: 11.168\n",
            "Worker 7, [10/18]: Training Loss: 3.696513855, Training Accuracy: 12.912\n",
            "Worker 7, [11/18]: Training Loss: 3.766800209, Training Accuracy: 11.424\n",
            "Worker 7, [12/18]: Training Loss: 3.659118818, Training Accuracy: 13.632\n",
            "Worker 7, [13/18]: Training Loss: 3.725607510, Training Accuracy: 13.040\n",
            "Worker 7, [14/18]: Training Loss: 3.632759943, Training Accuracy: 13.904\n",
            "Worker 7, [15/18]: Training Loss: 3.701214007, Training Accuracy: 13.808\n",
            "Worker 7, [16/18]: Training Loss: 3.627646770, Training Accuracy: 14.352\n",
            "Worker 7, [17/18]: Training Loss: 3.710794940, Training Accuracy: 14.064\n",
            "Worker 7, [18/18]: Training Loss: 3.654277840, Training Accuracy: 14.080\n",
            "Time taken for training worker 7: 0:00:47.861929\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.877999335, Training Accuracy: 9.984\n",
            "Worker 8, [02/18]: Training Loss: 3.724391531, Training Accuracy: 12.144\n",
            "Worker 8, [03/18]: Training Loss: 3.957421398, Training Accuracy: 8.720\n",
            "Worker 8, [04/18]: Training Loss: 3.813692679, Training Accuracy: 10.464\n",
            "Worker 8, [05/18]: Training Loss: 3.904717312, Training Accuracy: 9.968\n",
            "Worker 8, [06/18]: Training Loss: 3.755529472, Training Accuracy: 11.632\n",
            "Worker 8, [07/18]: Training Loss: 3.851167489, Training Accuracy: 10.080\n",
            "Worker 8, [08/18]: Training Loss: 3.710641659, Training Accuracy: 12.576\n",
            "Worker 8, [09/18]: Training Loss: 3.812050491, Training Accuracy: 10.672\n",
            "Worker 8, [10/18]: Training Loss: 3.678020300, Training Accuracy: 12.768\n",
            "Worker 8, [11/18]: Training Loss: 3.767469632, Training Accuracy: 11.536\n",
            "Worker 8, [12/18]: Training Loss: 3.648442767, Training Accuracy: 13.120\n",
            "Worker 8, [13/18]: Training Loss: 3.720146821, Training Accuracy: 12.704\n",
            "Worker 8, [14/18]: Training Loss: 3.618566207, Training Accuracy: 13.536\n",
            "Worker 8, [15/18]: Training Loss: 3.687177169, Training Accuracy: 13.248\n",
            "Worker 8, [16/18]: Training Loss: 3.606106325, Training Accuracy: 14.608\n",
            "Worker 8, [17/18]: Training Loss: 3.702943831, Training Accuracy: 13.696\n",
            "Worker 8, [18/18]: Training Loss: 3.648534485, Training Accuracy: 14.080\n",
            "Time taken for training worker 8: 0:00:47.214042\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000507\n",
            "Local Step 03: Test Loss: 3.790375670, Test Accuracy: 13.160\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.840516385, Training Accuracy: 12.112\n",
            "Worker 1, [02/18]: Training Loss: 3.834565936, Training Accuracy: 12.240\n",
            "Worker 1, [03/18]: Training Loss: 3.757157318, Training Accuracy: 13.648\n",
            "Worker 1, [04/18]: Training Loss: 3.709014029, Training Accuracy: 14.016\n",
            "Worker 1, [05/18]: Training Loss: 3.740302100, Training Accuracy: 13.040\n",
            "Worker 1, [06/18]: Training Loss: 3.701146517, Training Accuracy: 13.456\n",
            "Worker 1, [07/18]: Training Loss: 3.751926626, Training Accuracy: 12.608\n",
            "Worker 1, [08/18]: Training Loss: 3.697408586, Training Accuracy: 13.168\n",
            "Worker 1, [09/18]: Training Loss: 3.758568997, Training Accuracy: 12.016\n",
            "Worker 1, [10/18]: Training Loss: 3.699788646, Training Accuracy: 13.424\n",
            "Worker 1, [11/18]: Training Loss: 3.764294765, Training Accuracy: 12.192\n",
            "Worker 1, [12/18]: Training Loss: 3.700913351, Training Accuracy: 13.472\n",
            "Worker 1, [13/18]: Training Loss: 3.793785942, Training Accuracy: 12.032\n",
            "Worker 1, [14/18]: Training Loss: 3.679854065, Training Accuracy: 13.328\n",
            "Worker 1, [15/18]: Training Loss: 3.781632606, Training Accuracy: 11.584\n",
            "Worker 1, [16/18]: Training Loss: 3.664663526, Training Accuracy: 13.664\n",
            "Worker 1, [17/18]: Training Loss: 3.750336601, Training Accuracy: 12.608\n",
            "Worker 1, [18/18]: Training Loss: 3.646099626, Training Accuracy: 13.712\n",
            "Time taken for training worker 1: 0:00:48.319844\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.727744353, Training Accuracy: 13.264\n",
            "Worker 2, [02/18]: Training Loss: 3.720951102, Training Accuracy: 13.536\n",
            "Worker 2, [03/18]: Training Loss: 3.685562182, Training Accuracy: 13.648\n",
            "Worker 2, [04/18]: Training Loss: 3.639578418, Training Accuracy: 14.576\n",
            "Worker 2, [05/18]: Training Loss: 3.656205151, Training Accuracy: 14.224\n",
            "Worker 2, [06/18]: Training Loss: 3.625245063, Training Accuracy: 13.888\n",
            "Worker 2, [07/18]: Training Loss: 3.674307033, Training Accuracy: 12.912\n",
            "Worker 2, [08/18]: Training Loss: 3.624657349, Training Accuracy: 13.728\n",
            "Worker 2, [09/18]: Training Loss: 3.692728398, Training Accuracy: 12.000\n",
            "Worker 2, [10/18]: Training Loss: 3.640615546, Training Accuracy: 13.584\n",
            "Worker 2, [11/18]: Training Loss: 3.698243611, Training Accuracy: 12.624\n",
            "Worker 2, [12/18]: Training Loss: 3.631674029, Training Accuracy: 12.640\n",
            "Worker 2, [13/18]: Training Loss: 3.708887168, Training Accuracy: 12.496\n",
            "Worker 2, [14/18]: Training Loss: 3.625352563, Training Accuracy: 13.280\n",
            "Worker 2, [15/18]: Training Loss: 3.704529383, Training Accuracy: 12.512\n",
            "Worker 2, [16/18]: Training Loss: 3.597623178, Training Accuracy: 13.408\n",
            "Worker 2, [17/18]: Training Loss: 3.690828309, Training Accuracy: 12.288\n",
            "Worker 2, [18/18]: Training Loss: 3.582818878, Training Accuracy: 14.096\n",
            "Time taken for training worker 2: 0:00:46.547939\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.704360317, Training Accuracy: 14.272\n",
            "Worker 3, [02/18]: Training Loss: 3.697890600, Training Accuracy: 14.368\n",
            "Worker 3, [03/18]: Training Loss: 3.708881466, Training Accuracy: 13.904\n",
            "Worker 3, [04/18]: Training Loss: 3.666946073, Training Accuracy: 14.128\n",
            "Worker 3, [05/18]: Training Loss: 3.682873018, Training Accuracy: 13.856\n",
            "Worker 3, [06/18]: Training Loss: 3.638005237, Training Accuracy: 14.368\n",
            "Worker 3, [07/18]: Training Loss: 3.686192257, Training Accuracy: 14.016\n",
            "Worker 3, [08/18]: Training Loss: 3.641215371, Training Accuracy: 13.920\n",
            "Worker 3, [09/18]: Training Loss: 3.711584497, Training Accuracy: 13.408\n",
            "Worker 3, [10/18]: Training Loss: 3.642494107, Training Accuracy: 14.160\n",
            "Worker 3, [11/18]: Training Loss: 3.699036194, Training Accuracy: 13.152\n",
            "Worker 3, [12/18]: Training Loss: 3.633760002, Training Accuracy: 14.160\n",
            "Worker 3, [13/18]: Training Loss: 3.725933571, Training Accuracy: 12.656\n",
            "Worker 3, [14/18]: Training Loss: 3.627551388, Training Accuracy: 14.000\n",
            "Worker 3, [15/18]: Training Loss: 3.738232805, Training Accuracy: 13.104\n",
            "Worker 3, [16/18]: Training Loss: 3.627837349, Training Accuracy: 14.000\n",
            "Worker 3, [17/18]: Training Loss: 3.703236648, Training Accuracy: 13.504\n",
            "Worker 3, [18/18]: Training Loss: 3.596912418, Training Accuracy: 14.944\n",
            "Time taken for training worker 3: 0:00:47.583420\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.704676171, Training Accuracy: 13.952\n",
            "Worker 4, [02/18]: Training Loss: 3.690741773, Training Accuracy: 14.224\n",
            "Worker 4, [03/18]: Training Loss: 3.696638134, Training Accuracy: 14.384\n",
            "Worker 4, [04/18]: Training Loss: 3.643991538, Training Accuracy: 15.024\n",
            "Worker 4, [05/18]: Training Loss: 3.660214597, Training Accuracy: 14.432\n",
            "Worker 4, [06/18]: Training Loss: 3.618615187, Training Accuracy: 15.408\n",
            "Worker 4, [07/18]: Training Loss: 3.674046088, Training Accuracy: 13.504\n",
            "Worker 4, [08/18]: Training Loss: 3.620921948, Training Accuracy: 14.528\n",
            "Worker 4, [09/18]: Training Loss: 3.694002088, Training Accuracy: 12.784\n",
            "Worker 4, [10/18]: Training Loss: 3.633336101, Training Accuracy: 14.144\n",
            "Worker 4, [11/18]: Training Loss: 3.714692897, Training Accuracy: 12.400\n",
            "Worker 4, [12/18]: Training Loss: 3.640132787, Training Accuracy: 14.352\n",
            "Worker 4, [13/18]: Training Loss: 3.712104046, Training Accuracy: 13.040\n",
            "Worker 4, [14/18]: Training Loss: 3.622055368, Training Accuracy: 14.336\n",
            "Worker 4, [15/18]: Training Loss: 3.696142175, Training Accuracy: 12.656\n",
            "Worker 4, [16/18]: Training Loss: 3.613632747, Training Accuracy: 14.592\n",
            "Worker 4, [17/18]: Training Loss: 3.691685533, Training Accuracy: 13.232\n",
            "Worker 4, [18/18]: Training Loss: 3.590694279, Training Accuracy: 14.912\n",
            "Time taken for training worker 4: 0:00:48.918339\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.686273173, Training Accuracy: 14.304\n",
            "Worker 5, [02/18]: Training Loss: 3.688117066, Training Accuracy: 14.176\n",
            "Worker 5, [03/18]: Training Loss: 3.697202116, Training Accuracy: 13.824\n",
            "Worker 5, [04/18]: Training Loss: 3.638035331, Training Accuracy: 14.288\n",
            "Worker 5, [05/18]: Training Loss: 3.650594400, Training Accuracy: 14.592\n",
            "Worker 5, [06/18]: Training Loss: 3.617018505, Training Accuracy: 14.288\n",
            "Worker 5, [07/18]: Training Loss: 3.674838633, Training Accuracy: 13.552\n",
            "Worker 5, [08/18]: Training Loss: 3.620853908, Training Accuracy: 14.240\n",
            "Worker 5, [09/18]: Training Loss: 3.692595832, Training Accuracy: 13.312\n",
            "Worker 5, [10/18]: Training Loss: 3.622684257, Training Accuracy: 14.272\n",
            "Worker 5, [11/18]: Training Loss: 3.701723089, Training Accuracy: 12.944\n",
            "Worker 5, [12/18]: Training Loss: 3.615975803, Training Accuracy: 14.272\n",
            "Worker 5, [13/18]: Training Loss: 3.707156597, Training Accuracy: 12.992\n",
            "Worker 5, [14/18]: Training Loss: 3.612071456, Training Accuracy: 15.024\n",
            "Worker 5, [15/18]: Training Loss: 3.700761321, Training Accuracy: 12.848\n",
            "Worker 5, [16/18]: Training Loss: 3.598055056, Training Accuracy: 14.832\n",
            "Worker 5, [17/18]: Training Loss: 3.679101859, Training Accuracy: 13.104\n",
            "Worker 5, [18/18]: Training Loss: 3.582124832, Training Accuracy: 14.496\n",
            "Time taken for training worker 5: 0:00:48.599151\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.684347654, Training Accuracy: 14.480\n",
            "Worker 6, [02/18]: Training Loss: 3.663966349, Training Accuracy: 14.496\n",
            "Worker 6, [03/18]: Training Loss: 3.689638498, Training Accuracy: 14.400\n",
            "Worker 6, [04/18]: Training Loss: 3.642988587, Training Accuracy: 14.336\n",
            "Worker 6, [05/18]: Training Loss: 3.667915240, Training Accuracy: 13.664\n",
            "Worker 6, [06/18]: Training Loss: 3.625692037, Training Accuracy: 14.432\n",
            "Worker 6, [07/18]: Training Loss: 3.673613560, Training Accuracy: 13.472\n",
            "Worker 6, [08/18]: Training Loss: 3.629448606, Training Accuracy: 13.456\n",
            "Worker 6, [09/18]: Training Loss: 3.681054526, Training Accuracy: 13.568\n",
            "Worker 6, [10/18]: Training Loss: 3.626600426, Training Accuracy: 14.016\n",
            "Worker 6, [11/18]: Training Loss: 3.704251503, Training Accuracy: 12.992\n",
            "Worker 6, [12/18]: Training Loss: 3.623408339, Training Accuracy: 14.464\n",
            "Worker 6, [13/18]: Training Loss: 3.724421769, Training Accuracy: 12.064\n",
            "Worker 6, [14/18]: Training Loss: 3.632061542, Training Accuracy: 13.744\n",
            "Worker 6, [15/18]: Training Loss: 3.683859626, Training Accuracy: 13.040\n",
            "Worker 6, [16/18]: Training Loss: 3.601144542, Training Accuracy: 14.224\n",
            "Worker 6, [17/18]: Training Loss: 3.684788864, Training Accuracy: 12.544\n",
            "Worker 6, [18/18]: Training Loss: 3.591012468, Training Accuracy: 14.304\n",
            "Time taken for training worker 6: 0:00:48.288290\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.696469120, Training Accuracy: 14.096\n",
            "Worker 7, [02/18]: Training Loss: 3.677786362, Training Accuracy: 14.272\n",
            "Worker 7, [03/18]: Training Loss: 3.695972331, Training Accuracy: 14.272\n",
            "Worker 7, [04/18]: Training Loss: 3.649956209, Training Accuracy: 14.368\n",
            "Worker 7, [05/18]: Training Loss: 3.668870398, Training Accuracy: 13.712\n",
            "Worker 7, [06/18]: Training Loss: 3.646670852, Training Accuracy: 14.240\n",
            "Worker 7, [07/18]: Training Loss: 3.675321842, Training Accuracy: 13.632\n",
            "Worker 7, [08/18]: Training Loss: 3.647855192, Training Accuracy: 13.440\n",
            "Worker 7, [09/18]: Training Loss: 3.702870734, Training Accuracy: 12.928\n",
            "Worker 7, [10/18]: Training Loss: 3.649393510, Training Accuracy: 12.816\n",
            "Worker 7, [11/18]: Training Loss: 3.717617974, Training Accuracy: 12.944\n",
            "Worker 7, [12/18]: Training Loss: 3.647376905, Training Accuracy: 13.024\n",
            "Worker 7, [13/18]: Training Loss: 3.715413665, Training Accuracy: 12.480\n",
            "Worker 7, [14/18]: Training Loss: 3.654250417, Training Accuracy: 13.600\n",
            "Worker 7, [15/18]: Training Loss: 3.726648275, Training Accuracy: 12.080\n",
            "Worker 7, [16/18]: Training Loss: 3.635316311, Training Accuracy: 12.864\n",
            "Worker 7, [17/18]: Training Loss: 3.747722458, Training Accuracy: 11.968\n",
            "Worker 7, [18/18]: Training Loss: 3.623127570, Training Accuracy: 13.200\n",
            "Time taken for training worker 7: 0:00:47.632790\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.700865561, Training Accuracy: 14.128\n",
            "Worker 8, [02/18]: Training Loss: 3.694525945, Training Accuracy: 14.032\n",
            "Worker 8, [03/18]: Training Loss: 3.687373526, Training Accuracy: 13.792\n",
            "Worker 8, [04/18]: Training Loss: 3.642383157, Training Accuracy: 14.048\n",
            "Worker 8, [05/18]: Training Loss: 3.667205942, Training Accuracy: 13.712\n",
            "Worker 8, [06/18]: Training Loss: 3.620913021, Training Accuracy: 14.208\n",
            "Worker 8, [07/18]: Training Loss: 3.669344790, Training Accuracy: 13.328\n",
            "Worker 8, [08/18]: Training Loss: 3.643153096, Training Accuracy: 13.824\n",
            "Worker 8, [09/18]: Training Loss: 3.695081514, Training Accuracy: 12.544\n",
            "Worker 8, [10/18]: Training Loss: 3.633861980, Training Accuracy: 13.616\n",
            "Worker 8, [11/18]: Training Loss: 3.707229463, Training Accuracy: 12.288\n",
            "Worker 8, [12/18]: Training Loss: 3.652866811, Training Accuracy: 13.152\n",
            "Worker 8, [13/18]: Training Loss: 3.725579113, Training Accuracy: 12.208\n",
            "Worker 8, [14/18]: Training Loss: 3.634917028, Training Accuracy: 13.472\n",
            "Worker 8, [15/18]: Training Loss: 3.709729791, Training Accuracy: 12.000\n",
            "Worker 8, [16/18]: Training Loss: 3.620810008, Training Accuracy: 13.616\n",
            "Worker 8, [17/18]: Training Loss: 3.692144776, Training Accuracy: 12.496\n",
            "Worker 8, [18/18]: Training Loss: 3.619908357, Training Accuracy: 13.344\n",
            "Time taken for training worker 8: 0:00:47.991716\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000518\n",
            "Local Step 04: Test Loss: 3.627113644, Test Accuracy: 15.300\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.772443455, Training Accuracy: 11.792\n",
            "Worker 1, [02/18]: Training Loss: 3.639537614, Training Accuracy: 13.728\n",
            "Worker 1, [03/18]: Training Loss: 3.725295962, Training Accuracy: 12.640\n",
            "Worker 1, [04/18]: Training Loss: 3.616108632, Training Accuracy: 14.384\n",
            "Worker 1, [05/18]: Training Loss: 3.671924630, Training Accuracy: 13.792\n",
            "Worker 1, [06/18]: Training Loss: 3.581162078, Training Accuracy: 14.832\n",
            "Worker 1, [07/18]: Training Loss: 3.641420710, Training Accuracy: 14.400\n",
            "Worker 1, [08/18]: Training Loss: 3.512950683, Training Accuracy: 16.000\n",
            "Worker 1, [09/18]: Training Loss: 3.574302357, Training Accuracy: 15.424\n",
            "Worker 1, [10/18]: Training Loss: 3.495382662, Training Accuracy: 16.672\n",
            "Worker 1, [11/18]: Training Loss: 3.512757423, Training Accuracy: 15.856\n",
            "Worker 1, [12/18]: Training Loss: 3.416871976, Training Accuracy: 17.856\n",
            "Worker 1, [13/18]: Training Loss: 3.454502548, Training Accuracy: 17.888\n",
            "Worker 1, [14/18]: Training Loss: 3.368409665, Training Accuracy: 17.920\n",
            "Worker 1, [15/18]: Training Loss: 3.420349863, Training Accuracy: 18.144\n",
            "Worker 1, [16/18]: Training Loss: 3.356669329, Training Accuracy: 19.456\n",
            "Worker 1, [17/18]: Training Loss: 3.410301625, Training Accuracy: 19.168\n",
            "Worker 1, [18/18]: Training Loss: 3.359290048, Training Accuracy: 19.472\n",
            "Time taken for training worker 1: 0:00:48.807998\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.704172988, Training Accuracy: 13.216\n",
            "Worker 2, [02/18]: Training Loss: 3.545365660, Training Accuracy: 14.576\n",
            "Worker 2, [03/18]: Training Loss: 3.647934804, Training Accuracy: 13.184\n",
            "Worker 2, [04/18]: Training Loss: 3.523256640, Training Accuracy: 15.088\n",
            "Worker 2, [05/18]: Training Loss: 3.595493579, Training Accuracy: 14.352\n",
            "Worker 2, [06/18]: Training Loss: 3.487607924, Training Accuracy: 16.224\n",
            "Worker 2, [07/18]: Training Loss: 3.535970547, Training Accuracy: 14.304\n",
            "Worker 2, [08/18]: Training Loss: 3.444009109, Training Accuracy: 16.208\n",
            "Worker 2, [09/18]: Training Loss: 3.482454353, Training Accuracy: 15.712\n",
            "Worker 2, [10/18]: Training Loss: 3.378177112, Training Accuracy: 18.032\n",
            "Worker 2, [11/18]: Training Loss: 3.428943622, Training Accuracy: 16.560\n",
            "Worker 2, [12/18]: Training Loss: 3.333502962, Training Accuracy: 18.688\n",
            "Worker 2, [13/18]: Training Loss: 3.360821366, Training Accuracy: 18.336\n",
            "Worker 2, [14/18]: Training Loss: 3.276292059, Training Accuracy: 19.808\n",
            "Worker 2, [15/18]: Training Loss: 3.317794810, Training Accuracy: 19.664\n",
            "Worker 2, [16/18]: Training Loss: 3.251319596, Training Accuracy: 20.160\n",
            "Worker 2, [17/18]: Training Loss: 3.305764592, Training Accuracy: 19.520\n",
            "Worker 2, [18/18]: Training Loss: 3.244649165, Training Accuracy: 20.192\n",
            "Time taken for training worker 2: 0:00:46.953558\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.677871653, Training Accuracy: 13.280\n",
            "Worker 3, [02/18]: Training Loss: 3.537854304, Training Accuracy: 15.520\n",
            "Worker 3, [03/18]: Training Loss: 3.649299135, Training Accuracy: 13.616\n",
            "Worker 3, [04/18]: Training Loss: 3.554089848, Training Accuracy: 15.168\n",
            "Worker 3, [05/18]: Training Loss: 3.594923983, Training Accuracy: 14.608\n",
            "Worker 3, [06/18]: Training Loss: 3.496897274, Training Accuracy: 15.968\n",
            "Worker 3, [07/18]: Training Loss: 3.562660872, Training Accuracy: 15.232\n",
            "Worker 3, [08/18]: Training Loss: 3.449955025, Training Accuracy: 16.640\n",
            "Worker 3, [09/18]: Training Loss: 3.517693060, Training Accuracy: 15.936\n",
            "Worker 3, [10/18]: Training Loss: 3.413353730, Training Accuracy: 17.520\n",
            "Worker 3, [11/18]: Training Loss: 3.445125220, Training Accuracy: 17.408\n",
            "Worker 3, [12/18]: Training Loss: 3.353980802, Training Accuracy: 18.384\n",
            "Worker 3, [13/18]: Training Loss: 3.388333257, Training Accuracy: 18.960\n",
            "Worker 3, [14/18]: Training Loss: 3.316507646, Training Accuracy: 19.680\n",
            "Worker 3, [15/18]: Training Loss: 3.340193517, Training Accuracy: 20.016\n",
            "Worker 3, [16/18]: Training Loss: 3.284693192, Training Accuracy: 20.240\n",
            "Worker 3, [17/18]: Training Loss: 3.330649590, Training Accuracy: 20.800\n",
            "Worker 3, [18/18]: Training Loss: 3.290329539, Training Accuracy: 20.992\n",
            "Time taken for training worker 3: 0:00:48.320703\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.672121503, Training Accuracy: 13.632\n",
            "Worker 4, [02/18]: Training Loss: 3.535739760, Training Accuracy: 16.336\n",
            "Worker 4, [03/18]: Training Loss: 3.634036512, Training Accuracy: 14.064\n",
            "Worker 4, [04/18]: Training Loss: 3.538833664, Training Accuracy: 15.520\n",
            "Worker 4, [05/18]: Training Loss: 3.602691794, Training Accuracy: 14.224\n",
            "Worker 4, [06/18]: Training Loss: 3.492747312, Training Accuracy: 16.288\n",
            "Worker 4, [07/18]: Training Loss: 3.562141185, Training Accuracy: 14.768\n",
            "Worker 4, [08/18]: Training Loss: 3.455115788, Training Accuracy: 16.576\n",
            "Worker 4, [09/18]: Training Loss: 3.494194877, Training Accuracy: 15.776\n",
            "Worker 4, [10/18]: Training Loss: 3.394872563, Training Accuracy: 18.624\n",
            "Worker 4, [11/18]: Training Loss: 3.423480029, Training Accuracy: 17.632\n",
            "Worker 4, [12/18]: Training Loss: 3.339607514, Training Accuracy: 19.248\n",
            "Worker 4, [13/18]: Training Loss: 3.382750981, Training Accuracy: 18.240\n",
            "Worker 4, [14/18]: Training Loss: 3.298477399, Training Accuracy: 19.856\n",
            "Worker 4, [15/18]: Training Loss: 3.331354470, Training Accuracy: 18.848\n",
            "Worker 4, [16/18]: Training Loss: 3.271626292, Training Accuracy: 20.256\n",
            "Worker 4, [17/18]: Training Loss: 3.313478803, Training Accuracy: 20.224\n",
            "Worker 4, [18/18]: Training Loss: 3.280619424, Training Accuracy: 20.656\n",
            "Time taken for training worker 4: 0:00:48.118010\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.676649150, Training Accuracy: 14.144\n",
            "Worker 5, [02/18]: Training Loss: 3.514206558, Training Accuracy: 15.744\n",
            "Worker 5, [03/18]: Training Loss: 3.631593522, Training Accuracy: 13.872\n",
            "Worker 5, [04/18]: Training Loss: 3.521555137, Training Accuracy: 15.840\n",
            "Worker 5, [05/18]: Training Loss: 3.589628385, Training Accuracy: 14.704\n",
            "Worker 5, [06/18]: Training Loss: 3.489732531, Training Accuracy: 16.320\n",
            "Worker 5, [07/18]: Training Loss: 3.564231238, Training Accuracy: 15.152\n",
            "Worker 5, [08/18]: Training Loss: 3.444108440, Training Accuracy: 17.184\n",
            "Worker 5, [09/18]: Training Loss: 3.490814029, Training Accuracy: 16.880\n",
            "Worker 5, [10/18]: Training Loss: 3.395312463, Training Accuracy: 18.000\n",
            "Worker 5, [11/18]: Training Loss: 3.426423606, Training Accuracy: 17.824\n",
            "Worker 5, [12/18]: Training Loss: 3.346820483, Training Accuracy: 19.120\n",
            "Worker 5, [13/18]: Training Loss: 3.362548940, Training Accuracy: 19.072\n",
            "Worker 5, [14/18]: Training Loss: 3.286002865, Training Accuracy: 19.856\n",
            "Worker 5, [15/18]: Training Loss: 3.325087895, Training Accuracy: 19.760\n",
            "Worker 5, [16/18]: Training Loss: 3.264947395, Training Accuracy: 20.608\n",
            "Worker 5, [17/18]: Training Loss: 3.301852195, Training Accuracy: 20.224\n",
            "Worker 5, [18/18]: Training Loss: 3.262597349, Training Accuracy: 20.992\n",
            "Time taken for training worker 5: 0:00:47.531600\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.669590646, Training Accuracy: 13.456\n",
            "Worker 6, [02/18]: Training Loss: 3.518739080, Training Accuracy: 15.520\n",
            "Worker 6, [03/18]: Training Loss: 3.629473248, Training Accuracy: 13.920\n",
            "Worker 6, [04/18]: Training Loss: 3.527480629, Training Accuracy: 15.264\n",
            "Worker 6, [05/18]: Training Loss: 3.604072962, Training Accuracy: 14.432\n",
            "Worker 6, [06/18]: Training Loss: 3.491285898, Training Accuracy: 16.048\n",
            "Worker 6, [07/18]: Training Loss: 3.554582934, Training Accuracy: 14.592\n",
            "Worker 6, [08/18]: Training Loss: 3.447058597, Training Accuracy: 16.320\n",
            "Worker 6, [09/18]: Training Loss: 3.495512541, Training Accuracy: 15.888\n",
            "Worker 6, [10/18]: Training Loss: 3.398027294, Training Accuracy: 17.184\n",
            "Worker 6, [11/18]: Training Loss: 3.449155421, Training Accuracy: 17.344\n",
            "Worker 6, [12/18]: Training Loss: 3.337266243, Training Accuracy: 18.480\n",
            "Worker 6, [13/18]: Training Loss: 3.375272325, Training Accuracy: 18.384\n",
            "Worker 6, [14/18]: Training Loss: 3.295586231, Training Accuracy: 19.696\n",
            "Worker 6, [15/18]: Training Loss: 3.326988938, Training Accuracy: 20.288\n",
            "Worker 6, [16/18]: Training Loss: 3.268474591, Training Accuracy: 20.352\n",
            "Worker 6, [17/18]: Training Loss: 3.301853411, Training Accuracy: 20.176\n",
            "Worker 6, [18/18]: Training Loss: 3.282674344, Training Accuracy: 20.816\n",
            "Time taken for training worker 6: 0:00:48.823545\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.675036384, Training Accuracy: 13.120\n",
            "Worker 7, [02/18]: Training Loss: 3.554867056, Training Accuracy: 15.152\n",
            "Worker 7, [03/18]: Training Loss: 3.649848167, Training Accuracy: 13.456\n",
            "Worker 7, [04/18]: Training Loss: 3.549938732, Training Accuracy: 15.008\n",
            "Worker 7, [05/18]: Training Loss: 3.639433807, Training Accuracy: 13.440\n",
            "Worker 7, [06/18]: Training Loss: 3.514109551, Training Accuracy: 15.408\n",
            "Worker 7, [07/18]: Training Loss: 3.587127659, Training Accuracy: 14.288\n",
            "Worker 7, [08/18]: Training Loss: 3.470423080, Training Accuracy: 16.272\n",
            "Worker 7, [09/18]: Training Loss: 3.525309976, Training Accuracy: 15.664\n",
            "Worker 7, [10/18]: Training Loss: 3.414680661, Training Accuracy: 17.536\n",
            "Worker 7, [11/18]: Training Loss: 3.449373515, Training Accuracy: 16.368\n",
            "Worker 7, [12/18]: Training Loss: 3.377111761, Training Accuracy: 18.416\n",
            "Worker 7, [13/18]: Training Loss: 3.404804561, Training Accuracy: 17.632\n",
            "Worker 7, [14/18]: Training Loss: 3.309195837, Training Accuracy: 18.864\n",
            "Worker 7, [15/18]: Training Loss: 3.339764376, Training Accuracy: 19.056\n",
            "Worker 7, [16/18]: Training Loss: 3.298546180, Training Accuracy: 19.840\n",
            "Worker 7, [17/18]: Training Loss: 3.339758537, Training Accuracy: 19.376\n",
            "Worker 7, [18/18]: Training Loss: 3.306349462, Training Accuracy: 19.392\n",
            "Time taken for training worker 7: 0:00:47.843839\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.676979805, Training Accuracy: 13.600\n",
            "Worker 8, [02/18]: Training Loss: 3.560135082, Training Accuracy: 15.008\n",
            "Worker 8, [03/18]: Training Loss: 3.663367668, Training Accuracy: 12.848\n",
            "Worker 8, [04/18]: Training Loss: 3.543945945, Training Accuracy: 15.200\n",
            "Worker 8, [05/18]: Training Loss: 3.601845021, Training Accuracy: 14.048\n",
            "Worker 8, [06/18]: Training Loss: 3.498158428, Training Accuracy: 16.176\n",
            "Worker 8, [07/18]: Training Loss: 3.578204992, Training Accuracy: 14.096\n",
            "Worker 8, [08/18]: Training Loss: 3.452584138, Training Accuracy: 16.080\n",
            "Worker 8, [09/18]: Training Loss: 3.495288744, Training Accuracy: 15.776\n",
            "Worker 8, [10/18]: Training Loss: 3.399412269, Training Accuracy: 17.120\n",
            "Worker 8, [11/18]: Training Loss: 3.454103623, Training Accuracy: 16.784\n",
            "Worker 8, [12/18]: Training Loss: 3.357617935, Training Accuracy: 17.936\n",
            "Worker 8, [13/18]: Training Loss: 3.387760449, Training Accuracy: 17.872\n",
            "Worker 8, [14/18]: Training Loss: 3.301269483, Training Accuracy: 19.376\n",
            "Worker 8, [15/18]: Training Loss: 3.352009170, Training Accuracy: 18.768\n",
            "Worker 8, [16/18]: Training Loss: 3.280782607, Training Accuracy: 19.664\n",
            "Worker 8, [17/18]: Training Loss: 3.321139929, Training Accuracy: 19.440\n",
            "Worker 8, [18/18]: Training Loss: 3.292861564, Training Accuracy: 19.744\n",
            "Time taken for training worker 8: 0:00:47.191232\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000520\n",
            "Local Step 05: Test Loss: 3.468031087, Test Accuracy: 17.760\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.560485784, Training Accuracy: 15.856\n",
            "Worker 1, [02/18]: Training Loss: 3.546879744, Training Accuracy: 16.288\n",
            "Worker 1, [03/18]: Training Loss: 3.411298835, Training Accuracy: 19.344\n",
            "Worker 1, [04/18]: Training Loss: 3.393273835, Training Accuracy: 18.672\n",
            "Worker 1, [05/18]: Training Loss: 3.412780698, Training Accuracy: 18.672\n",
            "Worker 1, [06/18]: Training Loss: 3.383568435, Training Accuracy: 18.688\n",
            "Worker 1, [07/18]: Training Loss: 3.432933309, Training Accuracy: 18.336\n",
            "Worker 1, [08/18]: Training Loss: 3.425076455, Training Accuracy: 18.496\n",
            "Worker 1, [09/18]: Training Loss: 3.462940931, Training Accuracy: 17.504\n",
            "Worker 1, [10/18]: Training Loss: 3.442978822, Training Accuracy: 17.376\n",
            "Worker 1, [11/18]: Training Loss: 3.505180488, Training Accuracy: 16.640\n",
            "Worker 1, [12/18]: Training Loss: 3.455464392, Training Accuracy: 16.976\n",
            "Worker 1, [13/18]: Training Loss: 3.522971601, Training Accuracy: 15.824\n",
            "Worker 1, [14/18]: Training Loss: 3.459791478, Training Accuracy: 17.504\n",
            "Worker 1, [15/18]: Training Loss: 3.536838342, Training Accuracy: 15.632\n",
            "Worker 1, [16/18]: Training Loss: 3.470770021, Training Accuracy: 16.400\n",
            "Worker 1, [17/18]: Training Loss: 3.547255908, Training Accuracy: 15.424\n",
            "Worker 1, [18/18]: Training Loss: 3.471146547, Training Accuracy: 16.640\n",
            "Time taken for training worker 1: 0:00:46.761363\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.487860003, Training Accuracy: 17.440\n",
            "Worker 2, [02/18]: Training Loss: 3.475534334, Training Accuracy: 17.504\n",
            "Worker 2, [03/18]: Training Loss: 3.314074400, Training Accuracy: 19.536\n",
            "Worker 2, [04/18]: Training Loss: 3.278918763, Training Accuracy: 20.112\n",
            "Worker 2, [05/18]: Training Loss: 3.311773449, Training Accuracy: 19.328\n",
            "Worker 2, [06/18]: Training Loss: 3.283696668, Training Accuracy: 19.168\n",
            "Worker 2, [07/18]: Training Loss: 3.346768321, Training Accuracy: 18.480\n",
            "Worker 2, [08/18]: Training Loss: 3.339558961, Training Accuracy: 18.096\n",
            "Worker 2, [09/18]: Training Loss: 3.379130322, Training Accuracy: 17.312\n",
            "Worker 2, [10/18]: Training Loss: 3.355968149, Training Accuracy: 17.664\n",
            "Worker 2, [11/18]: Training Loss: 3.424183366, Training Accuracy: 17.456\n",
            "Worker 2, [12/18]: Training Loss: 3.374565922, Training Accuracy: 16.976\n",
            "Worker 2, [13/18]: Training Loss: 3.446856445, Training Accuracy: 15.696\n",
            "Worker 2, [14/18]: Training Loss: 3.381059433, Training Accuracy: 17.664\n",
            "Worker 2, [15/18]: Training Loss: 3.455196933, Training Accuracy: 16.544\n",
            "Worker 2, [16/18]: Training Loss: 3.379287275, Training Accuracy: 17.472\n",
            "Worker 2, [17/18]: Training Loss: 3.444885967, Training Accuracy: 16.672\n",
            "Worker 2, [18/18]: Training Loss: 3.381982786, Training Accuracy: 17.952\n",
            "Time taken for training worker 2: 0:00:46.996353\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.468113615, Training Accuracy: 18.448\n",
            "Worker 3, [02/18]: Training Loss: 3.468860575, Training Accuracy: 18.496\n",
            "Worker 3, [03/18]: Training Loss: 3.334345236, Training Accuracy: 19.712\n",
            "Worker 3, [04/18]: Training Loss: 3.299218740, Training Accuracy: 20.960\n",
            "Worker 3, [05/18]: Training Loss: 3.331046905, Training Accuracy: 19.808\n",
            "Worker 3, [06/18]: Training Loss: 3.310116729, Training Accuracy: 19.728\n",
            "Worker 3, [07/18]: Training Loss: 3.378439568, Training Accuracy: 19.152\n",
            "Worker 3, [08/18]: Training Loss: 3.336327898, Training Accuracy: 19.024\n",
            "Worker 3, [09/18]: Training Loss: 3.388224485, Training Accuracy: 18.208\n",
            "Worker 3, [10/18]: Training Loss: 3.354154436, Training Accuracy: 18.368\n",
            "Worker 3, [11/18]: Training Loss: 3.434517388, Training Accuracy: 17.808\n",
            "Worker 3, [12/18]: Training Loss: 3.384552243, Training Accuracy: 17.728\n",
            "Worker 3, [13/18]: Training Loss: 3.463262249, Training Accuracy: 16.800\n",
            "Worker 3, [14/18]: Training Loss: 3.408095520, Training Accuracy: 17.808\n",
            "Worker 3, [15/18]: Training Loss: 3.479951951, Training Accuracy: 16.960\n",
            "Worker 3, [16/18]: Training Loss: 3.404402078, Training Accuracy: 16.976\n",
            "Worker 3, [17/18]: Training Loss: 3.455622023, Training Accuracy: 16.672\n",
            "Worker 3, [18/18]: Training Loss: 3.386984353, Training Accuracy: 17.712\n",
            "Time taken for training worker 3: 0:00:47.156061\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.464558183, Training Accuracy: 17.648\n",
            "Worker 4, [02/18]: Training Loss: 3.452613850, Training Accuracy: 18.176\n",
            "Worker 4, [03/18]: Training Loss: 3.320432858, Training Accuracy: 20.032\n",
            "Worker 4, [04/18]: Training Loss: 3.286403748, Training Accuracy: 20.624\n",
            "Worker 4, [05/18]: Training Loss: 3.324119762, Training Accuracy: 19.840\n",
            "Worker 4, [06/18]: Training Loss: 3.306454515, Training Accuracy: 19.664\n",
            "Worker 4, [07/18]: Training Loss: 3.339793164, Training Accuracy: 19.216\n",
            "Worker 4, [08/18]: Training Loss: 3.332806782, Training Accuracy: 19.376\n",
            "Worker 4, [09/18]: Training Loss: 3.385448684, Training Accuracy: 17.840\n",
            "Worker 4, [10/18]: Training Loss: 3.353279897, Training Accuracy: 18.544\n",
            "Worker 4, [11/18]: Training Loss: 3.430777304, Training Accuracy: 17.184\n",
            "Worker 4, [12/18]: Training Loss: 3.388636329, Training Accuracy: 18.320\n",
            "Worker 4, [13/18]: Training Loss: 3.456291084, Training Accuracy: 17.056\n",
            "Worker 4, [14/18]: Training Loss: 3.388605631, Training Accuracy: 18.096\n",
            "Worker 4, [15/18]: Training Loss: 3.464126283, Training Accuracy: 16.928\n",
            "Worker 4, [16/18]: Training Loss: 3.407056244, Training Accuracy: 17.424\n",
            "Worker 4, [17/18]: Training Loss: 3.464668707, Training Accuracy: 16.416\n",
            "Worker 4, [18/18]: Training Loss: 3.391879369, Training Accuracy: 17.456\n",
            "Time taken for training worker 4: 0:00:47.674965\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.465390517, Training Accuracy: 18.464\n",
            "Worker 5, [02/18]: Training Loss: 3.468605039, Training Accuracy: 17.840\n",
            "Worker 5, [03/18]: Training Loss: 3.318336360, Training Accuracy: 19.696\n",
            "Worker 5, [04/18]: Training Loss: 3.287064049, Training Accuracy: 19.520\n",
            "Worker 5, [05/18]: Training Loss: 3.318747457, Training Accuracy: 20.288\n",
            "Worker 5, [06/18]: Training Loss: 3.306206338, Training Accuracy: 19.888\n",
            "Worker 5, [07/18]: Training Loss: 3.348425999, Training Accuracy: 19.344\n",
            "Worker 5, [08/18]: Training Loss: 3.317319955, Training Accuracy: 19.632\n",
            "Worker 5, [09/18]: Training Loss: 3.382952072, Training Accuracy: 18.560\n",
            "Worker 5, [10/18]: Training Loss: 3.349063883, Training Accuracy: 18.768\n",
            "Worker 5, [11/18]: Training Loss: 3.420329658, Training Accuracy: 17.120\n",
            "Worker 5, [12/18]: Training Loss: 3.394787501, Training Accuracy: 17.616\n",
            "Worker 5, [13/18]: Training Loss: 3.452253636, Training Accuracy: 16.336\n",
            "Worker 5, [14/18]: Training Loss: 3.396611982, Training Accuracy: 17.968\n",
            "Worker 5, [15/18]: Training Loss: 3.445120352, Training Accuracy: 17.120\n",
            "Worker 5, [16/18]: Training Loss: 3.403703746, Training Accuracy: 17.600\n",
            "Worker 5, [17/18]: Training Loss: 3.446141637, Training Accuracy: 16.272\n",
            "Worker 5, [18/18]: Training Loss: 3.392854985, Training Accuracy: 17.600\n",
            "Time taken for training worker 5: 0:00:47.978370\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.447976353, Training Accuracy: 18.320\n",
            "Worker 6, [02/18]: Training Loss: 3.440897170, Training Accuracy: 18.480\n",
            "Worker 6, [03/18]: Training Loss: 3.311413300, Training Accuracy: 20.192\n",
            "Worker 6, [04/18]: Training Loss: 3.286492868, Training Accuracy: 20.272\n",
            "Worker 6, [05/18]: Training Loss: 3.318044137, Training Accuracy: 19.040\n",
            "Worker 6, [06/18]: Training Loss: 3.307538054, Training Accuracy: 19.488\n",
            "Worker 6, [07/18]: Training Loss: 3.348168913, Training Accuracy: 18.656\n",
            "Worker 6, [08/18]: Training Loss: 3.313467162, Training Accuracy: 19.392\n",
            "Worker 6, [09/18]: Training Loss: 3.391049480, Training Accuracy: 17.568\n",
            "Worker 6, [10/18]: Training Loss: 3.345014161, Training Accuracy: 18.352\n",
            "Worker 6, [11/18]: Training Loss: 3.423493001, Training Accuracy: 17.072\n",
            "Worker 6, [12/18]: Training Loss: 3.389160098, Training Accuracy: 17.424\n",
            "Worker 6, [13/18]: Training Loss: 3.452454499, Training Accuracy: 16.576\n",
            "Worker 6, [14/18]: Training Loss: 3.390937085, Training Accuracy: 17.568\n",
            "Worker 6, [15/18]: Training Loss: 3.446103412, Training Accuracy: 17.136\n",
            "Worker 6, [16/18]: Training Loss: 3.387575651, Training Accuracy: 17.136\n",
            "Worker 6, [17/18]: Training Loss: 3.454119466, Training Accuracy: 16.784\n",
            "Worker 6, [18/18]: Training Loss: 3.385832697, Training Accuracy: 17.152\n",
            "Time taken for training worker 6: 0:00:47.906541\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.459651008, Training Accuracy: 17.488\n",
            "Worker 7, [02/18]: Training Loss: 3.456429907, Training Accuracy: 17.568\n",
            "Worker 7, [03/18]: Training Loss: 3.334809384, Training Accuracy: 19.248\n",
            "Worker 7, [04/18]: Training Loss: 3.315156119, Training Accuracy: 19.568\n",
            "Worker 7, [05/18]: Training Loss: 3.334964645, Training Accuracy: 19.072\n",
            "Worker 7, [06/18]: Training Loss: 3.308520358, Training Accuracy: 19.152\n",
            "Worker 7, [07/18]: Training Loss: 3.359528841, Training Accuracy: 18.688\n",
            "Worker 7, [08/18]: Training Loss: 3.343389299, Training Accuracy: 18.448\n",
            "Worker 7, [09/18]: Training Loss: 3.410897289, Training Accuracy: 17.232\n",
            "Worker 7, [10/18]: Training Loss: 3.375442884, Training Accuracy: 17.968\n",
            "Worker 7, [11/18]: Training Loss: 3.450952863, Training Accuracy: 16.288\n",
            "Worker 7, [12/18]: Training Loss: 3.384837036, Training Accuracy: 17.632\n",
            "Worker 7, [13/18]: Training Loss: 3.466583520, Training Accuracy: 15.952\n",
            "Worker 7, [14/18]: Training Loss: 3.409837419, Training Accuracy: 17.120\n",
            "Worker 7, [15/18]: Training Loss: 3.494244245, Training Accuracy: 15.552\n",
            "Worker 7, [16/18]: Training Loss: 3.432208601, Training Accuracy: 16.720\n",
            "Worker 7, [17/18]: Training Loss: 3.483896725, Training Accuracy: 16.208\n",
            "Worker 7, [18/18]: Training Loss: 3.391928247, Training Accuracy: 17.680\n",
            "Time taken for training worker 7: 0:00:47.739539\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.471486196, Training Accuracy: 17.408\n",
            "Worker 8, [02/18]: Training Loss: 3.467649350, Training Accuracy: 17.328\n",
            "Worker 8, [03/18]: Training Loss: 3.333813251, Training Accuracy: 19.280\n",
            "Worker 8, [04/18]: Training Loss: 3.306391964, Training Accuracy: 19.632\n",
            "Worker 8, [05/18]: Training Loss: 3.335922261, Training Accuracy: 18.880\n",
            "Worker 8, [06/18]: Training Loss: 3.319050137, Training Accuracy: 18.992\n",
            "Worker 8, [07/18]: Training Loss: 3.359423265, Training Accuracy: 17.872\n",
            "Worker 8, [08/18]: Training Loss: 3.341764024, Training Accuracy: 18.000\n",
            "Worker 8, [09/18]: Training Loss: 3.400516680, Training Accuracy: 17.728\n",
            "Worker 8, [10/18]: Training Loss: 3.375274872, Training Accuracy: 17.808\n",
            "Worker 8, [11/18]: Training Loss: 3.426807270, Training Accuracy: 16.928\n",
            "Worker 8, [12/18]: Training Loss: 3.370891656, Training Accuracy: 17.376\n",
            "Worker 8, [13/18]: Training Loss: 3.483125368, Training Accuracy: 15.584\n",
            "Worker 8, [14/18]: Training Loss: 3.386959460, Training Accuracy: 17.792\n",
            "Worker 8, [15/18]: Training Loss: 3.466886209, Training Accuracy: 15.840\n",
            "Worker 8, [16/18]: Training Loss: 3.419200201, Training Accuracy: 16.976\n",
            "Worker 8, [17/18]: Training Loss: 3.470865033, Training Accuracy: 16.048\n",
            "Worker 8, [18/18]: Training Loss: 3.401220064, Training Accuracy: 17.024\n",
            "Time taken for training worker 8: 0:00:48.373168\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000513\n",
            "Local Step 06: Test Loss: 3.364777163, Test Accuracy: 20.030\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.611082325, Training Accuracy: 15.008\n",
            "Worker 1, [02/18]: Training Loss: 3.485490288, Training Accuracy: 16.080\n",
            "Worker 1, [03/18]: Training Loss: 3.497577013, Training Accuracy: 16.224\n",
            "Worker 1, [04/18]: Training Loss: 3.399786857, Training Accuracy: 17.776\n",
            "Worker 1, [05/18]: Training Loss: 3.458076735, Training Accuracy: 16.576\n",
            "Worker 1, [06/18]: Training Loss: 3.368555174, Training Accuracy: 19.088\n",
            "Worker 1, [07/18]: Training Loss: 3.392508008, Training Accuracy: 18.192\n",
            "Worker 1, [08/18]: Training Loss: 3.316233002, Training Accuracy: 19.568\n",
            "Worker 1, [09/18]: Training Loss: 3.333272231, Training Accuracy: 18.768\n",
            "Worker 1, [10/18]: Training Loss: 3.252735656, Training Accuracy: 21.008\n",
            "Worker 1, [11/18]: Training Loss: 3.256385944, Training Accuracy: 20.336\n",
            "Worker 1, [12/18]: Training Loss: 3.189160481, Training Accuracy: 21.584\n",
            "Worker 1, [13/18]: Training Loss: 3.198155488, Training Accuracy: 21.888\n",
            "Worker 1, [14/18]: Training Loss: 3.127872997, Training Accuracy: 23.280\n",
            "Worker 1, [15/18]: Training Loss: 3.145805738, Training Accuracy: 23.184\n",
            "Worker 1, [16/18]: Training Loss: 3.087310336, Training Accuracy: 24.192\n",
            "Worker 1, [17/18]: Training Loss: 3.126295520, Training Accuracy: 24.048\n",
            "Worker 1, [18/18]: Training Loss: 3.092633668, Training Accuracy: 24.352\n",
            "Time taken for training worker 1: 0:00:48.339587\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.551734586, Training Accuracy: 15.360\n",
            "Worker 2, [02/18]: Training Loss: 3.429325488, Training Accuracy: 16.640\n",
            "Worker 2, [03/18]: Training Loss: 3.414983849, Training Accuracy: 17.248\n",
            "Worker 2, [04/18]: Training Loss: 3.313545962, Training Accuracy: 18.496\n",
            "Worker 2, [05/18]: Training Loss: 3.364025038, Training Accuracy: 18.544\n",
            "Worker 2, [06/18]: Training Loss: 3.302869918, Training Accuracy: 18.752\n",
            "Worker 2, [07/18]: Training Loss: 3.327673501, Training Accuracy: 19.152\n",
            "Worker 2, [08/18]: Training Loss: 3.244099719, Training Accuracy: 19.776\n",
            "Worker 2, [09/18]: Training Loss: 3.240273223, Training Accuracy: 20.688\n",
            "Worker 2, [10/18]: Training Loss: 3.162114496, Training Accuracy: 21.072\n",
            "Worker 2, [11/18]: Training Loss: 3.171228270, Training Accuracy: 21.376\n",
            "Worker 2, [12/18]: Training Loss: 3.100844583, Training Accuracy: 22.400\n",
            "Worker 2, [13/18]: Training Loss: 3.105840724, Training Accuracy: 22.272\n",
            "Worker 2, [14/18]: Training Loss: 3.029959029, Training Accuracy: 24.144\n",
            "Worker 2, [15/18]: Training Loss: 3.049272948, Training Accuracy: 23.392\n",
            "Worker 2, [16/18]: Training Loss: 2.989588339, Training Accuracy: 25.232\n",
            "Worker 2, [17/18]: Training Loss: 3.021366740, Training Accuracy: 24.720\n",
            "Worker 2, [18/18]: Training Loss: 2.988646716, Training Accuracy: 25.360\n",
            "Time taken for training worker 2: 0:00:47.728571\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.530816531, Training Accuracy: 16.112\n",
            "Worker 3, [02/18]: Training Loss: 3.400641164, Training Accuracy: 17.872\n",
            "Worker 3, [03/18]: Training Loss: 3.450055307, Training Accuracy: 16.576\n",
            "Worker 3, [04/18]: Training Loss: 3.358095276, Training Accuracy: 18.512\n",
            "Worker 3, [05/18]: Training Loss: 3.366413722, Training Accuracy: 18.320\n",
            "Worker 3, [06/18]: Training Loss: 3.284906713, Training Accuracy: 19.712\n",
            "Worker 3, [07/18]: Training Loss: 3.337622518, Training Accuracy: 18.960\n",
            "Worker 3, [08/18]: Training Loss: 3.257419066, Training Accuracy: 20.160\n",
            "Worker 3, [09/18]: Training Loss: 3.271416260, Training Accuracy: 20.400\n",
            "Worker 3, [10/18]: Training Loss: 3.164386628, Training Accuracy: 21.728\n",
            "Worker 3, [11/18]: Training Loss: 3.202430139, Training Accuracy: 21.984\n",
            "Worker 3, [12/18]: Training Loss: 3.102829481, Training Accuracy: 24.016\n",
            "Worker 3, [13/18]: Training Loss: 3.124374959, Training Accuracy: 22.928\n",
            "Worker 3, [14/18]: Training Loss: 3.047568460, Training Accuracy: 24.768\n",
            "Worker 3, [15/18]: Training Loss: 3.070624476, Training Accuracy: 24.272\n",
            "Worker 3, [16/18]: Training Loss: 3.011181406, Training Accuracy: 25.920\n",
            "Worker 3, [17/18]: Training Loss: 3.053442135, Training Accuracy: 25.568\n",
            "Worker 3, [18/18]: Training Loss: 3.007292738, Training Accuracy: 26.048\n",
            "Time taken for training worker 3: 0:00:48.982672\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.514569905, Training Accuracy: 16.512\n",
            "Worker 4, [02/18]: Training Loss: 3.372778014, Training Accuracy: 18.288\n",
            "Worker 4, [03/18]: Training Loss: 3.431495360, Training Accuracy: 17.456\n",
            "Worker 4, [04/18]: Training Loss: 3.362703944, Training Accuracy: 18.320\n",
            "Worker 4, [05/18]: Training Loss: 3.383284712, Training Accuracy: 18.080\n",
            "Worker 4, [06/18]: Training Loss: 3.298684626, Training Accuracy: 19.088\n",
            "Worker 4, [07/18]: Training Loss: 3.314647718, Training Accuracy: 19.312\n",
            "Worker 4, [08/18]: Training Loss: 3.230996086, Training Accuracy: 20.576\n",
            "Worker 4, [09/18]: Training Loss: 3.264271724, Training Accuracy: 19.968\n",
            "Worker 4, [10/18]: Training Loss: 3.180066359, Training Accuracy: 21.136\n",
            "Worker 4, [11/18]: Training Loss: 3.176058716, Training Accuracy: 22.544\n",
            "Worker 4, [12/18]: Training Loss: 3.088100903, Training Accuracy: 22.656\n",
            "Worker 4, [13/18]: Training Loss: 3.111972797, Training Accuracy: 23.344\n",
            "Worker 4, [14/18]: Training Loss: 3.039368269, Training Accuracy: 24.848\n",
            "Worker 4, [15/18]: Training Loss: 3.053420271, Training Accuracy: 24.256\n",
            "Worker 4, [16/18]: Training Loss: 3.002853450, Training Accuracy: 25.280\n",
            "Worker 4, [17/18]: Training Loss: 3.027787909, Training Accuracy: 25.424\n",
            "Worker 4, [18/18]: Training Loss: 2.998488499, Training Accuracy: 25.888\n",
            "Time taken for training worker 4: 0:00:48.785164\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.547090589, Training Accuracy: 16.048\n",
            "Worker 5, [02/18]: Training Loss: 3.419998704, Training Accuracy: 18.208\n",
            "Worker 5, [03/18]: Training Loss: 3.431639732, Training Accuracy: 17.776\n",
            "Worker 5, [04/18]: Training Loss: 3.367744205, Training Accuracy: 18.736\n",
            "Worker 5, [05/18]: Training Loss: 3.385995763, Training Accuracy: 17.024\n",
            "Worker 5, [06/18]: Training Loss: 3.303820985, Training Accuracy: 19.536\n",
            "Worker 5, [07/18]: Training Loss: 3.322080517, Training Accuracy: 19.680\n",
            "Worker 5, [08/18]: Training Loss: 3.229355150, Training Accuracy: 20.192\n",
            "Worker 5, [09/18]: Training Loss: 3.274745457, Training Accuracy: 20.000\n",
            "Worker 5, [10/18]: Training Loss: 3.180374075, Training Accuracy: 22.160\n",
            "Worker 5, [11/18]: Training Loss: 3.206602710, Training Accuracy: 21.552\n",
            "Worker 5, [12/18]: Training Loss: 3.116757510, Training Accuracy: 22.544\n",
            "Worker 5, [13/18]: Training Loss: 3.108844081, Training Accuracy: 23.328\n",
            "Worker 5, [14/18]: Training Loss: 3.048853806, Training Accuracy: 23.920\n",
            "Worker 5, [15/18]: Training Loss: 3.075444346, Training Accuracy: 24.240\n",
            "Worker 5, [16/18]: Training Loss: 3.011870156, Training Accuracy: 25.168\n",
            "Worker 5, [17/18]: Training Loss: 3.051343947, Training Accuracy: 24.336\n",
            "Worker 5, [18/18]: Training Loss: 3.005546188, Training Accuracy: 25.248\n",
            "Time taken for training worker 5: 0:00:48.767679\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.527425036, Training Accuracy: 15.584\n",
            "Worker 6, [02/18]: Training Loss: 3.379952041, Training Accuracy: 17.728\n",
            "Worker 6, [03/18]: Training Loss: 3.405112116, Training Accuracy: 17.136\n",
            "Worker 6, [04/18]: Training Loss: 3.346362450, Training Accuracy: 18.720\n",
            "Worker 6, [05/18]: Training Loss: 3.378436906, Training Accuracy: 17.408\n",
            "Worker 6, [06/18]: Training Loss: 3.276944552, Training Accuracy: 19.760\n",
            "Worker 6, [07/18]: Training Loss: 3.319732846, Training Accuracy: 18.240\n",
            "Worker 6, [08/18]: Training Loss: 3.228385135, Training Accuracy: 20.736\n",
            "Worker 6, [09/18]: Training Loss: 3.250538704, Training Accuracy: 20.224\n",
            "Worker 6, [10/18]: Training Loss: 3.178804680, Training Accuracy: 21.248\n",
            "Worker 6, [11/18]: Training Loss: 3.183538544, Training Accuracy: 21.296\n",
            "Worker 6, [12/18]: Training Loss: 3.099631288, Training Accuracy: 22.752\n",
            "Worker 6, [13/18]: Training Loss: 3.120449957, Training Accuracy: 21.904\n",
            "Worker 6, [14/18]: Training Loss: 3.047121337, Training Accuracy: 24.368\n",
            "Worker 6, [15/18]: Training Loss: 3.060184080, Training Accuracy: 24.160\n",
            "Worker 6, [16/18]: Training Loss: 3.005056028, Training Accuracy: 24.368\n",
            "Worker 6, [17/18]: Training Loss: 3.043747812, Training Accuracy: 24.032\n",
            "Worker 6, [18/18]: Training Loss: 3.010117331, Training Accuracy: 25.072\n",
            "Time taken for training worker 6: 0:00:48.290980\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.543312039, Training Accuracy: 15.632\n",
            "Worker 7, [02/18]: Training Loss: 3.404537488, Training Accuracy: 17.200\n",
            "Worker 7, [03/18]: Training Loss: 3.477566512, Training Accuracy: 16.032\n",
            "Worker 7, [04/18]: Training Loss: 3.367830517, Training Accuracy: 18.320\n",
            "Worker 7, [05/18]: Training Loss: 3.406935775, Training Accuracy: 17.472\n",
            "Worker 7, [06/18]: Training Loss: 3.312308954, Training Accuracy: 18.640\n",
            "Worker 7, [07/18]: Training Loss: 3.346409956, Training Accuracy: 18.672\n",
            "Worker 7, [08/18]: Training Loss: 3.275219219, Training Accuracy: 19.744\n",
            "Worker 7, [09/18]: Training Loss: 3.298919089, Training Accuracy: 19.680\n",
            "Worker 7, [10/18]: Training Loss: 3.178560549, Training Accuracy: 21.392\n",
            "Worker 7, [11/18]: Training Loss: 3.225108015, Training Accuracy: 20.272\n",
            "Worker 7, [12/18]: Training Loss: 3.124258915, Training Accuracy: 22.368\n",
            "Worker 7, [13/18]: Training Loss: 3.133203774, Training Accuracy: 22.256\n",
            "Worker 7, [14/18]: Training Loss: 3.075007461, Training Accuracy: 24.032\n",
            "Worker 7, [15/18]: Training Loss: 3.094995209, Training Accuracy: 23.152\n",
            "Worker 7, [16/18]: Training Loss: 3.045162111, Training Accuracy: 24.752\n",
            "Worker 7, [17/18]: Training Loss: 3.070359254, Training Accuracy: 23.888\n",
            "Worker 7, [18/18]: Training Loss: 3.042314902, Training Accuracy: 24.864\n",
            "Time taken for training worker 7: 0:00:47.366473\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.554589391, Training Accuracy: 15.088\n",
            "Worker 8, [02/18]: Training Loss: 3.420871311, Training Accuracy: 16.768\n",
            "Worker 8, [03/18]: Training Loss: 3.454289624, Training Accuracy: 16.496\n",
            "Worker 8, [04/18]: Training Loss: 3.364057161, Training Accuracy: 17.840\n",
            "Worker 8, [05/18]: Training Loss: 3.407452814, Training Accuracy: 17.392\n",
            "Worker 8, [06/18]: Training Loss: 3.314612999, Training Accuracy: 18.224\n",
            "Worker 8, [07/18]: Training Loss: 3.340308043, Training Accuracy: 17.168\n",
            "Worker 8, [08/18]: Training Loss: 3.265230580, Training Accuracy: 18.800\n",
            "Worker 8, [09/18]: Training Loss: 3.270429743, Training Accuracy: 19.200\n",
            "Worker 8, [10/18]: Training Loss: 3.194559562, Training Accuracy: 19.968\n",
            "Worker 8, [11/18]: Training Loss: 3.187610930, Training Accuracy: 21.152\n",
            "Worker 8, [12/18]: Training Loss: 3.115178945, Training Accuracy: 21.648\n",
            "Worker 8, [13/18]: Training Loss: 3.131307522, Training Accuracy: 22.432\n",
            "Worker 8, [14/18]: Training Loss: 3.057725585, Training Accuracy: 23.584\n",
            "Worker 8, [15/18]: Training Loss: 3.087081119, Training Accuracy: 23.088\n",
            "Worker 8, [16/18]: Training Loss: 3.026477772, Training Accuracy: 24.384\n",
            "Worker 8, [17/18]: Training Loss: 3.052837433, Training Accuracy: 23.824\n",
            "Worker 8, [18/18]: Training Loss: 3.028173549, Training Accuracy: 24.416\n",
            "Time taken for training worker 8: 0:00:48.192697\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000546\n",
            "Local Step 07: Test Loss: 3.259915663, Test Accuracy: 21.850\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.372701261, Training Accuracy: 18.880\n",
            "Worker 1, [02/18]: Training Loss: 3.365535673, Training Accuracy: 19.328\n",
            "Worker 1, [03/18]: Training Loss: 3.136306038, Training Accuracy: 23.632\n",
            "Worker 1, [04/18]: Training Loss: 3.110241379, Training Accuracy: 23.520\n",
            "Worker 1, [05/18]: Training Loss: 3.161122991, Training Accuracy: 22.816\n",
            "Worker 1, [06/18]: Training Loss: 3.139104858, Training Accuracy: 22.688\n",
            "Worker 1, [07/18]: Training Loss: 3.204628528, Training Accuracy: 22.064\n",
            "Worker 1, [08/18]: Training Loss: 3.182088059, Training Accuracy: 22.032\n",
            "Worker 1, [09/18]: Training Loss: 3.244976306, Training Accuracy: 21.136\n",
            "Worker 1, [10/18]: Training Loss: 3.207308898, Training Accuracy: 20.992\n",
            "Worker 1, [11/18]: Training Loss: 3.291405809, Training Accuracy: 19.200\n",
            "Worker 1, [12/18]: Training Loss: 3.260832096, Training Accuracy: 20.800\n",
            "Worker 1, [13/18]: Training Loss: 3.325050203, Training Accuracy: 18.896\n",
            "Worker 1, [14/18]: Training Loss: 3.279249503, Training Accuracy: 19.504\n",
            "Worker 1, [15/18]: Training Loss: 3.349948438, Training Accuracy: 18.816\n",
            "Worker 1, [16/18]: Training Loss: 3.287074403, Training Accuracy: 19.184\n",
            "Worker 1, [17/18]: Training Loss: 3.334395343, Training Accuracy: 19.296\n",
            "Worker 1, [18/18]: Training Loss: 3.306105543, Training Accuracy: 19.472\n",
            "Time taken for training worker 1: 0:00:48.087373\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.329717006, Training Accuracy: 19.872\n",
            "Worker 2, [02/18]: Training Loss: 3.321603303, Training Accuracy: 19.488\n",
            "Worker 2, [03/18]: Training Loss: 3.047452501, Training Accuracy: 24.128\n",
            "Worker 2, [04/18]: Training Loss: 3.016952646, Training Accuracy: 24.736\n",
            "Worker 2, [05/18]: Training Loss: 3.041726930, Training Accuracy: 23.584\n",
            "Worker 2, [06/18]: Training Loss: 3.048010040, Training Accuracy: 24.064\n",
            "Worker 2, [07/18]: Training Loss: 3.094786408, Training Accuracy: 22.960\n",
            "Worker 2, [08/18]: Training Loss: 3.090843206, Training Accuracy: 23.040\n",
            "Worker 2, [09/18]: Training Loss: 3.162676964, Training Accuracy: 21.216\n",
            "Worker 2, [10/18]: Training Loss: 3.118362145, Training Accuracy: 22.016\n",
            "Worker 2, [11/18]: Training Loss: 3.206656310, Training Accuracy: 20.992\n",
            "Worker 2, [12/18]: Training Loss: 3.184073074, Training Accuracy: 20.544\n",
            "Worker 2, [13/18]: Training Loss: 3.224345815, Training Accuracy: 20.272\n",
            "Worker 2, [14/18]: Training Loss: 3.180786340, Training Accuracy: 20.656\n",
            "Worker 2, [15/18]: Training Loss: 3.284605527, Training Accuracy: 18.656\n",
            "Worker 2, [16/18]: Training Loss: 3.202231495, Training Accuracy: 20.864\n",
            "Worker 2, [17/18]: Training Loss: 3.256085362, Training Accuracy: 19.264\n",
            "Worker 2, [18/18]: Training Loss: 3.198130211, Training Accuracy: 20.064\n",
            "Time taken for training worker 2: 0:00:47.365128\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.316536981, Training Accuracy: 21.392\n",
            "Worker 3, [02/18]: Training Loss: 3.309806014, Training Accuracy: 21.216\n",
            "Worker 3, [03/18]: Training Loss: 3.057405649, Training Accuracy: 25.120\n",
            "Worker 3, [04/18]: Training Loss: 3.028232088, Training Accuracy: 25.840\n",
            "Worker 3, [05/18]: Training Loss: 3.075928530, Training Accuracy: 24.080\n",
            "Worker 3, [06/18]: Training Loss: 3.066443618, Training Accuracy: 24.192\n",
            "Worker 3, [07/18]: Training Loss: 3.117408207, Training Accuracy: 23.872\n",
            "Worker 3, [08/18]: Training Loss: 3.107974099, Training Accuracy: 23.136\n",
            "Worker 3, [09/18]: Training Loss: 3.163957343, Training Accuracy: 22.096\n",
            "Worker 3, [10/18]: Training Loss: 3.153504389, Training Accuracy: 22.480\n",
            "Worker 3, [11/18]: Training Loss: 3.209105171, Training Accuracy: 21.456\n",
            "Worker 3, [12/18]: Training Loss: 3.169803736, Training Accuracy: 21.648\n",
            "Worker 3, [13/18]: Training Loss: 3.247470544, Training Accuracy: 20.480\n",
            "Worker 3, [14/18]: Training Loss: 3.217360514, Training Accuracy: 20.832\n",
            "Worker 3, [15/18]: Training Loss: 3.283932489, Training Accuracy: 19.984\n",
            "Worker 3, [16/18]: Training Loss: 3.224643325, Training Accuracy: 20.944\n",
            "Worker 3, [17/18]: Training Loss: 3.281993255, Training Accuracy: 19.344\n",
            "Worker 3, [18/18]: Training Loss: 3.210685742, Training Accuracy: 20.976\n",
            "Time taken for training worker 3: 0:00:47.905147\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.302155585, Training Accuracy: 21.008\n",
            "Worker 4, [02/18]: Training Loss: 3.296640746, Training Accuracy: 20.736\n",
            "Worker 4, [03/18]: Training Loss: 3.046020481, Training Accuracy: 25.152\n",
            "Worker 4, [04/18]: Training Loss: 3.031484064, Training Accuracy: 24.896\n",
            "Worker 4, [05/18]: Training Loss: 3.064305242, Training Accuracy: 24.352\n",
            "Worker 4, [06/18]: Training Loss: 3.052912690, Training Accuracy: 24.384\n",
            "Worker 4, [07/18]: Training Loss: 3.101636135, Training Accuracy: 23.200\n",
            "Worker 4, [08/18]: Training Loss: 3.096830855, Training Accuracy: 22.640\n",
            "Worker 4, [09/18]: Training Loss: 3.161128407, Training Accuracy: 22.256\n",
            "Worker 4, [10/18]: Training Loss: 3.141157591, Training Accuracy: 22.064\n",
            "Worker 4, [11/18]: Training Loss: 3.198811456, Training Accuracy: 21.568\n",
            "Worker 4, [12/18]: Training Loss: 3.186951413, Training Accuracy: 21.392\n",
            "Worker 4, [13/18]: Training Loss: 3.248324316, Training Accuracy: 20.624\n",
            "Worker 4, [14/18]: Training Loss: 3.205376710, Training Accuracy: 21.248\n",
            "Worker 4, [15/18]: Training Loss: 3.250204454, Training Accuracy: 19.968\n",
            "Worker 4, [16/18]: Training Loss: 3.213872647, Training Accuracy: 20.800\n",
            "Worker 4, [17/18]: Training Loss: 3.292022678, Training Accuracy: 19.552\n",
            "Worker 4, [18/18]: Training Loss: 3.188809222, Training Accuracy: 21.568\n",
            "Time taken for training worker 4: 0:00:49.713274\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.319813553, Training Accuracy: 20.800\n",
            "Worker 5, [02/18]: Training Loss: 3.302673325, Training Accuracy: 20.528\n",
            "Worker 5, [03/18]: Training Loss: 3.059621015, Training Accuracy: 24.336\n",
            "Worker 5, [04/18]: Training Loss: 3.029078700, Training Accuracy: 24.608\n",
            "Worker 5, [05/18]: Training Loss: 3.069218529, Training Accuracy: 23.744\n",
            "Worker 5, [06/18]: Training Loss: 3.064291290, Training Accuracy: 23.424\n",
            "Worker 5, [07/18]: Training Loss: 3.121933589, Training Accuracy: 23.424\n",
            "Worker 5, [08/18]: Training Loss: 3.102457796, Training Accuracy: 22.736\n",
            "Worker 5, [09/18]: Training Loss: 3.158841549, Training Accuracy: 21.920\n",
            "Worker 5, [10/18]: Training Loss: 3.154491848, Training Accuracy: 21.968\n",
            "Worker 5, [11/18]: Training Loss: 3.210484877, Training Accuracy: 20.768\n",
            "Worker 5, [12/18]: Training Loss: 3.201110236, Training Accuracy: 20.800\n",
            "Worker 5, [13/18]: Training Loss: 3.238706827, Training Accuracy: 20.736\n",
            "Worker 5, [14/18]: Training Loss: 3.219256258, Training Accuracy: 20.416\n",
            "Worker 5, [15/18]: Training Loss: 3.263959444, Training Accuracy: 19.904\n",
            "Worker 5, [16/18]: Training Loss: 3.226652591, Training Accuracy: 20.352\n",
            "Worker 5, [17/18]: Training Loss: 3.277853238, Training Accuracy: 19.808\n",
            "Worker 5, [18/18]: Training Loss: 3.221411418, Training Accuracy: 20.688\n",
            "Time taken for training worker 5: 0:00:48.950300\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.302437914, Training Accuracy: 20.912\n",
            "Worker 6, [02/18]: Training Loss: 3.289154790, Training Accuracy: 20.672\n",
            "Worker 6, [03/18]: Training Loss: 3.043509744, Training Accuracy: 25.200\n",
            "Worker 6, [04/18]: Training Loss: 3.047372455, Training Accuracy: 24.080\n",
            "Worker 6, [05/18]: Training Loss: 3.063626282, Training Accuracy: 23.936\n",
            "Worker 6, [06/18]: Training Loss: 3.049503017, Training Accuracy: 23.248\n",
            "Worker 6, [07/18]: Training Loss: 3.099216663, Training Accuracy: 23.184\n",
            "Worker 6, [08/18]: Training Loss: 3.120667878, Training Accuracy: 22.640\n",
            "Worker 6, [09/18]: Training Loss: 3.148347091, Training Accuracy: 22.064\n",
            "Worker 6, [10/18]: Training Loss: 3.154669336, Training Accuracy: 21.200\n",
            "Worker 6, [11/18]: Training Loss: 3.205412154, Training Accuracy: 20.944\n",
            "Worker 6, [12/18]: Training Loss: 3.197642013, Training Accuracy: 21.360\n",
            "Worker 6, [13/18]: Training Loss: 3.252158973, Training Accuracy: 19.904\n",
            "Worker 6, [14/18]: Training Loss: 3.199338519, Training Accuracy: 20.416\n",
            "Worker 6, [15/18]: Training Loss: 3.281440657, Training Accuracy: 19.088\n",
            "Worker 6, [16/18]: Training Loss: 3.221677697, Training Accuracy: 20.688\n",
            "Worker 6, [17/18]: Training Loss: 3.274619893, Training Accuracy: 19.328\n",
            "Worker 6, [18/18]: Training Loss: 3.220082716, Training Accuracy: 19.792\n",
            "Time taken for training worker 6: 0:00:49.382088\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.306043844, Training Accuracy: 20.176\n",
            "Worker 7, [02/18]: Training Loss: 3.296892813, Training Accuracy: 20.288\n",
            "Worker 7, [03/18]: Training Loss: 3.074270387, Training Accuracy: 23.888\n",
            "Worker 7, [04/18]: Training Loss: 3.051976987, Training Accuracy: 24.144\n",
            "Worker 7, [05/18]: Training Loss: 3.091192360, Training Accuracy: 23.456\n",
            "Worker 7, [06/18]: Training Loss: 3.089763435, Training Accuracy: 23.472\n",
            "Worker 7, [07/18]: Training Loss: 3.123919638, Training Accuracy: 22.912\n",
            "Worker 7, [08/18]: Training Loss: 3.130947862, Training Accuracy: 23.008\n",
            "Worker 7, [09/18]: Training Loss: 3.179958876, Training Accuracy: 20.976\n",
            "Worker 7, [10/18]: Training Loss: 3.160861726, Training Accuracy: 21.760\n",
            "Worker 7, [11/18]: Training Loss: 3.240691521, Training Accuracy: 20.384\n",
            "Worker 7, [12/18]: Training Loss: 3.215641450, Training Accuracy: 20.688\n",
            "Worker 7, [13/18]: Training Loss: 3.279447161, Training Accuracy: 19.216\n",
            "Worker 7, [14/18]: Training Loss: 3.249544078, Training Accuracy: 19.664\n",
            "Worker 7, [15/18]: Training Loss: 3.283920081, Training Accuracy: 19.968\n",
            "Worker 7, [16/18]: Training Loss: 3.247115979, Training Accuracy: 20.096\n",
            "Worker 7, [17/18]: Training Loss: 3.296110299, Training Accuracy: 18.336\n",
            "Worker 7, [18/18]: Training Loss: 3.253291716, Training Accuracy: 20.080\n",
            "Time taken for training worker 7: 0:00:47.586408\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.327426331, Training Accuracy: 20.112\n",
            "Worker 8, [02/18]: Training Loss: 3.317770389, Training Accuracy: 20.016\n",
            "Worker 8, [03/18]: Training Loss: 3.062408761, Training Accuracy: 24.416\n",
            "Worker 8, [04/18]: Training Loss: 3.057299565, Training Accuracy: 23.968\n",
            "Worker 8, [05/18]: Training Loss: 3.087384260, Training Accuracy: 23.392\n",
            "Worker 8, [06/18]: Training Loss: 3.076480588, Training Accuracy: 23.424\n",
            "Worker 8, [07/18]: Training Loss: 3.111341318, Training Accuracy: 22.768\n",
            "Worker 8, [08/18]: Training Loss: 3.117757642, Training Accuracy: 22.864\n",
            "Worker 8, [09/18]: Training Loss: 3.163204310, Training Accuracy: 21.472\n",
            "Worker 8, [10/18]: Training Loss: 3.167278404, Training Accuracy: 20.560\n",
            "Worker 8, [11/18]: Training Loss: 3.240334039, Training Accuracy: 20.208\n",
            "Worker 8, [12/18]: Training Loss: 3.195326389, Training Accuracy: 20.704\n",
            "Worker 8, [13/18]: Training Loss: 3.261172562, Training Accuracy: 19.328\n",
            "Worker 8, [14/18]: Training Loss: 3.232999899, Training Accuracy: 19.792\n",
            "Worker 8, [15/18]: Training Loss: 3.281131538, Training Accuracy: 19.328\n",
            "Worker 8, [16/18]: Training Loss: 3.238643860, Training Accuracy: 19.200\n",
            "Worker 8, [17/18]: Training Loss: 3.292014217, Training Accuracy: 19.088\n",
            "Worker 8, [18/18]: Training Loss: 3.240340143, Training Accuracy: 19.648\n",
            "Time taken for training worker 8: 0:00:47.781923\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000634\n",
            "Local Step 08: Test Loss: 3.188746847, Test Accuracy: 23.400\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:26.596119\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8, Update Slow Model every 4 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.591649002, Training Accuracy: 1.856\n",
            "Worker 1, [02/18]: Training Loss: 4.461380151, Training Accuracy: 3.248\n",
            "Worker 1, [03/18]: Training Loss: 4.209155834, Training Accuracy: 5.616\n",
            "Worker 1, [04/18]: Training Loss: 4.055764522, Training Accuracy: 7.232\n",
            "Worker 1, [05/18]: Training Loss: 4.525288869, Training Accuracy: 2.416\n",
            "Worker 1, [06/18]: Training Loss: 4.203586977, Training Accuracy: 5.584\n",
            "Worker 1, [07/18]: Training Loss: 4.032087759, Training Accuracy: 7.632\n",
            "Worker 1, [08/18]: Training Loss: 3.920397328, Training Accuracy: 9.616\n",
            "Worker 1, [09/18]: Training Loss: 4.442411111, Training Accuracy: 3.696\n",
            "Worker 1, [10/18]: Training Loss: 4.125032585, Training Accuracy: 6.912\n",
            "Worker 1, [11/18]: Training Loss: 3.973301104, Training Accuracy: 9.072\n",
            "Worker 1, [12/18]: Training Loss: 3.883156207, Training Accuracy: 10.432\n",
            "Worker 1, [13/18]: Training Loss: 4.450860700, Training Accuracy: 5.472\n",
            "Worker 1, [14/18]: Training Loss: 4.155237154, Training Accuracy: 7.376\n",
            "Worker 1, [15/18]: Training Loss: 4.023333934, Training Accuracy: 8.240\n",
            "Worker 1, [16/18]: Training Loss: 3.967864961, Training Accuracy: 9.152\n",
            "Worker 1, [17/18]: Training Loss: 4.502877980, Training Accuracy: 7.312\n",
            "Worker 1, [18/18]: Training Loss: 4.477185682, Training Accuracy: 7.376\n",
            "Time taken for training worker 1: 0:00:48.183041\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.593739884, Training Accuracy: 1.424\n",
            "Worker 2, [02/18]: Training Loss: 4.434317477, Training Accuracy: 3.552\n",
            "Worker 2, [03/18]: Training Loss: 4.165322586, Training Accuracy: 5.984\n",
            "Worker 2, [04/18]: Training Loss: 4.024706125, Training Accuracy: 7.520\n",
            "Worker 2, [05/18]: Training Loss: 4.512821874, Training Accuracy: 3.040\n",
            "Worker 2, [06/18]: Training Loss: 4.177767308, Training Accuracy: 6.128\n",
            "Worker 2, [07/18]: Training Loss: 4.010744387, Training Accuracy: 8.128\n",
            "Worker 2, [08/18]: Training Loss: 3.886548840, Training Accuracy: 9.616\n",
            "Worker 2, [09/18]: Training Loss: 4.414624336, Training Accuracy: 4.016\n",
            "Worker 2, [10/18]: Training Loss: 4.096538463, Training Accuracy: 6.816\n",
            "Worker 2, [11/18]: Training Loss: 3.951413257, Training Accuracy: 9.328\n",
            "Worker 2, [12/18]: Training Loss: 3.849408116, Training Accuracy: 10.464\n",
            "Worker 2, [13/18]: Training Loss: 4.439181746, Training Accuracy: 5.648\n",
            "Worker 2, [14/18]: Training Loss: 4.119399750, Training Accuracy: 7.088\n",
            "Worker 2, [15/18]: Training Loss: 4.001278938, Training Accuracy: 8.768\n",
            "Worker 2, [16/18]: Training Loss: 3.928096494, Training Accuracy: 9.264\n",
            "Worker 2, [17/18]: Training Loss: 4.498451627, Training Accuracy: 6.704\n",
            "Worker 2, [18/18]: Training Loss: 4.468166011, Training Accuracy: 7.328\n",
            "Time taken for training worker 2: 0:00:48.241107\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.592126895, Training Accuracy: 1.744\n",
            "Worker 3, [02/18]: Training Loss: 4.433538573, Training Accuracy: 3.648\n",
            "Worker 3, [03/18]: Training Loss: 4.189453964, Training Accuracy: 5.968\n",
            "Worker 3, [04/18]: Training Loss: 4.067628182, Training Accuracy: 7.392\n",
            "Worker 3, [05/18]: Training Loss: 4.507562832, Training Accuracy: 2.832\n",
            "Worker 3, [06/18]: Training Loss: 4.202260601, Training Accuracy: 5.712\n",
            "Worker 3, [07/18]: Training Loss: 4.048916797, Training Accuracy: 7.936\n",
            "Worker 3, [08/18]: Training Loss: 3.928013763, Training Accuracy: 9.328\n",
            "Worker 3, [09/18]: Training Loss: 4.474058818, Training Accuracy: 3.696\n",
            "Worker 3, [10/18]: Training Loss: 4.145052311, Training Accuracy: 6.432\n",
            "Worker 3, [11/18]: Training Loss: 4.009389649, Training Accuracy: 8.016\n",
            "Worker 3, [12/18]: Training Loss: 3.914927276, Training Accuracy: 9.440\n",
            "Worker 3, [13/18]: Training Loss: 4.447803556, Training Accuracy: 5.408\n",
            "Worker 3, [14/18]: Training Loss: 4.150290518, Training Accuracy: 6.816\n",
            "Worker 3, [15/18]: Training Loss: 4.027739958, Training Accuracy: 8.512\n",
            "Worker 3, [16/18]: Training Loss: 3.959630735, Training Accuracy: 9.376\n",
            "Worker 3, [17/18]: Training Loss: 4.504645241, Training Accuracy: 6.336\n",
            "Worker 3, [18/18]: Training Loss: 4.478081217, Training Accuracy: 6.560\n",
            "Time taken for training worker 3: 0:00:47.503160\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.592817827, Training Accuracy: 1.680\n",
            "Worker 4, [02/18]: Training Loss: 4.457921101, Training Accuracy: 3.408\n",
            "Worker 4, [03/18]: Training Loss: 4.191824551, Training Accuracy: 6.032\n",
            "Worker 4, [04/18]: Training Loss: 4.052916916, Training Accuracy: 7.632\n",
            "Worker 4, [05/18]: Training Loss: 4.524498988, Training Accuracy: 2.848\n",
            "Worker 4, [06/18]: Training Loss: 4.203878023, Training Accuracy: 5.840\n",
            "Worker 4, [07/18]: Training Loss: 4.049766888, Training Accuracy: 7.856\n",
            "Worker 4, [08/18]: Training Loss: 3.916981391, Training Accuracy: 9.392\n",
            "Worker 4, [09/18]: Training Loss: 4.454633450, Training Accuracy: 3.728\n",
            "Worker 4, [10/18]: Training Loss: 4.151315806, Training Accuracy: 6.768\n",
            "Worker 4, [11/18]: Training Loss: 4.005634305, Training Accuracy: 8.448\n",
            "Worker 4, [12/18]: Training Loss: 3.881849401, Training Accuracy: 10.288\n",
            "Worker 4, [13/18]: Training Loss: 4.451487517, Training Accuracy: 4.944\n",
            "Worker 4, [14/18]: Training Loss: 4.153688930, Training Accuracy: 6.928\n",
            "Worker 4, [15/18]: Training Loss: 4.027028227, Training Accuracy: 8.784\n",
            "Worker 4, [16/18]: Training Loss: 3.963556555, Training Accuracy: 9.664\n",
            "Worker 4, [17/18]: Training Loss: 4.504629174, Training Accuracy: 6.304\n",
            "Worker 4, [18/18]: Training Loss: 4.478095755, Training Accuracy: 7.280\n",
            "Time taken for training worker 4: 0:00:47.452308\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 4.593315655, Training Accuracy: 1.504\n",
            "Worker 5, [02/18]: Training Loss: 4.438744282, Training Accuracy: 2.944\n",
            "Worker 5, [03/18]: Training Loss: 4.195042073, Training Accuracy: 5.632\n",
            "Worker 5, [04/18]: Training Loss: 4.041142989, Training Accuracy: 8.016\n",
            "Worker 5, [05/18]: Training Loss: 4.514537310, Training Accuracy: 2.512\n",
            "Worker 5, [06/18]: Training Loss: 4.230439782, Training Accuracy: 5.312\n",
            "Worker 5, [07/18]: Training Loss: 4.042128368, Training Accuracy: 7.904\n",
            "Worker 5, [08/18]: Training Loss: 3.939576263, Training Accuracy: 9.136\n",
            "Worker 5, [09/18]: Training Loss: 4.417331839, Training Accuracy: 4.288\n",
            "Worker 5, [10/18]: Training Loss: 4.114435914, Training Accuracy: 6.880\n",
            "Worker 5, [11/18]: Training Loss: 3.970315663, Training Accuracy: 8.928\n",
            "Worker 5, [12/18]: Training Loss: 3.878140245, Training Accuracy: 10.144\n",
            "Worker 5, [13/18]: Training Loss: 4.441139936, Training Accuracy: 5.456\n",
            "Worker 5, [14/18]: Training Loss: 4.142727107, Training Accuracy: 6.928\n",
            "Worker 5, [15/18]: Training Loss: 4.017856012, Training Accuracy: 8.016\n",
            "Worker 5, [16/18]: Training Loss: 3.954250389, Training Accuracy: 9.744\n",
            "Worker 5, [17/18]: Training Loss: 4.503839897, Training Accuracy: 7.056\n",
            "Worker 5, [18/18]: Training Loss: 4.476418544, Training Accuracy: 7.712\n",
            "Time taken for training worker 5: 0:00:47.497113\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 4.594001712, Training Accuracy: 1.808\n",
            "Worker 6, [02/18]: Training Loss: 4.445238147, Training Accuracy: 3.552\n",
            "Worker 6, [03/18]: Training Loss: 4.185383587, Training Accuracy: 5.136\n",
            "Worker 6, [04/18]: Training Loss: 4.042431153, Training Accuracy: 7.328\n",
            "Worker 6, [05/18]: Training Loss: 4.510937691, Training Accuracy: 2.832\n",
            "Worker 6, [06/18]: Training Loss: 4.196849779, Training Accuracy: 5.760\n",
            "Worker 6, [07/18]: Training Loss: 4.044022074, Training Accuracy: 7.168\n",
            "Worker 6, [08/18]: Training Loss: 3.921453814, Training Accuracy: 9.344\n",
            "Worker 6, [09/18]: Training Loss: 4.432506041, Training Accuracy: 4.304\n",
            "Worker 6, [10/18]: Training Loss: 4.121335205, Training Accuracy: 6.768\n",
            "Worker 6, [11/18]: Training Loss: 3.985024900, Training Accuracy: 8.144\n",
            "Worker 6, [12/18]: Training Loss: 3.885148496, Training Accuracy: 9.856\n",
            "Worker 6, [13/18]: Training Loss: 4.443068047, Training Accuracy: 5.616\n",
            "Worker 6, [14/18]: Training Loss: 4.133845298, Training Accuracy: 7.104\n",
            "Worker 6, [15/18]: Training Loss: 4.006305074, Training Accuracy: 8.432\n",
            "Worker 6, [16/18]: Training Loss: 3.953801751, Training Accuracy: 9.504\n",
            "Worker 6, [17/18]: Training Loss: 4.502447333, Training Accuracy: 7.312\n",
            "Worker 6, [18/18]: Training Loss: 4.474785727, Training Accuracy: 7.712\n",
            "Time taken for training worker 6: 0:00:48.826615\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 4.595262600, Training Accuracy: 1.488\n",
            "Worker 7, [02/18]: Training Loss: 4.444097733, Training Accuracy: 2.960\n",
            "Worker 7, [03/18]: Training Loss: 4.200626227, Training Accuracy: 5.280\n",
            "Worker 7, [04/18]: Training Loss: 4.050793998, Training Accuracy: 6.640\n",
            "Worker 7, [05/18]: Training Loss: 4.526709338, Training Accuracy: 2.688\n",
            "Worker 7, [06/18]: Training Loss: 4.237452614, Training Accuracy: 5.184\n",
            "Worker 7, [07/18]: Training Loss: 4.031028869, Training Accuracy: 8.224\n",
            "Worker 7, [08/18]: Training Loss: 3.913292807, Training Accuracy: 9.360\n",
            "Worker 7, [09/18]: Training Loss: 4.423923585, Training Accuracy: 4.112\n",
            "Worker 7, [10/18]: Training Loss: 4.120585137, Training Accuracy: 6.608\n",
            "Worker 7, [11/18]: Training Loss: 3.976358307, Training Accuracy: 8.336\n",
            "Worker 7, [12/18]: Training Loss: 3.872270776, Training Accuracy: 9.824\n",
            "Worker 7, [13/18]: Training Loss: 4.440134856, Training Accuracy: 6.064\n",
            "Worker 7, [14/18]: Training Loss: 4.134769481, Training Accuracy: 6.816\n",
            "Worker 7, [15/18]: Training Loss: 4.017639301, Training Accuracy: 7.872\n",
            "Worker 7, [16/18]: Training Loss: 3.954681615, Training Accuracy: 9.088\n",
            "Worker 7, [17/18]: Training Loss: 4.498016065, Training Accuracy: 7.136\n",
            "Worker 7, [18/18]: Training Loss: 4.471789097, Training Accuracy: 7.328\n",
            "Time taken for training worker 7: 0:00:46.643444\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 4.592726819, Training Accuracy: 1.376\n",
            "Worker 8, [02/18]: Training Loss: 4.445334571, Training Accuracy: 3.376\n",
            "Worker 8, [03/18]: Training Loss: 4.177924750, Training Accuracy: 5.040\n",
            "Worker 8, [04/18]: Training Loss: 4.032374779, Training Accuracy: 7.760\n",
            "Worker 8, [05/18]: Training Loss: 4.525955239, Training Accuracy: 2.656\n",
            "Worker 8, [06/18]: Training Loss: 4.200864855, Training Accuracy: 5.488\n",
            "Worker 8, [07/18]: Training Loss: 4.019847926, Training Accuracy: 7.856\n",
            "Worker 8, [08/18]: Training Loss: 3.894800746, Training Accuracy: 8.816\n",
            "Worker 8, [09/18]: Training Loss: 4.416234634, Training Accuracy: 4.560\n",
            "Worker 8, [10/18]: Training Loss: 4.108972834, Training Accuracy: 6.256\n",
            "Worker 8, [11/18]: Training Loss: 3.967371391, Training Accuracy: 8.400\n",
            "Worker 8, [12/18]: Training Loss: 3.863013268, Training Accuracy: 10.064\n",
            "Worker 8, [13/18]: Training Loss: 4.437980019, Training Accuracy: 5.200\n",
            "Worker 8, [14/18]: Training Loss: 4.129568117, Training Accuracy: 7.088\n",
            "Worker 8, [15/18]: Training Loss: 4.001834509, Training Accuracy: 8.896\n",
            "Worker 8, [16/18]: Training Loss: 3.949055903, Training Accuracy: 9.136\n",
            "Worker 8, [17/18]: Training Loss: 4.497938015, Training Accuracy: 7.104\n",
            "Worker 8, [18/18]: Training Loss: 4.470602770, Training Accuracy: 7.104\n",
            "Time taken for training worker 8: 0:00:49.117965\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000800\n",
            "Local Step 01: Test Loss: 4.492352592, Test Accuracy: 6.820\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.498767420, Training Accuracy: 5.904\n",
            "Worker 1, [02/18]: Training Loss: 4.494659190, Training Accuracy: 5.888\n",
            "Worker 1, [03/18]: Training Loss: 4.468053424, Training Accuracy: 5.920\n",
            "Worker 1, [04/18]: Training Loss: 4.386869538, Training Accuracy: 6.112\n",
            "Worker 1, [05/18]: Training Loss: 4.400943119, Training Accuracy: 6.480\n",
            "Worker 1, [06/18]: Training Loss: 4.151297786, Training Accuracy: 7.120\n",
            "Worker 1, [07/18]: Training Loss: 4.041889081, Training Accuracy: 8.256\n",
            "Worker 1, [08/18]: Training Loss: 3.962769885, Training Accuracy: 9.424\n",
            "Worker 1, [09/18]: Training Loss: 4.226871785, Training Accuracy: 6.288\n",
            "Worker 1, [10/18]: Training Loss: 4.005215214, Training Accuracy: 8.688\n",
            "Worker 1, [11/18]: Training Loss: 3.921415378, Training Accuracy: 9.808\n",
            "Worker 1, [12/18]: Training Loss: 3.820850144, Training Accuracy: 10.544\n",
            "Worker 1, [13/18]: Training Loss: 4.149972633, Training Accuracy: 7.056\n",
            "Worker 1, [14/18]: Training Loss: 3.936730723, Training Accuracy: 9.744\n",
            "Worker 1, [15/18]: Training Loss: 3.831309092, Training Accuracy: 10.784\n",
            "Worker 1, [16/18]: Training Loss: 3.718861614, Training Accuracy: 12.432\n",
            "Worker 1, [17/18]: Training Loss: 4.066028466, Training Accuracy: 8.128\n",
            "Worker 1, [18/18]: Training Loss: 3.852394564, Training Accuracy: 10.320\n",
            "Time taken for training worker 1: 0:00:47.891546\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.874447261, Training Accuracy: 10.192\n",
            "Worker 2, [02/18]: Training Loss: 3.829085486, Training Accuracy: 10.960\n",
            "Worker 2, [03/18]: Training Loss: 3.761304904, Training Accuracy: 11.744\n",
            "Worker 2, [04/18]: Training Loss: 3.705107728, Training Accuracy: 13.776\n",
            "Worker 2, [05/18]: Training Loss: 4.359732005, Training Accuracy: 7.776\n",
            "Worker 2, [06/18]: Training Loss: 4.067535853, Training Accuracy: 8.096\n",
            "Worker 2, [07/18]: Training Loss: 3.966632843, Training Accuracy: 8.400\n",
            "Worker 2, [08/18]: Training Loss: 3.880097973, Training Accuracy: 10.192\n",
            "Worker 2, [09/18]: Training Loss: 4.150657209, Training Accuracy: 7.536\n",
            "Worker 2, [10/18]: Training Loss: 3.915333539, Training Accuracy: 9.936\n",
            "Worker 2, [11/18]: Training Loss: 3.816413257, Training Accuracy: 10.720\n",
            "Worker 2, [12/18]: Training Loss: 3.733953928, Training Accuracy: 11.920\n",
            "Worker 2, [13/18]: Training Loss: 4.066300815, Training Accuracy: 7.824\n",
            "Worker 2, [14/18]: Training Loss: 3.855409608, Training Accuracy: 10.000\n",
            "Worker 2, [15/18]: Training Loss: 3.725453408, Training Accuracy: 12.176\n",
            "Worker 2, [16/18]: Training Loss: 3.626445001, Training Accuracy: 13.632\n",
            "Worker 2, [17/18]: Training Loss: 3.998278333, Training Accuracy: 9.040\n",
            "Worker 2, [18/18]: Training Loss: 3.764524148, Training Accuracy: 11.184\n",
            "Time taken for training worker 2: 0:00:48.181738\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.844304802, Training Accuracy: 10.560\n",
            "Worker 3, [02/18]: Training Loss: 3.797516098, Training Accuracy: 11.856\n",
            "Worker 3, [03/18]: Training Loss: 3.736015179, Training Accuracy: 13.216\n",
            "Worker 3, [04/18]: Training Loss: 3.672565550, Training Accuracy: 14.096\n",
            "Worker 3, [05/18]: Training Loss: 4.371446945, Training Accuracy: 7.488\n",
            "Worker 3, [06/18]: Training Loss: 4.087482506, Training Accuracy: 7.728\n",
            "Worker 3, [07/18]: Training Loss: 3.995617691, Training Accuracy: 8.768\n",
            "Worker 3, [08/18]: Training Loss: 3.907130378, Training Accuracy: 9.632\n",
            "Worker 3, [09/18]: Training Loss: 4.155502694, Training Accuracy: 7.120\n",
            "Worker 3, [10/18]: Training Loss: 3.946261549, Training Accuracy: 9.072\n",
            "Worker 3, [11/18]: Training Loss: 3.833988117, Training Accuracy: 11.680\n",
            "Worker 3, [12/18]: Training Loss: 3.750598937, Training Accuracy: 12.848\n",
            "Worker 3, [13/18]: Training Loss: 4.055507701, Training Accuracy: 8.416\n",
            "Worker 3, [14/18]: Training Loss: 3.854437324, Training Accuracy: 10.464\n",
            "Worker 3, [15/18]: Training Loss: 3.751397563, Training Accuracy: 12.352\n",
            "Worker 3, [16/18]: Training Loss: 3.662292427, Training Accuracy: 13.520\n",
            "Worker 3, [17/18]: Training Loss: 4.021049916, Training Accuracy: 8.944\n",
            "Worker 3, [18/18]: Training Loss: 3.798535281, Training Accuracy: 10.784\n",
            "Time taken for training worker 3: 0:00:46.423174\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.792559950, Training Accuracy: 12.000\n",
            "Worker 4, [02/18]: Training Loss: 3.745366148, Training Accuracy: 13.280\n",
            "Worker 4, [03/18]: Training Loss: 3.700371779, Training Accuracy: 13.984\n",
            "Worker 4, [04/18]: Training Loss: 3.672468811, Training Accuracy: 15.008\n",
            "Worker 4, [05/18]: Training Loss: 4.370312983, Training Accuracy: 7.808\n",
            "Worker 4, [06/18]: Training Loss: 4.085205132, Training Accuracy: 7.952\n",
            "Worker 4, [07/18]: Training Loss: 3.986597669, Training Accuracy: 9.232\n",
            "Worker 4, [08/18]: Training Loss: 3.905854763, Training Accuracy: 9.504\n",
            "Worker 4, [09/18]: Training Loss: 4.163317471, Training Accuracy: 7.600\n",
            "Worker 4, [10/18]: Training Loss: 3.927839204, Training Accuracy: 10.160\n",
            "Worker 4, [11/18]: Training Loss: 3.827537235, Training Accuracy: 11.296\n",
            "Worker 4, [12/18]: Training Loss: 3.738393375, Training Accuracy: 12.288\n",
            "Worker 4, [13/18]: Training Loss: 4.076408048, Training Accuracy: 8.032\n",
            "Worker 4, [14/18]: Training Loss: 3.838078360, Training Accuracy: 11.088\n",
            "Worker 4, [15/18]: Training Loss: 3.742765772, Training Accuracy: 12.192\n",
            "Worker 4, [16/18]: Training Loss: 3.661056183, Training Accuracy: 13.248\n",
            "Worker 4, [17/18]: Training Loss: 4.005035016, Training Accuracy: 8.688\n",
            "Worker 4, [18/18]: Training Loss: 3.794303081, Training Accuracy: 11.264\n",
            "Time taken for training worker 4: 0:00:46.707154\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.858227630, Training Accuracy: 10.704\n",
            "Worker 5, [02/18]: Training Loss: 3.794912579, Training Accuracy: 12.112\n",
            "Worker 5, [03/18]: Training Loss: 3.708693371, Training Accuracy: 13.744\n",
            "Worker 5, [04/18]: Training Loss: 3.674962027, Training Accuracy: 14.560\n",
            "Worker 5, [05/18]: Training Loss: 4.368383568, Training Accuracy: 7.424\n",
            "Worker 5, [06/18]: Training Loss: 4.077589587, Training Accuracy: 8.176\n",
            "Worker 5, [07/18]: Training Loss: 3.977462956, Training Accuracy: 9.360\n",
            "Worker 5, [08/18]: Training Loss: 3.909031926, Training Accuracy: 9.584\n",
            "Worker 5, [09/18]: Training Loss: 4.156032762, Training Accuracy: 7.728\n",
            "Worker 5, [10/18]: Training Loss: 3.933789684, Training Accuracy: 9.008\n",
            "Worker 5, [11/18]: Training Loss: 3.843756895, Training Accuracy: 10.048\n",
            "Worker 5, [12/18]: Training Loss: 3.761438584, Training Accuracy: 12.000\n",
            "Worker 5, [13/18]: Training Loss: 4.070244213, Training Accuracy: 8.352\n",
            "Worker 5, [14/18]: Training Loss: 3.850420507, Training Accuracy: 10.544\n",
            "Worker 5, [15/18]: Training Loss: 3.751407516, Training Accuracy: 12.096\n",
            "Worker 5, [16/18]: Training Loss: 3.637167108, Training Accuracy: 13.728\n",
            "Worker 5, [17/18]: Training Loss: 4.001648757, Training Accuracy: 8.752\n",
            "Worker 5, [18/18]: Training Loss: 3.804045706, Training Accuracy: 11.232\n",
            "Time taken for training worker 5: 0:00:47.742319\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.786753100, Training Accuracy: 12.384\n",
            "Worker 6, [02/18]: Training Loss: 3.753867519, Training Accuracy: 12.352\n",
            "Worker 6, [03/18]: Training Loss: 3.701916695, Training Accuracy: 13.728\n",
            "Worker 6, [04/18]: Training Loss: 3.641303566, Training Accuracy: 15.216\n",
            "Worker 6, [05/18]: Training Loss: 4.368033613, Training Accuracy: 7.456\n",
            "Worker 6, [06/18]: Training Loss: 4.076475243, Training Accuracy: 7.792\n",
            "Worker 6, [07/18]: Training Loss: 3.963694482, Training Accuracy: 8.928\n",
            "Worker 6, [08/18]: Training Loss: 3.893641122, Training Accuracy: 9.936\n",
            "Worker 6, [09/18]: Training Loss: 4.164170562, Training Accuracy: 7.392\n",
            "Worker 6, [10/18]: Training Loss: 3.935594802, Training Accuracy: 9.360\n",
            "Worker 6, [11/18]: Training Loss: 3.833882787, Training Accuracy: 10.672\n",
            "Worker 6, [12/18]: Training Loss: 3.746451575, Training Accuracy: 12.048\n",
            "Worker 6, [13/18]: Training Loss: 4.081276847, Training Accuracy: 8.016\n",
            "Worker 6, [14/18]: Training Loss: 3.857276177, Training Accuracy: 10.096\n",
            "Worker 6, [15/18]: Training Loss: 3.740709874, Training Accuracy: 11.968\n",
            "Worker 6, [16/18]: Training Loss: 3.653749468, Training Accuracy: 13.456\n",
            "Worker 6, [17/18]: Training Loss: 4.016664038, Training Accuracy: 8.816\n",
            "Worker 6, [18/18]: Training Loss: 3.809929266, Training Accuracy: 11.312\n",
            "Time taken for training worker 6: 0:00:46.804445\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.830162630, Training Accuracy: 11.376\n",
            "Worker 7, [02/18]: Training Loss: 3.802866179, Training Accuracy: 12.096\n",
            "Worker 7, [03/18]: Training Loss: 3.740944811, Training Accuracy: 12.592\n",
            "Worker 7, [04/18]: Training Loss: 3.681923397, Training Accuracy: 13.408\n",
            "Worker 7, [05/18]: Training Loss: 4.368519657, Training Accuracy: 8.096\n",
            "Worker 7, [06/18]: Training Loss: 4.081613473, Training Accuracy: 7.584\n",
            "Worker 7, [07/18]: Training Loss: 3.968511859, Training Accuracy: 9.232\n",
            "Worker 7, [08/18]: Training Loss: 3.892949858, Training Accuracy: 9.680\n",
            "Worker 7, [09/18]: Training Loss: 4.157832759, Training Accuracy: 8.000\n",
            "Worker 7, [10/18]: Training Loss: 3.936343356, Training Accuracy: 8.880\n",
            "Worker 7, [11/18]: Training Loss: 3.839176660, Training Accuracy: 9.888\n",
            "Worker 7, [12/18]: Training Loss: 3.761000439, Training Accuracy: 11.872\n",
            "Worker 7, [13/18]: Training Loss: 4.084041856, Training Accuracy: 7.728\n",
            "Worker 7, [14/18]: Training Loss: 3.861693224, Training Accuracy: 10.032\n",
            "Worker 7, [15/18]: Training Loss: 3.757632212, Training Accuracy: 11.520\n",
            "Worker 7, [16/18]: Training Loss: 3.663990736, Training Accuracy: 12.672\n",
            "Worker 7, [17/18]: Training Loss: 3.997307624, Training Accuracy: 8.288\n",
            "Worker 7, [18/18]: Training Loss: 3.805920774, Training Accuracy: 10.880\n",
            "Time taken for training worker 7: 0:00:48.359942\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.781672466, Training Accuracy: 11.344\n",
            "Worker 8, [02/18]: Training Loss: 3.748317276, Training Accuracy: 12.064\n",
            "Worker 8, [03/18]: Training Loss: 3.702020129, Training Accuracy: 13.552\n",
            "Worker 8, [04/18]: Training Loss: 3.650516359, Training Accuracy: 14.048\n",
            "Worker 8, [05/18]: Training Loss: 4.354720009, Training Accuracy: 7.888\n",
            "Worker 8, [06/18]: Training Loss: 4.069922639, Training Accuracy: 8.080\n",
            "Worker 8, [07/18]: Training Loss: 3.958510890, Training Accuracy: 8.704\n",
            "Worker 8, [08/18]: Training Loss: 3.887575583, Training Accuracy: 9.712\n",
            "Worker 8, [09/18]: Training Loss: 4.138283068, Training Accuracy: 7.504\n",
            "Worker 8, [10/18]: Training Loss: 3.921202149, Training Accuracy: 9.552\n",
            "Worker 8, [11/18]: Training Loss: 3.826073926, Training Accuracy: 10.736\n",
            "Worker 8, [12/18]: Training Loss: 3.748419307, Training Accuracy: 11.728\n",
            "Worker 8, [13/18]: Training Loss: 4.061321302, Training Accuracy: 7.872\n",
            "Worker 8, [14/18]: Training Loss: 3.861863611, Training Accuracy: 10.320\n",
            "Worker 8, [15/18]: Training Loss: 3.762203219, Training Accuracy: 11.376\n",
            "Worker 8, [16/18]: Training Loss: 3.660017230, Training Accuracy: 13.104\n",
            "Worker 8, [17/18]: Training Loss: 4.010273620, Training Accuracy: 8.784\n",
            "Worker 8, [18/18]: Training Loss: 3.794945152, Training Accuracy: 10.800\n",
            "Time taken for training worker 8: 0:00:47.267597\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000692\n",
            "Local Step 02: Test Loss: 3.736208372, Test Accuracy: 12.550\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.784081043, Training Accuracy: 12.080\n",
            "Worker 1, [02/18]: Training Loss: 3.645292538, Training Accuracy: 14.320\n",
            "Worker 1, [03/18]: Training Loss: 3.557946585, Training Accuracy: 15.280\n",
            "Worker 1, [04/18]: Training Loss: 3.462846111, Training Accuracy: 16.704\n",
            "Worker 1, [05/18]: Training Loss: 4.000717669, Training Accuracy: 9.440\n",
            "Worker 1, [06/18]: Training Loss: 3.785033221, Training Accuracy: 11.600\n",
            "Worker 1, [07/18]: Training Loss: 3.653542414, Training Accuracy: 13.824\n",
            "Worker 1, [08/18]: Training Loss: 3.525241708, Training Accuracy: 15.808\n",
            "Worker 1, [09/18]: Training Loss: 3.915700285, Training Accuracy: 10.272\n",
            "Worker 1, [10/18]: Training Loss: 3.692788397, Training Accuracy: 13.040\n",
            "Worker 1, [11/18]: Training Loss: 3.573150462, Training Accuracy: 14.864\n",
            "Worker 1, [12/18]: Training Loss: 3.487397919, Training Accuracy: 16.912\n",
            "Worker 1, [13/18]: Training Loss: 3.852552684, Training Accuracy: 12.112\n",
            "Worker 1, [14/18]: Training Loss: 3.671757090, Training Accuracy: 14.432\n",
            "Worker 1, [15/18]: Training Loss: 3.579364996, Training Accuracy: 15.136\n",
            "Worker 1, [16/18]: Training Loss: 3.532313310, Training Accuracy: 16.832\n",
            "Worker 1, [17/18]: Training Loss: 3.973630090, Training Accuracy: 14.400\n",
            "Worker 1, [18/18]: Training Loss: 3.836976986, Training Accuracy: 14.544\n",
            "Time taken for training worker 1: 0:00:48.891977\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.870509328, Training Accuracy: 10.256\n",
            "Worker 2, [02/18]: Training Loss: 3.698345362, Training Accuracy: 12.336\n",
            "Worker 2, [03/18]: Training Loss: 3.579620678, Training Accuracy: 13.920\n",
            "Worker 2, [04/18]: Training Loss: 3.459366071, Training Accuracy: 15.584\n",
            "Worker 2, [05/18]: Training Loss: 3.925179953, Training Accuracy: 10.112\n",
            "Worker 2, [06/18]: Training Loss: 3.690248236, Training Accuracy: 12.720\n",
            "Worker 2, [07/18]: Training Loss: 3.565675699, Training Accuracy: 14.400\n",
            "Worker 2, [08/18]: Training Loss: 3.433898500, Training Accuracy: 16.896\n",
            "Worker 2, [09/18]: Training Loss: 3.829994992, Training Accuracy: 11.472\n",
            "Worker 2, [10/18]: Training Loss: 3.621898060, Training Accuracy: 14.048\n",
            "Worker 2, [11/18]: Training Loss: 3.486051581, Training Accuracy: 15.536\n",
            "Worker 2, [12/18]: Training Loss: 3.402874307, Training Accuracy: 17.152\n",
            "Worker 2, [13/18]: Training Loss: 3.752477157, Training Accuracy: 13.200\n",
            "Worker 2, [14/18]: Training Loss: 3.570887454, Training Accuracy: 14.960\n",
            "Worker 2, [15/18]: Training Loss: 3.475846945, Training Accuracy: 16.544\n",
            "Worker 2, [16/18]: Training Loss: 3.417250008, Training Accuracy: 17.968\n",
            "Worker 2, [17/18]: Training Loss: 3.863862539, Training Accuracy: 15.936\n",
            "Worker 2, [18/18]: Training Loss: 3.721419147, Training Accuracy: 14.912\n",
            "Time taken for training worker 2: 0:00:48.129451\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.839773648, Training Accuracy: 11.072\n",
            "Worker 3, [02/18]: Training Loss: 3.670308787, Training Accuracy: 13.904\n",
            "Worker 3, [03/18]: Training Loss: 3.544983256, Training Accuracy: 15.728\n",
            "Worker 3, [04/18]: Training Loss: 3.443836565, Training Accuracy: 17.104\n",
            "Worker 3, [05/18]: Training Loss: 3.943047472, Training Accuracy: 10.032\n",
            "Worker 3, [06/18]: Training Loss: 3.718222635, Training Accuracy: 13.168\n",
            "Worker 3, [07/18]: Training Loss: 3.568683792, Training Accuracy: 15.376\n",
            "Worker 3, [08/18]: Training Loss: 3.460149135, Training Accuracy: 17.040\n",
            "Worker 3, [09/18]: Training Loss: 3.858603015, Training Accuracy: 10.912\n",
            "Worker 3, [10/18]: Training Loss: 3.644720849, Training Accuracy: 14.768\n",
            "Worker 3, [11/18]: Training Loss: 3.511839772, Training Accuracy: 16.416\n",
            "Worker 3, [12/18]: Training Loss: 3.403888089, Training Accuracy: 18.240\n",
            "Worker 3, [13/18]: Training Loss: 3.777138002, Training Accuracy: 13.664\n",
            "Worker 3, [14/18]: Training Loss: 3.592279244, Training Accuracy: 14.832\n",
            "Worker 3, [15/18]: Training Loss: 3.496591918, Training Accuracy: 17.296\n",
            "Worker 3, [16/18]: Training Loss: 3.435713415, Training Accuracy: 18.624\n",
            "Worker 3, [17/18]: Training Loss: 3.902288624, Training Accuracy: 15.312\n",
            "Worker 3, [18/18]: Training Loss: 3.751231354, Training Accuracy: 15.024\n",
            "Time taken for training worker 3: 0:00:46.728843\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.837480533, Training Accuracy: 11.344\n",
            "Worker 4, [02/18]: Training Loss: 3.638978097, Training Accuracy: 13.952\n",
            "Worker 4, [03/18]: Training Loss: 3.528968449, Training Accuracy: 15.600\n",
            "Worker 4, [04/18]: Training Loss: 3.433072784, Training Accuracy: 17.504\n",
            "Worker 4, [05/18]: Training Loss: 3.939110537, Training Accuracy: 9.904\n",
            "Worker 4, [06/18]: Training Loss: 3.709168215, Training Accuracy: 12.336\n",
            "Worker 4, [07/18]: Training Loss: 3.570190483, Training Accuracy: 14.560\n",
            "Worker 4, [08/18]: Training Loss: 3.452906847, Training Accuracy: 16.496\n",
            "Worker 4, [09/18]: Training Loss: 3.850901475, Training Accuracy: 11.472\n",
            "Worker 4, [10/18]: Training Loss: 3.628140564, Training Accuracy: 14.784\n",
            "Worker 4, [11/18]: Training Loss: 3.487010056, Training Accuracy: 16.608\n",
            "Worker 4, [12/18]: Training Loss: 3.397803540, Training Accuracy: 17.552\n",
            "Worker 4, [13/18]: Training Loss: 3.770666412, Training Accuracy: 13.920\n",
            "Worker 4, [14/18]: Training Loss: 3.576102712, Training Accuracy: 15.920\n",
            "Worker 4, [15/18]: Training Loss: 3.487092536, Training Accuracy: 16.688\n",
            "Worker 4, [16/18]: Training Loss: 3.419680255, Training Accuracy: 18.000\n",
            "Worker 4, [17/18]: Training Loss: 3.891593595, Training Accuracy: 16.224\n",
            "Worker 4, [18/18]: Training Loss: 3.745108665, Training Accuracy: 15.600\n",
            "Time taken for training worker 4: 0:00:48.230968\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.829318930, Training Accuracy: 11.344\n",
            "Worker 5, [02/18]: Training Loss: 3.659738601, Training Accuracy: 13.888\n",
            "Worker 5, [03/18]: Training Loss: 3.541913492, Training Accuracy: 15.776\n",
            "Worker 5, [04/18]: Training Loss: 3.418014597, Training Accuracy: 17.680\n",
            "Worker 5, [05/18]: Training Loss: 3.933081727, Training Accuracy: 9.984\n",
            "Worker 5, [06/18]: Training Loss: 3.713251605, Training Accuracy: 12.672\n",
            "Worker 5, [07/18]: Training Loss: 3.568725073, Training Accuracy: 15.760\n",
            "Worker 5, [08/18]: Training Loss: 3.444702601, Training Accuracy: 17.280\n",
            "Worker 5, [09/18]: Training Loss: 3.838663802, Training Accuracy: 12.208\n",
            "Worker 5, [10/18]: Training Loss: 3.612196399, Training Accuracy: 14.880\n",
            "Worker 5, [11/18]: Training Loss: 3.499752244, Training Accuracy: 16.272\n",
            "Worker 5, [12/18]: Training Loss: 3.392034409, Training Accuracy: 18.064\n",
            "Worker 5, [13/18]: Training Loss: 3.775517658, Training Accuracy: 12.976\n",
            "Worker 5, [14/18]: Training Loss: 3.573830573, Training Accuracy: 14.784\n",
            "Worker 5, [15/18]: Training Loss: 3.484088129, Training Accuracy: 16.688\n",
            "Worker 5, [16/18]: Training Loss: 3.416954055, Training Accuracy: 18.416\n",
            "Worker 5, [17/18]: Training Loss: 3.897082920, Training Accuracy: 15.152\n",
            "Worker 5, [18/18]: Training Loss: 3.743330396, Training Accuracy: 15.072\n",
            "Time taken for training worker 5: 0:00:48.712395\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.830928272, Training Accuracy: 10.416\n",
            "Worker 6, [02/18]: Training Loss: 3.634197748, Training Accuracy: 13.856\n",
            "Worker 6, [03/18]: Training Loss: 3.520471828, Training Accuracy: 15.776\n",
            "Worker 6, [04/18]: Training Loss: 3.418085986, Training Accuracy: 16.992\n",
            "Worker 6, [05/18]: Training Loss: 3.946560602, Training Accuracy: 9.344\n",
            "Worker 6, [06/18]: Training Loss: 3.710449129, Training Accuracy: 12.400\n",
            "Worker 6, [07/18]: Training Loss: 3.582430674, Training Accuracy: 14.128\n",
            "Worker 6, [08/18]: Training Loss: 3.468930563, Training Accuracy: 16.528\n",
            "Worker 6, [09/18]: Training Loss: 3.847735473, Training Accuracy: 11.552\n",
            "Worker 6, [10/18]: Training Loss: 3.636248968, Training Accuracy: 14.096\n",
            "Worker 6, [11/18]: Training Loss: 3.496045424, Training Accuracy: 16.224\n",
            "Worker 6, [12/18]: Training Loss: 3.403259876, Training Accuracy: 18.128\n",
            "Worker 6, [13/18]: Training Loss: 3.777760494, Training Accuracy: 13.440\n",
            "Worker 6, [14/18]: Training Loss: 3.588245810, Training Accuracy: 15.264\n",
            "Worker 6, [15/18]: Training Loss: 3.492856062, Training Accuracy: 16.752\n",
            "Worker 6, [16/18]: Training Loss: 3.423958540, Training Accuracy: 17.856\n",
            "Worker 6, [17/18]: Training Loss: 3.895933762, Training Accuracy: 15.248\n",
            "Worker 6, [18/18]: Training Loss: 3.744410980, Training Accuracy: 15.312\n",
            "Time taken for training worker 6: 0:00:47.584561\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.843950936, Training Accuracy: 10.496\n",
            "Worker 7, [02/18]: Training Loss: 3.674875748, Training Accuracy: 12.752\n",
            "Worker 7, [03/18]: Training Loss: 3.530430059, Training Accuracy: 15.504\n",
            "Worker 7, [04/18]: Training Loss: 3.420858050, Training Accuracy: 16.992\n",
            "Worker 7, [05/18]: Training Loss: 3.922939086, Training Accuracy: 10.576\n",
            "Worker 7, [06/18]: Training Loss: 3.715576666, Training Accuracy: 12.304\n",
            "Worker 7, [07/18]: Training Loss: 3.579338035, Training Accuracy: 14.656\n",
            "Worker 7, [08/18]: Training Loss: 3.471660458, Training Accuracy: 16.464\n",
            "Worker 7, [09/18]: Training Loss: 3.855043842, Training Accuracy: 11.200\n",
            "Worker 7, [10/18]: Training Loss: 3.650559202, Training Accuracy: 13.344\n",
            "Worker 7, [11/18]: Training Loss: 3.522917606, Training Accuracy: 15.872\n",
            "Worker 7, [12/18]: Training Loss: 3.413880005, Training Accuracy: 17.808\n",
            "Worker 7, [13/18]: Training Loss: 3.773604612, Training Accuracy: 12.480\n",
            "Worker 7, [14/18]: Training Loss: 3.588537423, Training Accuracy: 14.832\n",
            "Worker 7, [15/18]: Training Loss: 3.490069329, Training Accuracy: 16.512\n",
            "Worker 7, [16/18]: Training Loss: 3.445791103, Training Accuracy: 17.056\n",
            "Worker 7, [17/18]: Training Loss: 3.876773978, Training Accuracy: 15.216\n",
            "Worker 7, [18/18]: Training Loss: 3.732689950, Training Accuracy: 15.280\n",
            "Time taken for training worker 7: 0:00:48.347229\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.853276175, Training Accuracy: 9.984\n",
            "Worker 8, [02/18]: Training Loss: 3.678221771, Training Accuracy: 12.688\n",
            "Worker 8, [03/18]: Training Loss: 3.541816891, Training Accuracy: 15.408\n",
            "Worker 8, [04/18]: Training Loss: 3.445631777, Training Accuracy: 16.240\n",
            "Worker 8, [05/18]: Training Loss: 3.922591750, Training Accuracy: 9.552\n",
            "Worker 8, [06/18]: Training Loss: 3.695939453, Training Accuracy: 12.560\n",
            "Worker 8, [07/18]: Training Loss: 3.570173799, Training Accuracy: 14.352\n",
            "Worker 8, [08/18]: Training Loss: 3.472161174, Training Accuracy: 15.616\n",
            "Worker 8, [09/18]: Training Loss: 3.838555611, Training Accuracy: 10.336\n",
            "Worker 8, [10/18]: Training Loss: 3.645222352, Training Accuracy: 13.648\n",
            "Worker 8, [11/18]: Training Loss: 3.516143631, Training Accuracy: 15.280\n",
            "Worker 8, [12/18]: Training Loss: 3.415036654, Training Accuracy: 17.520\n",
            "Worker 8, [13/18]: Training Loss: 3.776450301, Training Accuracy: 12.720\n",
            "Worker 8, [14/18]: Training Loss: 3.580555675, Training Accuracy: 14.608\n",
            "Worker 8, [15/18]: Training Loss: 3.491519986, Training Accuracy: 16.416\n",
            "Worker 8, [16/18]: Training Loss: 3.419521349, Training Accuracy: 17.552\n",
            "Worker 8, [17/18]: Training Loss: 3.868941081, Training Accuracy: 14.880\n",
            "Worker 8, [18/18]: Training Loss: 3.725575960, Training Accuracy: 14.912\n",
            "Time taken for training worker 8: 0:00:47.874379\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000709\n",
            "Local Step 03: Test Loss: 3.763178470, Test Accuracy: 13.920\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.820153628, Training Accuracy: 13.184\n",
            "Worker 1, [02/18]: Training Loss: 3.807710531, Training Accuracy: 13.696\n",
            "Worker 1, [03/18]: Training Loss: 3.767121364, Training Accuracy: 13.520\n",
            "Worker 1, [04/18]: Training Loss: 3.714761510, Training Accuracy: 14.496\n",
            "Worker 1, [05/18]: Training Loss: 3.818201892, Training Accuracy: 13.504\n",
            "Worker 1, [06/18]: Training Loss: 3.679618923, Training Accuracy: 13.472\n",
            "Worker 1, [07/18]: Training Loss: 3.635055544, Training Accuracy: 14.400\n",
            "Worker 1, [08/18]: Training Loss: 3.579020196, Training Accuracy: 14.736\n",
            "Worker 1, [09/18]: Training Loss: 3.760920753, Training Accuracy: 13.008\n",
            "Worker 1, [10/18]: Training Loss: 3.634075851, Training Accuracy: 14.224\n",
            "Worker 1, [11/18]: Training Loss: 3.559437370, Training Accuracy: 15.440\n",
            "Worker 1, [12/18]: Training Loss: 3.493986757, Training Accuracy: 16.832\n",
            "Worker 1, [13/18]: Training Loss: 3.759211764, Training Accuracy: 12.304\n",
            "Worker 1, [14/18]: Training Loss: 3.626361078, Training Accuracy: 14.480\n",
            "Worker 1, [15/18]: Training Loss: 3.540487868, Training Accuracy: 15.616\n",
            "Worker 1, [16/18]: Training Loss: 3.443440831, Training Accuracy: 17.008\n",
            "Worker 1, [17/18]: Training Loss: 3.744344541, Training Accuracy: 13.104\n",
            "Worker 1, [18/18]: Training Loss: 3.562699478, Training Accuracy: 15.312\n",
            "Time taken for training worker 1: 0:00:48.798827\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.658385038, Training Accuracy: 14.048\n",
            "Worker 2, [02/18]: Training Loss: 3.609372421, Training Accuracy: 14.896\n",
            "Worker 2, [03/18]: Training Loss: 3.513745016, Training Accuracy: 16.640\n",
            "Worker 2, [04/18]: Training Loss: 3.448042145, Training Accuracy: 17.840\n",
            "Worker 2, [05/18]: Training Loss: 3.700725057, Training Accuracy: 14.960\n",
            "Worker 2, [06/18]: Training Loss: 3.549920406, Training Accuracy: 16.016\n",
            "Worker 2, [07/18]: Training Loss: 3.501034695, Training Accuracy: 15.904\n",
            "Worker 2, [08/18]: Training Loss: 3.458338847, Training Accuracy: 16.640\n",
            "Worker 2, [09/18]: Training Loss: 3.645914832, Training Accuracy: 14.272\n",
            "Worker 2, [10/18]: Training Loss: 3.515023665, Training Accuracy: 15.600\n",
            "Worker 2, [11/18]: Training Loss: 3.458682002, Training Accuracy: 16.000\n",
            "Worker 2, [12/18]: Training Loss: 3.397317276, Training Accuracy: 17.424\n",
            "Worker 2, [13/18]: Training Loss: 3.638110978, Training Accuracy: 14.160\n",
            "Worker 2, [14/18]: Training Loss: 3.497469807, Training Accuracy: 16.160\n",
            "Worker 2, [15/18]: Training Loss: 3.440330128, Training Accuracy: 16.256\n",
            "Worker 2, [16/18]: Training Loss: 3.352295681, Training Accuracy: 18.288\n",
            "Worker 2, [17/18]: Training Loss: 3.633127609, Training Accuracy: 13.680\n",
            "Worker 2, [18/18]: Training Loss: 3.485114883, Training Accuracy: 16.432\n",
            "Time taken for training worker 2: 0:00:48.389482\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.647219395, Training Accuracy: 13.760\n",
            "Worker 3, [02/18]: Training Loss: 3.608483740, Training Accuracy: 14.832\n",
            "Worker 3, [03/18]: Training Loss: 3.513990113, Training Accuracy: 16.960\n",
            "Worker 3, [04/18]: Training Loss: 3.422000031, Training Accuracy: 18.992\n",
            "Worker 3, [05/18]: Training Loss: 3.704263921, Training Accuracy: 15.808\n",
            "Worker 3, [06/18]: Training Loss: 3.569617395, Training Accuracy: 15.600\n",
            "Worker 3, [07/18]: Training Loss: 3.522346450, Training Accuracy: 16.560\n",
            "Worker 3, [08/18]: Training Loss: 3.475773809, Training Accuracy: 16.720\n",
            "Worker 3, [09/18]: Training Loss: 3.654764180, Training Accuracy: 14.848\n",
            "Worker 3, [10/18]: Training Loss: 3.557075252, Training Accuracy: 15.424\n",
            "Worker 3, [11/18]: Training Loss: 3.453506314, Training Accuracy: 17.360\n",
            "Worker 3, [12/18]: Training Loss: 3.403309912, Training Accuracy: 17.712\n",
            "Worker 3, [13/18]: Training Loss: 3.674568018, Training Accuracy: 12.944\n",
            "Worker 3, [14/18]: Training Loss: 3.505788664, Training Accuracy: 16.320\n",
            "Worker 3, [15/18]: Training Loss: 3.442680748, Training Accuracy: 17.040\n",
            "Worker 3, [16/18]: Training Loss: 3.353790269, Training Accuracy: 18.544\n",
            "Worker 3, [17/18]: Training Loss: 3.648543630, Training Accuracy: 14.240\n",
            "Worker 3, [18/18]: Training Loss: 3.492537603, Training Accuracy: 16.208\n",
            "Time taken for training worker 3: 0:00:48.194285\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.539661047, Training Accuracy: 15.200\n",
            "Worker 4, [02/18]: Training Loss: 3.515521998, Training Accuracy: 15.744\n",
            "Worker 4, [03/18]: Training Loss: 3.467164551, Training Accuracy: 17.872\n",
            "Worker 4, [04/18]: Training Loss: 3.387977549, Training Accuracy: 19.280\n",
            "Worker 4, [05/18]: Training Loss: 3.696750492, Training Accuracy: 15.600\n",
            "Worker 4, [06/18]: Training Loss: 3.550249886, Training Accuracy: 15.632\n",
            "Worker 4, [07/18]: Training Loss: 3.499164426, Training Accuracy: 16.832\n",
            "Worker 4, [08/18]: Training Loss: 3.447924434, Training Accuracy: 17.184\n",
            "Worker 4, [09/18]: Training Loss: 3.662525858, Training Accuracy: 14.624\n",
            "Worker 4, [10/18]: Training Loss: 3.519272658, Training Accuracy: 16.048\n",
            "Worker 4, [11/18]: Training Loss: 3.456196697, Training Accuracy: 16.832\n",
            "Worker 4, [12/18]: Training Loss: 3.398838968, Training Accuracy: 17.824\n",
            "Worker 4, [13/18]: Training Loss: 3.664815621, Training Accuracy: 13.888\n",
            "Worker 4, [14/18]: Training Loss: 3.516914798, Training Accuracy: 16.224\n",
            "Worker 4, [15/18]: Training Loss: 3.413021472, Training Accuracy: 18.336\n",
            "Worker 4, [16/18]: Training Loss: 3.348572918, Training Accuracy: 17.808\n",
            "Worker 4, [17/18]: Training Loss: 3.622211726, Training Accuracy: 14.944\n",
            "Worker 4, [18/18]: Training Loss: 3.479140754, Training Accuracy: 16.800\n",
            "Time taken for training worker 4: 0:00:48.569616\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.623623291, Training Accuracy: 16.096\n",
            "Worker 5, [02/18]: Training Loss: 3.543152824, Training Accuracy: 16.608\n",
            "Worker 5, [03/18]: Training Loss: 3.453231228, Training Accuracy: 18.144\n",
            "Worker 5, [04/18]: Training Loss: 3.398875584, Training Accuracy: 19.232\n",
            "Worker 5, [05/18]: Training Loss: 3.706435298, Training Accuracy: 15.232\n",
            "Worker 5, [06/18]: Training Loss: 3.563041072, Training Accuracy: 15.584\n",
            "Worker 5, [07/18]: Training Loss: 3.489618773, Training Accuracy: 16.320\n",
            "Worker 5, [08/18]: Training Loss: 3.448152528, Training Accuracy: 17.456\n",
            "Worker 5, [09/18]: Training Loss: 3.646729075, Training Accuracy: 14.064\n",
            "Worker 5, [10/18]: Training Loss: 3.522346061, Training Accuracy: 15.232\n",
            "Worker 5, [11/18]: Training Loss: 3.453398505, Training Accuracy: 16.960\n",
            "Worker 5, [12/18]: Training Loss: 3.392234559, Training Accuracy: 17.792\n",
            "Worker 5, [13/18]: Training Loss: 3.651745390, Training Accuracy: 14.640\n",
            "Worker 5, [14/18]: Training Loss: 3.507955712, Training Accuracy: 15.984\n",
            "Worker 5, [15/18]: Training Loss: 3.422820622, Training Accuracy: 17.520\n",
            "Worker 5, [16/18]: Training Loss: 3.354065265, Training Accuracy: 18.368\n",
            "Worker 5, [17/18]: Training Loss: 3.640983686, Training Accuracy: 14.752\n",
            "Worker 5, [18/18]: Training Loss: 3.479509456, Training Accuracy: 15.904\n",
            "Time taken for training worker 5: 0:00:47.927345\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.587845316, Training Accuracy: 15.568\n",
            "Worker 6, [02/18]: Training Loss: 3.532663929, Training Accuracy: 16.560\n",
            "Worker 6, [03/18]: Training Loss: 3.462442079, Training Accuracy: 17.936\n",
            "Worker 6, [04/18]: Training Loss: 3.388831187, Training Accuracy: 19.696\n",
            "Worker 6, [05/18]: Training Loss: 3.693832631, Training Accuracy: 15.616\n",
            "Worker 6, [06/18]: Training Loss: 3.558393130, Training Accuracy: 15.712\n",
            "Worker 6, [07/18]: Training Loss: 3.501215076, Training Accuracy: 16.240\n",
            "Worker 6, [08/18]: Training Loss: 3.464191588, Training Accuracy: 16.528\n",
            "Worker 6, [09/18]: Training Loss: 3.658999263, Training Accuracy: 14.304\n",
            "Worker 6, [10/18]: Training Loss: 3.522732358, Training Accuracy: 15.648\n",
            "Worker 6, [11/18]: Training Loss: 3.455151748, Training Accuracy: 16.112\n",
            "Worker 6, [12/18]: Training Loss: 3.383791228, Training Accuracy: 17.728\n",
            "Worker 6, [13/18]: Training Loss: 3.647598427, Training Accuracy: 13.616\n",
            "Worker 6, [14/18]: Training Loss: 3.499631067, Training Accuracy: 16.336\n",
            "Worker 6, [15/18]: Training Loss: 3.434928996, Training Accuracy: 16.080\n",
            "Worker 6, [16/18]: Training Loss: 3.347466620, Training Accuracy: 18.272\n",
            "Worker 6, [17/18]: Training Loss: 3.609789853, Training Accuracy: 14.608\n",
            "Worker 6, [18/18]: Training Loss: 3.493539601, Training Accuracy: 16.336\n",
            "Time taken for training worker 6: 0:00:46.473642\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.575752869, Training Accuracy: 15.056\n",
            "Worker 7, [02/18]: Training Loss: 3.535458411, Training Accuracy: 15.856\n",
            "Worker 7, [03/18]: Training Loss: 3.457920924, Training Accuracy: 16.848\n",
            "Worker 7, [04/18]: Training Loss: 3.408397585, Training Accuracy: 19.280\n",
            "Worker 7, [05/18]: Training Loss: 3.704697787, Training Accuracy: 15.088\n",
            "Worker 7, [06/18]: Training Loss: 3.556776132, Training Accuracy: 15.600\n",
            "Worker 7, [07/18]: Training Loss: 3.502415265, Training Accuracy: 16.112\n",
            "Worker 7, [08/18]: Training Loss: 3.468728102, Training Accuracy: 16.432\n",
            "Worker 7, [09/18]: Training Loss: 3.651225978, Training Accuracy: 13.984\n",
            "Worker 7, [10/18]: Training Loss: 3.535624764, Training Accuracy: 15.888\n",
            "Worker 7, [11/18]: Training Loss: 3.472072971, Training Accuracy: 16.112\n",
            "Worker 7, [12/18]: Training Loss: 3.419890535, Training Accuracy: 17.776\n",
            "Worker 7, [13/18]: Training Loss: 3.674712305, Training Accuracy: 13.184\n",
            "Worker 7, [14/18]: Training Loss: 3.530790117, Training Accuracy: 15.840\n",
            "Worker 7, [15/18]: Training Loss: 3.441285165, Training Accuracy: 16.960\n",
            "Worker 7, [16/18]: Training Loss: 3.393440950, Training Accuracy: 17.696\n",
            "Worker 7, [17/18]: Training Loss: 3.627047115, Training Accuracy: 14.272\n",
            "Worker 7, [18/18]: Training Loss: 3.496456725, Training Accuracy: 15.840\n",
            "Time taken for training worker 7: 0:00:46.383814\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.615671095, Training Accuracy: 14.448\n",
            "Worker 8, [02/18]: Training Loss: 3.567829643, Training Accuracy: 15.040\n",
            "Worker 8, [03/18]: Training Loss: 3.486687322, Training Accuracy: 16.592\n",
            "Worker 8, [04/18]: Training Loss: 3.422305791, Training Accuracy: 17.872\n",
            "Worker 8, [05/18]: Training Loss: 3.698864672, Training Accuracy: 14.352\n",
            "Worker 8, [06/18]: Training Loss: 3.564561146, Training Accuracy: 15.136\n",
            "Worker 8, [07/18]: Training Loss: 3.516009995, Training Accuracy: 16.128\n",
            "Worker 8, [08/18]: Training Loss: 3.467493009, Training Accuracy: 16.304\n",
            "Worker 8, [09/18]: Training Loss: 3.648983427, Training Accuracy: 13.984\n",
            "Worker 8, [10/18]: Training Loss: 3.532897450, Training Accuracy: 15.184\n",
            "Worker 8, [11/18]: Training Loss: 3.477156250, Training Accuracy: 15.680\n",
            "Worker 8, [12/18]: Training Loss: 3.408441184, Training Accuracy: 18.016\n",
            "Worker 8, [13/18]: Training Loss: 3.685321645, Training Accuracy: 12.704\n",
            "Worker 8, [14/18]: Training Loss: 3.539720616, Training Accuracy: 14.912\n",
            "Worker 8, [15/18]: Training Loss: 3.468441134, Training Accuracy: 15.968\n",
            "Worker 8, [16/18]: Training Loss: 3.369274582, Training Accuracy: 17.728\n",
            "Worker 8, [17/18]: Training Loss: 3.635449013, Training Accuracy: 13.616\n",
            "Worker 8, [18/18]: Training Loss: 3.510664273, Training Accuracy: 15.296\n",
            "Time taken for training worker 8: 0:00:49.052516\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000801\n",
            "Local Step 04: Test Loss: 3.554180189, Test Accuracy: 15.660\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.576745719, Training Accuracy: 15.488\n",
            "Worker 1, [02/18]: Training Loss: 3.414613991, Training Accuracy: 17.392\n",
            "Worker 1, [03/18]: Training Loss: 3.326206047, Training Accuracy: 19.520\n",
            "Worker 1, [04/18]: Training Loss: 3.224163739, Training Accuracy: 21.024\n",
            "Worker 1, [05/18]: Training Loss: 3.656601300, Training Accuracy: 13.968\n",
            "Worker 1, [06/18]: Training Loss: 3.511308928, Training Accuracy: 15.904\n",
            "Worker 1, [07/18]: Training Loss: 3.371424142, Training Accuracy: 18.176\n",
            "Worker 1, [08/18]: Training Loss: 3.271747711, Training Accuracy: 19.888\n",
            "Worker 1, [09/18]: Training Loss: 3.540694670, Training Accuracy: 16.784\n",
            "Worker 1, [10/18]: Training Loss: 3.398060932, Training Accuracy: 17.696\n",
            "Worker 1, [11/18]: Training Loss: 3.261738079, Training Accuracy: 20.576\n",
            "Worker 1, [12/18]: Training Loss: 3.192580673, Training Accuracy: 21.936\n",
            "Worker 1, [13/18]: Training Loss: 3.439353999, Training Accuracy: 19.280\n",
            "Worker 1, [14/18]: Training Loss: 3.300744327, Training Accuracy: 20.464\n",
            "Worker 1, [15/18]: Training Loss: 3.217589060, Training Accuracy: 21.776\n",
            "Worker 1, [16/18]: Training Loss: 3.169482197, Training Accuracy: 22.800\n",
            "Worker 1, [17/18]: Training Loss: 3.462628486, Training Accuracy: 20.720\n",
            "Worker 1, [18/18]: Training Loss: 3.361107826, Training Accuracy: 20.816\n",
            "Time taken for training worker 1: 0:00:48.167162\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.653179774, Training Accuracy: 14.160\n",
            "Worker 2, [02/18]: Training Loss: 3.476886109, Training Accuracy: 16.608\n",
            "Worker 2, [03/18]: Training Loss: 3.348465744, Training Accuracy: 18.672\n",
            "Worker 2, [04/18]: Training Loss: 3.243640676, Training Accuracy: 19.728\n",
            "Worker 2, [05/18]: Training Loss: 3.564936879, Training Accuracy: 15.328\n",
            "Worker 2, [06/18]: Training Loss: 3.372285575, Training Accuracy: 17.808\n",
            "Worker 2, [07/18]: Training Loss: 3.294984730, Training Accuracy: 18.928\n",
            "Worker 2, [08/18]: Training Loss: 3.177599335, Training Accuracy: 20.928\n",
            "Worker 2, [09/18]: Training Loss: 3.452534678, Training Accuracy: 16.528\n",
            "Worker 2, [10/18]: Training Loss: 3.300335816, Training Accuracy: 19.552\n",
            "Worker 2, [11/18]: Training Loss: 3.170581645, Training Accuracy: 21.200\n",
            "Worker 2, [12/18]: Training Loss: 3.069955789, Training Accuracy: 23.504\n",
            "Worker 2, [13/18]: Training Loss: 3.321299332, Training Accuracy: 18.896\n",
            "Worker 2, [14/18]: Training Loss: 3.179581598, Training Accuracy: 21.792\n",
            "Worker 2, [15/18]: Training Loss: 3.111118978, Training Accuracy: 22.752\n",
            "Worker 2, [16/18]: Training Loss: 3.056016654, Training Accuracy: 24.000\n",
            "Worker 2, [17/18]: Training Loss: 3.329125808, Training Accuracy: 21.280\n",
            "Worker 2, [18/18]: Training Loss: 3.237750890, Training Accuracy: 21.296\n",
            "Time taken for training worker 2: 0:00:48.695774\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.630954339, Training Accuracy: 14.560\n",
            "Worker 3, [02/18]: Training Loss: 3.487238407, Training Accuracy: 17.024\n",
            "Worker 3, [03/18]: Training Loss: 3.343961399, Training Accuracy: 19.280\n",
            "Worker 3, [04/18]: Training Loss: 3.249498684, Training Accuracy: 20.656\n",
            "Worker 3, [05/18]: Training Loss: 3.590759640, Training Accuracy: 14.928\n",
            "Worker 3, [06/18]: Training Loss: 3.403750804, Training Accuracy: 17.904\n",
            "Worker 3, [07/18]: Training Loss: 3.300335607, Training Accuracy: 19.568\n",
            "Worker 3, [08/18]: Training Loss: 3.193355327, Training Accuracy: 21.328\n",
            "Worker 3, [09/18]: Training Loss: 3.479803995, Training Accuracy: 17.168\n",
            "Worker 3, [10/18]: Training Loss: 3.311507271, Training Accuracy: 19.920\n",
            "Worker 3, [11/18]: Training Loss: 3.188560172, Training Accuracy: 22.192\n",
            "Worker 3, [12/18]: Training Loss: 3.101977137, Training Accuracy: 23.488\n",
            "Worker 3, [13/18]: Training Loss: 3.336230037, Training Accuracy: 20.880\n",
            "Worker 3, [14/18]: Training Loss: 3.210572318, Training Accuracy: 21.792\n",
            "Worker 3, [15/18]: Training Loss: 3.122787580, Training Accuracy: 23.920\n",
            "Worker 3, [16/18]: Training Loss: 3.066172262, Training Accuracy: 24.544\n",
            "Worker 3, [17/18]: Training Loss: 3.357669881, Training Accuracy: 22.256\n",
            "Worker 3, [18/18]: Training Loss: 3.264263985, Training Accuracy: 22.384\n",
            "Time taken for training worker 3: 0:00:48.806938\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.582593531, Training Accuracy: 15.120\n",
            "Worker 4, [02/18]: Training Loss: 3.456118109, Training Accuracy: 17.152\n",
            "Worker 4, [03/18]: Training Loss: 3.350130410, Training Accuracy: 18.576\n",
            "Worker 4, [04/18]: Training Loss: 3.237923902, Training Accuracy: 20.992\n",
            "Worker 4, [05/18]: Training Loss: 3.557352565, Training Accuracy: 15.744\n",
            "Worker 4, [06/18]: Training Loss: 3.397997727, Training Accuracy: 18.176\n",
            "Worker 4, [07/18]: Training Loss: 3.287858905, Training Accuracy: 19.552\n",
            "Worker 4, [08/18]: Training Loss: 3.202638164, Training Accuracy: 21.056\n",
            "Worker 4, [09/18]: Training Loss: 3.433019336, Training Accuracy: 17.904\n",
            "Worker 4, [10/18]: Training Loss: 3.304749562, Training Accuracy: 20.336\n",
            "Worker 4, [11/18]: Training Loss: 3.188117708, Training Accuracy: 21.264\n",
            "Worker 4, [12/18]: Training Loss: 3.106735405, Training Accuracy: 23.056\n",
            "Worker 4, [13/18]: Training Loss: 3.328820044, Training Accuracy: 19.952\n",
            "Worker 4, [14/18]: Training Loss: 3.203110332, Training Accuracy: 21.696\n",
            "Worker 4, [15/18]: Training Loss: 3.131273588, Training Accuracy: 23.584\n",
            "Worker 4, [16/18]: Training Loss: 3.054383672, Training Accuracy: 24.448\n",
            "Worker 4, [17/18]: Training Loss: 3.340003062, Training Accuracy: 22.656\n",
            "Worker 4, [18/18]: Training Loss: 3.254054091, Training Accuracy: 22.080\n",
            "Time taken for training worker 4: 0:00:47.189321\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.618781452, Training Accuracy: 14.992\n",
            "Worker 5, [02/18]: Training Loss: 3.468944039, Training Accuracy: 16.976\n",
            "Worker 5, [03/18]: Training Loss: 3.320855644, Training Accuracy: 19.328\n",
            "Worker 5, [04/18]: Training Loss: 3.228231642, Training Accuracy: 20.896\n",
            "Worker 5, [05/18]: Training Loss: 3.558257563, Training Accuracy: 15.392\n",
            "Worker 5, [06/18]: Training Loss: 3.420756897, Training Accuracy: 17.184\n",
            "Worker 5, [07/18]: Training Loss: 3.293449448, Training Accuracy: 19.776\n",
            "Worker 5, [08/18]: Training Loss: 3.211869614, Training Accuracy: 21.072\n",
            "Worker 5, [09/18]: Training Loss: 3.442208027, Training Accuracy: 18.096\n",
            "Worker 5, [10/18]: Training Loss: 3.297799490, Training Accuracy: 19.504\n",
            "Worker 5, [11/18]: Training Loss: 3.197946972, Training Accuracy: 21.280\n",
            "Worker 5, [12/18]: Training Loss: 3.089739853, Training Accuracy: 22.880\n",
            "Worker 5, [13/18]: Training Loss: 3.328767954, Training Accuracy: 20.288\n",
            "Worker 5, [14/18]: Training Loss: 3.206062677, Training Accuracy: 21.184\n",
            "Worker 5, [15/18]: Training Loss: 3.107691242, Training Accuracy: 23.904\n",
            "Worker 5, [16/18]: Training Loss: 3.076833384, Training Accuracy: 23.792\n",
            "Worker 5, [17/18]: Training Loss: 3.332470585, Training Accuracy: 21.936\n",
            "Worker 5, [18/18]: Training Loss: 3.240022881, Training Accuracy: 21.920\n",
            "Time taken for training worker 5: 0:00:47.512774\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.618025169, Training Accuracy: 14.784\n",
            "Worker 6, [02/18]: Training Loss: 3.442695387, Training Accuracy: 18.032\n",
            "Worker 6, [03/18]: Training Loss: 3.317587471, Training Accuracy: 18.640\n",
            "Worker 6, [04/18]: Training Loss: 3.253595649, Training Accuracy: 20.272\n",
            "Worker 6, [05/18]: Training Loss: 3.562871938, Training Accuracy: 15.168\n",
            "Worker 6, [06/18]: Training Loss: 3.418777546, Training Accuracy: 17.856\n",
            "Worker 6, [07/18]: Training Loss: 3.288699663, Training Accuracy: 20.000\n",
            "Worker 6, [08/18]: Training Loss: 3.183927322, Training Accuracy: 20.832\n",
            "Worker 6, [09/18]: Training Loss: 3.461419200, Training Accuracy: 16.976\n",
            "Worker 6, [10/18]: Training Loss: 3.308113660, Training Accuracy: 19.264\n",
            "Worker 6, [11/18]: Training Loss: 3.181785832, Training Accuracy: 21.152\n",
            "Worker 6, [12/18]: Training Loss: 3.118492961, Training Accuracy: 22.240\n",
            "Worker 6, [13/18]: Training Loss: 3.328220815, Training Accuracy: 20.224\n",
            "Worker 6, [14/18]: Training Loss: 3.200621427, Training Accuracy: 21.360\n",
            "Worker 6, [15/18]: Training Loss: 3.118537265, Training Accuracy: 23.088\n",
            "Worker 6, [16/18]: Training Loss: 3.055615722, Training Accuracy: 24.320\n",
            "Worker 6, [17/18]: Training Loss: 3.353835103, Training Accuracy: 21.856\n",
            "Worker 6, [18/18]: Training Loss: 3.243771862, Training Accuracy: 21.808\n",
            "Time taken for training worker 6: 0:00:48.801125\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.611424872, Training Accuracy: 14.352\n",
            "Worker 7, [02/18]: Training Loss: 3.472906801, Training Accuracy: 16.208\n",
            "Worker 7, [03/18]: Training Loss: 3.363995175, Training Accuracy: 18.224\n",
            "Worker 7, [04/18]: Training Loss: 3.253601502, Training Accuracy: 20.288\n",
            "Worker 7, [05/18]: Training Loss: 3.545957595, Training Accuracy: 15.344\n",
            "Worker 7, [06/18]: Training Loss: 3.430762111, Training Accuracy: 17.312\n",
            "Worker 7, [07/18]: Training Loss: 3.290015128, Training Accuracy: 19.200\n",
            "Worker 7, [08/18]: Training Loss: 3.188345916, Training Accuracy: 20.768\n",
            "Worker 7, [09/18]: Training Loss: 3.468170275, Training Accuracy: 16.720\n",
            "Worker 7, [10/18]: Training Loss: 3.323604044, Training Accuracy: 18.880\n",
            "Worker 7, [11/18]: Training Loss: 3.209315032, Training Accuracy: 20.800\n",
            "Worker 7, [12/18]: Training Loss: 3.118816288, Training Accuracy: 23.184\n",
            "Worker 7, [13/18]: Training Loss: 3.339712802, Training Accuracy: 19.472\n",
            "Worker 7, [14/18]: Training Loss: 3.216879307, Training Accuracy: 21.152\n",
            "Worker 7, [15/18]: Training Loss: 3.128002481, Training Accuracy: 22.544\n",
            "Worker 7, [16/18]: Training Loss: 3.070384086, Training Accuracy: 24.464\n",
            "Worker 7, [17/18]: Training Loss: 3.358952464, Training Accuracy: 21.088\n",
            "Worker 7, [18/18]: Training Loss: 3.257885935, Training Accuracy: 21.584\n",
            "Time taken for training worker 7: 0:00:47.525925\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.617409796, Training Accuracy: 14.384\n",
            "Worker 8, [02/18]: Training Loss: 3.452865878, Training Accuracy: 16.624\n",
            "Worker 8, [03/18]: Training Loss: 3.359722442, Training Accuracy: 17.536\n",
            "Worker 8, [04/18]: Training Loss: 3.238934013, Training Accuracy: 20.224\n",
            "Worker 8, [05/18]: Training Loss: 3.584050779, Training Accuracy: 14.688\n",
            "Worker 8, [06/18]: Training Loss: 3.428067884, Training Accuracy: 16.800\n",
            "Worker 8, [07/18]: Training Loss: 3.305883298, Training Accuracy: 18.832\n",
            "Worker 8, [08/18]: Training Loss: 3.211539324, Training Accuracy: 20.256\n",
            "Worker 8, [09/18]: Training Loss: 3.449941034, Training Accuracy: 16.400\n",
            "Worker 8, [10/18]: Training Loss: 3.312142114, Training Accuracy: 18.672\n",
            "Worker 8, [11/18]: Training Loss: 3.198894004, Training Accuracy: 21.536\n",
            "Worker 8, [12/18]: Training Loss: 3.116727566, Training Accuracy: 22.752\n",
            "Worker 8, [13/18]: Training Loss: 3.333450911, Training Accuracy: 19.648\n",
            "Worker 8, [14/18]: Training Loss: 3.228566167, Training Accuracy: 20.560\n",
            "Worker 8, [15/18]: Training Loss: 3.142338444, Training Accuracy: 22.576\n",
            "Worker 8, [16/18]: Training Loss: 3.085351662, Training Accuracy: 23.936\n",
            "Worker 8, [17/18]: Training Loss: 3.350859192, Training Accuracy: 20.592\n",
            "Worker 8, [18/18]: Training Loss: 3.259414948, Training Accuracy: 21.216\n",
            "Time taken for training worker 8: 0:00:47.469478\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000703\n",
            "Local Step 05: Test Loss: 3.363078451, Test Accuracy: 20.380\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.453358721, Training Accuracy: 18.368\n",
            "Worker 1, [02/18]: Training Loss: 3.461790314, Training Accuracy: 18.672\n",
            "Worker 1, [03/18]: Training Loss: 3.430794224, Training Accuracy: 18.496\n",
            "Worker 1, [04/18]: Training Loss: 3.411187050, Training Accuracy: 18.880\n",
            "Worker 1, [05/18]: Training Loss: 3.396106623, Training Accuracy: 19.856\n",
            "Worker 1, [06/18]: Training Loss: 3.320805416, Training Accuracy: 20.128\n",
            "Worker 1, [07/18]: Training Loss: 3.278729855, Training Accuracy: 20.816\n",
            "Worker 1, [08/18]: Training Loss: 3.281453157, Training Accuracy: 20.416\n",
            "Worker 1, [09/18]: Training Loss: 3.421418190, Training Accuracy: 17.872\n",
            "Worker 1, [10/18]: Training Loss: 3.340743746, Training Accuracy: 19.136\n",
            "Worker 1, [11/18]: Training Loss: 3.299519084, Training Accuracy: 19.856\n",
            "Worker 1, [12/18]: Training Loss: 3.270826741, Training Accuracy: 19.920\n",
            "Worker 1, [13/18]: Training Loss: 3.482215577, Training Accuracy: 16.880\n",
            "Worker 1, [14/18]: Training Loss: 3.375524348, Training Accuracy: 18.896\n",
            "Worker 1, [15/18]: Training Loss: 3.319127835, Training Accuracy: 19.056\n",
            "Worker 1, [16/18]: Training Loss: 3.242560321, Training Accuracy: 20.272\n",
            "Worker 1, [17/18]: Training Loss: 3.472428010, Training Accuracy: 16.768\n",
            "Worker 1, [18/18]: Training Loss: 3.378370857, Training Accuracy: 18.352\n",
            "Time taken for training worker 1: 0:00:46.785109\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.554453957, Training Accuracy: 15.920\n",
            "Worker 2, [02/18]: Training Loss: 3.462912236, Training Accuracy: 16.496\n",
            "Worker 2, [03/18]: Training Loss: 3.369869850, Training Accuracy: 19.040\n",
            "Worker 2, [04/18]: Training Loss: 3.281899416, Training Accuracy: 20.560\n",
            "Worker 2, [05/18]: Training Loss: 3.254929601, Training Accuracy: 21.552\n",
            "Worker 2, [06/18]: Training Loss: 3.192154313, Training Accuracy: 21.792\n",
            "Worker 2, [07/18]: Training Loss: 3.167398954, Training Accuracy: 21.824\n",
            "Worker 2, [08/18]: Training Loss: 3.136145353, Training Accuracy: 22.368\n",
            "Worker 2, [09/18]: Training Loss: 3.295681912, Training Accuracy: 19.504\n",
            "Worker 2, [10/18]: Training Loss: 3.237038688, Training Accuracy: 20.272\n",
            "Worker 2, [11/18]: Training Loss: 3.205274499, Training Accuracy: 20.864\n",
            "Worker 2, [12/18]: Training Loss: 3.148081612, Training Accuracy: 21.984\n",
            "Worker 2, [13/18]: Training Loss: 3.336537896, Training Accuracy: 18.304\n",
            "Worker 2, [14/18]: Training Loss: 3.284799233, Training Accuracy: 18.992\n",
            "Worker 2, [15/18]: Training Loss: 3.218626611, Training Accuracy: 20.576\n",
            "Worker 2, [16/18]: Training Loss: 3.124015811, Training Accuracy: 21.696\n",
            "Worker 2, [17/18]: Training Loss: 3.348902717, Training Accuracy: 18.464\n",
            "Worker 2, [18/18]: Training Loss: 3.276085739, Training Accuracy: 19.312\n",
            "Time taken for training worker 2: 0:00:48.254916\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.516209877, Training Accuracy: 16.960\n",
            "Worker 3, [02/18]: Training Loss: 3.423928794, Training Accuracy: 18.880\n",
            "Worker 3, [03/18]: Training Loss: 3.310756978, Training Accuracy: 20.800\n",
            "Worker 3, [04/18]: Training Loss: 3.254239056, Training Accuracy: 22.560\n",
            "Worker 3, [05/18]: Training Loss: 3.263462794, Training Accuracy: 22.032\n",
            "Worker 3, [06/18]: Training Loss: 3.208694307, Training Accuracy: 21.856\n",
            "Worker 3, [07/18]: Training Loss: 3.179221085, Training Accuracy: 22.480\n",
            "Worker 3, [08/18]: Training Loss: 3.155314282, Training Accuracy: 22.512\n",
            "Worker 3, [09/18]: Training Loss: 3.296920772, Training Accuracy: 20.288\n",
            "Worker 3, [10/18]: Training Loss: 3.260815890, Training Accuracy: 20.112\n",
            "Worker 3, [11/18]: Training Loss: 3.221690548, Training Accuracy: 20.816\n",
            "Worker 3, [12/18]: Training Loss: 3.172933401, Training Accuracy: 21.360\n",
            "Worker 3, [13/18]: Training Loss: 3.382166364, Training Accuracy: 18.208\n",
            "Worker 3, [14/18]: Training Loss: 3.300658917, Training Accuracy: 19.712\n",
            "Worker 3, [15/18]: Training Loss: 3.210685586, Training Accuracy: 21.776\n",
            "Worker 3, [16/18]: Training Loss: 3.163560327, Training Accuracy: 22.128\n",
            "Worker 3, [17/18]: Training Loss: 3.380838856, Training Accuracy: 18.384\n",
            "Worker 3, [18/18]: Training Loss: 3.286057151, Training Accuracy: 19.824\n",
            "Time taken for training worker 3: 0:00:48.436189\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.518609993, Training Accuracy: 16.960\n",
            "Worker 4, [02/18]: Training Loss: 3.411864592, Training Accuracy: 18.384\n",
            "Worker 4, [03/18]: Training Loss: 3.322722274, Training Accuracy: 20.720\n",
            "Worker 4, [04/18]: Training Loss: 3.243593797, Training Accuracy: 22.128\n",
            "Worker 4, [05/18]: Training Loss: 3.264891225, Training Accuracy: 22.048\n",
            "Worker 4, [06/18]: Training Loss: 3.203298569, Training Accuracy: 22.096\n",
            "Worker 4, [07/18]: Training Loss: 3.179840701, Training Accuracy: 22.144\n",
            "Worker 4, [08/18]: Training Loss: 3.151829029, Training Accuracy: 23.072\n",
            "Worker 4, [09/18]: Training Loss: 3.292182560, Training Accuracy: 19.904\n",
            "Worker 4, [10/18]: Training Loss: 3.234817422, Training Accuracy: 20.448\n",
            "Worker 4, [11/18]: Training Loss: 3.203244270, Training Accuracy: 21.280\n",
            "Worker 4, [12/18]: Training Loss: 3.153890123, Training Accuracy: 21.584\n",
            "Worker 4, [13/18]: Training Loss: 3.356592254, Training Accuracy: 19.104\n",
            "Worker 4, [14/18]: Training Loss: 3.279667086, Training Accuracy: 19.312\n",
            "Worker 4, [15/18]: Training Loss: 3.201184107, Training Accuracy: 21.840\n",
            "Worker 4, [16/18]: Training Loss: 3.143181733, Training Accuracy: 22.496\n",
            "Worker 4, [17/18]: Training Loss: 3.369523019, Training Accuracy: 18.064\n",
            "Worker 4, [18/18]: Training Loss: 3.261261239, Training Accuracy: 19.808\n",
            "Time taken for training worker 4: 0:00:48.069679\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.484890938, Training Accuracy: 17.664\n",
            "Worker 5, [02/18]: Training Loss: 3.421795205, Training Accuracy: 18.416\n",
            "Worker 5, [03/18]: Training Loss: 3.323322501, Training Accuracy: 19.952\n",
            "Worker 5, [04/18]: Training Loss: 3.256604489, Training Accuracy: 21.856\n",
            "Worker 5, [05/18]: Training Loss: 3.259728534, Training Accuracy: 21.232\n",
            "Worker 5, [06/18]: Training Loss: 3.177284051, Training Accuracy: 22.288\n",
            "Worker 5, [07/18]: Training Loss: 3.173599540, Training Accuracy: 21.808\n",
            "Worker 5, [08/18]: Training Loss: 3.146211537, Training Accuracy: 23.088\n",
            "Worker 5, [09/18]: Training Loss: 3.307172011, Training Accuracy: 19.888\n",
            "Worker 5, [10/18]: Training Loss: 3.258592467, Training Accuracy: 20.592\n",
            "Worker 5, [11/18]: Training Loss: 3.201165895, Training Accuracy: 21.392\n",
            "Worker 5, [12/18]: Training Loss: 3.195518241, Training Accuracy: 21.056\n",
            "Worker 5, [13/18]: Training Loss: 3.380881801, Training Accuracy: 18.496\n",
            "Worker 5, [14/18]: Training Loss: 3.302046949, Training Accuracy: 19.120\n",
            "Worker 5, [15/18]: Training Loss: 3.208418800, Training Accuracy: 20.496\n",
            "Worker 5, [16/18]: Training Loss: 3.162954472, Training Accuracy: 21.904\n",
            "Worker 5, [17/18]: Training Loss: 3.367226097, Training Accuracy: 18.432\n",
            "Worker 5, [18/18]: Training Loss: 3.274348643, Training Accuracy: 19.552\n",
            "Time taken for training worker 5: 0:00:48.347948\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.433550246, Training Accuracy: 18.704\n",
            "Worker 6, [02/18]: Training Loss: 3.394774632, Training Accuracy: 18.704\n",
            "Worker 6, [03/18]: Training Loss: 3.323059116, Training Accuracy: 20.416\n",
            "Worker 6, [04/18]: Training Loss: 3.238290908, Training Accuracy: 21.968\n",
            "Worker 6, [05/18]: Training Loss: 3.268969813, Training Accuracy: 21.136\n",
            "Worker 6, [06/18]: Training Loss: 3.196485792, Training Accuracy: 21.120\n",
            "Worker 6, [07/18]: Training Loss: 3.183340299, Training Accuracy: 21.680\n",
            "Worker 6, [08/18]: Training Loss: 3.170998510, Training Accuracy: 21.568\n",
            "Worker 6, [09/18]: Training Loss: 3.288776702, Training Accuracy: 20.704\n",
            "Worker 6, [10/18]: Training Loss: 3.245437756, Training Accuracy: 20.304\n",
            "Worker 6, [11/18]: Training Loss: 3.179076703, Training Accuracy: 21.392\n",
            "Worker 6, [12/18]: Training Loss: 3.167849052, Training Accuracy: 21.584\n",
            "Worker 6, [13/18]: Training Loss: 3.360436430, Training Accuracy: 18.416\n",
            "Worker 6, [14/18]: Training Loss: 3.284718445, Training Accuracy: 19.008\n",
            "Worker 6, [15/18]: Training Loss: 3.244584816, Training Accuracy: 19.920\n",
            "Worker 6, [16/18]: Training Loss: 3.144333800, Training Accuracy: 21.968\n",
            "Worker 6, [17/18]: Training Loss: 3.366886348, Training Accuracy: 18.192\n",
            "Worker 6, [18/18]: Training Loss: 3.290627399, Training Accuracy: 19.632\n",
            "Time taken for training worker 6: 0:00:47.688724\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.561609947, Training Accuracy: 15.856\n",
            "Worker 7, [02/18]: Training Loss: 3.447700014, Training Accuracy: 16.800\n",
            "Worker 7, [03/18]: Training Loss: 3.324739517, Training Accuracy: 19.616\n",
            "Worker 7, [04/18]: Training Loss: 3.255596694, Training Accuracy: 20.704\n",
            "Worker 7, [05/18]: Training Loss: 3.271493398, Training Accuracy: 21.600\n",
            "Worker 7, [06/18]: Training Loss: 3.214665809, Training Accuracy: 21.280\n",
            "Worker 7, [07/18]: Training Loss: 3.198696195, Training Accuracy: 21.056\n",
            "Worker 7, [08/18]: Training Loss: 3.173378645, Training Accuracy: 21.040\n",
            "Worker 7, [09/18]: Training Loss: 3.309309911, Training Accuracy: 18.768\n",
            "Worker 7, [10/18]: Training Loss: 3.251590821, Training Accuracy: 19.616\n",
            "Worker 7, [11/18]: Training Loss: 3.212713395, Training Accuracy: 20.672\n",
            "Worker 7, [12/18]: Training Loss: 3.167645107, Training Accuracy: 21.728\n",
            "Worker 7, [13/18]: Training Loss: 3.368641097, Training Accuracy: 18.656\n",
            "Worker 7, [14/18]: Training Loss: 3.284430672, Training Accuracy: 19.424\n",
            "Worker 7, [15/18]: Training Loss: 3.231835528, Training Accuracy: 20.480\n",
            "Worker 7, [16/18]: Training Loss: 3.181120011, Training Accuracy: 20.960\n",
            "Worker 7, [17/18]: Training Loss: 3.381305824, Training Accuracy: 18.000\n",
            "Worker 7, [18/18]: Training Loss: 3.315590267, Training Accuracy: 18.848\n",
            "Time taken for training worker 7: 0:00:47.996341\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.508616316, Training Accuracy: 16.912\n",
            "Worker 8, [02/18]: Training Loss: 3.456164341, Training Accuracy: 17.392\n",
            "Worker 8, [03/18]: Training Loss: 3.349215308, Training Accuracy: 19.232\n",
            "Worker 8, [04/18]: Training Loss: 3.274623182, Training Accuracy: 20.496\n",
            "Worker 8, [05/18]: Training Loss: 3.282983481, Training Accuracy: 20.928\n",
            "Worker 8, [06/18]: Training Loss: 3.213611797, Training Accuracy: 20.768\n",
            "Worker 8, [07/18]: Training Loss: 3.200257277, Training Accuracy: 20.976\n",
            "Worker 8, [08/18]: Training Loss: 3.180223913, Training Accuracy: 21.200\n",
            "Worker 8, [09/18]: Training Loss: 3.315103171, Training Accuracy: 19.824\n",
            "Worker 8, [10/18]: Training Loss: 3.277829199, Training Accuracy: 20.224\n",
            "Worker 8, [11/18]: Training Loss: 3.215604765, Training Accuracy: 19.680\n",
            "Worker 8, [12/18]: Training Loss: 3.184975573, Training Accuracy: 21.344\n",
            "Worker 8, [13/18]: Training Loss: 3.395274547, Training Accuracy: 17.440\n",
            "Worker 8, [14/18]: Training Loss: 3.296426269, Training Accuracy: 18.352\n",
            "Worker 8, [15/18]: Training Loss: 3.254563757, Training Accuracy: 19.312\n",
            "Worker 8, [16/18]: Training Loss: 3.177849925, Training Accuracy: 20.768\n",
            "Worker 8, [17/18]: Training Loss: 3.396644179, Training Accuracy: 17.424\n",
            "Worker 8, [18/18]: Training Loss: 3.283817848, Training Accuracy: 18.576\n",
            "Time taken for training worker 8: 0:00:48.243284\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000723\n",
            "Local Step 06: Test Loss: 3.374421065, Test Accuracy: 19.220\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.447553260, Training Accuracy: 17.792\n",
            "Worker 1, [02/18]: Training Loss: 3.293255504, Training Accuracy: 19.472\n",
            "Worker 1, [03/18]: Training Loss: 3.193708162, Training Accuracy: 21.808\n",
            "Worker 1, [04/18]: Training Loss: 3.059581988, Training Accuracy: 23.264\n",
            "Worker 1, [05/18]: Training Loss: 3.433987406, Training Accuracy: 17.440\n",
            "Worker 1, [06/18]: Training Loss: 3.268921023, Training Accuracy: 20.208\n",
            "Worker 1, [07/18]: Training Loss: 3.169629170, Training Accuracy: 21.728\n",
            "Worker 1, [08/18]: Training Loss: 3.075319117, Training Accuracy: 23.504\n",
            "Worker 1, [09/18]: Training Loss: 3.272282773, Training Accuracy: 20.176\n",
            "Worker 1, [10/18]: Training Loss: 3.159380536, Training Accuracy: 21.936\n",
            "Worker 1, [11/18]: Training Loss: 3.041332442, Training Accuracy: 24.848\n",
            "Worker 1, [12/18]: Training Loss: 2.958107138, Training Accuracy: 26.128\n",
            "Worker 1, [13/18]: Training Loss: 3.147565029, Training Accuracy: 22.784\n",
            "Worker 1, [14/18]: Training Loss: 3.042939663, Training Accuracy: 24.640\n",
            "Worker 1, [15/18]: Training Loss: 2.963326187, Training Accuracy: 26.368\n",
            "Worker 1, [16/18]: Training Loss: 2.885879081, Training Accuracy: 27.680\n",
            "Worker 1, [17/18]: Training Loss: 3.096585378, Training Accuracy: 25.360\n",
            "Worker 1, [18/18]: Training Loss: 3.040642826, Training Accuracy: 26.112\n",
            "Time taken for training worker 1: 0:00:48.627203\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.505667373, Training Accuracy: 16.272\n",
            "Worker 2, [02/18]: Training Loss: 3.316198001, Training Accuracy: 18.928\n",
            "Worker 2, [03/18]: Training Loss: 3.219815403, Training Accuracy: 20.528\n",
            "Worker 2, [04/18]: Training Loss: 3.109184039, Training Accuracy: 22.336\n",
            "Worker 2, [05/18]: Training Loss: 3.275950159, Training Accuracy: 20.112\n",
            "Worker 2, [06/18]: Training Loss: 3.202812791, Training Accuracy: 20.176\n",
            "Worker 2, [07/18]: Training Loss: 3.079264952, Training Accuracy: 23.344\n",
            "Worker 2, [08/18]: Training Loss: 2.955007592, Training Accuracy: 24.272\n",
            "Worker 2, [09/18]: Training Loss: 3.186897132, Training Accuracy: 21.056\n",
            "Worker 2, [10/18]: Training Loss: 3.049660508, Training Accuracy: 23.696\n",
            "Worker 2, [11/18]: Training Loss: 2.979586808, Training Accuracy: 24.848\n",
            "Worker 2, [12/18]: Training Loss: 2.851994982, Training Accuracy: 27.008\n",
            "Worker 2, [13/18]: Training Loss: 3.030788631, Training Accuracy: 24.336\n",
            "Worker 2, [14/18]: Training Loss: 2.925202951, Training Accuracy: 25.744\n",
            "Worker 2, [15/18]: Training Loss: 2.843385711, Training Accuracy: 27.520\n",
            "Worker 2, [16/18]: Training Loss: 2.775513121, Training Accuracy: 28.496\n",
            "Worker 2, [17/18]: Training Loss: 2.972847260, Training Accuracy: 27.056\n",
            "Worker 2, [18/18]: Training Loss: 2.908853806, Training Accuracy: 27.488\n",
            "Time taken for training worker 2: 0:00:49.392018\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.452437605, Training Accuracy: 17.856\n",
            "Worker 3, [02/18]: Training Loss: 3.314373702, Training Accuracy: 19.184\n",
            "Worker 3, [03/18]: Training Loss: 3.196031106, Training Accuracy: 22.000\n",
            "Worker 3, [04/18]: Training Loss: 3.104096220, Training Accuracy: 23.648\n",
            "Worker 3, [05/18]: Training Loss: 3.309518790, Training Accuracy: 19.648\n",
            "Worker 3, [06/18]: Training Loss: 3.240814516, Training Accuracy: 20.976\n",
            "Worker 3, [07/18]: Training Loss: 3.112371248, Training Accuracy: 22.112\n",
            "Worker 3, [08/18]: Training Loss: 2.988456495, Training Accuracy: 25.408\n",
            "Worker 3, [09/18]: Training Loss: 3.169499529, Training Accuracy: 22.144\n",
            "Worker 3, [10/18]: Training Loss: 3.089222521, Training Accuracy: 22.912\n",
            "Worker 3, [11/18]: Training Loss: 2.979624101, Training Accuracy: 25.728\n",
            "Worker 3, [12/18]: Training Loss: 2.882056066, Training Accuracy: 27.456\n",
            "Worker 3, [13/18]: Training Loss: 3.051193230, Training Accuracy: 25.504\n",
            "Worker 3, [14/18]: Training Loss: 2.958694495, Training Accuracy: 25.888\n",
            "Worker 3, [15/18]: Training Loss: 2.856893162, Training Accuracy: 28.576\n",
            "Worker 3, [16/18]: Training Loss: 2.807388374, Training Accuracy: 29.904\n",
            "Worker 3, [17/18]: Training Loss: 3.001401045, Training Accuracy: 27.632\n",
            "Worker 3, [18/18]: Training Loss: 2.923707288, Training Accuracy: 28.656\n",
            "Time taken for training worker 3: 0:00:48.027480\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.452560824, Training Accuracy: 17.376\n",
            "Worker 4, [02/18]: Training Loss: 3.310068201, Training Accuracy: 19.200\n",
            "Worker 4, [03/18]: Training Loss: 3.205575199, Training Accuracy: 21.440\n",
            "Worker 4, [04/18]: Training Loss: 3.099683175, Training Accuracy: 23.248\n",
            "Worker 4, [05/18]: Training Loss: 3.310408152, Training Accuracy: 19.392\n",
            "Worker 4, [06/18]: Training Loss: 3.194728068, Training Accuracy: 20.864\n",
            "Worker 4, [07/18]: Training Loss: 3.079020819, Training Accuracy: 23.952\n",
            "Worker 4, [08/18]: Training Loss: 2.982713123, Training Accuracy: 24.608\n",
            "Worker 4, [09/18]: Training Loss: 3.163039305, Training Accuracy: 22.064\n",
            "Worker 4, [10/18]: Training Loss: 3.076396536, Training Accuracy: 23.568\n",
            "Worker 4, [11/18]: Training Loss: 2.961795410, Training Accuracy: 25.344\n",
            "Worker 4, [12/18]: Training Loss: 2.863423841, Training Accuracy: 26.736\n",
            "Worker 4, [13/18]: Training Loss: 3.030270372, Training Accuracy: 24.480\n",
            "Worker 4, [14/18]: Training Loss: 2.933850179, Training Accuracy: 26.144\n",
            "Worker 4, [15/18]: Training Loss: 2.849859233, Training Accuracy: 27.728\n",
            "Worker 4, [16/18]: Training Loss: 2.774165686, Training Accuracy: 29.776\n",
            "Worker 4, [17/18]: Training Loss: 2.969635409, Training Accuracy: 28.016\n",
            "Worker 4, [18/18]: Training Loss: 2.909879521, Training Accuracy: 27.872\n",
            "Time taken for training worker 4: 0:00:48.857768\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.471859377, Training Accuracy: 17.648\n",
            "Worker 5, [02/18]: Training Loss: 3.311066939, Training Accuracy: 19.712\n",
            "Worker 5, [03/18]: Training Loss: 3.209246195, Training Accuracy: 21.056\n",
            "Worker 5, [04/18]: Training Loss: 3.098658095, Training Accuracy: 23.712\n",
            "Worker 5, [05/18]: Training Loss: 3.321883747, Training Accuracy: 18.960\n",
            "Worker 5, [06/18]: Training Loss: 3.205807318, Training Accuracy: 20.608\n",
            "Worker 5, [07/18]: Training Loss: 3.109862216, Training Accuracy: 22.752\n",
            "Worker 5, [08/18]: Training Loss: 2.993409673, Training Accuracy: 24.624\n",
            "Worker 5, [09/18]: Training Loss: 3.179590651, Training Accuracy: 22.080\n",
            "Worker 5, [10/18]: Training Loss: 3.079039243, Training Accuracy: 23.264\n",
            "Worker 5, [11/18]: Training Loss: 2.966323089, Training Accuracy: 26.240\n",
            "Worker 5, [12/18]: Training Loss: 2.856305152, Training Accuracy: 27.264\n",
            "Worker 5, [13/18]: Training Loss: 3.040922858, Training Accuracy: 24.656\n",
            "Worker 5, [14/18]: Training Loss: 2.933707400, Training Accuracy: 26.448\n",
            "Worker 5, [15/18]: Training Loss: 2.855649525, Training Accuracy: 27.840\n",
            "Worker 5, [16/18]: Training Loss: 2.789730169, Training Accuracy: 29.216\n",
            "Worker 5, [17/18]: Training Loss: 2.984921806, Training Accuracy: 27.024\n",
            "Worker 5, [18/18]: Training Loss: 2.934135194, Training Accuracy: 27.520\n",
            "Time taken for training worker 5: 0:00:47.901663\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.467597857, Training Accuracy: 16.944\n",
            "Worker 6, [02/18]: Training Loss: 3.298550633, Training Accuracy: 19.824\n",
            "Worker 6, [03/18]: Training Loss: 3.214666311, Training Accuracy: 20.720\n",
            "Worker 6, [04/18]: Training Loss: 3.088829303, Training Accuracy: 23.360\n",
            "Worker 6, [05/18]: Training Loss: 3.316204696, Training Accuracy: 19.392\n",
            "Worker 6, [06/18]: Training Loss: 3.211922594, Training Accuracy: 21.024\n",
            "Worker 6, [07/18]: Training Loss: 3.078623268, Training Accuracy: 23.792\n",
            "Worker 6, [08/18]: Training Loss: 2.996692005, Training Accuracy: 25.040\n",
            "Worker 6, [09/18]: Training Loss: 3.179788828, Training Accuracy: 21.456\n",
            "Worker 6, [10/18]: Training Loss: 3.071688713, Training Accuracy: 23.392\n",
            "Worker 6, [11/18]: Training Loss: 2.976020733, Training Accuracy: 25.696\n",
            "Worker 6, [12/18]: Training Loss: 2.866450310, Training Accuracy: 28.064\n",
            "Worker 6, [13/18]: Training Loss: 3.035664936, Training Accuracy: 24.512\n",
            "Worker 6, [14/18]: Training Loss: 2.954574417, Training Accuracy: 25.632\n",
            "Worker 6, [15/18]: Training Loss: 2.865574379, Training Accuracy: 27.680\n",
            "Worker 6, [16/18]: Training Loss: 2.804977488, Training Accuracy: 29.200\n",
            "Worker 6, [17/18]: Training Loss: 2.996186896, Training Accuracy: 26.640\n",
            "Worker 6, [18/18]: Training Loss: 2.934281286, Training Accuracy: 26.880\n",
            "Time taken for training worker 6: 0:00:47.273869\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.480210526, Training Accuracy: 15.968\n",
            "Worker 7, [02/18]: Training Loss: 3.340950516, Training Accuracy: 19.264\n",
            "Worker 7, [03/18]: Training Loss: 3.213398435, Training Accuracy: 20.704\n",
            "Worker 7, [04/18]: Training Loss: 3.122559399, Training Accuracy: 21.568\n",
            "Worker 7, [05/18]: Training Loss: 3.303734923, Training Accuracy: 18.784\n",
            "Worker 7, [06/18]: Training Loss: 3.206688197, Training Accuracy: 20.608\n",
            "Worker 7, [07/18]: Training Loss: 3.100362405, Training Accuracy: 22.544\n",
            "Worker 7, [08/18]: Training Loss: 2.978813969, Training Accuracy: 25.024\n",
            "Worker 7, [09/18]: Training Loss: 3.184543695, Training Accuracy: 21.072\n",
            "Worker 7, [10/18]: Training Loss: 3.078081362, Training Accuracy: 22.800\n",
            "Worker 7, [11/18]: Training Loss: 2.984767950, Training Accuracy: 24.576\n",
            "Worker 7, [12/18]: Training Loss: 2.860323033, Training Accuracy: 27.024\n",
            "Worker 7, [13/18]: Training Loss: 3.046419594, Training Accuracy: 24.160\n",
            "Worker 7, [14/18]: Training Loss: 2.943067120, Training Accuracy: 26.240\n",
            "Worker 7, [15/18]: Training Loss: 2.877749643, Training Accuracy: 26.544\n",
            "Worker 7, [16/18]: Training Loss: 2.796216953, Training Accuracy: 28.896\n",
            "Worker 7, [17/18]: Training Loss: 2.991388988, Training Accuracy: 26.432\n",
            "Worker 7, [18/18]: Training Loss: 2.937449740, Training Accuracy: 26.944\n",
            "Time taken for training worker 7: 0:00:48.939574\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.460292174, Training Accuracy: 16.704\n",
            "Worker 8, [02/18]: Training Loss: 3.326669674, Training Accuracy: 19.440\n",
            "Worker 8, [03/18]: Training Loss: 3.197906604, Training Accuracy: 20.656\n",
            "Worker 8, [04/18]: Training Loss: 3.109011796, Training Accuracy: 22.208\n",
            "Worker 8, [05/18]: Training Loss: 3.323095198, Training Accuracy: 18.720\n",
            "Worker 8, [06/18]: Training Loss: 3.206105476, Training Accuracy: 20.432\n",
            "Worker 8, [07/18]: Training Loss: 3.091760212, Training Accuracy: 22.320\n",
            "Worker 8, [08/18]: Training Loss: 2.991980740, Training Accuracy: 23.920\n",
            "Worker 8, [09/18]: Training Loss: 3.195716014, Training Accuracy: 21.280\n",
            "Worker 8, [10/18]: Training Loss: 3.093893998, Training Accuracy: 22.544\n",
            "Worker 8, [11/18]: Training Loss: 2.985475387, Training Accuracy: 24.656\n",
            "Worker 8, [12/18]: Training Loss: 2.864088173, Training Accuracy: 27.200\n",
            "Worker 8, [13/18]: Training Loss: 3.043594908, Training Accuracy: 23.856\n",
            "Worker 8, [14/18]: Training Loss: 2.956299254, Training Accuracy: 25.552\n",
            "Worker 8, [15/18]: Training Loss: 2.866665908, Training Accuracy: 27.712\n",
            "Worker 8, [16/18]: Training Loss: 2.806051860, Training Accuracy: 29.216\n",
            "Worker 8, [17/18]: Training Loss: 3.004474078, Training Accuracy: 26.352\n",
            "Worker 8, [18/18]: Training Loss: 2.942774644, Training Accuracy: 27.344\n",
            "Time taken for training worker 8: 0:00:48.690408\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000834\n",
            "Local Step 07: Test Loss: 3.133769972, Test Accuracy: 24.400\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.264507963, Training Accuracy: 21.408\n",
            "Worker 1, [02/18]: Training Loss: 3.254035419, Training Accuracy: 21.840\n",
            "Worker 1, [03/18]: Training Loss: 3.235667637, Training Accuracy: 21.984\n",
            "Worker 1, [04/18]: Training Loss: 3.221107206, Training Accuracy: 21.824\n",
            "Worker 1, [05/18]: Training Loss: 3.086399803, Training Accuracy: 24.768\n",
            "Worker 1, [06/18]: Training Loss: 3.063444914, Training Accuracy: 24.016\n",
            "Worker 1, [07/18]: Training Loss: 3.042508001, Training Accuracy: 23.776\n",
            "Worker 1, [08/18]: Training Loss: 3.024990143, Training Accuracy: 24.864\n",
            "Worker 1, [09/18]: Training Loss: 3.162846200, Training Accuracy: 22.816\n",
            "Worker 1, [10/18]: Training Loss: 3.154949811, Training Accuracy: 22.000\n",
            "Worker 1, [11/18]: Training Loss: 3.098283179, Training Accuracy: 22.736\n",
            "Worker 1, [12/18]: Training Loss: 3.052015015, Training Accuracy: 24.096\n",
            "Worker 1, [13/18]: Training Loss: 3.246824374, Training Accuracy: 21.248\n",
            "Worker 1, [14/18]: Training Loss: 3.189679769, Training Accuracy: 21.232\n",
            "Worker 1, [15/18]: Training Loss: 3.122604866, Training Accuracy: 23.088\n",
            "Worker 1, [16/18]: Training Loss: 3.053119713, Training Accuracy: 24.304\n",
            "Worker 1, [17/18]: Training Loss: 3.259956820, Training Accuracy: 19.984\n",
            "Worker 1, [18/18]: Training Loss: 3.172431705, Training Accuracy: 21.536\n",
            "Time taken for training worker 1: 0:00:49.408236\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.421150305, Training Accuracy: 17.760\n",
            "Worker 2, [02/18]: Training Loss: 3.333916676, Training Accuracy: 19.072\n",
            "Worker 2, [03/18]: Training Loss: 3.215688856, Training Accuracy: 21.776\n",
            "Worker 2, [04/18]: Training Loss: 3.146379519, Training Accuracy: 24.016\n",
            "Worker 2, [05/18]: Training Loss: 2.962543084, Training Accuracy: 26.016\n",
            "Worker 2, [06/18]: Training Loss: 2.919741030, Training Accuracy: 25.680\n",
            "Worker 2, [07/18]: Training Loss: 2.927603863, Training Accuracy: 25.792\n",
            "Worker 2, [08/18]: Training Loss: 2.923087855, Training Accuracy: 25.456\n",
            "Worker 2, [09/18]: Training Loss: 3.030081729, Training Accuracy: 24.048\n",
            "Worker 2, [10/18]: Training Loss: 2.999492631, Training Accuracy: 24.112\n",
            "Worker 2, [11/18]: Training Loss: 2.991550244, Training Accuracy: 24.032\n",
            "Worker 2, [12/18]: Training Loss: 2.947625681, Training Accuracy: 26.160\n",
            "Worker 2, [13/18]: Training Loss: 3.121882465, Training Accuracy: 22.080\n",
            "Worker 2, [14/18]: Training Loss: 3.086504919, Training Accuracy: 22.304\n",
            "Worker 2, [15/18]: Training Loss: 2.987583676, Training Accuracy: 24.368\n",
            "Worker 2, [16/18]: Training Loss: 2.991528477, Training Accuracy: 24.192\n",
            "Worker 2, [17/18]: Training Loss: 3.175451052, Training Accuracy: 20.640\n",
            "Worker 2, [18/18]: Training Loss: 3.071972665, Training Accuracy: 23.168\n",
            "Time taken for training worker 2: 0:00:49.521098\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.376782974, Training Accuracy: 19.408\n",
            "Worker 3, [02/18]: Training Loss: 3.336635118, Training Accuracy: 19.664\n",
            "Worker 3, [03/18]: Training Loss: 3.225099561, Training Accuracy: 22.208\n",
            "Worker 3, [04/18]: Training Loss: 3.139737806, Training Accuracy: 23.520\n",
            "Worker 3, [05/18]: Training Loss: 2.976751121, Training Accuracy: 27.216\n",
            "Worker 3, [06/18]: Training Loss: 2.948428049, Training Accuracy: 26.768\n",
            "Worker 3, [07/18]: Training Loss: 2.935521170, Training Accuracy: 26.800\n",
            "Worker 3, [08/18]: Training Loss: 2.959508319, Training Accuracy: 26.752\n",
            "Worker 3, [09/18]: Training Loss: 3.081543436, Training Accuracy: 23.280\n",
            "Worker 3, [10/18]: Training Loss: 3.026571118, Training Accuracy: 24.944\n",
            "Worker 3, [11/18]: Training Loss: 3.008229115, Training Accuracy: 24.240\n",
            "Worker 3, [12/18]: Training Loss: 2.980283917, Training Accuracy: 24.576\n",
            "Worker 3, [13/18]: Training Loss: 3.147496805, Training Accuracy: 21.968\n",
            "Worker 3, [14/18]: Training Loss: 3.086067920, Training Accuracy: 23.328\n",
            "Worker 3, [15/18]: Training Loss: 3.047437325, Training Accuracy: 24.176\n",
            "Worker 3, [16/18]: Training Loss: 2.983814332, Training Accuracy: 25.264\n",
            "Worker 3, [17/18]: Training Loss: 3.168369872, Training Accuracy: 21.824\n",
            "Worker 3, [18/18]: Training Loss: 3.098137564, Training Accuracy: 22.912\n",
            "Time taken for training worker 3: 0:00:49.341982\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.314739458, Training Accuracy: 20.064\n",
            "Worker 4, [02/18]: Training Loss: 3.286602329, Training Accuracy: 20.352\n",
            "Worker 4, [03/18]: Training Loss: 3.209167274, Training Accuracy: 22.384\n",
            "Worker 4, [04/18]: Training Loss: 3.147397732, Training Accuracy: 23.392\n",
            "Worker 4, [05/18]: Training Loss: 2.960448742, Training Accuracy: 27.120\n",
            "Worker 4, [06/18]: Training Loss: 2.917534711, Training Accuracy: 26.656\n",
            "Worker 4, [07/18]: Training Loss: 2.918921004, Training Accuracy: 26.048\n",
            "Worker 4, [08/18]: Training Loss: 2.926108292, Training Accuracy: 25.712\n",
            "Worker 4, [09/18]: Training Loss: 3.052528994, Training Accuracy: 24.336\n",
            "Worker 4, [10/18]: Training Loss: 3.030504704, Training Accuracy: 24.304\n",
            "Worker 4, [11/18]: Training Loss: 2.990441008, Training Accuracy: 24.736\n",
            "Worker 4, [12/18]: Training Loss: 2.976215433, Training Accuracy: 24.976\n",
            "Worker 4, [13/18]: Training Loss: 3.142306148, Training Accuracy: 22.272\n",
            "Worker 4, [14/18]: Training Loss: 3.099386999, Training Accuracy: 22.704\n",
            "Worker 4, [15/18]: Training Loss: 3.023375484, Training Accuracy: 23.936\n",
            "Worker 4, [16/18]: Training Loss: 2.972323663, Training Accuracy: 24.960\n",
            "Worker 4, [17/18]: Training Loss: 3.189582265, Training Accuracy: 21.248\n",
            "Worker 4, [18/18]: Training Loss: 3.107909889, Training Accuracy: 23.008\n",
            "Time taken for training worker 4: 0:00:48.888656\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.425379203, Training Accuracy: 18.848\n",
            "Worker 5, [02/18]: Training Loss: 3.333663310, Training Accuracy: 19.536\n",
            "Worker 5, [03/18]: Training Loss: 3.222356611, Training Accuracy: 21.968\n",
            "Worker 5, [04/18]: Training Loss: 3.140068808, Training Accuracy: 23.440\n",
            "Worker 5, [05/18]: Training Loss: 2.966456041, Training Accuracy: 26.144\n",
            "Worker 5, [06/18]: Training Loss: 2.937212562, Training Accuracy: 26.432\n",
            "Worker 5, [07/18]: Training Loss: 2.948219110, Training Accuracy: 26.640\n",
            "Worker 5, [08/18]: Training Loss: 2.920687301, Training Accuracy: 26.304\n",
            "Worker 5, [09/18]: Training Loss: 3.040490046, Training Accuracy: 24.224\n",
            "Worker 5, [10/18]: Training Loss: 3.020920133, Training Accuracy: 24.768\n",
            "Worker 5, [11/18]: Training Loss: 2.986773121, Training Accuracy: 24.912\n",
            "Worker 5, [12/18]: Training Loss: 2.993450340, Training Accuracy: 24.176\n",
            "Worker 5, [13/18]: Training Loss: 3.137630572, Training Accuracy: 22.128\n",
            "Worker 5, [14/18]: Training Loss: 3.123191894, Training Accuracy: 23.056\n",
            "Worker 5, [15/18]: Training Loss: 3.040850131, Training Accuracy: 23.792\n",
            "Worker 5, [16/18]: Training Loss: 2.982703350, Training Accuracy: 24.944\n",
            "Worker 5, [17/18]: Training Loss: 3.184664065, Training Accuracy: 21.136\n",
            "Worker 5, [18/18]: Training Loss: 3.117306021, Training Accuracy: 22.240\n",
            "Time taken for training worker 5: 0:00:48.326262\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.294779617, Training Accuracy: 20.144\n",
            "Worker 6, [02/18]: Training Loss: 3.285637301, Training Accuracy: 20.608\n",
            "Worker 6, [03/18]: Training Loss: 3.208769231, Training Accuracy: 22.048\n",
            "Worker 6, [04/18]: Training Loss: 3.144961360, Training Accuracy: 23.264\n",
            "Worker 6, [05/18]: Training Loss: 2.983714116, Training Accuracy: 26.000\n",
            "Worker 6, [06/18]: Training Loss: 2.944699662, Training Accuracy: 25.872\n",
            "Worker 6, [07/18]: Training Loss: 2.931196923, Training Accuracy: 26.960\n",
            "Worker 6, [08/18]: Training Loss: 2.935334293, Training Accuracy: 26.368\n",
            "Worker 6, [09/18]: Training Loss: 3.044329677, Training Accuracy: 24.320\n",
            "Worker 6, [10/18]: Training Loss: 3.029042312, Training Accuracy: 24.272\n",
            "Worker 6, [11/18]: Training Loss: 3.029373658, Training Accuracy: 23.696\n",
            "Worker 6, [12/18]: Training Loss: 2.982844440, Training Accuracy: 24.880\n",
            "Worker 6, [13/18]: Training Loss: 3.130598852, Training Accuracy: 22.016\n",
            "Worker 6, [14/18]: Training Loss: 3.111609768, Training Accuracy: 22.736\n",
            "Worker 6, [15/18]: Training Loss: 3.059592821, Training Accuracy: 22.544\n",
            "Worker 6, [16/18]: Training Loss: 2.986052922, Training Accuracy: 24.896\n",
            "Worker 6, [17/18]: Training Loss: 3.200712992, Training Accuracy: 21.168\n",
            "Worker 6, [18/18]: Training Loss: 3.123466679, Training Accuracy: 22.000\n",
            "Time taken for training worker 6: 0:00:47.376783\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.336233601, Training Accuracy: 19.152\n",
            "Worker 7, [02/18]: Training Loss: 3.281319042, Training Accuracy: 20.192\n",
            "Worker 7, [03/18]: Training Loss: 3.186570793, Training Accuracy: 22.000\n",
            "Worker 7, [04/18]: Training Loss: 3.145556357, Training Accuracy: 22.704\n",
            "Worker 7, [05/18]: Training Loss: 2.981098586, Training Accuracy: 25.648\n",
            "Worker 7, [06/18]: Training Loss: 2.944740052, Training Accuracy: 26.048\n",
            "Worker 7, [07/18]: Training Loss: 2.956518794, Training Accuracy: 25.760\n",
            "Worker 7, [08/18]: Training Loss: 2.930159919, Training Accuracy: 25.504\n",
            "Worker 7, [09/18]: Training Loss: 3.081463274, Training Accuracy: 23.392\n",
            "Worker 7, [10/18]: Training Loss: 3.043039529, Training Accuracy: 24.016\n",
            "Worker 7, [11/18]: Training Loss: 3.019391218, Training Accuracy: 23.888\n",
            "Worker 7, [12/18]: Training Loss: 2.987947072, Training Accuracy: 25.168\n",
            "Worker 7, [13/18]: Training Loss: 3.168672464, Training Accuracy: 21.632\n",
            "Worker 7, [14/18]: Training Loss: 3.132074003, Training Accuracy: 22.416\n",
            "Worker 7, [15/18]: Training Loss: 3.070827869, Training Accuracy: 23.312\n",
            "Worker 7, [16/18]: Training Loss: 3.004850806, Training Accuracy: 24.256\n",
            "Worker 7, [17/18]: Training Loss: 3.182148938, Training Accuracy: 20.464\n",
            "Worker 7, [18/18]: Training Loss: 3.126646078, Training Accuracy: 22.416\n",
            "Time taken for training worker 7: 0:00:50.509965\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.487398106, Training Accuracy: 17.328\n",
            "Worker 8, [02/18]: Training Loss: 3.379166951, Training Accuracy: 18.720\n",
            "Worker 8, [03/18]: Training Loss: 3.262593320, Training Accuracy: 20.672\n",
            "Worker 8, [04/18]: Training Loss: 3.180068573, Training Accuracy: 22.576\n",
            "Worker 8, [05/18]: Training Loss: 2.987480580, Training Accuracy: 25.680\n",
            "Worker 8, [06/18]: Training Loss: 2.954021707, Training Accuracy: 26.096\n",
            "Worker 8, [07/18]: Training Loss: 2.937506997, Training Accuracy: 25.520\n",
            "Worker 8, [08/18]: Training Loss: 2.942159555, Training Accuracy: 25.200\n",
            "Worker 8, [09/18]: Training Loss: 3.064514793, Training Accuracy: 23.536\n",
            "Worker 8, [10/18]: Training Loss: 3.044925524, Training Accuracy: 23.440\n",
            "Worker 8, [11/18]: Training Loss: 3.024623375, Training Accuracy: 23.248\n",
            "Worker 8, [12/18]: Training Loss: 3.013616260, Training Accuracy: 24.048\n",
            "Worker 8, [13/18]: Training Loss: 3.165615427, Training Accuracy: 21.552\n",
            "Worker 8, [14/18]: Training Loss: 3.125911929, Training Accuracy: 22.000\n",
            "Worker 8, [15/18]: Training Loss: 3.058171379, Training Accuracy: 22.768\n",
            "Worker 8, [16/18]: Training Loss: 3.013147867, Training Accuracy: 23.088\n",
            "Worker 8, [17/18]: Training Loss: 3.204355551, Training Accuracy: 20.208\n",
            "Worker 8, [18/18]: Training Loss: 3.134879779, Training Accuracy: 21.488\n",
            "Time taken for training worker 8: 0:00:47.757311\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000690\n",
            "Local Step 08: Test Loss: 3.220950405, Test Accuracy: 22.330\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:25.203013\n",
            "//////////////////////////////////////////////////\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8, Update Slow Model every 8 steps\n",
            "==================================================\n",
            "Worker 1, [01/18]: Training Loss: 4.592582902, Training Accuracy: 1.728\n",
            "Worker 1, [02/18]: Training Loss: 4.467283156, Training Accuracy: 3.296\n",
            "Worker 1, [03/18]: Training Loss: 4.214452072, Training Accuracy: 5.664\n",
            "Worker 1, [04/18]: Training Loss: 4.061420285, Training Accuracy: 7.088\n",
            "Worker 1, [05/18]: Training Loss: 3.952016633, Training Accuracy: 8.592\n",
            "Worker 1, [06/18]: Training Loss: 3.835159993, Training Accuracy: 10.176\n",
            "Worker 1, [07/18]: Training Loss: 3.759467938, Training Accuracy: 11.312\n",
            "Worker 1, [08/18]: Training Loss: 3.648887342, Training Accuracy: 13.680\n",
            "Worker 1, [09/18]: Training Loss: 4.562251174, Training Accuracy: 1.984\n",
            "Worker 1, [10/18]: Training Loss: 4.313063792, Training Accuracy: 5.008\n",
            "Worker 1, [11/18]: Training Loss: 4.086085590, Training Accuracy: 7.312\n",
            "Worker 1, [12/18]: Training Loss: 3.956898407, Training Accuracy: 9.024\n",
            "Worker 1, [13/18]: Training Loss: 3.850445828, Training Accuracy: 11.088\n",
            "Worker 1, [14/18]: Training Loss: 3.767391601, Training Accuracy: 12.240\n",
            "Worker 1, [15/18]: Training Loss: 3.708151319, Training Accuracy: 13.552\n",
            "Worker 1, [16/18]: Training Loss: 3.659760461, Training Accuracy: 14.112\n",
            "Worker 1, [17/18]: Training Loss: 4.567156519, Training Accuracy: 4.256\n",
            "Worker 1, [18/18]: Training Loss: 4.558580627, Training Accuracy: 4.848\n",
            "Time taken for training worker 1: 0:00:49.453866\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 4.592647188, Training Accuracy: 1.440\n",
            "Worker 2, [02/18]: Training Loss: 4.424763215, Training Accuracy: 3.328\n",
            "Worker 2, [03/18]: Training Loss: 4.180032793, Training Accuracy: 5.792\n",
            "Worker 2, [04/18]: Training Loss: 4.056420278, Training Accuracy: 6.832\n",
            "Worker 2, [05/18]: Training Loss: 3.934330296, Training Accuracy: 8.480\n",
            "Worker 2, [06/18]: Training Loss: 3.818090891, Training Accuracy: 10.192\n",
            "Worker 2, [07/18]: Training Loss: 3.717975553, Training Accuracy: 12.240\n",
            "Worker 2, [08/18]: Training Loss: 3.647210810, Training Accuracy: 13.248\n",
            "Worker 2, [09/18]: Training Loss: 4.540024281, Training Accuracy: 2.688\n",
            "Worker 2, [10/18]: Training Loss: 4.227925135, Training Accuracy: 5.760\n",
            "Worker 2, [11/18]: Training Loss: 4.043071771, Training Accuracy: 7.728\n",
            "Worker 2, [12/18]: Training Loss: 3.926165138, Training Accuracy: 8.992\n",
            "Worker 2, [13/18]: Training Loss: 3.813462688, Training Accuracy: 10.992\n",
            "Worker 2, [14/18]: Training Loss: 3.725490451, Training Accuracy: 12.832\n",
            "Worker 2, [15/18]: Training Loss: 3.669993797, Training Accuracy: 13.760\n",
            "Worker 2, [16/18]: Training Loss: 3.620190591, Training Accuracy: 14.208\n",
            "Worker 2, [17/18]: Training Loss: 4.566478681, Training Accuracy: 3.504\n",
            "Worker 2, [18/18]: Training Loss: 4.557561237, Training Accuracy: 4.384\n",
            "Time taken for training worker 2: 0:00:46.792066\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 4.592696297, Training Accuracy: 1.632\n",
            "Worker 3, [02/18]: Training Loss: 4.447264584, Training Accuracy: 3.312\n",
            "Worker 3, [03/18]: Training Loss: 4.203186597, Training Accuracy: 6.016\n",
            "Worker 3, [04/18]: Training Loss: 4.064763402, Training Accuracy: 7.248\n",
            "Worker 3, [05/18]: Training Loss: 3.948637018, Training Accuracy: 9.136\n",
            "Worker 3, [06/18]: Training Loss: 3.851390899, Training Accuracy: 10.336\n",
            "Worker 3, [07/18]: Training Loss: 3.735150327, Training Accuracy: 12.144\n",
            "Worker 3, [08/18]: Training Loss: 3.643952900, Training Accuracy: 13.456\n",
            "Worker 3, [09/18]: Training Loss: 4.533355518, Training Accuracy: 3.664\n",
            "Worker 3, [10/18]: Training Loss: 4.216332377, Training Accuracy: 5.952\n",
            "Worker 3, [11/18]: Training Loss: 4.059888312, Training Accuracy: 8.064\n",
            "Worker 3, [12/18]: Training Loss: 3.962445276, Training Accuracy: 8.880\n",
            "Worker 3, [13/18]: Training Loss: 3.860494390, Training Accuracy: 10.944\n",
            "Worker 3, [14/18]: Training Loss: 3.788812112, Training Accuracy: 11.728\n",
            "Worker 3, [15/18]: Training Loss: 3.724057414, Training Accuracy: 12.544\n",
            "Worker 3, [16/18]: Training Loss: 3.661262787, Training Accuracy: 14.320\n",
            "Worker 3, [17/18]: Training Loss: 4.569556421, Training Accuracy: 3.472\n",
            "Worker 3, [18/18]: Training Loss: 4.560372946, Training Accuracy: 3.760\n",
            "Time taken for training worker 3: 0:00:49.381935\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 4.594042087, Training Accuracy: 1.328\n",
            "Worker 4, [02/18]: Training Loss: 4.447787737, Training Accuracy: 3.168\n",
            "Worker 4, [03/18]: Training Loss: 4.190731156, Training Accuracy: 6.240\n",
            "Worker 4, [04/18]: Training Loss: 4.064025329, Training Accuracy: 7.440\n",
            "Worker 4, [05/18]: Training Loss: 3.938823376, Training Accuracy: 8.656\n",
            "Worker 4, [06/18]: Training Loss: 3.841390500, Training Accuracy: 10.368\n",
            "Worker 4, [07/18]: Training Loss: 3.739491069, Training Accuracy: 12.176\n",
            "Worker 4, [08/18]: Training Loss: 3.639488398, Training Accuracy: 13.760\n",
            "Worker 4, [09/18]: Training Loss: 4.555139702, Training Accuracy: 3.280\n",
            "Worker 4, [10/18]: Training Loss: 4.251073791, Training Accuracy: 5.808\n",
            "Worker 4, [11/18]: Training Loss: 4.054480326, Training Accuracy: 8.112\n",
            "Worker 4, [12/18]: Training Loss: 3.925933874, Training Accuracy: 10.080\n",
            "Worker 4, [13/18]: Training Loss: 3.834262052, Training Accuracy: 11.072\n",
            "Worker 4, [14/18]: Training Loss: 3.734742515, Training Accuracy: 12.848\n",
            "Worker 4, [15/18]: Training Loss: 3.676276647, Training Accuracy: 13.952\n",
            "Worker 4, [16/18]: Training Loss: 3.626799111, Training Accuracy: 14.288\n",
            "Worker 4, [17/18]: Training Loss: 4.568184906, Training Accuracy: 3.968\n",
            "Worker 4, [18/18]: Training Loss: 4.560046804, Training Accuracy: 4.160\n",
            "Time taken for training worker 4: 0:00:49.037081\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 4.592777622, Training Accuracy: 1.584\n",
            "Worker 5, [02/18]: Training Loss: 4.446220919, Training Accuracy: 2.960\n",
            "Worker 5, [03/18]: Training Loss: 4.210368152, Training Accuracy: 5.328\n",
            "Worker 5, [04/18]: Training Loss: 4.052443607, Training Accuracy: 7.520\n",
            "Worker 5, [05/18]: Training Loss: 3.955104159, Training Accuracy: 8.528\n",
            "Worker 5, [06/18]: Training Loss: 3.831565981, Training Accuracy: 10.512\n",
            "Worker 5, [07/18]: Training Loss: 3.745692268, Training Accuracy: 12.048\n",
            "Worker 5, [08/18]: Training Loss: 3.631994123, Training Accuracy: 13.840\n",
            "Worker 5, [09/18]: Training Loss: 4.546323621, Training Accuracy: 2.528\n",
            "Worker 5, [10/18]: Training Loss: 4.297316989, Training Accuracy: 5.312\n",
            "Worker 5, [11/18]: Training Loss: 4.080809637, Training Accuracy: 7.296\n",
            "Worker 5, [12/18]: Training Loss: 3.954792828, Training Accuracy: 9.024\n",
            "Worker 5, [13/18]: Training Loss: 3.869445526, Training Accuracy: 10.608\n",
            "Worker 5, [14/18]: Training Loss: 3.789792431, Training Accuracy: 11.600\n",
            "Worker 5, [15/18]: Training Loss: 3.727945926, Training Accuracy: 12.944\n",
            "Worker 5, [16/18]: Training Loss: 3.667133142, Training Accuracy: 14.224\n",
            "Worker 5, [17/18]: Training Loss: 4.569929366, Training Accuracy: 3.520\n",
            "Worker 5, [18/18]: Training Loss: 4.561299188, Training Accuracy: 4.512\n",
            "Time taken for training worker 5: 0:00:47.146022\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 4.594442898, Training Accuracy: 1.664\n",
            "Worker 6, [02/18]: Training Loss: 4.441193104, Training Accuracy: 3.504\n",
            "Worker 6, [03/18]: Training Loss: 4.186413395, Training Accuracy: 5.808\n",
            "Worker 6, [04/18]: Training Loss: 4.044371834, Training Accuracy: 6.880\n",
            "Worker 6, [05/18]: Training Loss: 3.938748221, Training Accuracy: 8.544\n",
            "Worker 6, [06/18]: Training Loss: 3.832791727, Training Accuracy: 10.448\n",
            "Worker 6, [07/18]: Training Loss: 3.732052224, Training Accuracy: 12.208\n",
            "Worker 6, [08/18]: Training Loss: 3.636221436, Training Accuracy: 13.664\n",
            "Worker 6, [09/18]: Training Loss: 4.528455384, Training Accuracy: 2.736\n",
            "Worker 6, [10/18]: Training Loss: 4.216936746, Training Accuracy: 5.696\n",
            "Worker 6, [11/18]: Training Loss: 4.035150085, Training Accuracy: 7.424\n",
            "Worker 6, [12/18]: Training Loss: 3.924251286, Training Accuracy: 9.376\n",
            "Worker 6, [13/18]: Training Loss: 3.823187556, Training Accuracy: 10.704\n",
            "Worker 6, [14/18]: Training Loss: 3.748156348, Training Accuracy: 11.936\n",
            "Worker 6, [15/18]: Training Loss: 3.695503690, Training Accuracy: 13.184\n",
            "Worker 6, [16/18]: Training Loss: 3.636429993, Training Accuracy: 14.176\n",
            "Worker 6, [17/18]: Training Loss: 4.568511306, Training Accuracy: 3.520\n",
            "Worker 6, [18/18]: Training Loss: 4.560318694, Training Accuracy: 4.144\n",
            "Time taken for training worker 6: 0:00:47.579718\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 4.596053717, Training Accuracy: 1.232\n",
            "Worker 7, [02/18]: Training Loss: 4.453439430, Training Accuracy: 2.560\n",
            "Worker 7, [03/18]: Training Loss: 4.190429070, Training Accuracy: 5.568\n",
            "Worker 7, [04/18]: Training Loss: 4.067821342, Training Accuracy: 6.624\n",
            "Worker 7, [05/18]: Training Loss: 3.940340886, Training Accuracy: 8.896\n",
            "Worker 7, [06/18]: Training Loss: 3.831678038, Training Accuracy: 10.768\n",
            "Worker 7, [07/18]: Training Loss: 3.721631600, Training Accuracy: 12.144\n",
            "Worker 7, [08/18]: Training Loss: 3.646169762, Training Accuracy: 13.312\n",
            "Worker 7, [09/18]: Training Loss: 4.523123727, Training Accuracy: 2.768\n",
            "Worker 7, [10/18]: Training Loss: 4.211734767, Training Accuracy: 5.664\n",
            "Worker 7, [11/18]: Training Loss: 4.020719961, Training Accuracy: 8.064\n",
            "Worker 7, [12/18]: Training Loss: 3.893242629, Training Accuracy: 9.968\n",
            "Worker 7, [13/18]: Training Loss: 3.791333354, Training Accuracy: 11.760\n",
            "Worker 7, [14/18]: Training Loss: 3.715079582, Training Accuracy: 13.024\n",
            "Worker 7, [15/18]: Training Loss: 3.650800856, Training Accuracy: 13.232\n",
            "Worker 7, [16/18]: Training Loss: 3.605309447, Training Accuracy: 14.624\n",
            "Worker 7, [17/18]: Training Loss: 4.565427118, Training Accuracy: 3.408\n",
            "Worker 7, [18/18]: Training Loss: 4.556474311, Training Accuracy: 4.032\n",
            "Time taken for training worker 7: 0:00:47.538065\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 4.592654890, Training Accuracy: 1.632\n",
            "Worker 8, [02/18]: Training Loss: 4.451211467, Training Accuracy: 3.360\n",
            "Worker 8, [03/18]: Training Loss: 4.177342381, Training Accuracy: 5.888\n",
            "Worker 8, [04/18]: Training Loss: 4.042413485, Training Accuracy: 7.184\n",
            "Worker 8, [05/18]: Training Loss: 3.922728723, Training Accuracy: 9.024\n",
            "Worker 8, [06/18]: Training Loss: 3.817907569, Training Accuracy: 10.320\n",
            "Worker 8, [07/18]: Training Loss: 3.724089917, Training Accuracy: 11.712\n",
            "Worker 8, [08/18]: Training Loss: 3.631237903, Training Accuracy: 13.152\n",
            "Worker 8, [09/18]: Training Loss: 4.526930347, Training Accuracy: 2.848\n",
            "Worker 8, [10/18]: Training Loss: 4.200021637, Training Accuracy: 5.888\n",
            "Worker 8, [11/18]: Training Loss: 4.020750980, Training Accuracy: 7.632\n",
            "Worker 8, [12/18]: Training Loss: 3.913657006, Training Accuracy: 9.456\n",
            "Worker 8, [13/18]: Training Loss: 3.805540357, Training Accuracy: 10.464\n",
            "Worker 8, [14/18]: Training Loss: 3.726434464, Training Accuracy: 12.416\n",
            "Worker 8, [15/18]: Training Loss: 3.656911485, Training Accuracy: 13.536\n",
            "Worker 8, [16/18]: Training Loss: 3.612248078, Training Accuracy: 14.480\n",
            "Worker 8, [17/18]: Training Loss: 4.565894263, Training Accuracy: 4.032\n",
            "Worker 8, [18/18]: Training Loss: 4.556493813, Training Accuracy: 4.544\n",
            "Time taken for training worker 8: 0:00:48.892199\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000757\n",
            "Local Step 01: Test Loss: 4.566184266, Test Accuracy: 3.550\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.568044020, Training Accuracy: 3.120\n",
            "Worker 1, [02/18]: Training Loss: 4.566704098, Training Accuracy: 3.184\n",
            "Worker 1, [03/18]: Training Loss: 4.558721664, Training Accuracy: 3.696\n",
            "Worker 1, [04/18]: Training Loss: 4.534724250, Training Accuracy: 5.024\n",
            "Worker 1, [05/18]: Training Loss: 4.461415758, Training Accuracy: 4.752\n",
            "Worker 1, [06/18]: Training Loss: 4.273910639, Training Accuracy: 5.968\n",
            "Worker 1, [07/18]: Training Loss: 4.114158472, Training Accuracy: 6.880\n",
            "Worker 1, [08/18]: Training Loss: 4.018046639, Training Accuracy: 8.464\n",
            "Worker 1, [09/18]: Training Loss: 4.389792420, Training Accuracy: 4.368\n",
            "Worker 1, [10/18]: Training Loss: 4.055426590, Training Accuracy: 7.808\n",
            "Worker 1, [11/18]: Training Loss: 3.911950751, Training Accuracy: 9.680\n",
            "Worker 1, [12/18]: Training Loss: 3.823624127, Training Accuracy: 11.520\n",
            "Worker 1, [13/18]: Training Loss: 3.738235907, Training Accuracy: 12.368\n",
            "Worker 1, [14/18]: Training Loss: 3.653332725, Training Accuracy: 13.984\n",
            "Worker 1, [15/18]: Training Loss: 3.587917591, Training Accuracy: 14.752\n",
            "Worker 1, [16/18]: Training Loss: 3.519469677, Training Accuracy: 15.520\n",
            "Worker 1, [17/18]: Training Loss: 4.194727348, Training Accuracy: 6.928\n",
            "Worker 1, [18/18]: Training Loss: 3.891067836, Training Accuracy: 10.096\n",
            "Time taken for training worker 1: 0:00:49.630575\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.849800030, Training Accuracy: 11.008\n",
            "Worker 2, [02/18]: Training Loss: 3.824187992, Training Accuracy: 11.328\n",
            "Worker 2, [03/18]: Training Loss: 3.758499240, Training Accuracy: 12.704\n",
            "Worker 2, [04/18]: Training Loss: 3.691257727, Training Accuracy: 13.552\n",
            "Worker 2, [05/18]: Training Loss: 3.635490459, Training Accuracy: 14.400\n",
            "Worker 2, [06/18]: Training Loss: 3.588904880, Training Accuracy: 14.688\n",
            "Worker 2, [07/18]: Training Loss: 3.538422660, Training Accuracy: 14.896\n",
            "Worker 2, [08/18]: Training Loss: 3.498223280, Training Accuracy: 15.568\n",
            "Worker 2, [09/18]: Training Loss: 4.352983947, Training Accuracy: 5.984\n",
            "Worker 2, [10/18]: Training Loss: 3.996480660, Training Accuracy: 8.224\n",
            "Worker 2, [11/18]: Training Loss: 3.841871636, Training Accuracy: 10.016\n",
            "Worker 2, [12/18]: Training Loss: 3.741260169, Training Accuracy: 11.472\n",
            "Worker 2, [13/18]: Training Loss: 3.660157454, Training Accuracy: 13.104\n",
            "Worker 2, [14/18]: Training Loss: 3.563694691, Training Accuracy: 14.304\n",
            "Worker 2, [15/18]: Training Loss: 3.483476271, Training Accuracy: 15.328\n",
            "Worker 2, [16/18]: Training Loss: 3.426771042, Training Accuracy: 16.704\n",
            "Worker 2, [17/18]: Training Loss: 4.139140791, Training Accuracy: 7.216\n",
            "Worker 2, [18/18]: Training Loss: 3.800128158, Training Accuracy: 10.944\n",
            "Time taken for training worker 2: 0:00:47.719326\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.801077042, Training Accuracy: 11.568\n",
            "Worker 3, [02/18]: Training Loss: 3.766285828, Training Accuracy: 11.968\n",
            "Worker 3, [03/18]: Training Loss: 3.708033087, Training Accuracy: 13.264\n",
            "Worker 3, [04/18]: Training Loss: 3.638079529, Training Accuracy: 14.624\n",
            "Worker 3, [05/18]: Training Loss: 3.589027760, Training Accuracy: 15.472\n",
            "Worker 3, [06/18]: Training Loss: 3.552810504, Training Accuracy: 16.592\n",
            "Worker 3, [07/18]: Training Loss: 3.513065345, Training Accuracy: 17.040\n",
            "Worker 3, [08/18]: Training Loss: 3.472197671, Training Accuracy: 16.960\n",
            "Worker 3, [09/18]: Training Loss: 4.359916220, Training Accuracy: 5.264\n",
            "Worker 3, [10/18]: Training Loss: 4.010807268, Training Accuracy: 8.512\n",
            "Worker 3, [11/18]: Training Loss: 3.865038422, Training Accuracy: 10.576\n",
            "Worker 3, [12/18]: Training Loss: 3.733989747, Training Accuracy: 12.752\n",
            "Worker 3, [13/18]: Training Loss: 3.657375547, Training Accuracy: 14.000\n",
            "Worker 3, [14/18]: Training Loss: 3.560634017, Training Accuracy: 15.648\n",
            "Worker 3, [15/18]: Training Loss: 3.501931886, Training Accuracy: 16.400\n",
            "Worker 3, [16/18]: Training Loss: 3.404642502, Training Accuracy: 18.112\n",
            "Worker 3, [17/18]: Training Loss: 4.127315091, Training Accuracy: 8.080\n",
            "Worker 3, [18/18]: Training Loss: 3.799189582, Training Accuracy: 11.248\n",
            "Time taken for training worker 3: 0:00:49.619993\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.784147340, Training Accuracy: 12.256\n",
            "Worker 4, [02/18]: Training Loss: 3.735712759, Training Accuracy: 13.472\n",
            "Worker 4, [03/18]: Training Loss: 3.669796039, Training Accuracy: 14.144\n",
            "Worker 4, [04/18]: Training Loss: 3.616154839, Training Accuracy: 15.408\n",
            "Worker 4, [05/18]: Training Loss: 3.570838123, Training Accuracy: 16.128\n",
            "Worker 4, [06/18]: Training Loss: 3.528133137, Training Accuracy: 16.720\n",
            "Worker 4, [07/18]: Training Loss: 3.474128674, Training Accuracy: 16.688\n",
            "Worker 4, [08/18]: Training Loss: 3.434487370, Training Accuracy: 17.504\n",
            "Worker 4, [09/18]: Training Loss: 4.357235079, Training Accuracy: 6.096\n",
            "Worker 4, [10/18]: Training Loss: 4.011964382, Training Accuracy: 8.448\n",
            "Worker 4, [11/18]: Training Loss: 3.836043049, Training Accuracy: 10.832\n",
            "Worker 4, [12/18]: Training Loss: 3.732342465, Training Accuracy: 12.688\n",
            "Worker 4, [13/18]: Training Loss: 3.650777870, Training Accuracy: 13.392\n",
            "Worker 4, [14/18]: Training Loss: 3.549536722, Training Accuracy: 15.312\n",
            "Worker 4, [15/18]: Training Loss: 3.477650277, Training Accuracy: 16.704\n",
            "Worker 4, [16/18]: Training Loss: 3.407346295, Training Accuracy: 16.848\n",
            "Worker 4, [17/18]: Training Loss: 4.116222854, Training Accuracy: 7.360\n",
            "Worker 4, [18/18]: Training Loss: 3.789034216, Training Accuracy: 11.568\n",
            "Time taken for training worker 4: 0:00:48.406347\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.759535308, Training Accuracy: 12.976\n",
            "Worker 5, [02/18]: Training Loss: 3.737955047, Training Accuracy: 13.152\n",
            "Worker 5, [03/18]: Training Loss: 3.687992415, Training Accuracy: 14.032\n",
            "Worker 5, [04/18]: Training Loss: 3.628596513, Training Accuracy: 14.416\n",
            "Worker 5, [05/18]: Training Loss: 3.559944922, Training Accuracy: 16.240\n",
            "Worker 5, [06/18]: Training Loss: 3.538714830, Training Accuracy: 16.384\n",
            "Worker 5, [07/18]: Training Loss: 3.482912560, Training Accuracy: 16.928\n",
            "Worker 5, [08/18]: Training Loss: 3.452465607, Training Accuracy: 17.936\n",
            "Worker 5, [09/18]: Training Loss: 4.347868233, Training Accuracy: 5.520\n",
            "Worker 5, [10/18]: Training Loss: 4.015040704, Training Accuracy: 8.720\n",
            "Worker 5, [11/18]: Training Loss: 3.864657078, Training Accuracy: 10.736\n",
            "Worker 5, [12/18]: Training Loss: 3.751331113, Training Accuracy: 12.720\n",
            "Worker 5, [13/18]: Training Loss: 3.642042150, Training Accuracy: 13.584\n",
            "Worker 5, [14/18]: Training Loss: 3.564629382, Training Accuracy: 14.800\n",
            "Worker 5, [15/18]: Training Loss: 3.492227946, Training Accuracy: 15.664\n",
            "Worker 5, [16/18]: Training Loss: 3.421962011, Training Accuracy: 17.360\n",
            "Worker 5, [17/18]: Training Loss: 4.130418014, Training Accuracy: 7.792\n",
            "Worker 5, [18/18]: Training Loss: 3.787405634, Training Accuracy: 11.040\n",
            "Time taken for training worker 5: 0:00:48.555104\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.757247258, Training Accuracy: 12.272\n",
            "Worker 6, [02/18]: Training Loss: 3.726898532, Training Accuracy: 12.400\n",
            "Worker 6, [03/18]: Training Loss: 3.656428831, Training Accuracy: 14.192\n",
            "Worker 6, [04/18]: Training Loss: 3.591012896, Training Accuracy: 15.584\n",
            "Worker 6, [05/18]: Training Loss: 3.544570176, Training Accuracy: 15.968\n",
            "Worker 6, [06/18]: Training Loss: 3.500380971, Training Accuracy: 15.840\n",
            "Worker 6, [07/18]: Training Loss: 3.473299053, Training Accuracy: 16.992\n",
            "Worker 6, [08/18]: Training Loss: 3.420923075, Training Accuracy: 17.456\n",
            "Worker 6, [09/18]: Training Loss: 4.336224215, Training Accuracy: 5.264\n",
            "Worker 6, [10/18]: Training Loss: 3.997257710, Training Accuracy: 8.224\n",
            "Worker 6, [11/18]: Training Loss: 3.846848459, Training Accuracy: 10.816\n",
            "Worker 6, [12/18]: Training Loss: 3.737195621, Training Accuracy: 12.304\n",
            "Worker 6, [13/18]: Training Loss: 3.651620741, Training Accuracy: 12.768\n",
            "Worker 6, [14/18]: Training Loss: 3.575276633, Training Accuracy: 14.784\n",
            "Worker 6, [15/18]: Training Loss: 3.505090952, Training Accuracy: 16.064\n",
            "Worker 6, [16/18]: Training Loss: 3.419938170, Training Accuracy: 17.328\n",
            "Worker 6, [17/18]: Training Loss: 4.111725943, Training Accuracy: 7.600\n",
            "Worker 6, [18/18]: Training Loss: 3.795687043, Training Accuracy: 11.360\n",
            "Time taken for training worker 6: 0:00:47.393239\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.791680630, Training Accuracy: 11.472\n",
            "Worker 7, [02/18]: Training Loss: 3.763038767, Training Accuracy: 11.504\n",
            "Worker 7, [03/18]: Training Loss: 3.706423582, Training Accuracy: 12.752\n",
            "Worker 7, [04/18]: Training Loss: 3.642673651, Training Accuracy: 14.592\n",
            "Worker 7, [05/18]: Training Loss: 3.574944842, Training Accuracy: 15.440\n",
            "Worker 7, [06/18]: Training Loss: 3.546074186, Training Accuracy: 15.792\n",
            "Worker 7, [07/18]: Training Loss: 3.484276803, Training Accuracy: 17.216\n",
            "Worker 7, [08/18]: Training Loss: 3.473041189, Training Accuracy: 15.936\n",
            "Worker 7, [09/18]: Training Loss: 4.330104981, Training Accuracy: 5.760\n",
            "Worker 7, [10/18]: Training Loss: 3.989075554, Training Accuracy: 8.672\n",
            "Worker 7, [11/18]: Training Loss: 3.826822473, Training Accuracy: 10.560\n",
            "Worker 7, [12/18]: Training Loss: 3.738285177, Training Accuracy: 11.920\n",
            "Worker 7, [13/18]: Training Loss: 3.645312672, Training Accuracy: 13.376\n",
            "Worker 7, [14/18]: Training Loss: 3.557197004, Training Accuracy: 14.832\n",
            "Worker 7, [15/18]: Training Loss: 3.495491964, Training Accuracy: 15.552\n",
            "Worker 7, [16/18]: Training Loss: 3.435639437, Training Accuracy: 16.736\n",
            "Worker 7, [17/18]: Training Loss: 4.110539125, Training Accuracy: 7.424\n",
            "Worker 7, [18/18]: Training Loss: 3.783325332, Training Accuracy: 11.440\n",
            "Time taken for training worker 7: 0:00:48.413976\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.773330431, Training Accuracy: 12.240\n",
            "Worker 8, [02/18]: Training Loss: 3.734348774, Training Accuracy: 12.640\n",
            "Worker 8, [03/18]: Training Loss: 3.683835314, Training Accuracy: 13.936\n",
            "Worker 8, [04/18]: Training Loss: 3.627594396, Training Accuracy: 14.544\n",
            "Worker 8, [05/18]: Training Loss: 3.581632926, Training Accuracy: 15.744\n",
            "Worker 8, [06/18]: Training Loss: 3.539167677, Training Accuracy: 15.856\n",
            "Worker 8, [07/18]: Training Loss: 3.497168930, Training Accuracy: 15.984\n",
            "Worker 8, [08/18]: Training Loss: 3.475596798, Training Accuracy: 16.016\n",
            "Worker 8, [09/18]: Training Loss: 4.342296304, Training Accuracy: 5.088\n",
            "Worker 8, [10/18]: Training Loss: 3.985752259, Training Accuracy: 8.080\n",
            "Worker 8, [11/18]: Training Loss: 3.837707060, Training Accuracy: 10.512\n",
            "Worker 8, [12/18]: Training Loss: 3.744764085, Training Accuracy: 12.016\n",
            "Worker 8, [13/18]: Training Loss: 3.647286700, Training Accuracy: 13.232\n",
            "Worker 8, [14/18]: Training Loss: 3.573070657, Training Accuracy: 13.696\n",
            "Worker 8, [15/18]: Training Loss: 3.509002851, Training Accuracy: 15.632\n",
            "Worker 8, [16/18]: Training Loss: 3.426161309, Training Accuracy: 16.416\n",
            "Worker 8, [17/18]: Training Loss: 4.098176226, Training Accuracy: 7.680\n",
            "Worker 8, [18/18]: Training Loss: 3.781432959, Training Accuracy: 11.056\n",
            "Time taken for training worker 8: 0:00:47.462590\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000715\n",
            "Local Step 02: Test Loss: 3.747959283, Test Accuracy: 12.510\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.751716950, Training Accuracy: 12.112\n",
            "Worker 1, [02/18]: Training Loss: 3.604153643, Training Accuracy: 15.072\n",
            "Worker 1, [03/18]: Training Loss: 3.505306366, Training Accuracy: 16.352\n",
            "Worker 1, [04/18]: Training Loss: 3.396538878, Training Accuracy: 17.872\n",
            "Worker 1, [05/18]: Training Loss: 3.304008754, Training Accuracy: 19.520\n",
            "Worker 1, [06/18]: Training Loss: 3.201323774, Training Accuracy: 21.152\n",
            "Worker 1, [07/18]: Training Loss: 3.114322078, Training Accuracy: 22.288\n",
            "Worker 1, [08/18]: Training Loss: 3.025612967, Training Accuracy: 23.888\n",
            "Worker 1, [09/18]: Training Loss: 4.083274905, Training Accuracy: 8.768\n",
            "Worker 1, [10/18]: Training Loss: 3.758548994, Training Accuracy: 12.656\n",
            "Worker 1, [11/18]: Training Loss: 3.614975148, Training Accuracy: 15.040\n",
            "Worker 1, [12/18]: Training Loss: 3.486665504, Training Accuracy: 16.576\n",
            "Worker 1, [13/18]: Training Loss: 3.378902627, Training Accuracy: 18.592\n",
            "Worker 1, [14/18]: Training Loss: 3.305025563, Training Accuracy: 20.128\n",
            "Worker 1, [15/18]: Training Loss: 3.239415699, Training Accuracy: 21.216\n",
            "Worker 1, [16/18]: Training Loss: 3.182025885, Training Accuracy: 22.128\n",
            "Worker 1, [17/18]: Training Loss: 4.312672669, Training Accuracy: 13.456\n",
            "Worker 1, [18/18]: Training Loss: 4.213038337, Training Accuracy: 12.544\n",
            "Time taken for training worker 1: 0:00:48.786770\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.944367995, Training Accuracy: 9.120\n",
            "Worker 2, [02/18]: Training Loss: 3.679250810, Training Accuracy: 12.656\n",
            "Worker 2, [03/18]: Training Loss: 3.528248351, Training Accuracy: 15.200\n",
            "Worker 2, [04/18]: Training Loss: 3.425849559, Training Accuracy: 16.656\n",
            "Worker 2, [05/18]: Training Loss: 3.286228005, Training Accuracy: 19.040\n",
            "Worker 2, [06/18]: Training Loss: 3.193114947, Training Accuracy: 20.992\n",
            "Worker 2, [07/18]: Training Loss: 3.098743283, Training Accuracy: 22.048\n",
            "Worker 2, [08/18]: Training Loss: 2.976158310, Training Accuracy: 24.512\n",
            "Worker 2, [09/18]: Training Loss: 4.012088729, Training Accuracy: 10.240\n",
            "Worker 2, [10/18]: Training Loss: 3.664140487, Training Accuracy: 12.784\n",
            "Worker 2, [11/18]: Training Loss: 3.491311776, Training Accuracy: 16.128\n",
            "Worker 2, [12/18]: Training Loss: 3.373168690, Training Accuracy: 17.856\n",
            "Worker 2, [13/18]: Training Loss: 3.257207369, Training Accuracy: 20.112\n",
            "Worker 2, [14/18]: Training Loss: 3.171495255, Training Accuracy: 21.328\n",
            "Worker 2, [15/18]: Training Loss: 3.103203917, Training Accuracy: 23.024\n",
            "Worker 2, [16/18]: Training Loss: 3.030720645, Training Accuracy: 24.320\n",
            "Worker 2, [17/18]: Training Loss: 4.278418312, Training Accuracy: 14.240\n",
            "Worker 2, [18/18]: Training Loss: 4.160781593, Training Accuracy: 13.872\n",
            "Time taken for training worker 2: 0:00:47.992965\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.913735190, Training Accuracy: 9.808\n",
            "Worker 3, [02/18]: Training Loss: 3.664514493, Training Accuracy: 13.616\n",
            "Worker 3, [03/18]: Training Loss: 3.528381557, Training Accuracy: 15.568\n",
            "Worker 3, [04/18]: Training Loss: 3.417963125, Training Accuracy: 18.000\n",
            "Worker 3, [05/18]: Training Loss: 3.294860112, Training Accuracy: 19.440\n",
            "Worker 3, [06/18]: Training Loss: 3.176044406, Training Accuracy: 22.816\n",
            "Worker 3, [07/18]: Training Loss: 3.085431598, Training Accuracy: 22.944\n",
            "Worker 3, [08/18]: Training Loss: 2.969126310, Training Accuracy: 25.472\n",
            "Worker 3, [09/18]: Training Loss: 4.005157120, Training Accuracy: 9.280\n",
            "Worker 3, [10/18]: Training Loss: 3.650814733, Training Accuracy: 14.496\n",
            "Worker 3, [11/18]: Training Loss: 3.496866221, Training Accuracy: 16.640\n",
            "Worker 3, [12/18]: Training Loss: 3.371125795, Training Accuracy: 18.672\n",
            "Worker 3, [13/18]: Training Loss: 3.259514303, Training Accuracy: 20.528\n",
            "Worker 3, [14/18]: Training Loss: 3.168978912, Training Accuracy: 22.384\n",
            "Worker 3, [15/18]: Training Loss: 3.089285809, Training Accuracy: 24.176\n",
            "Worker 3, [16/18]: Training Loss: 3.037539879, Training Accuracy: 25.280\n",
            "Worker 3, [17/18]: Training Loss: 4.275294396, Training Accuracy: 15.552\n",
            "Worker 3, [18/18]: Training Loss: 4.156258758, Training Accuracy: 14.560\n",
            "Time taken for training worker 3: 0:00:48.300317\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.913385216, Training Accuracy: 10.928\n",
            "Worker 4, [02/18]: Training Loss: 3.643744882, Training Accuracy: 13.952\n",
            "Worker 4, [03/18]: Training Loss: 3.488732182, Training Accuracy: 16.928\n",
            "Worker 4, [04/18]: Training Loss: 3.389249133, Training Accuracy: 18.352\n",
            "Worker 4, [05/18]: Training Loss: 3.269097715, Training Accuracy: 19.936\n",
            "Worker 4, [06/18]: Training Loss: 3.174632019, Training Accuracy: 21.824\n",
            "Worker 4, [07/18]: Training Loss: 3.071710504, Training Accuracy: 23.600\n",
            "Worker 4, [08/18]: Training Loss: 2.970206105, Training Accuracy: 25.408\n",
            "Worker 4, [09/18]: Training Loss: 4.035972505, Training Accuracy: 9.504\n",
            "Worker 4, [10/18]: Training Loss: 3.659036646, Training Accuracy: 13.792\n",
            "Worker 4, [11/18]: Training Loss: 3.500770698, Training Accuracy: 16.224\n",
            "Worker 4, [12/18]: Training Loss: 3.367606569, Training Accuracy: 18.848\n",
            "Worker 4, [13/18]: Training Loss: 3.276461414, Training Accuracy: 20.288\n",
            "Worker 4, [14/18]: Training Loss: 3.172456418, Training Accuracy: 22.416\n",
            "Worker 4, [15/18]: Training Loss: 3.089405442, Training Accuracy: 23.792\n",
            "Worker 4, [16/18]: Training Loss: 3.026482631, Training Accuracy: 24.976\n",
            "Worker 4, [17/18]: Training Loss: 4.277770485, Training Accuracy: 14.816\n",
            "Worker 4, [18/18]: Training Loss: 4.157151013, Training Accuracy: 14.080\n",
            "Time taken for training worker 4: 0:00:48.096839\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.885411713, Training Accuracy: 10.496\n",
            "Worker 5, [02/18]: Training Loss: 3.637414000, Training Accuracy: 13.648\n",
            "Worker 5, [03/18]: Training Loss: 3.502636476, Training Accuracy: 16.464\n",
            "Worker 5, [04/18]: Training Loss: 3.368099950, Training Accuracy: 18.160\n",
            "Worker 5, [05/18]: Training Loss: 3.289981635, Training Accuracy: 19.984\n",
            "Worker 5, [06/18]: Training Loss: 3.184449130, Training Accuracy: 21.040\n",
            "Worker 5, [07/18]: Training Loss: 3.097533868, Training Accuracy: 23.056\n",
            "Worker 5, [08/18]: Training Loss: 2.983133535, Training Accuracy: 25.136\n",
            "Worker 5, [09/18]: Training Loss: 4.022481332, Training Accuracy: 9.712\n",
            "Worker 5, [10/18]: Training Loss: 3.666322153, Training Accuracy: 13.456\n",
            "Worker 5, [11/18]: Training Loss: 3.477447400, Training Accuracy: 16.368\n",
            "Worker 5, [12/18]: Training Loss: 3.376604815, Training Accuracy: 18.432\n",
            "Worker 5, [13/18]: Training Loss: 3.278563018, Training Accuracy: 20.208\n",
            "Worker 5, [14/18]: Training Loss: 3.188182785, Training Accuracy: 21.936\n",
            "Worker 5, [15/18]: Training Loss: 3.121726970, Training Accuracy: 23.248\n",
            "Worker 5, [16/18]: Training Loss: 3.044676158, Training Accuracy: 24.608\n",
            "Worker 5, [17/18]: Training Loss: 4.280513549, Training Accuracy: 14.944\n",
            "Worker 5, [18/18]: Training Loss: 4.165553317, Training Accuracy: 14.064\n",
            "Time taken for training worker 5: 0:00:47.741518\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.894389157, Training Accuracy: 10.256\n",
            "Worker 6, [02/18]: Training Loss: 3.612384587, Training Accuracy: 14.272\n",
            "Worker 6, [03/18]: Training Loss: 3.495440838, Training Accuracy: 16.016\n",
            "Worker 6, [04/18]: Training Loss: 3.398764812, Training Accuracy: 18.176\n",
            "Worker 6, [05/18]: Training Loss: 3.282442431, Training Accuracy: 19.184\n",
            "Worker 6, [06/18]: Training Loss: 3.177309224, Training Accuracy: 21.696\n",
            "Worker 6, [07/18]: Training Loss: 3.089090043, Training Accuracy: 22.480\n",
            "Worker 6, [08/18]: Training Loss: 2.979451248, Training Accuracy: 25.552\n",
            "Worker 6, [09/18]: Training Loss: 4.004445302, Training Accuracy: 10.080\n",
            "Worker 6, [10/18]: Training Loss: 3.658948760, Training Accuracy: 13.616\n",
            "Worker 6, [11/18]: Training Loss: 3.488274749, Training Accuracy: 16.576\n",
            "Worker 6, [12/18]: Training Loss: 3.387311018, Training Accuracy: 17.968\n",
            "Worker 6, [13/18]: Training Loss: 3.267423963, Training Accuracy: 20.496\n",
            "Worker 6, [14/18]: Training Loss: 3.165125552, Training Accuracy: 21.856\n",
            "Worker 6, [15/18]: Training Loss: 3.109946373, Training Accuracy: 22.304\n",
            "Worker 6, [16/18]: Training Loss: 3.059148703, Training Accuracy: 24.768\n",
            "Worker 6, [17/18]: Training Loss: 4.283810951, Training Accuracy: 14.832\n",
            "Worker 6, [18/18]: Training Loss: 4.170169465, Training Accuracy: 13.872\n",
            "Time taken for training worker 6: 0:00:49.350825\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.913839854, Training Accuracy: 10.320\n",
            "Worker 7, [02/18]: Training Loss: 3.639026469, Training Accuracy: 14.128\n",
            "Worker 7, [03/18]: Training Loss: 3.512047026, Training Accuracy: 16.176\n",
            "Worker 7, [04/18]: Training Loss: 3.416111292, Training Accuracy: 17.248\n",
            "Worker 7, [05/18]: Training Loss: 3.301766814, Training Accuracy: 18.720\n",
            "Worker 7, [06/18]: Training Loss: 3.185510049, Training Accuracy: 20.944\n",
            "Worker 7, [07/18]: Training Loss: 3.086545898, Training Accuracy: 22.960\n",
            "Worker 7, [08/18]: Training Loss: 2.995706101, Training Accuracy: 24.304\n",
            "Worker 7, [09/18]: Training Loss: 4.018724904, Training Accuracy: 9.440\n",
            "Worker 7, [10/18]: Training Loss: 3.683680595, Training Accuracy: 13.264\n",
            "Worker 7, [11/18]: Training Loss: 3.503917682, Training Accuracy: 15.744\n",
            "Worker 7, [12/18]: Training Loss: 3.393008064, Training Accuracy: 17.440\n",
            "Worker 7, [13/18]: Training Loss: 3.293620944, Training Accuracy: 20.000\n",
            "Worker 7, [14/18]: Training Loss: 3.193006625, Training Accuracy: 21.104\n",
            "Worker 7, [15/18]: Training Loss: 3.124589713, Training Accuracy: 22.848\n",
            "Worker 7, [16/18]: Training Loss: 3.059494393, Training Accuracy: 23.984\n",
            "Worker 7, [17/18]: Training Loss: 4.269341274, Training Accuracy: 14.368\n",
            "Worker 7, [18/18]: Training Loss: 4.153383435, Training Accuracy: 14.160\n",
            "Time taken for training worker 7: 0:00:49.627108\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.892461602, Training Accuracy: 9.680\n",
            "Worker 8, [02/18]: Training Loss: 3.661557076, Training Accuracy: 13.248\n",
            "Worker 8, [03/18]: Training Loss: 3.506169139, Training Accuracy: 15.328\n",
            "Worker 8, [04/18]: Training Loss: 3.406045293, Training Accuracy: 16.704\n",
            "Worker 8, [05/18]: Training Loss: 3.293999942, Training Accuracy: 19.072\n",
            "Worker 8, [06/18]: Training Loss: 3.197032836, Training Accuracy: 19.968\n",
            "Worker 8, [07/18]: Training Loss: 3.082317669, Training Accuracy: 23.104\n",
            "Worker 8, [08/18]: Training Loss: 3.004852429, Training Accuracy: 24.288\n",
            "Worker 8, [09/18]: Training Loss: 3.991536009, Training Accuracy: 10.112\n",
            "Worker 8, [10/18]: Training Loss: 3.648468412, Training Accuracy: 13.184\n",
            "Worker 8, [11/18]: Training Loss: 3.485548114, Training Accuracy: 15.808\n",
            "Worker 8, [12/18]: Training Loss: 3.363930349, Training Accuracy: 18.192\n",
            "Worker 8, [13/18]: Training Loss: 3.262308123, Training Accuracy: 20.576\n",
            "Worker 8, [14/18]: Training Loss: 3.171878992, Training Accuracy: 21.648\n",
            "Worker 8, [15/18]: Training Loss: 3.101262195, Training Accuracy: 23.136\n",
            "Worker 8, [16/18]: Training Loss: 3.033216406, Training Accuracy: 24.256\n",
            "Worker 8, [17/18]: Training Loss: 4.270949592, Training Accuracy: 13.744\n",
            "Worker 8, [18/18]: Training Loss: 4.155343776, Training Accuracy: 13.296\n",
            "Time taken for training worker 8: 0:00:48.819408\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000697\n",
            "Local Step 03: Test Loss: 4.146308457, Test Accuracy: 12.840\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 4.179425969, Training Accuracy: 11.840\n",
            "Worker 1, [02/18]: Training Loss: 4.155334881, Training Accuracy: 12.032\n",
            "Worker 1, [03/18]: Training Loss: 4.058419279, Training Accuracy: 11.536\n",
            "Worker 1, [04/18]: Training Loss: 3.883327124, Training Accuracy: 12.128\n",
            "Worker 1, [05/18]: Training Loss: 3.759244247, Training Accuracy: 13.424\n",
            "Worker 1, [06/18]: Training Loss: 3.671225925, Training Accuracy: 14.288\n",
            "Worker 1, [07/18]: Training Loss: 3.589314672, Training Accuracy: 15.088\n",
            "Worker 1, [08/18]: Training Loss: 3.531099662, Training Accuracy: 16.000\n",
            "Worker 1, [09/18]: Training Loss: 3.912417847, Training Accuracy: 11.056\n",
            "Worker 1, [10/18]: Training Loss: 3.659037753, Training Accuracy: 14.128\n",
            "Worker 1, [11/18]: Training Loss: 3.531995620, Training Accuracy: 16.336\n",
            "Worker 1, [12/18]: Training Loss: 3.475247814, Training Accuracy: 16.864\n",
            "Worker 1, [13/18]: Training Loss: 3.406464550, Training Accuracy: 18.000\n",
            "Worker 1, [14/18]: Training Loss: 3.332521363, Training Accuracy: 19.344\n",
            "Worker 1, [15/18]: Training Loss: 3.266571845, Training Accuracy: 20.080\n",
            "Worker 1, [16/18]: Training Loss: 3.191436539, Training Accuracy: 21.872\n",
            "Worker 1, [17/18]: Training Loss: 3.834334252, Training Accuracy: 11.824\n",
            "Worker 1, [18/18]: Training Loss: 3.540804024, Training Accuracy: 16.128\n",
            "Time taken for training worker 1: 0:00:48.180273\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.626484289, Training Accuracy: 14.384\n",
            "Worker 2, [02/18]: Training Loss: 3.556576561, Training Accuracy: 15.056\n",
            "Worker 2, [03/18]: Training Loss: 3.462347242, Training Accuracy: 16.752\n",
            "Worker 2, [04/18]: Training Loss: 3.392497457, Training Accuracy: 18.960\n",
            "Worker 2, [05/18]: Training Loss: 3.325459261, Training Accuracy: 19.264\n",
            "Worker 2, [06/18]: Training Loss: 3.284032196, Training Accuracy: 20.080\n",
            "Worker 2, [07/18]: Training Loss: 3.246739132, Training Accuracy: 20.576\n",
            "Worker 2, [08/18]: Training Loss: 3.188782994, Training Accuracy: 21.472\n",
            "Worker 2, [09/18]: Training Loss: 3.812463770, Training Accuracy: 12.256\n",
            "Worker 2, [10/18]: Training Loss: 3.527703696, Training Accuracy: 15.232\n",
            "Worker 2, [11/18]: Training Loss: 3.417700429, Training Accuracy: 16.912\n",
            "Worker 2, [12/18]: Training Loss: 3.347353342, Training Accuracy: 18.368\n",
            "Worker 2, [13/18]: Training Loss: 3.266082812, Training Accuracy: 19.008\n",
            "Worker 2, [14/18]: Training Loss: 3.205568260, Training Accuracy: 20.480\n",
            "Worker 2, [15/18]: Training Loss: 3.134632794, Training Accuracy: 21.424\n",
            "Worker 2, [16/18]: Training Loss: 3.084109292, Training Accuracy: 22.640\n",
            "Worker 2, [17/18]: Training Loss: 3.713635605, Training Accuracy: 13.280\n",
            "Worker 2, [18/18]: Training Loss: 3.451058509, Training Accuracy: 16.864\n",
            "Time taken for training worker 2: 0:00:47.104697\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.553125489, Training Accuracy: 14.928\n",
            "Worker 3, [02/18]: Training Loss: 3.501998320, Training Accuracy: 16.512\n",
            "Worker 3, [03/18]: Training Loss: 3.432445567, Training Accuracy: 17.952\n",
            "Worker 3, [04/18]: Training Loss: 3.356404086, Training Accuracy: 19.904\n",
            "Worker 3, [05/18]: Training Loss: 3.288384844, Training Accuracy: 21.120\n",
            "Worker 3, [06/18]: Training Loss: 3.261723788, Training Accuracy: 21.392\n",
            "Worker 3, [07/18]: Training Loss: 3.218467569, Training Accuracy: 21.600\n",
            "Worker 3, [08/18]: Training Loss: 3.154178624, Training Accuracy: 22.896\n",
            "Worker 3, [09/18]: Training Loss: 3.833588710, Training Accuracy: 13.088\n",
            "Worker 3, [10/18]: Training Loss: 3.534994685, Training Accuracy: 15.920\n",
            "Worker 3, [11/18]: Training Loss: 3.426034774, Training Accuracy: 17.456\n",
            "Worker 3, [12/18]: Training Loss: 3.343010355, Training Accuracy: 18.944\n",
            "Worker 3, [13/18]: Training Loss: 3.279409399, Training Accuracy: 19.808\n",
            "Worker 3, [14/18]: Training Loss: 3.209059997, Training Accuracy: 21.568\n",
            "Worker 3, [15/18]: Training Loss: 3.124562426, Training Accuracy: 22.784\n",
            "Worker 3, [16/18]: Training Loss: 3.109660582, Training Accuracy: 22.800\n",
            "Worker 3, [17/18]: Training Loss: 3.724327988, Training Accuracy: 12.928\n",
            "Worker 3, [18/18]: Training Loss: 3.453769533, Training Accuracy: 16.832\n",
            "Time taken for training worker 3: 0:00:48.567387\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.559719358, Training Accuracy: 15.168\n",
            "Worker 4, [02/18]: Training Loss: 3.510234470, Training Accuracy: 16.080\n",
            "Worker 4, [03/18]: Training Loss: 3.407567056, Training Accuracy: 18.112\n",
            "Worker 4, [04/18]: Training Loss: 3.341157346, Training Accuracy: 20.576\n",
            "Worker 4, [05/18]: Training Loss: 3.282892473, Training Accuracy: 21.152\n",
            "Worker 4, [06/18]: Training Loss: 3.218253197, Training Accuracy: 22.144\n",
            "Worker 4, [07/18]: Training Loss: 3.186498399, Training Accuracy: 22.736\n",
            "Worker 4, [08/18]: Training Loss: 3.175628728, Training Accuracy: 22.080\n",
            "Worker 4, [09/18]: Training Loss: 3.814293107, Training Accuracy: 13.296\n",
            "Worker 4, [10/18]: Training Loss: 3.533145343, Training Accuracy: 16.048\n",
            "Worker 4, [11/18]: Training Loss: 3.418240922, Training Accuracy: 17.488\n",
            "Worker 4, [12/18]: Training Loss: 3.339624570, Training Accuracy: 18.864\n",
            "Worker 4, [13/18]: Training Loss: 3.258611487, Training Accuracy: 19.888\n",
            "Worker 4, [14/18]: Training Loss: 3.181086299, Training Accuracy: 21.120\n",
            "Worker 4, [15/18]: Training Loss: 3.150889735, Training Accuracy: 21.776\n",
            "Worker 4, [16/18]: Training Loss: 3.074811210, Training Accuracy: 22.592\n",
            "Worker 4, [17/18]: Training Loss: 3.694469430, Training Accuracy: 13.456\n",
            "Worker 4, [18/18]: Training Loss: 3.437912274, Training Accuracy: 17.456\n",
            "Time taken for training worker 4: 0:00:47.734960\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.565265283, Training Accuracy: 16.480\n",
            "Worker 5, [02/18]: Training Loss: 3.486686709, Training Accuracy: 17.200\n",
            "Worker 5, [03/18]: Training Loss: 3.405818107, Training Accuracy: 18.736\n",
            "Worker 5, [04/18]: Training Loss: 3.342734466, Training Accuracy: 19.920\n",
            "Worker 5, [05/18]: Training Loss: 3.283552566, Training Accuracy: 20.976\n",
            "Worker 5, [06/18]: Training Loss: 3.238618442, Training Accuracy: 21.600\n",
            "Worker 5, [07/18]: Training Loss: 3.184048645, Training Accuracy: 22.352\n",
            "Worker 5, [08/18]: Training Loss: 3.169437350, Training Accuracy: 22.304\n",
            "Worker 5, [09/18]: Training Loss: 3.824099609, Training Accuracy: 12.912\n",
            "Worker 5, [10/18]: Training Loss: 3.537941115, Training Accuracy: 16.032\n",
            "Worker 5, [11/18]: Training Loss: 3.438177885, Training Accuracy: 17.392\n",
            "Worker 5, [12/18]: Training Loss: 3.336353416, Training Accuracy: 18.688\n",
            "Worker 5, [13/18]: Training Loss: 3.281012484, Training Accuracy: 19.888\n",
            "Worker 5, [14/18]: Training Loss: 3.215133511, Training Accuracy: 20.608\n",
            "Worker 5, [15/18]: Training Loss: 3.142807309, Training Accuracy: 21.968\n",
            "Worker 5, [16/18]: Training Loss: 3.082609765, Training Accuracy: 22.928\n",
            "Worker 5, [17/18]: Training Loss: 3.721029610, Training Accuracy: 13.712\n",
            "Worker 5, [18/18]: Training Loss: 3.440941813, Training Accuracy: 17.008\n",
            "Time taken for training worker 5: 0:00:48.699809\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.524399745, Training Accuracy: 16.704\n",
            "Worker 6, [02/18]: Training Loss: 3.491861565, Training Accuracy: 17.504\n",
            "Worker 6, [03/18]: Training Loss: 3.406325513, Training Accuracy: 18.832\n",
            "Worker 6, [04/18]: Training Loss: 3.328500733, Training Accuracy: 20.144\n",
            "Worker 6, [05/18]: Training Loss: 3.273093596, Training Accuracy: 21.152\n",
            "Worker 6, [06/18]: Training Loss: 3.208376848, Training Accuracy: 22.176\n",
            "Worker 6, [07/18]: Training Loss: 3.185619323, Training Accuracy: 21.616\n",
            "Worker 6, [08/18]: Training Loss: 3.145493203, Training Accuracy: 22.112\n",
            "Worker 6, [09/18]: Training Loss: 3.823534922, Training Accuracy: 12.768\n",
            "Worker 6, [10/18]: Training Loss: 3.538763165, Training Accuracy: 15.360\n",
            "Worker 6, [11/18]: Training Loss: 3.436547053, Training Accuracy: 17.456\n",
            "Worker 6, [12/18]: Training Loss: 3.364875550, Training Accuracy: 17.520\n",
            "Worker 6, [13/18]: Training Loss: 3.292195853, Training Accuracy: 19.872\n",
            "Worker 6, [14/18]: Training Loss: 3.249135759, Training Accuracy: 19.840\n",
            "Worker 6, [15/18]: Training Loss: 3.154124107, Training Accuracy: 21.248\n",
            "Worker 6, [16/18]: Training Loss: 3.086373144, Training Accuracy: 22.992\n",
            "Worker 6, [17/18]: Training Loss: 3.696597853, Training Accuracy: 13.712\n",
            "Worker 6, [18/18]: Training Loss: 3.441462573, Training Accuracy: 16.864\n",
            "Time taken for training worker 6: 0:00:47.310621\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.550009075, Training Accuracy: 15.440\n",
            "Worker 7, [02/18]: Training Loss: 3.501579628, Training Accuracy: 15.680\n",
            "Worker 7, [03/18]: Training Loss: 3.415132282, Training Accuracy: 17.872\n",
            "Worker 7, [04/18]: Training Loss: 3.337423994, Training Accuracy: 19.232\n",
            "Worker 7, [05/18]: Training Loss: 3.298250315, Training Accuracy: 20.352\n",
            "Worker 7, [06/18]: Training Loss: 3.247345968, Training Accuracy: 20.384\n",
            "Worker 7, [07/18]: Training Loss: 3.198697854, Training Accuracy: 21.168\n",
            "Worker 7, [08/18]: Training Loss: 3.173231599, Training Accuracy: 21.776\n",
            "Worker 7, [09/18]: Training Loss: 3.803677583, Training Accuracy: 12.848\n",
            "Worker 7, [10/18]: Training Loss: 3.538720943, Training Accuracy: 15.360\n",
            "Worker 7, [11/18]: Training Loss: 3.443030569, Training Accuracy: 17.104\n",
            "Worker 7, [12/18]: Training Loss: 3.370015290, Training Accuracy: 17.856\n",
            "Worker 7, [13/18]: Training Loss: 3.287278596, Training Accuracy: 18.976\n",
            "Worker 7, [14/18]: Training Loss: 3.212843034, Training Accuracy: 19.872\n",
            "Worker 7, [15/18]: Training Loss: 3.176609582, Training Accuracy: 21.072\n",
            "Worker 7, [16/18]: Training Loss: 3.093263312, Training Accuracy: 22.944\n",
            "Worker 7, [17/18]: Training Loss: 3.712246878, Training Accuracy: 13.648\n",
            "Worker 7, [18/18]: Training Loss: 3.480359082, Training Accuracy: 16.112\n",
            "Time taken for training worker 7: 0:00:48.328288\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.560156868, Training Accuracy: 14.880\n",
            "Worker 8, [02/18]: Training Loss: 3.517694254, Training Accuracy: 15.664\n",
            "Worker 8, [03/18]: Training Loss: 3.426467988, Training Accuracy: 17.728\n",
            "Worker 8, [04/18]: Training Loss: 3.361642149, Training Accuracy: 19.008\n",
            "Worker 8, [05/18]: Training Loss: 3.297583137, Training Accuracy: 20.336\n",
            "Worker 8, [06/18]: Training Loss: 3.249524211, Training Accuracy: 20.320\n",
            "Worker 8, [07/18]: Training Loss: 3.202583612, Training Accuracy: 21.456\n",
            "Worker 8, [08/18]: Training Loss: 3.179649604, Training Accuracy: 21.200\n",
            "Worker 8, [09/18]: Training Loss: 3.819018308, Training Accuracy: 12.720\n",
            "Worker 8, [10/18]: Training Loss: 3.520850203, Training Accuracy: 15.536\n",
            "Worker 8, [11/18]: Training Loss: 3.421616605, Training Accuracy: 16.624\n",
            "Worker 8, [12/18]: Training Loss: 3.349322696, Training Accuracy: 17.648\n",
            "Worker 8, [13/18]: Training Loss: 3.274633787, Training Accuracy: 18.992\n",
            "Worker 8, [14/18]: Training Loss: 3.205543637, Training Accuracy: 21.104\n",
            "Worker 8, [15/18]: Training Loss: 3.163130867, Training Accuracy: 21.040\n",
            "Worker 8, [16/18]: Training Loss: 3.088518780, Training Accuracy: 22.224\n",
            "Worker 8, [17/18]: Training Loss: 3.731213472, Training Accuracy: 12.800\n",
            "Worker 8, [18/18]: Training Loss: 3.449254841, Training Accuracy: 16.400\n",
            "Time taken for training worker 8: 0:00:47.645114\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000784\n",
            "Local Step 04: Test Loss: 3.448478623, Test Accuracy: 17.170\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.510088492, Training Accuracy: 16.752\n",
            "Worker 1, [02/18]: Training Loss: 3.361195895, Training Accuracy: 18.672\n",
            "Worker 1, [03/18]: Training Loss: 3.225530972, Training Accuracy: 20.992\n",
            "Worker 1, [04/18]: Training Loss: 3.125338764, Training Accuracy: 22.816\n",
            "Worker 1, [05/18]: Training Loss: 3.063454759, Training Accuracy: 23.024\n",
            "Worker 1, [06/18]: Training Loss: 2.943473624, Training Accuracy: 25.392\n",
            "Worker 1, [07/18]: Training Loss: 2.844225319, Training Accuracy: 27.584\n",
            "Worker 1, [08/18]: Training Loss: 2.733031168, Training Accuracy: 29.440\n",
            "Worker 1, [09/18]: Training Loss: 3.685508460, Training Accuracy: 14.128\n",
            "Worker 1, [10/18]: Training Loss: 3.403756249, Training Accuracy: 17.856\n",
            "Worker 1, [11/18]: Training Loss: 3.236482688, Training Accuracy: 21.392\n",
            "Worker 1, [12/18]: Training Loss: 3.138910612, Training Accuracy: 23.008\n",
            "Worker 1, [13/18]: Training Loss: 3.040948067, Training Accuracy: 25.216\n",
            "Worker 1, [14/18]: Training Loss: 2.919526660, Training Accuracy: 26.448\n",
            "Worker 1, [15/18]: Training Loss: 2.856323218, Training Accuracy: 28.528\n",
            "Worker 1, [16/18]: Training Loss: 2.783463164, Training Accuracy: 29.520\n",
            "Worker 1, [17/18]: Training Loss: 3.840818128, Training Accuracy: 19.280\n",
            "Worker 1, [18/18]: Training Loss: 3.637812481, Training Accuracy: 18.896\n",
            "Time taken for training worker 1: 0:00:48.477640\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.660702944, Training Accuracy: 13.424\n",
            "Worker 2, [02/18]: Training Loss: 3.424723508, Training Accuracy: 16.880\n",
            "Worker 2, [03/18]: Training Loss: 3.289905548, Training Accuracy: 18.976\n",
            "Worker 2, [04/18]: Training Loss: 3.167932664, Training Accuracy: 21.504\n",
            "Worker 2, [05/18]: Training Loss: 3.070805102, Training Accuracy: 22.560\n",
            "Worker 2, [06/18]: Training Loss: 2.946368587, Training Accuracy: 25.696\n",
            "Worker 2, [07/18]: Training Loss: 2.845342227, Training Accuracy: 27.952\n",
            "Worker 2, [08/18]: Training Loss: 2.732556893, Training Accuracy: 29.648\n",
            "Worker 2, [09/18]: Training Loss: 3.568520568, Training Accuracy: 15.888\n",
            "Worker 2, [10/18]: Training Loss: 3.281472992, Training Accuracy: 19.632\n",
            "Worker 2, [11/18]: Training Loss: 3.136989238, Training Accuracy: 21.952\n",
            "Worker 2, [12/18]: Training Loss: 3.006786689, Training Accuracy: 24.192\n",
            "Worker 2, [13/18]: Training Loss: 2.904581425, Training Accuracy: 26.752\n",
            "Worker 2, [14/18]: Training Loss: 2.782683458, Training Accuracy: 28.432\n",
            "Worker 2, [15/18]: Training Loss: 2.728114252, Training Accuracy: 30.080\n",
            "Worker 2, [16/18]: Training Loss: 2.652071367, Training Accuracy: 31.568\n",
            "Worker 2, [17/18]: Training Loss: 3.727612179, Training Accuracy: 22.560\n",
            "Worker 2, [18/18]: Training Loss: 3.498409614, Training Accuracy: 21.456\n",
            "Time taken for training worker 2: 0:00:48.222178\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.635609138, Training Accuracy: 14.592\n",
            "Worker 3, [02/18]: Training Loss: 3.417672897, Training Accuracy: 17.856\n",
            "Worker 3, [03/18]: Training Loss: 3.287056709, Training Accuracy: 20.384\n",
            "Worker 3, [04/18]: Training Loss: 3.188645202, Training Accuracy: 21.632\n",
            "Worker 3, [05/18]: Training Loss: 3.080451853, Training Accuracy: 22.944\n",
            "Worker 3, [06/18]: Training Loss: 2.985131789, Training Accuracy: 24.816\n",
            "Worker 3, [07/18]: Training Loss: 2.883540078, Training Accuracy: 27.312\n",
            "Worker 3, [08/18]: Training Loss: 2.769265323, Training Accuracy: 29.008\n",
            "Worker 3, [09/18]: Training Loss: 3.557328436, Training Accuracy: 17.408\n",
            "Worker 3, [10/18]: Training Loss: 3.288893923, Training Accuracy: 20.464\n",
            "Worker 3, [11/18]: Training Loss: 3.132992781, Training Accuracy: 23.792\n",
            "Worker 3, [12/18]: Training Loss: 3.013312992, Training Accuracy: 24.816\n",
            "Worker 3, [13/18]: Training Loss: 2.897133710, Training Accuracy: 27.808\n",
            "Worker 3, [14/18]: Training Loss: 2.814748348, Training Accuracy: 28.800\n",
            "Worker 3, [15/18]: Training Loss: 2.726254955, Training Accuracy: 30.800\n",
            "Worker 3, [16/18]: Training Loss: 2.668791275, Training Accuracy: 32.000\n",
            "Worker 3, [17/18]: Training Loss: 3.727698878, Training Accuracy: 23.280\n",
            "Worker 3, [18/18]: Training Loss: 3.500460002, Training Accuracy: 21.728\n",
            "Time taken for training worker 3: 0:00:47.141516\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.625648005, Training Accuracy: 14.656\n",
            "Worker 4, [02/18]: Training Loss: 3.421583356, Training Accuracy: 17.280\n",
            "Worker 4, [03/18]: Training Loss: 3.263254871, Training Accuracy: 19.536\n",
            "Worker 4, [04/18]: Training Loss: 3.161519785, Training Accuracy: 21.472\n",
            "Worker 4, [05/18]: Training Loss: 3.045047334, Training Accuracy: 23.008\n",
            "Worker 4, [06/18]: Training Loss: 2.961879905, Training Accuracy: 25.712\n",
            "Worker 4, [07/18]: Training Loss: 2.857743103, Training Accuracy: 26.928\n",
            "Worker 4, [08/18]: Training Loss: 2.800786055, Training Accuracy: 28.304\n",
            "Worker 4, [09/18]: Training Loss: 3.538114124, Training Accuracy: 16.448\n",
            "Worker 4, [10/18]: Training Loss: 3.272381795, Training Accuracy: 20.064\n",
            "Worker 4, [11/18]: Training Loss: 3.111562622, Training Accuracy: 23.136\n",
            "Worker 4, [12/18]: Training Loss: 2.993042418, Training Accuracy: 24.704\n",
            "Worker 4, [13/18]: Training Loss: 2.899233553, Training Accuracy: 26.640\n",
            "Worker 4, [14/18]: Training Loss: 2.797115102, Training Accuracy: 28.608\n",
            "Worker 4, [15/18]: Training Loss: 2.726190528, Training Accuracy: 30.848\n",
            "Worker 4, [16/18]: Training Loss: 2.648531943, Training Accuracy: 32.256\n",
            "Worker 4, [17/18]: Training Loss: 3.731965211, Training Accuracy: 22.864\n",
            "Worker 4, [18/18]: Training Loss: 3.497021979, Training Accuracy: 22.624\n",
            "Time taken for training worker 4: 0:00:48.813085\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.614222390, Training Accuracy: 14.672\n",
            "Worker 5, [02/18]: Training Loss: 3.401446980, Training Accuracy: 18.368\n",
            "Worker 5, [03/18]: Training Loss: 3.309135972, Training Accuracy: 19.552\n",
            "Worker 5, [04/18]: Training Loss: 3.159677238, Training Accuracy: 21.440\n",
            "Worker 5, [05/18]: Training Loss: 3.048070630, Training Accuracy: 23.552\n",
            "Worker 5, [06/18]: Training Loss: 2.966298845, Training Accuracy: 25.376\n",
            "Worker 5, [07/18]: Training Loss: 2.874867091, Training Accuracy: 27.504\n",
            "Worker 5, [08/18]: Training Loss: 2.763693863, Training Accuracy: 29.728\n",
            "Worker 5, [09/18]: Training Loss: 3.552953063, Training Accuracy: 16.992\n",
            "Worker 5, [10/18]: Training Loss: 3.291576242, Training Accuracy: 19.792\n",
            "Worker 5, [11/18]: Training Loss: 3.139529958, Training Accuracy: 22.176\n",
            "Worker 5, [12/18]: Training Loss: 3.025807977, Training Accuracy: 24.848\n",
            "Worker 5, [13/18]: Training Loss: 2.915099402, Training Accuracy: 26.976\n",
            "Worker 5, [14/18]: Training Loss: 2.815750825, Training Accuracy: 28.448\n",
            "Worker 5, [15/18]: Training Loss: 2.744932525, Training Accuracy: 30.016\n",
            "Worker 5, [16/18]: Training Loss: 2.664602739, Training Accuracy: 32.032\n",
            "Worker 5, [17/18]: Training Loss: 3.729043474, Training Accuracy: 22.064\n",
            "Worker 5, [18/18]: Training Loss: 3.505429088, Training Accuracy: 20.736\n",
            "Time taken for training worker 5: 0:00:48.063452\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.590751619, Training Accuracy: 15.440\n",
            "Worker 6, [02/18]: Training Loss: 3.422693425, Training Accuracy: 17.616\n",
            "Worker 6, [03/18]: Training Loss: 3.274676882, Training Accuracy: 19.936\n",
            "Worker 6, [04/18]: Training Loss: 3.161006991, Training Accuracy: 22.464\n",
            "Worker 6, [05/18]: Training Loss: 3.053945546, Training Accuracy: 23.472\n",
            "Worker 6, [06/18]: Training Loss: 2.977039816, Training Accuracy: 24.816\n",
            "Worker 6, [07/18]: Training Loss: 2.863509241, Training Accuracy: 27.488\n",
            "Worker 6, [08/18]: Training Loss: 2.762752419, Training Accuracy: 29.312\n",
            "Worker 6, [09/18]: Training Loss: 3.548978786, Training Accuracy: 16.912\n",
            "Worker 6, [10/18]: Training Loss: 3.274152921, Training Accuracy: 20.000\n",
            "Worker 6, [11/18]: Training Loss: 3.138823424, Training Accuracy: 22.416\n",
            "Worker 6, [12/18]: Training Loss: 3.027401851, Training Accuracy: 24.368\n",
            "Worker 6, [13/18]: Training Loss: 2.932971786, Training Accuracy: 26.096\n",
            "Worker 6, [14/18]: Training Loss: 2.820137236, Training Accuracy: 29.056\n",
            "Worker 6, [15/18]: Training Loss: 2.743407191, Training Accuracy: 30.384\n",
            "Worker 6, [16/18]: Training Loss: 2.678217177, Training Accuracy: 31.984\n",
            "Worker 6, [17/18]: Training Loss: 3.746140592, Training Accuracy: 22.320\n",
            "Worker 6, [18/18]: Training Loss: 3.513337809, Training Accuracy: 20.928\n",
            "Time taken for training worker 6: 0:00:47.957207\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.620445704, Training Accuracy: 15.040\n",
            "Worker 7, [02/18]: Training Loss: 3.401482419, Training Accuracy: 17.088\n",
            "Worker 7, [03/18]: Training Loss: 3.275728625, Training Accuracy: 19.360\n",
            "Worker 7, [04/18]: Training Loss: 3.165768952, Training Accuracy: 21.584\n",
            "Worker 7, [05/18]: Training Loss: 3.062441120, Training Accuracy: 23.552\n",
            "Worker 7, [06/18]: Training Loss: 2.977760517, Training Accuracy: 25.104\n",
            "Worker 7, [07/18]: Training Loss: 2.873061839, Training Accuracy: 26.800\n",
            "Worker 7, [08/18]: Training Loss: 2.787039973, Training Accuracy: 28.672\n",
            "Worker 7, [09/18]: Training Loss: 3.562420205, Training Accuracy: 16.048\n",
            "Worker 7, [10/18]: Training Loss: 3.300510735, Training Accuracy: 19.456\n",
            "Worker 7, [11/18]: Training Loss: 3.149359988, Training Accuracy: 21.840\n",
            "Worker 7, [12/18]: Training Loss: 3.046649132, Training Accuracy: 23.456\n",
            "Worker 7, [13/18]: Training Loss: 2.938581501, Training Accuracy: 26.160\n",
            "Worker 7, [14/18]: Training Loss: 2.833010333, Training Accuracy: 27.840\n",
            "Worker 7, [15/18]: Training Loss: 2.772883909, Training Accuracy: 29.584\n",
            "Worker 7, [16/18]: Training Loss: 2.710890729, Training Accuracy: 30.880\n",
            "Worker 7, [17/18]: Training Loss: 3.748036197, Training Accuracy: 22.256\n",
            "Worker 7, [18/18]: Training Loss: 3.518349144, Training Accuracy: 21.424\n",
            "Time taken for training worker 7: 0:00:48.426955\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.618761420, Training Accuracy: 14.208\n",
            "Worker 8, [02/18]: Training Loss: 3.444423559, Training Accuracy: 16.800\n",
            "Worker 8, [03/18]: Training Loss: 3.270294160, Training Accuracy: 19.456\n",
            "Worker 8, [04/18]: Training Loss: 3.159952813, Training Accuracy: 21.776\n",
            "Worker 8, [05/18]: Training Loss: 3.071497822, Training Accuracy: 22.912\n",
            "Worker 8, [06/18]: Training Loss: 2.975276996, Training Accuracy: 24.416\n",
            "Worker 8, [07/18]: Training Loss: 2.895182490, Training Accuracy: 26.272\n",
            "Worker 8, [08/18]: Training Loss: 2.773575265, Training Accuracy: 28.512\n",
            "Worker 8, [09/18]: Training Loss: 3.558742791, Training Accuracy: 15.664\n",
            "Worker 8, [10/18]: Training Loss: 3.269200994, Training Accuracy: 18.992\n",
            "Worker 8, [11/18]: Training Loss: 3.143626223, Training Accuracy: 22.688\n",
            "Worker 8, [12/18]: Training Loss: 3.013594058, Training Accuracy: 25.040\n",
            "Worker 8, [13/18]: Training Loss: 2.923490018, Training Accuracy: 25.744\n",
            "Worker 8, [14/18]: Training Loss: 2.833444111, Training Accuracy: 27.440\n",
            "Worker 8, [15/18]: Training Loss: 2.750291871, Training Accuracy: 29.808\n",
            "Worker 8, [16/18]: Training Loss: 2.676782919, Training Accuracy: 31.792\n",
            "Worker 8, [17/18]: Training Loss: 3.732451680, Training Accuracy: 21.168\n",
            "Worker 8, [18/18]: Training Loss: 3.506913015, Training Accuracy: 20.160\n",
            "Time taken for training worker 8: 0:00:48.082186\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000747\n",
            "Local Step 05: Test Loss: 3.539628178, Test Accuracy: 19.360\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.622724881, Training Accuracy: 17.808\n",
            "Worker 1, [02/18]: Training Loss: 3.599940877, Training Accuracy: 18.400\n",
            "Worker 1, [03/18]: Training Loss: 3.521926870, Training Accuracy: 18.048\n",
            "Worker 1, [04/18]: Training Loss: 3.435761710, Training Accuracy: 19.280\n",
            "Worker 1, [05/18]: Training Loss: 3.381639301, Training Accuracy: 19.728\n",
            "Worker 1, [06/18]: Training Loss: 3.324712427, Training Accuracy: 20.464\n",
            "Worker 1, [07/18]: Training Loss: 3.287539090, Training Accuracy: 20.688\n",
            "Worker 1, [08/18]: Training Loss: 3.244553009, Training Accuracy: 21.536\n",
            "Worker 1, [09/18]: Training Loss: 3.517450111, Training Accuracy: 17.088\n",
            "Worker 1, [10/18]: Training Loss: 3.350501039, Training Accuracy: 19.040\n",
            "Worker 1, [11/18]: Training Loss: 3.244247159, Training Accuracy: 20.608\n",
            "Worker 1, [12/18]: Training Loss: 3.174243175, Training Accuracy: 22.224\n",
            "Worker 1, [13/18]: Training Loss: 3.118319682, Training Accuracy: 22.880\n",
            "Worker 1, [14/18]: Training Loss: 3.068318591, Training Accuracy: 23.920\n",
            "Worker 1, [15/18]: Training Loss: 3.039598874, Training Accuracy: 24.752\n",
            "Worker 1, [16/18]: Training Loss: 2.937363834, Training Accuracy: 25.600\n",
            "Worker 1, [17/18]: Training Loss: 3.513895891, Training Accuracy: 16.768\n",
            "Worker 1, [18/18]: Training Loss: 3.319392190, Training Accuracy: 18.960\n",
            "Time taken for training worker 1: 0:00:48.693038\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.433019402, Training Accuracy: 17.824\n",
            "Worker 2, [02/18]: Training Loss: 3.400446600, Training Accuracy: 18.656\n",
            "Worker 2, [03/18]: Training Loss: 3.290557431, Training Accuracy: 20.544\n",
            "Worker 2, [04/18]: Training Loss: 3.192011653, Training Accuracy: 22.768\n",
            "Worker 2, [05/18]: Training Loss: 3.132935045, Training Accuracy: 23.136\n",
            "Worker 2, [06/18]: Training Loss: 3.063727693, Training Accuracy: 24.672\n",
            "Worker 2, [07/18]: Training Loss: 3.033132847, Training Accuracy: 24.096\n",
            "Worker 2, [08/18]: Training Loss: 2.999281309, Training Accuracy: 25.168\n",
            "Worker 2, [09/18]: Training Loss: 3.393495443, Training Accuracy: 18.576\n",
            "Worker 2, [10/18]: Training Loss: 3.188328765, Training Accuracy: 21.808\n",
            "Worker 2, [11/18]: Training Loss: 3.140967235, Training Accuracy: 21.424\n",
            "Worker 2, [12/18]: Training Loss: 3.057748622, Training Accuracy: 24.048\n",
            "Worker 2, [13/18]: Training Loss: 3.010218868, Training Accuracy: 23.728\n",
            "Worker 2, [14/18]: Training Loss: 2.975452180, Training Accuracy: 25.120\n",
            "Worker 2, [15/18]: Training Loss: 2.892777187, Training Accuracy: 26.432\n",
            "Worker 2, [16/18]: Training Loss: 2.840971665, Training Accuracy: 27.232\n",
            "Worker 2, [17/18]: Training Loss: 3.399889722, Training Accuracy: 17.808\n",
            "Worker 2, [18/18]: Training Loss: 3.178403662, Training Accuracy: 21.216\n",
            "Time taken for training worker 2: 0:00:47.827813\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.388512458, Training Accuracy: 19.120\n",
            "Worker 3, [02/18]: Training Loss: 3.311967655, Training Accuracy: 20.784\n",
            "Worker 3, [03/18]: Training Loss: 3.228324321, Training Accuracy: 22.384\n",
            "Worker 3, [04/18]: Training Loss: 3.153262034, Training Accuracy: 23.360\n",
            "Worker 3, [05/18]: Training Loss: 3.096969244, Training Accuracy: 24.752\n",
            "Worker 3, [06/18]: Training Loss: 3.049744358, Training Accuracy: 25.712\n",
            "Worker 3, [07/18]: Training Loss: 3.005092891, Training Accuracy: 25.664\n",
            "Worker 3, [08/18]: Training Loss: 2.986896082, Training Accuracy: 26.496\n",
            "Worker 3, [09/18]: Training Loss: 3.381787127, Training Accuracy: 19.920\n",
            "Worker 3, [10/18]: Training Loss: 3.200948216, Training Accuracy: 21.200\n",
            "Worker 3, [11/18]: Training Loss: 3.149180948, Training Accuracy: 22.752\n",
            "Worker 3, [12/18]: Training Loss: 3.076386277, Training Accuracy: 23.504\n",
            "Worker 3, [13/18]: Training Loss: 3.028200945, Training Accuracy: 24.160\n",
            "Worker 3, [14/18]: Training Loss: 2.976876843, Training Accuracy: 24.928\n",
            "Worker 3, [15/18]: Training Loss: 2.941808618, Training Accuracy: 25.472\n",
            "Worker 3, [16/18]: Training Loss: 2.875247286, Training Accuracy: 26.656\n",
            "Worker 3, [17/18]: Training Loss: 3.388727001, Training Accuracy: 19.136\n",
            "Worker 3, [18/18]: Training Loss: 3.221467317, Training Accuracy: 20.752\n",
            "Time taken for training worker 3: 0:00:49.325162\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.461670807, Training Accuracy: 17.376\n",
            "Worker 4, [02/18]: Training Loss: 3.338909351, Training Accuracy: 19.392\n",
            "Worker 4, [03/18]: Training Loss: 3.232131744, Training Accuracy: 21.808\n",
            "Worker 4, [04/18]: Training Loss: 3.163950813, Training Accuracy: 22.960\n",
            "Worker 4, [05/18]: Training Loss: 3.107281047, Training Accuracy: 23.792\n",
            "Worker 4, [06/18]: Training Loss: 3.057065825, Training Accuracy: 24.848\n",
            "Worker 4, [07/18]: Training Loss: 3.015024134, Training Accuracy: 25.088\n",
            "Worker 4, [08/18]: Training Loss: 2.973008336, Training Accuracy: 26.560\n",
            "Worker 4, [09/18]: Training Loss: 3.393956822, Training Accuracy: 19.488\n",
            "Worker 4, [10/18]: Training Loss: 3.182255898, Training Accuracy: 21.616\n",
            "Worker 4, [11/18]: Training Loss: 3.101016249, Training Accuracy: 23.056\n",
            "Worker 4, [12/18]: Training Loss: 3.099737138, Training Accuracy: 22.976\n",
            "Worker 4, [13/18]: Training Loss: 3.050190130, Training Accuracy: 23.808\n",
            "Worker 4, [14/18]: Training Loss: 2.986623273, Training Accuracy: 25.104\n",
            "Worker 4, [15/18]: Training Loss: 2.918489804, Training Accuracy: 26.432\n",
            "Worker 4, [16/18]: Training Loss: 2.856450465, Training Accuracy: 27.008\n",
            "Worker 4, [17/18]: Training Loss: 3.395432886, Training Accuracy: 18.656\n",
            "Worker 4, [18/18]: Training Loss: 3.186735688, Training Accuracy: 22.320\n",
            "Time taken for training worker 4: 0:00:47.506375\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.459990818, Training Accuracy: 18.000\n",
            "Worker 5, [02/18]: Training Loss: 3.339151098, Training Accuracy: 19.472\n",
            "Worker 5, [03/18]: Training Loss: 3.239813992, Training Accuracy: 21.648\n",
            "Worker 5, [04/18]: Training Loss: 3.166872852, Training Accuracy: 23.136\n",
            "Worker 5, [05/18]: Training Loss: 3.098936541, Training Accuracy: 24.256\n",
            "Worker 5, [06/18]: Training Loss: 3.047715722, Training Accuracy: 24.304\n",
            "Worker 5, [07/18]: Training Loss: 3.027100527, Training Accuracy: 25.008\n",
            "Worker 5, [08/18]: Training Loss: 2.984548496, Training Accuracy: 25.952\n",
            "Worker 5, [09/18]: Training Loss: 3.396840232, Training Accuracy: 19.648\n",
            "Worker 5, [10/18]: Training Loss: 3.204383371, Training Accuracy: 21.856\n",
            "Worker 5, [11/18]: Training Loss: 3.143593674, Training Accuracy: 22.256\n",
            "Worker 5, [12/18]: Training Loss: 3.073283826, Training Accuracy: 23.104\n",
            "Worker 5, [13/18]: Training Loss: 3.021036530, Training Accuracy: 24.736\n",
            "Worker 5, [14/18]: Training Loss: 2.990779169, Training Accuracy: 25.008\n",
            "Worker 5, [15/18]: Training Loss: 2.937249330, Training Accuracy: 25.856\n",
            "Worker 5, [16/18]: Training Loss: 2.846495159, Training Accuracy: 27.392\n",
            "Worker 5, [17/18]: Training Loss: 3.415309359, Training Accuracy: 18.400\n",
            "Worker 5, [18/18]: Training Loss: 3.209978520, Training Accuracy: 20.592\n",
            "Time taken for training worker 5: 0:00:47.642876\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.434327014, Training Accuracy: 17.872\n",
            "Worker 6, [02/18]: Training Loss: 3.366410959, Training Accuracy: 19.648\n",
            "Worker 6, [03/18]: Training Loss: 3.242229617, Training Accuracy: 22.000\n",
            "Worker 6, [04/18]: Training Loss: 3.148200205, Training Accuracy: 23.520\n",
            "Worker 6, [05/18]: Training Loss: 3.099111825, Training Accuracy: 24.784\n",
            "Worker 6, [06/18]: Training Loss: 3.043673291, Training Accuracy: 24.688\n",
            "Worker 6, [07/18]: Training Loss: 3.003013677, Training Accuracy: 25.344\n",
            "Worker 6, [08/18]: Training Loss: 2.992455602, Training Accuracy: 25.200\n",
            "Worker 6, [09/18]: Training Loss: 3.394848972, Training Accuracy: 19.344\n",
            "Worker 6, [10/18]: Training Loss: 3.205491492, Training Accuracy: 21.040\n",
            "Worker 6, [11/18]: Training Loss: 3.135909010, Training Accuracy: 22.704\n",
            "Worker 6, [12/18]: Training Loss: 3.103741682, Training Accuracy: 22.640\n",
            "Worker 6, [13/18]: Training Loss: 3.017105879, Training Accuracy: 24.272\n",
            "Worker 6, [14/18]: Training Loss: 2.981816937, Training Accuracy: 24.656\n",
            "Worker 6, [15/18]: Training Loss: 2.925813405, Training Accuracy: 26.144\n",
            "Worker 6, [16/18]: Training Loss: 2.871613364, Training Accuracy: 26.848\n",
            "Worker 6, [17/18]: Training Loss: 3.391193198, Training Accuracy: 18.688\n",
            "Worker 6, [18/18]: Training Loss: 3.216999837, Training Accuracy: 20.752\n",
            "Time taken for training worker 6: 0:00:47.803769\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.365874697, Training Accuracy: 18.288\n",
            "Worker 7, [02/18]: Training Loss: 3.308535238, Training Accuracy: 20.112\n",
            "Worker 7, [03/18]: Training Loss: 3.240896235, Training Accuracy: 20.768\n",
            "Worker 7, [04/18]: Training Loss: 3.156292412, Training Accuracy: 22.512\n",
            "Worker 7, [05/18]: Training Loss: 3.096012432, Training Accuracy: 23.648\n",
            "Worker 7, [06/18]: Training Loss: 3.057191807, Training Accuracy: 24.480\n",
            "Worker 7, [07/18]: Training Loss: 3.006170239, Training Accuracy: 24.592\n",
            "Worker 7, [08/18]: Training Loss: 2.979941604, Training Accuracy: 25.632\n",
            "Worker 7, [09/18]: Training Loss: 3.407084429, Training Accuracy: 19.584\n",
            "Worker 7, [10/18]: Training Loss: 3.232079294, Training Accuracy: 20.912\n",
            "Worker 7, [11/18]: Training Loss: 3.118169461, Training Accuracy: 22.368\n",
            "Worker 7, [12/18]: Training Loss: 3.099249616, Training Accuracy: 23.216\n",
            "Worker 7, [13/18]: Training Loss: 3.057202485, Training Accuracy: 23.168\n",
            "Worker 7, [14/18]: Training Loss: 2.972577012, Training Accuracy: 24.880\n",
            "Worker 7, [15/18]: Training Loss: 2.918172904, Training Accuracy: 25.952\n",
            "Worker 7, [16/18]: Training Loss: 2.892742787, Training Accuracy: 26.368\n",
            "Worker 7, [17/18]: Training Loss: 3.404470351, Training Accuracy: 18.512\n",
            "Worker 7, [18/18]: Training Loss: 3.223604857, Training Accuracy: 20.976\n",
            "Time taken for training worker 7: 0:00:47.712980\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.383686289, Training Accuracy: 18.672\n",
            "Worker 8, [02/18]: Training Loss: 3.326216092, Training Accuracy: 19.424\n",
            "Worker 8, [03/18]: Training Loss: 3.219099368, Training Accuracy: 21.136\n",
            "Worker 8, [04/18]: Training Loss: 3.168355370, Training Accuracy: 22.528\n",
            "Worker 8, [05/18]: Training Loss: 3.107205744, Training Accuracy: 23.984\n",
            "Worker 8, [06/18]: Training Loss: 3.078503925, Training Accuracy: 24.432\n",
            "Worker 8, [07/18]: Training Loss: 3.031458227, Training Accuracy: 24.576\n",
            "Worker 8, [08/18]: Training Loss: 2.987938149, Training Accuracy: 25.616\n",
            "Worker 8, [09/18]: Training Loss: 3.382695638, Training Accuracy: 19.008\n",
            "Worker 8, [10/18]: Training Loss: 3.208424663, Training Accuracy: 21.184\n",
            "Worker 8, [11/18]: Training Loss: 3.153465658, Training Accuracy: 21.184\n",
            "Worker 8, [12/18]: Training Loss: 3.080922222, Training Accuracy: 23.312\n",
            "Worker 8, [13/18]: Training Loss: 3.040007085, Training Accuracy: 22.896\n",
            "Worker 8, [14/18]: Training Loss: 2.971819885, Training Accuracy: 25.584\n",
            "Worker 8, [15/18]: Training Loss: 2.947517118, Training Accuracy: 25.344\n",
            "Worker 8, [16/18]: Training Loss: 2.847426500, Training Accuracy: 27.216\n",
            "Worker 8, [17/18]: Training Loss: 3.381917258, Training Accuracy: 17.856\n",
            "Worker 8, [18/18]: Training Loss: 3.246634264, Training Accuracy: 19.856\n",
            "Time taken for training worker 8: 0:00:49.576909\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000685\n",
            "Local Step 06: Test Loss: 3.216707227, Test Accuracy: 21.520\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.391498179, Training Accuracy: 18.816\n",
            "Worker 1, [02/18]: Training Loss: 3.198110875, Training Accuracy: 21.408\n",
            "Worker 1, [03/18]: Training Loss: 3.096122357, Training Accuracy: 23.520\n",
            "Worker 1, [04/18]: Training Loss: 2.964930936, Training Accuracy: 25.552\n",
            "Worker 1, [05/18]: Training Loss: 2.887580181, Training Accuracy: 27.232\n",
            "Worker 1, [06/18]: Training Loss: 2.772930819, Training Accuracy: 29.120\n",
            "Worker 1, [07/18]: Training Loss: 2.674921739, Training Accuracy: 30.752\n",
            "Worker 1, [08/18]: Training Loss: 2.572446461, Training Accuracy: 33.504\n",
            "Worker 1, [09/18]: Training Loss: 3.359906720, Training Accuracy: 19.520\n",
            "Worker 1, [10/18]: Training Loss: 3.119738384, Training Accuracy: 23.184\n",
            "Worker 1, [11/18]: Training Loss: 2.978105844, Training Accuracy: 25.696\n",
            "Worker 1, [12/18]: Training Loss: 2.861810166, Training Accuracy: 27.440\n",
            "Worker 1, [13/18]: Training Loss: 2.748525931, Training Accuracy: 30.384\n",
            "Worker 1, [14/18]: Training Loss: 2.652050590, Training Accuracy: 31.712\n",
            "Worker 1, [15/18]: Training Loss: 2.563626216, Training Accuracy: 34.416\n",
            "Worker 1, [16/18]: Training Loss: 2.499435858, Training Accuracy: 35.008\n",
            "Worker 1, [17/18]: Training Loss: 3.364797298, Training Accuracy: 25.568\n",
            "Worker 1, [18/18]: Training Loss: 3.171280824, Training Accuracy: 25.408\n",
            "Time taken for training worker 1: 0:00:48.695448\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.459713873, Training Accuracy: 16.688\n",
            "Worker 2, [02/18]: Training Loss: 3.258547189, Training Accuracy: 20.368\n",
            "Worker 2, [03/18]: Training Loss: 3.107911358, Training Accuracy: 22.832\n",
            "Worker 2, [04/18]: Training Loss: 3.017353537, Training Accuracy: 24.352\n",
            "Worker 2, [05/18]: Training Loss: 2.897342054, Training Accuracy: 26.656\n",
            "Worker 2, [06/18]: Training Loss: 2.802152113, Training Accuracy: 28.336\n",
            "Worker 2, [07/18]: Training Loss: 2.705424272, Training Accuracy: 29.968\n",
            "Worker 2, [08/18]: Training Loss: 2.589016278, Training Accuracy: 32.032\n",
            "Worker 2, [09/18]: Training Loss: 3.228962606, Training Accuracy: 21.024\n",
            "Worker 2, [10/18]: Training Loss: 3.003720476, Training Accuracy: 24.432\n",
            "Worker 2, [11/18]: Training Loss: 2.873872582, Training Accuracy: 26.096\n",
            "Worker 2, [12/18]: Training Loss: 2.732224932, Training Accuracy: 29.984\n",
            "Worker 2, [13/18]: Training Loss: 2.626316917, Training Accuracy: 31.664\n",
            "Worker 2, [14/18]: Training Loss: 2.536158986, Training Accuracy: 33.424\n",
            "Worker 2, [15/18]: Training Loss: 2.458456876, Training Accuracy: 35.104\n",
            "Worker 2, [16/18]: Training Loss: 2.405965857, Training Accuracy: 36.144\n",
            "Worker 2, [17/18]: Training Loss: 3.234112270, Training Accuracy: 27.072\n",
            "Worker 2, [18/18]: Training Loss: 3.028555919, Training Accuracy: 27.168\n",
            "Time taken for training worker 2: 0:00:48.982889\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.436878380, Training Accuracy: 18.000\n",
            "Worker 3, [02/18]: Training Loss: 3.261560017, Training Accuracy: 20.976\n",
            "Worker 3, [03/18]: Training Loss: 3.128887872, Training Accuracy: 23.424\n",
            "Worker 3, [04/18]: Training Loss: 3.027752949, Training Accuracy: 24.864\n",
            "Worker 3, [05/18]: Training Loss: 2.937613743, Training Accuracy: 26.064\n",
            "Worker 3, [06/18]: Training Loss: 2.818002268, Training Accuracy: 28.864\n",
            "Worker 3, [07/18]: Training Loss: 2.726816382, Training Accuracy: 30.112\n",
            "Worker 3, [08/18]: Training Loss: 2.592339812, Training Accuracy: 33.632\n",
            "Worker 3, [09/18]: Training Loss: 3.218550675, Training Accuracy: 22.096\n",
            "Worker 3, [10/18]: Training Loss: 3.001643942, Training Accuracy: 25.456\n",
            "Worker 3, [11/18]: Training Loss: 2.890981253, Training Accuracy: 27.152\n",
            "Worker 3, [12/18]: Training Loss: 2.769888722, Training Accuracy: 29.440\n",
            "Worker 3, [13/18]: Training Loss: 2.656992406, Training Accuracy: 31.984\n",
            "Worker 3, [14/18]: Training Loss: 2.564368769, Training Accuracy: 33.952\n",
            "Worker 3, [15/18]: Training Loss: 2.489402486, Training Accuracy: 35.280\n",
            "Worker 3, [16/18]: Training Loss: 2.416322713, Training Accuracy: 37.408\n",
            "Worker 3, [17/18]: Training Loss: 3.231139173, Training Accuracy: 28.816\n",
            "Worker 3, [18/18]: Training Loss: 3.025889192, Training Accuracy: 28.768\n",
            "Time taken for training worker 3: 0:00:48.932876\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.417851472, Training Accuracy: 18.464\n",
            "Worker 4, [02/18]: Training Loss: 3.242565610, Training Accuracy: 20.544\n",
            "Worker 4, [03/18]: Training Loss: 3.134842668, Training Accuracy: 23.152\n",
            "Worker 4, [04/18]: Training Loss: 3.007097913, Training Accuracy: 24.960\n",
            "Worker 4, [05/18]: Training Loss: 2.893709789, Training Accuracy: 26.960\n",
            "Worker 4, [06/18]: Training Loss: 2.781731703, Training Accuracy: 29.072\n",
            "Worker 4, [07/18]: Training Loss: 2.715697254, Training Accuracy: 29.568\n",
            "Worker 4, [08/18]: Training Loss: 2.560614980, Training Accuracy: 33.264\n",
            "Worker 4, [09/18]: Training Loss: 3.215162353, Training Accuracy: 22.032\n",
            "Worker 4, [10/18]: Training Loss: 2.998844903, Training Accuracy: 24.528\n",
            "Worker 4, [11/18]: Training Loss: 2.878545807, Training Accuracy: 27.008\n",
            "Worker 4, [12/18]: Training Loss: 2.744970436, Training Accuracy: 29.408\n",
            "Worker 4, [13/18]: Training Loss: 2.653170571, Training Accuracy: 31.552\n",
            "Worker 4, [14/18]: Training Loss: 2.541749996, Training Accuracy: 33.808\n",
            "Worker 4, [15/18]: Training Loss: 2.452042859, Training Accuracy: 36.304\n",
            "Worker 4, [16/18]: Training Loss: 2.377017621, Training Accuracy: 37.920\n",
            "Worker 4, [17/18]: Training Loss: 3.227414676, Training Accuracy: 28.544\n",
            "Worker 4, [18/18]: Training Loss: 3.018727434, Training Accuracy: 28.448\n",
            "Time taken for training worker 4: 0:00:49.120314\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.406976469, Training Accuracy: 18.240\n",
            "Worker 5, [02/18]: Training Loss: 3.241364739, Training Accuracy: 20.624\n",
            "Worker 5, [03/18]: Training Loss: 3.134869325, Training Accuracy: 22.544\n",
            "Worker 5, [04/18]: Training Loss: 3.025284431, Training Accuracy: 24.448\n",
            "Worker 5, [05/18]: Training Loss: 2.892942008, Training Accuracy: 26.848\n",
            "Worker 5, [06/18]: Training Loss: 2.792182762, Training Accuracy: 29.008\n",
            "Worker 5, [07/18]: Training Loss: 2.697757689, Training Accuracy: 30.768\n",
            "Worker 5, [08/18]: Training Loss: 2.578396746, Training Accuracy: 33.056\n",
            "Worker 5, [09/18]: Training Loss: 3.197579462, Training Accuracy: 22.912\n",
            "Worker 5, [10/18]: Training Loss: 2.998980916, Training Accuracy: 24.576\n",
            "Worker 5, [11/18]: Training Loss: 2.871933429, Training Accuracy: 26.928\n",
            "Worker 5, [12/18]: Training Loss: 2.749129366, Training Accuracy: 29.648\n",
            "Worker 5, [13/18]: Training Loss: 2.672078663, Training Accuracy: 30.672\n",
            "Worker 5, [14/18]: Training Loss: 2.544767660, Training Accuracy: 33.408\n",
            "Worker 5, [15/18]: Training Loss: 2.459806935, Training Accuracy: 36.048\n",
            "Worker 5, [16/18]: Training Loss: 2.389029708, Training Accuracy: 37.568\n",
            "Worker 5, [17/18]: Training Loss: 3.228094855, Training Accuracy: 28.128\n",
            "Worker 5, [18/18]: Training Loss: 3.011018296, Training Accuracy: 28.528\n",
            "Time taken for training worker 5: 0:00:48.506663\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.394941782, Training Accuracy: 17.920\n",
            "Worker 6, [02/18]: Training Loss: 3.218665955, Training Accuracy: 21.040\n",
            "Worker 6, [03/18]: Training Loss: 3.120281237, Training Accuracy: 23.936\n",
            "Worker 6, [04/18]: Training Loss: 3.012738461, Training Accuracy: 24.768\n",
            "Worker 6, [05/18]: Training Loss: 2.900126014, Training Accuracy: 27.104\n",
            "Worker 6, [06/18]: Training Loss: 2.804584425, Training Accuracy: 28.352\n",
            "Worker 6, [07/18]: Training Loss: 2.706228604, Training Accuracy: 31.008\n",
            "Worker 6, [08/18]: Training Loss: 2.581376141, Training Accuracy: 32.880\n",
            "Worker 6, [09/18]: Training Loss: 3.249532605, Training Accuracy: 21.712\n",
            "Worker 6, [10/18]: Training Loss: 3.000586176, Training Accuracy: 25.264\n",
            "Worker 6, [11/18]: Training Loss: 2.894448047, Training Accuracy: 26.112\n",
            "Worker 6, [12/18]: Training Loss: 2.760635692, Training Accuracy: 29.664\n",
            "Worker 6, [13/18]: Training Loss: 2.666095172, Training Accuracy: 31.184\n",
            "Worker 6, [14/18]: Training Loss: 2.560932510, Training Accuracy: 34.112\n",
            "Worker 6, [15/18]: Training Loss: 2.481726527, Training Accuracy: 35.664\n",
            "Worker 6, [16/18]: Training Loss: 2.415280320, Training Accuracy: 37.312\n",
            "Worker 6, [17/18]: Training Loss: 3.242074889, Training Accuracy: 27.696\n",
            "Worker 6, [18/18]: Training Loss: 3.033544864, Training Accuracy: 27.408\n",
            "Time taken for training worker 6: 0:00:46.322265\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.424841547, Training Accuracy: 17.520\n",
            "Worker 7, [02/18]: Training Loss: 3.244283477, Training Accuracy: 19.824\n",
            "Worker 7, [03/18]: Training Loss: 3.106279843, Training Accuracy: 22.688\n",
            "Worker 7, [04/18]: Training Loss: 3.033355107, Training Accuracy: 23.920\n",
            "Worker 7, [05/18]: Training Loss: 2.915178666, Training Accuracy: 26.000\n",
            "Worker 7, [06/18]: Training Loss: 2.789997437, Training Accuracy: 28.208\n",
            "Worker 7, [07/18]: Training Loss: 2.734494365, Training Accuracy: 29.392\n",
            "Worker 7, [08/18]: Training Loss: 2.599906226, Training Accuracy: 32.832\n",
            "Worker 7, [09/18]: Training Loss: 3.220478187, Training Accuracy: 22.064\n",
            "Worker 7, [10/18]: Training Loss: 3.023470798, Training Accuracy: 24.160\n",
            "Worker 7, [11/18]: Training Loss: 2.881707559, Training Accuracy: 26.992\n",
            "Worker 7, [12/18]: Training Loss: 2.792521757, Training Accuracy: 28.752\n",
            "Worker 7, [13/18]: Training Loss: 2.666139702, Training Accuracy: 30.848\n",
            "Worker 7, [14/18]: Training Loss: 2.585041270, Training Accuracy: 33.536\n",
            "Worker 7, [15/18]: Training Loss: 2.488824837, Training Accuracy: 34.704\n",
            "Worker 7, [16/18]: Training Loss: 2.430900588, Training Accuracy: 36.496\n",
            "Worker 7, [17/18]: Training Loss: 3.247182428, Training Accuracy: 27.376\n",
            "Worker 7, [18/18]: Training Loss: 3.050241125, Training Accuracy: 27.632\n",
            "Time taken for training worker 7: 0:00:47.893430\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.434708401, Training Accuracy: 17.728\n",
            "Worker 8, [02/18]: Training Loss: 3.255901575, Training Accuracy: 20.416\n",
            "Worker 8, [03/18]: Training Loss: 3.129930173, Training Accuracy: 22.240\n",
            "Worker 8, [04/18]: Training Loss: 3.008302742, Training Accuracy: 24.208\n",
            "Worker 8, [05/18]: Training Loss: 2.939620772, Training Accuracy: 25.728\n",
            "Worker 8, [06/18]: Training Loss: 2.808971162, Training Accuracy: 28.560\n",
            "Worker 8, [07/18]: Training Loss: 2.712510428, Training Accuracy: 30.368\n",
            "Worker 8, [08/18]: Training Loss: 2.616668627, Training Accuracy: 31.824\n",
            "Worker 8, [09/18]: Training Loss: 3.225720299, Training Accuracy: 21.008\n",
            "Worker 8, [10/18]: Training Loss: 3.012496192, Training Accuracy: 23.936\n",
            "Worker 8, [11/18]: Training Loss: 2.877773920, Training Accuracy: 26.608\n",
            "Worker 8, [12/18]: Training Loss: 2.775334448, Training Accuracy: 29.744\n",
            "Worker 8, [13/18]: Training Loss: 2.666720707, Training Accuracy: 31.008\n",
            "Worker 8, [14/18]: Training Loss: 2.569230254, Training Accuracy: 33.744\n",
            "Worker 8, [15/18]: Training Loss: 2.488810163, Training Accuracy: 34.592\n",
            "Worker 8, [16/18]: Training Loss: 2.411835414, Training Accuracy: 37.216\n",
            "Worker 8, [17/18]: Training Loss: 3.240940646, Training Accuracy: 28.048\n",
            "Worker 8, [18/18]: Training Loss: 3.041272939, Training Accuracy: 27.392\n",
            "Time taken for training worker 8: 0:00:47.155163\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000696\n",
            "Local Step 07: Test Loss: 3.162070804, Test Accuracy: 25.050\n",
            "**************************************************\n",
            "Worker 1, [01/18]: Training Loss: 3.272469647, Training Accuracy: 22.176\n",
            "Worker 1, [02/18]: Training Loss: 3.268377061, Training Accuracy: 22.000\n",
            "Worker 1, [03/18]: Training Loss: 3.227301252, Training Accuracy: 23.120\n",
            "Worker 1, [04/18]: Training Loss: 3.185748915, Training Accuracy: 23.760\n",
            "Worker 1, [05/18]: Training Loss: 3.140746562, Training Accuracy: 23.952\n",
            "Worker 1, [06/18]: Training Loss: 3.101203914, Training Accuracy: 24.032\n",
            "Worker 1, [07/18]: Training Loss: 3.087204724, Training Accuracy: 24.192\n",
            "Worker 1, [08/18]: Training Loss: 3.054905884, Training Accuracy: 24.096\n",
            "Worker 1, [09/18]: Training Loss: 3.202498526, Training Accuracy: 22.608\n",
            "Worker 1, [10/18]: Training Loss: 3.071977754, Training Accuracy: 23.136\n",
            "Worker 1, [11/18]: Training Loss: 3.028267641, Training Accuracy: 24.240\n",
            "Worker 1, [12/18]: Training Loss: 2.952648039, Training Accuracy: 25.312\n",
            "Worker 1, [13/18]: Training Loss: 2.929455509, Training Accuracy: 25.520\n",
            "Worker 1, [14/18]: Training Loss: 2.856647022, Training Accuracy: 27.296\n",
            "Worker 1, [15/18]: Training Loss: 2.810973146, Training Accuracy: 28.176\n",
            "Worker 1, [16/18]: Training Loss: 2.740110680, Training Accuracy: 29.936\n",
            "Worker 1, [17/18]: Training Loss: 3.255504730, Training Accuracy: 20.432\n",
            "Worker 1, [18/18]: Training Loss: 3.091842004, Training Accuracy: 23.504\n",
            "Time taken for training worker 1: 0:00:48.207205\n",
            "--------------------------------------------------\n",
            "Worker 2, [01/18]: Training Loss: 3.292475992, Training Accuracy: 19.968\n",
            "Worker 2, [02/18]: Training Loss: 3.239075629, Training Accuracy: 21.072\n",
            "Worker 2, [03/18]: Training Loss: 3.125978825, Training Accuracy: 22.816\n",
            "Worker 2, [04/18]: Training Loss: 3.037730268, Training Accuracy: 25.120\n",
            "Worker 2, [05/18]: Training Loss: 2.973394681, Training Accuracy: 26.608\n",
            "Worker 2, [06/18]: Training Loss: 2.925396905, Training Accuracy: 26.640\n",
            "Worker 2, [07/18]: Training Loss: 2.881476115, Training Accuracy: 27.408\n",
            "Worker 2, [08/18]: Training Loss: 2.851379292, Training Accuracy: 28.448\n",
            "Worker 2, [09/18]: Training Loss: 3.067585755, Training Accuracy: 24.160\n",
            "Worker 2, [10/18]: Training Loss: 2.951009016, Training Accuracy: 25.184\n",
            "Worker 2, [11/18]: Training Loss: 2.879136701, Training Accuracy: 26.576\n",
            "Worker 2, [12/18]: Training Loss: 2.862820805, Training Accuracy: 26.944\n",
            "Worker 2, [13/18]: Training Loss: 2.837866941, Training Accuracy: 27.808\n",
            "Worker 2, [14/18]: Training Loss: 2.753269578, Training Accuracy: 28.160\n",
            "Worker 2, [15/18]: Training Loss: 2.729763012, Training Accuracy: 29.424\n",
            "Worker 2, [16/18]: Training Loss: 2.633297721, Training Accuracy: 31.472\n",
            "Worker 2, [17/18]: Training Loss: 3.135222627, Training Accuracy: 22.384\n",
            "Worker 2, [18/18]: Training Loss: 2.992482426, Training Accuracy: 24.432\n",
            "Time taken for training worker 2: 0:00:47.130127\n",
            "--------------------------------------------------\n",
            "Worker 3, [01/18]: Training Loss: 3.363195950, Training Accuracy: 19.840\n",
            "Worker 3, [02/18]: Training Loss: 3.273155439, Training Accuracy: 21.104\n",
            "Worker 3, [03/18]: Training Loss: 3.135376492, Training Accuracy: 24.096\n",
            "Worker 3, [04/18]: Training Loss: 3.062323526, Training Accuracy: 25.296\n",
            "Worker 3, [05/18]: Training Loss: 2.992845457, Training Accuracy: 26.624\n",
            "Worker 3, [06/18]: Training Loss: 2.934231860, Training Accuracy: 27.552\n",
            "Worker 3, [07/18]: Training Loss: 2.894627834, Training Accuracy: 28.240\n",
            "Worker 3, [08/18]: Training Loss: 2.846884474, Training Accuracy: 28.960\n",
            "Worker 3, [09/18]: Training Loss: 3.074755691, Training Accuracy: 24.944\n",
            "Worker 3, [10/18]: Training Loss: 2.949599395, Training Accuracy: 25.968\n",
            "Worker 3, [11/18]: Training Loss: 2.904283146, Training Accuracy: 26.032\n",
            "Worker 3, [12/18]: Training Loss: 2.863788782, Training Accuracy: 27.936\n",
            "Worker 3, [13/18]: Training Loss: 2.835216856, Training Accuracy: 28.656\n",
            "Worker 3, [14/18]: Training Loss: 2.778020095, Training Accuracy: 28.752\n",
            "Worker 3, [15/18]: Training Loss: 2.737985346, Training Accuracy: 28.896\n",
            "Worker 3, [16/18]: Training Loss: 2.695407780, Training Accuracy: 30.336\n",
            "Worker 3, [17/18]: Training Loss: 3.161429748, Training Accuracy: 22.544\n",
            "Worker 3, [18/18]: Training Loss: 3.024299415, Training Accuracy: 24.592\n",
            "Time taken for training worker 3: 0:00:48.151663\n",
            "--------------------------------------------------\n",
            "Worker 4, [01/18]: Training Loss: 3.317235156, Training Accuracy: 20.016\n",
            "Worker 4, [02/18]: Training Loss: 3.263408242, Training Accuracy: 20.336\n",
            "Worker 4, [03/18]: Training Loss: 3.137197852, Training Accuracy: 23.600\n",
            "Worker 4, [04/18]: Training Loss: 3.068467410, Training Accuracy: 24.656\n",
            "Worker 4, [05/18]: Training Loss: 2.970576933, Training Accuracy: 26.672\n",
            "Worker 4, [06/18]: Training Loss: 2.916173906, Training Accuracy: 27.808\n",
            "Worker 4, [07/18]: Training Loss: 2.890680316, Training Accuracy: 27.584\n",
            "Worker 4, [08/18]: Training Loss: 2.840585142, Training Accuracy: 29.056\n",
            "Worker 4, [09/18]: Training Loss: 3.046795920, Training Accuracy: 24.576\n",
            "Worker 4, [10/18]: Training Loss: 2.944658452, Training Accuracy: 25.920\n",
            "Worker 4, [11/18]: Training Loss: 2.906511008, Training Accuracy: 26.416\n",
            "Worker 4, [12/18]: Training Loss: 2.875036602, Training Accuracy: 27.008\n",
            "Worker 4, [13/18]: Training Loss: 2.824344859, Training Accuracy: 27.392\n",
            "Worker 4, [14/18]: Training Loss: 2.794872201, Training Accuracy: 28.784\n",
            "Worker 4, [15/18]: Training Loss: 2.716410948, Training Accuracy: 30.144\n",
            "Worker 4, [16/18]: Training Loss: 2.684950678, Training Accuracy: 30.352\n",
            "Worker 4, [17/18]: Training Loss: 3.125946103, Training Accuracy: 22.576\n",
            "Worker 4, [18/18]: Training Loss: 3.051436234, Training Accuracy: 23.344\n",
            "Time taken for training worker 4: 0:00:48.327803\n",
            "--------------------------------------------------\n",
            "Worker 5, [01/18]: Training Loss: 3.300916815, Training Accuracy: 19.920\n",
            "Worker 5, [02/18]: Training Loss: 3.223675572, Training Accuracy: 21.696\n",
            "Worker 5, [03/18]: Training Loss: 3.138222872, Training Accuracy: 23.472\n",
            "Worker 5, [04/18]: Training Loss: 3.036275158, Training Accuracy: 25.680\n",
            "Worker 5, [05/18]: Training Loss: 2.979216685, Training Accuracy: 26.608\n",
            "Worker 5, [06/18]: Training Loss: 2.918930399, Training Accuracy: 27.936\n",
            "Worker 5, [07/18]: Training Loss: 2.869567385, Training Accuracy: 28.272\n",
            "Worker 5, [08/18]: Training Loss: 2.821264773, Training Accuracy: 29.344\n",
            "Worker 5, [09/18]: Training Loss: 3.056935495, Training Accuracy: 24.640\n",
            "Worker 5, [10/18]: Training Loss: 2.953138052, Training Accuracy: 25.376\n",
            "Worker 5, [11/18]: Training Loss: 2.905845769, Training Accuracy: 26.384\n",
            "Worker 5, [12/18]: Training Loss: 2.846292963, Training Accuracy: 28.096\n",
            "Worker 5, [13/18]: Training Loss: 2.828477237, Training Accuracy: 27.472\n",
            "Worker 5, [14/18]: Training Loss: 2.752321761, Training Accuracy: 29.456\n",
            "Worker 5, [15/18]: Training Loss: 2.745165543, Training Accuracy: 29.232\n",
            "Worker 5, [16/18]: Training Loss: 2.666244555, Training Accuracy: 31.184\n",
            "Worker 5, [17/18]: Training Loss: 3.163255998, Training Accuracy: 22.160\n",
            "Worker 5, [18/18]: Training Loss: 2.991402862, Training Accuracy: 25.296\n",
            "Time taken for training worker 5: 0:00:47.308834\n",
            "--------------------------------------------------\n",
            "Worker 6, [01/18]: Training Loss: 3.276287220, Training Accuracy: 20.928\n",
            "Worker 6, [02/18]: Training Loss: 3.216156835, Training Accuracy: 22.864\n",
            "Worker 6, [03/18]: Training Loss: 3.130245289, Training Accuracy: 23.664\n",
            "Worker 6, [04/18]: Training Loss: 3.040849175, Training Accuracy: 26.000\n",
            "Worker 6, [05/18]: Training Loss: 2.972214835, Training Accuracy: 27.152\n",
            "Worker 6, [06/18]: Training Loss: 2.922392086, Training Accuracy: 28.144\n",
            "Worker 6, [07/18]: Training Loss: 2.864815727, Training Accuracy: 28.672\n",
            "Worker 6, [08/18]: Training Loss: 2.836319819, Training Accuracy: 28.752\n",
            "Worker 6, [09/18]: Training Loss: 3.066020961, Training Accuracy: 24.784\n",
            "Worker 6, [10/18]: Training Loss: 2.951957613, Training Accuracy: 25.744\n",
            "Worker 6, [11/18]: Training Loss: 2.916539771, Training Accuracy: 26.224\n",
            "Worker 6, [12/18]: Training Loss: 2.849860819, Training Accuracy: 27.648\n",
            "Worker 6, [13/18]: Training Loss: 2.826569674, Training Accuracy: 28.064\n",
            "Worker 6, [14/18]: Training Loss: 2.787172819, Training Accuracy: 28.480\n",
            "Worker 6, [15/18]: Training Loss: 2.733825061, Training Accuracy: 29.536\n",
            "Worker 6, [16/18]: Training Loss: 2.676557130, Training Accuracy: 30.944\n",
            "Worker 6, [17/18]: Training Loss: 3.159116431, Training Accuracy: 22.032\n",
            "Worker 6, [18/18]: Training Loss: 3.022369078, Training Accuracy: 24.304\n",
            "Time taken for training worker 6: 0:00:47.561979\n",
            "--------------------------------------------------\n",
            "Worker 7, [01/18]: Training Loss: 3.312853623, Training Accuracy: 19.712\n",
            "Worker 7, [02/18]: Training Loss: 3.225069815, Training Accuracy: 21.392\n",
            "Worker 7, [03/18]: Training Loss: 3.127327795, Training Accuracy: 23.280\n",
            "Worker 7, [04/18]: Training Loss: 3.032354406, Training Accuracy: 25.360\n",
            "Worker 7, [05/18]: Training Loss: 2.964066143, Training Accuracy: 26.192\n",
            "Worker 7, [06/18]: Training Loss: 2.908827482, Training Accuracy: 26.464\n",
            "Worker 7, [07/18]: Training Loss: 2.872758530, Training Accuracy: 27.872\n",
            "Worker 7, [08/18]: Training Loss: 2.843906911, Training Accuracy: 28.272\n",
            "Worker 7, [09/18]: Training Loss: 3.070567126, Training Accuracy: 24.240\n",
            "Worker 7, [10/18]: Training Loss: 2.978894071, Training Accuracy: 24.320\n",
            "Worker 7, [11/18]: Training Loss: 2.937246860, Training Accuracy: 25.568\n",
            "Worker 7, [12/18]: Training Loss: 2.878819826, Training Accuracy: 26.080\n",
            "Worker 7, [13/18]: Training Loss: 2.843544490, Training Accuracy: 27.376\n",
            "Worker 7, [14/18]: Training Loss: 2.786735710, Training Accuracy: 27.632\n",
            "Worker 7, [15/18]: Training Loss: 2.754092907, Training Accuracy: 29.072\n",
            "Worker 7, [16/18]: Training Loss: 2.723796414, Training Accuracy: 29.648\n",
            "Worker 7, [17/18]: Training Loss: 3.160190962, Training Accuracy: 22.288\n",
            "Worker 7, [18/18]: Training Loss: 3.038457501, Training Accuracy: 23.136\n",
            "Time taken for training worker 7: 0:00:48.439984\n",
            "--------------------------------------------------\n",
            "Worker 8, [01/18]: Training Loss: 3.300235306, Training Accuracy: 19.952\n",
            "Worker 8, [02/18]: Training Loss: 3.235011247, Training Accuracy: 21.008\n",
            "Worker 8, [03/18]: Training Loss: 3.133619810, Training Accuracy: 23.152\n",
            "Worker 8, [04/18]: Training Loss: 3.045085158, Training Accuracy: 24.560\n",
            "Worker 8, [05/18]: Training Loss: 2.984238437, Training Accuracy: 26.432\n",
            "Worker 8, [06/18]: Training Loss: 2.940244222, Training Accuracy: 26.944\n",
            "Worker 8, [07/18]: Training Loss: 2.879509043, Training Accuracy: 28.016\n",
            "Worker 8, [08/18]: Training Loss: 2.844664048, Training Accuracy: 27.760\n",
            "Worker 8, [09/18]: Training Loss: 3.041767354, Training Accuracy: 24.480\n",
            "Worker 8, [10/18]: Training Loss: 2.966690063, Training Accuracy: 24.832\n",
            "Worker 8, [11/18]: Training Loss: 2.938878076, Training Accuracy: 25.712\n",
            "Worker 8, [12/18]: Training Loss: 2.894238501, Training Accuracy: 26.448\n",
            "Worker 8, [13/18]: Training Loss: 2.824465958, Training Accuracy: 27.200\n",
            "Worker 8, [14/18]: Training Loss: 2.797176332, Training Accuracy: 27.632\n",
            "Worker 8, [15/18]: Training Loss: 2.770426278, Training Accuracy: 28.448\n",
            "Worker 8, [16/18]: Training Loss: 2.687287151, Training Accuracy: 30.240\n",
            "Worker 8, [17/18]: Training Loss: 3.160884290, Training Accuracy: 21.872\n",
            "Worker 8, [18/18]: Training Loss: 3.024654933, Training Accuracy: 23.408\n",
            "Time taken for training worker 8: 0:00:48.228277\n",
            "--------------------------------------------------\n",
            "**************************************************\n",
            "Time taken for synchronization: 0:00:00.000792\n",
            "Local Step 08: Test Loss: 3.110572795, Test Accuracy: 24.500\n",
            "**************************************************\n",
            "//////////////////////////////////////////////////\n",
            "Total time taken for local_SGD: 0:51:32.612608\n",
            "//////////////////////////////////////////////////\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "beta = 0.9\n",
        "parameters = {'lr': lr, 'wd': wd, 'beta': beta}\n",
        "K = [2, 4, 8]\n",
        "J = [4, 8]\n",
        "T = [2, 4, 8]\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize slow model\n",
        "slow_model = LeNet5()\n",
        "slow_model.load_state_dict(initial_state_dict)\n",
        "\n",
        "for k in K:\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    for t in T:\n",
        "      print('='*50)\n",
        "      print(f'Number of Workers:{k}, Number of Local Steps:{j}, Update Slow Model every {t} steps')\n",
        "      print('='*50)\n",
        "      local_SGD_SLOWMO(shard_loaders, loss_fn, parameters, k, j, t, initial_state_dict, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Personal Contribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# print(os.environ.get('CUDA_VISIBLE_DEVICES'))\n",
        "# import torch\n",
        "# print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu115\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (1.11.0+cu115)\n",
            "Requirement already satisfied: torchvision in ./.venv/lib/python3.10/site-packages (0.12.0+cu115)\n",
            "Requirement already satisfied: torchaudio in ./.venv/lib/python3.10/site-packages (0.11.0+cu115)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2024.6.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu115"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 11.5\n",
            "PyTorch version: 1.11.0+cu115\n",
            "CUDA_VISIBLE_DEVICES: None\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# print(\"CUDA available:\", torch.cuda.is_available())\n",
        "# print(\"CUDA version:\", torch.version.cuda)\n",
        "# print(\"PyTorch version:\", torch.__version__)\n",
        "# print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get('CUDA_VISIBLE_DEVICES'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torch 1.11.0+cu115\n",
            "Uninstalling torch-1.11.0+cu115:\n",
            "  Successfully uninstalled torch-1.11.0+cu115\n",
            "Found existing installation: torchvision 0.12.0+cu115\n",
            "Uninstalling torchvision-0.12.0+cu115:\n",
            "  Successfully uninstalled torchvision-0.12.0+cu115\n",
            "Found existing installation: torchaudio 0.11.0+cu115\n",
            "Uninstalling torchaudio-0.11.0+cu115:\n",
            "  Successfully uninstalled torchaudio-0.11.0+cu115\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu115\n",
            "Collecting torch\n",
            "  Using cached https://download.pytorch.org/whl/cu115/torch-1.11.0%2Bcu115-cp310-cp310-linux_x86_64.whl (2138.5 MB)\n",
            "Collecting torchvision\n",
            "  Using cached https://download.pytorch.org/whl/cu115/torchvision-0.12.0%2Bcu115-cp310-cp310-linux_x86_64.whl (22.3 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached https://download.pytorch.org/whl/cu115/torchaudio-0.11.0%2Bcu115-cp310-cp310-linux_x86_64.whl (2.9 MB)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2024.6.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "Successfully installed torch-1.11.0+cu115 torchaudio-0.11.0+cu115 torchvision-0.12.0+cu115\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# !pip uninstall torch torchvision torchaudio -y\n",
        "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu115\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 11.5\n",
            "PyTorch version: 1.11.0+cu115\n",
            "CUDA_VISIBLE_DEVICES: None\n"
          ]
        }
      ],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# print(\"CUDA available:\", torch.cuda.is_available())\n",
        "# print(\"CUDA version:\", torch.version.cuda)\n",
        "# print(\"PyTorch version:\", torch.__version__)\n",
        "# print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get('CUDA_VISIBLE_DEVICES'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BGJAcU7dTxJ1",
        "V2mj0Wd-T73T",
        "ybM87poAtHnl",
        "5fjzE9q4UOPU",
        "SEseiEKFt0mR",
        "taX_5ElNuKxC",
        "aeMWj_f0sbQE",
        "3GXZaFXruZI_"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06d3de2006b14793bd57a5ca89d44e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d86018628f420e8d7e516ba5827e35",
            "placeholder": "​",
            "style": "IPY_MODEL_8877fd11846246f989e31835e5d3e7ae",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "07dc9b3c563e4615bec4dbd3233bf4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ff6351429c48c2b835305d3111af40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5de35a9063345b1a12e212718a02575",
            "placeholder": "​",
            "style": "IPY_MODEL_e86e517239b54ca4a6767a300aa7e01d",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "09b762f5ba784066a9408ffcfdea5b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9ee7dc8817456aab4af03cbfa4c6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b42ea1995bb410b99e653780dad3916": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4b10bb8bff4d40afa8df981440fe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d710da02bfe4c8e80d205158d9d64c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ef1563b6ba74b86a7bf7af3fcc3d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fdaf43c468043139e5d72397b118371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104402d4cba5477499593d972bc48e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13e7a0db2aa74e35b7d1948224358d76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1574e69b88de479da2aadc2dfdd43261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a0bbd1e2b14cef8a2f9accf120c1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175043eb44e44b4f9aefaf51aae6fb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e710b571d142a3a08cd233590b7171",
            "placeholder": "​",
            "style": "IPY_MODEL_2671c3bf3cfd49aa9ad6841c289068cc",
            "value": "0.019 MB of 0.019 MB uploaded\r"
          }
        },
        "17ac4efa9cf148e5be69edbc5b0bdecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18cb73ac1b224757920e7a8187b3ba4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ed5f5d4f714246bbdf44513ecc50f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f9d7ac8fa8a4bcdb76fe2b2cb443f66",
              "IPY_MODEL_71c0cc303cfc44ba8d989d5f8feca119"
            ],
            "layout": "IPY_MODEL_07dc9b3c563e4615bec4dbd3233bf4ba"
          }
        },
        "1b093d744b374154afe2058e4a6de822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b1acf7a1f5f43739e1fe0894ba48950": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d534596e41340438fc8d083fff6aa8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d74e9350c2c4c61b2e95924ec133012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9d7ac8fa8a4bcdb76fe2b2cb443f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ccc0b32e9a4ceebd6045dff63e6621",
            "placeholder": "​",
            "style": "IPY_MODEL_104402d4cba5477499593d972bc48e9d",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "1feabb0772134ace893d71cb905e9b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1acf7a1f5f43739e1fe0894ba48950",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d710da02bfe4c8e80d205158d9d64c7",
            "value": 1
          }
        },
        "1fef0782f0804736881f03c2e31c3d64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2402e482be7e484fa98ae3f60f68d95a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2671c3bf3cfd49aa9ad6841c289068cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2991ead42a2a4637b2902ca26837d74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e0bb90e33ec4e198857c255080ef6f0",
              "IPY_MODEL_77790c4dcd124f73907619689fb8d37c"
            ],
            "layout": "IPY_MODEL_1fef0782f0804736881f03c2e31c3d64"
          }
        },
        "2bc1423c729a4faa9a184ae092eda8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd5fda76227433aa9332e6e48cd415b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6480fe59104c7aa15d39bf6ea4a63b",
              "IPY_MODEL_3cb7b5c42e844747ae133750b7d42882"
            ],
            "layout": "IPY_MODEL_b81cc89707e44dedb51081d13a3ba424"
          }
        },
        "2d65b320aaed40cd87b8f78c99c614e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f39d5f73c7647f1804e4212cb39924d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e7ede02663f4eb0927872bf17858f18",
              "IPY_MODEL_a562d76741f74b10b8095be14da779d1"
            ],
            "layout": "IPY_MODEL_f4e7759ba0f544d8a28a9922e06e890b"
          }
        },
        "30d70d57987c4349b55560e5d9626201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36ac25551e574241bed4d7e5a4301d95",
              "IPY_MODEL_6898349b9c754ca7be91bea29cabbba5"
            ],
            "layout": "IPY_MODEL_623f947ef06c41569be7fcdda4141174"
          }
        },
        "32c759d7fff64701a6ad61b38ac63187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67aa8f8c2b244c9a9a3bb11caf491247",
            "placeholder": "​",
            "style": "IPY_MODEL_09b762f5ba784066a9408ffcfdea5b2e",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "33050a2d80c24235aecc36cb34e79684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a438b911c04f1f96c67b4f7ba7477d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7b6956e7e34db68cd38dee19c798f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d71c8b5d30df474ca6f30976d0a33c71",
            "value": 1
          }
        },
        "3445c5fe76514de0b6b9cc31200c8544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0748d32c99741d39b18512400e07f30",
            "placeholder": "​",
            "style": "IPY_MODEL_dc43eb867d6b446cb0cb8e5debae57e7",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "346856a22f0e45b2be0c14aa7902261f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d90a90d5854bcaa2bc5f385cdad931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3606009883cf4212b7e1ed6e4f182845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a546b812d6403cbf5ed693318a9744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a5f301338a4e5185c042a22684ed4a",
            "placeholder": "​",
            "style": "IPY_MODEL_48c7de7682f242fd86a234d1607187f4",
            "value": "0.020 MB of 0.020 MB uploaded\r"
          }
        },
        "36ac25551e574241bed4d7e5a4301d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d268f74266044451b230f20756bab2f6",
            "placeholder": "​",
            "style": "IPY_MODEL_6896790e80d1450c821918c7ef41e42f",
            "value": "0.027 MB of 0.027 MB uploaded\r"
          }
        },
        "371471be80ca47dbb005c853b7832f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1574e69b88de479da2aadc2dfdd43261",
            "placeholder": "​",
            "style": "IPY_MODEL_f523ae2aca8c46878f0a6ddc1f798ef5",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "397b6d4daaf04a1181413adc5e30db0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39aecb8ffe0645fbadccf8b0f8ed2486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0b3657d30547d7abe702d6c1e7b7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb7b5c42e844747ae133750b7d42882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fdaf43c468043139e5d72397b118371",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f63fffe56ff64f1eb2b6e8f14974f011",
            "value": 1
          }
        },
        "3ee2c346d4d74faa915ef8315e3303c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "403dcd5f10de42ddbb67c8108e3bc34c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4302f47b1ff043aca2523212b015e080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_371471be80ca47dbb005c853b7832f04",
              "IPY_MODEL_e75a0d8ae24e462aa3075a813aad302d"
            ],
            "layout": "IPY_MODEL_fd2cd8045a5c4387b98d080782289c48"
          }
        },
        "431cf75dd1cc4840b14f678876f45bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5f3871113994f1eb993c126d793d147",
              "IPY_MODEL_7903555c1e884408b70c9951ecae84ec"
            ],
            "layout": "IPY_MODEL_2d65b320aaed40cd87b8f78c99c614e7"
          }
        },
        "45bdcbbed9ae47ffb24bd2a962345eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c9d83bf8af443bb376ed4858ce35f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0b3657d30547d7abe702d6c1e7b7c4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17ac4efa9cf148e5be69edbc5b0bdecf",
            "value": 1
          }
        },
        "48c7de7682f242fd86a234d1607187f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49727de0590f41dca6addf3f4ffe33f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497de066b1964cd4b931476e0bd50c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4cfb14c56e477cbfef5a652c05fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b733fc6800e4a0ab36bba52ff84f1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2cc873f917444c833e152f7c2555de",
            "placeholder": "​",
            "style": "IPY_MODEL_49727de0590f41dca6addf3f4ffe33f2",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "5055c91b4ed34c1baf249fa25948e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33050a2d80c24235aecc36cb34e79684",
            "placeholder": "​",
            "style": "IPY_MODEL_2bc1423c729a4faa9a184ae092eda8ad",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "50b4ba3147b540abad020ae780353f27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557cf2de74314915b7204d9055fa6987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a345ff7386643eeb7a5b190d69d2e0e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f4783e2060a4295bb68036a4a7310d9",
            "value": 1
          }
        },
        "5630d5fcb50a46f2887e0cce74a005a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567cc1542f09433f8cc8b3a39237f198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584e5a6aada04535b64c40c3ece566e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf516644d1a4ebf82c7e9dfa13e560b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36a546b812d6403cbf5ed693318a9744",
              "IPY_MODEL_aed05a015df946c7bae33226c3a8ddc6"
            ],
            "layout": "IPY_MODEL_d601ef3ebb6c4b688ac53a65979aa445"
          }
        },
        "5e0116dc735e4ad995a5b1a039c6a55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76dfea14213f4e66b269b901150c6cba",
            "placeholder": "​",
            "style": "IPY_MODEL_d1e4a03094b94c34ac235ffbd0c7fa06",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "5f3a33bc6a334c9e8c5886caa5f015ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8040d3a83de41319a2a836def914b1b",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4b10bb8bff4d40afa8df981440fe43",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "60957598b6c64ab0987d583b788dd674": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623f947ef06c41569be7fcdda4141174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63dd47b50bdc44e88edd97d14585f7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e0116dc735e4ad995a5b1a039c6a55a",
              "IPY_MODEL_8cf1e952ed294ccdbc3bb2275b5d3efd"
            ],
            "layout": "IPY_MODEL_7421027bfcb34262a1b99d297e49bf8e"
          }
        },
        "64224c777f01418e904dcd30ecd7c5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99929754d3094d03a5f311177ac26cb3",
            "placeholder": "​",
            "style": "IPY_MODEL_9ea517158b974c5da17899e3fea4fc3b",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "67aa8f8c2b244c9a9a3bb11caf491247": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6896790e80d1450c821918c7ef41e42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6898349b9c754ca7be91bea29cabbba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30700c8bfb449cda98a40d75828f3d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77beee57b67d4bad826f616e5483b87a",
            "value": 1
          }
        },
        "68d86018628f420e8d7e516ba5827e35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ff4108835c462b929d0b5c78497555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696917cb66a74c41b87f9b436f8ce42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77a9b4df16ba408a941d67a51eed303d",
              "IPY_MODEL_b3b0d42308df44e6b43a06f7424d489d"
            ],
            "layout": "IPY_MODEL_fd23196beb964eb0a631b1fcb3893545"
          }
        },
        "6a345ff7386643eeb7a5b190d69d2e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa92cf922724ac08c45385ff8a58447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abbcbe71a314356ba04f8349d1fc127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3326a99729a416abca13d3122196e64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d534596e41340438fc8d083fff6aa8b",
            "value": 1
          }
        },
        "6c30f9a9e6c44d78ad39f43a5f11a6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e51a8e2e7e6463486d7b11454333941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7ede02663f4eb0927872bf17858f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9ee7dc8817456aab4af03cbfa4c6ed",
            "placeholder": "​",
            "style": "IPY_MODEL_567cc1542f09433f8cc8b3a39237f198",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "7064cd1e5d794c258dbeeb63a9ae9f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71c0cc303cfc44ba8d989d5f8feca119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fe0a51b14b4e548454d4f83215336c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e13a8bef6e14973912966984e83cd4c",
            "value": 1
          }
        },
        "71e710b571d142a3a08cd233590b7171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7421027bfcb34262a1b99d297e49bf8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76dfea14213f4e66b269b901150c6cba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77790c4dcd124f73907619689fb8d37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e7a0db2aa74e35b7d1948224358d76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7064cd1e5d794c258dbeeb63a9ae9f9b",
            "value": 1
          }
        },
        "77a9b4df16ba408a941d67a51eed303d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e51a8e2e7e6463486d7b11454333941",
            "placeholder": "​",
            "style": "IPY_MODEL_18cb73ac1b224757920e7a8187b3ba4d",
            "value": "0.020 MB of 0.020 MB uploaded\r"
          }
        },
        "77beee57b67d4bad826f616e5483b87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77c702b6d9c04f00b8e624f31a591f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d67121f0ab4daf96d0bdd2c433259b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ee2c346d4d74faa915ef8315e3303c8",
            "value": 1
          }
        },
        "7903555c1e884408b70c9951ecae84ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac87babb2f2a4781ab863c3b8f613807",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3970cfd36ed4450b7c8f958a6499dc4",
            "value": 1
          }
        },
        "7e2cc873f917444c833e152f7c2555de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804c12a3f13840c7bdb2e6df69e62c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ff4108835c462b929d0b5c78497555",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a63e1d987556448280ca217f17b60b49",
            "value": 1
          }
        },
        "80fe0a51b14b4e548454d4f83215336c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81408f178c46447f90d36d1d18cdad82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06d3de2006b14793bd57a5ca89d44e4a",
              "IPY_MODEL_804c12a3f13840c7bdb2e6df69e62c10"
            ],
            "layout": "IPY_MODEL_4a4cfb14c56e477cbfef5a652c05fabc"
          }
        },
        "81500a36ef5e4a9e9b36aef01bee3697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "829bba2a5bb947a0bcf121c527902255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829eee71e4d74403a22941b15dfcf9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8587c890f2a847e293a101405d64fc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_175043eb44e44b4f9aefaf51aae6fb10",
              "IPY_MODEL_db36d0cc7691440a9792ac779e161e62"
            ],
            "layout": "IPY_MODEL_c6a68af25a2847e98201847781419670"
          }
        },
        "8795a05c814c469083b31be62e79289f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8877fd11846246f989e31835e5d3e7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889653c19d8e43cfb6f56ed46af5b76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cf1e952ed294ccdbc3bb2275b5d3efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e410ff55fc448bbe87c8975a552e88",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49251ce876f4d9292a4179b48ebb22a",
            "value": 1
          }
        },
        "8dc245e02cac40f1b601fa42a0e6e77a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e13a8bef6e14973912966984e83cd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f4783e2060a4295bb68036a4a7310d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "904f899f441149e9b707699a0ebf31b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90b585318084475b9543b3226230d373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3a33bc6a334c9e8c5886caa5f015ca",
              "IPY_MODEL_46c9d83bf8af443bb376ed4858ce35f7"
            ],
            "layout": "IPY_MODEL_2402e482be7e484fa98ae3f60f68d95a"
          }
        },
        "9387a738135842cf965db860499510f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5630d5fcb50a46f2887e0cce74a005a6",
            "placeholder": "​",
            "style": "IPY_MODEL_fed90f96881140119ee97a0d2120b615",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "97c3921b8e454ccdb7b4db95d4440c64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99929754d3094d03a5f311177ac26cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d88657b39fd4b169d61b1b8d240e6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e0bb90e33ec4e198857c255080ef6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3606009883cf4212b7e1ed6e4f182845",
            "placeholder": "​",
            "style": "IPY_MODEL_39aecb8ffe0645fbadccf8b0f8ed2486",
            "value": "0.021 MB of 0.021 MB uploaded\r"
          }
        },
        "9ea517158b974c5da17899e3fea4fc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d013e4d3e942b6b362ab5ade6d1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a30700c8bfb449cda98a40d75828f3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ccc0b32e9a4ceebd6045dff63e6621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a562d76741f74b10b8095be14da779d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc245e02cac40f1b601fa42a0e6e77a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b093d744b374154afe2058e4a6de822",
            "value": 1
          }
        },
        "a5758bfac16a4388a036005a15812d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5f3871113994f1eb993c126d793d147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_346856a22f0e45b2be0c14aa7902261f",
            "placeholder": "​",
            "style": "IPY_MODEL_397b6d4daaf04a1181413adc5e30db0c",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "a63e1d987556448280ca217f17b60b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ba8ab59be54b8ca096631627ee9713": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6aa819c1fd4776ac47af588aaaaacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64224c777f01418e904dcd30ecd7c5ef",
              "IPY_MODEL_c1dbd12595384bc6a0240aaeb16014dc"
            ],
            "layout": "IPY_MODEL_6aa92cf922724ac08c45385ff8a58447"
          }
        },
        "ab0b891f55f648cdbace9bc4540c51c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab580ef13b18428c994fc4f8b80885b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb268a732bc74b2d81ec3c3a6ecd0362",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2915a147a4246dba7984a90f23c34ae",
            "value": 1
          }
        },
        "ab62d64100a84b1faae744ee0f99501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b4ba3147b540abad020ae780353f27",
            "placeholder": "​",
            "style": "IPY_MODEL_584e5a6aada04535b64c40c3ece566e8",
            "value": "0.017 MB of 0.017 MB uploaded\r"
          }
        },
        "ac87babb2f2a4781ab863c3b8f613807": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed05a015df946c7bae33226c3a8ddc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403dcd5f10de42ddbb67c8108e3bc34c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1d013e4d3e942b6b362ab5ade6d1a80",
            "value": 1
          }
        },
        "b0748d32c99741d39b18512400e07f30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3970cfd36ed4450b7c8f958a6499dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3b0d42308df44e6b43a06f7424d489d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef1563b6ba74b86a7bf7af3fcc3d5d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_889653c19d8e43cfb6f56ed46af5b76f",
            "value": 1
          }
        },
        "b81cc89707e44dedb51081d13a3ba424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6f9560801c461a90a0fd2f8c20d918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5055c91b4ed34c1baf249fa25948e84f",
              "IPY_MODEL_1feabb0772134ace893d71cb905e9b12"
            ],
            "layout": "IPY_MODEL_fb5f2e328dff44018f41180c2a2ec871"
          }
        },
        "bb2ee36dd3c04926b10b832928d7d0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbeb5bacc824f3aacd20e50d38bb70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1dbd12595384bc6a0240aaeb16014dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2ee36dd3c04926b10b832928d7d0a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d88657b39fd4b169d61b1b8d240e6ff",
            "value": 1
          }
        },
        "c20d73b37f6a497a8847e2fd20a98d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a0bbd1e2b14cef8a2f9accf120c1ad",
            "placeholder": "​",
            "style": "IPY_MODEL_e181391aa4424c04804ac665abd6f594",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "c59ee0d8b9fb4694ada362115bf965a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab62d64100a84b1faae744ee0f99501a",
              "IPY_MODEL_6abbcbe71a314356ba04f8349d1fc127"
            ],
            "layout": "IPY_MODEL_97c3921b8e454ccdb7b4db95d4440c64"
          }
        },
        "c5bb24dc0f56483b88a0efbfa2a1c8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5de35a9063345b1a12e212718a02575": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a68af25a2847e98201847781419670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e410ff55fc448bbe87c8975a552e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe10db0bb8d45609a0f3d59a30c8f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07ff6351429c48c2b835305d3111af40",
              "IPY_MODEL_ab580ef13b18428c994fc4f8b80885b6"
            ],
            "layout": "IPY_MODEL_497de066b1964cd4b931476e0bd50c66"
          }
        },
        "d1e4a03094b94c34ac235ffbd0c7fa06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d268f74266044451b230f20756bab2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3326a99729a416abca13d3122196e64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d601ef3ebb6c4b688ac53a65979aa445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71c8b5d30df474ca6f30976d0a33c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d770fa4de3bd479886dbf8e1f6369543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c20d73b37f6a497a8847e2fd20a98d16",
              "IPY_MODEL_edd61f4569b54b869669aebf91420508"
            ],
            "layout": "IPY_MODEL_a6ba8ab59be54b8ca096631627ee9713"
          }
        },
        "db36d0cc7691440a9792ac779e161e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45bdcbbed9ae47ffb24bd2a962345eaa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcbeb5bacc824f3aacd20e50d38bb70a",
            "value": 1
          }
        },
        "dc43eb867d6b446cb0cb8e5debae57e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcbb358118e644a2a75d44d8adb6747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60957598b6c64ab0987d583b788dd674",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4ad17a7648245069c70f2f3fb79105a",
            "value": 1
          }
        },
        "df97494c2f654ffbaceb9ca801ff3113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1e5353cb6a1427a8b0b9d91d6067ef7",
              "IPY_MODEL_77c702b6d9c04f00b8e624f31a591f01"
            ],
            "layout": "IPY_MODEL_8795a05c814c469083b31be62e79289f"
          }
        },
        "e181391aa4424c04804ac665abd6f594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e5353cb6a1427a8b0b9d91d6067ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829eee71e4d74403a22941b15dfcf9bc",
            "placeholder": "​",
            "style": "IPY_MODEL_ab0b891f55f648cdbace9bc4540c51c6",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "e4a5f301338a4e5185c042a22684ed4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ad17a7648245069c70f2f3fb79105a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6a773393e084de9a117fbbf43b7a59e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d67121f0ab4daf96d0bdd2c433259b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75a0d8ae24e462aa3075a813aad302d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b42ea1995bb410b99e653780dad3916",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3ebd9b7bf7a4d24b54ab6673322f74b",
            "value": 1
          }
        },
        "e8040d3a83de41319a2a836def914b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e851c69b66ca4e8a80779a69435b855f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b733fc6800e4a0ab36bba52ff84f1a5",
              "IPY_MODEL_dcbb358118e644a2a75d44d8adb6747b"
            ],
            "layout": "IPY_MODEL_829bba2a5bb947a0bcf121c527902255"
          }
        },
        "e86e517239b54ca4a6767a300aa7e01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eafc1e77174c4758a3780b481d694ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c30f9a9e6c44d78ad39f43a5f11a6d0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81500a36ef5e4a9e9b36aef01bee3697",
            "value": 1
          }
        },
        "eb268a732bc74b2d81ec3c3a6ecd0362": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd61f4569b54b869669aebf91420508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ce66183b2543e7bf19b71d90d1c53e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904f899f441149e9b707699a0ebf31b5",
            "value": 1
          }
        },
        "f2915a147a4246dba7984a90f23c34ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ebd9b7bf7a4d24b54ab6673322f74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f49251ce876f4d9292a4179b48ebb22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e7759ba0f544d8a28a9922e06e890b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f523ae2aca8c46878f0a6ddc1f798ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5fd8db807e144578a2e20762d7369d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32c759d7fff64701a6ad61b38ac63187",
              "IPY_MODEL_557cf2de74314915b7204d9055fa6987"
            ],
            "layout": "IPY_MODEL_c5bb24dc0f56483b88a0efbfa2a1c8ee"
          }
        },
        "f63fffe56ff64f1eb2b6e8f14974f011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f76ed5acf91a4edf92950dcb88356f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9387a738135842cf965db860499510f5",
              "IPY_MODEL_33a438b911c04f1f96c67b4f7ba7477d"
            ],
            "layout": "IPY_MODEL_35d90a90d5854bcaa2bc5f385cdad931"
          }
        },
        "f8ce66183b2543e7bf19b71d90d1c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9dca98d1b8c402db8fa03f1354a051b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3445c5fe76514de0b6b9cc31200c8544",
              "IPY_MODEL_eafc1e77174c4758a3780b481d694ae0"
            ],
            "layout": "IPY_MODEL_e6a773393e084de9a117fbbf43b7a59e"
          }
        },
        "fb5f2e328dff44018f41180c2a2ec871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd23196beb964eb0a631b1fcb3893545": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2cd8045a5c4387b98d080782289c48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6480fe59104c7aa15d39bf6ea4a63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d74e9350c2c4c61b2e95924ec133012",
            "placeholder": "​",
            "style": "IPY_MODEL_a5758bfac16a4388a036005a15812d1d",
            "value": "0.017 MB of 0.017 MB uploaded\r"
          }
        },
        "fed90f96881140119ee97a0d2120b615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7b6956e7e34db68cd38dee19c798f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
