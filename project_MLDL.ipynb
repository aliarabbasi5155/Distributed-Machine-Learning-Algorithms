{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVF2_gqB0EDy",
        "outputId": "d30ab9fc-a12a-41d6-f66a-a1fd1c26307d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (1.11.0+cu115)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.12.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torchvision in ./.venv/lib/python3.10/site-packages (0.12.0+cu115)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torchvision) (4.12.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from torchvision) (2.32.3)\n",
            "Requirement already satisfied: torch==1.11.0 in ./.venv/lib/python3.10/site-packages (from torchvision) (1.11.0+cu115)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.10/site-packages (from torchvision) (10.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->torchvision) (2024.6.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.10/site-packages (3.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.10/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.10/site-packages (from matplotlib) (10.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.10/site-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install missing dependencies\n",
        "!pip install -q torchinfo torchmetrics wandb\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGJAcU7dTxJ1"
      },
      "source": [
        "### Import important libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "bnVg3M4l0EyA"
      },
      "outputs": [],
      "source": [
        "# Import required libraries/code\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "from torchinfo import summary\n",
        "\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import random_split, DataLoader, Subset\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.optimizer import Optimizer\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import wandb\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "from typing import Optional, Union, Callable, List\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "import copy\n",
        "from itertools import combinations\n",
        "import time\n",
        "from datetime import timedelta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQg3CXCtgB-5",
        "outputId": "7b5a2e28-b427-4b64-f013-8c1977e97423"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FC7BMY9z0H3L",
        "outputId": "3a9750af-17c1-4e3c-f816-20ff79567d9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QH26cxftUt3"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "knmNFhHg0CwT"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define a class for handling CIFAR100 data\n",
        "class CIFAR100Data:\n",
        "    \"\"\"\n",
        "    A class used to represent the CIFAR100 dataset.\n",
        "\n",
        "    ...\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    batch_size : int\n",
        "        the number of samples that will be propagated through the network simultaneously\n",
        "    original_train_set : torchvision.datasets.CIFAR100\n",
        "        the original training set downloaded from CIFAR100\n",
        "    original_test_set : torchvision.datasets.CIFAR100\n",
        "        the original test set downloaded from CIFAR100\n",
        "    train_set : torch.utils.data.Subset\n",
        "        the training set after splitting the original training set\n",
        "    validation_set : torch.utils.data.Subset\n",
        "        the validation set after splitting the original training set\n",
        "    test_set : torchvision.datasets.CIFAR100\n",
        "        the test set, same as the original test set\n",
        "    original_train_loader : torch.utils.data.DataLoader\n",
        "        data loader for the original training set\n",
        "    original_test_loader : torch.utils.data.DataLoader\n",
        "        data loader for the original test set\n",
        "    train_loader : torch.utils.data.DataLoader\n",
        "        data loader for the training set\n",
        "    validation_loader : torch.utils.data.DataLoader\n",
        "        data loader for the validation set\n",
        "    test_loader : torch.utils.data.DataLoader\n",
        "        data loader for the test set\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    compute_mean_std(loader)\n",
        "        Computes the mean and standard deviation of the images in the loader.\n",
        "    download_data()\n",
        "        Downloads the CIFAR100 dataset.\n",
        "    split_data(original_train_set, validation_ratio=0.2)\n",
        "        Splits the original training set into a training set and a validation set.\n",
        "    compute_statistics(train_set)\n",
        "        Computes the mean and standard deviation of the training set.\n",
        "    apply_transforms(train_mean, train_std, is_validation_set_available = False)\n",
        "        Defines and applies the transformations for the training set, validation set, and test set.\n",
        "    save_data(data_loader, data_set, file_name: str)\n",
        "        Saves the data loader to Google Drive.\n",
        "    load_data(file_name: str)\n",
        "        Loads the data loader from Google Drive.\n",
        "    create_and_save_data_loaders(train_set, test_set, validation_set=None)\n",
        "        Creates data loaders for the training, validation, and test sets and saves them to Google Drive.\n",
        "    prepare_data(validation_ratio = None)\n",
        "        Prepares the data by downloading it, splitting it, computing statistics, applying transforms, and creating and saving data loaders.\n",
        "    train_valid_test(validation_ratio=0.2)\n",
        "        Loads or prepares the data loaders for the training, validation, and test sets and returns them.\n",
        "    train_test()\n",
        "        Loads or prepares the data loaders for the original training and test sets and returns them.\n",
        "    iid_shards(num_shards=2)\n",
        "        Loads or prepares the data loaders for the shards of the original training set and returns them.\n",
        "    \"\"\"\n",
        "    def __init__(self, batch_size=64):\n",
        "        \"\"\"\n",
        "        Initialize the CIFAR100Data object with the given batch size.\n",
        "\n",
        "        Parameters:\n",
        "        batch_size (int): The size of the batches for the data loaders.\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.original_train_set = None\n",
        "        self.original_test_set = None\n",
        "        self.train_set = None\n",
        "        self.validation_set = None\n",
        "        self.test_set = None\n",
        "\n",
        "        self.original_train_loader = None\n",
        "        self.original_test_loader = None\n",
        "        self.train_loader = None\n",
        "        self.validation_loader = None\n",
        "        self.test_loader = None\n",
        "\n",
        "    def compute_mean_std(self, loader):\n",
        "        \"\"\"\n",
        "        Compute the mean and standard deviation of the images in the loader.\n",
        "\n",
        "        Parameters:\n",
        "        loader (DataLoader): The DataLoader object containing the image data.\n",
        "\n",
        "        Returns:\n",
        "        mean (Tensor): The mean of the images.\n",
        "        std (Tensor): The standard deviation of the images.\n",
        "        \"\"\"\n",
        "        channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "        for data, _ in loader:\n",
        "            channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
        "            channels_squared_sum += torch.mean(data**2, dim=[0, 2, 3])\n",
        "            num_batches += 1\n",
        "        mean = channels_sum / num_batches\n",
        "        std = torch.sqrt((channels_squared_sum / num_batches) - mean**2)\n",
        "        return mean, std\n",
        "\n",
        "    def download_data(self):\n",
        "        \"\"\"\n",
        "        Download the CIFAR100 dataset and store it in instance variables.\n",
        "        \"\"\"\n",
        "        self.original_train_set = CIFAR100(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "        self.original_test_set = CIFAR100(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "    def split_data(self, original_train_set, validation_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Split the original training set into a training set and a validation set.\n",
        "\n",
        "        Parameters:\n",
        "        original_train_set (Dataset): The original training set.\n",
        "        validation_ratio (float): The ratio of the original training set to use for validation.\n",
        "\n",
        "        Returns:\n",
        "        train_set (Subset): The new training set.\n",
        "        validation_set (Subset): The new validation set.\n",
        "        \"\"\"\n",
        "        train_len = int(len(original_train_set) * (1 - validation_ratio))\n",
        "        val_len = len(original_train_set) - train_len\n",
        "        train_set, validation_set = random_split(original_train_set, [train_len, val_len])\n",
        "\n",
        "        return train_set, validation_set\n",
        "\n",
        "    def compute_statistics(self, train_set):\n",
        "        \"\"\"\n",
        "        Compute the mean and standard deviation of the train set.\n",
        "\n",
        "        Parameters:\n",
        "        train_set (Dataset/Subset): The training set.\n",
        "\n",
        "        Returns:\n",
        "        train_mean (Tensor): The mean of the training set.\n",
        "        train_std (Tensor): The standard deviation of the training set.\n",
        "        \"\"\"\n",
        "        trainloader_tmp = DataLoader(train_set, batch_size=self.batch_size, shuffle=True)\n",
        "        train_mean, train_std = self.compute_mean_std(trainloader_tmp)\n",
        "\n",
        "        return train_mean, train_std\n",
        "\n",
        "    def apply_transforms(self, train_mean, train_std, is_validation_set_available = False):\n",
        "        \"\"\"\n",
        "        Define the transformations for the training set, validation set, and test set\n",
        "        and apply them to the datasets.\n",
        "\n",
        "        Parameters:\n",
        "        train_mean (Tensor): The mean of the training set.\n",
        "        train_std (Tensor): The standard deviation of the training set.\n",
        "        is_validation_set_available (bool): Whether a validation set is available.\n",
        "        \"\"\"\n",
        "\n",
        "        # Transformations for the training set\n",
        "        train_transforms = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(train_mean.tolist(), train_std.tolist())\n",
        "        ])\n",
        "\n",
        "        # Transformations for the validation and test sets\n",
        "        test_val_transforms = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(train_mean.tolist(), train_std.tolist())\n",
        "        ])\n",
        "\n",
        "        # Apply the transformations to the datasets\n",
        "        if is_validation_set_available:\n",
        "            self.train_set.transform = train_transforms\n",
        "            self.validation_set.transform = test_val_transforms\n",
        "            self.test_set.transform = test_val_transforms\n",
        "        else:\n",
        "            self.original_train_set.transform = train_transforms\n",
        "            self.original_test_set.transform = test_val_transforms\n",
        "\n",
        "    def save_data(self, data_loader, file_name: str):\n",
        "        \"\"\"\n",
        "        Save the given data loader and data set to Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        data_loader (DataLoader): The data loader to save.\n",
        "        file_name (str): The name of the file to save the data loader and data set to.\n",
        "        \"\"\"\n",
        "        # Check if the directory exists, if not, create it\n",
        "        # if not os.path.exists('/content/gdrive/MyDrive/data/data_loaders/'):\n",
        "        #     os.makedirs('/content/gdrive/MyDrive/data/data_loaders/')\n",
        "\n",
        "        # Open each file in write-binary mode on Google Drive and dump (pickle) the data loader into it\n",
        "        # with open(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl', 'wb') as f:\n",
        "        #     pickle.dump(data_loader, f)\n",
        "        if not os.path.exists(f'./data/data_loaders/{self.batch_size}/'):\n",
        "            os.makedirs(f'./data/data_loaders/{self.batch_size}/')\n",
        "        \n",
        "        open(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl', 'wb').write(pickle.dumps(data_loader))\n",
        "\n",
        "    def load_data(self, file_name: str):\n",
        "        \"\"\"\n",
        "        Load a data loader from Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        file_name (str): The name of the file to load the data loader from.\n",
        "\n",
        "        Returns:\n",
        "        data_loader (DataLoader): The loaded data loader, or None if the file does not exist.\n",
        "        \"\"\"\n",
        "        # Check if the file exists\n",
        "        # if os.path.exists(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl'):\n",
        "        #     # If it exists, open the file in read-binary mode and load (unpickle) the data loader from it\n",
        "        #     with open(f'/content/gdrive/MyDrive/data/data_loaders/{self.batch_size}_{file_name}_loader.pkl', 'rb') as f:\n",
        "        #         return pickle.load(f)\n",
        "        # else:\n",
        "        #     return None\n",
        "        if os.path.exists(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl'):\n",
        "            return pickle.loads(open(f'./data/data_loaders/{self.batch_size}/{file_name}_loader.pkl', 'rb').read())\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def create_and_save_data_loaders(self, train_set, test_set, train_name: str, test_name: str, validation_set=None):\n",
        "        \"\"\"\n",
        "        Create data loaders for the training, validation, and test sets and save them to Google Drive.\n",
        "\n",
        "        Parameters:\n",
        "        train_set (Subset): The training set.\n",
        "        test_set (Subset): The test set.\n",
        "        validation_set (Subset, optional): The validation set.\n",
        "\n",
        "        Returns:\n",
        "        train_loader (DataLoader): The data loader for the training set.\n",
        "        validation_loader (DataLoader): The data loader for the validation set, if it exists.\n",
        "        test_loader (DataLoader): The data loader for the test set.\n",
        "        \"\"\"\n",
        "        train_loader = DataLoader(train_set, batch_size=self.batch_size, shuffle=True, num_workers =8)\n",
        "        test_loader = DataLoader(test_set, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
        "\n",
        "        # Save the newly created data loaders to Google Drive\n",
        "        self.save_data(train_loader, train_name)\n",
        "        self.save_data(test_loader, test_name)\n",
        "\n",
        "        if validation_set is not None:\n",
        "            validation_loader = DataLoader(validation_set, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
        "            self.save_data(validation_loader, 'validation')\n",
        "            return train_loader, validation_loader, test_loader\n",
        "\n",
        "        return train_loader, test_loader\n",
        "\n",
        "    def prepare_data(self, validation_ratio = None):\n",
        "        \"\"\"\n",
        "        Prepare the data by downloading it, splitting it into training, validation, and test sets,\n",
        "        computing statistics, applying transformations, and creating and saving data loaders.\n",
        "\n",
        "        Parameters:\n",
        "        validation_ratio (float, optional): The ratio of the original training set to use for validation.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            self.download_data()\n",
        "        except IOError:\n",
        "            print(\"Error downloading data\")\n",
        "            return\n",
        "\n",
        "        if validation_ratio is not None:\n",
        "            self.train_set, self.validation_set = self.split_data(self.original_train_set, validation_ratio)\n",
        "            if self.validation_set is None:\n",
        "                print(\"Validation set is not available\")\n",
        "                return\n",
        "            self.test_set = self.original_test_set\n",
        "            train_mean, train_std = self.compute_statistics(self.train_set)\n",
        "            self.apply_transforms(train_mean, train_std, is_validation_set_available = True)\n",
        "\n",
        "            # Create and save data loaders\n",
        "            self.train_loader, self.validation_loader, self.test_loader = self.create_and_save_data_loaders(self.train_set, self.test_set, 'train', 'test', self.validation_set)\n",
        "\n",
        "        else:\n",
        "            train_mean, train_std = self.compute_statistics(self.original_train_set)\n",
        "            self.apply_transforms(train_mean, train_std)\n",
        "\n",
        "            # Create and save data loaders\n",
        "            self.original_train_loader, self.original_test_loader = self.create_and_save_data_loaders(self.original_train_set, self.original_test_set, 'original_train', 'original_test')\n",
        "\n",
        "    def train_valid_test(self, validation_ratio=0.2):\n",
        "        \"\"\"\n",
        "        Load the training, validation, and test data loaders from Google Drive, or prepare the data if they do not exist.\n",
        "\n",
        "        Parameters:\n",
        "        validation_ratio (float): The ratio of the original training set to use for validation.\n",
        "\n",
        "        Returns:\n",
        "        train_loader (DataLoader): The data loader for the training set.\n",
        "        validation_loader (DataLoader): The data loader for the validation set.\n",
        "        test_loader (DataLoader): The data loader for the test set.\n",
        "        \"\"\"\n",
        "        self.train_loader = self.load_data('train')\n",
        "        self.validation_loader = self.load_data('validation')\n",
        "        self.test_loader = self.load_data('test')\n",
        "\n",
        "        if self.train_loader is None or self.validation_loader is None or self.test_loader is None:\n",
        "            self.prepare_data(validation_ratio)\n",
        "\n",
        "        # Return the data loaders\n",
        "        return self.train_loader, self.validation_loader, self.test_loader\n",
        "\n",
        "    def train_test(self):\n",
        "        \"\"\"\n",
        "        Load the original training and test data loaders from Google Drive, or prepare the data if they do not exist.\n",
        "\n",
        "        Returns:\n",
        "        original_train_loader (DataLoader): The data loader for the original training set.\n",
        "        original_test_loader (DataLoader): The data loader for the original test set.\n",
        "        \"\"\"\n",
        "        self.original_train_loader = self.load_data('original_train')\n",
        "        self.original_test_loader = self.load_data('original_test')\n",
        "\n",
        "        if self.original_train_loader is None or self.original_test_loader is None:\n",
        "            self.prepare_data()\n",
        "\n",
        "        # Return the data loaders\n",
        "        return self.original_train_loader, self.original_test_loader\n",
        "\n",
        "    def iid_shards(self, num_shards=2):\n",
        "        \"\"\"\n",
        "        Create or load independent and identically distributed (IID) shards of the original training set.\n",
        "\n",
        "        Parameters:\n",
        "        num_shards (int): The number of shards to create.\n",
        "\n",
        "        Returns:\n",
        "        shard_loaders (list of DataLoader): The data loaders for the shards.\n",
        "        \"\"\"\n",
        "        # Try to load the shard datasets and their corresponding data loaders from Google Drive\n",
        "        shard_loaders = []\n",
        "        for i in range(num_shards):\n",
        "            shard_loader = self.load_data(f'iid_sharding/{num_shards}_chunk_{i+1}')\n",
        "            if shard_loader is None:\n",
        "                break\n",
        "            shard_loaders.append(shard_loader)\n",
        "\n",
        "        # If all shard data loaders were successfully loaded, return them\n",
        "        if len(shard_loaders) == num_shards:\n",
        "            return shard_loaders\n",
        "\n",
        "        # If not all shard data loaders were successfully loaded, create them\n",
        "        if self.original_train_set is None:\n",
        "            self.download_data()\n",
        "            train_mean, train_std = self.compute_statistics(self.original_train_set)\n",
        "            self.apply_transforms(train_mean, train_std)\n",
        "\n",
        "        # Shuffle the indices\n",
        "        indices = torch.randperm(len(self.original_train_set))\n",
        "\n",
        "        # Split the indices into K chunks\n",
        "        shard_size = len(indices) // num_shards\n",
        "        shards = [indices[i*shard_size:(i+1)*shard_size] for i in range(num_shards)]\n",
        "\n",
        "        # Create subsets for each shard\n",
        "        shard_datasets = [Subset(self.original_train_set, shard) for shard in shards]\n",
        "\n",
        "        # Create data loaders for each shard\n",
        "        shard_loaders = [DataLoader(shard_dataset, batch_size=self.batch_size, shuffle=True) for shard_dataset in shard_datasets]\n",
        "\n",
        "        # Save each shard dataset and its corresponding data loader\n",
        "        for i, shard_loader in enumerate(shard_loaders):\n",
        "            self.save_data(shard_loader, f'iid_sharding_{num_shards}_chunk_{i+1}')\n",
        "\n",
        "        return shard_loaders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "KE_ErnYB06JF"
      },
      "outputs": [],
      "source": [
        "data = CIFAR100Data()\n",
        "train_loader, validation_loader, test_loader = data.train_valid_test(validation_ratio=0.2)\n",
        "original_train_loader, original_test_loader = data.train_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fjzE9q4UOPU"
      },
      "source": [
        "### Define the model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "KaLfzyjo0Pzk"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture\n",
        "# Check if it is LeNet-5 or similar to LeNet-5 we want similar.\n",
        "class LeNet5(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=5, padding=0) # 28x28\n",
        "        self.conv2 = nn.Conv2d(64, 64, kernel_size=5, padding=0) # 10x10\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 14x14 for conv1 and 5x5 for conv2\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(5 * 5 * 64, 384)\n",
        "        self.fc2 = nn.Linear(384, 192)\n",
        "        self.fc3 = nn.Linear(192, 100)\n",
        "\n",
        "    def forward(self, x, indexing=None):\n",
        "        intermediate_outputs = {}\n",
        "\n",
        "        # Convolutional and pooling layers\n",
        "        x = F.relu(self.conv1(x))\n",
        "        if indexing == 'conv1':\n",
        "            return x\n",
        "        intermediate_outputs['conv1'] = x\n",
        "\n",
        "        x = self.pool(x)\n",
        "        if indexing == 'pool1':\n",
        "            return x\n",
        "        intermediate_outputs['pool1'] = x\n",
        "\n",
        "        x = F.relu(self.conv2(x))\n",
        "        if indexing == 'conv2':\n",
        "            return x\n",
        "        intermediate_outputs['conv2'] = x\n",
        "\n",
        "        x = self.pool(x)\n",
        "        if indexing == 'pool2':\n",
        "            return x\n",
        "        intermediate_outputs['pool2'] = x\n",
        "\n",
        "        # Flatten layer\n",
        "        x = self.flatten(x)\n",
        "        if indexing == 'flatten':\n",
        "            return x\n",
        "        intermediate_outputs['flatten'] = x\n",
        "\n",
        "        # Fully connected layers\n",
        "        x = F.relu(self.fc1(x))\n",
        "        if indexing == 'fc1':\n",
        "            return x\n",
        "        intermediate_outputs['fc1'] = x\n",
        "\n",
        "        x = F.relu(self.fc2(x))\n",
        "        if indexing == 'fc2':\n",
        "            return x\n",
        "        intermediate_outputs['fc2'] = x\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        if indexing == 'fc3':\n",
        "            return x\n",
        "        intermediate_outputs['fc3'] = x\n",
        "\n",
        "        # If no indexing, return final output\n",
        "        return x if indexing is None else intermediate_outputs.get(indexing, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "-4HtbSQ20ea5"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEseiEKFt0mR"
      },
      "source": [
        "### Define some basic functions for train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "JZNSgcBp0jEl"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, loss_fn, accumulation_steps=1, device=device, is_wandb=False):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    optimizer.zero_grad()  # Initialize gradients to zero at the start of each epoch\n",
        "\n",
        "    for i, (inputs, targets) in enumerate(dataloader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        loss.backward()  # Backpropagation\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        # Gradient accumulation\n",
        "        if (i+1) % accumulation_steps == 0 or i+1 == len(dataloader):\n",
        "            optimizer.step()  # Update model parameters\n",
        "            optimizer.zero_grad()  # Reset gradients to zero\n",
        "\n",
        "    train_loss = running_loss / len(dataloader)\n",
        "    train_accuracy = 100. * correct / total\n",
        "\n",
        "    if is_wandb:\n",
        "        wandb.log({\"Train Loss\": train_loss, \"Train Accuracy\": train_accuracy})\n",
        "\n",
        "    return train_loss, train_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "m6dkKxXh0i7n"
      },
      "outputs": [],
      "source": [
        "def test(model, dataloader, loss_fn, device = device, is_wandb= False):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "            if is_wandb:\n",
        "              # Log the loss and accuracy values at each step\n",
        "              wandb.log({\n",
        "                  'Test Loss': test_loss / (batch_idx + 1),\n",
        "                  'Test Accuracy': 100 * correct / total\n",
        "              })\n",
        "\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_accuracy = 100. * correct / total\n",
        "\n",
        "    return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "ZD7Vge_wYwvX"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, epoch, batch_size, optimizer_name, hyperparameters):\n",
        "    # dir_path = f\"/content/gdrive/MyDrive/{optimizer_name}/{batch_size}/\"\n",
        "    dir_path = f\"./train/{optimizer_name}/{batch_size}/\"\n",
        "    for key, value in hyperparameters.items():\n",
        "        dir_path = os.path.join(dir_path, f\"{key}_{value}/\")\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "    path = os.path.join(dir_path, f\"epoch_{epoch:03}.pt\")\n",
        "    torch.save(state, path)\n",
        "\n",
        "    # Get list of all files\n",
        "    list_of_files = glob.glob(os.path.join(dir_path, f\"epoch_*.pt\"))\n",
        "    # Sort files by creation time\n",
        "    list_of_files.sort(key=os.path.getctime)\n",
        "    # If there are more than 2 files, delete the second last one\n",
        "    if len(list_of_files) > 1:\n",
        "        os.remove(list_of_files[-2])\n",
        "\n",
        "def load_checkpoint(optimizer_name, batch_size, hyperparameters):\n",
        "    # dir_path = f\"/content/gdrive/MyDrive/{optimizer_name}/{batch_size}/\"\n",
        "    dir_path = f\"./train/{optimizer_name}/{batch_size}/\"\n",
        "    for key, value in hyperparameters.items():\n",
        "        dir_path = os.path.join(dir_path, f\"{key}_{value}/\")\n",
        "    list_of_files = glob.glob(os.path.join(dir_path, f\"epoch_*.pt\")) # * means all if need specific format then *.csv\n",
        "    if not list_of_files:  # I'm using glob which can return an empty list\n",
        "        return None\n",
        "    latest_file = max(list_of_files, key=os.path.getctime)\n",
        "    if os.path.isfile(latest_file):\n",
        "        return torch.load(latest_file)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "9Yjx-yZf-Sbz"
      },
      "outputs": [],
      "source": [
        "def run_training(\n",
        "    num_epochs,\n",
        "    model,\n",
        "    trainloader,\n",
        "    validationloader,\n",
        "    testloader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    optimizer_name: str,\n",
        "    accumulation_steps=1,\n",
        "    hyperparameters=None,\n",
        "    is_wandb = False,\n",
        "    n_epochs_stop = None,\n",
        "    warmup_ratio = 0\n",
        "  ):\n",
        "\n",
        "  best_accuracy = 0\n",
        "  epochs_no_improve = 0\n",
        "  warmup_steps = int(warmup_ratio * num_epochs)\n",
        "  lr = optimizer.param_groups[0]['lr']\n",
        "  \n",
        "  start_epoch = 0\n",
        "  run_id = None\n",
        "  run_name = None\n",
        "  # Load checkpoint if available\n",
        "  checkpoint = load_checkpoint(optimizer_name, trainloader.batch_size, hyperparameters)\n",
        "  if checkpoint is not None:\n",
        "      model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      start_epoch = checkpoint['epoch'] + 1\n",
        "      run_id = checkpoint.get('wandb_run_id', None)\n",
        "      run_name = checkpoint.get('wandb_run_name', None)\n",
        "\n",
        "  else:\n",
        "    run_name = \" \".join([f\"{key}={value}\" for key, value in hyperparameters.items()])\n",
        "\n",
        "  if is_wandb:\n",
        "    # Initialize a wandb run with the given hyperparameters\n",
        "    wandb.init(id=run_id, name=run_name, project=f'cifar100-training-mldl2024-baseline-{optimizer_name}',\n",
        "                   config=hyperparameters if hyperparameters is not None else {},\n",
        "                   resume=\"allow\", reinit=True)\n",
        "\n",
        "  for epoch in range(start_epoch, num_epochs):\n",
        "      if epoch < warmup_steps:\n",
        "        optimizer.param_groups[0]['lr'] = lr * epoch / warmup_steps\n",
        "      elif epoch == warmup_steps:\n",
        "        optimizer.param_groups[0]['lr'] = lr\n",
        "          \n",
        "      # Call the training function for each epoch\n",
        "      train_loss, train_acc = train(model, trainloader, optimizer, loss_fn, accumulation_steps, device, is_wandb=is_wandb)\n",
        "      print(f'[{epoch+1}/{num_epochs}]: Training Loss: {train_loss}, Training Accuracy: {train_acc}')\n",
        "      scheduler.step() # Update learning rate based on scheduler\n",
        "\n",
        "      # Save checkpoint\n",
        "      save_checkpoint({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'loss': criterion,\n",
        "                    'wandb_run_id': wandb.run.id if is_wandb else None,\n",
        "                    'wandb_run_name': wandb.run.name if is_wandb else None,\n",
        "                    }, epoch, trainloader.batch_size, optimizer_name, hyperparameters)\n",
        "\n",
        "      if validationloader is not None:\n",
        "        val_loss, val_acc = test(model, validationloader, criterion)\n",
        "        print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
        "\n",
        "\n",
        "        if n_epochs_stop is not None:\n",
        "          if val_acc > best_accuracy:\n",
        "                best_accuracy = val_acc\n",
        "                epochs_no_improve = 0\n",
        "          else:\n",
        "              epochs_no_improve += 1\n",
        "              if epochs_no_improve == n_epochs_stop:\n",
        "                  print('Early stopping!')\n",
        "                  break\n",
        "\n",
        "  print('*'*70)\n",
        "  test_loss, test_acc = test(model, testloader, criterion, is_wandb = is_wandb)\n",
        "  print(f'Test Loss: {test_loss}, Test Accuracy: {test_acc}')\n",
        "\n",
        "\n",
        "  # Finish the wandb run after all epochs\n",
        "  wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taX_5ElNuKxC"
      },
      "source": [
        "# **Centeralised baseline**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "8hxWmieIE7jF"
      },
      "outputs": [],
      "source": [
        "learning_rates = [1e-03, 1e-02]\n",
        "weight_decays = [1e-04, 1e-03, 4e-04]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SGDM (Stochastic Gradient Descent with Momentum)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8587c890f2a847e293a101405d64fc0d",
            "175043eb44e44b4f9aefaf51aae6fb10",
            "db36d0cc7691440a9792ac779e161e62",
            "c6a68af25a2847e98201847781419670",
            "71e710b571d142a3a08cd233590b7171",
            "2671c3bf3cfd49aa9ad6841c289068cc",
            "45bdcbbed9ae47ffb24bd2a962345eaa",
            "bcbeb5bacc824f3aacd20e50d38bb70a",
            "2991ead42a2a4637b2902ca26837d74b",
            "9e0bb90e33ec4e198857c255080ef6f0",
            "77790c4dcd124f73907619689fb8d37c",
            "1fef0782f0804736881f03c2e31c3d64",
            "3606009883cf4212b7e1ed6e4f182845",
            "39aecb8ffe0645fbadccf8b0f8ed2486",
            "13e7a0db2aa74e35b7d1948224358d76",
            "7064cd1e5d794c258dbeeb63a9ae9f9b",
            "5cf516644d1a4ebf82c7e9dfa13e560b",
            "36a546b812d6403cbf5ed693318a9744",
            "aed05a015df946c7bae33226c3a8ddc6",
            "d601ef3ebb6c4b688ac53a65979aa445",
            "e4a5f301338a4e5185c042a22684ed4a",
            "48c7de7682f242fd86a234d1607187f4",
            "403dcd5f10de42ddbb67c8108e3bc34c",
            "a1d013e4d3e942b6b362ab5ade6d1a80",
            "e851c69b66ca4e8a80779a69435b855f",
            "4b733fc6800e4a0ab36bba52ff84f1a5",
            "dcbb358118e644a2a75d44d8adb6747b",
            "829bba2a5bb947a0bcf121c527902255",
            "7e2cc873f917444c833e152f7c2555de",
            "49727de0590f41dca6addf3f4ffe33f2",
            "60957598b6c64ab0987d583b788dd674",
            "e4ad17a7648245069c70f2f3fb79105a",
            "431cf75dd1cc4840b14f678876f45bc9",
            "a5f3871113994f1eb993c126d793d147",
            "7903555c1e884408b70c9951ecae84ec",
            "2d65b320aaed40cd87b8f78c99c614e7",
            "346856a22f0e45b2be0c14aa7902261f",
            "397b6d4daaf04a1181413adc5e30db0c",
            "ac87babb2f2a4781ab863c3b8f613807",
            "b3970cfd36ed4450b7c8f958a6499dc4",
            "df97494c2f654ffbaceb9ca801ff3113",
            "e1e5353cb6a1427a8b0b9d91d6067ef7",
            "77c702b6d9c04f00b8e624f31a591f01",
            "8795a05c814c469083b31be62e79289f",
            "829eee71e4d74403a22941b15dfcf9bc",
            "ab0b891f55f648cdbace9bc4540c51c6",
            "e6d67121f0ab4daf96d0bdd2c433259b",
            "3ee2c346d4d74faa915ef8315e3303c8"
          ]
        },
        "id": "9rGKhc7FJB8u",
        "outputId": "9b4eddc5-dc51-4af2-fdbe-4ba3175d3642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240611_235508-gw8sn909</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">learning_rate=0.001 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[10/150]: Training Loss: 3.7955315692901612, Training Accuracy: 12.3825\n",
            "Validation Loss: 3.7704276780413974, Validation Accuracy: 12.97\n",
            "[11/150]: Training Loss: 3.693796951675415, Training Accuracy: 14.2675\n",
            "Validation Loss: 3.6661312990127857, Validation Accuracy: 14.76\n",
            "[12/150]: Training Loss: 3.5919596023559572, Training Accuracy: 16.0125\n",
            "Validation Loss: 3.5912161389733575, Validation Accuracy: 16.26\n",
            "[13/150]: Training Loss: 3.5116733703613283, Training Accuracy: 17.3775\n",
            "Validation Loss: 3.5196323546634356, Validation Accuracy: 16.95\n",
            "[14/150]: Training Loss: 3.4402521675109865, Training Accuracy: 18.835\n",
            "Validation Loss: 3.4998342930131656, Validation Accuracy: 17.78\n",
            "[15/150]: Training Loss: 3.374294019317627, Training Accuracy: 19.835\n",
            "Validation Loss: 3.412280123704558, Validation Accuracy: 19.05\n",
            "[16/150]: Training Loss: 3.3126377914428713, Training Accuracy: 20.9225\n",
            "Validation Loss: 3.3567575497232425, Validation Accuracy: 20.21\n",
            "[17/150]: Training Loss: 3.264142190551758, Training Accuracy: 21.7475\n",
            "Validation Loss: 3.3158142976700122, Validation Accuracy: 20.54\n",
            "[18/150]: Training Loss: 3.212448757171631, Training Accuracy: 22.925\n",
            "Validation Loss: 3.288792388454364, Validation Accuracy: 21.5\n",
            "[19/150]: Training Loss: 3.16608261680603, Training Accuracy: 23.6325\n",
            "Validation Loss: 3.247776625262704, Validation Accuracy: 22.28\n",
            "[20/150]: Training Loss: 3.1185284183502198, Training Accuracy: 24.565\n",
            "Validation Loss: 3.2615917640127194, Validation Accuracy: 21.82\n",
            "[21/150]: Training Loss: 3.0692719429016115, Training Accuracy: 25.24\n",
            "Validation Loss: 3.188312981538712, Validation Accuracy: 23.06\n",
            "[22/150]: Training Loss: 3.0227535221099853, Training Accuracy: 26.3125\n",
            "Validation Loss: 3.189725389905796, Validation Accuracy: 23.3\n",
            "[23/150]: Training Loss: 2.9822758083343506, Training Accuracy: 26.9425\n",
            "Validation Loss: 3.1865678501736587, Validation Accuracy: 24.06\n",
            "[24/150]: Training Loss: 2.9383605140686035, Training Accuracy: 27.7575\n",
            "Validation Loss: 3.1210442075304163, Validation Accuracy: 25.28\n",
            "[25/150]: Training Loss: 2.8941220123291016, Training Accuracy: 28.8275\n",
            "Validation Loss: 3.0783458576080904, Validation Accuracy: 26.38\n",
            "[26/150]: Training Loss: 2.846640188598633, Training Accuracy: 29.6625\n",
            "Validation Loss: 3.0489486524253895, Validation Accuracy: 26.15\n",
            "[27/150]: Training Loss: 2.803463589859009, Training Accuracy: 30.53\n",
            "Validation Loss: 3.0650304320511546, Validation Accuracy: 26.3\n",
            "[28/150]: Training Loss: 2.7623793058395387, Training Accuracy: 31.4175\n",
            "Validation Loss: 3.016696295161156, Validation Accuracy: 27.16\n",
            "[29/150]: Training Loss: 2.724277519607544, Training Accuracy: 31.9075\n",
            "Validation Loss: 3.001434786304547, Validation Accuracy: 27.8\n",
            "[30/150]: Training Loss: 2.6789874454498293, Training Accuracy: 33.0275\n",
            "Validation Loss: 3.016883801502787, Validation Accuracy: 27.3\n",
            "[31/150]: Training Loss: 2.639483213806152, Training Accuracy: 33.66\n",
            "Validation Loss: 2.98876147361318, Validation Accuracy: 28.67\n",
            "[32/150]: Training Loss: 2.5927667430877683, Training Accuracy: 34.5325\n",
            "Validation Loss: 2.994789396881298, Validation Accuracy: 27.54\n",
            "[33/150]: Training Loss: 2.5531089670181273, Training Accuracy: 35.2525\n",
            "Validation Loss: 2.997880709399084, Validation Accuracy: 28.54\n",
            "[34/150]: Training Loss: 2.5080887552261353, Training Accuracy: 36.16\n",
            "Validation Loss: 2.9557720460709493, Validation Accuracy: 29.05\n",
            "[35/150]: Training Loss: 2.470765545463562, Training Accuracy: 37.03\n",
            "Validation Loss: 2.960252163516488, Validation Accuracy: 29.2\n",
            "[36/150]: Training Loss: 2.4253519346237185, Training Accuracy: 37.9225\n",
            "Validation Loss: 2.9324972644733016, Validation Accuracy: 29.32\n",
            "[37/150]: Training Loss: 2.3800090463638304, Training Accuracy: 39.06\n",
            "Validation Loss: 2.9341223923264037, Validation Accuracy: 30.21\n",
            "[38/150]: Training Loss: 2.3413858253479005, Training Accuracy: 39.57\n",
            "Validation Loss: 2.9640257130762575, Validation Accuracy: 29.88\n",
            "[39/150]: Training Loss: 2.301597819519043, Training Accuracy: 40.4175\n",
            "Validation Loss: 3.0218158800890493, Validation Accuracy: 28.21\n",
            "[40/150]: Training Loss: 2.2570854791641235, Training Accuracy: 41.3725\n",
            "Validation Loss: 3.0180870347721562, Validation Accuracy: 29.27\n",
            "[41/150]: Training Loss: 2.2198365371704103, Training Accuracy: 42.375\n",
            "Validation Loss: 2.938889775306556, Validation Accuracy: 30.41\n",
            "[42/150]: Training Loss: 2.1788083906173705, Training Accuracy: 43.24\n",
            "Validation Loss: 2.931537726882157, Validation Accuracy: 30.24\n",
            "[43/150]: Training Loss: 2.130757416725159, Training Accuracy: 44.2975\n",
            "Validation Loss: 2.935111481672639, Validation Accuracy: 30.94\n",
            "[44/150]: Training Loss: 2.0930950580596925, Training Accuracy: 45.0275\n",
            "Validation Loss: 2.9872301232283283, Validation Accuracy: 30.88\n",
            "[45/150]: Training Loss: 2.0451603315353393, Training Accuracy: 46.14\n",
            "Validation Loss: 2.9818537857881777, Validation Accuracy: 30.2\n",
            "[46/150]: Training Loss: 2.004084638786316, Training Accuracy: 47.0275\n",
            "Validation Loss: 2.995785168022107, Validation Accuracy: 30.23\n",
            "[47/150]: Training Loss: 1.9692718086242675, Training Accuracy: 47.845\n",
            "Validation Loss: 3.0542795536624396, Validation Accuracy: 30.14\n",
            "[48/150]: Training Loss: 1.9216952280044555, Training Accuracy: 48.8675\n",
            "Validation Loss: 2.9834766873888148, Validation Accuracy: 31.12\n",
            "[49/150]: Training Loss: 1.8784988208770752, Training Accuracy: 49.9625\n",
            "Validation Loss: 3.0277192516691365, Validation Accuracy: 31.11\n",
            "[50/150]: Training Loss: 1.8381427211761474, Training Accuracy: 50.9275\n",
            "Validation Loss: 3.062338437244391, Validation Accuracy: 31.08\n",
            "[51/150]: Training Loss: 1.7901163187026978, Training Accuracy: 52.055\n",
            "Validation Loss: 3.1062804225144114, Validation Accuracy: 30.8\n",
            "[52/150]: Training Loss: 1.7526374937057496, Training Accuracy: 52.695\n",
            "Validation Loss: 3.121828522651818, Validation Accuracy: 31.1\n",
            "[53/150]: Training Loss: 1.7035991048812866, Training Accuracy: 53.87\n",
            "Validation Loss: 3.1324675629852683, Validation Accuracy: 30.77\n",
            "[54/150]: Training Loss: 1.6695509649276734, Training Accuracy: 54.6\n",
            "Validation Loss: 3.1344476976212423, Validation Accuracy: 30.74\n",
            "[55/150]: Training Loss: 1.6191298002243042, Training Accuracy: 55.795\n",
            "Validation Loss: 3.2295576159361823, Validation Accuracy: 29.87\n",
            "[56/150]: Training Loss: 1.5762285459518433, Training Accuracy: 56.7875\n",
            "Validation Loss: 3.242111048121361, Validation Accuracy: 30.56\n",
            "[57/150]: Training Loss: 1.5393764123916627, Training Accuracy: 58.005\n",
            "Validation Loss: 3.303940733526922, Validation Accuracy: 29.53\n",
            "[58/150]: Training Loss: 1.4886947209358214, Training Accuracy: 59.32\n",
            "Validation Loss: 3.306815612088343, Validation Accuracy: 30.63\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 12.757227435992782, Test Accuracy: 12.53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.53</td></tr><tr><td>Test Loss</td><td>12.75723</td></tr><tr><td>Train Accuracy</td><td>59.32</td></tr><tr><td>Train Loss</td><td>1.48869</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/gw8sn909</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240611_235508-gw8sn909/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240611_235923-9i8aijvl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">learning_rate=0.001 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605354942321777, Training Accuracy: 1.0075\n",
            "Validation Loss: 4.604883777108162, Validation Accuracy: 0.9\n",
            "[2/150]: Training Loss: 4.602973918151855, Training Accuracy: 1.0475\n",
            "Validation Loss: 4.6016397293965525, Validation Accuracy: 0.9\n",
            "[3/150]: Training Loss: 4.596875128936768, Training Accuracy: 1.3425\n",
            "Validation Loss: 4.590152442834939, Validation Accuracy: 2.52\n",
            "[4/150]: Training Loss: 4.556022624969483, Training Accuracy: 2.9175\n",
            "Validation Loss: 4.472016604842653, Validation Accuracy: 3.55\n",
            "[5/150]: Training Loss: 4.280242394256592, Training Accuracy: 4.6625\n",
            "Validation Loss: 4.20257385673037, Validation Accuracy: 5.95\n",
            "[6/150]: Training Loss: 4.122820203781128, Training Accuracy: 6.5925\n",
            "Validation Loss: 4.098185727550725, Validation Accuracy: 6.72\n",
            "[7/150]: Training Loss: 4.0448949375152585, Training Accuracy: 7.655\n",
            "Validation Loss: 4.033748802865387, Validation Accuracy: 8.54\n",
            "[8/150]: Training Loss: 3.977578921508789, Training Accuracy: 9.06\n",
            "Validation Loss: 3.970679567118359, Validation Accuracy: 8.73\n",
            "[9/150]: Training Loss: 3.9144488010406495, Training Accuracy: 9.9875\n",
            "Validation Loss: 3.902484763200116, Validation Accuracy: 10.84\n",
            "[10/150]: Training Loss: 3.8504066452026366, Training Accuracy: 11.2025\n",
            "Validation Loss: 3.853308222096437, Validation Accuracy: 11.05\n",
            "[11/150]: Training Loss: 3.776761824798584, Training Accuracy: 12.605\n",
            "Validation Loss: 3.7683646602995076, Validation Accuracy: 13.16\n",
            "[12/150]: Training Loss: 3.6920017036437986, Training Accuracy: 14.09\n",
            "Validation Loss: 3.712872941023225, Validation Accuracy: 13.54\n",
            "[13/150]: Training Loss: 3.617317741394043, Training Accuracy: 15.2475\n",
            "Validation Loss: 3.619570322097487, Validation Accuracy: 14.95\n",
            "[14/150]: Training Loss: 3.5433271072387695, Training Accuracy: 16.7275\n",
            "Validation Loss: 3.5456171734317854, Validation Accuracy: 16.81\n",
            "[15/150]: Training Loss: 3.47977327041626, Training Accuracy: 17.6525\n",
            "Validation Loss: 3.503120666856219, Validation Accuracy: 17.12\n",
            "[16/150]: Training Loss: 3.4149503967285155, Training Accuracy: 18.85\n",
            "Validation Loss: 3.449874220380358, Validation Accuracy: 17.98\n",
            "[17/150]: Training Loss: 3.357447999191284, Training Accuracy: 20.3025\n",
            "Validation Loss: 3.3906334479143667, Validation Accuracy: 19.6\n",
            "[18/150]: Training Loss: 3.3055746353149416, Training Accuracy: 20.985\n",
            "Validation Loss: 3.34384480859064, Validation Accuracy: 20.15\n",
            "[19/150]: Training Loss: 3.249339769363403, Training Accuracy: 21.955\n",
            "Validation Loss: 3.3408105813773576, Validation Accuracy: 20.75\n",
            "[20/150]: Training Loss: 3.2052097175598147, Training Accuracy: 22.84\n",
            "Validation Loss: 3.3127595497544404, Validation Accuracy: 21.29\n",
            "[21/150]: Training Loss: 3.150541979598999, Training Accuracy: 23.8475\n",
            "Validation Loss: 3.267914258750381, Validation Accuracy: 22.13\n",
            "[22/150]: Training Loss: 3.1069109004974367, Training Accuracy: 24.64\n",
            "Validation Loss: 3.2093709350391557, Validation Accuracy: 23.03\n",
            "[23/150]: Training Loss: 3.0725105766296386, Training Accuracy: 25.155\n",
            "Validation Loss: 3.2081045861456805, Validation Accuracy: 23.23\n",
            "[24/150]: Training Loss: 3.0264828220367432, Training Accuracy: 26.165\n",
            "Validation Loss: 3.153175331225061, Validation Accuracy: 23.9\n",
            "[25/150]: Training Loss: 2.9784529972076417, Training Accuracy: 27.0575\n",
            "Validation Loss: 3.120233716478773, Validation Accuracy: 24.62\n",
            "[26/150]: Training Loss: 2.9407661106109617, Training Accuracy: 27.7025\n",
            "Validation Loss: 3.122152067293787, Validation Accuracy: 25.03\n",
            "[27/150]: Training Loss: 2.9034343135833742, Training Accuracy: 28.395\n",
            "Validation Loss: 3.062598638473802, Validation Accuracy: 25.75\n",
            "[28/150]: Training Loss: 2.859911437988281, Training Accuracy: 29.1425\n",
            "Validation Loss: 3.0851597072212558, Validation Accuracy: 26.24\n",
            "[29/150]: Training Loss: 2.825396254348755, Training Accuracy: 29.9575\n",
            "Validation Loss: 3.0798455939930713, Validation Accuracy: 25.39\n",
            "[30/150]: Training Loss: 2.783854722213745, Training Accuracy: 30.46\n",
            "Validation Loss: 2.994018077850342, Validation Accuracy: 27.4\n",
            "[31/150]: Training Loss: 2.7530001544952394, Training Accuracy: 31.445\n",
            "Validation Loss: 3.023551480785297, Validation Accuracy: 26.3\n",
            "[32/150]: Training Loss: 2.715887685775757, Training Accuracy: 31.8725\n",
            "Validation Loss: 2.966492583037941, Validation Accuracy: 27.56\n",
            "[33/150]: Training Loss: 2.673046026611328, Training Accuracy: 32.72\n",
            "Validation Loss: 2.9745204934648646, Validation Accuracy: 27.99\n",
            "[34/150]: Training Loss: 2.6407437208175657, Training Accuracy: 33.34\n",
            "Validation Loss: 2.942354439170497, Validation Accuracy: 29.0\n",
            "[35/150]: Training Loss: 2.5946556980133058, Training Accuracy: 34.7025\n",
            "Validation Loss: 2.930390673837844, Validation Accuracy: 28.88\n",
            "[36/150]: Training Loss: 2.560257712173462, Training Accuracy: 35.2025\n",
            "Validation Loss: 2.9051667292406607, Validation Accuracy: 29.88\n",
            "[37/150]: Training Loss: 2.5238379081726072, Training Accuracy: 35.76\n",
            "Validation Loss: 2.890098687190159, Validation Accuracy: 29.33\n",
            "[38/150]: Training Loss: 2.486947275352478, Training Accuracy: 36.69\n",
            "Validation Loss: 2.9050150206134577, Validation Accuracy: 29.6\n",
            "[39/150]: Training Loss: 2.452709559249878, Training Accuracy: 37.475\n",
            "Validation Loss: 2.8899250182376544, Validation Accuracy: 29.65\n",
            "[40/150]: Training Loss: 2.4208646841049193, Training Accuracy: 37.9575\n",
            "Validation Loss: 2.9285842643421924, Validation Accuracy: 29.49\n",
            "[41/150]: Training Loss: 2.3780534410476686, Training Accuracy: 38.925\n",
            "Validation Loss: 2.896095122501349, Validation Accuracy: 30.27\n",
            "[42/150]: Training Loss: 2.3445595056533812, Training Accuracy: 39.4975\n",
            "Validation Loss: 2.903249968389037, Validation Accuracy: 29.49\n",
            "[43/150]: Training Loss: 2.3128848968505857, Training Accuracy: 40.2375\n",
            "Validation Loss: 2.8930906854617366, Validation Accuracy: 30.18\n",
            "[44/150]: Training Loss: 2.275460436248779, Training Accuracy: 40.965\n",
            "Validation Loss: 2.847154028096776, Validation Accuracy: 30.73\n",
            "[45/150]: Training Loss: 2.2384806400299073, Training Accuracy: 41.705\n",
            "Validation Loss: 2.898577917912963, Validation Accuracy: 30.18\n",
            "[46/150]: Training Loss: 2.214237283706665, Training Accuracy: 42.415\n",
            "Validation Loss: 2.8367908441337053, Validation Accuracy: 31.94\n",
            "[47/150]: Training Loss: 2.174029080581665, Training Accuracy: 43.2825\n",
            "Validation Loss: 2.8599718254842577, Validation Accuracy: 31.4\n",
            "[48/150]: Training Loss: 2.134048504257202, Training Accuracy: 44.0225\n",
            "Validation Loss: 2.8570211207031444, Validation Accuracy: 31.32\n",
            "[49/150]: Training Loss: 2.1011022747039796, Training Accuracy: 44.7675\n",
            "Validation Loss: 2.876888126324696, Validation Accuracy: 31.24\n",
            "[50/150]: Training Loss: 2.066174629211426, Training Accuracy: 45.84\n",
            "Validation Loss: 2.873898560833779, Validation Accuracy: 31.01\n",
            "[51/150]: Training Loss: 2.0310755935668947, Training Accuracy: 46.2775\n",
            "Validation Loss: 2.8654664003165666, Validation Accuracy: 31.98\n",
            "[52/150]: Training Loss: 1.9909400806427002, Training Accuracy: 47.45\n",
            "Validation Loss: 2.8746210936528103, Validation Accuracy: 31.69\n",
            "[53/150]: Training Loss: 1.9579231163024902, Training Accuracy: 48.0525\n",
            "Validation Loss: 2.8748430902031576, Validation Accuracy: 31.57\n",
            "[54/150]: Training Loss: 1.9230639179229736, Training Accuracy: 48.785\n",
            "Validation Loss: 2.910501542364716, Validation Accuracy: 31.56\n",
            "[55/150]: Training Loss: 1.8876561931610107, Training Accuracy: 49.645\n",
            "Validation Loss: 2.8805068404811203, Validation Accuracy: 32.02\n",
            "[56/150]: Training Loss: 1.8495587772369384, Training Accuracy: 50.57\n",
            "Validation Loss: 2.9215301510634695, Validation Accuracy: 31.68\n",
            "[57/150]: Training Loss: 1.8102108228683471, Training Accuracy: 51.2975\n",
            "Validation Loss: 2.926473318391545, Validation Accuracy: 32.35\n",
            "[58/150]: Training Loss: 1.7818908670425415, Training Accuracy: 52.1325\n",
            "Validation Loss: 2.9246792929947, Validation Accuracy: 32.57\n",
            "[59/150]: Training Loss: 1.7456034435272216, Training Accuracy: 52.775\n",
            "Validation Loss: 2.984062427168439, Validation Accuracy: 31.53\n",
            "[60/150]: Training Loss: 1.706142727279663, Training Accuracy: 53.955\n",
            "Validation Loss: 2.9781496843714623, Validation Accuracy: 32.57\n",
            "[61/150]: Training Loss: 1.6744635740280152, Training Accuracy: 54.59\n",
            "Validation Loss: 3.0356672569444982, Validation Accuracy: 31.58\n",
            "[62/150]: Training Loss: 1.6349090488433837, Training Accuracy: 55.5975\n",
            "Validation Loss: 3.0081513763233354, Validation Accuracy: 32.09\n",
            "[63/150]: Training Loss: 1.6007863130569457, Training Accuracy: 56.41\n",
            "Validation Loss: 3.032350327558578, Validation Accuracy: 32.3\n",
            "[64/150]: Training Loss: 1.5609112140655517, Training Accuracy: 57.235\n",
            "Validation Loss: 3.077729872077893, Validation Accuracy: 31.42\n",
            "[65/150]: Training Loss: 1.5253083936691285, Training Accuracy: 58.1475\n",
            "Validation Loss: 3.0732312840261278, Validation Accuracy: 32.72\n",
            "[66/150]: Training Loss: 1.4928287380218506, Training Accuracy: 59.1925\n",
            "Validation Loss: 3.0616249688871346, Validation Accuracy: 31.97\n",
            "[67/150]: Training Loss: 1.4535140877723693, Training Accuracy: 60.1225\n",
            "Validation Loss: 3.124178699627044, Validation Accuracy: 32.15\n",
            "[68/150]: Training Loss: 1.4196137544631957, Training Accuracy: 60.7675\n",
            "Validation Loss: 3.2008153435530935, Validation Accuracy: 31.3\n",
            "[69/150]: Training Loss: 1.3877691086769104, Training Accuracy: 61.4575\n",
            "Validation Loss: 3.1977471834535054, Validation Accuracy: 31.22\n",
            "[70/150]: Training Loss: 1.3564362874031066, Training Accuracy: 62.2125\n",
            "Validation Loss: 3.2483551836317512, Validation Accuracy: 31.49\n",
            "[71/150]: Training Loss: 1.3180213891029358, Training Accuracy: 63.6275\n",
            "Validation Loss: 3.3253093616218323, Validation Accuracy: 31.54\n",
            "[72/150]: Training Loss: 1.2782609523773194, Training Accuracy: 64.6325\n",
            "Validation Loss: 3.300645703722717, Validation Accuracy: 32.03\n",
            "[73/150]: Training Loss: 1.2435202094078064, Training Accuracy: 65.5975\n",
            "Validation Loss: 3.340803805430224, Validation Accuracy: 31.19\n",
            "[74/150]: Training Loss: 1.2111891516685487, Training Accuracy: 66.105\n",
            "Validation Loss: 3.3482626076716526, Validation Accuracy: 31.98\n",
            "[75/150]: Training Loss: 1.1782402634620666, Training Accuracy: 67.3425\n",
            "Validation Loss: 3.442917116128715, Validation Accuracy: 31.68\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 15.762403002210483, Test Accuracy: 12.36\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.36</td></tr><tr><td>Test Loss</td><td>15.7624</td></tr><tr><td>Train Accuracy</td><td>67.3425</td></tr><tr><td>Train Loss</td><td>1.17824</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/9i8aijvl</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240611_235923-9i8aijvl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_002202-8lcpcbs2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605505518341064, Training Accuracy: 1.0675\n",
            "Validation Loss: 4.60469646514601, Validation Accuracy: 0.9\n",
            "[2/150]: Training Loss: 4.603742761993408, Training Accuracy: 1.0775\n",
            "Validation Loss: 4.602513228252435, Validation Accuracy: 0.97\n",
            "[3/150]: Training Loss: 4.60020831451416, Training Accuracy: 1.42\n",
            "Validation Loss: 4.596951505940432, Validation Accuracy: 1.39\n",
            "[4/150]: Training Loss: 4.590583048248291, Training Accuracy: 1.345\n",
            "Validation Loss: 4.579934718502555, Validation Accuracy: 1.81\n",
            "[5/150]: Training Loss: 4.522595316314697, Training Accuracy: 2.9\n",
            "Validation Loss: 4.390095902096694, Validation Accuracy: 3.43\n",
            "[6/150]: Training Loss: 4.228593465805054, Training Accuracy: 5.2625\n",
            "Validation Loss: 4.173950313762495, Validation Accuracy: 5.48\n",
            "[7/150]: Training Loss: 4.1090137573242185, Training Accuracy: 6.88\n",
            "Validation Loss: 4.087003700292794, Validation Accuracy: 7.44\n",
            "[8/150]: Training Loss: 4.035317427825928, Training Accuracy: 8.06\n",
            "Validation Loss: 4.015521998618059, Validation Accuracy: 8.52\n",
            "[9/150]: Training Loss: 3.960421589279175, Training Accuracy: 9.445\n",
            "Validation Loss: 3.9580009849208175, Validation Accuracy: 9.3\n",
            "[10/150]: Training Loss: 3.8591443000793455, Training Accuracy: 11.34\n",
            "Validation Loss: 3.84393062105604, Validation Accuracy: 11.61\n",
            "[11/150]: Training Loss: 3.7639447425842287, Training Accuracy: 12.9725\n",
            "Validation Loss: 3.7741037219952625, Validation Accuracy: 12.76\n",
            "[12/150]: Training Loss: 3.6964004222869873, Training Accuracy: 14.225\n",
            "Validation Loss: 3.6935869903321477, Validation Accuracy: 14.02\n",
            "[13/150]: Training Loss: 3.6246248401641847, Training Accuracy: 15.4325\n",
            "Validation Loss: 3.6313245053503924, Validation Accuracy: 15.35\n",
            "[14/150]: Training Loss: 3.5586987380981445, Training Accuracy: 16.58\n",
            "Validation Loss: 3.570704687932494, Validation Accuracy: 16.63\n",
            "[15/150]: Training Loss: 3.492145662689209, Training Accuracy: 17.56\n",
            "Validation Loss: 3.5174384117126465, Validation Accuracy: 17.05\n",
            "[16/150]: Training Loss: 3.4223767150878905, Training Accuracy: 18.875\n",
            "Validation Loss: 3.4360159157188077, Validation Accuracy: 18.52\n",
            "[17/150]: Training Loss: 3.3623727890014647, Training Accuracy: 19.63\n",
            "Validation Loss: 3.3825773327213944, Validation Accuracy: 19.78\n",
            "[18/150]: Training Loss: 3.3074194034576414, Training Accuracy: 20.8975\n",
            "Validation Loss: 3.3404667316728336, Validation Accuracy: 20.19\n",
            "[19/150]: Training Loss: 3.251063732147217, Training Accuracy: 21.8975\n",
            "Validation Loss: 3.312105529627223, Validation Accuracy: 20.9\n",
            "[20/150]: Training Loss: 3.204967420578003, Training Accuracy: 22.7225\n",
            "Validation Loss: 3.2530917027953326, Validation Accuracy: 22.31\n",
            "[21/150]: Training Loss: 3.15532322807312, Training Accuracy: 23.64\n",
            "Validation Loss: 3.229210142876692, Validation Accuracy: 22.45\n",
            "[22/150]: Training Loss: 3.1103267768859864, Training Accuracy: 24.38\n",
            "Validation Loss: 3.213347544336015, Validation Accuracy: 23.38\n",
            "[23/150]: Training Loss: 3.0626929641723635, Training Accuracy: 25.55\n",
            "Validation Loss: 3.181753307391124, Validation Accuracy: 24.04\n",
            "[24/150]: Training Loss: 3.01508925819397, Training Accuracy: 26.1675\n",
            "Validation Loss: 3.159736381214895, Validation Accuracy: 24.07\n",
            "[25/150]: Training Loss: 2.977297193527222, Training Accuracy: 26.95\n",
            "Validation Loss: 3.139521881273598, Validation Accuracy: 24.65\n",
            "[26/150]: Training Loss: 2.9348321487426756, Training Accuracy: 27.76\n",
            "Validation Loss: 3.129030877617514, Validation Accuracy: 25.02\n",
            "[27/150]: Training Loss: 2.892203674316406, Training Accuracy: 28.71\n",
            "Validation Loss: 3.1089744279339055, Validation Accuracy: 24.88\n",
            "[28/150]: Training Loss: 2.8514965145111084, Training Accuracy: 29.41\n",
            "Validation Loss: 3.0390360476864373, Validation Accuracy: 26.37\n",
            "[29/150]: Training Loss: 2.8064930957794187, Training Accuracy: 30.3275\n",
            "Validation Loss: 3.0866621254356046, Validation Accuracy: 26.25\n",
            "[30/150]: Training Loss: 2.771508701324463, Training Accuracy: 30.8325\n",
            "Validation Loss: 3.034489528388734, Validation Accuracy: 26.79\n",
            "[31/150]: Training Loss: 2.726985428237915, Training Accuracy: 32.06\n",
            "Validation Loss: 2.994590279403006, Validation Accuracy: 27.49\n",
            "[32/150]: Training Loss: 2.693068378448486, Training Accuracy: 32.6375\n",
            "Validation Loss: 2.991791993949064, Validation Accuracy: 27.57\n",
            "[33/150]: Training Loss: 2.6538521224975584, Training Accuracy: 33.305\n",
            "Validation Loss: 2.9930253712234984, Validation Accuracy: 27.59\n",
            "[34/150]: Training Loss: 2.6168819108963013, Training Accuracy: 33.9675\n",
            "Validation Loss: 2.9458029012011875, Validation Accuracy: 28.63\n",
            "[35/150]: Training Loss: 2.5724296060562133, Training Accuracy: 34.885\n",
            "Validation Loss: 2.9706625437280936, Validation Accuracy: 28.37\n",
            "[36/150]: Training Loss: 2.532205513381958, Training Accuracy: 35.7275\n",
            "Validation Loss: 3.0205048026552626, Validation Accuracy: 27.62\n",
            "[37/150]: Training Loss: 2.501378486442566, Training Accuracy: 36.655\n",
            "Validation Loss: 2.9459367466580337, Validation Accuracy: 29.16\n",
            "[38/150]: Training Loss: 2.4599771045684813, Training Accuracy: 37.265\n",
            "Validation Loss: 2.9162613555883907, Validation Accuracy: 29.42\n",
            "[39/150]: Training Loss: 2.416532469558716, Training Accuracy: 38.265\n",
            "Validation Loss: 2.9226647676176327, Validation Accuracy: 29.71\n",
            "[40/150]: Training Loss: 2.377360425758362, Training Accuracy: 39.1\n",
            "Validation Loss: 2.912419487716286, Validation Accuracy: 30.24\n",
            "[41/150]: Training Loss: 2.3416698053359983, Training Accuracy: 39.7725\n",
            "Validation Loss: 2.9336505536061184, Validation Accuracy: 29.72\n",
            "[42/150]: Training Loss: 2.302257305908203, Training Accuracy: 40.6025\n",
            "Validation Loss: 2.9164519552971906, Validation Accuracy: 30.29\n",
            "[43/150]: Training Loss: 2.2648201442718507, Training Accuracy: 41.4425\n",
            "Validation Loss: 2.917926338068239, Validation Accuracy: 30.33\n",
            "[44/150]: Training Loss: 2.2238695373535156, Training Accuracy: 42.1875\n",
            "Validation Loss: 2.920909085091512, Validation Accuracy: 30.59\n",
            "[45/150]: Training Loss: 2.186175981903076, Training Accuracy: 43.1875\n",
            "Validation Loss: 2.979639395027404, Validation Accuracy: 29.65\n",
            "[46/150]: Training Loss: 2.1421424005508425, Training Accuracy: 44.26\n",
            "Validation Loss: 2.955421671745883, Validation Accuracy: 29.75\n",
            "[47/150]: Training Loss: 2.1072659519195556, Training Accuracy: 44.7325\n",
            "Validation Loss: 2.9603501687383957, Validation Accuracy: 30.38\n",
            "[48/150]: Training Loss: 2.0704134420394897, Training Accuracy: 45.5625\n",
            "Validation Loss: 2.9289260366160397, Validation Accuracy: 30.82\n",
            "[49/150]: Training Loss: 2.0253924531936645, Training Accuracy: 46.8725\n",
            "Validation Loss: 2.9537550051500845, Validation Accuracy: 30.64\n",
            "[50/150]: Training Loss: 1.9894214233398437, Training Accuracy: 47.5425\n",
            "Validation Loss: 2.992744015280608, Validation Accuracy: 30.54\n",
            "[51/150]: Training Loss: 1.9478775398254395, Training Accuracy: 48.1625\n",
            "Validation Loss: 3.0440484505550116, Validation Accuracy: 30.87\n",
            "[52/150]: Training Loss: 1.9146845523834228, Training Accuracy: 48.9825\n",
            "Validation Loss: 2.9890038989911414, Validation Accuracy: 31.24\n",
            "[53/150]: Training Loss: 1.8723485668182374, Training Accuracy: 50.01\n",
            "Validation Loss: 2.993290390937951, Validation Accuracy: 31.22\n",
            "[54/150]: Training Loss: 1.8348793195724487, Training Accuracy: 50.52\n",
            "Validation Loss: 3.0035920021640266, Validation Accuracy: 31.61\n",
            "[55/150]: Training Loss: 1.7904879375457763, Training Accuracy: 52.175\n",
            "Validation Loss: 3.0537699574877504, Validation Accuracy: 30.68\n",
            "[56/150]: Training Loss: 1.7518022777557374, Training Accuracy: 52.58\n",
            "Validation Loss: 3.0826165934277188, Validation Accuracy: 30.36\n",
            "[57/150]: Training Loss: 1.723713356781006, Training Accuracy: 53.2725\n",
            "Validation Loss: 3.0921939679771473, Validation Accuracy: 30.79\n",
            "[58/150]: Training Loss: 1.673542138671875, Training Accuracy: 54.7525\n",
            "Validation Loss: 3.114953031965122, Validation Accuracy: 30.97\n",
            "[59/150]: Training Loss: 1.6370127866744995, Training Accuracy: 55.3475\n",
            "Validation Loss: 3.1347598710637183, Validation Accuracy: 31.13\n",
            "[60/150]: Training Loss: 1.595728307723999, Training Accuracy: 56.3775\n",
            "Validation Loss: 3.211446317138186, Validation Accuracy: 30.86\n",
            "[61/150]: Training Loss: 1.5595929719924926, Training Accuracy: 57.445\n",
            "Validation Loss: 3.1916901260424573, Validation Accuracy: 31.69\n",
            "[62/150]: Training Loss: 1.5153404804229735, Training Accuracy: 58.605\n",
            "Validation Loss: 3.2764444821959087, Validation Accuracy: 30.21\n",
            "[63/150]: Training Loss: 1.4795546808242799, Training Accuracy: 59.165\n",
            "Validation Loss: 3.2651574581292024, Validation Accuracy: 31.32\n",
            "[64/150]: Training Loss: 1.443065357875824, Training Accuracy: 60.3525\n",
            "Validation Loss: 3.2850031807164477, Validation Accuracy: 30.88\n",
            "[65/150]: Training Loss: 1.3952457666397096, Training Accuracy: 61.3125\n",
            "Validation Loss: 3.334014499263399, Validation Accuracy: 30.51\n",
            "[66/150]: Training Loss: 1.3616252402305602, Training Accuracy: 62.2875\n",
            "Validation Loss: 3.3781587804199025, Validation Accuracy: 30.85\n",
            "[67/150]: Training Loss: 1.3209700021743775, Training Accuracy: 63.1475\n",
            "Validation Loss: 3.4392695958447304, Validation Accuracy: 30.92\n",
            "[68/150]: Training Loss: 1.2754105567932128, Training Accuracy: 64.4\n",
            "Validation Loss: 3.487312679837464, Validation Accuracy: 30.89\n",
            "[69/150]: Training Loss: 1.2461662047386168, Training Accuracy: 65.2125\n",
            "Validation Loss: 3.470762025019166, Validation Accuracy: 30.79\n",
            "[70/150]: Training Loss: 1.2068843828201294, Training Accuracy: 66.345\n",
            "Validation Loss: 3.5463279022532666, Validation Accuracy: 30.57\n",
            "[71/150]: Training Loss: 1.174416847038269, Training Accuracy: 66.87\n",
            "Validation Loss: 3.5970414428953914, Validation Accuracy: 30.5\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.28561769473325, Test Accuracy: 11.15\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>11.15</td></tr><tr><td>Test Loss</td><td>17.28562</td></tr><tr><td>Train Accuracy</td><td>66.87</td></tr><tr><td>Train Loss</td><td>1.17442</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/8lcpcbs2</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_002202-8lcpcbs2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_002809-yufpefeq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">learning_rate=0.01 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.394053651046753, Training Accuracy: 3.235\n",
            "Validation Loss: 4.1179144488778086, Validation Accuracy: 6.51\n",
            "[2/150]: Training Loss: 3.940752759170532, Training Accuracy: 9.1825\n",
            "Validation Loss: 3.793641860318032, Validation Accuracy: 10.96\n",
            "[3/150]: Training Loss: 3.607163610458374, Training Accuracy: 14.85\n",
            "Validation Loss: 3.445422892357893, Validation Accuracy: 18.4\n",
            "[4/150]: Training Loss: 3.32619926071167, Training Accuracy: 19.315\n",
            "Validation Loss: 3.202780070578217, Validation Accuracy: 21.55\n",
            "[5/150]: Training Loss: 3.0974891372680666, Training Accuracy: 23.9725\n",
            "Validation Loss: 3.0388081802684033, Validation Accuracy: 24.97\n",
            "[6/150]: Training Loss: 2.901975968170166, Training Accuracy: 27.42\n",
            "Validation Loss: 3.0498315498327755, Validation Accuracy: 25.89\n",
            "[7/150]: Training Loss: 2.72861491394043, Training Accuracy: 31.1425\n",
            "Validation Loss: 2.817266490049423, Validation Accuracy: 30.26\n",
            "[8/150]: Training Loss: 2.565713974761963, Training Accuracy: 33.8575\n",
            "Validation Loss: 2.7873742094465124, Validation Accuracy: 30.1\n",
            "[9/150]: Training Loss: 2.394580401802063, Training Accuracy: 37.745\n",
            "Validation Loss: 2.714815883879449, Validation Accuracy: 32.43\n",
            "[10/150]: Training Loss: 2.2325665201187133, Training Accuracy: 41.275\n",
            "Validation Loss: 2.6796328748107716, Validation Accuracy: 33.37\n",
            "[11/150]: Training Loss: 2.0732334920883178, Training Accuracy: 44.825\n",
            "Validation Loss: 2.743416508291937, Validation Accuracy: 33.16\n",
            "[12/150]: Training Loss: 1.9020709432601928, Training Accuracy: 48.52\n",
            "Validation Loss: 2.761919692823082, Validation Accuracy: 34.09\n",
            "[13/150]: Training Loss: 1.723027162361145, Training Accuracy: 52.47\n",
            "Validation Loss: 2.781366317894808, Validation Accuracy: 33.87\n",
            "[14/150]: Training Loss: 1.5519161633491516, Training Accuracy: 56.5925\n",
            "Validation Loss: 2.8901124114443544, Validation Accuracy: 32.73\n",
            "[15/150]: Training Loss: 1.3848727501869202, Training Accuracy: 60.6225\n",
            "Validation Loss: 3.061296709024223, Validation Accuracy: 32.5\n",
            "[16/150]: Training Loss: 1.2385452840805053, Training Accuracy: 64.0375\n",
            "Validation Loss: 3.1685607524434474, Validation Accuracy: 33.0\n",
            "[17/150]: Training Loss: 1.0766600145339966, Training Accuracy: 68.1675\n",
            "Validation Loss: 3.470290554556877, Validation Accuracy: 32.52\n",
            "[18/150]: Training Loss: 0.953560617685318, Training Accuracy: 71.2375\n",
            "Validation Loss: 3.737919813508441, Validation Accuracy: 32.63\n",
            "[19/150]: Training Loss: 0.8452390188217163, Training Accuracy: 74.1975\n",
            "Validation Loss: 3.9338995074010956, Validation Accuracy: 32.13\n",
            "[20/150]: Training Loss: 0.7454726006031036, Training Accuracy: 76.935\n",
            "Validation Loss: 4.16999766325495, Validation Accuracy: 32.08\n",
            "[21/150]: Training Loss: 0.6607641342639923, Training Accuracy: 79.455\n",
            "Validation Loss: 4.340858131457287, Validation Accuracy: 31.19\n",
            "[22/150]: Training Loss: 0.5830736963987351, Training Accuracy: 81.7975\n",
            "Validation Loss: 4.7213960696177875, Validation Accuracy: 32.35\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 31.791706814128123, Test Accuracy: 14.4\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>14.4</td></tr><tr><td>Test Loss</td><td>31.79171</td></tr><tr><td>Train Accuracy</td><td>81.7975</td></tr><tr><td>Train Loss</td><td>0.58307</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/yufpefeq</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_002809-yufpefeq/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_003027-5ijvpyn3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.452998904800415, Training Accuracy: 2.615\n",
            "Validation Loss: 4.1346032179085315, Validation Accuracy: 5.28\n",
            "[2/150]: Training Loss: 3.9527258255004885, Training Accuracy: 8.88\n",
            "Validation Loss: 3.7435999432946465, Validation Accuracy: 11.55\n",
            "[3/150]: Training Loss: 3.6381911922454835, Training Accuracy: 14.3725\n",
            "Validation Loss: 3.50478922181828, Validation Accuracy: 15.58\n",
            "[4/150]: Training Loss: 3.3785652015686036, Training Accuracy: 18.865\n",
            "Validation Loss: 3.3451961089091697, Validation Accuracy: 19.0\n",
            "[5/150]: Training Loss: 3.17810930519104, Training Accuracy: 22.375\n",
            "Validation Loss: 3.1223374703887163, Validation Accuracy: 23.6\n",
            "[6/150]: Training Loss: 3.0013810291290284, Training Accuracy: 25.565\n",
            "Validation Loss: 3.015145599462424, Validation Accuracy: 25.56\n",
            "[7/150]: Training Loss: 2.8544215950012206, Training Accuracy: 28.7175\n",
            "Validation Loss: 2.917889818264421, Validation Accuracy: 28.04\n",
            "[8/150]: Training Loss: 2.6971351528167724, Training Accuracy: 31.3825\n",
            "Validation Loss: 2.8436176351680875, Validation Accuracy: 29.6\n",
            "[9/150]: Training Loss: 2.567851602554321, Training Accuracy: 34.1025\n",
            "Validation Loss: 2.748332465530201, Validation Accuracy: 31.45\n",
            "[10/150]: Training Loss: 2.422238304901123, Training Accuracy: 37.085\n",
            "Validation Loss: 2.7193879473740887, Validation Accuracy: 32.08\n",
            "[11/150]: Training Loss: 2.3000989530563354, Training Accuracy: 39.695\n",
            "Validation Loss: 2.736810536141608, Validation Accuracy: 32.35\n",
            "[12/150]: Training Loss: 2.170335920906067, Training Accuracy: 42.5\n",
            "Validation Loss: 2.668315727239961, Validation Accuracy: 34.0\n",
            "[13/150]: Training Loss: 2.037977534675598, Training Accuracy: 45.47\n",
            "Validation Loss: 2.6606684786498924, Validation Accuracy: 34.72\n",
            "[14/150]: Training Loss: 1.9109795570373536, Training Accuracy: 48.245\n",
            "Validation Loss: 2.677434118690005, Validation Accuracy: 34.85\n",
            "[15/150]: Training Loss: 1.7840767404556275, Training Accuracy: 50.9475\n",
            "Validation Loss: 2.6786925458604363, Validation Accuracy: 35.46\n",
            "[16/150]: Training Loss: 1.6501886499404907, Training Accuracy: 54.325\n",
            "Validation Loss: 2.749260063383989, Validation Accuracy: 34.73\n",
            "[17/150]: Training Loss: 1.5220398645401, Training Accuracy: 57.045\n",
            "Validation Loss: 2.9064030396710536, Validation Accuracy: 34.13\n",
            "[18/150]: Training Loss: 1.3921052120208741, Training Accuracy: 60.4275\n",
            "Validation Loss: 2.978949681968446, Validation Accuracy: 33.67\n",
            "[19/150]: Training Loss: 1.2853214281082153, Training Accuracy: 62.9225\n",
            "Validation Loss: 3.0623086941470006, Validation Accuracy: 33.54\n",
            "[20/150]: Training Loss: 1.1686985822677611, Training Accuracy: 65.5875\n",
            "Validation Loss: 3.099342126755198, Validation Accuracy: 34.34\n",
            "[21/150]: Training Loss: 1.0535273086547852, Training Accuracy: 68.77\n",
            "Validation Loss: 3.2730220791640554, Validation Accuracy: 32.71\n",
            "[22/150]: Training Loss: 0.9473227613449097, Training Accuracy: 71.6425\n",
            "Validation Loss: 3.5567993069909942, Validation Accuracy: 33.18\n",
            "[23/150]: Training Loss: 0.8736372189521789, Training Accuracy: 73.5275\n",
            "Validation Loss: 3.4931609501504592, Validation Accuracy: 33.71\n",
            "[24/150]: Training Loss: 0.7797131684780121, Training Accuracy: 76.18\n",
            "Validation Loss: 3.6084122536288703, Validation Accuracy: 31.79\n",
            "[25/150]: Training Loss: 0.72144877743721, Training Accuracy: 77.925\n",
            "Validation Loss: 3.6706639156220064, Validation Accuracy: 33.34\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.253872677019448, Test Accuracy: 18.45\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>18.45</td></tr><tr><td>Test Loss</td><td>17.25387</td></tr><tr><td>Train Accuracy</td><td>77.925</td></tr><tr><td>Train Loss</td><td>0.72145</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/5ijvpyn3</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_003027-5ijvpyn3/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_003346-pvvd2my8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">learning_rate=0.01 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.436210793685913, Training Accuracy: 2.8025\n",
            "Validation Loss: 4.1512272403498365, Validation Accuracy: 5.38\n",
            "[2/150]: Training Loss: 3.943741687011719, Training Accuracy: 9.175\n",
            "Validation Loss: 3.791590502307673, Validation Accuracy: 11.54\n",
            "[3/150]: Training Loss: 3.6135140613555907, Training Accuracy: 14.57\n",
            "Validation Loss: 3.473675949558331, Validation Accuracy: 17.5\n",
            "[4/150]: Training Loss: 3.3465395004272462, Training Accuracy: 19.22\n",
            "Validation Loss: 3.3301091406755385, Validation Accuracy: 19.19\n",
            "[5/150]: Training Loss: 3.1310076709747316, Training Accuracy: 22.94\n",
            "Validation Loss: 3.0678081117617855, Validation Accuracy: 24.65\n",
            "[6/150]: Training Loss: 2.9402838905334474, Training Accuracy: 26.4875\n",
            "Validation Loss: 2.9766739310732313, Validation Accuracy: 25.68\n",
            "[7/150]: Training Loss: 2.7704892574310302, Training Accuracy: 29.855\n",
            "Validation Loss: 2.8771827342403924, Validation Accuracy: 28.79\n",
            "[8/150]: Training Loss: 2.6034393648147582, Training Accuracy: 33.84\n",
            "Validation Loss: 2.7646109807263515, Validation Accuracy: 31.02\n",
            "[9/150]: Training Loss: 2.436837389945984, Training Accuracy: 37.1175\n",
            "Validation Loss: 2.731329696193622, Validation Accuracy: 32.37\n",
            "[10/150]: Training Loss: 2.273189482879639, Training Accuracy: 40.3275\n",
            "Validation Loss: 2.663352646645467, Validation Accuracy: 33.62\n",
            "[11/150]: Training Loss: 2.1113974294662476, Training Accuracy: 44.0125\n",
            "Validation Loss: 2.70243866884025, Validation Accuracy: 33.48\n",
            "[12/150]: Training Loss: 1.9719651878356934, Training Accuracy: 46.755\n",
            "Validation Loss: 2.7540456124931385, Validation Accuracy: 34.46\n",
            "[13/150]: Training Loss: 1.8135078485488891, Training Accuracy: 50.6725\n",
            "Validation Loss: 2.7649777801173507, Validation Accuracy: 34.67\n",
            "[14/150]: Training Loss: 1.663066688156128, Training Accuracy: 53.855\n",
            "Validation Loss: 2.8507347205641924, Validation Accuracy: 34.61\n",
            "[15/150]: Training Loss: 1.5029290641784667, Training Accuracy: 57.7575\n",
            "Validation Loss: 2.961932021341506, Validation Accuracy: 33.61\n",
            "[16/150]: Training Loss: 1.3492597907066346, Training Accuracy: 61.345\n",
            "Validation Loss: 3.0608204777833, Validation Accuracy: 33.71\n",
            "[17/150]: Training Loss: 1.2147304633140563, Training Accuracy: 64.7325\n",
            "Validation Loss: 3.1523648325804694, Validation Accuracy: 33.57\n",
            "[18/150]: Training Loss: 1.0741954045295716, Training Accuracy: 68.3375\n",
            "Validation Loss: 3.4972750517972715, Validation Accuracy: 32.75\n",
            "[19/150]: Training Loss: 0.9752286433696746, Training Accuracy: 70.7775\n",
            "Validation Loss: 3.703600254787761, Validation Accuracy: 32.29\n",
            "[20/150]: Training Loss: 0.8703240002632141, Training Accuracy: 73.66\n",
            "Validation Loss: 3.6860399884023485, Validation Accuracy: 32.6\n",
            "[21/150]: Training Loss: 0.7578078193187714, Training Accuracy: 76.6025\n",
            "Validation Loss: 4.062916931832672, Validation Accuracy: 31.29\n",
            "[22/150]: Training Loss: 0.673084812450409, Training Accuracy: 79.0375\n",
            "Validation Loss: 4.114260547480006, Validation Accuracy: 31.62\n",
            "[23/150]: Training Loss: 0.6178978152275085, Training Accuracy: 80.77\n",
            "Validation Loss: 4.332119194565306, Validation Accuracy: 32.24\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 24.731220123874156, Test Accuracy: 17.1\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>17.1</td></tr><tr><td>Test Loss</td><td>24.73122</td></tr><tr><td>Train Accuracy</td><td>80.77</td></tr><tr><td>Train Loss</td><td>0.6179</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning/runs/pvvd2my8</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_003346-pvvd2my8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "  for wd in weight_decays:\n",
        "\n",
        "    print('='*50)\n",
        "    print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "    print('='*50)\n",
        "\n",
        "    hyperparameters = {'learning_rate': lr,\n",
        "                       'weight_decay' : wd\n",
        "                       }\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(num_epochs, model, train_loader, validation_loader, test_loader, optimizer, scheduler, criterion, device, 'SGDM-HyperParameterTuning', hyperparameters=hyperparameters, is_wandb = True, n_epochs_stop = 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Training Using Best Hyperparameters Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f9dca98d1b8c402db8fa03f1354a051b",
            "3445c5fe76514de0b6b9cc31200c8544",
            "eafc1e77174c4758a3780b481d694ae0",
            "e6a773393e084de9a117fbbf43b7a59e",
            "b0748d32c99741d39b18512400e07f30",
            "dc43eb867d6b446cb0cb8e5debae57e7",
            "6c30f9a9e6c44d78ad39f43a5f11a6d0",
            "81500a36ef5e4a9e9b36aef01bee3697"
          ]
        },
        "id": "i9Q1MpZmVAUp",
        "outputId": "00a406f8-47bc-405c-d5e8-e10713b7f5fe"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234711-4i9h8t3n</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 1.8986814637093028, Test Accuracy: 57.55\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>57.55</td></tr><tr><td>Test Loss</td><td>1.89868</td></tr><tr><td>Train Accuracy</td><td>87.314</td></tr><tr><td>Train Loss</td><td>0.44531</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM/runs/4i9h8t3n</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-SGDM</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234711-4i9h8t3n/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                  'weight_decay' : wd}\n",
        "\n",
        "# Load the model\n",
        "model_0 = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer_0 = torch.optim.SGD(model_0.parameters(), lr=lr, momentum=0.9, weight_decay=wd)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_0, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model_0, original_train_loader, original_test_loader, original_test_loader, optimizer_0, scheduler, criterion, device, optimizer_name='SGDM', hyperparameters=hyperparameters, is_wandb=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### AdamW (Adam with Weight Decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ba6f9560801c461a90a0fd2f8c20d918",
            "5055c91b4ed34c1baf249fa25948e84f",
            "1feabb0772134ace893d71cb905e9b12",
            "fb5f2e328dff44018f41180c2a2ec871",
            "33050a2d80c24235aecc36cb34e79684",
            "2bc1423c729a4faa9a184ae092eda8ad",
            "1b1acf7a1f5f43739e1fe0894ba48950",
            "0d710da02bfe4c8e80d205158d9d64c7",
            "d770fa4de3bd479886dbf8e1f6369543",
            "c20d73b37f6a497a8847e2fd20a98d16",
            "edd61f4569b54b869669aebf91420508",
            "a6ba8ab59be54b8ca096631627ee9713",
            "15a0bbd1e2b14cef8a2f9accf120c1ad",
            "e181391aa4424c04804ac665abd6f594",
            "f8ce66183b2543e7bf19b71d90d1c53e",
            "904f899f441149e9b707699a0ebf31b5",
            "f76ed5acf91a4edf92950dcb88356f23",
            "9387a738135842cf965db860499510f5",
            "33a438b911c04f1f96c67b4f7ba7477d",
            "35d90a90d5854bcaa2bc5f385cdad931",
            "5630d5fcb50a46f2887e0cce74a005a6",
            "fed90f96881140119ee97a0d2120b615",
            "ff7b6956e7e34db68cd38dee19c798f1",
            "d71c8b5d30df474ca6f30976d0a33c71",
            "cbe10db0bb8d45609a0f3d59a30c8f61",
            "07ff6351429c48c2b835305d3111af40",
            "ab580ef13b18428c994fc4f8b80885b6",
            "497de066b1964cd4b931476e0bd50c66",
            "c5de35a9063345b1a12e212718a02575",
            "e86e517239b54ca4a6767a300aa7e01d",
            "eb268a732bc74b2d81ec3c3a6ecd0362",
            "f2915a147a4246dba7984a90f23c34ae",
            "2f39d5f73c7647f1804e4212cb39924d",
            "6e7ede02663f4eb0927872bf17858f18",
            "a562d76741f74b10b8095be14da779d1",
            "f4e7759ba0f544d8a28a9922e06e890b",
            "0a9ee7dc8817456aab4af03cbfa4c6ed",
            "567cc1542f09433f8cc8b3a39237f198",
            "8dc245e02cac40f1b601fa42a0e6e77a",
            "1b093d744b374154afe2058e4a6de822",
            "4302f47b1ff043aca2523212b015e080",
            "371471be80ca47dbb005c853b7832f04",
            "e75a0d8ae24e462aa3075a813aad302d",
            "fd2cd8045a5c4387b98d080782289c48",
            "1574e69b88de479da2aadc2dfdd43261",
            "f523ae2aca8c46878f0a6ddc1f798ef5",
            "0b42ea1995bb410b99e653780dad3916",
            "f3ebd9b7bf7a4d24b54ab6673322f74b"
          ]
        },
        "id": "Toi1eWRqJuhK",
        "outputId": "bd028d6d-1e8d-4fff-bccf-88ed9aa1c4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:ymdv8k6d) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>7.7625</td></tr><tr><td>Train Loss</td><td>4.01706</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.00095 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/ymdv8k6d' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/ymdv8k6d</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_034825-ymdv8k6d/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:ymdv8k6d). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_034959-j16vayol</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">learning_rate=0.001 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.032126424407959, Training Accuracy: 7.645\n",
            "Validation Loss: 3.633875617555752, Validation Accuracy: 13.81\n",
            "[2/150]: Training Loss: 3.4117616390228274, Training Accuracy: 17.9375\n",
            "Validation Loss: 3.291252329091358, Validation Accuracy: 19.57\n",
            "[3/150]: Training Loss: 3.0980306770324706, Training Accuracy: 23.7325\n",
            "Validation Loss: 3.0133402590539045, Validation Accuracy: 25.49\n",
            "[4/150]: Training Loss: 2.875119793319702, Training Accuracy: 27.905\n",
            "Validation Loss: 2.9483105938905365, Validation Accuracy: 26.77\n",
            "[5/150]: Training Loss: 2.6911334384918213, Training Accuracy: 31.615\n",
            "Validation Loss: 2.851942961383018, Validation Accuracy: 28.77\n",
            "[6/150]: Training Loss: 2.5383362628936768, Training Accuracy: 34.6425\n",
            "Validation Loss: 2.8010447116414454, Validation Accuracy: 30.38\n",
            "[7/150]: Training Loss: 2.3951899276733397, Training Accuracy: 37.7375\n",
            "Validation Loss: 2.772052654035532, Validation Accuracy: 31.08\n",
            "[8/150]: Training Loss: 2.2677825828552245, Training Accuracy: 40.2175\n",
            "Validation Loss: 2.740394227823634, Validation Accuracy: 32.51\n",
            "[9/150]: Training Loss: 2.1415996942520144, Training Accuracy: 43.1725\n",
            "Validation Loss: 2.7748732961666813, Validation Accuracy: 31.82\n",
            "[10/150]: Training Loss: 2.016268748664856, Training Accuracy: 45.7725\n",
            "Validation Loss: 2.766294874203433, Validation Accuracy: 33.51\n",
            "[11/150]: Training Loss: 1.8994886245727538, Training Accuracy: 48.375\n",
            "Validation Loss: 2.840820978401573, Validation Accuracy: 32.8\n",
            "[12/150]: Training Loss: 1.7866277021408081, Training Accuracy: 51.045\n",
            "Validation Loss: 2.8579562796149283, Validation Accuracy: 32.9\n",
            "[13/150]: Training Loss: 1.6882859018325806, Training Accuracy: 53.12\n",
            "Validation Loss: 2.923183766899595, Validation Accuracy: 32.48\n",
            "[14/150]: Training Loss: 1.5779105269432068, Training Accuracy: 55.655\n",
            "Validation Loss: 3.072260461795102, Validation Accuracy: 32.29\n",
            "[15/150]: Training Loss: 1.478017513847351, Training Accuracy: 58.1575\n",
            "Validation Loss: 3.1435716137005265, Validation Accuracy: 32.08\n",
            "[16/150]: Training Loss: 1.3899440537452699, Training Accuracy: 59.9975\n",
            "Validation Loss: 3.176926696376436, Validation Accuracy: 31.97\n",
            "[17/150]: Training Loss: 1.3004323136329652, Training Accuracy: 62.3725\n",
            "Validation Loss: 3.3300343015391354, Validation Accuracy: 32.02\n",
            "[18/150]: Training Loss: 1.2033100715637206, Training Accuracy: 64.74\n",
            "Validation Loss: 3.478040464364799, Validation Accuracy: 31.7\n",
            "[19/150]: Training Loss: 1.1342673721313477, Training Accuracy: 66.51\n",
            "Validation Loss: 3.621978481863714, Validation Accuracy: 31.07\n",
            "[20/150]: Training Loss: 1.057302718448639, Training Accuracy: 68.56\n",
            "Validation Loss: 3.8245642261140667, Validation Accuracy: 31.16\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 198.79228443704594, Test Accuracy: 3.39\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>3.39</td></tr><tr><td>Test Loss</td><td>198.79228</td></tr><tr><td>Train Accuracy</td><td>68.56</td></tr><tr><td>Train Loss</td><td>1.0573</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/j16vayol</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_034959-j16vayol/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035204-l4zoq5dd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">learning_rate=0.001 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.108658624267578, Training Accuracy: 6.6075\n",
            "Validation Loss: 3.7040131304674087, Validation Accuracy: 12.1\n",
            "[2/150]: Training Loss: 3.5060665573120118, Training Accuracy: 16.015\n",
            "Validation Loss: 3.3598362321306947, Validation Accuracy: 18.42\n",
            "[3/150]: Training Loss: 3.1865245040893555, Training Accuracy: 21.7275\n",
            "Validation Loss: 3.128495198146553, Validation Accuracy: 22.84\n",
            "[4/150]: Training Loss: 2.9679495239257814, Training Accuracy: 25.8525\n",
            "Validation Loss: 2.9615708293428846, Validation Accuracy: 26.83\n",
            "[5/150]: Training Loss: 2.797335900115967, Training Accuracy: 29.515\n",
            "Validation Loss: 2.9264626108157406, Validation Accuracy: 26.96\n",
            "[6/150]: Training Loss: 2.6617756172180176, Training Accuracy: 32.13\n",
            "Validation Loss: 2.8755724490827816, Validation Accuracy: 28.35\n",
            "[7/150]: Training Loss: 2.54268462638855, Training Accuracy: 34.435\n",
            "Validation Loss: 2.7718013547788, Validation Accuracy: 30.25\n",
            "[8/150]: Training Loss: 2.424749851608276, Training Accuracy: 37.1025\n",
            "Validation Loss: 2.7567353567500024, Validation Accuracy: 31.11\n",
            "[9/150]: Training Loss: 2.3229350467681886, Training Accuracy: 39.08\n",
            "Validation Loss: 2.7088757032042095, Validation Accuracy: 32.08\n",
            "[10/150]: Training Loss: 2.2215481660842897, Training Accuracy: 41.4275\n",
            "Validation Loss: 2.75471066821153, Validation Accuracy: 31.83\n",
            "[11/150]: Training Loss: 2.134213170814514, Training Accuracy: 43.25\n",
            "Validation Loss: 2.8348169676057853, Validation Accuracy: 31.64\n",
            "[12/150]: Training Loss: 2.051020913696289, Training Accuracy: 44.9475\n",
            "Validation Loss: 2.7630925406316282, Validation Accuracy: 32.98\n",
            "[13/150]: Training Loss: 1.960823282814026, Training Accuracy: 46.7775\n",
            "Validation Loss: 2.7420302629470825, Validation Accuracy: 33.4\n",
            "[14/150]: Training Loss: 1.8790180908203125, Training Accuracy: 48.855\n",
            "Validation Loss: 2.7926843044864142, Validation Accuracy: 33.79\n",
            "[15/150]: Training Loss: 1.80182436504364, Training Accuracy: 50.6875\n",
            "Validation Loss: 2.8919099911003356, Validation Accuracy: 33.19\n",
            "[16/150]: Training Loss: 1.727850655937195, Training Accuracy: 52.3025\n",
            "Validation Loss: 2.8964282950018623, Validation Accuracy: 33.5\n",
            "[17/150]: Training Loss: 1.6616035480499267, Training Accuracy: 53.85\n",
            "Validation Loss: 3.033423226350432, Validation Accuracy: 32.53\n",
            "[18/150]: Training Loss: 1.5868734314918518, Training Accuracy: 55.5\n",
            "Validation Loss: 3.032342692089688, Validation Accuracy: 33.04\n",
            "[19/150]: Training Loss: 1.5333876008987426, Training Accuracy: 56.7525\n",
            "Validation Loss: 3.079486154446936, Validation Accuracy: 32.97\n",
            "[20/150]: Training Loss: 1.4575365795135498, Training Accuracy: 58.77\n",
            "Validation Loss: 3.181258452166418, Validation Accuracy: 32.82\n",
            "[21/150]: Training Loss: 1.39640816450119, Training Accuracy: 60.14\n",
            "Validation Loss: 3.216413262543405, Validation Accuracy: 32.76\n",
            "[22/150]: Training Loss: 1.337559293270111, Training Accuracy: 61.5275\n",
            "Validation Loss: 3.3633130872325534, Validation Accuracy: 31.73\n",
            "[23/150]: Training Loss: 1.2836213255882263, Training Accuracy: 62.6875\n",
            "Validation Loss: 3.4558656868661286, Validation Accuracy: 32.33\n",
            "[24/150]: Training Loss: 1.2338986722946168, Training Accuracy: 64.2825\n",
            "Validation Loss: 3.4873077155678134, Validation Accuracy: 32.02\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 156.72609671817463, Test Accuracy: 3.33\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>3.33</td></tr><tr><td>Test Loss</td><td>156.7261</td></tr><tr><td>Train Accuracy</td><td>64.2825</td></tr><tr><td>Train Loss</td><td>1.2339</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/l4zoq5dd</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035204-l4zoq5dd/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035441-y4ask5ys</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.053023485183716, Training Accuracy: 7.3\n",
            "Validation Loss: 3.71551227873298, Validation Accuracy: 12.6\n",
            "[2/150]: Training Loss: 3.4803551902770997, Training Accuracy: 16.4825\n",
            "Validation Loss: 3.3104240119836894, Validation Accuracy: 19.6\n",
            "[3/150]: Training Loss: 3.1457452793121337, Training Accuracy: 22.71\n",
            "Validation Loss: 3.1647931253834134, Validation Accuracy: 22.36\n",
            "[4/150]: Training Loss: 2.9213612785339356, Training Accuracy: 26.8375\n",
            "Validation Loss: 2.967867093481076, Validation Accuracy: 26.13\n",
            "[5/150]: Training Loss: 2.7346919048309326, Training Accuracy: 30.745\n",
            "Validation Loss: 2.870804744161618, Validation Accuracy: 28.43\n",
            "[6/150]: Training Loss: 2.580346668434143, Training Accuracy: 33.8975\n",
            "Validation Loss: 2.813369401700937, Validation Accuracy: 29.97\n",
            "[7/150]: Training Loss: 2.4525743492126466, Training Accuracy: 36.445\n",
            "Validation Loss: 2.8111886962963517, Validation Accuracy: 31.76\n",
            "[8/150]: Training Loss: 2.3342738655090334, Training Accuracy: 38.8\n",
            "Validation Loss: 2.7751463211266096, Validation Accuracy: 31.29\n",
            "[9/150]: Training Loss: 2.230911629486084, Training Accuracy: 40.89\n",
            "Validation Loss: 2.733239137443008, Validation Accuracy: 32.32\n",
            "[10/150]: Training Loss: 2.127202660560608, Training Accuracy: 43.0575\n",
            "Validation Loss: 2.740311449500406, Validation Accuracy: 32.67\n",
            "[11/150]: Training Loss: 2.0320646129608155, Training Accuracy: 45.3025\n",
            "Validation Loss: 2.7493710031934606, Validation Accuracy: 33.28\n",
            "[12/150]: Training Loss: 1.9452043891906738, Training Accuracy: 47.2675\n",
            "Validation Loss: 2.776471818328663, Validation Accuracy: 33.2\n",
            "[13/150]: Training Loss: 1.8665077058792114, Training Accuracy: 49.035\n",
            "Validation Loss: 2.801089420440091, Validation Accuracy: 32.56\n",
            "[14/150]: Training Loss: 1.782764630126953, Training Accuracy: 50.66\n",
            "Validation Loss: 2.869801163673401, Validation Accuracy: 33.19\n",
            "[15/150]: Training Loss: 1.6995231729507447, Training Accuracy: 52.77\n",
            "Validation Loss: 3.0037558374890856, Validation Accuracy: 32.92\n",
            "[16/150]: Training Loss: 1.6300209772109986, Training Accuracy: 54.165\n",
            "Validation Loss: 2.9989138818850183, Validation Accuracy: 32.86\n",
            "[17/150]: Training Loss: 1.5460361848831177, Training Accuracy: 56.605\n",
            "Validation Loss: 3.0711293569795646, Validation Accuracy: 32.69\n",
            "[18/150]: Training Loss: 1.48129998254776, Training Accuracy: 57.9875\n",
            "Validation Loss: 3.1773584519222284, Validation Accuracy: 31.98\n",
            "[19/150]: Training Loss: 1.4184319323539734, Training Accuracy: 59.43\n",
            "Validation Loss: 3.278900881481778, Validation Accuracy: 31.73\n",
            "[20/150]: Training Loss: 1.3525760270118714, Training Accuracy: 60.9775\n",
            "Validation Loss: 3.3168472605905714, Validation Accuracy: 31.51\n",
            "[21/150]: Training Loss: 1.275265542125702, Training Accuracy: 63.035\n",
            "Validation Loss: 3.5034019506660994, Validation Accuracy: 31.12\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 67.07529235645464, Test Accuracy: 5.39\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>5.39</td></tr><tr><td>Test Loss</td><td>67.07529</td></tr><tr><td>Train Accuracy</td><td>63.035</td></tr><tr><td>Train Loss</td><td>1.27527</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/y4ask5ys</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035441-y4ask5ys/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035656-za8h22vt</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">learning_rate=0.01 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.622148120880127, Training Accuracy: 0.935\n",
            "Validation Loss: 4.609954472560032, Validation Accuracy: 0.99\n",
            "[2/150]: Training Loss: 4.609106838226318, Training Accuracy: 0.9475\n",
            "Validation Loss: 4.611106529357327, Validation Accuracy: 0.9\n",
            "[3/150]: Training Loss: 4.608888108062744, Training Accuracy: 0.9925\n",
            "Validation Loss: 4.608767968074531, Validation Accuracy: 0.84\n",
            "[4/150]: Training Loss: 4.608837638854981, Training Accuracy: 0.935\n",
            "Validation Loss: 4.610516976399027, Validation Accuracy: 0.89\n",
            "[5/150]: Training Loss: 4.608827792358398, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.610510003035236, Validation Accuracy: 0.9\n",
            "[6/150]: Training Loss: 4.608845700073243, Training Accuracy: 0.935\n",
            "Validation Loss: 4.609803257474474, Validation Accuracy: 0.83\n",
            "[7/150]: Training Loss: 4.608741146087646, Training Accuracy: 0.9625\n",
            "Validation Loss: 4.60897787665106, Validation Accuracy: 0.89\n",
            "[8/150]: Training Loss: 4.608720026397705, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.610442146374162, Validation Accuracy: 0.89\n",
            "[9/150]: Training Loss: 4.60900821762085, Training Accuracy: 1.005\n",
            "Validation Loss: 4.609640285467646, Validation Accuracy: 0.9\n",
            "[10/150]: Training Loss: 4.609175831604004, Training Accuracy: 0.9175\n",
            "Validation Loss: 4.609878120908312, Validation Accuracy: 0.95\n",
            "[11/150]: Training Loss: 4.609065142822265, Training Accuracy: 0.8625\n",
            "Validation Loss: 4.610616553361249, Validation Accuracy: 0.9\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 19.343990089027745, Test Accuracy: 1.01\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.01</td></tr><tr><td>Test Loss</td><td>19.34399</td></tr><tr><td>Train Accuracy</td><td>0.8625</td></tr><tr><td>Train Loss</td><td>4.60907</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/za8h22vt</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035656-za8h22vt/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_035822-1oq8f1cm</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.625637398529053, Training Accuracy: 0.885\n",
            "Validation Loss: 4.60909015509733, Validation Accuracy: 1.06\n",
            "[2/150]: Training Loss: 4.608977200317383, Training Accuracy: 0.94\n",
            "Validation Loss: 4.609363568056921, Validation Accuracy: 0.92\n",
            "[3/150]: Training Loss: 4.608765270996094, Training Accuracy: 0.9275\n",
            "Validation Loss: 4.610460181145152, Validation Accuracy: 0.9\n",
            "[4/150]: Training Loss: 4.609055269622803, Training Accuracy: 0.855\n",
            "Validation Loss: 4.609649321076217, Validation Accuracy: 0.91\n",
            "[5/150]: Training Loss: 4.608893507385254, Training Accuracy: 0.965\n",
            "Validation Loss: 4.610334041012321, Validation Accuracy: 1.15\n",
            "[6/150]: Training Loss: 4.609225297546387, Training Accuracy: 1.0125\n",
            "Validation Loss: 4.608022522774472, Validation Accuracy: 1.16\n",
            "[7/150]: Training Loss: 4.609016616821289, Training Accuracy: 0.9875\n",
            "Validation Loss: 4.609603547746209, Validation Accuracy: 0.82\n",
            "[8/150]: Training Loss: 4.609039859008789, Training Accuracy: 1.0025\n",
            "Validation Loss: 4.608962860836345, Validation Accuracy: 0.88\n",
            "[9/150]: Training Loss: 4.608584417724609, Training Accuracy: 0.98\n",
            "Validation Loss: 4.609565239803047, Validation Accuracy: 0.92\n",
            "[10/150]: Training Loss: 4.609195093536377, Training Accuracy: 0.9675\n",
            "Validation Loss: 4.609652103132503, Validation Accuracy: 0.9\n",
            "[11/150]: Training Loss: 4.608826132202148, Training Accuracy: 0.975\n",
            "Validation Loss: 4.610933561993253, Validation Accuracy: 0.95\n",
            "[12/150]: Training Loss: 4.609026128387451, Training Accuracy: 1.0425\n",
            "Validation Loss: 4.609673776444356, Validation Accuracy: 0.81\n",
            "[13/150]: Training Loss: 4.60898267364502, Training Accuracy: 0.9275\n",
            "Validation Loss: 4.6093105510541585, Validation Accuracy: 0.89\n",
            "[14/150]: Training Loss: 4.608909271240234, Training Accuracy: 0.885\n",
            "Validation Loss: 4.610904125650977, Validation Accuracy: 0.82\n",
            "[15/150]: Training Loss: 4.609115404510498, Training Accuracy: 0.925\n",
            "Validation Loss: 4.609269661508548, Validation Accuracy: 0.9\n",
            "[16/150]: Training Loss: 4.608642578887939, Training Accuracy: 0.9875\n",
            "Validation Loss: 4.610215545459917, Validation Accuracy: 0.81\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 51.00807974748551, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>51.00808</td></tr><tr><td>Train Accuracy</td><td>0.9875</td></tr><tr><td>Train Loss</td><td>4.60864</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/1oq8f1cm</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_035822-1oq8f1cm/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_040031-bgr70v9g</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">learning_rate=0.01 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.626314550018311, Training Accuracy: 0.9725\n",
            "Validation Loss: 4.610879454643103, Validation Accuracy: 0.88\n",
            "[2/150]: Training Loss: 4.609021481323242, Training Accuracy: 0.9225\n",
            "Validation Loss: 4.6096283493527945, Validation Accuracy: 1.0\n",
            "[3/150]: Training Loss: 4.608779692077637, Training Accuracy: 0.9575\n",
            "Validation Loss: 4.610723838684665, Validation Accuracy: 1.07\n",
            "[4/150]: Training Loss: 4.609119167327881, Training Accuracy: 0.9125\n",
            "Validation Loss: 4.60863508236636, Validation Accuracy: 0.89\n",
            "[5/150]: Training Loss: 4.608814185333252, Training Accuracy: 0.95\n",
            "Validation Loss: 4.611634175488903, Validation Accuracy: 0.93\n",
            "[6/150]: Training Loss: 4.6092648048400875, Training Accuracy: 0.8575\n",
            "Validation Loss: 4.610189516832874, Validation Accuracy: 0.92\n",
            "[7/150]: Training Loss: 4.6090187705993655, Training Accuracy: 1.005\n",
            "Validation Loss: 4.610130288798338, Validation Accuracy: 0.88\n",
            "[8/150]: Training Loss: 4.608886881256104, Training Accuracy: 1.01\n",
            "Validation Loss: 4.610127786162552, Validation Accuracy: 0.84\n",
            "[9/150]: Training Loss: 4.608884384155274, Training Accuracy: 1.0175\n",
            "Validation Loss: 4.610361232879056, Validation Accuracy: 0.95\n",
            "[10/150]: Training Loss: 4.60871681137085, Training Accuracy: 1.0025\n",
            "Validation Loss: 4.6113608263100785, Validation Accuracy: 1.03\n",
            "[11/150]: Training Loss: 4.608806131744385, Training Accuracy: 1.035\n",
            "Validation Loss: 4.609321922253651, Validation Accuracy: 0.94\n",
            "[12/150]: Training Loss: 4.6090567108154294, Training Accuracy: 0.9075\n",
            "Validation Loss: 4.6090145414801915, Validation Accuracy: 0.9\n",
            "[13/150]: Training Loss: 4.608706290435791, Training Accuracy: 0.9225\n",
            "Validation Loss: 4.609259438362851, Validation Accuracy: 0.82\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 7.142075587230123, Test Accuracy: 1.08\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.08</td></tr><tr><td>Test Loss</td><td>7.14208</td></tr><tr><td>Train Accuracy</td><td>0.9225</td></tr><tr><td>Train Loss</td><td>4.60871</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning/runs/bgr70v9g</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_040031-bgr70v9g/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "  for wd in weight_decays:\n",
        "\n",
        "    print('='*50)\n",
        "    print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "    print('='*50)\n",
        "\n",
        "    hyperparameters = {'learning_rate': lr,\n",
        "                       'weight_decay' : wd\n",
        "                       }\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(num_epochs, model, train_loader, validation_loader, test_loader, optimizer, scheduler, criterion, device, 'AdamW-HyperParameterTuning', hyperparameters=hyperparameters, is_wandb = True, n_epochs_stop = 10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Training Using Best Hyperparameters Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "63dd47b50bdc44e88edd97d14585f7ea",
            "5e0116dc735e4ad995a5b1a039c6a55a",
            "8cf1e952ed294ccdbc3bb2275b5d3efd",
            "7421027bfcb34262a1b99d297e49bf8e",
            "76dfea14213f4e66b269b901150c6cba",
            "d1e4a03094b94c34ac235ffbd0c7fa06",
            "c8e410ff55fc448bbe87c8975a552e88",
            "f49251ce876f4d9292a4179b48ebb22a"
          ]
        },
        "id": "dC9sTmuvEymk",
        "outputId": "66657750-ed1c-435f-c9e5-a2cc4271560e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234720-ulxra0pg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 2.113396340115055, Test Accuracy: 49.46\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>49.46</td></tr><tr><td>Test Loss</td><td>2.1134</td></tr><tr><td>Train Accuracy</td><td>65.458</td></tr><tr><td>Train Loss</td><td>1.1963</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW/runs/ulxra0pg</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-AdamW</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234720-ulxra0pg/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1e-03\n",
        "wd = 4e-04\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model_1 = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer_1 = torch.optim.AdamW(model_1.parameters(), lr=lr, weight_decay=wd)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_1, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model_1, original_train_loader, original_test_loader, original_test_loader, optimizer_1, scheduler, criterion, device, optimizer_name='AdamW', hyperparameters=hyperparameters, is_wandb = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeMWj_f0sbQE"
      },
      "source": [
        "# **Large Batch Optimizers**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LARS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "WkZmVFG0q90m"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "class LARS(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements LARS (Layer-wise Adaptive Rate Scaling).\n",
        "\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "        lr (float): learning rate (default: 1e-3)\n",
        "        momentum (float, optional): momentum factor (default: 0)\n",
        "        trust_coef (float, optional): LARS coefficient as used in the paper (default: 1e-3)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        dampening (float, optional): dampening for momentum (default: 0)\n",
        "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
        "        epsilon (float, optional): epsilon to prevent zero division (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            params,\n",
        "            lr: float = 1e-3,\n",
        "            momentum: float = 0,\n",
        "            trust_coef: float = 1e-3,\n",
        "            dampening: float = 0,\n",
        "            weight_decay: float = 0,\n",
        "            nesterov=False,\n",
        "            epsilon: float = 1e-9\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LARS optimizer.\n",
        "\n",
        "        Args:\n",
        "            params: iterable of parameters to optimize or dicts defining\n",
        "            lr: learning rate\n",
        "            momentum: momentum factor\n",
        "            trust_coef: LARS coefficient as used in the paper\n",
        "            weight_decay: weight decay (L2 penalty)\n",
        "            dampening: dampening for momentum\n",
        "            nesterov: enables Nesterov momentum\n",
        "            epsilon: epsilon to prevent zero division\n",
        "        \"\"\"\n",
        "\n",
        "        if lr <= 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(\n",
        "            lr=lr,\n",
        "            momentum=momentum,\n",
        "            trust_coef=trust_coef,\n",
        "            dampening=dampening,\n",
        "            weight_decay=weight_decay,\n",
        "            nesterov=nesterov,\n",
        "            epsilon=epsilon)\n",
        "\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(LARS, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        \"\"\"\n",
        "        Sets the state of the optimizer.\n",
        "\n",
        "        Args:\n",
        "            state: The state to set the optimizer to.\n",
        "        \"\"\"\n",
        "        super(LARS, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def _compute_local_lr(self, p, weight_decay, trust_coef, epsilon):\n",
        "        \"\"\"\n",
        "        Computes the local learning rate for a given parameter.\n",
        "\n",
        "        Args:\n",
        "            p: The parameter to compute the local learning rate for.\n",
        "            weight_decay: The weight decay factor.\n",
        "            trust_coef: The trust coefficient.\n",
        "            epsilon: A small constant for numerical stability.\n",
        "\n",
        "        Returns:\n",
        "            float: The computed local learning rate.\n",
        "        \"\"\"\n",
        "        w_norm = torch.norm(p.data)\n",
        "        g_norm = torch.norm(p.grad.data)\n",
        "        if w_norm * g_norm > 0:\n",
        "            return trust_coef * w_norm / (g_norm + weight_decay * w_norm + epsilon)\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    def _update_params(self, p, d_p, local_lr, lr, momentum, buf,\n",
        "                       dampening, nesterov, weight_decay):\n",
        "        \"\"\"\n",
        "        Updates the parameters with the computed update.\n",
        "\n",
        "        Args:\n",
        "            p: The parameter to be updated.\n",
        "            d_p: The computed update for the parameter.\n",
        "            local_lr: The local learning rate.\n",
        "            lr: The global learning rate.\n",
        "            momentum: The momentum factor.\n",
        "            buf: The buffer for the momentum.\n",
        "            dampening: The dampening for the momentum.\n",
        "            nesterov: A flag indicating whether to use Nesterov momentum.\n",
        "            weight_decay: The weight decay factor.\n",
        "        \"\"\"\n",
        "        if weight_decay != 0:\n",
        "            d_p.add_(weight_decay, p.data)\n",
        "        if momentum != 0:\n",
        "            param_state = self.state[p]\n",
        "            if 'momentum_buffer' not in param_state:\n",
        "                buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "            else:\n",
        "                buf = param_state['momentum_buffer']\n",
        "            buf.mul_(momentum).add_(1 - dampening, d_p)\n",
        "            if nesterov:\n",
        "                d_p = d_p.add(momentum, buf)\n",
        "            else:\n",
        "                d_p = buf\n",
        "\n",
        "        p.data.add_(-local_lr * lr, d_p)\n",
        "\n",
        "    def step(self):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        \"\"\"\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            trust_coef = group['trust_coef']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "            epsilon = group['epsilon']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                local_lr = self._compute_local_lr(p, weight_decay, trust_coef, epsilon)\n",
        "                self._update_params(p, p.grad.data, local_lr, group['lr'], momentum, None, dampening, nesterov, weight_decay)\n",
        "\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "dh421LdmM9XP"
      },
      "outputs": [],
      "source": [
        "learning_rates = [1e-02, 5e-02, 1e-01, 5e-01, 1, 1.5, 2]\n",
        "wd = 1e-03"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LARS Hyperparameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "30d70d57987c4349b55560e5d9626201",
            "36ac25551e574241bed4d7e5a4301d95",
            "6898349b9c754ca7be91bea29cabbba5",
            "623f947ef06c41569be7fcdda4141174",
            "d268f74266044451b230f20756bab2f6",
            "6896790e80d1450c821918c7ef41e42f",
            "a30700c8bfb449cda98a40d75828f3d3",
            "77beee57b67d4bad826f616e5483b87a",
            "c59ee0d8b9fb4694ada362115bf965a9",
            "ab62d64100a84b1faae744ee0f99501a",
            "6abbcbe71a314356ba04f8349d1fc127",
            "97c3921b8e454ccdb7b4db95d4440c64",
            "50b4ba3147b540abad020ae780353f27",
            "584e5a6aada04535b64c40c3ece566e8",
            "d3326a99729a416abca13d3122196e64",
            "1d534596e41340438fc8d083fff6aa8b",
            "19ed5f5d4f714246bbdf44513ecc50f0",
            "1f9d7ac8fa8a4bcdb76fe2b2cb443f66",
            "71c0cc303cfc44ba8d989d5f8feca119",
            "07dc9b3c563e4615bec4dbd3233bf4ba",
            "a3ccc0b32e9a4ceebd6045dff63e6621",
            "104402d4cba5477499593d972bc48e9d",
            "80fe0a51b14b4e548454d4f83215336c",
            "8e13a8bef6e14973912966984e83cd4c"
          ]
        },
        "id": "dzsCB_Q9NnCD",
        "outputId": "56d144bd-faa8-4df2-a19c-7cc15394622d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.01 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_022555-nh2g7isx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">learning_rate=0.01 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.605613048553467, Training Accuracy: 1.0325\n",
            "Validation Loss: 4.605481047539195, Validation Accuracy: 1.01\n",
            "[2/150]: Training Loss: 4.603893094635009, Training Accuracy: 1.2825\n",
            "Validation Loss: 4.603514659176966, Validation Accuracy: 1.37\n",
            "[3/150]: Training Loss: 4.601452378845215, Training Accuracy: 1.7625\n",
            "Validation Loss: 4.600479241389378, Validation Accuracy: 1.96\n",
            "[4/150]: Training Loss: 4.597398109436035, Training Accuracy: 1.815\n",
            "Validation Loss: 4.595512341541849, Validation Accuracy: 1.41\n",
            "[5/150]: Training Loss: 4.590549831390381, Training Accuracy: 1.5175\n",
            "Validation Loss: 4.587287993947411, Validation Accuracy: 1.68\n",
            "[6/150]: Training Loss: 4.579249038696289, Training Accuracy: 1.93\n",
            "Validation Loss: 4.573939116897097, Validation Accuracy: 2.37\n",
            "[7/150]: Training Loss: 4.560530513763427, Training Accuracy: 2.69\n",
            "Validation Loss: 4.5522112117451465, Validation Accuracy: 2.64\n",
            "[8/150]: Training Loss: 4.5309873321533205, Training Accuracy: 2.92\n",
            "Validation Loss: 4.519049043108703, Validation Accuracy: 2.85\n",
            "[9/150]: Training Loss: 4.488997451782226, Training Accuracy: 2.9475\n",
            "Validation Loss: 4.475813519423175, Validation Accuracy: 3.12\n",
            "[10/150]: Training Loss: 4.439574425506592, Training Accuracy: 3.3375\n",
            "Validation Loss: 4.429785430811013, Validation Accuracy: 3.32\n",
            "[11/150]: Training Loss: 4.391272030639648, Training Accuracy: 3.61\n",
            "Validation Loss: 4.386288050633327, Validation Accuracy: 3.95\n",
            "[12/150]: Training Loss: 4.346567308807373, Training Accuracy: 4.215\n",
            "Validation Loss: 4.348948326839763, Validation Accuracy: 4.02\n",
            "[13/150]: Training Loss: 4.3075446601867675, Training Accuracy: 4.48\n",
            "Validation Loss: 4.312188755934406, Validation Accuracy: 4.38\n",
            "[14/150]: Training Loss: 4.274280471801758, Training Accuracy: 4.9575\n",
            "Validation Loss: 4.284171402074729, Validation Accuracy: 4.91\n",
            "[15/150]: Training Loss: 4.24782478981018, Training Accuracy: 5.3275\n",
            "Validation Loss: 4.261963683328811, Validation Accuracy: 5.05\n",
            "[16/150]: Training Loss: 4.226929823303223, Training Accuracy: 5.7425\n",
            "Validation Loss: 4.2434815540435205, Validation Accuracy: 5.46\n",
            "[17/150]: Training Loss: 4.210706592941285, Training Accuracy: 5.9375\n",
            "Validation Loss: 4.230875344792748, Validation Accuracy: 5.78\n",
            "[18/150]: Training Loss: 4.197167670059204, Training Accuracy: 6.23\n",
            "Validation Loss: 4.218225898256727, Validation Accuracy: 5.69\n",
            "[19/150]: Training Loss: 4.1860190193176265, Training Accuracy: 6.505\n",
            "Validation Loss: 4.208940963076937, Validation Accuracy: 5.86\n",
            "[20/150]: Training Loss: 4.175828193664551, Training Accuracy: 6.6025\n",
            "Validation Loss: 4.201019479970264, Validation Accuracy: 6.0\n",
            "[21/150]: Training Loss: 4.167100285339355, Training Accuracy: 6.8025\n",
            "Validation Loss: 4.1936384735593375, Validation Accuracy: 5.97\n",
            "[22/150]: Training Loss: 4.158846283340454, Training Accuracy: 6.92\n",
            "Validation Loss: 4.185141735016161, Validation Accuracy: 6.28\n",
            "[23/150]: Training Loss: 4.151738377380371, Training Accuracy: 7.0375\n",
            "Validation Loss: 4.178911400448745, Validation Accuracy: 6.83\n",
            "[24/150]: Training Loss: 4.144738430023193, Training Accuracy: 7.23\n",
            "Validation Loss: 4.172337419667821, Validation Accuracy: 6.52\n",
            "[25/150]: Training Loss: 4.1379581127166745, Training Accuracy: 7.265\n",
            "Validation Loss: 4.165943450988478, Validation Accuracy: 6.63\n",
            "[26/150]: Training Loss: 4.132068264770508, Training Accuracy: 7.4525\n",
            "Validation Loss: 4.160335552920202, Validation Accuracy: 7.0\n",
            "[27/150]: Training Loss: 4.126062253570557, Training Accuracy: 7.4725\n",
            "Validation Loss: 4.157630066962758, Validation Accuracy: 6.66\n",
            "[28/150]: Training Loss: 4.120529958724975, Training Accuracy: 7.52\n",
            "Validation Loss: 4.150649539983956, Validation Accuracy: 7.07\n",
            "[29/150]: Training Loss: 4.115550531768799, Training Accuracy: 7.6175\n",
            "Validation Loss: 4.145238416210102, Validation Accuracy: 7.01\n",
            "[30/150]: Training Loss: 4.109972083282471, Training Accuracy: 7.74\n",
            "Validation Loss: 4.140822541182208, Validation Accuracy: 6.87\n",
            "[31/150]: Training Loss: 4.1054605201721195, Training Accuracy: 7.7775\n",
            "Validation Loss: 4.135137576206475, Validation Accuracy: 7.26\n",
            "[32/150]: Training Loss: 4.100883611297608, Training Accuracy: 7.9175\n",
            "Validation Loss: 4.13245949623691, Validation Accuracy: 7.37\n",
            "[33/150]: Training Loss: 4.096106577682495, Training Accuracy: 7.965\n",
            "Validation Loss: 4.1272796597450405, Validation Accuracy: 7.21\n",
            "[34/150]: Training Loss: 4.092031303024292, Training Accuracy: 8.075\n",
            "Validation Loss: 4.1231977316983945, Validation Accuracy: 7.19\n",
            "[35/150]: Training Loss: 4.087661064910889, Training Accuracy: 8.0775\n",
            "Validation Loss: 4.119425037104612, Validation Accuracy: 7.42\n",
            "[36/150]: Training Loss: 4.083959820175171, Training Accuracy: 8.14\n",
            "Validation Loss: 4.117144297642313, Validation Accuracy: 7.43\n",
            "[37/150]: Training Loss: 4.079987169265747, Training Accuracy: 8.2575\n",
            "Validation Loss: 4.112940530108798, Validation Accuracy: 7.33\n",
            "[38/150]: Training Loss: 4.076256622695923, Training Accuracy: 8.275\n",
            "Validation Loss: 4.10887487071335, Validation Accuracy: 7.72\n",
            "[39/150]: Training Loss: 4.072722610473633, Training Accuracy: 8.2625\n",
            "Validation Loss: 4.1064621779569395, Validation Accuracy: 7.62\n",
            "[40/150]: Training Loss: 4.06919368019104, Training Accuracy: 8.4025\n",
            "Validation Loss: 4.102874081605559, Validation Accuracy: 7.77\n",
            "[41/150]: Training Loss: 4.065893580627441, Training Accuracy: 8.425\n",
            "Validation Loss: 4.101947505003328, Validation Accuracy: 7.99\n",
            "[42/150]: Training Loss: 4.062419548797608, Training Accuracy: 8.64\n",
            "Validation Loss: 4.096677272942416, Validation Accuracy: 7.69\n",
            "[43/150]: Training Loss: 4.059447618484497, Training Accuracy: 8.6025\n",
            "Validation Loss: 4.096899234565201, Validation Accuracy: 7.72\n",
            "[44/150]: Training Loss: 4.056013444137573, Training Accuracy: 8.5725\n",
            "Validation Loss: 4.091373089772121, Validation Accuracy: 7.88\n",
            "[45/150]: Training Loss: 4.053135622024536, Training Accuracy: 8.6275\n",
            "Validation Loss: 4.088051226488345, Validation Accuracy: 8.07\n",
            "[46/150]: Training Loss: 4.049987061309815, Training Accuracy: 8.63\n",
            "Validation Loss: 4.085329578180981, Validation Accuracy: 8.03\n",
            "[47/150]: Training Loss: 4.047172613143921, Training Accuracy: 8.7125\n",
            "Validation Loss: 4.082841596785625, Validation Accuracy: 7.78\n",
            "[48/150]: Training Loss: 4.0441587448120115, Training Accuracy: 8.745\n",
            "Validation Loss: 4.081506820241357, Validation Accuracy: 8.21\n",
            "[49/150]: Training Loss: 4.04135802230835, Training Accuracy: 8.82\n",
            "Validation Loss: 4.079341964357218, Validation Accuracy: 8.03\n",
            "[50/150]: Training Loss: 4.0387205871582035, Training Accuracy: 8.7775\n",
            "Validation Loss: 4.075337004509701, Validation Accuracy: 8.12\n",
            "[51/150]: Training Loss: 4.036031353759766, Training Accuracy: 8.9025\n",
            "Validation Loss: 4.074757421092623, Validation Accuracy: 8.17\n",
            "[52/150]: Training Loss: 4.033370276260376, Training Accuracy: 8.91\n",
            "Validation Loss: 4.071030196110914, Validation Accuracy: 8.29\n",
            "[53/150]: Training Loss: 4.031033205032348, Training Accuracy: 8.965\n",
            "Validation Loss: 4.069437462812776, Validation Accuracy: 8.36\n",
            "[54/150]: Training Loss: 4.028417000579834, Training Accuracy: 9.095\n",
            "Validation Loss: 4.067116659917649, Validation Accuracy: 8.11\n",
            "[55/150]: Training Loss: 4.0260539081573485, Training Accuracy: 9.045\n",
            "Validation Loss: 4.065322780305413, Validation Accuracy: 8.45\n",
            "[56/150]: Training Loss: 4.0235095344543454, Training Accuracy: 9.085\n",
            "Validation Loss: 4.064038521165301, Validation Accuracy: 8.38\n",
            "[57/150]: Training Loss: 4.02125683631897, Training Accuracy: 9.18\n",
            "Validation Loss: 4.0599597381178745, Validation Accuracy: 8.62\n",
            "[58/150]: Training Loss: 4.019049766159058, Training Accuracy: 9.2225\n",
            "Validation Loss: 4.058757024206174, Validation Accuracy: 8.53\n",
            "[59/150]: Training Loss: 4.016744113540649, Training Accuracy: 9.3325\n",
            "Validation Loss: 4.056453751910264, Validation Accuracy: 8.65\n",
            "[60/150]: Training Loss: 4.014383445358276, Training Accuracy: 9.33\n",
            "Validation Loss: 4.054738797959248, Validation Accuracy: 8.49\n",
            "[61/150]: Training Loss: 4.012673494720459, Training Accuracy: 9.4\n",
            "Validation Loss: 4.05312654015365, Validation Accuracy: 8.45\n",
            "[62/150]: Training Loss: 4.0104282833099365, Training Accuracy: 9.3375\n",
            "Validation Loss: 4.050798089640915, Validation Accuracy: 8.61\n",
            "[63/150]: Training Loss: 4.0085177280426025, Training Accuracy: 9.345\n",
            "Validation Loss: 4.047672698452215, Validation Accuracy: 9.08\n",
            "[64/150]: Training Loss: 4.007076532363891, Training Accuracy: 9.44\n",
            "Validation Loss: 4.047075613289122, Validation Accuracy: 8.55\n",
            "[65/150]: Training Loss: 4.004718017959595, Training Accuracy: 9.47\n",
            "Validation Loss: 4.044435259642874, Validation Accuracy: 8.66\n",
            "[66/150]: Training Loss: 4.002854734802246, Training Accuracy: 9.58\n",
            "Validation Loss: 4.043384468479521, Validation Accuracy: 8.68\n",
            "[67/150]: Training Loss: 4.000918030929565, Training Accuracy: 9.59\n",
            "Validation Loss: 4.042230905241268, Validation Accuracy: 8.87\n",
            "[68/150]: Training Loss: 3.9992192554473878, Training Accuracy: 9.5775\n",
            "Validation Loss: 4.040329585409468, Validation Accuracy: 8.83\n",
            "[69/150]: Training Loss: 3.9973626461029053, Training Accuracy: 9.615\n",
            "Validation Loss: 4.037929029221747, Validation Accuracy: 9.01\n",
            "[70/150]: Training Loss: 3.9957307056427003, Training Accuracy: 9.69\n",
            "Validation Loss: 4.037050957892351, Validation Accuracy: 8.67\n",
            "[71/150]: Training Loss: 3.9943285522460936, Training Accuracy: 9.7375\n",
            "Validation Loss: 4.0364253475407885, Validation Accuracy: 8.88\n",
            "[72/150]: Training Loss: 3.9925530368804933, Training Accuracy: 9.7025\n",
            "Validation Loss: 4.033815119676529, Validation Accuracy: 8.93\n",
            "[73/150]: Training Loss: 3.9908373458862303, Training Accuracy: 9.7625\n",
            "Validation Loss: 4.0321422671056855, Validation Accuracy: 8.97\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 4.837270994854581, Test Accuracy: 5.7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>5.7</td></tr><tr><td>Test Loss</td><td>4.83727</td></tr><tr><td>Train Accuracy</td><td>9.7625</td></tr><tr><td>Train Loss</td><td>3.99084</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.01 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/nh2g7isx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_022555-nh2g7isx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.05 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_023355-cthymqs8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">learning_rate=0.05 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.600790646362305, Training Accuracy: 1.1675\n",
            "Validation Loss: 4.590667490746565, Validation Accuracy: 1.26\n",
            "[2/150]: Training Loss: 4.559383809661865, Training Accuracy: 2.1575\n",
            "Validation Loss: 4.506907958133965, Validation Accuracy: 2.54\n",
            "[3/150]: Training Loss: 4.4036731437683105, Training Accuracy: 3.8525\n",
            "Validation Loss: 4.321598778864381, Validation Accuracy: 4.84\n",
            "[4/150]: Training Loss: 4.246265041351318, Training Accuracy: 5.2175\n",
            "Validation Loss: 4.227905522486207, Validation Accuracy: 6.02\n",
            "[5/150]: Training Loss: 4.176178216934204, Training Accuracy: 6.1675\n",
            "Validation Loss: 4.179626170237353, Validation Accuracy: 6.38\n",
            "[6/150]: Training Loss: 4.135982835769654, Training Accuracy: 6.6675\n",
            "Validation Loss: 4.148335417364813, Validation Accuracy: 6.64\n",
            "[7/150]: Training Loss: 4.108450821304321, Training Accuracy: 7.2275\n",
            "Validation Loss: 4.130975275282648, Validation Accuracy: 6.89\n",
            "[8/150]: Training Loss: 4.0844139430999755, Training Accuracy: 7.6\n",
            "Validation Loss: 4.101699337078507, Validation Accuracy: 7.5\n",
            "[9/150]: Training Loss: 4.065156806564331, Training Accuracy: 7.93\n",
            "Validation Loss: 4.086441223788413, Validation Accuracy: 7.13\n",
            "[10/150]: Training Loss: 4.045691847991943, Training Accuracy: 8.4825\n",
            "Validation Loss: 4.07577043733779, Validation Accuracy: 8.03\n",
            "[11/150]: Training Loss: 4.029001393127442, Training Accuracy: 8.6075\n",
            "Validation Loss: 4.055504823186595, Validation Accuracy: 8.33\n",
            "[12/150]: Training Loss: 4.011618738937378, Training Accuracy: 9.0575\n",
            "Validation Loss: 4.039901239856793, Validation Accuracy: 8.48\n",
            "[13/150]: Training Loss: 3.9964084663391115, Training Accuracy: 9.2925\n",
            "Validation Loss: 4.02936831097694, Validation Accuracy: 8.91\n",
            "[14/150]: Training Loss: 3.9814702980041505, Training Accuracy: 9.4925\n",
            "Validation Loss: 4.011358877655807, Validation Accuracy: 9.08\n",
            "[15/150]: Training Loss: 3.967844100570679, Training Accuracy: 9.735\n",
            "Validation Loss: 4.00843292133064, Validation Accuracy: 9.01\n",
            "[16/150]: Training Loss: 3.9526515048980713, Training Accuracy: 10.11\n",
            "Validation Loss: 3.983490101091421, Validation Accuracy: 9.73\n",
            "[17/150]: Training Loss: 3.9376510147094725, Training Accuracy: 10.2675\n",
            "Validation Loss: 3.9689508137429597, Validation Accuracy: 9.61\n",
            "[18/150]: Training Loss: 3.9245626121520996, Training Accuracy: 10.52\n",
            "Validation Loss: 3.9620496361118973, Validation Accuracy: 9.98\n",
            "[19/150]: Training Loss: 3.910297552108765, Training Accuracy: 10.8175\n",
            "Validation Loss: 3.952874835129756, Validation Accuracy: 10.09\n",
            "[20/150]: Training Loss: 3.8983414665222167, Training Accuracy: 11.1225\n",
            "Validation Loss: 3.930051308528633, Validation Accuracy: 10.44\n",
            "[21/150]: Training Loss: 3.8838251056671145, Training Accuracy: 11.2975\n",
            "Validation Loss: 3.9188870700301637, Validation Accuracy: 10.53\n",
            "[22/150]: Training Loss: 3.870637998199463, Training Accuracy: 11.44\n",
            "Validation Loss: 3.903455512538837, Validation Accuracy: 10.81\n",
            "[23/150]: Training Loss: 3.857129457092285, Training Accuracy: 11.84\n",
            "Validation Loss: 3.8918681099156665, Validation Accuracy: 11.32\n",
            "[24/150]: Training Loss: 3.8432881324768067, Training Accuracy: 12.0075\n",
            "Validation Loss: 3.8916967568124177, Validation Accuracy: 11.36\n",
            "[25/150]: Training Loss: 3.829104020690918, Training Accuracy: 12.395\n",
            "Validation Loss: 3.874841636912838, Validation Accuracy: 11.71\n",
            "[26/150]: Training Loss: 3.814932382965088, Training Accuracy: 12.6375\n",
            "Validation Loss: 3.862990617752075, Validation Accuracy: 11.7\n",
            "[27/150]: Training Loss: 3.801380111312866, Training Accuracy: 12.8\n",
            "Validation Loss: 3.850984105638638, Validation Accuracy: 12.17\n",
            "[28/150]: Training Loss: 3.7865677406311034, Training Accuracy: 13.18\n",
            "Validation Loss: 3.830880017796899, Validation Accuracy: 12.18\n",
            "[29/150]: Training Loss: 3.7712997707366944, Training Accuracy: 13.4425\n",
            "Validation Loss: 3.816112823547072, Validation Accuracy: 12.61\n",
            "[30/150]: Training Loss: 3.7579914638519285, Training Accuracy: 13.83\n",
            "Validation Loss: 3.817626942494872, Validation Accuracy: 12.9\n",
            "[31/150]: Training Loss: 3.7429426765441893, Training Accuracy: 14.14\n",
            "Validation Loss: 3.795013807381794, Validation Accuracy: 12.82\n",
            "[32/150]: Training Loss: 3.7270426654815676, Training Accuracy: 14.46\n",
            "Validation Loss: 3.774455428882769, Validation Accuracy: 13.53\n",
            "[33/150]: Training Loss: 3.7124608081817625, Training Accuracy: 14.53\n",
            "Validation Loss: 3.7734299799439253, Validation Accuracy: 13.65\n",
            "[34/150]: Training Loss: 3.695247130584717, Training Accuracy: 15.0575\n",
            "Validation Loss: 3.749705171888801, Validation Accuracy: 14.01\n",
            "[35/150]: Training Loss: 3.679954329299927, Training Accuracy: 15.12\n",
            "Validation Loss: 3.7417220279669308, Validation Accuracy: 13.98\n",
            "[36/150]: Training Loss: 3.6635797924041746, Training Accuracy: 15.48\n",
            "Validation Loss: 3.7247597214522634, Validation Accuracy: 14.42\n",
            "[37/150]: Training Loss: 3.6480526805877687, Training Accuracy: 15.7375\n",
            "Validation Loss: 3.7059438805671254, Validation Accuracy: 14.5\n",
            "[38/150]: Training Loss: 3.6313486305236817, Training Accuracy: 16.3075\n",
            "Validation Loss: 3.6903846977622647, Validation Accuracy: 14.92\n",
            "[39/150]: Training Loss: 3.6153011852264405, Training Accuracy: 16.3475\n",
            "Validation Loss: 3.6778608826315327, Validation Accuracy: 14.79\n",
            "[40/150]: Training Loss: 3.60027672958374, Training Accuracy: 16.67\n",
            "Validation Loss: 3.6614270756958396, Validation Accuracy: 15.31\n",
            "[41/150]: Training Loss: 3.585800159072876, Training Accuracy: 16.7725\n",
            "Validation Loss: 3.655038889805982, Validation Accuracy: 15.05\n",
            "[42/150]: Training Loss: 3.5694461936950685, Training Accuracy: 17.0375\n",
            "Validation Loss: 3.636945672855256, Validation Accuracy: 15.93\n",
            "[43/150]: Training Loss: 3.5568551288604735, Training Accuracy: 17.3975\n",
            "Validation Loss: 3.627324414101376, Validation Accuracy: 16.21\n",
            "[44/150]: Training Loss: 3.5419315227508545, Training Accuracy: 17.7\n",
            "Validation Loss: 3.6199980754001886, Validation Accuracy: 16.01\n",
            "[45/150]: Training Loss: 3.529905016708374, Training Accuracy: 17.7675\n",
            "Validation Loss: 3.6078376861134913, Validation Accuracy: 16.36\n",
            "[46/150]: Training Loss: 3.5179548221588135, Training Accuracy: 18.195\n",
            "Validation Loss: 3.591066009679418, Validation Accuracy: 16.38\n",
            "[47/150]: Training Loss: 3.5055387844085693, Training Accuracy: 18.2875\n",
            "Validation Loss: 3.5880215836178726, Validation Accuracy: 16.91\n",
            "[48/150]: Training Loss: 3.4944853992462157, Training Accuracy: 18.445\n",
            "Validation Loss: 3.573359035382605, Validation Accuracy: 17.28\n",
            "[49/150]: Training Loss: 3.4836856788635253, Training Accuracy: 18.615\n",
            "Validation Loss: 3.5583009431316595, Validation Accuracy: 17.54\n",
            "[50/150]: Training Loss: 3.4725227031707764, Training Accuracy: 18.9225\n",
            "Validation Loss: 3.5552009609854145, Validation Accuracy: 17.27\n",
            "[51/150]: Training Loss: 3.461646089553833, Training Accuracy: 19.095\n",
            "Validation Loss: 3.5449378551191586, Validation Accuracy: 17.49\n",
            "[52/150]: Training Loss: 3.451679636383057, Training Accuracy: 19.2575\n",
            "Validation Loss: 3.5295108943987805, Validation Accuracy: 17.59\n",
            "[53/150]: Training Loss: 3.44256662979126, Training Accuracy: 19.475\n",
            "Validation Loss: 3.5264732868048796, Validation Accuracy: 17.73\n",
            "[54/150]: Training Loss: 3.4335047622680666, Training Accuracy: 19.5175\n",
            "Validation Loss: 3.521607499213735, Validation Accuracy: 17.96\n",
            "[55/150]: Training Loss: 3.425080271530151, Training Accuracy: 19.8125\n",
            "Validation Loss: 3.513597962203299, Validation Accuracy: 18.01\n",
            "[56/150]: Training Loss: 3.4155618144989015, Training Accuracy: 19.8425\n",
            "Validation Loss: 3.5052308413633115, Validation Accuracy: 18.2\n",
            "[57/150]: Training Loss: 3.4078545150756834, Training Accuracy: 20.0575\n",
            "Validation Loss: 3.498734108202017, Validation Accuracy: 18.36\n",
            "[58/150]: Training Loss: 3.399192015457153, Training Accuracy: 20.1425\n",
            "Validation Loss: 3.4935538814326, Validation Accuracy: 18.5\n",
            "[59/150]: Training Loss: 3.3918968856811524, Training Accuracy: 20.275\n",
            "Validation Loss: 3.4842984858591843, Validation Accuracy: 18.83\n",
            "[60/150]: Training Loss: 3.3846318199157714, Training Accuracy: 20.45\n",
            "Validation Loss: 3.475666542721402, Validation Accuracy: 18.75\n",
            "[61/150]: Training Loss: 3.378842526626587, Training Accuracy: 20.395\n",
            "Validation Loss: 3.47740289360095, Validation Accuracy: 18.53\n",
            "[62/150]: Training Loss: 3.369043716430664, Training Accuracy: 20.85\n",
            "Validation Loss: 3.469373791081131, Validation Accuracy: 18.88\n",
            "[63/150]: Training Loss: 3.363127135467529, Training Accuracy: 20.8125\n",
            "Validation Loss: 3.453160047531128, Validation Accuracy: 19.11\n",
            "[64/150]: Training Loss: 3.355681411361694, Training Accuracy: 21.0925\n",
            "Validation Loss: 3.466009464992839, Validation Accuracy: 19.12\n",
            "[65/150]: Training Loss: 3.3498121349334715, Training Accuracy: 21.1625\n",
            "Validation Loss: 3.4505164547331013, Validation Accuracy: 19.11\n",
            "[66/150]: Training Loss: 3.343057912063599, Training Accuracy: 21.225\n",
            "Validation Loss: 3.4455762957311737, Validation Accuracy: 19.05\n",
            "[67/150]: Training Loss: 3.3380538593292237, Training Accuracy: 21.2275\n",
            "Validation Loss: 3.448872314137258, Validation Accuracy: 18.99\n",
            "[68/150]: Training Loss: 3.3309446399688722, Training Accuracy: 21.4425\n",
            "Validation Loss: 3.434380317189891, Validation Accuracy: 19.65\n",
            "[69/150]: Training Loss: 3.325505153656006, Training Accuracy: 21.5125\n",
            "Validation Loss: 3.428423096419899, Validation Accuracy: 19.77\n",
            "[70/150]: Training Loss: 3.319794240951538, Training Accuracy: 21.7375\n",
            "Validation Loss: 3.4293241318623733, Validation Accuracy: 19.58\n",
            "[71/150]: Training Loss: 3.3128502590179445, Training Accuracy: 21.7775\n",
            "Validation Loss: 3.422350405128139, Validation Accuracy: 19.89\n",
            "[72/150]: Training Loss: 3.308202914047241, Training Accuracy: 21.9175\n",
            "Validation Loss: 3.4211007197191763, Validation Accuracy: 20.03\n",
            "[73/150]: Training Loss: 3.3036910511016844, Training Accuracy: 21.85\n",
            "Validation Loss: 3.412458062931231, Validation Accuracy: 19.99\n",
            "[74/150]: Training Loss: 3.2999632190704347, Training Accuracy: 22.05\n",
            "Validation Loss: 3.410503987294094, Validation Accuracy: 19.96\n",
            "[75/150]: Training Loss: 3.2934399642944334, Training Accuracy: 21.9825\n",
            "Validation Loss: 3.4070342604521735, Validation Accuracy: 20.1\n",
            "[76/150]: Training Loss: 3.288022666168213, Training Accuracy: 22.4075\n",
            "Validation Loss: 3.3981059220186465, Validation Accuracy: 20.33\n",
            "[77/150]: Training Loss: 3.283489876937866, Training Accuracy: 22.37\n",
            "Validation Loss: 3.403488172846995, Validation Accuracy: 20.14\n",
            "[78/150]: Training Loss: 3.279419002151489, Training Accuracy: 22.4725\n",
            "Validation Loss: 3.39810815434547, Validation Accuracy: 20.23\n",
            "[79/150]: Training Loss: 3.275748169708252, Training Accuracy: 22.3675\n",
            "Validation Loss: 3.3924497191313727, Validation Accuracy: 20.38\n",
            "[80/150]: Training Loss: 3.2700943855285645, Training Accuracy: 22.625\n",
            "Validation Loss: 3.394149239655513, Validation Accuracy: 20.3\n",
            "[81/150]: Training Loss: 3.266976011657715, Training Accuracy: 22.6325\n",
            "Validation Loss: 3.389360663237845, Validation Accuracy: 20.25\n",
            "[82/150]: Training Loss: 3.2631465213775637, Training Accuracy: 22.7725\n",
            "Validation Loss: 3.3781265529098023, Validation Accuracy: 20.61\n",
            "[83/150]: Training Loss: 3.2582495727539063, Training Accuracy: 22.885\n",
            "Validation Loss: 3.380337715148926, Validation Accuracy: 20.88\n",
            "[84/150]: Training Loss: 3.2537473976135254, Training Accuracy: 23.075\n",
            "Validation Loss: 3.3771434042863784, Validation Accuracy: 20.89\n",
            "[85/150]: Training Loss: 3.2507594604492187, Training Accuracy: 22.9875\n",
            "Validation Loss: 3.3780695936482426, Validation Accuracy: 20.92\n",
            "[86/150]: Training Loss: 3.246923331832886, Training Accuracy: 23.055\n",
            "Validation Loss: 3.3708357325025426, Validation Accuracy: 20.88\n",
            "[87/150]: Training Loss: 3.2429458431243896, Training Accuracy: 23.1625\n",
            "Validation Loss: 3.36568513493629, Validation Accuracy: 21.0\n",
            "[88/150]: Training Loss: 3.239496036148071, Training Accuracy: 23.09\n",
            "Validation Loss: 3.369001481183775, Validation Accuracy: 20.84\n",
            "[89/150]: Training Loss: 3.235803797531128, Training Accuracy: 23.2875\n",
            "Validation Loss: 3.362776779065466, Validation Accuracy: 21.19\n",
            "[90/150]: Training Loss: 3.2327476997375486, Training Accuracy: 23.39\n",
            "Validation Loss: 3.3616829556264696, Validation Accuracy: 21.16\n",
            "[91/150]: Training Loss: 3.229936269760132, Training Accuracy: 23.3875\n",
            "Validation Loss: 3.360888686149743, Validation Accuracy: 21.41\n",
            "[92/150]: Training Loss: 3.2263083686828615, Training Accuracy: 23.4225\n",
            "Validation Loss: 3.359251875786265, Validation Accuracy: 21.08\n",
            "[93/150]: Training Loss: 3.224231428909302, Training Accuracy: 23.5575\n",
            "Validation Loss: 3.3559617753241473, Validation Accuracy: 21.38\n",
            "[94/150]: Training Loss: 3.2209563293457033, Training Accuracy: 23.52\n",
            "Validation Loss: 3.3566071850479027, Validation Accuracy: 21.38\n",
            "[95/150]: Training Loss: 3.2181186485290527, Training Accuracy: 23.5925\n",
            "Validation Loss: 3.3525171613996956, Validation Accuracy: 21.11\n",
            "[96/150]: Training Loss: 3.2156093044281007, Training Accuracy: 23.6025\n",
            "Validation Loss: 3.3487717983828986, Validation Accuracy: 21.48\n",
            "[97/150]: Training Loss: 3.211993044281006, Training Accuracy: 23.67\n",
            "Validation Loss: 3.3509595333390934, Validation Accuracy: 21.34\n",
            "[98/150]: Training Loss: 3.2086189796447755, Training Accuracy: 23.7725\n",
            "Validation Loss: 3.35127718585312, Validation Accuracy: 21.49\n",
            "[99/150]: Training Loss: 3.2077421699523927, Training Accuracy: 23.7925\n",
            "Validation Loss: 3.345605060553095, Validation Accuracy: 21.5\n",
            "[100/150]: Training Loss: 3.2047137928009035, Training Accuracy: 23.7025\n",
            "Validation Loss: 3.3447778088271996, Validation Accuracy: 21.56\n",
            "[101/150]: Training Loss: 3.202946053314209, Training Accuracy: 23.8775\n",
            "Validation Loss: 3.342098644584607, Validation Accuracy: 21.49\n",
            "[102/150]: Training Loss: 3.2004322288513185, Training Accuracy: 23.8375\n",
            "Validation Loss: 3.343631648713616, Validation Accuracy: 21.61\n",
            "[103/150]: Training Loss: 3.1983728965759277, Training Accuracy: 23.9425\n",
            "Validation Loss: 3.3422155471364405, Validation Accuracy: 21.24\n",
            "[104/150]: Training Loss: 3.196205286026001, Training Accuracy: 23.9975\n",
            "Validation Loss: 3.3361381269564294, Validation Accuracy: 21.8\n",
            "[105/150]: Training Loss: 3.194296379852295, Training Accuracy: 23.9125\n",
            "Validation Loss: 3.3376316750884816, Validation Accuracy: 21.59\n",
            "[106/150]: Training Loss: 3.1917529289245605, Training Accuracy: 23.9425\n",
            "Validation Loss: 3.3328404289901634, Validation Accuracy: 21.83\n",
            "[107/150]: Training Loss: 3.1901755290985108, Training Accuracy: 24.06\n",
            "Validation Loss: 3.335774242498313, Validation Accuracy: 21.85\n",
            "[108/150]: Training Loss: 3.188256001663208, Training Accuracy: 24.01\n",
            "Validation Loss: 3.335664199416045, Validation Accuracy: 21.84\n",
            "[109/150]: Training Loss: 3.186541044998169, Training Accuracy: 24.1\n",
            "Validation Loss: 3.331627411447513, Validation Accuracy: 21.98\n",
            "[110/150]: Training Loss: 3.184773151397705, Training Accuracy: 24.0825\n",
            "Validation Loss: 3.3308697946512016, Validation Accuracy: 21.79\n",
            "[111/150]: Training Loss: 3.1835228912353517, Training Accuracy: 24.1275\n",
            "Validation Loss: 3.3312593797209917, Validation Accuracy: 21.68\n",
            "[112/150]: Training Loss: 3.181557007980347, Training Accuracy: 24.2275\n",
            "Validation Loss: 3.3289258191539983, Validation Accuracy: 21.87\n",
            "[113/150]: Training Loss: 3.180008267211914, Training Accuracy: 24.3675\n",
            "Validation Loss: 3.3277820234845397, Validation Accuracy: 21.73\n",
            "[114/150]: Training Loss: 3.1787550163269045, Training Accuracy: 24.2975\n",
            "Validation Loss: 3.326631183077575, Validation Accuracy: 21.95\n",
            "[115/150]: Training Loss: 3.177647034072876, Training Accuracy: 24.285\n",
            "Validation Loss: 3.3255794716488785, Validation Accuracy: 22.03\n",
            "[116/150]: Training Loss: 3.176307448196411, Training Accuracy: 24.385\n",
            "Validation Loss: 3.3254039242009448, Validation Accuracy: 21.9\n",
            "[117/150]: Training Loss: 3.175141114425659, Training Accuracy: 24.3075\n",
            "Validation Loss: 3.3223649164673628, Validation Accuracy: 22.03\n",
            "[118/150]: Training Loss: 3.173803305053711, Training Accuracy: 24.4125\n",
            "Validation Loss: 3.323437298938727, Validation Accuracy: 21.99\n",
            "[119/150]: Training Loss: 3.1727485507965087, Training Accuracy: 24.345\n",
            "Validation Loss: 3.3220133781433105, Validation Accuracy: 22.09\n",
            "[120/150]: Training Loss: 3.171308903121948, Training Accuracy: 24.475\n",
            "Validation Loss: 3.320924275999616, Validation Accuracy: 22.15\n",
            "[121/150]: Training Loss: 3.1707864654541016, Training Accuracy: 24.485\n",
            "Validation Loss: 3.3217681638754097, Validation Accuracy: 21.98\n",
            "[122/150]: Training Loss: 3.169487755203247, Training Accuracy: 24.5\n",
            "Validation Loss: 3.3205978354071357, Validation Accuracy: 22.2\n",
            "[123/150]: Training Loss: 3.1687754665374754, Training Accuracy: 24.4775\n",
            "Validation Loss: 3.3199286217902118, Validation Accuracy: 22.03\n",
            "[124/150]: Training Loss: 3.1677217502593993, Training Accuracy: 24.5225\n",
            "Validation Loss: 3.3194276329818044, Validation Accuracy: 22.2\n",
            "[125/150]: Training Loss: 3.1672953506469725, Training Accuracy: 24.53\n",
            "Validation Loss: 3.3200536381666828, Validation Accuracy: 22.05\n",
            "[126/150]: Training Loss: 3.166370540237427, Training Accuracy: 24.53\n",
            "Validation Loss: 3.3180840486174175, Validation Accuracy: 22.01\n",
            "[127/150]: Training Loss: 3.165336986541748, Training Accuracy: 24.565\n",
            "Validation Loss: 3.318746434655159, Validation Accuracy: 22.24\n",
            "[128/150]: Training Loss: 3.164968849182129, Training Accuracy: 24.535\n",
            "Validation Loss: 3.3186944214401732, Validation Accuracy: 22.05\n",
            "[129/150]: Training Loss: 3.1642740074157714, Training Accuracy: 24.5175\n",
            "Validation Loss: 3.3177084133123897, Validation Accuracy: 22.21\n",
            "[130/150]: Training Loss: 3.16352066116333, Training Accuracy: 24.655\n",
            "Validation Loss: 3.318562794642843, Validation Accuracy: 22.01\n",
            "[131/150]: Training Loss: 3.1630500473022463, Training Accuracy: 24.5975\n",
            "Validation Loss: 3.317300656798539, Validation Accuracy: 22.06\n",
            "[132/150]: Training Loss: 3.1626014945983885, Training Accuracy: 24.66\n",
            "Validation Loss: 3.317058933768303, Validation Accuracy: 22.16\n",
            "[133/150]: Training Loss: 3.161920825958252, Training Accuracy: 24.64\n",
            "Validation Loss: 3.3171579837799072, Validation Accuracy: 22.02\n",
            "[134/150]: Training Loss: 3.161545040512085, Training Accuracy: 24.6375\n",
            "Validation Loss: 3.316502076045723, Validation Accuracy: 22.18\n",
            "[135/150]: Training Loss: 3.1611102500915527, Training Accuracy: 24.585\n",
            "Validation Loss: 3.3166633107859615, Validation Accuracy: 22.06\n",
            "[136/150]: Training Loss: 3.160765283203125, Training Accuracy: 24.6325\n",
            "Validation Loss: 3.3164391669498126, Validation Accuracy: 22.14\n",
            "[137/150]: Training Loss: 3.160325936508179, Training Accuracy: 24.6675\n",
            "Validation Loss: 3.315987286294342, Validation Accuracy: 22.11\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 5.462109195198982, Test Accuracy: 10.88\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>10.88</td></tr><tr><td>Test Loss</td><td>5.46211</td></tr><tr><td>Train Accuracy</td><td>24.6675</td></tr><tr><td>Train Loss</td><td>3.16033</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.05 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/cthymqs8</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_023355-cthymqs8/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.1 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_024913-26wygp07</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">learning_rate=0.1 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.554393922424317, Training Accuracy: 2.2\n",
            "Validation Loss: 4.421840394378468, Validation Accuracy: 3.74\n",
            "[2/150]: Training Loss: 4.284681567382813, Training Accuracy: 4.52\n",
            "Validation Loss: 4.239770348664302, Validation Accuracy: 4.95\n",
            "[3/150]: Training Loss: 4.181965134429932, Training Accuracy: 5.585\n",
            "Validation Loss: 4.184003517126581, Validation Accuracy: 5.53\n",
            "[4/150]: Training Loss: 4.125413941192627, Training Accuracy: 6.6775\n",
            "Validation Loss: 4.123335443484556, Validation Accuracy: 6.52\n",
            "[5/150]: Training Loss: 4.084817845535278, Training Accuracy: 7.4525\n",
            "Validation Loss: 4.096477279237881, Validation Accuracy: 6.87\n",
            "[6/150]: Training Loss: 4.048351853179931, Training Accuracy: 8.1125\n",
            "Validation Loss: 4.069233142646255, Validation Accuracy: 7.8\n",
            "[7/150]: Training Loss: 4.018422792816162, Training Accuracy: 8.56\n",
            "Validation Loss: 4.0364193445558, Validation Accuracy: 8.44\n",
            "[8/150]: Training Loss: 3.989247378540039, Training Accuracy: 8.9625\n",
            "Validation Loss: 4.010960247865908, Validation Accuracy: 8.51\n",
            "[9/150]: Training Loss: 3.9593318000793456, Training Accuracy: 9.5725\n",
            "Validation Loss: 3.9864684988738626, Validation Accuracy: 8.73\n",
            "[10/150]: Training Loss: 3.935969552612305, Training Accuracy: 9.97\n",
            "Validation Loss: 3.959391053315181, Validation Accuracy: 9.43\n",
            "[11/150]: Training Loss: 3.910384812927246, Training Accuracy: 10.53\n",
            "Validation Loss: 3.9335520723063473, Validation Accuracy: 10.05\n",
            "[12/150]: Training Loss: 3.8837633472442628, Training Accuracy: 11.015\n",
            "Validation Loss: 3.9218593843423637, Validation Accuracy: 9.91\n",
            "[13/150]: Training Loss: 3.85968777885437, Training Accuracy: 11.265\n",
            "Validation Loss: 3.884523991566555, Validation Accuracy: 10.94\n",
            "[14/150]: Training Loss: 3.83401321182251, Training Accuracy: 12.19\n",
            "Validation Loss: 3.8702170302154153, Validation Accuracy: 11.29\n",
            "[15/150]: Training Loss: 3.8098957332611083, Training Accuracy: 12.6325\n",
            "Validation Loss: 3.840197701363047, Validation Accuracy: 11.62\n",
            "[16/150]: Training Loss: 3.7832756935119627, Training Accuracy: 13.2\n",
            "Validation Loss: 3.8233511766810326, Validation Accuracy: 12.45\n",
            "[17/150]: Training Loss: 3.755026846694946, Training Accuracy: 13.5\n",
            "Validation Loss: 3.7900661996975065, Validation Accuracy: 12.91\n",
            "[18/150]: Training Loss: 3.7291974296569825, Training Accuracy: 14.06\n",
            "Validation Loss: 3.7731176181963293, Validation Accuracy: 13.22\n",
            "[19/150]: Training Loss: 3.703822989273071, Training Accuracy: 14.6625\n",
            "Validation Loss: 3.742501725057128, Validation Accuracy: 13.6\n",
            "[20/150]: Training Loss: 3.676954047012329, Training Accuracy: 15.14\n",
            "Validation Loss: 3.718170521365609, Validation Accuracy: 14.24\n",
            "[21/150]: Training Loss: 3.6502103706359863, Training Accuracy: 15.59\n",
            "Validation Loss: 3.6871351967951296, Validation Accuracy: 14.81\n",
            "[22/150]: Training Loss: 3.622364068222046, Training Accuracy: 16.105\n",
            "Validation Loss: 3.67376760464565, Validation Accuracy: 14.79\n",
            "[23/150]: Training Loss: 3.5969187736511232, Training Accuracy: 16.585\n",
            "Validation Loss: 3.6408486214413007, Validation Accuracy: 15.59\n",
            "[24/150]: Training Loss: 3.568799534988403, Training Accuracy: 17.215\n",
            "Validation Loss: 3.6294803862359113, Validation Accuracy: 15.79\n",
            "[25/150]: Training Loss: 3.5421108798980714, Training Accuracy: 17.57\n",
            "Validation Loss: 3.598143538092352, Validation Accuracy: 16.37\n",
            "[26/150]: Training Loss: 3.5124191093444823, Training Accuracy: 18.205\n",
            "Validation Loss: 3.5703049495721317, Validation Accuracy: 16.98\n",
            "[27/150]: Training Loss: 3.484529112625122, Training Accuracy: 18.7275\n",
            "Validation Loss: 3.5376776236637384, Validation Accuracy: 17.48\n",
            "[28/150]: Training Loss: 3.455819899749756, Training Accuracy: 19.0425\n",
            "Validation Loss: 3.5291991643844898, Validation Accuracy: 17.68\n",
            "[29/150]: Training Loss: 3.4284223934173585, Training Accuracy: 19.5625\n",
            "Validation Loss: 3.4991380257211673, Validation Accuracy: 18.43\n",
            "[30/150]: Training Loss: 3.4028552402496337, Training Accuracy: 20.0525\n",
            "Validation Loss: 3.4806957472661497, Validation Accuracy: 18.35\n",
            "[31/150]: Training Loss: 3.376880758666992, Training Accuracy: 20.5925\n",
            "Validation Loss: 3.450026891793415, Validation Accuracy: 19.53\n",
            "[32/150]: Training Loss: 3.354429434585571, Training Accuracy: 21.165\n",
            "Validation Loss: 3.435450357995975, Validation Accuracy: 19.72\n",
            "[33/150]: Training Loss: 3.3340842437744143, Training Accuracy: 21.175\n",
            "Validation Loss: 3.418211444927629, Validation Accuracy: 19.67\n",
            "[34/150]: Training Loss: 3.314141171646118, Training Accuracy: 21.5925\n",
            "Validation Loss: 3.4085868847597935, Validation Accuracy: 20.29\n",
            "[35/150]: Training Loss: 3.2981444416046144, Training Accuracy: 21.85\n",
            "Validation Loss: 3.3930132495369882, Validation Accuracy: 20.07\n",
            "[36/150]: Training Loss: 3.280233634567261, Training Accuracy: 22.4375\n",
            "Validation Loss: 3.3805624132703063, Validation Accuracy: 20.71\n",
            "[37/150]: Training Loss: 3.2627798179626466, Training Accuracy: 22.555\n",
            "Validation Loss: 3.365730774630407, Validation Accuracy: 21.1\n",
            "[38/150]: Training Loss: 3.246723106765747, Training Accuracy: 22.8925\n",
            "Validation Loss: 3.3649645671722994, Validation Accuracy: 21.17\n",
            "[39/150]: Training Loss: 3.23333472366333, Training Accuracy: 23.1725\n",
            "Validation Loss: 3.340107489543356, Validation Accuracy: 21.48\n",
            "[40/150]: Training Loss: 3.2185105766296385, Training Accuracy: 23.425\n",
            "Validation Loss: 3.3351985269291387, Validation Accuracy: 21.9\n",
            "[41/150]: Training Loss: 3.2041201099395753, Training Accuracy: 23.65\n",
            "Validation Loss: 3.320353848159693, Validation Accuracy: 22.37\n",
            "[42/150]: Training Loss: 3.1920853351593017, Training Accuracy: 23.97\n",
            "Validation Loss: 3.3151075627393785, Validation Accuracy: 21.98\n",
            "[43/150]: Training Loss: 3.178889651107788, Training Accuracy: 24.015\n",
            "Validation Loss: 3.3039617690311114, Validation Accuracy: 22.11\n",
            "[44/150]: Training Loss: 3.164986518096924, Training Accuracy: 24.4275\n",
            "Validation Loss: 3.2982496850809473, Validation Accuracy: 22.16\n",
            "[45/150]: Training Loss: 3.1540319355010986, Training Accuracy: 24.705\n",
            "Validation Loss: 3.2881052099215755, Validation Accuracy: 22.49\n",
            "[46/150]: Training Loss: 3.1423869262695314, Training Accuracy: 24.745\n",
            "Validation Loss: 3.285053641932785, Validation Accuracy: 22.32\n",
            "[47/150]: Training Loss: 3.1313994647979735, Training Accuracy: 25.0425\n",
            "Validation Loss: 3.2773830009873506, Validation Accuracy: 22.64\n",
            "[48/150]: Training Loss: 3.1199681632995606, Training Accuracy: 25.2175\n",
            "Validation Loss: 3.2647413463349553, Validation Accuracy: 22.66\n",
            "[49/150]: Training Loss: 3.107323546600342, Training Accuracy: 25.5575\n",
            "Validation Loss: 3.277184949559011, Validation Accuracy: 22.72\n",
            "[50/150]: Training Loss: 3.0971016899108887, Training Accuracy: 25.77\n",
            "Validation Loss: 3.2499756160055755, Validation Accuracy: 22.69\n",
            "[51/150]: Training Loss: 3.0865638957977293, Training Accuracy: 25.915\n",
            "Validation Loss: 3.28796663102071, Validation Accuracy: 22.45\n",
            "[52/150]: Training Loss: 3.075482699203491, Training Accuracy: 26.0775\n",
            "Validation Loss: 3.256385016593204, Validation Accuracy: 22.97\n",
            "[53/150]: Training Loss: 3.0676188301086427, Training Accuracy: 26.045\n",
            "Validation Loss: 3.2297865843317313, Validation Accuracy: 23.53\n",
            "[54/150]: Training Loss: 3.0562880493164064, Training Accuracy: 26.5925\n",
            "Validation Loss: 3.2346752266974965, Validation Accuracy: 23.32\n",
            "[55/150]: Training Loss: 3.046115529251099, Training Accuracy: 26.525\n",
            "Validation Loss: 3.229158471344383, Validation Accuracy: 23.27\n",
            "[56/150]: Training Loss: 3.0363171295166014, Training Accuracy: 26.5875\n",
            "Validation Loss: 3.2251109287237667, Validation Accuracy: 23.85\n",
            "[57/150]: Training Loss: 3.0262594100952147, Training Accuracy: 26.96\n",
            "Validation Loss: 3.20999311793382, Validation Accuracy: 23.73\n",
            "[58/150]: Training Loss: 3.018730586242676, Training Accuracy: 26.925\n",
            "Validation Loss: 3.206504849111958, Validation Accuracy: 23.66\n",
            "[59/150]: Training Loss: 3.007856759262085, Training Accuracy: 27.315\n",
            "Validation Loss: 3.2090084021258507, Validation Accuracy: 24.02\n",
            "[60/150]: Training Loss: 3.0000602096557616, Training Accuracy: 27.39\n",
            "Validation Loss: 3.2029919001706846, Validation Accuracy: 23.96\n",
            "[61/150]: Training Loss: 2.9893322017669677, Training Accuracy: 27.6525\n",
            "Validation Loss: 3.207233451733923, Validation Accuracy: 23.61\n",
            "[62/150]: Training Loss: 2.9812552192687987, Training Accuracy: 27.855\n",
            "Validation Loss: 3.191280894978031, Validation Accuracy: 23.71\n",
            "[63/150]: Training Loss: 2.972245023727417, Training Accuracy: 27.83\n",
            "Validation Loss: 3.191427630224046, Validation Accuracy: 24.21\n",
            "[64/150]: Training Loss: 2.9653648654937745, Training Accuracy: 28.0175\n",
            "Validation Loss: 3.189020594214178, Validation Accuracy: 24.07\n",
            "[65/150]: Training Loss: 2.957701969909668, Training Accuracy: 28.245\n",
            "Validation Loss: 3.183226536793314, Validation Accuracy: 23.98\n",
            "[66/150]: Training Loss: 2.9480487686157226, Training Accuracy: 28.3725\n",
            "Validation Loss: 3.1869888670125586, Validation Accuracy: 24.08\n",
            "[67/150]: Training Loss: 2.9404784973144533, Training Accuracy: 28.5625\n",
            "Validation Loss: 3.1826100653144205, Validation Accuracy: 24.61\n",
            "[68/150]: Training Loss: 2.9308408599853517, Training Accuracy: 28.73\n",
            "Validation Loss: 3.1697433404861743, Validation Accuracy: 24.11\n",
            "[69/150]: Training Loss: 2.924504146194458, Training Accuracy: 28.735\n",
            "Validation Loss: 3.164285852650928, Validation Accuracy: 24.76\n",
            "[70/150]: Training Loss: 2.9181696743011476, Training Accuracy: 29.045\n",
            "Validation Loss: 3.1617295559804153, Validation Accuracy: 24.5\n",
            "[71/150]: Training Loss: 2.909669787979126, Training Accuracy: 28.97\n",
            "Validation Loss: 3.16842480222131, Validation Accuracy: 24.55\n",
            "[72/150]: Training Loss: 2.901284480667114, Training Accuracy: 29.165\n",
            "Validation Loss: 3.16541398710506, Validation Accuracy: 24.39\n",
            "[73/150]: Training Loss: 2.8958903297424317, Training Accuracy: 29.41\n",
            "Validation Loss: 3.156350550378204, Validation Accuracy: 24.81\n",
            "[74/150]: Training Loss: 2.8880927780151366, Training Accuracy: 29.51\n",
            "Validation Loss: 3.1484538536922186, Validation Accuracy: 24.79\n",
            "[75/150]: Training Loss: 2.8816709129333495, Training Accuracy: 29.6575\n",
            "Validation Loss: 3.1521760521421007, Validation Accuracy: 24.75\n",
            "[76/150]: Training Loss: 2.874811888885498, Training Accuracy: 29.6025\n",
            "Validation Loss: 3.1412497159022434, Validation Accuracy: 24.86\n",
            "[77/150]: Training Loss: 2.868447174453735, Training Accuracy: 29.75\n",
            "Validation Loss: 3.148860450003557, Validation Accuracy: 25.12\n",
            "[78/150]: Training Loss: 2.8620141311645506, Training Accuracy: 30.02\n",
            "Validation Loss: 3.1491585096735863, Validation Accuracy: 25.07\n",
            "[79/150]: Training Loss: 2.8542796688079832, Training Accuracy: 30.2175\n",
            "Validation Loss: 3.1315311428847585, Validation Accuracy: 25.26\n",
            "[80/150]: Training Loss: 2.8495312446594236, Training Accuracy: 30.2625\n",
            "Validation Loss: 3.1400332511610287, Validation Accuracy: 25.12\n",
            "[81/150]: Training Loss: 2.8422299156188964, Training Accuracy: 30.4475\n",
            "Validation Loss: 3.129277274866772, Validation Accuracy: 25.51\n",
            "[82/150]: Training Loss: 2.8352813999176028, Training Accuracy: 30.645\n",
            "Validation Loss: 3.1319479532302563, Validation Accuracy: 25.37\n",
            "[83/150]: Training Loss: 2.830805637359619, Training Accuracy: 30.595\n",
            "Validation Loss: 3.1387126217981813, Validation Accuracy: 25.34\n",
            "[84/150]: Training Loss: 2.824944213485718, Training Accuracy: 30.7875\n",
            "Validation Loss: 3.1277991054923673, Validation Accuracy: 25.58\n",
            "[85/150]: Training Loss: 2.8196789070129396, Training Accuracy: 31.02\n",
            "Validation Loss: 3.1215793433462737, Validation Accuracy: 25.59\n",
            "[86/150]: Training Loss: 2.814448028564453, Training Accuracy: 31.1025\n",
            "Validation Loss: 3.1227446027622103, Validation Accuracy: 25.41\n",
            "[87/150]: Training Loss: 2.8087932884216307, Training Accuracy: 31.3075\n",
            "Validation Loss: 3.123080830665151, Validation Accuracy: 25.3\n",
            "[88/150]: Training Loss: 2.8027573429107666, Training Accuracy: 31.35\n",
            "Validation Loss: 3.1130096623851995, Validation Accuracy: 25.94\n",
            "[89/150]: Training Loss: 2.7979101371765136, Training Accuracy: 31.195\n",
            "Validation Loss: 3.1245606795997376, Validation Accuracy: 25.59\n",
            "[90/150]: Training Loss: 2.79326137008667, Training Accuracy: 31.37\n",
            "Validation Loss: 3.1252101788854905, Validation Accuracy: 25.47\n",
            "[91/150]: Training Loss: 2.7884928009033203, Training Accuracy: 31.3925\n",
            "Validation Loss: 3.115745410797702, Validation Accuracy: 25.52\n",
            "[92/150]: Training Loss: 2.7844152694702147, Training Accuracy: 31.5825\n",
            "Validation Loss: 3.1132962870749696, Validation Accuracy: 25.67\n",
            "[93/150]: Training Loss: 2.7792159679412842, Training Accuracy: 31.665\n",
            "Validation Loss: 3.111494478906036, Validation Accuracy: 25.84\n",
            "[94/150]: Training Loss: 2.773549281311035, Training Accuracy: 31.6525\n",
            "Validation Loss: 3.1067730256706287, Validation Accuracy: 25.89\n",
            "[95/150]: Training Loss: 2.76964068031311, Training Accuracy: 31.895\n",
            "Validation Loss: 3.1083280220153227, Validation Accuracy: 25.78\n",
            "[96/150]: Training Loss: 2.7651722465515136, Training Accuracy: 31.8825\n",
            "Validation Loss: 3.1057740730844485, Validation Accuracy: 25.67\n",
            "[97/150]: Training Loss: 2.761124114608765, Training Accuracy: 32.1025\n",
            "Validation Loss: 3.1073889534944183, Validation Accuracy: 25.55\n",
            "[98/150]: Training Loss: 2.756427172470093, Training Accuracy: 32.1475\n",
            "Validation Loss: 3.1095221422280477, Validation Accuracy: 25.75\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 6.147166403995198, Test Accuracy: 12.53\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.53</td></tr><tr><td>Test Loss</td><td>6.14717</td></tr><tr><td>Train Accuracy</td><td>32.1475</td></tr><tr><td>Train Loss</td><td>2.75643</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.1 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/26wygp07</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_024913-26wygp07/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.5 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_030015-a8qnvlbp</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">learning_rate=0.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.377298123168945, Training Accuracy: 3.2725\n",
            "Validation Loss: 4.2101050941807445, Validation Accuracy: 5.2\n",
            "[2/150]: Training Loss: 4.07323479423523, Training Accuracy: 7.05\n",
            "Validation Loss: 3.997956647994412, Validation Accuracy: 8.69\n",
            "[3/150]: Training Loss: 3.9166299026489257, Training Accuracy: 9.98\n",
            "Validation Loss: 3.8700176090191882, Validation Accuracy: 10.85\n",
            "[4/150]: Training Loss: 3.76255333404541, Training Accuracy: 12.6475\n",
            "Validation Loss: 3.7763638131937403, Validation Accuracy: 12.03\n",
            "[5/150]: Training Loss: 3.6385873168945313, Training Accuracy: 14.8\n",
            "Validation Loss: 3.5995885247637514, Validation Accuracy: 15.3\n",
            "[6/150]: Training Loss: 3.5313883621215822, Training Accuracy: 16.6625\n",
            "Validation Loss: 3.547201700271315, Validation Accuracy: 16.33\n",
            "[7/150]: Training Loss: 3.4311797870635985, Training Accuracy: 18.0425\n",
            "Validation Loss: 3.447270431336324, Validation Accuracy: 18.49\n",
            "[8/150]: Training Loss: 3.3406018447875976, Training Accuracy: 20.2325\n",
            "Validation Loss: 3.3745645914867426, Validation Accuracy: 19.81\n",
            "[9/150]: Training Loss: 3.2601512760162352, Training Accuracy: 21.73\n",
            "Validation Loss: 3.3083346163391307, Validation Accuracy: 21.21\n",
            "[10/150]: Training Loss: 3.190315942764282, Training Accuracy: 23.0925\n",
            "Validation Loss: 3.2459553244766917, Validation Accuracy: 22.4\n",
            "[11/150]: Training Loss: 3.120881378555298, Training Accuracy: 24.2625\n",
            "Validation Loss: 3.2441095774340782, Validation Accuracy: 22.07\n",
            "[12/150]: Training Loss: 3.065099639892578, Training Accuracy: 25.1825\n",
            "Validation Loss: 3.205546066259882, Validation Accuracy: 22.44\n",
            "[13/150]: Training Loss: 3.002047216796875, Training Accuracy: 26.4075\n",
            "Validation Loss: 3.1507282090035216, Validation Accuracy: 24.42\n",
            "[14/150]: Training Loss: 2.947496301269531, Training Accuracy: 27.6075\n",
            "Validation Loss: 3.1272822519776167, Validation Accuracy: 24.2\n",
            "[15/150]: Training Loss: 2.8929669227600097, Training Accuracy: 28.1625\n",
            "Validation Loss: 3.08642372052381, Validation Accuracy: 25.55\n",
            "[16/150]: Training Loss: 2.8405557304382323, Training Accuracy: 29.4725\n",
            "Validation Loss: 3.021532262206837, Validation Accuracy: 26.7\n",
            "[17/150]: Training Loss: 2.7890852066040037, Training Accuracy: 30.505\n",
            "Validation Loss: 3.042905480998337, Validation Accuracy: 26.24\n",
            "[18/150]: Training Loss: 2.74124369392395, Training Accuracy: 31.39\n",
            "Validation Loss: 2.9991517309929914, Validation Accuracy: 26.63\n",
            "[19/150]: Training Loss: 2.692549164581299, Training Accuracy: 32.36\n",
            "Validation Loss: 2.9798509998685994, Validation Accuracy: 27.88\n",
            "[20/150]: Training Loss: 2.6449439025878907, Training Accuracy: 33.1025\n",
            "Validation Loss: 3.0654538998937912, Validation Accuracy: 26.5\n",
            "[21/150]: Training Loss: 2.6013897836685183, Training Accuracy: 34.135\n",
            "Validation Loss: 2.937944315041706, Validation Accuracy: 29.27\n",
            "[22/150]: Training Loss: 2.5583987575531006, Training Accuracy: 35.0375\n",
            "Validation Loss: 2.965156334980278, Validation Accuracy: 28.48\n",
            "[23/150]: Training Loss: 2.5067957414627076, Training Accuracy: 36.145\n",
            "Validation Loss: 2.940655703757219, Validation Accuracy: 28.99\n",
            "[24/150]: Training Loss: 2.4618710725784303, Training Accuracy: 37.005\n",
            "Validation Loss: 2.9297352444594074, Validation Accuracy: 28.88\n",
            "[25/150]: Training Loss: 2.4159774208068847, Training Accuracy: 37.9375\n",
            "Validation Loss: 2.9579435579336373, Validation Accuracy: 28.85\n",
            "[26/150]: Training Loss: 2.3772740001678465, Training Accuracy: 38.8375\n",
            "Validation Loss: 2.892203370476984, Validation Accuracy: 29.97\n",
            "[27/150]: Training Loss: 2.331508861351013, Training Accuracy: 39.695\n",
            "Validation Loss: 2.902201515853785, Validation Accuracy: 29.95\n",
            "[28/150]: Training Loss: 2.292740362548828, Training Accuracy: 40.25\n",
            "Validation Loss: 2.884886794788822, Validation Accuracy: 30.54\n",
            "[29/150]: Training Loss: 2.246493480873108, Training Accuracy: 41.2375\n",
            "Validation Loss: 2.9104482884619647, Validation Accuracy: 30.14\n",
            "[30/150]: Training Loss: 2.203635430717468, Training Accuracy: 42.4475\n",
            "Validation Loss: 2.9059300164508213, Validation Accuracy: 31.3\n",
            "[31/150]: Training Loss: 2.1624910346984865, Training Accuracy: 43.2625\n",
            "Validation Loss: 2.884638991325524, Validation Accuracy: 31.26\n",
            "[32/150]: Training Loss: 2.122718844985962, Training Accuracy: 44.17\n",
            "Validation Loss: 2.9034518907024602, Validation Accuracy: 30.71\n",
            "[33/150]: Training Loss: 2.0803083070755006, Training Accuracy: 45.055\n",
            "Validation Loss: 2.8911248453103813, Validation Accuracy: 31.08\n",
            "[34/150]: Training Loss: 2.0393711433410644, Training Accuracy: 45.9575\n",
            "Validation Loss: 2.9181400818429934, Validation Accuracy: 31.06\n",
            "[35/150]: Training Loss: 2.001698533630371, Training Accuracy: 46.8225\n",
            "Validation Loss: 2.9216579084943053, Validation Accuracy: 30.6\n",
            "[36/150]: Training Loss: 1.9612565605163574, Training Accuracy: 47.845\n",
            "Validation Loss: 2.95554546945414, Validation Accuracy: 31.47\n",
            "[37/150]: Training Loss: 1.9143695009231567, Training Accuracy: 48.7825\n",
            "Validation Loss: 2.9769522748934993, Validation Accuracy: 30.95\n",
            "[38/150]: Training Loss: 1.8757219652175903, Training Accuracy: 49.6925\n",
            "Validation Loss: 2.954901927595685, Validation Accuracy: 31.79\n",
            "[39/150]: Training Loss: 1.8348310264587402, Training Accuracy: 50.46\n",
            "Validation Loss: 2.97764066374226, Validation Accuracy: 31.41\n",
            "[40/150]: Training Loss: 1.7973475383758546, Training Accuracy: 51.6725\n",
            "Validation Loss: 3.0162993069666966, Validation Accuracy: 31.12\n",
            "[41/150]: Training Loss: 1.7525395877838135, Training Accuracy: 52.525\n",
            "Validation Loss: 3.0236745138836514, Validation Accuracy: 30.91\n",
            "[42/150]: Training Loss: 1.7114470052719115, Training Accuracy: 53.885\n",
            "Validation Loss: 3.051269774224348, Validation Accuracy: 31.17\n",
            "[43/150]: Training Loss: 1.6800853149414063, Training Accuracy: 54.0875\n",
            "Validation Loss: 3.0829398237216243, Validation Accuracy: 31.28\n",
            "[44/150]: Training Loss: 1.636157625389099, Training Accuracy: 55.3375\n",
            "Validation Loss: 3.110968621673098, Validation Accuracy: 31.14\n",
            "[45/150]: Training Loss: 1.589929871749878, Training Accuracy: 56.7225\n",
            "Validation Loss: 3.142918248085459, Validation Accuracy: 31.26\n",
            "[46/150]: Training Loss: 1.5445106566429139, Training Accuracy: 57.9225\n",
            "Validation Loss: 3.1339099574240907, Validation Accuracy: 31.8\n",
            "[47/150]: Training Loss: 1.5067133940696715, Training Accuracy: 58.8375\n",
            "Validation Loss: 3.1682807533604325, Validation Accuracy: 31.84\n",
            "[48/150]: Training Loss: 1.4696476486206054, Training Accuracy: 59.655\n",
            "Validation Loss: 3.2345377184023523, Validation Accuracy: 30.89\n",
            "[49/150]: Training Loss: 1.4380368849754332, Training Accuracy: 60.32\n",
            "Validation Loss: 3.2836993484740047, Validation Accuracy: 31.58\n",
            "[50/150]: Training Loss: 1.3966082113265992, Training Accuracy: 61.33\n",
            "Validation Loss: 3.369933787424853, Validation Accuracy: 30.61\n",
            "[51/150]: Training Loss: 1.3530357138633728, Training Accuracy: 62.43\n",
            "Validation Loss: 3.357933571384211, Validation Accuracy: 31.19\n",
            "[52/150]: Training Loss: 1.31355241689682, Training Accuracy: 63.4325\n",
            "Validation Loss: 3.41107276138986, Validation Accuracy: 30.17\n",
            "[53/150]: Training Loss: 1.2827554839134216, Training Accuracy: 64.0425\n",
            "Validation Loss: 3.376580183673057, Validation Accuracy: 30.85\n",
            "[54/150]: Training Loss: 1.2412437489509582, Training Accuracy: 65.2825\n",
            "Validation Loss: 3.48424918332677, Validation Accuracy: 30.12\n",
            "[55/150]: Training Loss: 1.1999455925941467, Training Accuracy: 66.39\n",
            "Validation Loss: 3.4844332743602195, Validation Accuracy: 30.82\n",
            "[56/150]: Training Loss: 1.1624719073295593, Training Accuracy: 67.315\n",
            "Validation Loss: 3.535801676428242, Validation Accuracy: 30.86\n",
            "[57/150]: Training Loss: 1.1305819693565369, Training Accuracy: 67.9275\n",
            "Validation Loss: 3.6139490315868597, Validation Accuracy: 30.44\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 16.0335865749675, Test Accuracy: 13.22\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.22</td></tr><tr><td>Test Loss</td><td>16.03359</td></tr><tr><td>Train Accuracy</td><td>67.9275</td></tr><tr><td>Train Loss</td><td>1.13058</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/a8qnvlbp</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_030015-a8qnvlbp/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:1 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_030647-hgowk59s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">learning_rate=1 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.390103232955933, Training Accuracy: 2.935\n",
            "Validation Loss: 4.160131826522244, Validation Accuracy: 5.54\n",
            "[2/150]: Training Loss: 4.031327721786499, Training Accuracy: 7.5025\n",
            "Validation Loss: 3.9958771960750505, Validation Accuracy: 8.6\n",
            "[3/150]: Training Loss: 3.800543330383301, Training Accuracy: 11.665\n",
            "Validation Loss: 3.7379826664165328, Validation Accuracy: 12.06\n",
            "[4/150]: Training Loss: 3.6242603660583494, Training Accuracy: 14.345\n",
            "Validation Loss: 3.559469526740396, Validation Accuracy: 15.28\n",
            "[5/150]: Training Loss: 3.48455090675354, Training Accuracy: 16.9325\n",
            "Validation Loss: 3.491581111956554, Validation Accuracy: 16.56\n",
            "[6/150]: Training Loss: 3.3448009601593016, Training Accuracy: 19.435\n",
            "Validation Loss: 3.3586603653658726, Validation Accuracy: 19.41\n",
            "[7/150]: Training Loss: 3.229361641693115, Training Accuracy: 21.4375\n",
            "Validation Loss: 3.2139996130754995, Validation Accuracy: 21.78\n",
            "[8/150]: Training Loss: 3.1254781677246095, Training Accuracy: 23.4825\n",
            "Validation Loss: 3.168266389020689, Validation Accuracy: 22.86\n",
            "[9/150]: Training Loss: 3.0173661666870117, Training Accuracy: 25.6925\n",
            "Validation Loss: 3.1283769850518293, Validation Accuracy: 24.17\n",
            "[10/150]: Training Loss: 2.931245880126953, Training Accuracy: 26.99\n",
            "Validation Loss: 3.016676799506898, Validation Accuracy: 25.79\n",
            "[11/150]: Training Loss: 2.8445968715667727, Training Accuracy: 28.6675\n",
            "Validation Loss: 2.968725839238258, Validation Accuracy: 26.94\n",
            "[12/150]: Training Loss: 2.769311902618408, Training Accuracy: 30.345\n",
            "Validation Loss: 2.935349525160091, Validation Accuracy: 27.73\n",
            "[13/150]: Training Loss: 2.698523984146118, Training Accuracy: 31.47\n",
            "Validation Loss: 2.9356894462731233, Validation Accuracy: 28.11\n",
            "[14/150]: Training Loss: 2.6179113666534426, Training Accuracy: 33.2625\n",
            "Validation Loss: 2.8293940914664297, Validation Accuracy: 30.0\n",
            "[15/150]: Training Loss: 2.5539515073776244, Training Accuracy: 34.565\n",
            "Validation Loss: 2.8150154101620815, Validation Accuracy: 30.54\n",
            "[16/150]: Training Loss: 2.482784992599487, Training Accuracy: 36.2825\n",
            "Validation Loss: 2.801185814438352, Validation Accuracy: 30.73\n",
            "[17/150]: Training Loss: 2.416481968307495, Training Accuracy: 37.2175\n",
            "Validation Loss: 2.778297721200688, Validation Accuracy: 31.36\n",
            "[18/150]: Training Loss: 2.3516669242858885, Training Accuracy: 38.785\n",
            "Validation Loss: 2.803610542017943, Validation Accuracy: 31.44\n",
            "[19/150]: Training Loss: 2.2785828254699707, Training Accuracy: 40.36\n",
            "Validation Loss: 2.770737362515395, Validation Accuracy: 31.54\n",
            "[20/150]: Training Loss: 2.2117202407836913, Training Accuracy: 42.02\n",
            "Validation Loss: 2.751694551698721, Validation Accuracy: 32.2\n",
            "[21/150]: Training Loss: 2.1421232624053954, Training Accuracy: 43.1125\n",
            "Validation Loss: 2.7352929327897963, Validation Accuracy: 32.64\n",
            "[22/150]: Training Loss: 2.0760102186203, Training Accuracy: 44.805\n",
            "Validation Loss: 2.7648525397489023, Validation Accuracy: 32.85\n",
            "[23/150]: Training Loss: 2.0119320999145507, Training Accuracy: 46.1375\n",
            "Validation Loss: 2.7834541448362313, Validation Accuracy: 33.19\n",
            "[24/150]: Training Loss: 1.946039645767212, Training Accuracy: 47.555\n",
            "Validation Loss: 2.805889447023914, Validation Accuracy: 33.52\n",
            "[25/150]: Training Loss: 1.8788161462783814, Training Accuracy: 49.055\n",
            "Validation Loss: 2.7862223508251702, Validation Accuracy: 34.25\n",
            "[26/150]: Training Loss: 1.799899059486389, Training Accuracy: 50.915\n",
            "Validation Loss: 2.804932374863108, Validation Accuracy: 33.77\n",
            "[27/150]: Training Loss: 1.7454933450698853, Training Accuracy: 52.16\n",
            "Validation Loss: 2.861256376193587, Validation Accuracy: 33.83\n",
            "[28/150]: Training Loss: 1.6650921211242675, Training Accuracy: 53.9225\n",
            "Validation Loss: 2.877333830116661, Validation Accuracy: 34.25\n",
            "[29/150]: Training Loss: 1.6064131809234619, Training Accuracy: 55.555\n",
            "Validation Loss: 2.973996728089205, Validation Accuracy: 33.39\n",
            "[30/150]: Training Loss: 1.543812055683136, Training Accuracy: 56.7775\n",
            "Validation Loss: 2.943861024394916, Validation Accuracy: 34.15\n",
            "[31/150]: Training Loss: 1.4620859157562256, Training Accuracy: 58.88\n",
            "Validation Loss: 2.9692332015675342, Validation Accuracy: 33.88\n",
            "[32/150]: Training Loss: 1.4009520672798157, Training Accuracy: 60.3925\n",
            "Validation Loss: 3.024310210707841, Validation Accuracy: 33.42\n",
            "[33/150]: Training Loss: 1.3313846939086913, Training Accuracy: 62.155\n",
            "Validation Loss: 3.1067024993289047, Validation Accuracy: 33.18\n",
            "[34/150]: Training Loss: 1.2518226915359496, Training Accuracy: 64.225\n",
            "Validation Loss: 3.307321997964458, Validation Accuracy: 33.31\n",
            "[35/150]: Training Loss: 1.1938729809761048, Training Accuracy: 65.5075\n",
            "Validation Loss: 3.3076086089869214, Validation Accuracy: 32.76\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 18.36642926210051, Test Accuracy: 13.77\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.77</td></tr><tr><td>Test Loss</td><td>18.36643</td></tr><tr><td>Train Accuracy</td><td>65.5075</td></tr><tr><td>Train Loss</td><td>1.19387</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hgowk59s</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_030647-hgowk59s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:1.5 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_031055-hfm8dgbz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.426865048217773, Training Accuracy: 2.45\n",
            "Validation Loss: 4.219578746018136, Validation Accuracy: 4.19\n",
            "[2/150]: Training Loss: 4.060279036712647, Training Accuracy: 6.7225\n",
            "Validation Loss: 3.8940811293899635, Validation Accuracy: 9.43\n",
            "[3/150]: Training Loss: 3.7707011901855467, Training Accuracy: 11.6925\n",
            "Validation Loss: 3.8030508642743346, Validation Accuracy: 11.0\n",
            "[4/150]: Training Loss: 3.58028080368042, Training Accuracy: 15.05\n",
            "Validation Loss: 3.516739834645751, Validation Accuracy: 16.1\n",
            "[5/150]: Training Loss: 3.4152388591766356, Training Accuracy: 17.82\n",
            "Validation Loss: 3.411277610025588, Validation Accuracy: 17.62\n",
            "[6/150]: Training Loss: 3.2448327434539794, Training Accuracy: 20.7725\n",
            "Validation Loss: 3.2892891753251385, Validation Accuracy: 19.86\n",
            "[7/150]: Training Loss: 3.1129616333007815, Training Accuracy: 23.41\n",
            "Validation Loss: 3.155244686041668, Validation Accuracy: 22.75\n",
            "[8/150]: Training Loss: 2.9936462223052978, Training Accuracy: 25.73\n",
            "Validation Loss: 3.020396041262681, Validation Accuracy: 25.53\n",
            "[9/150]: Training Loss: 2.8851455352783204, Training Accuracy: 28.0475\n",
            "Validation Loss: 2.9794276216227535, Validation Accuracy: 26.31\n",
            "[10/150]: Training Loss: 2.7872766895294188, Training Accuracy: 29.955\n",
            "Validation Loss: 2.873067584007409, Validation Accuracy: 28.57\n",
            "[11/150]: Training Loss: 2.6929493949890135, Training Accuracy: 31.84\n",
            "Validation Loss: 2.8678578267431565, Validation Accuracy: 28.72\n",
            "[12/150]: Training Loss: 2.60749265499115, Training Accuracy: 33.46\n",
            "Validation Loss: 2.831394789325204, Validation Accuracy: 29.21\n",
            "[13/150]: Training Loss: 2.5269983169555665, Training Accuracy: 35.2325\n",
            "Validation Loss: 2.8061546094857963, Validation Accuracy: 29.73\n",
            "[14/150]: Training Loss: 2.430880810165405, Training Accuracy: 37.0475\n",
            "Validation Loss: 2.777110814288923, Validation Accuracy: 31.06\n",
            "[15/150]: Training Loss: 2.357077407836914, Training Accuracy: 38.8175\n",
            "Validation Loss: 2.7613005273661035, Validation Accuracy: 32.32\n",
            "[16/150]: Training Loss: 2.2730004482269286, Training Accuracy: 40.5\n",
            "Validation Loss: 2.7338021667140304, Validation Accuracy: 32.77\n",
            "[17/150]: Training Loss: 2.183533114242554, Training Accuracy: 42.27\n",
            "Validation Loss: 2.764839885341134, Validation Accuracy: 32.81\n",
            "[18/150]: Training Loss: 2.1031003602981566, Training Accuracy: 43.9825\n",
            "Validation Loss: 2.7428993381512394, Validation Accuracy: 32.82\n",
            "[19/150]: Training Loss: 2.0166405237197877, Training Accuracy: 46.195\n",
            "Validation Loss: 2.792896580544247, Validation Accuracy: 32.59\n",
            "[20/150]: Training Loss: 1.9404266941070556, Training Accuracy: 47.745\n",
            "Validation Loss: 2.742409686374057, Validation Accuracy: 34.58\n",
            "[21/150]: Training Loss: 1.8538161834716798, Training Accuracy: 49.4875\n",
            "Validation Loss: 2.809636064395783, Validation Accuracy: 33.93\n",
            "[22/150]: Training Loss: 1.768288578414917, Training Accuracy: 51.4775\n",
            "Validation Loss: 2.7697540058451855, Validation Accuracy: 34.68\n",
            "[23/150]: Training Loss: 1.684787001991272, Training Accuracy: 53.0825\n",
            "Validation Loss: 2.8915080067458425, Validation Accuracy: 33.94\n",
            "[24/150]: Training Loss: 1.6049392827987672, Training Accuracy: 55.145\n",
            "Validation Loss: 2.8930992533446878, Validation Accuracy: 33.94\n",
            "[25/150]: Training Loss: 1.511135014438629, Training Accuracy: 57.31\n",
            "Validation Loss: 2.9712191205115834, Validation Accuracy: 33.37\n",
            "[26/150]: Training Loss: 1.431588893699646, Training Accuracy: 59.12\n",
            "Validation Loss: 3.04860136311525, Validation Accuracy: 34.26\n",
            "[27/150]: Training Loss: 1.359563471508026, Training Accuracy: 60.8075\n",
            "Validation Loss: 3.205587582983029, Validation Accuracy: 33.21\n",
            "[28/150]: Training Loss: 1.2744348917961121, Training Accuracy: 63.0075\n",
            "Validation Loss: 3.1817259317750386, Validation Accuracy: 32.84\n",
            "[29/150]: Training Loss: 1.2077363389968871, Training Accuracy: 64.38\n",
            "Validation Loss: 3.2625666909916387, Validation Accuracy: 33.74\n",
            "[30/150]: Training Loss: 1.146615783405304, Training Accuracy: 66.3775\n",
            "Validation Loss: 3.439337396317986, Validation Accuracy: 32.76\n",
            "[31/150]: Training Loss: 1.0637209503173828, Training Accuracy: 68.4275\n",
            "Validation Loss: 3.464182601612844, Validation Accuracy: 32.3\n",
            "[32/150]: Training Loss: 1.0153738078117371, Training Accuracy: 69.42\n",
            "Validation Loss: 3.585658008125937, Validation Accuracy: 32.99\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 20.296875631733304, Test Accuracy: 15.72\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>15.72</td></tr><tr><td>Test Loss</td><td>20.29688</td></tr><tr><td>Train Accuracy</td><td>69.42</td></tr><tr><td>Train Loss</td><td>1.01537</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/hfm8dgbz</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_031055-hfm8dgbz/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:2 and wd:0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240612_031444-ws7fqwm1</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">learning_rate=2 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.6014143745422365, Training Accuracy: 0.98\n",
            "Validation Loss: 4.606205284215842, Validation Accuracy: 0.91\n",
            "[2/150]: Training Loss: 4.605726162719726, Training Accuracy: 0.93\n",
            "Validation Loss: 4.606422876856129, Validation Accuracy: 0.91\n",
            "[3/150]: Training Loss: 4.605443458557129, Training Accuracy: 0.9375\n",
            "Validation Loss: 4.606579792727331, Validation Accuracy: 0.82\n",
            "[4/150]: Training Loss: 4.6053140991210935, Training Accuracy: 1.015\n",
            "Validation Loss: 4.606754381945179, Validation Accuracy: 0.82\n",
            "[5/150]: Training Loss: 4.6052259376525875, Training Accuracy: 1.0275\n",
            "Validation Loss: 4.60688726765335, Validation Accuracy: 0.82\n",
            "[6/150]: Training Loss: 4.605191477966309, Training Accuracy: 1.0175\n",
            "Validation Loss: 4.607019655264107, Validation Accuracy: 0.82\n",
            "[7/150]: Training Loss: 4.6051658882141115, Training Accuracy: 1.015\n",
            "Validation Loss: 4.607097844409335, Validation Accuracy: 0.82\n",
            "[8/150]: Training Loss: 4.605149390411377, Training Accuracy: 0.9775\n",
            "Validation Loss: 4.607179025176224, Validation Accuracy: 0.82\n",
            "[9/150]: Training Loss: 4.605146067810058, Training Accuracy: 0.9425\n",
            "Validation Loss: 4.6072455181437695, Validation Accuracy: 0.82\n",
            "[10/150]: Training Loss: 4.605130741882324, Training Accuracy: 1.02\n",
            "Validation Loss: 4.607305599625703, Validation Accuracy: 0.82\n",
            "[11/150]: Training Loss: 4.605136211395264, Training Accuracy: 0.9625\n",
            "Validation Loss: 4.607342504392005, Validation Accuracy: 0.82\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 4.605385412835771, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>4.60539</td></tr><tr><td>Train Accuracy</td><td>0.9625</td></tr><tr><td>Train Loss</td><td>4.60514</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=2 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning/runs/ws7fqwm1</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240612_031444-ws7fqwm1/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "\n",
        "for lr in learning_rates:\n",
        "\n",
        "  print('='*50)\n",
        "  print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {'learning_rate': lr,\n",
        "                      'weight_decay' : wd\n",
        "                      }\n",
        "  # Load the model\n",
        "  model = LeNet5().to(device)\n",
        "\n",
        "  # Optimizer and scheduler setup\n",
        "  optimizer = LARS(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "  # Training\n",
        "  run_training(num_epochs,\n",
        "                model,\n",
        "                train_loader,\n",
        "                validation_loader,\n",
        "                test_loader,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                criterion,\n",
        "                device,\n",
        "                'LARS-HyperParameterTuning',\n",
        "                hyperparameters=hyperparameters,\n",
        "                is_wandb = True,\n",
        "                n_epochs_stop = 10\n",
        "  )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LARS BaseLine B-Size 64 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2bd5fda76227433aa9332e6e48cd415b",
            "fd6480fe59104c7aa15d39bf6ea4a63b",
            "3cb7b5c42e844747ae133750b7d42882",
            "b81cc89707e44dedb51081d13a3ba424",
            "1d74e9350c2c4c61b2e95924ec133012",
            "a5758bfac16a4388a036005a15812d1d",
            "0fdaf43c468043139e5d72397b118371",
            "f63fffe56ff64f1eb2b6e8f14974f011"
          ]
        },
        "id": "czSHzFs7SQug",
        "outputId": "fc513f95-8814-4002-e0d6-2a2eedad7dd7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_005802-t2cjgem5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_1584951/4263216451.py:113: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1578.)\n",
            "  d_p.add_(weight_decay, p.data)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.004822687724667, Training Accuracy: 8.156\n",
            "Validation Loss: 3.6169370329304105, Validation Accuracy: 15.1\n",
            "[2/150]: Training Loss: 3.489779775099986, Training Accuracy: 16.288\n",
            "Validation Loss: 3.195649910884298, Validation Accuracy: 21.71\n",
            "[3/150]: Training Loss: 3.188335987003258, Training Accuracy: 21.346\n",
            "Validation Loss: 2.9737777011409685, Validation Accuracy: 26.15\n",
            "[4/150]: Training Loss: 3.0118914528576006, Training Accuracy: 24.982\n",
            "Validation Loss: 2.7995891707717995, Validation Accuracy: 29.11\n",
            "[5/150]: Training Loss: 2.8688232484071152, Training Accuracy: 28.08\n",
            "Validation Loss: 2.7174989600090464, Validation Accuracy: 30.23\n",
            "[6/150]: Training Loss: 2.7214920926276984, Training Accuracy: 30.662\n",
            "Validation Loss: 2.5305145515757763, Validation Accuracy: 34.82\n",
            "[7/150]: Training Loss: 2.6200312084858983, Training Accuracy: 32.576\n",
            "Validation Loss: 2.474041129373441, Validation Accuracy: 35.97\n",
            "[8/150]: Training Loss: 2.53857664821093, Training Accuracy: 34.358\n",
            "Validation Loss: 2.3864964094890913, Validation Accuracy: 37.73\n",
            "[9/150]: Training Loss: 2.460603771764604, Training Accuracy: 36.126\n",
            "Validation Loss: 2.3855689604570913, Validation Accuracy: 38.2\n",
            "[10/150]: Training Loss: 2.3902963816052507, Training Accuracy: 37.29\n",
            "Validation Loss: 2.301407885399594, Validation Accuracy: 40.45\n",
            "[11/150]: Training Loss: 2.3503475908733087, Training Accuracy: 38.624\n",
            "Validation Loss: 2.3037940666174435, Validation Accuracy: 39.96\n",
            "[12/150]: Training Loss: 2.303130599696313, Training Accuracy: 39.49\n",
            "Validation Loss: 2.2026211046109534, Validation Accuracy: 42.0\n",
            "[13/150]: Training Loss: 2.2486851939459895, Training Accuracy: 40.568\n",
            "Validation Loss: 2.212206517055536, Validation Accuracy: 42.21\n",
            "[14/150]: Training Loss: 2.203081512085312, Training Accuracy: 41.506\n",
            "Validation Loss: 2.1992271386893694, Validation Accuracy: 43.09\n",
            "[15/150]: Training Loss: 2.159660982963679, Training Accuracy: 42.428\n",
            "Validation Loss: 2.1746684677281958, Validation Accuracy: 43.09\n",
            "[16/150]: Training Loss: 2.1303664485511877, Training Accuracy: 43.166\n",
            "Validation Loss: 2.146143364298875, Validation Accuracy: 44.21\n",
            "[17/150]: Training Loss: 2.1123076631589925, Training Accuracy: 43.67\n",
            "Validation Loss: 2.1201481705258605, Validation Accuracy: 44.27\n",
            "[18/150]: Training Loss: 2.0810553551939748, Training Accuracy: 44.61\n",
            "Validation Loss: 2.0423277001472036, Validation Accuracy: 46.15\n",
            "[19/150]: Training Loss: 2.0513661890993338, Training Accuracy: 44.866\n",
            "Validation Loss: 2.091191877225402, Validation Accuracy: 44.81\n",
            "[20/150]: Training Loss: 2.018301057541157, Training Accuracy: 45.826\n",
            "Validation Loss: 2.1546491832490178, Validation Accuracy: 43.92\n",
            "[21/150]: Training Loss: 1.99891439834824, Training Accuracy: 46.082\n",
            "Validation Loss: 2.149173748720983, Validation Accuracy: 44.11\n",
            "[22/150]: Training Loss: 1.9834696277023276, Training Accuracy: 46.51\n",
            "Validation Loss: 2.0435469044241934, Validation Accuracy: 46.15\n",
            "[23/150]: Training Loss: 1.954583641970554, Training Accuracy: 46.984\n",
            "Validation Loss: 2.0593765806999937, Validation Accuracy: 46.4\n",
            "[24/150]: Training Loss: 1.9357828209772134, Training Accuracy: 47.47\n",
            "Validation Loss: 1.9959042148225625, Validation Accuracy: 47.77\n",
            "[25/150]: Training Loss: 1.9152823200311198, Training Accuracy: 48.11\n",
            "Validation Loss: 2.007097185037698, Validation Accuracy: 46.74\n",
            "[26/150]: Training Loss: 1.889640983870572, Training Accuracy: 48.486\n",
            "Validation Loss: 2.0237637371014636, Validation Accuracy: 46.53\n",
            "[27/150]: Training Loss: 1.8898505502954468, Training Accuracy: 48.75\n",
            "Validation Loss: 1.9383376062295998, Validation Accuracy: 48.79\n",
            "[28/150]: Training Loss: 1.8655293333865797, Training Accuracy: 49.182\n",
            "Validation Loss: 2.000895071181522, Validation Accuracy: 47.12\n",
            "[29/150]: Training Loss: 1.843536861564802, Training Accuracy: 49.576\n",
            "Validation Loss: 2.0557514102595627, Validation Accuracy: 46.42\n",
            "[30/150]: Training Loss: 1.8280195388037834, Training Accuracy: 49.938\n",
            "Validation Loss: 1.9708276941518115, Validation Accuracy: 48.17\n",
            "[31/150]: Training Loss: 1.8121484304632982, Training Accuracy: 50.256\n",
            "Validation Loss: 2.0148930929269, Validation Accuracy: 48.07\n",
            "[32/150]: Training Loss: 1.7905213011195287, Training Accuracy: 51.016\n",
            "Validation Loss: 1.9494955805456562, Validation Accuracy: 48.66\n",
            "[33/150]: Training Loss: 1.7819690168513667, Training Accuracy: 51.152\n",
            "Validation Loss: 1.9355155472542829, Validation Accuracy: 49.85\n",
            "[34/150]: Training Loss: 1.7735850943628784, Training Accuracy: 51.054\n",
            "Validation Loss: 1.9679190664534356, Validation Accuracy: 48.93\n",
            "[35/150]: Training Loss: 1.7615117981000934, Training Accuracy: 51.618\n",
            "Validation Loss: 2.019153520559809, Validation Accuracy: 47.96\n",
            "[36/150]: Training Loss: 1.7415476721875809, Training Accuracy: 51.984\n",
            "Validation Loss: 1.9617887530357214, Validation Accuracy: 48.72\n",
            "[37/150]: Training Loss: 1.7273670095007132, Training Accuracy: 52.228\n",
            "Validation Loss: 1.9595575993228111, Validation Accuracy: 49.25\n",
            "[38/150]: Training Loss: 1.7174837630423134, Training Accuracy: 52.45\n",
            "Validation Loss: 1.9162586555359469, Validation Accuracy: 50.15\n",
            "[39/150]: Training Loss: 1.6948718257877222, Training Accuracy: 53.104\n",
            "Validation Loss: 1.9148104600845628, Validation Accuracy: 50.11\n",
            "[40/150]: Training Loss: 1.6948116973537923, Training Accuracy: 53.164\n",
            "Validation Loss: 1.9015048544877653, Validation Accuracy: 50.46\n",
            "[41/150]: Training Loss: 1.669160524292675, Training Accuracy: 53.832\n",
            "Validation Loss: 1.9202428220943282, Validation Accuracy: 49.95\n",
            "[42/150]: Training Loss: 1.6587599679027372, Training Accuracy: 53.99\n",
            "Validation Loss: 1.9989394374713776, Validation Accuracy: 48.53\n",
            "[43/150]: Training Loss: 1.6486307676033596, Training Accuracy: 54.324\n",
            "Validation Loss: 1.9677664428759531, Validation Accuracy: 49.26\n",
            "[44/150]: Training Loss: 1.6284820756034168, Training Accuracy: 54.798\n",
            "Validation Loss: 1.917847274215358, Validation Accuracy: 50.53\n",
            "[45/150]: Training Loss: 1.6195188324774623, Training Accuracy: 54.902\n",
            "Validation Loss: 1.9071525859225327, Validation Accuracy: 50.67\n",
            "[46/150]: Training Loss: 1.6109208017206558, Training Accuracy: 54.96\n",
            "Validation Loss: 1.8967621220145257, Validation Accuracy: 51.23\n",
            "[47/150]: Training Loss: 1.602793920375502, Training Accuracy: 55.188\n",
            "Validation Loss: 1.8559222494720653, Validation Accuracy: 51.43\n",
            "[48/150]: Training Loss: 1.5858894056066528, Training Accuracy: 55.652\n",
            "Validation Loss: 1.9233948349193404, Validation Accuracy: 50.32\n",
            "[49/150]: Training Loss: 1.5650417865694637, Training Accuracy: 56.188\n",
            "Validation Loss: 1.9384330412384811, Validation Accuracy: 49.91\n",
            "[50/150]: Training Loss: 1.5663130182744291, Training Accuracy: 56.228\n",
            "Validation Loss: 1.8889641389725313, Validation Accuracy: 51.35\n",
            "[51/150]: Training Loss: 1.542809939445437, Training Accuracy: 56.846\n",
            "Validation Loss: 1.8398898855136459, Validation Accuracy: 51.84\n",
            "[52/150]: Training Loss: 1.5279571914002108, Training Accuracy: 57.064\n",
            "Validation Loss: 1.9208611204366015, Validation Accuracy: 50.34\n",
            "[53/150]: Training Loss: 1.510901224735143, Training Accuracy: 57.122\n",
            "Validation Loss: 1.9133090471765797, Validation Accuracy: 50.8\n",
            "[54/150]: Training Loss: 1.511483409596831, Training Accuracy: 57.642\n",
            "Validation Loss: 1.8751734176259132, Validation Accuracy: 51.71\n",
            "[55/150]: Training Loss: 1.4843521323960152, Training Accuracy: 58.136\n",
            "Validation Loss: 1.8774340836105832, Validation Accuracy: 51.56\n",
            "[56/150]: Training Loss: 1.4896384542403014, Training Accuracy: 57.742\n",
            "Validation Loss: 1.8484339972210537, Validation Accuracy: 52.7\n",
            "[57/150]: Training Loss: 1.4539345915207778, Training Accuracy: 58.774\n",
            "Validation Loss: 1.8711960125880636, Validation Accuracy: 50.9\n",
            "[58/150]: Training Loss: 1.4413522976591153, Training Accuracy: 59.254\n",
            "Validation Loss: 1.8433482806394055, Validation Accuracy: 52.14\n",
            "[59/150]: Training Loss: 1.435598407407551, Training Accuracy: 59.348\n",
            "Validation Loss: 1.842708926291982, Validation Accuracy: 52.32\n",
            "[60/150]: Training Loss: 1.415708273572995, Training Accuracy: 59.856\n",
            "Validation Loss: 1.8708495941891032, Validation Accuracy: 51.34\n",
            "[61/150]: Training Loss: 1.4131718484489508, Training Accuracy: 59.934\n",
            "Validation Loss: 1.8397565495436359, Validation Accuracy: 52.21\n",
            "[62/150]: Training Loss: 1.3917764421466672, Training Accuracy: 60.466\n",
            "Validation Loss: 1.8553483759521678, Validation Accuracy: 52.56\n",
            "[63/150]: Training Loss: 1.3845181973541485, Training Accuracy: 60.468\n",
            "Validation Loss: 1.8767407699755043, Validation Accuracy: 51.4\n",
            "[64/150]: Training Loss: 1.3718093946156904, Training Accuracy: 60.9\n",
            "Validation Loss: 1.833029270931414, Validation Accuracy: 53.34\n",
            "[65/150]: Training Loss: 1.3485638827771482, Training Accuracy: 61.372\n",
            "Validation Loss: 1.8435825352456159, Validation Accuracy: 52.78\n",
            "[66/150]: Training Loss: 1.3356790865778618, Training Accuracy: 61.914\n",
            "Validation Loss: 1.8920623299422537, Validation Accuracy: 52.03\n",
            "[67/150]: Training Loss: 1.3243823959242047, Training Accuracy: 61.984\n",
            "Validation Loss: 1.8541991725848739, Validation Accuracy: 53.25\n",
            "[68/150]: Training Loss: 1.3088703974128684, Training Accuracy: 62.324\n",
            "Validation Loss: 1.8384279855497323, Validation Accuracy: 52.97\n",
            "[69/150]: Training Loss: 1.2935843141487493, Training Accuracy: 62.726\n",
            "Validation Loss: 1.8648313618010017, Validation Accuracy: 52.35\n",
            "[70/150]: Training Loss: 1.2788333388240747, Training Accuracy: 63.162\n",
            "Validation Loss: 1.8200989673092107, Validation Accuracy: 53.57\n",
            "[71/150]: Training Loss: 1.275286832810058, Training Accuracy: 63.326\n",
            "Validation Loss: 1.8271277934122996, Validation Accuracy: 52.6\n",
            "[72/150]: Training Loss: 1.2548354720063222, Training Accuracy: 63.724\n",
            "Validation Loss: 1.832458599357848, Validation Accuracy: 53.43\n",
            "[73/150]: Training Loss: 1.2409771790589823, Training Accuracy: 64.15\n",
            "Validation Loss: 1.8489187993821066, Validation Accuracy: 53.54\n",
            "[74/150]: Training Loss: 1.2177538118703897, Training Accuracy: 64.682\n",
            "Validation Loss: 1.8377945020699957, Validation Accuracy: 53.86\n",
            "[75/150]: Training Loss: 1.2167601452764039, Training Accuracy: 64.92\n",
            "Validation Loss: 1.856788229031168, Validation Accuracy: 53.15\n",
            "[76/150]: Training Loss: 1.1967681403964987, Training Accuracy: 65.394\n",
            "Validation Loss: 1.8202834759548212, Validation Accuracy: 54.44\n",
            "[77/150]: Training Loss: 1.1781836492021371, Training Accuracy: 65.698\n",
            "Validation Loss: 1.8182067392738002, Validation Accuracy: 54.42\n",
            "[78/150]: Training Loss: 1.1718934528967913, Training Accuracy: 65.94\n",
            "Validation Loss: 1.8361693392893312, Validation Accuracy: 53.34\n",
            "[79/150]: Training Loss: 1.1540917455387847, Training Accuracy: 66.372\n",
            "Validation Loss: 1.8517911365837048, Validation Accuracy: 53.86\n",
            "[80/150]: Training Loss: 1.1260635425215182, Training Accuracy: 67.01\n",
            "Validation Loss: 1.8486420083197819, Validation Accuracy: 53.93\n",
            "[81/150]: Training Loss: 1.1187372058248886, Training Accuracy: 67.426\n",
            "Validation Loss: 1.822678742894701, Validation Accuracy: 54.82\n",
            "[82/150]: Training Loss: 1.1072917601184162, Training Accuracy: 67.646\n",
            "Validation Loss: 1.8640035948935587, Validation Accuracy: 53.57\n",
            "[83/150]: Training Loss: 1.082973983510376, Training Accuracy: 68.116\n",
            "Validation Loss: 1.867675439567323, Validation Accuracy: 53.9\n",
            "[84/150]: Training Loss: 1.0828096682915602, Training Accuracy: 68.366\n",
            "Validation Loss: 1.826197045244229, Validation Accuracy: 54.16\n",
            "[85/150]: Training Loss: 1.0598852286100997, Training Accuracy: 68.856\n",
            "Validation Loss: 1.8198747148938998, Validation Accuracy: 54.4\n",
            "[86/150]: Training Loss: 1.0407975543185572, Training Accuracy: 69.42\n",
            "Validation Loss: 1.8279076829837386, Validation Accuracy: 54.55\n",
            "[87/150]: Training Loss: 1.030418163827618, Training Accuracy: 69.804\n",
            "Validation Loss: 1.854318435784358, Validation Accuracy: 54.88\n",
            "[88/150]: Training Loss: 1.0299987217120807, Training Accuracy: 69.594\n",
            "Validation Loss: 1.8434015595988862, Validation Accuracy: 54.47\n",
            "[89/150]: Training Loss: 1.0026646399741892, Training Accuracy: 70.49\n",
            "Validation Loss: 1.8365007965428055, Validation Accuracy: 54.24\n",
            "[90/150]: Training Loss: 0.9944430979164055, Training Accuracy: 70.764\n",
            "Validation Loss: 1.845389035097353, Validation Accuracy: 54.42\n",
            "[91/150]: Training Loss: 0.9791042178945468, Training Accuracy: 70.958\n",
            "Validation Loss: 1.8592563897940764, Validation Accuracy: 54.71\n",
            "[92/150]: Training Loss: 0.9622275731371491, Training Accuracy: 71.348\n",
            "Validation Loss: 1.8250258181505143, Validation Accuracy: 55.29\n",
            "[93/150]: Training Loss: 0.9501752741349018, Training Accuracy: 71.708\n",
            "Validation Loss: 1.849954966526882, Validation Accuracy: 55.02\n",
            "[94/150]: Training Loss: 0.9297837285358278, Training Accuracy: 72.38\n",
            "Validation Loss: 1.8463909307103248, Validation Accuracy: 55.77\n",
            "[95/150]: Training Loss: 0.9163948694991944, Training Accuracy: 72.898\n",
            "Validation Loss: 1.8669461308011583, Validation Accuracy: 55.06\n",
            "[96/150]: Training Loss: 0.9114100606468938, Training Accuracy: 72.956\n",
            "Validation Loss: 1.8656909784693627, Validation Accuracy: 54.75\n",
            "[97/150]: Training Loss: 0.8974789249165284, Training Accuracy: 73.276\n",
            "Validation Loss: 1.834348332350421, Validation Accuracy: 55.01\n",
            "[98/150]: Training Loss: 0.8797091352360328, Training Accuracy: 73.696\n",
            "Validation Loss: 1.8680614483584264, Validation Accuracy: 55.11\n",
            "[99/150]: Training Loss: 0.8685366097085007, Training Accuracy: 74.026\n",
            "Validation Loss: 1.8696094318559975, Validation Accuracy: 55.43\n",
            "[100/150]: Training Loss: 0.8596895751745804, Training Accuracy: 74.396\n",
            "Validation Loss: 1.8580050965782944, Validation Accuracy: 55.31\n",
            "[101/150]: Training Loss: 0.8450928368531835, Training Accuracy: 74.934\n",
            "Validation Loss: 1.8560257132645626, Validation Accuracy: 55.71\n",
            "[102/150]: Training Loss: 0.834670692567935, Training Accuracy: 75.278\n",
            "Validation Loss: 1.8615986776959366, Validation Accuracy: 55.84\n",
            "[103/150]: Training Loss: 0.8168128573757303, Training Accuracy: 75.56\n",
            "Validation Loss: 1.8920900590100866, Validation Accuracy: 55.38\n",
            "[104/150]: Training Loss: 0.8022570627577165, Training Accuracy: 76.022\n",
            "Validation Loss: 1.9013077168707635, Validation Accuracy: 55.71\n",
            "[105/150]: Training Loss: 0.7898137537414766, Training Accuracy: 76.588\n",
            "Validation Loss: 1.8971044345266501, Validation Accuracy: 55.23\n",
            "[106/150]: Training Loss: 0.7799203321528252, Training Accuracy: 76.854\n",
            "Validation Loss: 1.8587115873956377, Validation Accuracy: 55.33\n",
            "[107/150]: Training Loss: 0.7687876791600377, Training Accuracy: 76.832\n",
            "Validation Loss: 1.9066706402286602, Validation Accuracy: 55.7\n",
            "[108/150]: Training Loss: 0.7502601898234823, Training Accuracy: 77.674\n",
            "Validation Loss: 1.891866291784177, Validation Accuracy: 56.06\n",
            "[109/150]: Training Loss: 0.7453718431236799, Training Accuracy: 77.84\n",
            "Validation Loss: 1.9089836011267012, Validation Accuracy: 55.88\n",
            "[110/150]: Training Loss: 0.7324799866322667, Training Accuracy: 78.2\n",
            "Validation Loss: 1.8889893972949616, Validation Accuracy: 55.7\n",
            "[111/150]: Training Loss: 0.716928729620736, Training Accuracy: 78.53\n",
            "Validation Loss: 1.9158697025791096, Validation Accuracy: 56.07\n",
            "[112/150]: Training Loss: 0.7084723916809882, Training Accuracy: 78.768\n",
            "Validation Loss: 1.9187719480247254, Validation Accuracy: 55.71\n",
            "[113/150]: Training Loss: 0.6928996008146754, Training Accuracy: 79.508\n",
            "Validation Loss: 1.9122050970223299, Validation Accuracy: 56.4\n",
            "[114/150]: Training Loss: 0.686598046775669, Training Accuracy: 79.428\n",
            "Validation Loss: 1.895180571990408, Validation Accuracy: 56.18\n",
            "[115/150]: Training Loss: 0.6837174600881079, Training Accuracy: 79.66\n",
            "Validation Loss: 1.9321321894408792, Validation Accuracy: 55.4\n",
            "[116/150]: Training Loss: 0.6646802525233735, Training Accuracy: 80.106\n",
            "Validation Loss: 1.9081798047776435, Validation Accuracy: 56.21\n",
            "[117/150]: Training Loss: 0.6522155370172638, Training Accuracy: 80.528\n",
            "Validation Loss: 1.9046855428416258, Validation Accuracy: 56.69\n",
            "[118/150]: Training Loss: 0.6456939719064766, Training Accuracy: 80.752\n",
            "Validation Loss: 1.9132253895899294, Validation Accuracy: 56.47\n",
            "[119/150]: Training Loss: 0.6339363064378729, Training Accuracy: 81.286\n",
            "Validation Loss: 1.914469665782467, Validation Accuracy: 56.51\n",
            "[120/150]: Training Loss: 0.6339401570351227, Training Accuracy: 81.134\n",
            "Validation Loss: 1.913045568830648, Validation Accuracy: 55.93\n",
            "[121/150]: Training Loss: 0.6202226441610804, Training Accuracy: 81.422\n",
            "Validation Loss: 1.9112963069016766, Validation Accuracy: 56.58\n",
            "[122/150]: Training Loss: 0.6146376765216403, Training Accuracy: 81.858\n",
            "Validation Loss: 1.916867652516456, Validation Accuracy: 56.28\n",
            "[123/150]: Training Loss: 0.6090771163363591, Training Accuracy: 81.96\n",
            "Validation Loss: 1.9238637059357515, Validation Accuracy: 56.33\n",
            "[124/150]: Training Loss: 0.5977434807497523, Training Accuracy: 82.352\n",
            "Validation Loss: 1.9187599549627607, Validation Accuracy: 56.09\n",
            "[125/150]: Training Loss: 0.5865007763933343, Training Accuracy: 82.728\n",
            "Validation Loss: 1.9290249192031326, Validation Accuracy: 55.85\n",
            "[126/150]: Training Loss: 0.5832711922390686, Training Accuracy: 82.85\n",
            "Validation Loss: 1.925058329560954, Validation Accuracy: 56.54\n",
            "[127/150]: Training Loss: 0.5710540865845692, Training Accuracy: 83.058\n",
            "Validation Loss: 1.9433572846613112, Validation Accuracy: 56.46\n",
            "[128/150]: Training Loss: 0.566251437987208, Training Accuracy: 83.328\n",
            "Validation Loss: 1.9474792632327718, Validation Accuracy: 56.24\n",
            "[129/150]: Training Loss: 0.5592512233787791, Training Accuracy: 83.606\n",
            "Validation Loss: 1.9336790825910628, Validation Accuracy: 56.49\n",
            "[130/150]: Training Loss: 0.5560948127675849, Training Accuracy: 83.726\n",
            "Validation Loss: 1.9358682472994373, Validation Accuracy: 56.75\n",
            "[131/150]: Training Loss: 0.5547005703191623, Training Accuracy: 83.68\n",
            "Validation Loss: 1.941912688647106, Validation Accuracy: 56.32\n",
            "[132/150]: Training Loss: 0.5438491536299591, Training Accuracy: 84.188\n",
            "Validation Loss: 1.9333096700868788, Validation Accuracy: 56.52\n",
            "[133/150]: Training Loss: 0.5359534242421465, Training Accuracy: 84.398\n",
            "Validation Loss: 1.9515662831106004, Validation Accuracy: 56.36\n",
            "[134/150]: Training Loss: 0.5345852662763937, Training Accuracy: 84.37\n",
            "Validation Loss: 1.939547040280263, Validation Accuracy: 56.31\n",
            "[135/150]: Training Loss: 0.5338244077266024, Training Accuracy: 84.354\n",
            "Validation Loss: 1.9529236646214867, Validation Accuracy: 56.4\n",
            "[136/150]: Training Loss: 0.5233329969751256, Training Accuracy: 84.792\n",
            "Validation Loss: 1.9439837556735726, Validation Accuracy: 56.43\n",
            "[137/150]: Training Loss: 0.519332280549247, Training Accuracy: 84.868\n",
            "Validation Loss: 1.9427648835880742, Validation Accuracy: 56.25\n",
            "[138/150]: Training Loss: 0.513342816468395, Training Accuracy: 85.202\n",
            "Validation Loss: 1.9522086123751987, Validation Accuracy: 56.69\n",
            "[139/150]: Training Loss: 0.5097889236515135, Training Accuracy: 85.132\n",
            "Validation Loss: 1.950890618904381, Validation Accuracy: 56.41\n",
            "[140/150]: Training Loss: 0.5080071812319329, Training Accuracy: 85.386\n",
            "Validation Loss: 1.9511753282729227, Validation Accuracy: 56.69\n",
            "[141/150]: Training Loss: 0.5083310039299528, Training Accuracy: 85.398\n",
            "Validation Loss: 1.9493300193434309, Validation Accuracy: 56.5\n",
            "[142/150]: Training Loss: 0.5110094372726157, Training Accuracy: 85.232\n",
            "Validation Loss: 1.9510933920076698, Validation Accuracy: 56.46\n",
            "[143/150]: Training Loss: 0.5043484553161179, Training Accuracy: 85.402\n",
            "Validation Loss: 1.9473720959797027, Validation Accuracy: 56.53\n",
            "[144/150]: Training Loss: 0.5001817758926346, Training Accuracy: 85.59\n",
            "Validation Loss: 1.9499852835752403, Validation Accuracy: 56.64\n",
            "[145/150]: Training Loss: 0.5050505888088584, Training Accuracy: 85.566\n",
            "Validation Loss: 1.9509570135432444, Validation Accuracy: 56.58\n",
            "[146/150]: Training Loss: 0.4944563165230824, Training Accuracy: 85.7\n",
            "Validation Loss: 1.9510046653686814, Validation Accuracy: 56.56\n",
            "[147/150]: Training Loss: 0.4947198845655717, Training Accuracy: 85.914\n",
            "Validation Loss: 1.9500796012817674, Validation Accuracy: 56.62\n",
            "[148/150]: Training Loss: 0.4965038236487857, Training Accuracy: 85.548\n",
            "Validation Loss: 1.9505202922092122, Validation Accuracy: 56.65\n",
            "[149/150]: Training Loss: 0.4984786443964905, Training Accuracy: 85.54\n",
            "Validation Loss: 1.94986033325742, Validation Accuracy: 56.62\n",
            "[150/150]: Training Loss: 0.498654707256333, Training Accuracy: 85.464\n",
            "Validation Loss: 1.9498052581860001, Validation Accuracy: 56.63\n",
            "**********************************************************************\n",
            "Test Loss: 1.9498052581860001, Test Accuracy: 56.63\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>56.63</td></tr><tr><td>Test Loss</td><td>1.94981</td></tr><tr><td>Train Accuracy</td><td>85.464</td></tr><tr><td>Train Loss</td><td>0.49865</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS/runs/t2cjgem5</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_005802-t2cjgem5/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1.5\n",
        "wd = 1e-03\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer = LARS(model.parameters(), lr=lr, weight_decay=wd, momentum=0.9)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(\n",
        "    num_epochs,\n",
        "    model,\n",
        "    original_train_loader,\n",
        "    original_test_loader,\n",
        "    original_test_loader,\n",
        "    optimizer,\n",
        "    scheduler,\n",
        "    criterion,\n",
        "    device,\n",
        "    optimizer_name='LARS',\n",
        "    hyperparameters=hyperparameters,\n",
        "    is_wandb = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LARS Test Large Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "81408f178c46447f90d36d1d18cdad82",
            "06d3de2006b14793bd57a5ca89d44e4a",
            "804c12a3f13840c7bdb2e6df69e62c10",
            "4a4cfb14c56e477cbfef5a652c05fabc",
            "68d86018628f420e8d7e516ba5827e35",
            "8877fd11846246f989e31835e5d3e7ae",
            "68ff4108835c462b929d0b5c78497555",
            "a63e1d987556448280ca217f17b60b49"
          ]
        },
        "id": "RFWHh4OL50WX",
        "outputId": "099a0039-9168-4d4e-84ec-4d6300dd3498"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 512, Learning rate: 4.242640687119286, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:9hoyxk41) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/9hoyxk41' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/9hoyxk41</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_012745-9hoyxk41/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:9hoyxk41). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_012749-momu4e5u</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">batch_size=512 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.194531238808924, Training Accuracy: 5.802\n",
            "Validation Loss: 3.8219263911247254, Validation Accuracy: 11.06\n",
            "[2/150]: Training Loss: 3.737521487839368, Training Accuracy: 12.162\n",
            "Validation Loss: 3.5326468467712404, Validation Accuracy: 15.5\n",
            "[3/150]: Training Loss: 3.469568571265863, Training Accuracy: 16.654\n",
            "Validation Loss: 3.2325081706047056, Validation Accuracy: 21.14\n",
            "[4/150]: Training Loss: 3.2623822543085836, Training Accuracy: 20.338\n",
            "Validation Loss: 3.041664385795593, Validation Accuracy: 24.34\n",
            "[5/150]: Training Loss: 3.1202199824002324, Training Accuracy: 23.134\n",
            "Validation Loss: 2.9670259952545166, Validation Accuracy: 26.23\n",
            "[6/150]: Training Loss: 2.973516508024566, Training Accuracy: 25.864\n",
            "Validation Loss: 2.835892844200134, Validation Accuracy: 28.97\n",
            "[7/150]: Training Loss: 2.8618772808386357, Training Accuracy: 27.73\n",
            "Validation Loss: 2.731530475616455, Validation Accuracy: 31.08\n",
            "[8/150]: Training Loss: 2.7622045083921782, Training Accuracy: 29.856\n",
            "Validation Loss: 2.6019123077392576, Validation Accuracy: 33.01\n",
            "[9/150]: Training Loss: 2.719049726213728, Training Accuracy: 30.804\n",
            "Validation Loss: 2.6247976064682006, Validation Accuracy: 33.43\n",
            "[10/150]: Training Loss: 2.6084506000791277, Training Accuracy: 33.166\n",
            "Validation Loss: 2.4777934432029722, Validation Accuracy: 36.28\n",
            "[11/150]: Training Loss: 2.5361861233808556, Training Accuracy: 34.45\n",
            "Validation Loss: 2.3982665181159972, Validation Accuracy: 37.66\n",
            "[12/150]: Training Loss: 2.486152622164512, Training Accuracy: 35.61\n",
            "Validation Loss: 2.4073413372039796, Validation Accuracy: 37.69\n",
            "[13/150]: Training Loss: 2.419785971544227, Training Accuracy: 36.994\n",
            "Validation Loss: 2.3586077094078064, Validation Accuracy: 39.62\n",
            "[14/150]: Training Loss: 2.378681479668131, Training Accuracy: 37.686\n",
            "Validation Loss: 2.2874060750007628, Validation Accuracy: 40.44\n",
            "[15/150]: Training Loss: 2.3229291341742693, Training Accuracy: 39.04\n",
            "Validation Loss: 2.391434836387634, Validation Accuracy: 38.28\n",
            "[16/150]: Training Loss: 2.3006048445798912, Training Accuracy: 39.566\n",
            "Validation Loss: 2.233357620239258, Validation Accuracy: 40.92\n",
            "[17/150]: Training Loss: 2.270021514016755, Training Accuracy: 40.304\n",
            "Validation Loss: 2.2809773087501526, Validation Accuracy: 40.35\n",
            "[18/150]: Training Loss: 2.219994238444737, Training Accuracy: 41.128\n",
            "Validation Loss: 2.208327281475067, Validation Accuracy: 42.26\n",
            "[19/150]: Training Loss: 2.1639412665853697, Training Accuracy: 42.49\n",
            "Validation Loss: 2.1477415204048156, Validation Accuracy: 43.47\n",
            "[20/150]: Training Loss: 2.1379866052647025, Training Accuracy: 43.012\n",
            "Validation Loss: 2.202856254577637, Validation Accuracy: 42.27\n",
            "[21/150]: Training Loss: 2.139409989726787, Training Accuracy: 43.086\n",
            "Validation Loss: 2.1385614931583405, Validation Accuracy: 43.93\n",
            "[22/150]: Training Loss: 2.07097029564332, Training Accuracy: 44.974\n",
            "Validation Loss: 2.128925609588623, Validation Accuracy: 44.07\n",
            "[23/150]: Training Loss: 2.0605698106240253, Training Accuracy: 44.808\n",
            "Validation Loss: 2.15288764834404, Validation Accuracy: 44.03\n",
            "[24/150]: Training Loss: 2.0457090200210106, Training Accuracy: 45.174\n",
            "Validation Loss: 2.1201067209243774, Validation Accuracy: 44.63\n",
            "[25/150]: Training Loss: 2.0101604510326774, Training Accuracy: 45.978\n",
            "Validation Loss: 2.0930452048778534, Validation Accuracy: 45.37\n",
            "[26/150]: Training Loss: 1.9699756795046282, Training Accuracy: 46.9\n",
            "Validation Loss: 2.089737904071808, Validation Accuracy: 45.61\n",
            "[27/150]: Training Loss: 1.967079225851565, Training Accuracy: 47.01\n",
            "Validation Loss: 2.1089664578437803, Validation Accuracy: 44.55\n",
            "[28/150]: Training Loss: 1.9404766535272404, Training Accuracy: 47.568\n",
            "Validation Loss: 2.0624644994735717, Validation Accuracy: 45.57\n",
            "[29/150]: Training Loss: 1.928514483023663, Training Accuracy: 47.712\n",
            "Validation Loss: 2.0849966049194335, Validation Accuracy: 45.11\n",
            "[30/150]: Training Loss: 1.9005685375661265, Training Accuracy: 48.44\n",
            "Validation Loss: 2.015596163272858, Validation Accuracy: 46.79\n",
            "[31/150]: Training Loss: 1.868617719533492, Training Accuracy: 49.064\n",
            "Validation Loss: 2.044619733095169, Validation Accuracy: 45.67\n",
            "[32/150]: Training Loss: 1.8784857465296376, Training Accuracy: 48.794\n",
            "Validation Loss: 2.029283958673477, Validation Accuracy: 46.27\n",
            "[33/150]: Training Loss: 1.8382798968529215, Training Accuracy: 49.868\n",
            "Validation Loss: 1.9727658331394196, Validation Accuracy: 48.14\n",
            "[34/150]: Training Loss: 1.8194199094966965, Training Accuracy: 50.486\n",
            "Validation Loss: 1.9934200942516327, Validation Accuracy: 47.5\n",
            "[35/150]: Training Loss: 1.7988280094399745, Training Accuracy: 50.79\n",
            "Validation Loss: 2.0087626039981843, Validation Accuracy: 46.76\n",
            "[36/150]: Training Loss: 1.8009161900500863, Training Accuracy: 50.804\n",
            "Validation Loss: 1.9823269903659821, Validation Accuracy: 48.14\n",
            "[37/150]: Training Loss: 1.767955198579905, Training Accuracy: 51.498\n",
            "Validation Loss: 1.973670369386673, Validation Accuracy: 48.18\n",
            "[38/150]: Training Loss: 1.761318182458683, Training Accuracy: 51.526\n",
            "Validation Loss: 1.9882086098194123, Validation Accuracy: 47.85\n",
            "[39/150]: Training Loss: 1.7494291188765545, Training Accuracy: 52.066\n",
            "Validation Loss: 1.945462554693222, Validation Accuracy: 48.63\n",
            "[40/150]: Training Loss: 1.7158451688532927, Training Accuracy: 52.788\n",
            "Validation Loss: 1.9138611912727357, Validation Accuracy: 49.24\n",
            "[41/150]: Training Loss: 1.7024361783144426, Training Accuracy: 52.972\n",
            "Validation Loss: 1.9541066110134124, Validation Accuracy: 49.38\n",
            "[42/150]: Training Loss: 1.6934348527266054, Training Accuracy: 53.184\n",
            "Validation Loss: 1.9292299151420593, Validation Accuracy: 49.48\n",
            "[43/150]: Training Loss: 1.6734726489806662, Training Accuracy: 53.69\n",
            "Validation Loss: 1.9281952559947968, Validation Accuracy: 49.57\n",
            "[44/150]: Training Loss: 1.6466177933070125, Training Accuracy: 54.438\n",
            "Validation Loss: 1.92038534283638, Validation Accuracy: 49.7\n",
            "[45/150]: Training Loss: 1.6545339092916371, Training Accuracy: 54.198\n",
            "Validation Loss: 1.9556318461894988, Validation Accuracy: 49.26\n",
            "[46/150]: Training Loss: 1.619915745696243, Training Accuracy: 54.986\n",
            "Validation Loss: 1.899458384513855, Validation Accuracy: 50.32\n",
            "[47/150]: Training Loss: 1.6211930987786274, Training Accuracy: 54.738\n",
            "Validation Loss: 1.9299038767814636, Validation Accuracy: 49.14\n",
            "[48/150]: Training Loss: 1.5995109361045214, Training Accuracy: 55.258\n",
            "Validation Loss: 1.9302596151828766, Validation Accuracy: 49.32\n",
            "[49/150]: Training Loss: 1.5750943154704815, Training Accuracy: 55.898\n",
            "Validation Loss: 1.8993667602539062, Validation Accuracy: 49.91\n",
            "[50/150]: Training Loss: 1.5744633698950008, Training Accuracy: 55.76\n",
            "Validation Loss: 1.9295048713684082, Validation Accuracy: 50.3\n",
            "[51/150]: Training Loss: 1.5583884862004493, Training Accuracy: 56.348\n",
            "Validation Loss: 1.925916600227356, Validation Accuracy: 50.14\n",
            "[52/150]: Training Loss: 1.5439508910081825, Training Accuracy: 56.592\n",
            "Validation Loss: 1.8903591930866241, Validation Accuracy: 50.65\n",
            "[53/150]: Training Loss: 1.5187961057740815, Training Accuracy: 57.12\n",
            "Validation Loss: 1.893898105621338, Validation Accuracy: 51.28\n",
            "[54/150]: Training Loss: 1.500082329827912, Training Accuracy: 57.754\n",
            "Validation Loss: 1.8901280999183654, Validation Accuracy: 50.42\n",
            "[55/150]: Training Loss: 1.5054621915428006, Training Accuracy: 57.632\n",
            "Validation Loss: 1.890578955411911, Validation Accuracy: 51.07\n",
            "[56/150]: Training Loss: 1.4812841756003243, Training Accuracy: 57.986\n",
            "Validation Loss: 1.9068008363246918, Validation Accuracy: 51.44\n",
            "[57/150]: Training Loss: 1.4542514341218131, Training Accuracy: 58.654\n",
            "Validation Loss: 1.8665942788124084, Validation Accuracy: 51.26\n",
            "[58/150]: Training Loss: 1.4304890097404013, Training Accuracy: 59.206\n",
            "Validation Loss: 1.872557681798935, Validation Accuracy: 51.35\n",
            "[59/150]: Training Loss: 1.4232833567930727, Training Accuracy: 59.584\n",
            "Validation Loss: 1.9096780002117157, Validation Accuracy: 50.55\n",
            "[60/150]: Training Loss: 1.4309481491847915, Training Accuracy: 59.184\n",
            "Validation Loss: 1.8791188061237336, Validation Accuracy: 51.2\n",
            "[61/150]: Training Loss: 1.40531452334657, Training Accuracy: 59.96\n",
            "Validation Loss: 1.8862035810947417, Validation Accuracy: 51.85\n",
            "[62/150]: Training Loss: 1.3938273799662688, Training Accuracy: 60.274\n",
            "Validation Loss: 1.8729142725467682, Validation Accuracy: 51.37\n",
            "[63/150]: Training Loss: 1.3863425692733453, Training Accuracy: 60.462\n",
            "Validation Loss: 1.8725131154060364, Validation Accuracy: 52.01\n",
            "[64/150]: Training Loss: 1.366844469187211, Training Accuracy: 60.966\n",
            "Validation Loss: 1.8498412251472474, Validation Accuracy: 51.87\n",
            "[65/150]: Training Loss: 1.3531476259231567, Training Accuracy: 61.048\n",
            "Validation Loss: 1.8571744859218597, Validation Accuracy: 52.36\n",
            "[66/150]: Training Loss: 1.3398733954040372, Training Accuracy: 61.472\n",
            "Validation Loss: 1.869799542427063, Validation Accuracy: 52.02\n",
            "[67/150]: Training Loss: 1.3146201080205488, Training Accuracy: 62.184\n",
            "Validation Loss: 1.85557941198349, Validation Accuracy: 52.16\n",
            "[68/150]: Training Loss: 1.3349930096645743, Training Accuracy: 61.624\n",
            "Validation Loss: 1.899474561214447, Validation Accuracy: 51.8\n",
            "[69/150]: Training Loss: 1.2890492300597989, Training Accuracy: 63.07\n",
            "Validation Loss: 1.8615913569927216, Validation Accuracy: 52.55\n",
            "[70/150]: Training Loss: 1.281143541238746, Training Accuracy: 63.172\n",
            "Validation Loss: 1.8803191304206848, Validation Accuracy: 51.97\n",
            "[71/150]: Training Loss: 1.2725608847579177, Training Accuracy: 63.378\n",
            "Validation Loss: 1.859445983171463, Validation Accuracy: 52.42\n",
            "[72/150]: Training Loss: 1.2559378949963316, Training Accuracy: 63.878\n",
            "Validation Loss: 1.8568916201591492, Validation Accuracy: 52.05\n",
            "[73/150]: Training Loss: 1.236931935865052, Training Accuracy: 64.244\n",
            "Validation Loss: 1.8739505887031556, Validation Accuracy: 52.77\n",
            "[74/150]: Training Loss: 1.2173650824293798, Training Accuracy: 64.762\n",
            "Validation Loss: 1.8348273098468781, Validation Accuracy: 53.4\n",
            "[75/150]: Training Loss: 1.2067504488691991, Training Accuracy: 65.066\n",
            "Validation Loss: 1.8692607581615448, Validation Accuracy: 53.1\n",
            "[76/150]: Training Loss: 1.1903777292796545, Training Accuracy: 65.334\n",
            "Validation Loss: 1.8275393545627594, Validation Accuracy: 54.25\n",
            "[77/150]: Training Loss: 1.1792806843105628, Training Accuracy: 65.694\n",
            "Validation Loss: 1.8515967845916748, Validation Accuracy: 53.52\n",
            "[78/150]: Training Loss: 1.1699374263383904, Training Accuracy: 65.942\n",
            "Validation Loss: 1.8811356365680694, Validation Accuracy: 53.09\n",
            "[79/150]: Training Loss: 1.1490371531369734, Training Accuracy: 66.792\n",
            "Validation Loss: 1.8353333652019501, Validation Accuracy: 53.82\n",
            "[80/150]: Training Loss: 1.13668700383634, Training Accuracy: 66.562\n",
            "Validation Loss: 1.8432445168495177, Validation Accuracy: 53.57\n",
            "[81/150]: Training Loss: 1.1307378818794174, Training Accuracy: 67.21\n",
            "Validation Loss: 1.8481176435947417, Validation Accuracy: 53.14\n",
            "[82/150]: Training Loss: 1.113474543605532, Training Accuracy: 67.312\n",
            "Validation Loss: 1.8410939693450927, Validation Accuracy: 53.83\n",
            "[83/150]: Training Loss: 1.087531100122296, Training Accuracy: 68.23\n",
            "Validation Loss: 1.8605490565299987, Validation Accuracy: 54.45\n",
            "[84/150]: Training Loss: 1.0892518618885352, Training Accuracy: 68.016\n",
            "Validation Loss: 1.8244962751865388, Validation Accuracy: 54.28\n",
            "[85/150]: Training Loss: 1.0597951071602958, Training Accuracy: 68.916\n",
            "Validation Loss: 1.848558533191681, Validation Accuracy: 54.32\n",
            "[86/150]: Training Loss: 1.0610668713949165, Training Accuracy: 69.08\n",
            "Validation Loss: 1.834687203168869, Validation Accuracy: 54.36\n",
            "[87/150]: Training Loss: 1.029247879373784, Training Accuracy: 69.662\n",
            "Validation Loss: 1.8577094554901123, Validation Accuracy: 54.1\n",
            "[88/150]: Training Loss: 1.0305843438420976, Training Accuracy: 69.63\n",
            "Validation Loss: 1.88287433385849, Validation Accuracy: 53.74\n",
            "[89/150]: Training Loss: 1.0086117690923262, Training Accuracy: 70.346\n",
            "Validation Loss: 1.8663456857204437, Validation Accuracy: 53.54\n",
            "[90/150]: Training Loss: 0.9981355539390019, Training Accuracy: 70.802\n",
            "Validation Loss: 1.8623527228832244, Validation Accuracy: 53.93\n",
            "[91/150]: Training Loss: 0.986907957159743, Training Accuracy: 70.956\n",
            "Validation Loss: 1.8775681614875794, Validation Accuracy: 54.56\n",
            "[92/150]: Training Loss: 0.9677880217834395, Training Accuracy: 71.402\n",
            "Validation Loss: 1.886433583498001, Validation Accuracy: 54.06\n",
            "[93/150]: Training Loss: 0.9601449692735866, Training Accuracy: 71.714\n",
            "Validation Loss: 1.848057508468628, Validation Accuracy: 55.12\n",
            "[94/150]: Training Loss: 0.9483164567120221, Training Accuracy: 71.99\n",
            "Validation Loss: 1.8797329545021058, Validation Accuracy: 54.52\n",
            "[95/150]: Training Loss: 0.9349474110165421, Training Accuracy: 72.398\n",
            "Validation Loss: 1.8802269518375396, Validation Accuracy: 54.13\n",
            "[96/150]: Training Loss: 0.9153923319310558, Training Accuracy: 72.582\n",
            "Validation Loss: 1.8897387385368347, Validation Accuracy: 54.28\n",
            "[97/150]: Training Loss: 0.9160392132340646, Training Accuracy: 72.794\n",
            "Validation Loss: 1.9283715963363648, Validation Accuracy: 53.5\n",
            "[98/150]: Training Loss: 0.9007182382807439, Training Accuracy: 73.294\n",
            "Validation Loss: 1.8609421133995057, Validation Accuracy: 54.96\n",
            "[99/150]: Training Loss: 0.8783578246223683, Training Accuracy: 73.912\n",
            "Validation Loss: 1.8637104988098145, Validation Accuracy: 54.56\n",
            "[100/150]: Training Loss: 0.8765367439814976, Training Accuracy: 74.022\n",
            "Validation Loss: 1.8750475943088531, Validation Accuracy: 54.59\n",
            "[101/150]: Training Loss: 0.8546222393610039, Training Accuracy: 74.918\n",
            "Validation Loss: 1.8807278335094453, Validation Accuracy: 55.13\n",
            "[102/150]: Training Loss: 0.8389398102857628, Training Accuracy: 74.972\n",
            "Validation Loss: 1.8944664776325226, Validation Accuracy: 54.78\n",
            "[103/150]: Training Loss: 0.8364474201688961, Training Accuracy: 75.32\n",
            "Validation Loss: 1.8999429523944855, Validation Accuracy: 54.68\n",
            "[104/150]: Training Loss: 0.8233104719191181, Training Accuracy: 75.606\n",
            "Validation Loss: 1.9150757372379303, Validation Accuracy: 54.49\n",
            "[105/150]: Training Loss: 0.8071710479502775, Training Accuracy: 76.094\n",
            "Validation Loss: 1.8923523843288421, Validation Accuracy: 55.54\n",
            "[106/150]: Training Loss: 0.7909371567015745, Training Accuracy: 76.448\n",
            "Validation Loss: 1.883741980791092, Validation Accuracy: 54.92\n",
            "[107/150]: Training Loss: 0.7867257595062256, Training Accuracy: 76.748\n",
            "Validation Loss: 1.8950099110603333, Validation Accuracy: 55.47\n",
            "[108/150]: Training Loss: 0.7650761269793218, Training Accuracy: 77.31\n",
            "Validation Loss: 1.9024061024188996, Validation Accuracy: 54.91\n",
            "[109/150]: Training Loss: 0.7652728691393015, Training Accuracy: 77.178\n",
            "Validation Loss: 1.9312968671321868, Validation Accuracy: 54.57\n",
            "[110/150]: Training Loss: 0.7572217492424712, Training Accuracy: 77.548\n",
            "Validation Loss: 1.8906243860721588, Validation Accuracy: 55.71\n",
            "[111/150]: Training Loss: 0.738684381149253, Training Accuracy: 77.932\n",
            "Validation Loss: 1.945603609085083, Validation Accuracy: 55.18\n",
            "[112/150]: Training Loss: 0.7319968044757843, Training Accuracy: 78.382\n",
            "Validation Loss: 1.9286673545837403, Validation Accuracy: 55.27\n",
            "[113/150]: Training Loss: 0.7233879006638819, Training Accuracy: 78.482\n",
            "Validation Loss: 1.9232488691806793, Validation Accuracy: 55.58\n",
            "[114/150]: Training Loss: 0.7083694521261721, Training Accuracy: 78.814\n",
            "Validation Loss: 1.907062864303589, Validation Accuracy: 55.51\n",
            "[115/150]: Training Loss: 0.7031112666032753, Training Accuracy: 79.204\n",
            "Validation Loss: 1.9117585182189942, Validation Accuracy: 56.02\n",
            "[116/150]: Training Loss: 0.6852655745282465, Training Accuracy: 79.458\n",
            "Validation Loss: 1.9387612223625184, Validation Accuracy: 55.18\n",
            "[117/150]: Training Loss: 0.6826438423322172, Training Accuracy: 79.792\n",
            "Validation Loss: 1.923887985944748, Validation Accuracy: 55.49\n",
            "[118/150]: Training Loss: 0.6681522337757811, Training Accuracy: 80.242\n",
            "Validation Loss: 1.940861666202545, Validation Accuracy: 55.59\n",
            "[119/150]: Training Loss: 0.6691557758924912, Training Accuracy: 80.146\n",
            "Validation Loss: 1.953080016374588, Validation Accuracy: 55.29\n",
            "[120/150]: Training Loss: 0.6531465272514188, Training Accuracy: 80.714\n",
            "Validation Loss: 1.9404853343963624, Validation Accuracy: 55.54\n",
            "[121/150]: Training Loss: 0.6419856098233437, Training Accuracy: 81.21\n",
            "Validation Loss: 1.9526274442672729, Validation Accuracy: 56.17\n",
            "[122/150]: Training Loss: 0.6383003540793244, Training Accuracy: 81.27\n",
            "Validation Loss: 1.9685742020606996, Validation Accuracy: 55.67\n",
            "[123/150]: Training Loss: 0.6263646182357049, Training Accuracy: 81.396\n",
            "Validation Loss: 1.9449464201927185, Validation Accuracy: 56.05\n",
            "[124/150]: Training Loss: 0.62737323982375, Training Accuracy: 81.438\n",
            "Validation Loss: 1.9453241765499114, Validation Accuracy: 56.28\n",
            "[125/150]: Training Loss: 0.6171576502371807, Training Accuracy: 81.866\n",
            "Validation Loss: 1.9553956925868987, Validation Accuracy: 55.63\n",
            "[126/150]: Training Loss: 0.6041063827519514, Training Accuracy: 82.16\n",
            "Validation Loss: 1.9582968175411224, Validation Accuracy: 56.15\n",
            "[127/150]: Training Loss: 0.6006453934372687, Training Accuracy: 82.38\n",
            "Validation Loss: 1.9529106080532075, Validation Accuracy: 56.03\n",
            "[128/150]: Training Loss: 0.6008156434613832, Training Accuracy: 82.348\n",
            "Validation Loss: 1.9448323190212249, Validation Accuracy: 56.3\n",
            "[129/150]: Training Loss: 0.5887871582289131, Training Accuracy: 82.762\n",
            "Validation Loss: 1.9513534665107728, Validation Accuracy: 56.25\n",
            "[130/150]: Training Loss: 0.5888028677020755, Training Accuracy: 82.86\n",
            "Validation Loss: 1.9529175937175751, Validation Accuracy: 56.18\n",
            "[131/150]: Training Loss: 0.5761450562550097, Training Accuracy: 83.106\n",
            "Validation Loss: 1.9645096361637115, Validation Accuracy: 56.02\n",
            "[132/150]: Training Loss: 0.5727416809116092, Training Accuracy: 83.094\n",
            "Validation Loss: 1.963749361038208, Validation Accuracy: 56.38\n",
            "[133/150]: Training Loss: 0.5652356436666177, Training Accuracy: 83.672\n",
            "Validation Loss: 1.9716902256011963, Validation Accuracy: 56.28\n",
            "[134/150]: Training Loss: 0.5695076165150623, Training Accuracy: 83.448\n",
            "Validation Loss: 1.964329320192337, Validation Accuracy: 55.99\n",
            "[135/150]: Training Loss: 0.5608592775403237, Training Accuracy: 83.678\n",
            "Validation Loss: 1.9603359639644622, Validation Accuracy: 56.25\n",
            "[136/150]: Training Loss: 0.5542723040799705, Training Accuracy: 83.854\n",
            "Validation Loss: 1.9673468470573425, Validation Accuracy: 56.04\n",
            "[137/150]: Training Loss: 0.5495593383604166, Training Accuracy: 84.128\n",
            "Validation Loss: 1.9731853008270264, Validation Accuracy: 56.19\n",
            "[138/150]: Training Loss: 0.5444910410715609, Training Accuracy: 84.204\n",
            "Validation Loss: 1.9700454473495483, Validation Accuracy: 56.12\n",
            "[139/150]: Training Loss: 0.5433347140039716, Training Accuracy: 84.306\n",
            "Validation Loss: 1.9688788115978242, Validation Accuracy: 56.13\n",
            "[140/150]: Training Loss: 0.5362506448006144, Training Accuracy: 84.586\n",
            "Validation Loss: 1.966701751947403, Validation Accuracy: 56.24\n",
            "[141/150]: Training Loss: 0.5390761190531205, Training Accuracy: 84.338\n",
            "Validation Loss: 1.9651995241641997, Validation Accuracy: 56.21\n",
            "[142/150]: Training Loss: 0.5341207445884237, Training Accuracy: 84.41\n",
            "Validation Loss: 1.9675312757492065, Validation Accuracy: 56.34\n",
            "[143/150]: Training Loss: 0.5282508870776819, Training Accuracy: 84.872\n",
            "Validation Loss: 1.967752468585968, Validation Accuracy: 56.25\n",
            "[144/150]: Training Loss: 0.5355107656547001, Training Accuracy: 84.532\n",
            "Validation Loss: 1.967381328344345, Validation Accuracy: 56.19\n",
            "[145/150]: Training Loss: 0.5333734960580359, Training Accuracy: 84.51\n",
            "Validation Loss: 1.969217723608017, Validation Accuracy: 56.19\n",
            "[146/150]: Training Loss: 0.5298109002867524, Training Accuracy: 84.75\n",
            "Validation Loss: 1.9694741308689117, Validation Accuracy: 56.12\n",
            "[147/150]: Training Loss: 0.529324583253082, Training Accuracy: 84.722\n",
            "Validation Loss: 1.9707287430763245, Validation Accuracy: 56.17\n",
            "[148/150]: Training Loss: 0.5251490242627203, Training Accuracy: 84.936\n",
            "Validation Loss: 1.9699740409851074, Validation Accuracy: 56.26\n",
            "[149/150]: Training Loss: 0.5242341507454308, Training Accuracy: 84.942\n",
            "Validation Loss: 1.97024707198143, Validation Accuracy: 56.16\n",
            "[150/150]: Training Loss: 0.5341996495821038, Training Accuracy: 84.57\n",
            "Validation Loss: 1.9700913786888123, Validation Accuracy: 56.18\n",
            "**********************************************************************\n",
            "Test Loss: 1.9700913786888123, Test Accuracy: 56.18\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>56.18</td></tr><tr><td>Test Loss</td><td>1.97009</td></tr><tr><td>Train Accuracy</td><td>84.57</td></tr><tr><td>Train Loss</td><td>0.5342</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/momu4e5u</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_012749-momu4e5u/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 1024, Learning rate: 6.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_014707-w80ujlhs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">batch_size=1024 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.271560571631607, Training Accuracy: 4.982\n",
            "Validation Loss: 3.9391962051391602, Validation Accuracy: 8.84\n",
            "[2/150]: Training Loss: 3.82728639914065, Training Accuracy: 10.948\n",
            "Validation Loss: 3.6827336311340333, Validation Accuracy: 13.37\n",
            "[3/150]: Training Loss: 3.6269987845907408, Training Accuracy: 14.39\n",
            "Validation Loss: 3.4175909042358397, Validation Accuracy: 18.27\n",
            "[4/150]: Training Loss: 3.4358463238696664, Training Accuracy: 17.696\n",
            "Validation Loss: 3.2815504550933836, Validation Accuracy: 20.38\n",
            "[5/150]: Training Loss: 3.3039202203555984, Training Accuracy: 19.798\n",
            "Validation Loss: 3.171510195732117, Validation Accuracy: 23.09\n",
            "[6/150]: Training Loss: 3.1788000671231016, Training Accuracy: 22.106\n",
            "Validation Loss: 3.083156633377075, Validation Accuracy: 24.25\n",
            "[7/150]: Training Loss: 3.0781905553778826, Training Accuracy: 24.04\n",
            "Validation Loss: 2.9470993995666506, Validation Accuracy: 26.99\n",
            "[8/150]: Training Loss: 2.9905799846259917, Training Accuracy: 25.462\n",
            "Validation Loss: 2.8303237915039063, Validation Accuracy: 29.04\n",
            "[9/150]: Training Loss: 2.8789747199233697, Training Accuracy: 28.024\n",
            "Validation Loss: 2.7251497507095337, Validation Accuracy: 31.63\n",
            "[10/150]: Training Loss: 2.752841701312941, Training Accuracy: 30.378\n",
            "Validation Loss: 2.6787135124206545, Validation Accuracy: 32.86\n",
            "[11/150]: Training Loss: 2.664300650966411, Training Accuracy: 32.018\n",
            "Validation Loss: 2.5810091733932494, Validation Accuracy: 34.34\n",
            "[12/150]: Training Loss: 2.6055227445096385, Training Accuracy: 33.34\n",
            "Validation Loss: 2.511804437637329, Validation Accuracy: 35.24\n",
            "[13/150]: Training Loss: 2.569062106463374, Training Accuracy: 34.12\n",
            "Validation Loss: 2.452015995979309, Validation Accuracy: 36.63\n",
            "[14/150]: Training Loss: 2.4965496793085213, Training Accuracy: 35.586\n",
            "Validation Loss: 2.353745174407959, Validation Accuracy: 38.35\n",
            "[15/150]: Training Loss: 2.4792360870205625, Training Accuracy: 35.788\n",
            "Validation Loss: 2.362164545059204, Validation Accuracy: 38.51\n",
            "[16/150]: Training Loss: 2.406777240792099, Training Accuracy: 37.498\n",
            "Validation Loss: 2.322283720970154, Validation Accuracy: 39.52\n",
            "[17/150]: Training Loss: 2.3524391651153564, Training Accuracy: 38.372\n",
            "Validation Loss: 2.2932183027267454, Validation Accuracy: 40.0\n",
            "[18/150]: Training Loss: 2.3162564647441006, Training Accuracy: 39.304\n",
            "Validation Loss: 2.390507221221924, Validation Accuracy: 38.54\n",
            "[19/150]: Training Loss: 2.3010421821049283, Training Accuracy: 39.48\n",
            "Validation Loss: 2.2039053201675416, Validation Accuracy: 42.83\n",
            "[20/150]: Training Loss: 2.2905601968570632, Training Accuracy: 40.014\n",
            "Validation Loss: 2.327000045776367, Validation Accuracy: 39.01\n",
            "[21/150]: Training Loss: 2.2232315151058897, Training Accuracy: 41.472\n",
            "Validation Loss: 2.1848330736160277, Validation Accuracy: 42.37\n",
            "[22/150]: Training Loss: 2.175964046497734, Training Accuracy: 42.316\n",
            "Validation Loss: 2.192854475975037, Validation Accuracy: 42.34\n",
            "[23/150]: Training Loss: 2.12663603315548, Training Accuracy: 43.39\n",
            "Validation Loss: 2.184653973579407, Validation Accuracy: 42.91\n",
            "[24/150]: Training Loss: 2.1151150294712613, Training Accuracy: 43.664\n",
            "Validation Loss: 2.1352186679840086, Validation Accuracy: 43.8\n",
            "[25/150]: Training Loss: 2.0990794507824644, Training Accuracy: 44.256\n",
            "Validation Loss: 2.088001215457916, Validation Accuracy: 44.67\n",
            "[26/150]: Training Loss: 2.0608093349301084, Training Accuracy: 44.852\n",
            "Validation Loss: 2.1832612276077272, Validation Accuracy: 42.92\n",
            "[27/150]: Training Loss: 2.0558675892499028, Training Accuracy: 45.23\n",
            "Validation Loss: 2.176005721092224, Validation Accuracy: 43.08\n",
            "[28/150]: Training Loss: 2.0222370770512796, Training Accuracy: 45.868\n",
            "Validation Loss: 2.1084380388259887, Validation Accuracy: 44.53\n",
            "[29/150]: Training Loss: 1.9681626996215509, Training Accuracy: 47.006\n",
            "Validation Loss: 2.07066353559494, Validation Accuracy: 45.38\n",
            "[30/150]: Training Loss: 1.9436734793137531, Training Accuracy: 47.268\n",
            "Validation Loss: 2.0732940912246702, Validation Accuracy: 45.56\n",
            "[31/150]: Training Loss: 1.9339864083698817, Training Accuracy: 48.042\n",
            "Validation Loss: 2.095534420013428, Validation Accuracy: 45.23\n",
            "[32/150]: Training Loss: 1.9033171717001467, Training Accuracy: 48.32\n",
            "Validation Loss: 2.111021065711975, Validation Accuracy: 45.35\n",
            "[33/150]: Training Loss: 1.904011852887212, Training Accuracy: 48.414\n",
            "Validation Loss: 2.050978398323059, Validation Accuracy: 46.52\n",
            "[34/150]: Training Loss: 1.8750450124545974, Training Accuracy: 48.976\n",
            "Validation Loss: 2.080773401260376, Validation Accuracy: 45.2\n",
            "[35/150]: Training Loss: 1.8805813740710824, Training Accuracy: 48.968\n",
            "Validation Loss: 2.036470913887024, Validation Accuracy: 46.34\n",
            "[36/150]: Training Loss: 1.851276424466347, Training Accuracy: 49.646\n",
            "Validation Loss: 2.1005828619003295, Validation Accuracy: 45.2\n",
            "[37/150]: Training Loss: 1.8493371909978438, Training Accuracy: 49.736\n",
            "Validation Loss: 2.003628730773926, Validation Accuracy: 46.62\n",
            "[38/150]: Training Loss: 1.7895233460835047, Training Accuracy: 50.876\n",
            "Validation Loss: 1.9916603326797486, Validation Accuracy: 47.91\n",
            "[39/150]: Training Loss: 1.783764887829216, Training Accuracy: 51.294\n",
            "Validation Loss: 2.066832160949707, Validation Accuracy: 45.61\n",
            "[40/150]: Training Loss: 1.7760933297021049, Training Accuracy: 51.504\n",
            "Validation Loss: 1.9901643991470337, Validation Accuracy: 47.5\n",
            "[41/150]: Training Loss: 1.7614454274274864, Training Accuracy: 51.798\n",
            "Validation Loss: 2.0182290196418764, Validation Accuracy: 47.1\n",
            "[42/150]: Training Loss: 1.7892101711156416, Training Accuracy: 51.024\n",
            "Validation Loss: 1.9716030478477478, Validation Accuracy: 48.76\n",
            "[43/150]: Training Loss: 1.7074257597631337, Training Accuracy: 52.916\n",
            "Validation Loss: 1.9718806385993957, Validation Accuracy: 48.61\n",
            "[44/150]: Training Loss: 1.714418238523055, Training Accuracy: 52.714\n",
            "Validation Loss: 2.0062466263771057, Validation Accuracy: 48.27\n",
            "[45/150]: Training Loss: 1.6869578483153362, Training Accuracy: 53.334\n",
            "Validation Loss: 1.95201518535614, Validation Accuracy: 49.06\n",
            "[46/150]: Training Loss: 1.6628945092765652, Training Accuracy: 53.922\n",
            "Validation Loss: 2.012867844104767, Validation Accuracy: 47.15\n",
            "[47/150]: Training Loss: 1.6412470778640436, Training Accuracy: 54.254\n",
            "Validation Loss: 1.923640739917755, Validation Accuracy: 49.27\n",
            "[48/150]: Training Loss: 1.6261077705694704, Training Accuracy: 55.032\n",
            "Validation Loss: 1.9601864099502564, Validation Accuracy: 48.98\n",
            "[49/150]: Training Loss: 1.6493362480280351, Training Accuracy: 54.152\n",
            "Validation Loss: 1.9593440890312195, Validation Accuracy: 48.65\n",
            "[50/150]: Training Loss: 1.612999371119908, Training Accuracy: 55.134\n",
            "Validation Loss: 1.9344399094581604, Validation Accuracy: 49.38\n",
            "[51/150]: Training Loss: 1.5939155281806479, Training Accuracy: 55.666\n",
            "Validation Loss: 1.9557547926902772, Validation Accuracy: 48.7\n",
            "[52/150]: Training Loss: 1.6124721181635955, Training Accuracy: 55.024\n",
            "Validation Loss: 1.9627613067626952, Validation Accuracy: 48.75\n",
            "[53/150]: Training Loss: 1.5704505808499394, Training Accuracy: 56.09\n",
            "Validation Loss: 1.9339674592018128, Validation Accuracy: 49.77\n",
            "[54/150]: Training Loss: 1.556705151285444, Training Accuracy: 56.304\n",
            "Validation Loss: 1.910308563709259, Validation Accuracy: 50.74\n",
            "[55/150]: Training Loss: 1.5271518887305746, Training Accuracy: 57.15\n",
            "Validation Loss: 1.8914035081863403, Validation Accuracy: 50.77\n",
            "[56/150]: Training Loss: 1.5157563102488616, Training Accuracy: 57.53\n",
            "Validation Loss: 1.8953699111938476, Validation Accuracy: 50.82\n",
            "[57/150]: Training Loss: 1.4868425179500968, Training Accuracy: 58.284\n",
            "Validation Loss: 1.960522997379303, Validation Accuracy: 49.2\n",
            "[58/150]: Training Loss: 1.5009924586938352, Training Accuracy: 57.544\n",
            "Validation Loss: 1.9257111549377441, Validation Accuracy: 50.88\n",
            "[59/150]: Training Loss: 1.4776659741693614, Training Accuracy: 58.214\n",
            "Validation Loss: 1.9358840227127074, Validation Accuracy: 50.04\n",
            "[60/150]: Training Loss: 1.4657867806298392, Training Accuracy: 58.49\n",
            "Validation Loss: 2.0199026823043824, Validation Accuracy: 48.59\n",
            "[61/150]: Training Loss: 1.4666189709488227, Training Accuracy: 58.868\n",
            "Validation Loss: 1.9441120982170106, Validation Accuracy: 49.79\n",
            "[62/150]: Training Loss: 1.4370595435706937, Training Accuracy: 59.142\n",
            "Validation Loss: 1.8950949430465698, Validation Accuracy: 51.17\n",
            "[63/150]: Training Loss: 1.4119965835493438, Training Accuracy: 59.966\n",
            "Validation Loss: 1.946419107913971, Validation Accuracy: 49.96\n",
            "[64/150]: Training Loss: 1.3992952692265412, Training Accuracy: 60.37\n",
            "Validation Loss: 1.929420042037964, Validation Accuracy: 50.74\n",
            "[65/150]: Training Loss: 1.3843509275086072, Training Accuracy: 60.93\n",
            "Validation Loss: 1.8808708190917969, Validation Accuracy: 51.52\n",
            "[66/150]: Training Loss: 1.3892741276293386, Training Accuracy: 60.538\n",
            "Validation Loss: 1.9178170323371888, Validation Accuracy: 51.05\n",
            "[67/150]: Training Loss: 1.3926233807388617, Training Accuracy: 60.324\n",
            "Validation Loss: 1.879079854488373, Validation Accuracy: 52.14\n",
            "[68/150]: Training Loss: 1.3284603332986638, Training Accuracy: 62.108\n",
            "Validation Loss: 1.8741150736808776, Validation Accuracy: 51.87\n",
            "[69/150]: Training Loss: 1.3297611377677139, Training Accuracy: 62.144\n",
            "Validation Loss: 1.8850895166397095, Validation Accuracy: 51.78\n",
            "[70/150]: Training Loss: 1.3190836857776254, Training Accuracy: 62.086\n",
            "Validation Loss: 1.8964969992637635, Validation Accuracy: 51.72\n",
            "[71/150]: Training Loss: 1.297834805079869, Training Accuracy: 63.002\n",
            "Validation Loss: 1.8922056078910827, Validation Accuracy: 51.94\n",
            "[72/150]: Training Loss: 1.3022558105235198, Training Accuracy: 62.866\n",
            "Validation Loss: 1.8891796469688416, Validation Accuracy: 52.07\n",
            "[73/150]: Training Loss: 1.2681196271156778, Training Accuracy: 63.622\n",
            "Validation Loss: 1.9051270723342895, Validation Accuracy: 52.41\n",
            "[74/150]: Training Loss: 1.2562547800492267, Training Accuracy: 64.092\n",
            "Validation Loss: 1.8912514567375183, Validation Accuracy: 52.28\n",
            "[75/150]: Training Loss: 1.2469108761573324, Training Accuracy: 64.088\n",
            "Validation Loss: 1.9140023827552795, Validation Accuracy: 52.11\n",
            "[76/150]: Training Loss: 1.2424099080416622, Training Accuracy: 64.206\n",
            "Validation Loss: 1.896690595149994, Validation Accuracy: 52.53\n",
            "[77/150]: Training Loss: 1.2172678052162638, Training Accuracy: 64.804\n",
            "Validation Loss: 1.8944836139678956, Validation Accuracy: 52.54\n",
            "[78/150]: Training Loss: 1.198543380717842, Training Accuracy: 65.358\n",
            "Validation Loss: 1.8942208647727967, Validation Accuracy: 52.32\n",
            "[79/150]: Training Loss: 1.198562699921277, Training Accuracy: 65.602\n",
            "Validation Loss: 1.8823209404945374, Validation Accuracy: 52.42\n",
            "[80/150]: Training Loss: 1.1809428224758225, Training Accuracy: 66.04\n",
            "Validation Loss: 1.8809239506721496, Validation Accuracy: 52.57\n",
            "[81/150]: Training Loss: 1.1573098119424314, Training Accuracy: 66.476\n",
            "Validation Loss: 1.904803991317749, Validation Accuracy: 52.64\n",
            "[82/150]: Training Loss: 1.1748385405053898, Training Accuracy: 65.876\n",
            "Validation Loss: 1.8975732803344727, Validation Accuracy: 52.68\n",
            "[83/150]: Training Loss: 1.1381618465696062, Training Accuracy: 67.06\n",
            "Validation Loss: 1.87950758934021, Validation Accuracy: 53.8\n",
            "[84/150]: Training Loss: 1.1169312851769584, Training Accuracy: 67.614\n",
            "Validation Loss: 1.9594017744064331, Validation Accuracy: 51.52\n",
            "[85/150]: Training Loss: 1.1326112601221825, Training Accuracy: 67.212\n",
            "Validation Loss: 1.9392709732055664, Validation Accuracy: 52.51\n",
            "[86/150]: Training Loss: 1.1153452299079116, Training Accuracy: 67.558\n",
            "Validation Loss: 1.8824020862579345, Validation Accuracy: 53.05\n",
            "[87/150]: Training Loss: 1.075961629955136, Training Accuracy: 68.556\n",
            "Validation Loss: 1.8995132923126221, Validation Accuracy: 53.22\n",
            "[88/150]: Training Loss: 1.0561599804430593, Training Accuracy: 69.222\n",
            "Validation Loss: 1.8934579133987426, Validation Accuracy: 53.25\n",
            "[89/150]: Training Loss: 1.0379744488365796, Training Accuracy: 69.548\n",
            "Validation Loss: 1.8907739281654359, Validation Accuracy: 54.05\n",
            "[90/150]: Training Loss: 1.0645462481343015, Training Accuracy: 69.002\n",
            "Validation Loss: 1.9286641478538513, Validation Accuracy: 52.38\n",
            "[91/150]: Training Loss: 1.0510404596523362, Training Accuracy: 69.392\n",
            "Validation Loss: 1.897424077987671, Validation Accuracy: 53.61\n",
            "[92/150]: Training Loss: 1.017185703832276, Training Accuracy: 70.506\n",
            "Validation Loss: 1.9066467523574828, Validation Accuracy: 53.56\n",
            "[93/150]: Training Loss: 0.9912244945156331, Training Accuracy: 70.89\n",
            "Validation Loss: 1.9277787804603577, Validation Accuracy: 53.53\n",
            "[94/150]: Training Loss: 1.0054571652898983, Training Accuracy: 70.53\n",
            "Validation Loss: 1.8809196829795838, Validation Accuracy: 54.1\n",
            "[95/150]: Training Loss: 0.9765667416611497, Training Accuracy: 71.32\n",
            "Validation Loss: 1.8944197297096252, Validation Accuracy: 53.48\n",
            "[96/150]: Training Loss: 0.9578249174721387, Training Accuracy: 71.926\n",
            "Validation Loss: 1.942376160621643, Validation Accuracy: 53.53\n",
            "[97/150]: Training Loss: 0.9575933753227701, Training Accuracy: 71.676\n",
            "Validation Loss: 1.8917027354240417, Validation Accuracy: 53.65\n",
            "[98/150]: Training Loss: 0.944321874453097, Training Accuracy: 72.258\n",
            "Validation Loss: 1.8984474778175353, Validation Accuracy: 54.22\n",
            "[99/150]: Training Loss: 0.9205025398001379, Training Accuracy: 72.942\n",
            "Validation Loss: 1.9325331091880797, Validation Accuracy: 54.27\n",
            "[100/150]: Training Loss: 0.9185542439927861, Training Accuracy: 72.924\n",
            "Validation Loss: 1.9163445711135865, Validation Accuracy: 54.26\n",
            "[101/150]: Training Loss: 0.8990846799344433, Training Accuracy: 73.314\n",
            "Validation Loss: 1.9365061402320862, Validation Accuracy: 54.02\n",
            "[102/150]: Training Loss: 0.8797871519108208, Training Accuracy: 74.004\n",
            "Validation Loss: 1.937075173854828, Validation Accuracy: 54.45\n",
            "[103/150]: Training Loss: 0.8798652291297913, Training Accuracy: 74.044\n",
            "Validation Loss: 1.9165674328804017, Validation Accuracy: 54.24\n",
            "[104/150]: Training Loss: 0.8599669252123151, Training Accuracy: 74.54\n",
            "Validation Loss: 1.9492801547050476, Validation Accuracy: 53.91\n",
            "[105/150]: Training Loss: 0.8473539729507602, Training Accuracy: 74.856\n",
            "Validation Loss: 1.9327858686447144, Validation Accuracy: 53.8\n",
            "[106/150]: Training Loss: 0.8454914895855651, Training Accuracy: 74.948\n",
            "Validation Loss: 1.918694531917572, Validation Accuracy: 54.58\n",
            "[107/150]: Training Loss: 0.8351617601453042, Training Accuracy: 75.38\n",
            "Validation Loss: 1.925265645980835, Validation Accuracy: 54.65\n",
            "[108/150]: Training Loss: 0.8257343720416633, Training Accuracy: 75.846\n",
            "Validation Loss: 1.9380712270736695, Validation Accuracy: 54.61\n",
            "[109/150]: Training Loss: 0.803754199524315, Training Accuracy: 76.216\n",
            "Validation Loss: 1.952760434150696, Validation Accuracy: 54.15\n",
            "[110/150]: Training Loss: 0.8017950021490758, Training Accuracy: 76.334\n",
            "Validation Loss: 1.938999843597412, Validation Accuracy: 54.87\n",
            "[111/150]: Training Loss: 0.7898118264821111, Training Accuracy: 76.776\n",
            "Validation Loss: 1.9549705505371093, Validation Accuracy: 54.67\n",
            "[112/150]: Training Loss: 0.7774463660862981, Training Accuracy: 76.952\n",
            "Validation Loss: 1.9725535273551942, Validation Accuracy: 54.17\n",
            "[113/150]: Training Loss: 0.7767588861134588, Training Accuracy: 76.824\n",
            "Validation Loss: 1.9652800679206848, Validation Accuracy: 54.49\n",
            "[114/150]: Training Loss: 0.7543022997525274, Training Accuracy: 77.61\n",
            "Validation Loss: 1.9479739904403686, Validation Accuracy: 54.85\n",
            "[115/150]: Training Loss: 0.7407014296979321, Training Accuracy: 78.064\n",
            "Validation Loss: 1.974105668067932, Validation Accuracy: 54.73\n",
            "[116/150]: Training Loss: 0.7379214763641357, Training Accuracy: 78.122\n",
            "Validation Loss: 1.9709696292877197, Validation Accuracy: 54.92\n",
            "[117/150]: Training Loss: 0.7280089295640284, Training Accuracy: 78.332\n",
            "Validation Loss: 1.9550812244415283, Validation Accuracy: 54.87\n",
            "[118/150]: Training Loss: 0.719780373330019, Training Accuracy: 78.916\n",
            "Validation Loss: 1.9715718150138855, Validation Accuracy: 54.88\n",
            "[119/150]: Training Loss: 0.7140980338563725, Training Accuracy: 78.938\n",
            "Validation Loss: 1.9744232773780823, Validation Accuracy: 54.88\n",
            "[120/150]: Training Loss: 0.7100381559255172, Training Accuracy: 79.112\n",
            "Validation Loss: 1.9600295305252076, Validation Accuracy: 55.01\n",
            "[121/150]: Training Loss: 0.695380872609664, Training Accuracy: 79.644\n",
            "Validation Loss: 1.9685936331748963, Validation Accuracy: 55.25\n",
            "[122/150]: Training Loss: 0.693044870483632, Training Accuracy: 79.566\n",
            "Validation Loss: 1.973974621295929, Validation Accuracy: 54.99\n",
            "[123/150]: Training Loss: 0.685412128360904, Training Accuracy: 79.762\n",
            "Validation Loss: 1.981511080265045, Validation Accuracy: 55.03\n",
            "[124/150]: Training Loss: 0.6729757055944326, Training Accuracy: 80.388\n",
            "Validation Loss: 1.9723920106887818, Validation Accuracy: 54.88\n",
            "[125/150]: Training Loss: 0.6728029567368177, Training Accuracy: 80.238\n",
            "Validation Loss: 1.972815704345703, Validation Accuracy: 55.06\n",
            "[126/150]: Training Loss: 0.6577607624384821, Training Accuracy: 80.906\n",
            "Validation Loss: 1.9941662311553956, Validation Accuracy: 55.01\n",
            "[127/150]: Training Loss: 0.6531734880135984, Training Accuracy: 80.798\n",
            "Validation Loss: 1.9830293536186219, Validation Accuracy: 55.29\n",
            "[128/150]: Training Loss: 0.6451807484334829, Training Accuracy: 80.998\n",
            "Validation Loss: 1.98456552028656, Validation Accuracy: 55.25\n",
            "[129/150]: Training Loss: 0.6361871045462939, Training Accuracy: 81.438\n",
            "Validation Loss: 1.991374099254608, Validation Accuracy: 55.33\n",
            "[130/150]: Training Loss: 0.6329771852006718, Training Accuracy: 81.326\n",
            "Validation Loss: 1.982979428768158, Validation Accuracy: 55.15\n",
            "[131/150]: Training Loss: 0.6337368731596031, Training Accuracy: 81.498\n",
            "Validation Loss: 1.9814332127571106, Validation Accuracy: 55.25\n",
            "[132/150]: Training Loss: 0.6237865613431347, Training Accuracy: 81.828\n",
            "Validation Loss: 1.9956311464309693, Validation Accuracy: 55.37\n",
            "[133/150]: Training Loss: 0.6184223087466493, Training Accuracy: 81.804\n",
            "Validation Loss: 1.997809612751007, Validation Accuracy: 55.31\n",
            "[134/150]: Training Loss: 0.6162658759525844, Training Accuracy: 82.05\n",
            "Validation Loss: 1.9944164514541627, Validation Accuracy: 55.37\n",
            "[135/150]: Training Loss: 0.6049274242654139, Training Accuracy: 82.308\n",
            "Validation Loss: 2.0007421493530275, Validation Accuracy: 55.18\n",
            "[136/150]: Training Loss: 0.6065428415123297, Training Accuracy: 82.346\n",
            "Validation Loss: 2.002026319503784, Validation Accuracy: 55.35\n",
            "[137/150]: Training Loss: 0.6054561515243686, Training Accuracy: 82.446\n",
            "Validation Loss: 2.0026141166687013, Validation Accuracy: 55.51\n",
            "[138/150]: Training Loss: 0.6016628170499996, Training Accuracy: 82.674\n",
            "Validation Loss: 1.9972286820411682, Validation Accuracy: 55.54\n",
            "[139/150]: Training Loss: 0.599141927397981, Training Accuracy: 82.822\n",
            "Validation Loss: 1.9984585762023925, Validation Accuracy: 55.21\n",
            "[140/150]: Training Loss: 0.5853999877462581, Training Accuracy: 82.924\n",
            "Validation Loss: 2.0003657698631288, Validation Accuracy: 55.39\n",
            "[141/150]: Training Loss: 0.5930902678139356, Training Accuracy: 82.696\n",
            "Validation Loss: 1.9994045495986938, Validation Accuracy: 55.54\n",
            "[142/150]: Training Loss: 0.5897825044028613, Training Accuracy: 83.098\n",
            "Validation Loss: 2.0004444122314453, Validation Accuracy: 55.4\n",
            "[143/150]: Training Loss: 0.5907509253949536, Training Accuracy: 82.836\n",
            "Validation Loss: 1.9981922507286072, Validation Accuracy: 55.3\n",
            "[144/150]: Training Loss: 0.5838782507546094, Training Accuracy: 83.046\n",
            "Validation Loss: 1.9986275434494019, Validation Accuracy: 55.59\n",
            "[145/150]: Training Loss: 0.5819402069461589, Training Accuracy: 83.02\n",
            "Validation Loss: 2.0001697182655334, Validation Accuracy: 55.45\n",
            "[146/150]: Training Loss: 0.5872244786243049, Training Accuracy: 82.898\n",
            "Validation Loss: 2.000009226799011, Validation Accuracy: 55.41\n",
            "[147/150]: Training Loss: 0.5821643848808444, Training Accuracy: 83.186\n",
            "Validation Loss: 2.0006944298744203, Validation Accuracy: 55.35\n",
            "[148/150]: Training Loss: 0.5849178761852031, Training Accuracy: 83.14\n",
            "Validation Loss: 2.000812566280365, Validation Accuracy: 55.33\n",
            "[149/150]: Training Loss: 0.5800890168365167, Training Accuracy: 83.304\n",
            "Validation Loss: 2.000700604915619, Validation Accuracy: 55.4\n",
            "[150/150]: Training Loss: 0.5826626444349483, Training Accuracy: 83.206\n",
            "Validation Loss: 2.000621163845062, Validation Accuracy: 55.35\n",
            "**********************************************************************\n",
            "Test Loss: 2.000621163845062, Test Accuracy: 55.35\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>55.35</td></tr><tr><td>Test Loss</td><td>2.00062</td></tr><tr><td>Train Accuracy</td><td>83.206</td></tr><tr><td>Train Loss</td><td>0.58266</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=1024 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/w80ujlhs</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_014707-w80ujlhs/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 2048, Learning rate: 8.485281374238571, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_022321-j8jszxxs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">batch_size=2048 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.36701738357544, Training Accuracy: 3.886\n",
            "Validation Loss: 4.163058471679688, Validation Accuracy: 5.67\n",
            "[2/150]: Training Loss: 4.113679485321045, Training Accuracy: 6.492\n",
            "Validation Loss: 3.9081267356872558, Validation Accuracy: 9.58\n",
            "[3/150]: Training Loss: 3.8604202461242676, Training Accuracy: 10.016\n",
            "Validation Loss: 3.6436347484588625, Validation Accuracy: 14.06\n",
            "[4/150]: Training Loss: 3.7227595615386964, Training Accuracy: 12.524\n",
            "Validation Loss: 3.58444561958313, Validation Accuracy: 15.49\n",
            "[5/150]: Training Loss: 3.5834127140045164, Training Accuracy: 14.702\n",
            "Validation Loss: 3.4575596332550047, Validation Accuracy: 17.38\n",
            "[6/150]: Training Loss: 3.4569161987304686, Training Accuracy: 16.904\n",
            "Validation Loss: 3.262946367263794, Validation Accuracy: 20.16\n",
            "[7/150]: Training Loss: 3.3158952045440673, Training Accuracy: 19.406\n",
            "Validation Loss: 3.2002731800079345, Validation Accuracy: 22.26\n",
            "[8/150]: Training Loss: 3.1832161426544188, Training Accuracy: 22.068\n",
            "Validation Loss: 3.0290011405944823, Validation Accuracy: 24.81\n",
            "[9/150]: Training Loss: 3.185646390914917, Training Accuracy: 21.936\n",
            "Validation Loss: 3.1018139362335204, Validation Accuracy: 24.11\n",
            "[10/150]: Training Loss: 3.0637048053741456, Training Accuracy: 23.926\n",
            "Validation Loss: 2.9448835372924806, Validation Accuracy: 26.91\n",
            "[11/150]: Training Loss: 2.951322078704834, Training Accuracy: 26.03\n",
            "Validation Loss: 2.8756459236145018, Validation Accuracy: 27.94\n",
            "[12/150]: Training Loss: 2.9279331874847414, Training Accuracy: 26.79\n",
            "Validation Loss: 2.9318973541259767, Validation Accuracy: 27.51\n",
            "[13/150]: Training Loss: 2.828905839920044, Training Accuracy: 28.722\n",
            "Validation Loss: 2.634994125366211, Validation Accuracy: 33.35\n",
            "[14/150]: Training Loss: 2.8078646850585938, Training Accuracy: 29.266\n",
            "Validation Loss: 2.7456551074981688, Validation Accuracy: 30.56\n",
            "[15/150]: Training Loss: 2.712659044265747, Training Accuracy: 30.836\n",
            "Validation Loss: 2.5297746658325195, Validation Accuracy: 34.77\n",
            "[16/150]: Training Loss: 2.651611213684082, Training Accuracy: 32.136\n",
            "Validation Loss: 2.547566270828247, Validation Accuracy: 34.69\n",
            "[17/150]: Training Loss: 2.599648675918579, Training Accuracy: 33.174\n",
            "Validation Loss: 2.5292351245880127, Validation Accuracy: 34.72\n",
            "[18/150]: Training Loss: 2.577428216934204, Training Accuracy: 33.64\n",
            "Validation Loss: 2.5313771247863768, Validation Accuracy: 35.11\n",
            "[19/150]: Training Loss: 2.575561113357544, Training Accuracy: 33.86\n",
            "Validation Loss: 2.50340313911438, Validation Accuracy: 36.18\n",
            "[20/150]: Training Loss: 2.617272434234619, Training Accuracy: 32.958\n",
            "Validation Loss: 2.601680040359497, Validation Accuracy: 34.74\n",
            "[21/150]: Training Loss: 2.503620433807373, Training Accuracy: 35.3\n",
            "Validation Loss: 2.3930795192718506, Validation Accuracy: 38.69\n",
            "[22/150]: Training Loss: 2.4627874088287354, Training Accuracy: 36.662\n",
            "Validation Loss: 2.669213056564331, Validation Accuracy: 33.56\n",
            "[23/150]: Training Loss: 2.548478717803955, Training Accuracy: 34.642\n",
            "Validation Loss: 2.3424915313720702, Validation Accuracy: 39.2\n",
            "[24/150]: Training Loss: 2.3940266799926757, Training Accuracy: 37.736\n",
            "Validation Loss: 2.3067100048065186, Validation Accuracy: 39.53\n",
            "[25/150]: Training Loss: 2.3650291538238526, Training Accuracy: 38.102\n",
            "Validation Loss: 2.4807125091552735, Validation Accuracy: 36.63\n",
            "[26/150]: Training Loss: 2.3525609493255617, Training Accuracy: 38.382\n",
            "Validation Loss: 2.3692517280578613, Validation Accuracy: 39.11\n",
            "[27/150]: Training Loss: 2.2789812183380125, Training Accuracy: 40.074\n",
            "Validation Loss: 2.2349360942840577, Validation Accuracy: 41.75\n",
            "[28/150]: Training Loss: 2.2222459888458252, Training Accuracy: 40.97\n",
            "Validation Loss: 2.19801549911499, Validation Accuracy: 42.61\n",
            "[29/150]: Training Loss: 2.214301881790161, Training Accuracy: 41.694\n",
            "Validation Loss: 2.605668783187866, Validation Accuracy: 35.32\n",
            "[30/150]: Training Loss: 2.338454341888428, Training Accuracy: 38.786\n",
            "Validation Loss: 2.288765287399292, Validation Accuracy: 40.36\n",
            "[31/150]: Training Loss: 2.201904296875, Training Accuracy: 41.99\n",
            "Validation Loss: 2.205613946914673, Validation Accuracy: 42.56\n",
            "[32/150]: Training Loss: 2.1113436079025267, Training Accuracy: 43.934\n",
            "Validation Loss: 2.321266937255859, Validation Accuracy: 41.03\n",
            "[33/150]: Training Loss: 2.1466791677474975, Training Accuracy: 43.006\n",
            "Validation Loss: 2.1349957466125487, Validation Accuracy: 43.8\n",
            "[34/150]: Training Loss: 2.1290991640090944, Training Accuracy: 43.29\n",
            "Validation Loss: 2.217708683013916, Validation Accuracy: 42.79\n",
            "[35/150]: Training Loss: 2.0663461446762086, Training Accuracy: 44.68\n",
            "Validation Loss: 2.3302943229675295, Validation Accuracy: 40.26\n",
            "[36/150]: Training Loss: 2.0297911977767944, Training Accuracy: 45.408\n",
            "Validation Loss: 2.21708025932312, Validation Accuracy: 43.36\n",
            "[37/150]: Training Loss: 2.0129797410964967, Training Accuracy: 45.814\n",
            "Validation Loss: 2.0887409687042235, Validation Accuracy: 45.25\n",
            "[38/150]: Training Loss: 1.937804069519043, Training Accuracy: 47.634\n",
            "Validation Loss: 2.0723501682281493, Validation Accuracy: 45.71\n",
            "[39/150]: Training Loss: 1.943020739555359, Training Accuracy: 47.708\n",
            "Validation Loss: 2.0943463325500487, Validation Accuracy: 44.8\n",
            "[40/150]: Training Loss: 1.9138334608078003, Training Accuracy: 48.346\n",
            "Validation Loss: 2.2366223335266113, Validation Accuracy: 42.21\n",
            "[41/150]: Training Loss: 1.9987104320526123, Training Accuracy: 46.376\n",
            "Validation Loss: 2.12234206199646, Validation Accuracy: 45.35\n",
            "[42/150]: Training Loss: 1.9329777145385743, Training Accuracy: 47.608\n",
            "Validation Loss: 2.097510814666748, Validation Accuracy: 45.23\n",
            "[43/150]: Training Loss: 1.9182713079452514, Training Accuracy: 47.922\n",
            "Validation Loss: 2.085854196548462, Validation Accuracy: 45.54\n",
            "[44/150]: Training Loss: 1.900009379386902, Training Accuracy: 48.732\n",
            "Validation Loss: 2.051387619972229, Validation Accuracy: 46.24\n",
            "[45/150]: Training Loss: 1.8408135080337524, Training Accuracy: 49.714\n",
            "Validation Loss: 2.0023281574249268, Validation Accuracy: 47.57\n",
            "[46/150]: Training Loss: 1.785364203453064, Training Accuracy: 51.326\n",
            "Validation Loss: 2.049905252456665, Validation Accuracy: 46.49\n",
            "[47/150]: Training Loss: 1.8102792501449585, Training Accuracy: 50.858\n",
            "Validation Loss: 2.0309868812561036, Validation Accuracy: 46.64\n",
            "[48/150]: Training Loss: 1.7956236791610718, Training Accuracy: 50.794\n",
            "Validation Loss: 2.0011850118637087, Validation Accuracy: 47.81\n",
            "[49/150]: Training Loss: 1.7439770412445068, Training Accuracy: 52.0\n",
            "Validation Loss: 1.9770531415939332, Validation Accuracy: 48.07\n",
            "[50/150]: Training Loss: 1.7183953332901, Training Accuracy: 52.358\n",
            "Validation Loss: 2.0561673641204834, Validation Accuracy: 46.4\n",
            "[51/150]: Training Loss: 1.717338604927063, Training Accuracy: 53.112\n",
            "Validation Loss: 1.9954840183258056, Validation Accuracy: 47.55\n",
            "[52/150]: Training Loss: 1.7013448238372804, Training Accuracy: 53.098\n",
            "Validation Loss: 2.0024028778076173, Validation Accuracy: 47.72\n",
            "[53/150]: Training Loss: 1.7069044065475465, Training Accuracy: 53.0\n",
            "Validation Loss: 2.08711462020874, Validation Accuracy: 45.49\n",
            "[54/150]: Training Loss: 1.6761716079711915, Training Accuracy: 53.252\n",
            "Validation Loss: 1.9557607173919678, Validation Accuracy: 49.03\n",
            "[55/150]: Training Loss: 1.6440558958053588, Training Accuracy: 54.564\n",
            "Validation Loss: 1.9891844987869263, Validation Accuracy: 48.39\n",
            "[56/150]: Training Loss: 1.6161942625045775, Training Accuracy: 54.926\n",
            "Validation Loss: 2.029493975639343, Validation Accuracy: 47.58\n",
            "[57/150]: Training Loss: 1.6047872447967528, Training Accuracy: 55.192\n",
            "Validation Loss: 1.967372179031372, Validation Accuracy: 48.91\n",
            "[58/150]: Training Loss: 1.713731393814087, Training Accuracy: 52.926\n",
            "Validation Loss: 2.0652761220932008, Validation Accuracy: 46.68\n",
            "[59/150]: Training Loss: 1.6507894086837769, Training Accuracy: 54.226\n",
            "Validation Loss: 1.9929080486297608, Validation Accuracy: 48.66\n",
            "[60/150]: Training Loss: 1.6021452569961547, Training Accuracy: 55.432\n",
            "Validation Loss: 1.9558722257614136, Validation Accuracy: 49.28\n",
            "[61/150]: Training Loss: 1.543088173866272, Training Accuracy: 56.656\n",
            "Validation Loss: 1.9447553634643555, Validation Accuracy: 49.2\n",
            "[62/150]: Training Loss: 1.5494691371917724, Training Accuracy: 56.864\n",
            "Validation Loss: 1.885341501235962, Validation Accuracy: 50.76\n",
            "[63/150]: Training Loss: 1.4937063312530519, Training Accuracy: 58.158\n",
            "Validation Loss: 1.9500130414962769, Validation Accuracy: 49.94\n",
            "[64/150]: Training Loss: 1.4539641427993775, Training Accuracy: 59.004\n",
            "Validation Loss: 1.9285942554473876, Validation Accuracy: 49.98\n",
            "[65/150]: Training Loss: 1.4972302389144898, Training Accuracy: 57.904\n",
            "Validation Loss: 1.9630061149597169, Validation Accuracy: 49.26\n",
            "[66/150]: Training Loss: 1.518665623664856, Training Accuracy: 57.152\n",
            "Validation Loss: 1.9333840608596802, Validation Accuracy: 50.24\n",
            "[67/150]: Training Loss: 1.5036478281021117, Training Accuracy: 57.512\n",
            "Validation Loss: 1.961331272125244, Validation Accuracy: 50.09\n",
            "[68/150]: Training Loss: 1.4539181280136109, Training Accuracy: 59.142\n",
            "Validation Loss: 1.9611144304275512, Validation Accuracy: 49.25\n",
            "[69/150]: Training Loss: 1.46078604221344, Training Accuracy: 58.794\n",
            "Validation Loss: 1.916247057914734, Validation Accuracy: 50.02\n",
            "[70/150]: Training Loss: 1.4112844705581664, Training Accuracy: 59.934\n",
            "Validation Loss: 1.8900265216827392, Validation Accuracy: 51.2\n",
            "[71/150]: Training Loss: 1.3915088891983032, Training Accuracy: 60.376\n",
            "Validation Loss: 1.9043931245803833, Validation Accuracy: 50.87\n",
            "[72/150]: Training Loss: 1.3921622323989868, Training Accuracy: 60.564\n",
            "Validation Loss: 1.9693795204162599, Validation Accuracy: 50.0\n",
            "[73/150]: Training Loss: 1.3862884998321534, Training Accuracy: 60.752\n",
            "Validation Loss: 1.9339972734451294, Validation Accuracy: 50.94\n",
            "[74/150]: Training Loss: 1.358318910598755, Training Accuracy: 61.528\n",
            "Validation Loss: 1.9029748439788818, Validation Accuracy: 51.01\n",
            "[75/150]: Training Loss: 1.3378327751159669, Training Accuracy: 61.9\n",
            "Validation Loss: 1.9114508390426637, Validation Accuracy: 51.04\n",
            "[76/150]: Training Loss: 1.307257251739502, Training Accuracy: 62.684\n",
            "Validation Loss: 1.897865653038025, Validation Accuracy: 51.33\n",
            "[77/150]: Training Loss: 1.307571873664856, Training Accuracy: 62.566\n",
            "Validation Loss: 1.9430776834487915, Validation Accuracy: 50.79\n",
            "[78/150]: Training Loss: 1.2927326250076294, Training Accuracy: 62.904\n",
            "Validation Loss: 1.910500168800354, Validation Accuracy: 52.01\n",
            "[79/150]: Training Loss: 1.2737730932235718, Training Accuracy: 63.4\n",
            "Validation Loss: 1.8831387996673583, Validation Accuracy: 52.08\n",
            "[80/150]: Training Loss: 1.254057068824768, Training Accuracy: 64.394\n",
            "Validation Loss: 1.8864023208618164, Validation Accuracy: 51.51\n",
            "[81/150]: Training Loss: 1.2196114826202393, Training Accuracy: 64.948\n",
            "Validation Loss: 1.9068121194839478, Validation Accuracy: 51.97\n",
            "[82/150]: Training Loss: 1.2375918960571288, Training Accuracy: 64.48\n",
            "Validation Loss: 1.9304296493530273, Validation Accuracy: 51.61\n",
            "[83/150]: Training Loss: 1.2156933164596557, Training Accuracy: 64.806\n",
            "Validation Loss: 1.9103889226913453, Validation Accuracy: 51.82\n",
            "[84/150]: Training Loss: 1.1918401718139648, Training Accuracy: 65.572\n",
            "Validation Loss: 1.9341503858566285, Validation Accuracy: 51.6\n",
            "[85/150]: Training Loss: 1.2064945554733277, Training Accuracy: 65.146\n",
            "Validation Loss: 1.9983864784240724, Validation Accuracy: 50.34\n",
            "[86/150]: Training Loss: 1.201401376724243, Training Accuracy: 65.426\n",
            "Validation Loss: 1.9176611185073853, Validation Accuracy: 51.45\n",
            "[87/150]: Training Loss: 1.1660136127471923, Training Accuracy: 66.176\n",
            "Validation Loss: 1.943800139427185, Validation Accuracy: 51.49\n",
            "[88/150]: Training Loss: 1.1312262058258056, Training Accuracy: 67.438\n",
            "Validation Loss: 1.9152551412582397, Validation Accuracy: 51.68\n",
            "[89/150]: Training Loss: 1.1454276323318482, Training Accuracy: 66.958\n",
            "Validation Loss: 1.9066155195236205, Validation Accuracy: 52.43\n",
            "[90/150]: Training Loss: 1.1536525392532349, Training Accuracy: 66.622\n",
            "Validation Loss: 1.912238073348999, Validation Accuracy: 51.99\n",
            "[91/150]: Training Loss: 1.1152591037750244, Training Accuracy: 67.662\n",
            "Validation Loss: 1.9254616022109985, Validation Accuracy: 52.11\n",
            "[92/150]: Training Loss: 1.0796469306945802, Training Accuracy: 68.538\n",
            "Validation Loss: 1.918501377105713, Validation Accuracy: 52.25\n",
            "[93/150]: Training Loss: 1.0836839008331298, Training Accuracy: 68.43\n",
            "Validation Loss: 1.9036231279373168, Validation Accuracy: 52.52\n",
            "[94/150]: Training Loss: 1.111613211631775, Training Accuracy: 67.66\n",
            "Validation Loss: 1.9749577283859252, Validation Accuracy: 51.0\n",
            "[95/150]: Training Loss: 1.1183206748962402, Training Accuracy: 67.53\n",
            "Validation Loss: 1.9319661378860473, Validation Accuracy: 52.53\n",
            "[96/150]: Training Loss: 1.0428566884994508, Training Accuracy: 69.502\n",
            "Validation Loss: 1.9246442794799805, Validation Accuracy: 52.17\n",
            "[97/150]: Training Loss: 1.029050705432892, Training Accuracy: 70.002\n",
            "Validation Loss: 1.9244839429855347, Validation Accuracy: 52.21\n",
            "[98/150]: Training Loss: 1.0212417674064636, Training Accuracy: 70.272\n",
            "Validation Loss: 1.9145327806472778, Validation Accuracy: 52.78\n",
            "[99/150]: Training Loss: 1.0124672603607179, Training Accuracy: 70.44\n",
            "Validation Loss: 1.9107223749160767, Validation Accuracy: 53.04\n",
            "[100/150]: Training Loss: 0.9880559778213501, Training Accuracy: 71.17\n",
            "Validation Loss: 1.9347419500350953, Validation Accuracy: 52.57\n",
            "[101/150]: Training Loss: 0.9812371230125427, Training Accuracy: 71.144\n",
            "Validation Loss: 1.9186458826065063, Validation Accuracy: 53.22\n",
            "[102/150]: Training Loss: 0.9656218528747559, Training Accuracy: 72.014\n",
            "Validation Loss: 1.9120693922042846, Validation Accuracy: 53.07\n",
            "[103/150]: Training Loss: 0.9567889213562012, Training Accuracy: 71.89\n",
            "Validation Loss: 1.9197413206100464, Validation Accuracy: 52.84\n",
            "[104/150]: Training Loss: 0.9529655456542969, Training Accuracy: 72.086\n",
            "Validation Loss: 1.9144711256027223, Validation Accuracy: 53.0\n",
            "[105/150]: Training Loss: 0.9852134394645691, Training Accuracy: 71.252\n",
            "Validation Loss: 1.9319961071014404, Validation Accuracy: 53.06\n",
            "[106/150]: Training Loss: 0.9273789191246032, Training Accuracy: 72.91\n",
            "Validation Loss: 1.9424444437026978, Validation Accuracy: 52.84\n",
            "[107/150]: Training Loss: 0.9234069514274598, Training Accuracy: 73.084\n",
            "Validation Loss: 1.9234145641326905, Validation Accuracy: 52.94\n",
            "[108/150]: Training Loss: 0.9229924130439758, Training Accuracy: 73.21\n",
            "Validation Loss: 1.9324826002120972, Validation Accuracy: 52.73\n",
            "[109/150]: Training Loss: 0.9058748340606689, Training Accuracy: 73.67\n",
            "Validation Loss: 1.9500421285629272, Validation Accuracy: 53.29\n",
            "[110/150]: Training Loss: 0.8911954641342164, Training Accuracy: 73.872\n",
            "Validation Loss: 1.941013789176941, Validation Accuracy: 53.28\n",
            "[111/150]: Training Loss: 0.8825567650794983, Training Accuracy: 74.012\n",
            "Validation Loss: 1.9361898183822632, Validation Accuracy: 53.09\n",
            "[112/150]: Training Loss: 0.8620765686035157, Training Accuracy: 74.656\n",
            "Validation Loss: 1.9341821908950805, Validation Accuracy: 53.36\n",
            "[113/150]: Training Loss: 0.8601221704483032, Training Accuracy: 74.8\n",
            "Validation Loss: 1.9615466117858886, Validation Accuracy: 53.34\n",
            "[114/150]: Training Loss: 0.8472113418579101, Training Accuracy: 75.216\n",
            "Validation Loss: 1.950052309036255, Validation Accuracy: 53.42\n",
            "[115/150]: Training Loss: 0.84150705575943, Training Accuracy: 75.34\n",
            "Validation Loss: 1.9719900608062744, Validation Accuracy: 53.33\n",
            "[116/150]: Training Loss: 0.8295826292037964, Training Accuracy: 75.764\n",
            "Validation Loss: 1.9504849910736084, Validation Accuracy: 53.65\n",
            "[117/150]: Training Loss: 0.8204774522781372, Training Accuracy: 76.024\n",
            "Validation Loss: 1.9509764194488526, Validation Accuracy: 54.02\n",
            "[118/150]: Training Loss: 0.8103749394416809, Training Accuracy: 76.418\n",
            "Validation Loss: 1.9664921760559082, Validation Accuracy: 53.3\n",
            "[119/150]: Training Loss: 0.8074698400497436, Training Accuracy: 76.44\n",
            "Validation Loss: 1.955758023262024, Validation Accuracy: 53.71\n",
            "[120/150]: Training Loss: 0.8068988251686097, Training Accuracy: 76.406\n",
            "Validation Loss: 1.9637468814849854, Validation Accuracy: 53.55\n",
            "[121/150]: Training Loss: 0.7903911852836609, Training Accuracy: 76.678\n",
            "Validation Loss: 1.9706329584121705, Validation Accuracy: 53.57\n",
            "[122/150]: Training Loss: 0.7799955105781555, Training Accuracy: 77.276\n",
            "Validation Loss: 1.976036286354065, Validation Accuracy: 53.7\n",
            "[123/150]: Training Loss: 0.7765986251831055, Training Accuracy: 77.324\n",
            "Validation Loss: 1.9730368375778198, Validation Accuracy: 53.3\n",
            "[124/150]: Training Loss: 0.7681253123283386, Training Accuracy: 77.54\n",
            "Validation Loss: 1.9741400957107544, Validation Accuracy: 53.63\n",
            "[125/150]: Training Loss: 0.7622663331031799, Training Accuracy: 77.518\n",
            "Validation Loss: 1.9705329179763793, Validation Accuracy: 54.09\n",
            "[126/150]: Training Loss: 0.7574337005615235, Training Accuracy: 78.034\n",
            "Validation Loss: 1.9730172395706176, Validation Accuracy: 53.71\n",
            "[127/150]: Training Loss: 0.7504327082633973, Training Accuracy: 78.258\n",
            "Validation Loss: 1.9689469575881957, Validation Accuracy: 53.87\n",
            "[128/150]: Training Loss: 0.7432142400741577, Training Accuracy: 78.082\n",
            "Validation Loss: 1.9787657976150512, Validation Accuracy: 53.54\n",
            "[129/150]: Training Loss: 0.7408276867866516, Training Accuracy: 78.396\n",
            "Validation Loss: 1.9802783012390137, Validation Accuracy: 53.89\n",
            "[130/150]: Training Loss: 0.7272537612915039, Training Accuracy: 78.856\n",
            "Validation Loss: 1.9677628517150878, Validation Accuracy: 53.76\n",
            "[131/150]: Training Loss: 0.7158604049682618, Training Accuracy: 78.946\n",
            "Validation Loss: 1.97785542011261, Validation Accuracy: 53.9\n",
            "[132/150]: Training Loss: 0.7163805866241455, Training Accuracy: 79.138\n",
            "Validation Loss: 1.976898455619812, Validation Accuracy: 53.7\n",
            "[133/150]: Training Loss: 0.721850438117981, Training Accuracy: 78.816\n",
            "Validation Loss: 1.9874832153320312, Validation Accuracy: 53.66\n",
            "[134/150]: Training Loss: 0.719142906665802, Training Accuracy: 79.046\n",
            "Validation Loss: 1.9858264207839966, Validation Accuracy: 53.92\n",
            "[135/150]: Training Loss: 0.7152685523033142, Training Accuracy: 79.11\n",
            "Validation Loss: 1.9745909452438355, Validation Accuracy: 53.99\n",
            "[136/150]: Training Loss: 0.7077970743179322, Training Accuracy: 79.564\n",
            "Validation Loss: 1.9791152715682983, Validation Accuracy: 53.54\n",
            "[137/150]: Training Loss: 0.7019647455215454, Training Accuracy: 79.626\n",
            "Validation Loss: 1.9777050018310547, Validation Accuracy: 54.06\n",
            "[138/150]: Training Loss: 0.6962298607826233, Training Accuracy: 79.744\n",
            "Validation Loss: 1.9783851623535156, Validation Accuracy: 53.9\n",
            "[139/150]: Training Loss: 0.6945947551727295, Training Accuracy: 79.802\n",
            "Validation Loss: 1.9834458827972412, Validation Accuracy: 53.84\n",
            "[140/150]: Training Loss: 0.6916244769096375, Training Accuracy: 79.876\n",
            "Validation Loss: 1.9782796621322631, Validation Accuracy: 54.08\n",
            "[141/150]: Training Loss: 0.686495201587677, Training Accuracy: 80.022\n",
            "Validation Loss: 1.9823485612869263, Validation Accuracy: 54.07\n",
            "[142/150]: Training Loss: 0.6907814073562623, Training Accuracy: 80.056\n",
            "Validation Loss: 1.9827837467193603, Validation Accuracy: 53.98\n",
            "[143/150]: Training Loss: 0.6871487998962402, Training Accuracy: 80.084\n",
            "Validation Loss: 1.9844423055648803, Validation Accuracy: 54.1\n",
            "[144/150]: Training Loss: 0.6854921150207519, Training Accuracy: 80.314\n",
            "Validation Loss: 1.9852968454360962, Validation Accuracy: 53.98\n",
            "[145/150]: Training Loss: 0.6804221367835999, Training Accuracy: 80.244\n",
            "Validation Loss: 1.9844240427017212, Validation Accuracy: 54.1\n",
            "[146/150]: Training Loss: 0.682576208114624, Training Accuracy: 80.136\n",
            "Validation Loss: 1.9841588735580444, Validation Accuracy: 54.07\n",
            "[147/150]: Training Loss: 0.6786355781555176, Training Accuracy: 80.254\n",
            "Validation Loss: 1.9839539051055908, Validation Accuracy: 54.12\n",
            "[148/150]: Training Loss: 0.6753697633743286, Training Accuracy: 80.27\n",
            "Validation Loss: 1.9842885971069335, Validation Accuracy: 54.16\n",
            "[149/150]: Training Loss: 0.6753653740882873, Training Accuracy: 80.488\n",
            "Validation Loss: 1.9842547655105591, Validation Accuracy: 54.12\n",
            "[150/150]: Training Loss: 0.6740122199058532, Training Accuracy: 80.532\n",
            "Validation Loss: 1.984296441078186, Validation Accuracy: 54.15\n",
            "**********************************************************************\n",
            "Test Loss: 1.984296441078186, Test Accuracy: 54.15\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>54.15</td></tr><tr><td>Test Loss</td><td>1.9843</td></tr><tr><td>Train Accuracy</td><td>80.532</td></tr><tr><td>Train Loss</td><td>0.67401</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=2048 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/j8jszxxs</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_022321-j8jszxxs/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 4096, Learning rate: 12.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_024410-fcrci1zx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">batch_size=4096 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.448218419001653, Training Accuracy: 3.104\n",
            "Validation Loss: 4.19553820292155, Validation Accuracy: 5.83\n",
            "[2/150]: Training Loss: 4.162900081047645, Training Accuracy: 5.992\n",
            "Validation Loss: 4.001244783401489, Validation Accuracy: 8.19\n",
            "[3/150]: Training Loss: 3.9526728116548977, Training Accuracy: 9.02\n",
            "Validation Loss: 3.849735975265503, Validation Accuracy: 10.99\n",
            "[4/150]: Training Loss: 3.9088880098783054, Training Accuracy: 9.748\n",
            "Validation Loss: 3.7720150152842202, Validation Accuracy: 11.82\n",
            "[5/150]: Training Loss: 3.7579474999354434, Training Accuracy: 11.674\n",
            "Validation Loss: 3.6346964836120605, Validation Accuracy: 13.58\n",
            "[6/150]: Training Loss: 3.8317384169651914, Training Accuracy: 10.848\n",
            "Validation Loss: 3.6928911209106445, Validation Accuracy: 13.8\n",
            "[7/150]: Training Loss: 3.6279670825371375, Training Accuracy: 13.764\n",
            "Validation Loss: 3.426232655843099, Validation Accuracy: 17.9\n",
            "[8/150]: Training Loss: 3.559702047934899, Training Accuracy: 15.198\n",
            "Validation Loss: 3.5184563795725503, Validation Accuracy: 15.74\n",
            "[9/150]: Training Loss: 3.619346306874202, Training Accuracy: 14.12\n",
            "Validation Loss: 3.4724766413370767, Validation Accuracy: 16.53\n",
            "[10/150]: Training Loss: 3.4825954070458045, Training Accuracy: 16.518\n",
            "Validation Loss: 3.491668939590454, Validation Accuracy: 17.05\n",
            "[11/150]: Training Loss: 3.5322888447688174, Training Accuracy: 15.738\n",
            "Validation Loss: 3.3563063939412436, Validation Accuracy: 18.53\n",
            "[12/150]: Training Loss: 3.381067386040321, Training Accuracy: 18.274\n",
            "Validation Loss: 3.371330420176188, Validation Accuracy: 18.51\n",
            "[13/150]: Training Loss: 3.3759262011601376, Training Accuracy: 18.364\n",
            "Validation Loss: 3.1718979676564536, Validation Accuracy: 22.38\n",
            "[14/150]: Training Loss: 3.24786586027879, Training Accuracy: 20.88\n",
            "Validation Loss: 3.149214585622152, Validation Accuracy: 22.67\n",
            "[15/150]: Training Loss: 3.155352940926185, Training Accuracy: 22.24\n",
            "Validation Loss: 2.999330917994181, Validation Accuracy: 25.44\n",
            "[16/150]: Training Loss: 2.9997272124657264, Training Accuracy: 25.252\n",
            "Validation Loss: 2.8626222610473633, Validation Accuracy: 28.18\n",
            "[17/150]: Training Loss: 2.952247326190655, Training Accuracy: 26.39\n",
            "Validation Loss: 3.0151708920796714, Validation Accuracy: 25.48\n",
            "[18/150]: Training Loss: 3.035908350577721, Training Accuracy: 24.716\n",
            "Validation Loss: 2.84928830464681, Validation Accuracy: 28.54\n",
            "[19/150]: Training Loss: 2.8744187355041504, Training Accuracy: 27.56\n",
            "Validation Loss: 2.732924222946167, Validation Accuracy: 30.87\n",
            "[20/150]: Training Loss: 2.7774770443256083, Training Accuracy: 29.672\n",
            "Validation Loss: 2.800260861714681, Validation Accuracy: 29.69\n",
            "[21/150]: Training Loss: 2.9696661142202525, Training Accuracy: 26.582\n",
            "Validation Loss: 3.213308095932007, Validation Accuracy: 22.23\n",
            "[22/150]: Training Loss: 3.2055968137887807, Training Accuracy: 22.87\n",
            "Validation Loss: 3.0360422134399414, Validation Accuracy: 25.56\n",
            "[23/150]: Training Loss: 3.0269867456876316, Training Accuracy: 25.102\n",
            "Validation Loss: 2.861661911010742, Validation Accuracy: 29.24\n",
            "[24/150]: Training Loss: 2.8519647121429443, Training Accuracy: 28.248\n",
            "Validation Loss: 2.682717482248942, Validation Accuracy: 31.6\n",
            "[25/150]: Training Loss: 2.705435276031494, Training Accuracy: 31.156\n",
            "Validation Loss: 2.509896198908488, Validation Accuracy: 35.11\n",
            "[26/150]: Training Loss: 2.613956708174485, Training Accuracy: 33.41\n",
            "Validation Loss: 2.505950371424357, Validation Accuracy: 34.77\n",
            "[27/150]: Training Loss: 3.002190589904785, Training Accuracy: 26.466\n",
            "Validation Loss: 2.775864839553833, Validation Accuracy: 29.88\n",
            "[28/150]: Training Loss: 2.742469017322247, Training Accuracy: 30.316\n",
            "Validation Loss: 2.589009443918864, Validation Accuracy: 33.99\n",
            "[29/150]: Training Loss: 2.8341226394359884, Training Accuracy: 29.282\n",
            "Validation Loss: 2.8079089323679605, Validation Accuracy: 29.56\n",
            "[30/150]: Training Loss: 2.745966214400071, Training Accuracy: 30.384\n",
            "Validation Loss: 2.5663379033406577, Validation Accuracy: 34.18\n",
            "[31/150]: Training Loss: 2.5754335476801944, Training Accuracy: 33.944\n",
            "Validation Loss: 2.4243160088857016, Validation Accuracy: 37.33\n",
            "[32/150]: Training Loss: 2.4728290117703953, Training Accuracy: 35.998\n",
            "Validation Loss: 2.4164366722106934, Validation Accuracy: 37.02\n",
            "[33/150]: Training Loss: 2.550288127018855, Training Accuracy: 34.558\n",
            "Validation Loss: 2.4929703871409097, Validation Accuracy: 35.7\n",
            "[34/150]: Training Loss: 2.5172606064723086, Training Accuracy: 35.468\n",
            "Validation Loss: 2.5022354125976562, Validation Accuracy: 35.92\n",
            "[35/150]: Training Loss: 2.5095452528733473, Training Accuracy: 35.052\n",
            "Validation Loss: 2.3538503646850586, Validation Accuracy: 38.43\n",
            "[36/150]: Training Loss: 2.595434335561899, Training Accuracy: 34.342\n",
            "Validation Loss: 2.7459415594736734, Validation Accuracy: 30.95\n",
            "[37/150]: Training Loss: 2.5996641562535214, Training Accuracy: 33.51\n",
            "Validation Loss: 2.4413878122965493, Validation Accuracy: 37.55\n",
            "[38/150]: Training Loss: 2.4308731005742, Training Accuracy: 36.788\n",
            "Validation Loss: 2.3517263730367026, Validation Accuracy: 38.8\n",
            "[39/150]: Training Loss: 2.3385920707996073, Training Accuracy: 39.318\n",
            "Validation Loss: 2.4507851600646973, Validation Accuracy: 37.58\n",
            "[40/150]: Training Loss: 2.4006691529200626, Training Accuracy: 37.842\n",
            "Validation Loss: 2.3381757736206055, Validation Accuracy: 39.0\n",
            "[41/150]: Training Loss: 2.4301048792325535, Training Accuracy: 36.898\n",
            "Validation Loss: 2.3649702866872153, Validation Accuracy: 38.64\n",
            "[42/150]: Training Loss: 2.282798070173997, Training Accuracy: 39.856\n",
            "Validation Loss: 2.2728551228841147, Validation Accuracy: 40.36\n",
            "[43/150]: Training Loss: 2.235896715751061, Training Accuracy: 40.962\n",
            "Validation Loss: 2.2269629637400308, Validation Accuracy: 41.47\n",
            "[44/150]: Training Loss: 2.277051045344426, Training Accuracy: 40.666\n",
            "Validation Loss: 2.393709977467855, Validation Accuracy: 38.68\n",
            "[45/150]: Training Loss: 2.266980061164269, Training Accuracy: 40.186\n",
            "Validation Loss: 2.260339101155599, Validation Accuracy: 41.24\n",
            "[46/150]: Training Loss: 2.2269545518434963, Training Accuracy: 41.5\n",
            "Validation Loss: 2.184856653213501, Validation Accuracy: 42.59\n",
            "[47/150]: Training Loss: 2.1506412762861986, Training Accuracy: 42.82\n",
            "Validation Loss: 2.151843468348185, Validation Accuracy: 43.6\n",
            "[48/150]: Training Loss: 2.0945023756760817, Training Accuracy: 45.142\n",
            "Validation Loss: 2.1851927439371743, Validation Accuracy: 42.94\n",
            "[49/150]: Training Loss: 2.368942279082078, Training Accuracy: 38.482\n",
            "Validation Loss: 2.311251401901245, Validation Accuracy: 39.8\n",
            "[50/150]: Training Loss: 2.1795968275803785, Training Accuracy: 42.274\n",
            "Validation Loss: 2.1368969281514487, Validation Accuracy: 43.53\n",
            "[51/150]: Training Loss: 2.287435614145719, Training Accuracy: 40.578\n",
            "Validation Loss: 2.3101561864217124, Validation Accuracy: 40.31\n",
            "[52/150]: Training Loss: 2.133154667340792, Training Accuracy: 43.412\n",
            "Validation Loss: 2.101039091746012, Validation Accuracy: 44.48\n",
            "[53/150]: Training Loss: 2.009332299232483, Training Accuracy: 46.076\n",
            "Validation Loss: 2.053215821584066, Validation Accuracy: 46.02\n",
            "[54/150]: Training Loss: 2.0092475414276123, Training Accuracy: 46.312\n",
            "Validation Loss: 2.068614880243937, Validation Accuracy: 45.15\n",
            "[55/150]: Training Loss: 2.0747447105554433, Training Accuracy: 44.708\n",
            "Validation Loss: 2.0757156213124595, Validation Accuracy: 45.38\n",
            "[56/150]: Training Loss: 2.0832339341823873, Training Accuracy: 44.52\n",
            "Validation Loss: 2.2822861671447754, Validation Accuracy: 40.59\n",
            "[57/150]: Training Loss: 2.035889350450956, Training Accuracy: 45.234\n",
            "Validation Loss: 2.077279488245646, Validation Accuracy: 45.32\n",
            "[58/150]: Training Loss: 1.9101605140245879, Training Accuracy: 48.098\n",
            "Validation Loss: 2.075277328491211, Validation Accuracy: 45.52\n",
            "[59/150]: Training Loss: 1.930518700526311, Training Accuracy: 47.694\n",
            "Validation Loss: 2.0554560820261636, Validation Accuracy: 45.94\n",
            "[60/150]: Training Loss: 1.9262570784642146, Training Accuracy: 47.71\n",
            "Validation Loss: 1.9856750170389812, Validation Accuracy: 46.93\n",
            "[61/150]: Training Loss: 1.8526782714403593, Training Accuracy: 49.478\n",
            "Validation Loss: 1.9915226300557454, Validation Accuracy: 46.83\n",
            "[62/150]: Training Loss: 1.8636801151128917, Training Accuracy: 49.23\n",
            "Validation Loss: 2.094877322514852, Validation Accuracy: 45.09\n",
            "[63/150]: Training Loss: 1.8440089867665217, Training Accuracy: 49.998\n",
            "Validation Loss: 1.9725687503814697, Validation Accuracy: 47.58\n",
            "[64/150]: Training Loss: 1.8951456546783447, Training Accuracy: 48.798\n",
            "Validation Loss: 2.079833189646403, Validation Accuracy: 45.33\n",
            "[65/150]: Training Loss: 1.9134588700074415, Training Accuracy: 48.274\n",
            "Validation Loss: 2.0578166246414185, Validation Accuracy: 45.69\n",
            "[66/150]: Training Loss: 1.850765347480774, Training Accuracy: 49.748\n",
            "Validation Loss: 2.0475390752156577, Validation Accuracy: 47.14\n",
            "[67/150]: Training Loss: 1.7821540557421172, Training Accuracy: 51.288\n",
            "Validation Loss: 1.9497700134913127, Validation Accuracy: 48.19\n",
            "[68/150]: Training Loss: 1.7319823136696448, Training Accuracy: 52.606\n",
            "Validation Loss: 2.018282691637675, Validation Accuracy: 47.2\n",
            "[69/150]: Training Loss: 1.7186179894667406, Training Accuracy: 52.626\n",
            "Validation Loss: 1.9749605258305867, Validation Accuracy: 48.19\n",
            "[70/150]: Training Loss: 1.6911903069569514, Training Accuracy: 53.452\n",
            "Validation Loss: 1.9826482931772869, Validation Accuracy: 47.74\n",
            "[71/150]: Training Loss: 1.660032529097337, Training Accuracy: 54.11\n",
            "Validation Loss: 1.908194661140442, Validation Accuracy: 49.51\n",
            "[72/150]: Training Loss: 1.6769285110326915, Training Accuracy: 53.518\n",
            "Validation Loss: 1.954678734143575, Validation Accuracy: 48.03\n",
            "[73/150]: Training Loss: 1.6593820590239305, Training Accuracy: 53.96\n",
            "Validation Loss: 1.9272022247314453, Validation Accuracy: 48.63\n",
            "[74/150]: Training Loss: 1.6419056562276988, Training Accuracy: 54.992\n",
            "Validation Loss: 1.992493987083435, Validation Accuracy: 47.79\n",
            "[75/150]: Training Loss: 1.6689472198486328, Training Accuracy: 53.936\n",
            "Validation Loss: 1.9214499394098918, Validation Accuracy: 49.0\n",
            "[76/150]: Training Loss: 1.6087861702992365, Training Accuracy: 55.276\n",
            "Validation Loss: 1.896010160446167, Validation Accuracy: 49.84\n",
            "[77/150]: Training Loss: 1.5652516438410833, Training Accuracy: 56.72\n",
            "Validation Loss: 1.873304804166158, Validation Accuracy: 51.03\n",
            "[78/150]: Training Loss: 1.6746907876088069, Training Accuracy: 54.032\n",
            "Validation Loss: 1.954778750737508, Validation Accuracy: 49.08\n",
            "[79/150]: Training Loss: 1.5788640517454882, Training Accuracy: 55.932\n",
            "Validation Loss: 1.9272086222966511, Validation Accuracy: 50.3\n",
            "[80/150]: Training Loss: 1.6021267634171705, Training Accuracy: 55.644\n",
            "Validation Loss: 2.1279262701670327, Validation Accuracy: 45.34\n",
            "[81/150]: Training Loss: 1.7035195552385771, Training Accuracy: 53.114\n",
            "Validation Loss: 1.9278326431910198, Validation Accuracy: 49.04\n",
            "[82/150]: Training Loss: 1.559159095470722, Training Accuracy: 56.4\n",
            "Validation Loss: 1.9029817183812459, Validation Accuracy: 49.79\n",
            "[83/150]: Training Loss: 1.5267010835500865, Training Accuracy: 57.53\n",
            "Validation Loss: 1.9380817810694377, Validation Accuracy: 48.88\n",
            "[84/150]: Training Loss: 1.5102592706680298, Training Accuracy: 57.916\n",
            "Validation Loss: 1.8722127676010132, Validation Accuracy: 51.08\n",
            "[85/150]: Training Loss: 1.4807829398375292, Training Accuracy: 58.592\n",
            "Validation Loss: 1.9032895962397258, Validation Accuracy: 49.92\n",
            "[86/150]: Training Loss: 1.4740843681188731, Training Accuracy: 58.914\n",
            "Validation Loss: 1.8672935565312703, Validation Accuracy: 50.45\n",
            "[87/150]: Training Loss: 1.515398117212149, Training Accuracy: 57.934\n",
            "Validation Loss: 1.9412325620651245, Validation Accuracy: 49.15\n",
            "[88/150]: Training Loss: 1.576969366807204, Training Accuracy: 55.868\n",
            "Validation Loss: 1.935785969098409, Validation Accuracy: 49.25\n",
            "[89/150]: Training Loss: 1.4918665610826933, Training Accuracy: 58.11\n",
            "Validation Loss: 1.8986582358678181, Validation Accuracy: 51.05\n",
            "[90/150]: Training Loss: 1.4492073059082031, Training Accuracy: 59.446\n",
            "Validation Loss: 1.8367600440979004, Validation Accuracy: 51.57\n",
            "[91/150]: Training Loss: 1.4048503912412202, Training Accuracy: 60.418\n",
            "Validation Loss: 1.837977687517802, Validation Accuracy: 51.68\n",
            "[92/150]: Training Loss: 1.3744991559248705, Training Accuracy: 61.112\n",
            "Validation Loss: 1.8420219818751018, Validation Accuracy: 51.77\n",
            "[93/150]: Training Loss: 1.420577076765207, Training Accuracy: 60.392\n",
            "Validation Loss: 1.8663844267527263, Validation Accuracy: 51.21\n",
            "[94/150]: Training Loss: 1.4505155269916241, Training Accuracy: 59.012\n",
            "Validation Loss: 1.8934478759765625, Validation Accuracy: 50.84\n",
            "[95/150]: Training Loss: 1.4003274349065928, Training Accuracy: 60.672\n",
            "Validation Loss: 1.8551263411839802, Validation Accuracy: 51.69\n",
            "[96/150]: Training Loss: 1.3484498354104848, Training Accuracy: 61.974\n",
            "Validation Loss: 1.8562318483988445, Validation Accuracy: 51.96\n",
            "[97/150]: Training Loss: 1.314302426118117, Training Accuracy: 62.828\n",
            "Validation Loss: 1.8313268423080444, Validation Accuracy: 52.72\n",
            "[98/150]: Training Loss: 1.2976581683525672, Training Accuracy: 63.268\n",
            "Validation Loss: 1.8362118005752563, Validation Accuracy: 52.11\n",
            "[99/150]: Training Loss: 1.317265354670011, Training Accuracy: 62.994\n",
            "Validation Loss: 1.8350664774576824, Validation Accuracy: 52.02\n",
            "[100/150]: Training Loss: 1.2960394254097571, Training Accuracy: 63.262\n",
            "Validation Loss: 1.800865610440572, Validation Accuracy: 53.11\n",
            "[101/150]: Training Loss: 1.298880622937129, Training Accuracy: 62.896\n",
            "Validation Loss: 1.883919596672058, Validation Accuracy: 51.53\n",
            "[102/150]: Training Loss: 1.2974212628144484, Training Accuracy: 62.852\n",
            "Validation Loss: 1.8424270550409954, Validation Accuracy: 52.02\n",
            "[103/150]: Training Loss: 1.256823787322411, Training Accuracy: 63.952\n",
            "Validation Loss: 1.8408455053965251, Validation Accuracy: 52.54\n",
            "[104/150]: Training Loss: 1.252828497153062, Training Accuracy: 64.42\n",
            "Validation Loss: 1.8253253698349, Validation Accuracy: 52.37\n",
            "[105/150]: Training Loss: 1.2491283691846407, Training Accuracy: 64.358\n",
            "Validation Loss: 1.8558521668116252, Validation Accuracy: 52.17\n",
            "[106/150]: Training Loss: 1.229967685846182, Training Accuracy: 64.958\n",
            "Validation Loss: 1.8309193849563599, Validation Accuracy: 52.71\n",
            "[107/150]: Training Loss: 1.2172498794702382, Training Accuracy: 65.282\n",
            "Validation Loss: 1.8394190073013306, Validation Accuracy: 52.48\n",
            "[108/150]: Training Loss: 1.207243589254526, Training Accuracy: 65.544\n",
            "Validation Loss: 1.82985524336497, Validation Accuracy: 52.3\n",
            "[109/150]: Training Loss: 1.1976150732774, Training Accuracy: 65.54\n",
            "Validation Loss: 1.8410567442576091, Validation Accuracy: 52.6\n",
            "[110/150]: Training Loss: 1.1797684522775502, Training Accuracy: 66.22\n",
            "Validation Loss: 1.828009049097697, Validation Accuracy: 53.27\n",
            "[111/150]: Training Loss: 1.1586786141762366, Training Accuracy: 66.72\n",
            "Validation Loss: 1.8170452117919922, Validation Accuracy: 53.66\n",
            "[112/150]: Training Loss: 1.171253332724938, Training Accuracy: 66.59\n",
            "Validation Loss: 1.8729171355565388, Validation Accuracy: 52.55\n",
            "[113/150]: Training Loss: 1.2010775346022387, Training Accuracy: 65.75\n",
            "Validation Loss: 1.8387389580408733, Validation Accuracy: 53.17\n",
            "[114/150]: Training Loss: 1.1887562825129583, Training Accuracy: 66.114\n",
            "Validation Loss: 1.8573131561279297, Validation Accuracy: 52.59\n",
            "[115/150]: Training Loss: 1.1683265062478871, Training Accuracy: 66.588\n",
            "Validation Loss: 1.8474773168563843, Validation Accuracy: 53.17\n",
            "[116/150]: Training Loss: 1.1644465373112605, Training Accuracy: 66.768\n",
            "Validation Loss: 1.8591439326604207, Validation Accuracy: 52.41\n",
            "[117/150]: Training Loss: 1.1479460184390728, Training Accuracy: 67.308\n",
            "Validation Loss: 1.8460925817489624, Validation Accuracy: 53.29\n",
            "[118/150]: Training Loss: 1.1312938928604126, Training Accuracy: 67.496\n",
            "Validation Loss: 1.8282337188720703, Validation Accuracy: 53.62\n",
            "[119/150]: Training Loss: 1.1176557632593007, Training Accuracy: 68.078\n",
            "Validation Loss: 1.8184215625127156, Validation Accuracy: 53.58\n",
            "[120/150]: Training Loss: 1.1109853432728694, Training Accuracy: 68.212\n",
            "Validation Loss: 1.8269612789154053, Validation Accuracy: 53.4\n",
            "[121/150]: Training Loss: 1.092060116621164, Training Accuracy: 68.912\n",
            "Validation Loss: 1.8181384801864624, Validation Accuracy: 53.59\n",
            "[122/150]: Training Loss: 1.0812291502952576, Training Accuracy: 69.18\n",
            "Validation Loss: 1.8252775271733601, Validation Accuracy: 53.6\n",
            "[123/150]: Training Loss: 1.0699465458209698, Training Accuracy: 69.43\n",
            "Validation Loss: 1.834611177444458, Validation Accuracy: 54.01\n",
            "[124/150]: Training Loss: 1.0735741762014537, Training Accuracy: 69.112\n",
            "Validation Loss: 1.8203496138254802, Validation Accuracy: 53.93\n",
            "[125/150]: Training Loss: 1.0661220917334924, Training Accuracy: 69.538\n",
            "Validation Loss: 1.828150749206543, Validation Accuracy: 53.85\n",
            "[126/150]: Training Loss: 1.059658169746399, Training Accuracy: 69.666\n",
            "Validation Loss: 1.8271387418111165, Validation Accuracy: 53.8\n",
            "[127/150]: Training Loss: 1.0502580862778883, Training Accuracy: 70.108\n",
            "Validation Loss: 1.824654181798299, Validation Accuracy: 53.91\n",
            "[128/150]: Training Loss: 1.045825692323538, Training Accuracy: 69.762\n",
            "Validation Loss: 1.828839858373006, Validation Accuracy: 54.18\n",
            "[129/150]: Training Loss: 1.041814657358023, Training Accuracy: 70.04\n",
            "Validation Loss: 1.8183866739273071, Validation Accuracy: 53.89\n",
            "[130/150]: Training Loss: 1.0349373588195214, Training Accuracy: 70.334\n",
            "Validation Loss: 1.817612926165263, Validation Accuracy: 54.08\n",
            "[131/150]: Training Loss: 1.0304582439936125, Training Accuracy: 70.738\n",
            "Validation Loss: 1.8261488676071167, Validation Accuracy: 54.44\n",
            "[132/150]: Training Loss: 1.0328317513832679, Training Accuracy: 70.262\n",
            "Validation Loss: 1.8170503377914429, Validation Accuracy: 54.11\n",
            "[133/150]: Training Loss: 1.0127528584920442, Training Accuracy: 71.006\n",
            "Validation Loss: 1.823221206665039, Validation Accuracy: 54.24\n",
            "[134/150]: Training Loss: 1.0145881175994873, Training Accuracy: 70.876\n",
            "Validation Loss: 1.8177992900212605, Validation Accuracy: 54.42\n",
            "[135/150]: Training Loss: 1.0154722057856047, Training Accuracy: 70.856\n",
            "Validation Loss: 1.8151982227961223, Validation Accuracy: 54.36\n",
            "[136/150]: Training Loss: 1.0053791770568261, Training Accuracy: 70.962\n",
            "Validation Loss: 1.815675139427185, Validation Accuracy: 54.52\n",
            "[137/150]: Training Loss: 1.0002271212064302, Training Accuracy: 71.094\n",
            "Validation Loss: 1.8183471361796062, Validation Accuracy: 54.62\n",
            "[138/150]: Training Loss: 1.003823459148407, Training Accuracy: 71.112\n",
            "Validation Loss: 1.8167388836542766, Validation Accuracy: 54.32\n",
            "[139/150]: Training Loss: 1.0023488723314726, Training Accuracy: 71.28\n",
            "Validation Loss: 1.8161654869715373, Validation Accuracy: 54.5\n",
            "[140/150]: Training Loss: 0.996692391542288, Training Accuracy: 71.326\n",
            "Validation Loss: 1.8168489535649617, Validation Accuracy: 54.36\n",
            "[141/150]: Training Loss: 0.9932475502674396, Training Accuracy: 71.382\n",
            "Validation Loss: 1.8148254950841267, Validation Accuracy: 54.41\n",
            "[142/150]: Training Loss: 0.9950209443385785, Training Accuracy: 71.754\n",
            "Validation Loss: 1.8171526590983074, Validation Accuracy: 54.22\n",
            "[143/150]: Training Loss: 0.9949191717001108, Training Accuracy: 71.676\n",
            "Validation Loss: 1.8166076342264812, Validation Accuracy: 54.39\n",
            "[144/150]: Training Loss: 0.9898046300961421, Training Accuracy: 71.61\n",
            "Validation Loss: 1.8168938557306926, Validation Accuracy: 54.34\n",
            "[145/150]: Training Loss: 0.9879593665783222, Training Accuracy: 71.72\n",
            "Validation Loss: 1.8167452017466228, Validation Accuracy: 54.36\n",
            "[146/150]: Training Loss: 0.9881623249787551, Training Accuracy: 71.81\n",
            "Validation Loss: 1.8165217638015747, Validation Accuracy: 54.38\n",
            "[147/150]: Training Loss: 0.9901151886353126, Training Accuracy: 71.69\n",
            "Validation Loss: 1.81660795211792, Validation Accuracy: 54.48\n",
            "[148/150]: Training Loss: 0.9835631480583777, Training Accuracy: 71.944\n",
            "Validation Loss: 1.8168546358744304, Validation Accuracy: 54.43\n",
            "[149/150]: Training Loss: 0.9820910050318792, Training Accuracy: 72.082\n",
            "Validation Loss: 1.8165034850438435, Validation Accuracy: 54.45\n",
            "[150/150]: Training Loss: 0.9884678217080923, Training Accuracy: 71.694\n",
            "Validation Loss: 1.8165420691172283, Validation Accuracy: 54.48\n",
            "**********************************************************************\n",
            "Test Loss: 1.8165420691172283, Test Accuracy: 54.48\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>54.48</td></tr><tr><td>Test Loss</td><td>1.81654</td></tr><tr><td>Train Accuracy</td><td>71.694</td></tr><tr><td>Train Loss</td><td>0.98847</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=4096 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/fcrci1zx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_024410-fcrci1zx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 8192, Learning rate: 16.970562748477143, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_030841-573n6uz6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">batch_size=8192 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.543815356034499, Training Accuracy: 1.934\n",
            "Validation Loss: 4.557299613952637, Validation Accuracy: 4.11\n",
            "[2/150]: Training Loss: 4.4831575613755446, Training Accuracy: 3.478\n",
            "Validation Loss: 4.407679557800293, Validation Accuracy: 3.73\n",
            "[3/150]: Training Loss: 4.383443318880522, Training Accuracy: 4.272\n",
            "Validation Loss: 4.315660317738851, Validation Accuracy: 4.56\n",
            "[4/150]: Training Loss: 4.753879473759578, Training Accuracy: 2.854\n",
            "Validation Loss: 4.617130438486735, Validation Accuracy: 1.55\n",
            "[5/150]: Training Loss: 4.834007776700533, Training Accuracy: 1.152\n",
            "Validation Loss: 4.623517354329427, Validation Accuracy: 1.21\n",
            "[6/150]: Training Loss: 4.748236729548528, Training Accuracy: 1.046\n",
            "Validation Loss: 4.616909344991048, Validation Accuracy: 1.0\n",
            "[7/150]: Training Loss: 4.6143631201524, Training Accuracy: 1.022\n",
            "Validation Loss: 4.6133114496866865, Validation Accuracy: 0.95\n",
            "[8/150]: Training Loss: 86586261001215.23, Training Accuracy: 1.076\n",
            "Validation Loss: 199153685277354.66, Validation Accuracy: 1.08\n",
            "[9/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[11/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[12/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[13/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: inf, Training Accuracy: 1.0\n",
            "Validation Loss: inf, Validation Accuracy: 1.0\n",
            "[15/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[16/150]: Training Loss: inf, Training Accuracy: 1.004\n",
            "Validation Loss: inf, Validation Accuracy: 0.99\n",
            "[17/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[18/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[19/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[20/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[21/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[22/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[23/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[24/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[25/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[26/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[27/150]: Training Loss: inf, Training Accuracy: 0.998\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[28/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[29/150]: Training Loss: inf, Training Accuracy: 1.004\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[30/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[31/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[32/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: inf, Validation Accuracy: 1.02\n",
            "[33/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3707833002946235e+34, Validation Accuracy: 1.04\n",
            "[34/150]: Training Loss: 7.178876870446214e+34, Training Accuracy: 1.03\n",
            "Validation Loss: 6.908918765509594e+34, Validation Accuracy: 1.04\n",
            "[35/150]: Training Loss: 7.0300555279696e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 6.850623178707614e+34, Validation Accuracy: 1.04\n",
            "[36/150]: Training Loss: 7.161850738321898e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 6.997600003222513e+34, Validation Accuracy: 1.04\n",
            "[37/150]: Training Loss: 7.295138713909261e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.183176128279674e+34, Validation Accuracy: 1.04\n",
            "[38/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.320277327395843e+34, Validation Accuracy: 1.04\n",
            "[39/150]: Training Loss: 7.652232993118385e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.385754947129741e+34, Validation Accuracy: 1.04\n",
            "[40/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.395794805907017e+34, Validation Accuracy: 1.04\n",
            "[41/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.389329127611166e+34, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: 7.64618030431646e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.36814170130946e+34, Validation Accuracy: 1.04\n",
            "[43/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.351131744934992e+34, Validation Accuracy: 1.04\n",
            "[44/150]: Training Loss: inf, Training Accuracy: 1.026\n",
            "Validation Loss: 7.339262375838323e+34, Validation Accuracy: 1.04\n",
            "[45/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.334463460011365e+34, Validation Accuracy: 1.04\n",
            "[46/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.33473861281743e+34, Validation Accuracy: 1.04\n",
            "[47/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.342335768309189e+34, Validation Accuracy: 1.04\n",
            "[48/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343183509648092e+34, Validation Accuracy: 1.04\n",
            "[49/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.353242350172637e+34, Validation Accuracy: 1.04\n",
            "[50/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.35132750451987e+34, Validation Accuracy: 1.04\n",
            "[51/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.338507727590375e+34, Validation Accuracy: 1.04\n",
            "[52/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.345233868470492e+34, Validation Accuracy: 1.04\n",
            "[53/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.35075210998961e+34, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.35572186154199e+34, Validation Accuracy: 1.04\n",
            "[55/150]: Training Loss: 7.620612957278016e+34, Training Accuracy: 1.026\n",
            "Validation Loss: 7.362447672304763e+34, Validation Accuracy: 1.04\n",
            "[56/150]: Training Loss: 7.605070410587243e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.363398575313606e+34, Validation Accuracy: 1.04\n",
            "[57/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3600082701926835e+34, Validation Accuracy: 1.04\n",
            "[58/150]: Training Loss: 7.453089464225746e+34, Training Accuracy: 1.02\n",
            "Validation Loss: 7.363201660318024e+34, Validation Accuracy: 1.04\n",
            "[59/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.36800305202506e+34, Validation Accuracy: 1.04\n",
            "[60/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.36741461785972e+34, Validation Accuracy: 1.04\n",
            "[61/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.367097540150991e+34, Validation Accuracy: 1.04\n",
            "[62/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.360266091838198e+34, Validation Accuracy: 1.04\n",
            "[63/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.357579927011621e+34, Validation Accuracy: 1.04\n",
            "[64/150]: Training Loss: inf, Training Accuracy: 1.002\n",
            "Validation Loss: 7.3600130568941685e+34, Validation Accuracy: 1.04\n",
            "[65/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.361191245694225e+34, Validation Accuracy: 1.04\n",
            "[66/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.358085336664993e+34, Validation Accuracy: 1.04\n",
            "[67/150]: Training Loss: 7.58769795997563e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343106922424328e+34, Validation Accuracy: 1.04\n",
            "[68/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.340167062419033e+34, Validation Accuracy: 1.04\n",
            "[69/150]: Training Loss: 7.539564832453689e+34, Training Accuracy: 1.01\n",
            "Validation Loss: 7.3399107263015645e+34, Validation Accuracy: 1.04\n",
            "[70/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.343239299479195e+34, Validation Accuracy: 1.04\n",
            "[71/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.344283460637665e+34, Validation Accuracy: 1.04\n",
            "[72/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3470638739659e+34, Validation Accuracy: 1.04\n",
            "[73/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.337876213111667e+34, Validation Accuracy: 1.04\n",
            "[74/150]: Training Loss: 7.520041527682127e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.339984672586578e+34, Validation Accuracy: 1.04\n",
            "[75/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.341706399593216e+34, Validation Accuracy: 1.04\n",
            "[76/150]: Training Loss: 7.50774223153243e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.344978357646383e+34, Validation Accuracy: 1.04\n",
            "[77/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.34611412636776e+34, Validation Accuracy: 1.04\n",
            "[78/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.34531260145699e+34, Validation Accuracy: 1.04\n",
            "[79/150]: Training Loss: 7.570326728258824e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.35118538900336e+34, Validation Accuracy: 1.04\n",
            "[80/150]: Training Loss: 7.392040813047783e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.351906530340912e+34, Validation Accuracy: 1.04\n",
            "[81/150]: Training Loss: 7.55008671334021e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.357009484241519e+34, Validation Accuracy: 1.04\n",
            "[82/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.355688354631593e+34, Validation Accuracy: 1.04\n",
            "[83/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.351709120169314e+34, Validation Accuracy: 1.04\n",
            "[84/150]: Training Loss: 7.518704819072938e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.352724726177544e+34, Validation Accuracy: 1.04\n",
            "[85/150]: Training Loss: 7.480363492538042e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.353025628136426e+34, Validation Accuracy: 1.04\n",
            "[86/150]: Training Loss: 7.609761708160119e+34, Training Accuracy: 1.02\n",
            "Validation Loss: 7.355622331162831e+34, Validation Accuracy: 1.04\n",
            "[87/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.351417956672074e+34, Validation Accuracy: 1.04\n",
            "[88/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.3432506885275565e+34, Validation Accuracy: 1.04\n",
            "[89/150]: Training Loss: 7.571858879032369e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.342947970923284e+34, Validation Accuracy: 1.04\n",
            "[90/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.341380243657533e+34, Validation Accuracy: 1.04\n",
            "[91/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3435405315554215e+34, Validation Accuracy: 1.04\n",
            "[92/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.347343978532122e+34, Validation Accuracy: 1.04\n",
            "[93/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.349835869301868e+34, Validation Accuracy: 1.04\n",
            "[94/150]: Training Loss: 7.553363102583877e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.350179851574117e+34, Validation Accuracy: 1.04\n",
            "[95/150]: Training Loss: 7.518843468357338e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.349381297719442e+34, Validation Accuracy: 1.04\n",
            "[96/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.350629966572401e+34, Validation Accuracy: 1.04\n",
            "[97/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.350986328245043e+34, Validation Accuracy: 1.04\n",
            "[98/150]: Training Loss: inf, Training Accuracy: 1.02\n",
            "Validation Loss: 7.349232414797383e+34, Validation Accuracy: 1.04\n",
            "[99/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3498634341000755e+34, Validation Accuracy: 1.04\n",
            "[100/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.346068900291658e+34, Validation Accuracy: 1.04\n",
            "[101/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343747350071318e+34, Validation Accuracy: 1.04\n",
            "[102/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.343838462458209e+34, Validation Accuracy: 1.04\n",
            "[103/150]: Training Loss: 7.587162712793105e+34, Training Accuracy: 1.036\n",
            "Validation Loss: 7.34444604342949e+34, Validation Accuracy: 1.04\n",
            "[104/150]: Training Loss: 7.563224723389138e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.3440896817568485e+34, Validation Accuracy: 1.04\n",
            "[105/150]: Training Loss: 7.502001541710868e+34, Training Accuracy: 1.012\n",
            "Validation Loss: 7.343770788402729e+34, Validation Accuracy: 1.04\n",
            "[106/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.344186901314601e+34, Validation Accuracy: 1.04\n",
            "[107/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.347785180362123e+34, Validation Accuracy: 1.04\n",
            "[108/150]: Training Loss: 7.541743759284682e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.349218714927616e+34, Validation Accuracy: 1.04\n",
            "[109/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.350196357441308e+34, Validation Accuracy: 1.04\n",
            "[110/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.35085609695291e+34, Validation Accuracy: 1.04\n",
            "[111/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.3504860354105e+34, Validation Accuracy: 1.04\n",
            "[112/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: 7.350065630973159e+34, Validation Accuracy: 1.04\n",
            "[113/150]: Training Loss: 7.572177010577234e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.34878494073785e+34, Validation Accuracy: 1.04\n",
            "[114/150]: Training Loss: 7.602740036076367e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.345721781904642e+34, Validation Accuracy: 1.04\n",
            "[115/150]: Training Loss: 7.637903627666111e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.342419287997172e+34, Validation Accuracy: 1.04\n",
            "[116/150]: Training Loss: 7.578869428701e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.340205025913571e+34, Validation Accuracy: 1.04\n",
            "[117/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.33890419852029e+34, Validation Accuracy: 1.04\n",
            "[118/150]: Training Loss: 7.53878203535377e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3400515213487e+34, Validation Accuracy: 1.04\n",
            "[119/150]: Training Loss: 7.55180291722975e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.341673717976179e+34, Validation Accuracy: 1.04\n",
            "[120/150]: Training Loss: 7.52984426063198e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.341424314322931e+34, Validation Accuracy: 1.04\n",
            "[121/150]: Training Loss: inf, Training Accuracy: 1.008\n",
            "Validation Loss: 7.342221382649559e+34, Validation Accuracy: 1.04\n",
            "[122/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.341639550831095e+34, Validation Accuracy: 1.04\n",
            "[123/150]: Training Loss: 7.564221817432473e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.34171366217478e+34, Validation Accuracy: 1.04\n",
            "[124/150]: Training Loss: inf, Training Accuracy: 1.012\n",
            "Validation Loss: 7.341365883553077e+34, Validation Accuracy: 1.04\n",
            "[125/150]: Training Loss: 7.467476193914916e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.341843068173553e+34, Validation Accuracy: 1.04\n",
            "[126/150]: Training Loss: 7.557965611288089e+34, Training Accuracy: 1.018\n",
            "Validation Loss: 7.34209494770688e+34, Validation Accuracy: 1.04\n",
            "[127/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.342893501561555e+34, Validation Accuracy: 1.04\n",
            "[128/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: 7.343795217086171e+34, Validation Accuracy: 1.04\n",
            "[129/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.3440480869715285e+34, Validation Accuracy: 1.04\n",
            "[130/150]: Training Loss: inf, Training Accuracy: 1.026\n",
            "Validation Loss: 7.343806276017188e+34, Validation Accuracy: 1.04\n",
            "[131/150]: Training Loss: 7.511219776509865e+34, Training Accuracy: 1.006\n",
            "Validation Loss: 7.343705425168654e+34, Validation Accuracy: 1.04\n",
            "[132/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343869988664544e+34, Validation Accuracy: 1.04\n",
            "[133/150]: Training Loss: 7.572846983726496e+34, Training Accuracy: 1.004\n",
            "Validation Loss: 7.34368512295201e+34, Validation Accuracy: 1.04\n",
            "[134/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.3437027842299035e+34, Validation Accuracy: 1.04\n",
            "[135/150]: Training Loss: inf, Training Accuracy: 1.006\n",
            "Validation Loss: 7.34337316206211e+34, Validation Accuracy: 1.04\n",
            "[136/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343067143284399e+34, Validation Accuracy: 1.04\n",
            "[137/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.343213385267707e+34, Validation Accuracy: 1.04\n",
            "[138/150]: Training Loss: 7.591718865404154e+34, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343415086964774e+34, Validation Accuracy: 1.04\n",
            "[139/150]: Training Loss: inf, Training Accuracy: 1.024\n",
            "Validation Loss: 7.343418718255556e+34, Validation Accuracy: 1.04\n",
            "[140/150]: Training Loss: 7.5901811534230485e+34, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343325625164602e+34, Validation Accuracy: 1.04\n",
            "[141/150]: Training Loss: inf, Training Accuracy: 1.022\n",
            "Validation Loss: 7.343275777445687e+34, Validation Accuracy: 1.04\n",
            "[142/150]: Training Loss: inf, Training Accuracy: 1.014\n",
            "Validation Loss: 7.3432812243818595e+34, Validation Accuracy: 1.04\n",
            "[143/150]: Training Loss: 7.521443789977704e+34, Training Accuracy: 1.008\n",
            "Validation Loss: 7.343387192049222e+34, Validation Accuracy: 1.04\n",
            "[144/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343500752415492e+34, Validation Accuracy: 1.04\n",
            "[145/150]: Training Loss: 7.489635587251364e+34, Training Accuracy: 1.014\n",
            "Validation Loss: 7.343563144593472e+34, Validation Accuracy: 1.04\n",
            "[146/150]: Training Loss: inf, Training Accuracy: 1.018\n",
            "Validation Loss: 7.343603253850745e+34, Validation Accuracy: 1.04\n",
            "[147/150]: Training Loss: 7.537443193678667e+34, Training Accuracy: 1.026\n",
            "Validation Loss: 7.343630983707625e+34, Validation Accuracy: 1.04\n",
            "[148/150]: Training Loss: 7.421953062990879e+34, Training Accuracy: 1.024\n",
            "Validation Loss: 7.343639566758564e+34, Validation Accuracy: 1.04\n",
            "[149/150]: Training Loss: inf, Training Accuracy: 1.016\n",
            "Validation Loss: 7.343644683577394e+34, Validation Accuracy: 1.04\n",
            "[150/150]: Training Loss: inf, Training Accuracy: 1.01\n",
            "Validation Loss: 7.343644848636065e+34, Validation Accuracy: 1.04\n",
            "**********************************************************************\n",
            "Test Loss: 7.343644848636065e+34, Test Accuracy: 1.04\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td>                        </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.04</td></tr><tr><td>Test Loss</td><td>7.343644848636065e+34</td></tr><tr><td>Train Accuracy</td><td>1.01</td></tr><tr><td>Train Loss</td><td>inf</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=8192 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/573n6uz6</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_030841-573n6uz6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 16384, Learning rate: 24.0, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_033254-cneyt8y0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">batch_size=16384 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.5802256144010105, Training Accuracy: 1.524\n",
            "Validation Loss: 4.505903720855713, Validation Accuracy: 3.24\n",
            "[2/150]: Training Loss: 4.487952305720403, Training Accuracy: 2.782\n",
            "Validation Loss: 4.534458001454671, Validation Accuracy: 1.82\n",
            "[3/150]: Training Loss: 4.498784615443303, Training Accuracy: 2.232\n",
            "Validation Loss: 4.477282365163167, Validation Accuracy: 2.08\n",
            "[4/150]: Training Loss: 4.4941191306481, Training Accuracy: 2.178\n",
            "Validation Loss: 4.612959861755371, Validation Accuracy: 1.29\n",
            "[5/150]: Training Loss: 4.5912819642287035, Training Accuracy: 1.504\n",
            "Validation Loss: 5.598563989003499, Validation Accuracy: 2.19\n",
            "[6/150]: Training Loss: 5.028410141284649, Training Accuracy: 1.632\n",
            "Validation Loss: 7.806542873382568, Validation Accuracy: 1.07\n",
            "[7/150]: Training Loss: 14089.29747926272, Training Accuracy: 1.044\n",
            "Validation Loss: 7.282219409942627, Validation Accuracy: 0.93\n",
            "[8/150]: Training Loss: 461533512.8043683, Training Accuracy: 0.978\n",
            "Validation Loss: 145186464.0, Validation Accuracy: 0.98\n",
            "[9/150]: Training Loss: 1.1580541048823784e+29, Training Accuracy: 0.952\n",
            "Validation Loss: 2.748474842936338e+29, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: 2.8978003478935013e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484746540416787e+29, Validation Accuracy: 1.0\n",
            "[11/150]: Training Loss: 2.828666588105865e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748474402182133e+29, Validation Accuracy: 1.0\n",
            "[12/150]: Training Loss: 2.8943495766660634e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484738354981552e+29, Validation Accuracy: 1.0\n",
            "[13/150]: Training Loss: 2.848512485818888e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748472828059972e+29, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: 2.8171856724252214e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748468672377467e+29, Validation Accuracy: 1.0\n",
            "[15/150]: Training Loss: 2.9237725789099303e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7484595424689335e+29, Validation Accuracy: 1.0\n",
            "[16/150]: Training Loss: 2.8024521069540443e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.748430578621172e+29, Validation Accuracy: 1.0\n",
            "[17/150]: Training Loss: 2.818569224092193e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7483436870778873e+29, Validation Accuracy: 1.0\n",
            "[18/150]: Training Loss: 2.8163175416317275e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7480828865182598e+29, Validation Accuracy: 1.0\n",
            "[19/150]: Training Loss: 2.818046581630586e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7474053213752977e+29, Validation Accuracy: 1.0\n",
            "[20/150]: Training Loss: 2.8566013910414994e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7454263979594298e+29, Validation Accuracy: 1.0\n",
            "[21/150]: Training Loss: 2.8411686828451232e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.7395975495271803e+29, Validation Accuracy: 1.0\n",
            "[22/150]: Training Loss: 2.8607326044228643e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.722675988156443e+29, Validation Accuracy: 1.0\n",
            "[23/150]: Training Loss: 2.7987878847615806e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.6741031117411477e+29, Validation Accuracy: 1.0\n",
            "[24/150]: Training Loss: 2.723279453314973e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.535316349808136e+29, Validation Accuracy: 1.0\n",
            "[25/150]: Training Loss: 2.573586814635347e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 2.1297902431238725e+29, Validation Accuracy: 1.0\n",
            "[26/150]: Training Loss: 2.051805262233517e+29, Training Accuracy: 1.0\n",
            "Validation Loss: 1.0476803956799425e+29, Validation Accuracy: 1.0\n",
            "[27/150]: Training Loss: 8.450376531000046e+28, Training Accuracy: 1.0\n",
            "Validation Loss: 9.264404581011073e+18, Validation Accuracy: 1.0\n",
            "[28/150]: Training Loss: nan, Training Accuracy: 1.044\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[29/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[30/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[31/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[32/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[33/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[34/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[35/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[36/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[37/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[38/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[39/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[40/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[41/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[43/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[44/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[45/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[46/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[47/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[48/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[49/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[50/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[51/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[52/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[53/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[55/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[56/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[57/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[58/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[59/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[60/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[61/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[62/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[63/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[64/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[65/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[66/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[67/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[68/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[69/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[70/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[71/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[72/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[73/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[74/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[75/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[76/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[77/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[78/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[79/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[80/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[81/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[82/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[83/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[84/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[85/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[86/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[87/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[88/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[89/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[90/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[91/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[92/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[93/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[94/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[95/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[96/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[97/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[98/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[99/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[100/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[101/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[102/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[103/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[104/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[105/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[106/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[107/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[108/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[109/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[110/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[111/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[112/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[113/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[114/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[115/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[116/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[117/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[118/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[119/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[120/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[121/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[122/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[123/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[124/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[125/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[126/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[127/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[128/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[129/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[130/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[131/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[132/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[133/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[134/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[135/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[136/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[137/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[138/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[139/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[140/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[141/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[142/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[143/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[144/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[145/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[146/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[147/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[148/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[149/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[150/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "**********************************************************************\n",
            "Test Loss: nan, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td>                                 </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>nan</td></tr><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Train Loss</td><td>nan</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=16384 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/cneyt8y0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_033254-cneyt8y0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 32768, Learning rate: 33.941125496954285, Weight decay: 0.001\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_035739-zqj7yms0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">batch_size=32768 learning_rate=1.5 weight_decay=0.001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.600700745215783, Training Accuracy: 1.18\n",
            "Validation Loss: 4.5345486005147295, Validation Accuracy: 2.25\n",
            "[2/150]: Training Loss: 4.525542259216309, Training Accuracy: 2.194\n",
            "Validation Loss: 4.480770270029704, Validation Accuracy: 3.63\n",
            "[3/150]: Training Loss: 4.467245468726525, Training Accuracy: 3.348\n",
            "Validation Loss: 4.682004292805989, Validation Accuracy: 2.02\n",
            "[4/150]: Training Loss: 4.584587500645564, Training Accuracy: 2.316\n",
            "Validation Loss: 4.589324951171875, Validation Accuracy: 1.07\n",
            "[5/150]: Training Loss: 4.593533919407771, Training Accuracy: 1.128\n",
            "Validation Loss: 4.565906047821045, Validation Accuracy: 2.24\n",
            "[6/150]: Training Loss: 4.610266098609338, Training Accuracy: 1.65\n",
            "Validation Loss: 5.121236960093181, Validation Accuracy: 1.01\n",
            "[7/150]: Training Loss: 5.261244590465839, Training Accuracy: 1.226\n",
            "Validation Loss: 7.05544392267863, Validation Accuracy: 1.19\n",
            "[8/150]: Training Loss: 6.352289456587571, Training Accuracy: 1.176\n",
            "Validation Loss: 22.820095698038738, Validation Accuracy: 0.83\n",
            "[9/150]: Training Loss: 33.29087433448205, Training Accuracy: 0.906\n",
            "Validation Loss: 54.22376505533854, Validation Accuracy: 1.0\n",
            "[10/150]: Training Loss: 35.99252113929162, Training Accuracy: 0.988\n",
            "Validation Loss: 69.11057027180989, Validation Accuracy: 0.95\n",
            "[11/150]: Training Loss: 76.55324378380409, Training Accuracy: 1.196\n",
            "Validation Loss: 7.983708381652832, Validation Accuracy: 1.06\n",
            "[12/150]: Training Loss: 58.39160236945519, Training Accuracy: 1.032\n",
            "Validation Loss: 164.86418660481772, Validation Accuracy: 0.92\n",
            "[13/150]: Training Loss: 131.58557803814227, Training Accuracy: 0.95\n",
            "Validation Loss: 281.80524190266925, Validation Accuracy: 1.0\n",
            "[14/150]: Training Loss: 178.63248865421002, Training Accuracy: 0.962\n",
            "Validation Loss: 7817948401325397.0, Validation Accuracy: 1.39\n",
            "[15/150]: Training Loss: 4967409836682319.0, Training Accuracy: 1.34\n",
            "Validation Loss: 2.8247563537114726e+17, Validation Accuracy: 1.0\n",
            "[16/150]: Training Loss: 1.7259852552660077e+17, Training Accuracy: 0.982\n",
            "Validation Loss: 7061819945735509.0, Validation Accuracy: 0.96\n",
            "[17/150]: Training Loss: 7.113184439761936e+16, Training Accuracy: 0.924\n",
            "Validation Loss: 64496.6328125, Validation Accuracy: 1.0\n",
            "[18/150]: Training Loss: nan, Training Accuracy: 1.014\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[19/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[20/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[21/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[22/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[23/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[24/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[25/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[26/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[27/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[28/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[29/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[30/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[31/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[32/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[33/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[34/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[35/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[36/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[37/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[38/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[39/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[40/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[41/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[42/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[43/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[44/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[45/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[46/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[47/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[48/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[49/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[50/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[51/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[52/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[53/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[54/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[55/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[56/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[57/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[58/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[59/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[60/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[61/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[62/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[63/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[64/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[65/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[66/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[67/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[68/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[69/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[70/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[71/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[72/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[73/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[74/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[75/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[76/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[77/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[78/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[79/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[80/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[81/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[82/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[83/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[84/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[85/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[86/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[87/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[88/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[89/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[90/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[91/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[92/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[93/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[94/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[95/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[96/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[97/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[98/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[99/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[100/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[101/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[102/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[103/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[104/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[105/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[106/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[107/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[108/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[109/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[110/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[111/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[112/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[113/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[114/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[115/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[116/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[117/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[118/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[119/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[120/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[121/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[122/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[123/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[124/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[125/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[126/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[127/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[128/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[129/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[130/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[131/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[132/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[133/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[134/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[135/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[136/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[137/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[138/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[139/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[140/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[141/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[142/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[143/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[144/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[145/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[146/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[147/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[148/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[149/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "[150/150]: Training Loss: nan, Training Accuracy: 1.0\n",
            "Validation Loss: nan, Validation Accuracy: 1.0\n",
            "**********************************************************************\n",
            "Test Loss: nan, Test Accuracy: 1.0\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td>                                   </td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>1.0</td></tr><tr><td>Test Loss</td><td>nan</td></tr><tr><td>Train Accuracy</td><td>1.0</td></tr><tr><td>Train Loss</td><td>nan</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=32768 learning_rate=1.5 weight_decay=0.001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches/runs/zqj7yms0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LARS_Large_Batches</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_035739-zqj7yms0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 1.5\n",
        "wd = 1e-03\n",
        "batch_sizes = [512, 1024, 2048, 4096, 8192, 16384 , 32768]\n",
        "learning_rates = [lr * (batch_size / 64.0) ** 0.5 for batch_size in batch_sizes] # Root square scale-up of learning rate\n",
        "\n",
        "\n",
        "for i, batch_size in enumerate(batch_sizes):\n",
        "\n",
        "  print('='*50)\n",
        "  print(f'Batch size: {batch_size}, Weight decay: {wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rates[i],\n",
        "    'weight_decay' : wd\n",
        "  }\n",
        "  if batch_size <= 4096:\n",
        "  \n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= batch_size)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LARS(model.parameters(), lr= learning_rates[i], weight_decay=wd, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LARS_Large_Batches',\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )\n",
        "  else:\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= 4096)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LARS(model.parameters(), lr= learning_rates[i], weight_decay=wd, momentum=0.9)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "    accumulation_steps = batch_size // 4096\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LARS_Large_Batches',\n",
        "        accumulation_steps=accumulation_steps,\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LAMB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LAMB(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements LAMB (Layer-wise Adaptive Moments) optimizer.\n",
        "\n",
        "    Args:\n",
        "        params (iterable): Iterable of parameters to optimize or dicts defining parameter groups.\n",
        "        learning_rate (Union[float, Callable], optional): The learning rate. Default is 0.001.\n",
        "        beta_1 (float, optional): The exponential decay rate for the 1st moment estimates. Default is 0.9.\n",
        "        beta_2 (float, optional): The exponential decay rate for the 2nd moment estimates. Default is 0.999.\n",
        "        epsilon (float, optional): A small constant for numerical stability. Default is 1e-6.\n",
        "        weight_decay (float, optional): Weight decay. Default is 0.0.\n",
        "        exclude_from_weight_decay (Optional[List[str]], optional): List of regex patterns of variables excluded from weight decay. Variables whose name contain a substring matching the pattern will be excluded. Default is None.\n",
        "        exclude_from_layer_adaptation (Optional[List[str]], optional): List of regex patterns of variables excluded from layer adaptation. Variables whose name contain a substring matching the pattern will be excluded. Default is None.\n",
        "        name (str, optional): Optional name for the operations created when applying gradients. Defaults to \"LAMB\".\n",
        "        **kwargs: Keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`, `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip gradients by value, `decay` is included for backward compatibility to allow time inverse decay of learning rate. `lr` is included for backward compatibility, recommended to use `learning_rate` instead.\n",
        "\n",
        "    Note:\n",
        "        - If \"weight_decay_rate\" is found in kwargs, it will be renamed to \"weight_decay\", and will be deprecated in Addons 0.18.\n",
        "        - If exclude_from_layer_adaptation is None, it will be set to exclude_from_weight_decay.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr: Union[float, Callable] = 0.001,\n",
        "        beta_1: float = 0.9,\n",
        "        beta_2: float = 0.999,\n",
        "        epsilon: float = 1e-6,\n",
        "        wd: float = 0.0,\n",
        "        exclude_from_weight_decay: Optional[List[str]] = None,\n",
        "        exclude_from_layer_adaptation: Optional[List[str]] = None,\n",
        "        name: str = \"LAMB\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes a new instance of the LAMB optimizer.\n",
        "        \"\"\"\n",
        "\n",
        "        defaults = dict(\n",
        "            lr=lr,\n",
        "            betas=(beta_1, beta_2),\n",
        "            eps=epsilon,\n",
        "            wd=wd,\n",
        "            **kwargs)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "        # exclude_from_layer_adaptation is set to exclude_from_weight_decay if\n",
        "        # the arg is None.\n",
        "        if exclude_from_layer_adaptation:\n",
        "            self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "        else:\n",
        "            self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "    def _compute_update(self, p, grad, state, group):\n",
        "        \"\"\"\n",
        "        Computes the update for a given parameter.\n",
        "\n",
        "        Args:\n",
        "            p (Tensor): The parameter to be updated.\n",
        "            grad (Tensor): The gradient of the parameter.\n",
        "            state (dict): A dictionary containing information about the optimization state.\n",
        "            group (dict): A dictionary containing the optimization parameters.\n",
        "\n",
        "        Returns:\n",
        "            Tensor: The computed update for the parameter.\n",
        "        \"\"\"\n",
        "        # State initialization\n",
        "        if len(state) == 0:\n",
        "            state['step'] = 0\n",
        "            # Exponential moving average of gradient values\n",
        "            state['exp_avg'] = torch.zeros_like(p.data)\n",
        "            # Exponential moving average of squared gradient values\n",
        "            state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
        "\n",
        "        exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "        beta1, beta2 = group['betas']\n",
        "\n",
        "        state['step'] += 1\n",
        "\n",
        "        # Decay the first and second moment running average coefficient\n",
        "        exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "        exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "\n",
        "        denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "\n",
        "        update = exp_avg / denom\n",
        "\n",
        "        # LAMB layer-wise adaptation\n",
        "        r1 = p.data.pow(2).sum().sqrt()\n",
        "        r2 = update.pow(2).sum().sqrt()\n",
        "        r = torch.where(r1 == 0, torch.zeros_like(r1), r1 / r2)\n",
        "\n",
        "        return r * update\n",
        "\n",
        "    def _update_params(self, p, update, step_size, weight_decay):\n",
        "        \"\"\"\n",
        "        Updates the parameters with the computed update.\n",
        "\n",
        "        Args:\n",
        "            p (Tensor): The parameter to be updated.\n",
        "            update (Tensor): The computed update for the parameter.\n",
        "            step_size (float): The step size for the update.\n",
        "            weight_decay (float): The weight decay factor.\n",
        "        \"\"\"\n",
        "        if weight_decay != 0:\n",
        "            p.data.add_(-weight_decay * step_size, p.data)\n",
        "\n",
        "        p.data.add_(-step_size, update)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Args:\n",
        "            closure (callable, optional): A closure that reevaluates the model and returns the loss. Default is None.\n",
        "        \"\"\"\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('LAMB does not support sparse gradients.')\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                update = self._compute_update(p, grad, state, group)\n",
        "                self._update_params(p, update, group['lr'], group['weight_decay'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LAMB Hyperparameter Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ftxikW3Lr2ya"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.0009 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_045009-kw5xm0f9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">learning_rate=0.0009 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.366185345458985, Training Accuracy: 3.775\n",
            "Validation Loss: 4.140061999582182, Validation Accuracy: 6.19\n",
            "[2/150]: Training Loss: 3.9872212955474855, Training Accuracy: 9.2825\n",
            "Validation Loss: 3.9175391182018693, Validation Accuracy: 10.13\n",
            "[3/150]: Training Loss: 3.7751855819702147, Training Accuracy: 12.73\n",
            "Validation Loss: 3.754828929901123, Validation Accuracy: 13.44\n",
            "[4/150]: Training Loss: 3.6031822479248046, Training Accuracy: 15.7675\n",
            "Validation Loss: 3.5609892857302525, Validation Accuracy: 16.33\n",
            "[5/150]: Training Loss: 3.4478089206695555, Training Accuracy: 18.66\n",
            "Validation Loss: 3.4119288389849816, Validation Accuracy: 19.45\n",
            "[6/150]: Training Loss: 3.3203197284698485, Training Accuracy: 20.7075\n",
            "Validation Loss: 3.349654642639646, Validation Accuracy: 20.47\n",
            "[7/150]: Training Loss: 3.20732957611084, Training Accuracy: 22.7475\n",
            "Validation Loss: 3.2386614349996967, Validation Accuracy: 22.79\n",
            "[8/150]: Training Loss: 3.115479539489746, Training Accuracy: 24.5875\n",
            "Validation Loss: 3.1584747019846726, Validation Accuracy: 24.53\n",
            "[9/150]: Training Loss: 3.0234272315979003, Training Accuracy: 26.28\n",
            "Validation Loss: 3.0975672788680737, Validation Accuracy: 24.97\n",
            "[10/150]: Training Loss: 2.9408509815216064, Training Accuracy: 27.665\n",
            "Validation Loss: 3.0618672537955507, Validation Accuracy: 25.33\n",
            "[11/150]: Training Loss: 2.862503829956055, Training Accuracy: 29.3325\n",
            "Validation Loss: 2.9638838965422027, Validation Accuracy: 27.41\n",
            "[12/150]: Training Loss: 2.790407749938965, Training Accuracy: 30.48\n",
            "Validation Loss: 2.937404105617742, Validation Accuracy: 28.32\n",
            "[13/150]: Training Loss: 2.724927402114868, Training Accuracy: 31.9425\n",
            "Validation Loss: 2.9041963838467932, Validation Accuracy: 28.5\n",
            "[14/150]: Training Loss: 2.659171875, Training Accuracy: 33.2275\n",
            "Validation Loss: 2.8527053769227044, Validation Accuracy: 29.6\n",
            "[15/150]: Training Loss: 2.604087335395813, Training Accuracy: 34.1075\n",
            "Validation Loss: 2.8513991179739593, Validation Accuracy: 30.15\n",
            "[16/150]: Training Loss: 2.5427039728164673, Training Accuracy: 35.57\n",
            "Validation Loss: 2.8172519510718668, Validation Accuracy: 30.73\n",
            "[17/150]: Training Loss: 2.4821195234298705, Training Accuracy: 36.73\n",
            "Validation Loss: 2.826693563704278, Validation Accuracy: 31.28\n",
            "[18/150]: Training Loss: 2.4249122804641723, Training Accuracy: 37.97\n",
            "Validation Loss: 2.78142261353268, Validation Accuracy: 32.01\n",
            "[19/150]: Training Loss: 2.366035011482239, Training Accuracy: 39.02\n",
            "Validation Loss: 2.7907780021618884, Validation Accuracy: 31.84\n",
            "[20/150]: Training Loss: 2.3027314464569093, Training Accuracy: 40.4925\n",
            "Validation Loss: 2.740103484718663, Validation Accuracy: 32.92\n",
            "[21/150]: Training Loss: 2.24520486240387, Training Accuracy: 41.56\n",
            "Validation Loss: 2.720843028111063, Validation Accuracy: 33.71\n",
            "[22/150]: Training Loss: 2.194983146095276, Training Accuracy: 42.9375\n",
            "Validation Loss: 2.7611854592705987, Validation Accuracy: 32.67\n",
            "[23/150]: Training Loss: 2.138135533905029, Training Accuracy: 44.1975\n",
            "Validation Loss: 2.7068749218230037, Validation Accuracy: 33.35\n",
            "[24/150]: Training Loss: 2.078735979270935, Training Accuracy: 45.3275\n",
            "Validation Loss: 2.6949741673317686, Validation Accuracy: 34.58\n",
            "[25/150]: Training Loss: 2.0237128454208375, Training Accuracy: 46.48\n",
            "Validation Loss: 2.700145792809262, Validation Accuracy: 33.95\n",
            "[26/150]: Training Loss: 1.9667144546508788, Training Accuracy: 47.8375\n",
            "Validation Loss: 2.749180986623096, Validation Accuracy: 34.02\n",
            "[27/150]: Training Loss: 1.9086554452896118, Training Accuracy: 49.35\n",
            "Validation Loss: 2.719582610828861, Validation Accuracy: 34.45\n",
            "[28/150]: Training Loss: 1.845149391746521, Training Accuracy: 50.64\n",
            "Validation Loss: 2.735584658422288, Validation Accuracy: 34.52\n",
            "[29/150]: Training Loss: 1.7947315074920653, Training Accuracy: 51.665\n",
            "Validation Loss: 2.7848551835224127, Validation Accuracy: 33.98\n",
            "[30/150]: Training Loss: 1.7361212677001954, Training Accuracy: 53.24\n",
            "Validation Loss: 2.7989868426778513, Validation Accuracy: 34.65\n",
            "[31/150]: Training Loss: 1.675447853088379, Training Accuracy: 54.63\n",
            "Validation Loss: 2.805454480420252, Validation Accuracy: 35.16\n",
            "[32/150]: Training Loss: 1.6181456073760987, Training Accuracy: 55.7275\n",
            "Validation Loss: 2.825571666097945, Validation Accuracy: 35.24\n",
            "[33/150]: Training Loss: 1.5572484771728516, Training Accuracy: 57.33\n",
            "Validation Loss: 2.895953078178843, Validation Accuracy: 34.87\n",
            "[34/150]: Training Loss: 1.493730352783203, Training Accuracy: 58.9\n",
            "Validation Loss: 2.8819164500874317, Validation Accuracy: 34.54\n",
            "[35/150]: Training Loss: 1.4407835181236268, Training Accuracy: 60.1325\n",
            "Validation Loss: 2.9298907556351583, Validation Accuracy: 35.13\n",
            "[36/150]: Training Loss: 1.378046295261383, Training Accuracy: 61.6725\n",
            "Validation Loss: 2.9877944615236514, Validation Accuracy: 34.88\n",
            "[37/150]: Training Loss: 1.3214307213783265, Training Accuracy: 63.3825\n",
            "Validation Loss: 3.01296287281498, Validation Accuracy: 34.97\n",
            "[38/150]: Training Loss: 1.2566315541267394, Training Accuracy: 64.46\n",
            "Validation Loss: 3.1075331208052908, Validation Accuracy: 34.96\n",
            "[39/150]: Training Loss: 1.2033088095664979, Training Accuracy: 66.1\n",
            "Validation Loss: 3.1721465040923684, Validation Accuracy: 34.01\n",
            "[40/150]: Training Loss: 1.1419879460334779, Training Accuracy: 67.7475\n",
            "Validation Loss: 3.260179937265481, Validation Accuracy: 34.51\n",
            "[41/150]: Training Loss: 1.0848600325584412, Training Accuracy: 69.2325\n",
            "Validation Loss: 3.281414782165722, Validation Accuracy: 34.07\n",
            "[42/150]: Training Loss: 1.0264957049369812, Training Accuracy: 70.73\n",
            "Validation Loss: 3.4151626255861514, Validation Accuracy: 34.15\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 17.67243060336751, Test Accuracy: 14.49\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>14.49</td></tr><tr><td>Test Loss</td><td>17.67243</td></tr><tr><td>Train Accuracy</td><td>70.73</td></tr><tr><td>Train Loss</td><td>1.0265</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0009 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/kw5xm0f9</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_045009-kw5xm0f9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.00095 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_045608-cwudz2wj</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">learning_rate=0.00095 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.36243955039978, Training Accuracy: 3.8475\n",
            "Validation Loss: 4.152171432592307, Validation Accuracy: 6.23\n",
            "[2/150]: Training Loss: 3.988539717102051, Training Accuracy: 9.035\n",
            "Validation Loss: 3.8899211443153914, Validation Accuracy: 10.42\n",
            "[3/150]: Training Loss: 3.784552033996582, Training Accuracy: 12.44\n",
            "Validation Loss: 3.716481655266634, Validation Accuracy: 13.63\n",
            "[4/150]: Training Loss: 3.6115343948364256, Training Accuracy: 15.38\n",
            "Validation Loss: 3.575136796684022, Validation Accuracy: 15.25\n",
            "[5/150]: Training Loss: 3.464410584640503, Training Accuracy: 18.1625\n",
            "Validation Loss: 3.448981456695848, Validation Accuracy: 17.92\n",
            "[6/150]: Training Loss: 3.340861389923096, Training Accuracy: 20.2875\n",
            "Validation Loss: 3.3443257702384024, Validation Accuracy: 19.79\n",
            "[7/150]: Training Loss: 3.240240854263306, Training Accuracy: 22.0975\n",
            "Validation Loss: 3.2861741910314866, Validation Accuracy: 21.07\n",
            "[8/150]: Training Loss: 3.1493673683166503, Training Accuracy: 23.8725\n",
            "Validation Loss: 3.1970221844448408, Validation Accuracy: 22.88\n",
            "[9/150]: Training Loss: 3.058048994064331, Training Accuracy: 25.4\n",
            "Validation Loss: 3.149918096080707, Validation Accuracy: 23.89\n",
            "[10/150]: Training Loss: 2.980970076370239, Training Accuracy: 26.93\n",
            "Validation Loss: 3.05195216008812, Validation Accuracy: 25.52\n",
            "[11/150]: Training Loss: 2.8978964962005613, Training Accuracy: 28.4275\n",
            "Validation Loss: 3.035321120243923, Validation Accuracy: 26.01\n",
            "[12/150]: Training Loss: 2.828321962738037, Training Accuracy: 29.7825\n",
            "Validation Loss: 3.033455335410537, Validation Accuracy: 26.14\n",
            "[13/150]: Training Loss: 2.764588646316528, Training Accuracy: 31.0525\n",
            "Validation Loss: 2.9178414527018357, Validation Accuracy: 28.5\n",
            "[14/150]: Training Loss: 2.6963481563568115, Training Accuracy: 32.6275\n",
            "Validation Loss: 2.8597835826266342, Validation Accuracy: 29.48\n",
            "[15/150]: Training Loss: 2.6279782932281495, Training Accuracy: 33.5125\n",
            "Validation Loss: 2.820923639710542, Validation Accuracy: 30.76\n",
            "[16/150]: Training Loss: 2.567752400970459, Training Accuracy: 35.0025\n",
            "Validation Loss: 2.8166574232137886, Validation Accuracy: 30.67\n",
            "[17/150]: Training Loss: 2.5122242719650267, Training Accuracy: 36.11\n",
            "Validation Loss: 2.77275866611748, Validation Accuracy: 31.51\n",
            "[18/150]: Training Loss: 2.448093600654602, Training Accuracy: 37.37\n",
            "Validation Loss: 2.7573567454222663, Validation Accuracy: 31.87\n",
            "[19/150]: Training Loss: 2.390553472328186, Training Accuracy: 38.6925\n",
            "Validation Loss: 2.779167422823086, Validation Accuracy: 31.58\n",
            "[20/150]: Training Loss: 2.329650112724304, Training Accuracy: 39.8\n",
            "Validation Loss: 2.7296412940237933, Validation Accuracy: 32.77\n",
            "[21/150]: Training Loss: 2.2680850820541383, Training Accuracy: 41.2075\n",
            "Validation Loss: 2.7711537537301423, Validation Accuracy: 32.31\n",
            "[22/150]: Training Loss: 2.205855764579773, Training Accuracy: 42.4775\n",
            "Validation Loss: 2.710599136959975, Validation Accuracy: 33.08\n",
            "[23/150]: Training Loss: 2.153862490653992, Training Accuracy: 43.845\n",
            "Validation Loss: 2.6846724543601845, Validation Accuracy: 34.22\n",
            "[24/150]: Training Loss: 2.0879069725036623, Training Accuracy: 45.07\n",
            "Validation Loss: 2.6652191763470885, Validation Accuracy: 34.62\n",
            "[25/150]: Training Loss: 2.027932558250427, Training Accuracy: 46.0825\n",
            "Validation Loss: 2.7143203483265674, Validation Accuracy: 34.04\n",
            "[26/150]: Training Loss: 1.9607762811660767, Training Accuracy: 47.975\n",
            "Validation Loss: 2.6897484147624606, Validation Accuracy: 34.96\n",
            "[27/150]: Training Loss: 1.9115407361984253, Training Accuracy: 48.8575\n",
            "Validation Loss: 2.7138490722437574, Validation Accuracy: 34.41\n",
            "[28/150]: Training Loss: 1.8502281684875488, Training Accuracy: 50.4525\n",
            "Validation Loss: 2.699836605673383, Validation Accuracy: 35.02\n",
            "[29/150]: Training Loss: 1.790220089149475, Training Accuracy: 51.585\n",
            "Validation Loss: 2.7410409693505353, Validation Accuracy: 34.77\n",
            "[30/150]: Training Loss: 1.7332203540802003, Training Accuracy: 53.0625\n",
            "Validation Loss: 2.6978999216845083, Validation Accuracy: 35.51\n",
            "[31/150]: Training Loss: 1.6659312999725342, Training Accuracy: 54.48\n",
            "Validation Loss: 2.7799882926758688, Validation Accuracy: 35.39\n",
            "[32/150]: Training Loss: 1.6054936313629151, Training Accuracy: 55.9275\n",
            "Validation Loss: 2.783534232218554, Validation Accuracy: 35.38\n",
            "[33/150]: Training Loss: 1.5524930331230165, Training Accuracy: 57.2425\n",
            "Validation Loss: 2.7876193948612094, Validation Accuracy: 35.43\n",
            "[34/150]: Training Loss: 1.4864114666938781, Training Accuracy: 58.62\n",
            "Validation Loss: 2.8515792378954066, Validation Accuracy: 34.97\n",
            "[35/150]: Training Loss: 1.4250763600349425, Training Accuracy: 60.31\n",
            "Validation Loss: 2.89135210453325, Validation Accuracy: 34.83\n",
            "[36/150]: Training Loss: 1.3677435276031493, Training Accuracy: 61.51\n",
            "Validation Loss: 2.919705820691054, Validation Accuracy: 36.01\n",
            "[37/150]: Training Loss: 1.3075296778678893, Training Accuracy: 63.435\n",
            "Validation Loss: 3.000214212259669, Validation Accuracy: 35.23\n",
            "[38/150]: Training Loss: 1.2455093726158142, Training Accuracy: 64.7925\n",
            "Validation Loss: 3.0685715766469386, Validation Accuracy: 34.47\n",
            "[39/150]: Training Loss: 1.1875538174629212, Training Accuracy: 66.195\n",
            "Validation Loss: 3.0860758040361342, Validation Accuracy: 35.17\n",
            "[40/150]: Training Loss: 1.1235356809616088, Training Accuracy: 67.92\n",
            "Validation Loss: 3.142808488979461, Validation Accuracy: 35.12\n",
            "[41/150]: Training Loss: 1.0638824738502501, Training Accuracy: 69.31\n",
            "Validation Loss: 3.2775286580346954, Validation Accuracy: 35.6\n",
            "[42/150]: Training Loss: 1.0043726112365723, Training Accuracy: 71.1\n",
            "Validation Loss: 3.332795017084498, Validation Accuracy: 34.53\n",
            "[43/150]: Training Loss: 0.9537097842216492, Training Accuracy: 72.4\n",
            "Validation Loss: 3.416984627960594, Validation Accuracy: 34.84\n",
            "[44/150]: Training Loss: 0.8938642192840576, Training Accuracy: 74.145\n",
            "Validation Loss: 3.5402958104564886, Validation Accuracy: 34.94\n",
            "[45/150]: Training Loss: 0.8376890470981598, Training Accuracy: 75.4875\n",
            "Validation Loss: 3.6570517561238285, Validation Accuracy: 34.43\n",
            "[46/150]: Training Loss: 0.7843643071174622, Training Accuracy: 76.875\n",
            "Validation Loss: 3.745219696858886, Validation Accuracy: 34.67\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 24.405659256467395, Test Accuracy: 13.44\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>13.44</td></tr><tr><td>Test Loss</td><td>24.40566</td></tr><tr><td>Train Accuracy</td><td>76.875</td></tr><tr><td>Train Loss</td><td>0.78436</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.00095 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/cwudz2wj</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_045608-cwudz2wj/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.001 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_050220-wgvfp3rx</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">learning_rate=0.001 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.351185768127442, Training Accuracy: 3.94\n",
            "Validation Loss: 4.125218055810139, Validation Accuracy: 6.94\n",
            "[2/150]: Training Loss: 3.934326037979126, Training Accuracy: 9.675\n",
            "Validation Loss: 3.8352680054439863, Validation Accuracy: 11.53\n",
            "[3/150]: Training Loss: 3.6920593730926514, Training Accuracy: 14.25\n",
            "Validation Loss: 3.6194094821905636, Validation Accuracy: 15.04\n",
            "[4/150]: Training Loss: 3.5119912174224854, Training Accuracy: 17.235\n",
            "Validation Loss: 3.498675950773203, Validation Accuracy: 17.26\n",
            "[5/150]: Training Loss: 3.3595370391845703, Training Accuracy: 19.9025\n",
            "Validation Loss: 3.3320715184424334, Validation Accuracy: 20.65\n",
            "[6/150]: Training Loss: 3.2359037544250486, Training Accuracy: 22.135\n",
            "Validation Loss: 3.2282794827868226, Validation Accuracy: 21.83\n",
            "[7/150]: Training Loss: 3.1236792266845703, Training Accuracy: 24.1875\n",
            "Validation Loss: 3.1484436852157494, Validation Accuracy: 23.69\n",
            "[8/150]: Training Loss: 3.0264555549621583, Training Accuracy: 25.99\n",
            "Validation Loss: 3.0823915505864816, Validation Accuracy: 24.76\n",
            "[9/150]: Training Loss: 2.9406655250549316, Training Accuracy: 27.4325\n",
            "Validation Loss: 3.018990922126041, Validation Accuracy: 25.75\n",
            "[10/150]: Training Loss: 2.8602982753753663, Training Accuracy: 28.8825\n",
            "Validation Loss: 2.982261516486004, Validation Accuracy: 26.83\n",
            "[11/150]: Training Loss: 2.7865394050598145, Training Accuracy: 30.62\n",
            "Validation Loss: 2.881638531472273, Validation Accuracy: 28.86\n",
            "[12/150]: Training Loss: 2.713952407836914, Training Accuracy: 32.0525\n",
            "Validation Loss: 2.8773576226204063, Validation Accuracy: 28.51\n",
            "[13/150]: Training Loss: 2.6428218954086304, Training Accuracy: 33.4175\n",
            "Validation Loss: 2.852285245421586, Validation Accuracy: 29.44\n",
            "[14/150]: Training Loss: 2.5819866678237915, Training Accuracy: 34.2325\n",
            "Validation Loss: 2.8152025581165483, Validation Accuracy: 29.99\n",
            "[15/150]: Training Loss: 2.5168129930496215, Training Accuracy: 36.01\n",
            "Validation Loss: 2.7263220571408606, Validation Accuracy: 32.4\n",
            "[16/150]: Training Loss: 2.456671890640259, Training Accuracy: 37.025\n",
            "Validation Loss: 2.7360152697107596, Validation Accuracy: 31.89\n",
            "[17/150]: Training Loss: 2.394518960952759, Training Accuracy: 38.405\n",
            "Validation Loss: 2.693733840231683, Validation Accuracy: 33.43\n",
            "[18/150]: Training Loss: 2.329904039955139, Training Accuracy: 40.0125\n",
            "Validation Loss: 2.679514690569252, Validation Accuracy: 33.49\n",
            "[19/150]: Training Loss: 2.271217462730408, Training Accuracy: 41.0875\n",
            "Validation Loss: 2.7137394892941615, Validation Accuracy: 32.98\n",
            "[20/150]: Training Loss: 2.2047285720825194, Training Accuracy: 42.575\n",
            "Validation Loss: 2.6841572416815787, Validation Accuracy: 32.96\n",
            "[21/150]: Training Loss: 2.1471473873138427, Training Accuracy: 43.83\n",
            "Validation Loss: 2.6751675947456603, Validation Accuracy: 33.61\n",
            "[22/150]: Training Loss: 2.085570357322693, Training Accuracy: 45.055\n",
            "Validation Loss: 2.6481618797703153, Validation Accuracy: 34.55\n",
            "[23/150]: Training Loss: 2.0214510499954224, Training Accuracy: 46.6625\n",
            "Validation Loss: 2.638173457163914, Validation Accuracy: 35.26\n",
            "[24/150]: Training Loss: 1.9607698831558227, Training Accuracy: 48.02\n",
            "Validation Loss: 2.621039168849872, Validation Accuracy: 35.84\n",
            "[25/150]: Training Loss: 1.8981156831741333, Training Accuracy: 49.45\n",
            "Validation Loss: 2.62651793896013, Validation Accuracy: 36.22\n",
            "[26/150]: Training Loss: 1.8291910402297973, Training Accuracy: 51.235\n",
            "Validation Loss: 2.6563384396255394, Validation Accuracy: 35.62\n",
            "[27/150]: Training Loss: 1.7651165187835693, Training Accuracy: 52.31\n",
            "Validation Loss: 2.639584611935221, Validation Accuracy: 36.55\n",
            "[28/150]: Training Loss: 1.7005936141967772, Training Accuracy: 54.275\n",
            "Validation Loss: 2.7095768307424652, Validation Accuracy: 36.06\n",
            "[29/150]: Training Loss: 1.6383595853805542, Training Accuracy: 55.6225\n",
            "Validation Loss: 2.7259993150735355, Validation Accuracy: 35.64\n",
            "[30/150]: Training Loss: 1.5726151014328003, Training Accuracy: 57.1225\n",
            "Validation Loss: 2.7611397246646274, Validation Accuracy: 36.11\n",
            "[31/150]: Training Loss: 1.508023483467102, Training Accuracy: 58.3025\n",
            "Validation Loss: 2.7436208489594187, Validation Accuracy: 35.66\n",
            "[32/150]: Training Loss: 1.4352122190475465, Training Accuracy: 60.295\n",
            "Validation Loss: 2.8204059456564057, Validation Accuracy: 36.43\n",
            "[33/150]: Training Loss: 1.3806078368186951, Training Accuracy: 61.585\n",
            "Validation Loss: 2.876485233853577, Validation Accuracy: 34.85\n",
            "[34/150]: Training Loss: 1.3117412397384645, Training Accuracy: 63.325\n",
            "Validation Loss: 2.8764415660481544, Validation Accuracy: 36.16\n",
            "[35/150]: Training Loss: 1.2477456188201905, Training Accuracy: 64.815\n",
            "Validation Loss: 2.959255384032134, Validation Accuracy: 35.83\n",
            "[36/150]: Training Loss: 1.178989047718048, Training Accuracy: 66.845\n",
            "Validation Loss: 3.055402055667464, Validation Accuracy: 35.68\n",
            "[37/150]: Training Loss: 1.1195641567230226, Training Accuracy: 68.255\n",
            "Validation Loss: 3.092683092044417, Validation Accuracy: 35.74\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 19.867750665944094, Test Accuracy: 12.24\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>12.24</td></tr><tr><td>Test Loss</td><td>19.86775</td></tr><tr><td>Train Accuracy</td><td>68.255</td></tr><tr><td>Train Loss</td><td>1.11956</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.001 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/wgvfp3rx</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_050220-wgvfp3rx/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.0015 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_050736-gnfp4sxh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">learning_rate=0.0015 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.262849729156494, Training Accuracy: 4.9725\n",
            "Validation Loss: 3.9988777105975304, Validation Accuracy: 9.32\n",
            "[2/150]: Training Loss: 3.787733755874634, Training Accuracy: 12.5275\n",
            "Validation Loss: 3.666901140455987, Validation Accuracy: 14.13\n",
            "[3/150]: Training Loss: 3.5222632232666014, Training Accuracy: 16.975\n",
            "Validation Loss: 3.430799526773441, Validation Accuracy: 18.28\n",
            "[4/150]: Training Loss: 3.3261954177856445, Training Accuracy: 20.0275\n",
            "Validation Loss: 3.268884590476941, Validation Accuracy: 20.25\n",
            "[5/150]: Training Loss: 3.1651099575042725, Training Accuracy: 22.825\n",
            "Validation Loss: 3.140599861266507, Validation Accuracy: 23.63\n",
            "[6/150]: Training Loss: 3.0220409996032713, Training Accuracy: 25.57\n",
            "Validation Loss: 3.062152488975768, Validation Accuracy: 24.92\n",
            "[7/150]: Training Loss: 2.9046311878204345, Training Accuracy: 27.855\n",
            "Validation Loss: 2.9628464735237654, Validation Accuracy: 26.95\n",
            "[8/150]: Training Loss: 2.7910710647583006, Training Accuracy: 30.235\n",
            "Validation Loss: 2.8832454301749064, Validation Accuracy: 28.14\n",
            "[9/150]: Training Loss: 2.687530333709717, Training Accuracy: 32.2625\n",
            "Validation Loss: 2.8348786056421367, Validation Accuracy: 30.07\n",
            "[10/150]: Training Loss: 2.590290707015991, Training Accuracy: 34.1175\n",
            "Validation Loss: 2.7776184780582502, Validation Accuracy: 30.52\n",
            "[11/150]: Training Loss: 2.499223603057861, Training Accuracy: 36.12\n",
            "Validation Loss: 2.726046642680077, Validation Accuracy: 31.91\n",
            "[12/150]: Training Loss: 2.4020754039764403, Training Accuracy: 37.9725\n",
            "Validation Loss: 2.7060916757887337, Validation Accuracy: 32.51\n",
            "[13/150]: Training Loss: 2.302425242996216, Training Accuracy: 40.3075\n",
            "Validation Loss: 2.660059646436363, Validation Accuracy: 33.06\n",
            "[14/150]: Training Loss: 2.2182941759109496, Training Accuracy: 42.03\n",
            "Validation Loss: 2.647583461870813, Validation Accuracy: 34.15\n",
            "[15/150]: Training Loss: 2.1231776348114013, Training Accuracy: 43.9025\n",
            "Validation Loss: 2.6469775620539475, Validation Accuracy: 34.32\n",
            "[16/150]: Training Loss: 2.030972394180298, Training Accuracy: 45.9525\n",
            "Validation Loss: 2.7037209963342947, Validation Accuracy: 32.86\n",
            "[17/150]: Training Loss: 1.9431676984786987, Training Accuracy: 47.91\n",
            "Validation Loss: 2.5850457507333937, Validation Accuracy: 36.27\n",
            "[18/150]: Training Loss: 1.8313071418762208, Training Accuracy: 50.255\n",
            "Validation Loss: 2.699979861071155, Validation Accuracy: 35.5\n",
            "[19/150]: Training Loss: 1.7440621503829956, Training Accuracy: 52.4725\n",
            "Validation Loss: 2.661453550028953, Validation Accuracy: 35.96\n",
            "[20/150]: Training Loss: 1.637422308921814, Training Accuracy: 54.8325\n",
            "Validation Loss: 2.7208387426509977, Validation Accuracy: 35.5\n",
            "[21/150]: Training Loss: 1.5425473594665526, Training Accuracy: 57.03\n",
            "Validation Loss: 2.766743406368669, Validation Accuracy: 35.3\n",
            "[22/150]: Training Loss: 1.4425379981994628, Training Accuracy: 59.42\n",
            "Validation Loss: 2.7848968460301684, Validation Accuracy: 36.36\n",
            "[23/150]: Training Loss: 1.346246865272522, Training Accuracy: 61.82\n",
            "Validation Loss: 2.918702983552483, Validation Accuracy: 35.2\n",
            "[24/150]: Training Loss: 1.2415513612747193, Training Accuracy: 64.48\n",
            "Validation Loss: 3.0769596373199657, Validation Accuracy: 34.71\n",
            "[25/150]: Training Loss: 1.1484121152877809, Training Accuracy: 66.9425\n",
            "Validation Loss: 3.111480196570135, Validation Accuracy: 35.56\n",
            "[26/150]: Training Loss: 1.049374456501007, Training Accuracy: 69.2\n",
            "Validation Loss: 3.2441035076311437, Validation Accuracy: 35.12\n",
            "[27/150]: Training Loss: 0.9539197593688965, Training Accuracy: 71.64\n",
            "Validation Loss: 3.3398004808243673, Validation Accuracy: 34.83\n",
            "[28/150]: Training Loss: 0.8686957097053528, Training Accuracy: 73.885\n",
            "Validation Loss: 3.526861637261263, Validation Accuracy: 35.38\n",
            "[29/150]: Training Loss: 0.7777377708911896, Training Accuracy: 76.4\n",
            "Validation Loss: 3.74925019938475, Validation Accuracy: 34.95\n",
            "[30/150]: Training Loss: 0.6971015272140503, Training Accuracy: 78.4225\n",
            "Validation Loss: 3.921683767039305, Validation Accuracy: 34.49\n",
            "[31/150]: Training Loss: 0.6319020359992981, Training Accuracy: 80.37\n",
            "Validation Loss: 4.265976667404175, Validation Accuracy: 33.7\n",
            "[32/150]: Training Loss: 0.5592198015213012, Training Accuracy: 82.41\n",
            "Validation Loss: 4.3743809985507065, Validation Accuracy: 34.21\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 32.802743437943185, Test Accuracy: 15.7\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>15.7</td></tr><tr><td>Test Loss</td><td>32.80274</td></tr><tr><td>Train Accuracy</td><td>82.41</td></tr><tr><td>Train Loss</td><td>0.55922</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/gnfp4sxh</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_050736-gnfp4sxh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Hyperparameter with lr:0.002 and wd:0.0004\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_051217-y92gs5m0</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">learning_rate=0.002 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.222224911499024, Training Accuracy: 5.3975\n",
            "Validation Loss: 3.937301506662065, Validation Accuracy: 9.22\n",
            "[2/150]: Training Loss: 3.7261308227539063, Training Accuracy: 13.09\n",
            "Validation Loss: 3.593827167134376, Validation Accuracy: 15.34\n",
            "[3/150]: Training Loss: 3.4419474758148194, Training Accuracy: 18.2775\n",
            "Validation Loss: 3.3379262875599465, Validation Accuracy: 19.89\n",
            "[4/150]: Training Loss: 3.242010182952881, Training Accuracy: 21.865\n",
            "Validation Loss: 3.2397833553848754, Validation Accuracy: 21.54\n",
            "[5/150]: Training Loss: 3.074250465774536, Training Accuracy: 24.8525\n",
            "Validation Loss: 3.2218855049959414, Validation Accuracy: 22.29\n",
            "[6/150]: Training Loss: 2.9360343181610107, Training Accuracy: 27.3175\n",
            "Validation Loss: 2.9865669110778033, Validation Accuracy: 26.78\n",
            "[7/150]: Training Loss: 2.801424619293213, Training Accuracy: 30.0175\n",
            "Validation Loss: 2.881270451150882, Validation Accuracy: 28.82\n",
            "[8/150]: Training Loss: 2.688298546409607, Training Accuracy: 32.05\n",
            "Validation Loss: 2.8182313017025113, Validation Accuracy: 30.07\n",
            "[9/150]: Training Loss: 2.5692677375793456, Training Accuracy: 34.84\n",
            "Validation Loss: 2.7818179950592623, Validation Accuracy: 30.94\n",
            "[10/150]: Training Loss: 2.454072025489807, Training Accuracy: 37.1425\n",
            "Validation Loss: 2.741547807766374, Validation Accuracy: 32.13\n",
            "[11/150]: Training Loss: 2.341491235733032, Training Accuracy: 39.3875\n",
            "Validation Loss: 2.735630521349087, Validation Accuracy: 32.51\n",
            "[12/150]: Training Loss: 2.2293454483032225, Training Accuracy: 41.4725\n",
            "Validation Loss: 2.690371492106444, Validation Accuracy: 33.37\n",
            "[13/150]: Training Loss: 2.1135470266342162, Training Accuracy: 43.935\n",
            "Validation Loss: 2.7198572918108312, Validation Accuracy: 34.01\n",
            "[14/150]: Training Loss: 1.9979984771728516, Training Accuracy: 46.1675\n",
            "Validation Loss: 2.7182075719165195, Validation Accuracy: 34.3\n",
            "[15/150]: Training Loss: 1.8890921760559083, Training Accuracy: 49.265\n",
            "Validation Loss: 2.7245476724235873, Validation Accuracy: 34.8\n",
            "[16/150]: Training Loss: 1.7773400522232055, Training Accuracy: 51.53\n",
            "Validation Loss: 2.749075835677469, Validation Accuracy: 34.12\n",
            "[17/150]: Training Loss: 1.676476739501953, Training Accuracy: 53.69\n",
            "Validation Loss: 2.8863297662917216, Validation Accuracy: 34.72\n",
            "[18/150]: Training Loss: 1.5655937635421753, Training Accuracy: 56.19\n",
            "Validation Loss: 2.8975180911410385, Validation Accuracy: 35.07\n",
            "[19/150]: Training Loss: 1.4489710484504699, Training Accuracy: 59.165\n",
            "Validation Loss: 2.9350054689273715, Validation Accuracy: 34.48\n",
            "[20/150]: Training Loss: 1.3497021337509156, Training Accuracy: 61.3125\n",
            "Validation Loss: 3.0767477864672426, Validation Accuracy: 34.78\n",
            "[21/150]: Training Loss: 1.2329449357032776, Training Accuracy: 64.19\n",
            "Validation Loss: 3.22720639113408, Validation Accuracy: 33.72\n",
            "[22/150]: Training Loss: 1.1406824831962585, Training Accuracy: 66.7375\n",
            "Validation Loss: 3.406786183642734, Validation Accuracy: 33.27\n",
            "[23/150]: Training Loss: 1.044043209552765, Training Accuracy: 69.1625\n",
            "Validation Loss: 3.664752894905722, Validation Accuracy: 32.75\n",
            "[24/150]: Training Loss: 0.9549756371498108, Training Accuracy: 71.1525\n",
            "Validation Loss: 3.7399451838936777, Validation Accuracy: 32.73\n",
            "[25/150]: Training Loss: 0.8772646800518036, Training Accuracy: 73.25\n",
            "Validation Loss: 3.9628275534149946, Validation Accuracy: 33.22\n",
            "[26/150]: Training Loss: 0.7976884460449218, Training Accuracy: 75.4625\n",
            "Validation Loss: 4.143224073823091, Validation Accuracy: 32.26\n",
            "[27/150]: Training Loss: 0.7417024869441986, Training Accuracy: 76.86\n",
            "Validation Loss: 4.497031521645321, Validation Accuracy: 32.38\n",
            "[28/150]: Training Loss: 0.682380113697052, Training Accuracy: 78.7575\n",
            "Validation Loss: 4.677568254956774, Validation Accuracy: 32.16\n",
            "Early stopping!\n",
            "**********************************************************************\n",
            "Test Loss: 35.528370875461846, Test Accuracy: 11.85\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>11.85</td></tr><tr><td>Test Loss</td><td>35.52837</td></tr><tr><td>Train Accuracy</td><td>78.7575</td></tr><tr><td>Train Loss</td><td>0.68238</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.002 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning/runs/y92gs5m0</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB-HyperParameterTuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_051217-y92gs5m0/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "learning_rates = [9e-04, 95e-05, 1e-03, 15e-04, 2e-03]\n",
        "wd = 4e-04\n",
        "for lr in learning_rates:\n",
        "\n",
        "  print('='*50)\n",
        "  print(f'Hyperparameter with lr:{lr} and wd:{wd}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {'learning_rate': lr,\n",
        "                      'weight_decay' : wd\n",
        "                      }\n",
        "  # Load the model\n",
        "  model = LeNet5().to(device)\n",
        "\n",
        "  # Optimizer and scheduler setup\n",
        "  optimizer = LAMB(model.parameters(), lr=lr, weight_decay=wd)\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "  # Training\n",
        "  run_training(num_epochs,\n",
        "                model,\n",
        "                train_loader,\n",
        "                validation_loader,\n",
        "                test_loader,\n",
        "                optimizer,\n",
        "                scheduler,\n",
        "                criterion,\n",
        "                device,\n",
        "                'LAMB-HyperParameterTuning',\n",
        "                hyperparameters=hyperparameters,\n",
        "                is_wandb = True,\n",
        "                n_epochs_stop = 10\n",
        "  )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LAMB BaseLine B-Size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "90b585318084475b9543b3226230d373",
            "5f3a33bc6a334c9e8c5886caa5f015ca",
            "46c9d83bf8af443bb376ed4858ce35f7",
            "2402e482be7e484fa98ae3f60f68d95a",
            "e8040d3a83de41319a2a836def914b1b",
            "0b4b10bb8bff4d40afa8df981440fe43",
            "3b0b3657d30547d7abe702d6c1e7b7c4",
            "17ac4efa9cf148e5be69edbc5b0bdecf",
            "f5fd8db807e144578a2e20762d7369d0",
            "32c759d7fff64701a6ad61b38ac63187",
            "557cf2de74314915b7204d9055fa6987",
            "c5bb24dc0f56483b88a0efbfa2a1c8ee",
            "67aa8f8c2b244c9a9a3bb11caf491247",
            "09b762f5ba784066a9408ffcfdea5b2e",
            "6a345ff7386643eeb7a5b190d69d2e0e",
            "8f4783e2060a4295bb68036a4a7310d9",
            "aa6aa819c1fd4776ac47af588aaaaacd",
            "64224c777f01418e904dcd30ecd7c5ef",
            "c1dbd12595384bc6a0240aaeb16014dc",
            "6aa92cf922724ac08c45385ff8a58447",
            "99929754d3094d03a5f311177ac26cb3",
            "9ea517158b974c5da17899e3fea4fc3b",
            "bb2ee36dd3c04926b10b832928d7d0a0",
            "9d88657b39fd4b169d61b1b8d240e6ff"
          ]
        },
        "id": "7sUsHkiHgURG",
        "outputId": "3829f79a-3d06-48ee-fea5-a00c18f8744b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:uqgfhn52) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train Accuracy</td><td>22.668</td></tr><tr><td>Train Loss</td><td>3.18342</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015026019100214134 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/uqgfhn52' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/uqgfhn52</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_051725-uqgfhn52/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:uqgfhn52). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/Project/wandb/run-20240613_052010-62vz5e00</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">learning_rate=0.0015 weight_decay=0.0004</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/150]: Training Loss: 4.170614353226274, Training Accuracy: 6.554\n",
            "Validation Loss: 3.8419871087286883, Validation Accuracy: 11.55\n",
            "[2/150]: Training Loss: 3.73113738697813, Training Accuracy: 13.326\n",
            "Validation Loss: 3.5141605601948536, Validation Accuracy: 17.24\n",
            "[3/150]: Training Loss: 3.4963422099037853, Training Accuracy: 17.148\n",
            "Validation Loss: 3.329459586720558, Validation Accuracy: 21.14\n",
            "[4/150]: Training Loss: 3.32537763838268, Training Accuracy: 20.17\n",
            "Validation Loss: 3.1594036445496188, Validation Accuracy: 23.38\n",
            "[5/150]: Training Loss: 3.1821046982274948, Training Accuracy: 22.724\n",
            "Validation Loss: 3.024734082495331, Validation Accuracy: 25.42\n",
            "[6/150]: Training Loss: 3.0576654736648132, Training Accuracy: 24.838\n",
            "Validation Loss: 2.917888655024729, Validation Accuracy: 27.48\n",
            "[7/150]: Training Loss: 2.9461568444586166, Training Accuracy: 26.996\n",
            "Validation Loss: 2.8047209317517128, Validation Accuracy: 29.77\n",
            "[8/150]: Training Loss: 2.860208951298843, Training Accuracy: 28.704\n",
            "Validation Loss: 2.7236505541831826, Validation Accuracy: 30.98\n",
            "[9/150]: Training Loss: 2.7667418916512023, Training Accuracy: 30.53\n",
            "Validation Loss: 2.6368031137308496, Validation Accuracy: 33.13\n",
            "[10/150]: Training Loss: 2.6879202682343895, Training Accuracy: 31.998\n",
            "Validation Loss: 2.536134794259527, Validation Accuracy: 35.32\n",
            "[11/150]: Training Loss: 2.61040174458033, Training Accuracy: 33.4\n",
            "Validation Loss: 2.4932953764678567, Validation Accuracy: 36.12\n",
            "[12/150]: Training Loss: 2.546117087306879, Training Accuracy: 34.894\n",
            "Validation Loss: 2.4478625689342524, Validation Accuracy: 37.12\n",
            "[13/150]: Training Loss: 2.4885423736803975, Training Accuracy: 35.89\n",
            "Validation Loss: 2.4252931342762745, Validation Accuracy: 37.55\n",
            "[14/150]: Training Loss: 2.4414472836057852, Training Accuracy: 37.026\n",
            "Validation Loss: 2.3621389410298343, Validation Accuracy: 39.2\n",
            "[15/150]: Training Loss: 2.3877986550636, Training Accuracy: 37.84\n",
            "Validation Loss: 2.3034424402151896, Validation Accuracy: 40.21\n",
            "[16/150]: Training Loss: 2.3379326612138382, Training Accuracy: 39.018\n",
            "Validation Loss: 2.272260831419829, Validation Accuracy: 41.24\n",
            "[17/150]: Training Loss: 2.300395258247395, Training Accuracy: 39.968\n",
            "Validation Loss: 2.2585707120834644, Validation Accuracy: 40.6\n",
            "[18/150]: Training Loss: 2.254751528315532, Training Accuracy: 40.976\n",
            "Validation Loss: 2.2186143770339384, Validation Accuracy: 42.07\n",
            "[19/150]: Training Loss: 2.2090765830805843, Training Accuracy: 42.026\n",
            "Validation Loss: 2.1868586600965756, Validation Accuracy: 42.61\n",
            "[20/150]: Training Loss: 2.183374183562101, Training Accuracy: 42.532\n",
            "Validation Loss: 2.184412774007032, Validation Accuracy: 42.58\n",
            "[21/150]: Training Loss: 2.1446489868566507, Training Accuracy: 43.298\n",
            "Validation Loss: 2.144960983543639, Validation Accuracy: 43.98\n",
            "[22/150]: Training Loss: 2.1038296910198144, Training Accuracy: 44.234\n",
            "Validation Loss: 2.14452546493263, Validation Accuracy: 44.01\n",
            "[23/150]: Training Loss: 2.0707620507311026, Training Accuracy: 44.894\n",
            "Validation Loss: 2.098228795513226, Validation Accuracy: 45.23\n",
            "[24/150]: Training Loss: 2.043932166093451, Training Accuracy: 45.518\n",
            "Validation Loss: 2.0813077680624215, Validation Accuracy: 45.38\n",
            "[25/150]: Training Loss: 2.0066164360021994, Training Accuracy: 46.274\n",
            "Validation Loss: 2.075542102953431, Validation Accuracy: 45.85\n",
            "[26/150]: Training Loss: 1.9791695739302184, Training Accuracy: 46.988\n",
            "Validation Loss: 2.0774263060016995, Validation Accuracy: 45.28\n",
            "[27/150]: Training Loss: 1.948626570232079, Training Accuracy: 47.584\n",
            "Validation Loss: 2.0519798697939344, Validation Accuracy: 46.31\n",
            "[28/150]: Training Loss: 1.9167836584398508, Training Accuracy: 48.236\n",
            "Validation Loss: 2.0201504807563344, Validation Accuracy: 46.88\n",
            "[29/150]: Training Loss: 1.8909891124271676, Training Accuracy: 48.752\n",
            "Validation Loss: 2.040525470569635, Validation Accuracy: 46.57\n",
            "[30/150]: Training Loss: 1.8726914470153087, Training Accuracy: 49.618\n",
            "Validation Loss: 2.0113253760489687, Validation Accuracy: 47.44\n",
            "[31/150]: Training Loss: 1.8444365990131408, Training Accuracy: 50.096\n",
            "Validation Loss: 2.0178289990516225, Validation Accuracy: 47.23\n",
            "[32/150]: Training Loss: 1.8157384923047117, Training Accuracy: 50.462\n",
            "Validation Loss: 1.9997166759648901, Validation Accuracy: 47.55\n",
            "[33/150]: Training Loss: 1.7931588938474046, Training Accuracy: 51.29\n",
            "Validation Loss: 1.9950028824958073, Validation Accuracy: 47.93\n",
            "[34/150]: Training Loss: 1.770590110355631, Training Accuracy: 51.824\n",
            "Validation Loss: 1.993164770162789, Validation Accuracy: 48.12\n",
            "[35/150]: Training Loss: 1.7467985225607976, Training Accuracy: 52.03\n",
            "Validation Loss: 1.9869080242837311, Validation Accuracy: 47.9\n",
            "[36/150]: Training Loss: 1.7260596163742377, Training Accuracy: 52.556\n",
            "Validation Loss: 1.9724081488931255, Validation Accuracy: 48.61\n",
            "[37/150]: Training Loss: 1.7053224419998696, Training Accuracy: 53.142\n",
            "Validation Loss: 1.9826935643603087, Validation Accuracy: 48.29\n",
            "[38/150]: Training Loss: 1.67785135681367, Training Accuracy: 53.82\n",
            "Validation Loss: 1.9470138079041888, Validation Accuracy: 49.88\n",
            "[39/150]: Training Loss: 1.6623152171254463, Training Accuracy: 54.074\n",
            "Validation Loss: 1.9769204634769706, Validation Accuracy: 48.87\n",
            "[40/150]: Training Loss: 1.6364040380853522, Training Accuracy: 54.652\n",
            "Validation Loss: 1.9554897744184847, Validation Accuracy: 49.57\n",
            "[41/150]: Training Loss: 1.6296177715291758, Training Accuracy: 54.87\n",
            "Validation Loss: 1.9755018660976629, Validation Accuracy: 49.42\n",
            "[42/150]: Training Loss: 1.6172699540319955, Training Accuracy: 55.052\n",
            "Validation Loss: 1.9689236112460968, Validation Accuracy: 49.6\n",
            "[43/150]: Training Loss: 1.5901159763793506, Training Accuracy: 55.706\n",
            "Validation Loss: 1.9709602108426914, Validation Accuracy: 49.39\n",
            "[44/150]: Training Loss: 1.5688080241917954, Training Accuracy: 56.494\n",
            "Validation Loss: 1.944002225140857, Validation Accuracy: 50.24\n",
            "[45/150]: Training Loss: 1.5468424783490808, Training Accuracy: 57.02\n",
            "Validation Loss: 1.9809717410688947, Validation Accuracy: 49.68\n",
            "[46/150]: Training Loss: 1.5288271441331605, Training Accuracy: 57.372\n",
            "Validation Loss: 1.9420389149599016, Validation Accuracy: 50.41\n",
            "[47/150]: Training Loss: 1.527083154453341, Training Accuracy: 57.472\n",
            "Validation Loss: 1.9570772792123685, Validation Accuracy: 49.71\n",
            "[48/150]: Training Loss: 1.5049020071773578, Training Accuracy: 57.818\n",
            "Validation Loss: 1.954159548328181, Validation Accuracy: 50.38\n",
            "[49/150]: Training Loss: 1.48557850992893, Training Accuracy: 58.67\n",
            "Validation Loss: 1.934345255232161, Validation Accuracy: 50.33\n",
            "[50/150]: Training Loss: 1.461377340052134, Training Accuracy: 58.866\n",
            "Validation Loss: 1.9670750221629052, Validation Accuracy: 50.09\n",
            "[51/150]: Training Loss: 1.4531892761397545, Training Accuracy: 59.148\n",
            "Validation Loss: 1.9439144878630426, Validation Accuracy: 50.57\n",
            "[52/150]: Training Loss: 1.4365854823528348, Training Accuracy: 59.4\n",
            "Validation Loss: 1.9623823484797387, Validation Accuracy: 50.49\n",
            "[53/150]: Training Loss: 1.4231898410393453, Training Accuracy: 59.886\n",
            "Validation Loss: 1.9759472274476555, Validation Accuracy: 50.14\n",
            "[54/150]: Training Loss: 1.408926703664653, Training Accuracy: 60.114\n",
            "Validation Loss: 1.924273559242297, Validation Accuracy: 51.21\n",
            "[55/150]: Training Loss: 1.3876726690613095, Training Accuracy: 60.616\n",
            "Validation Loss: 1.9458329692767684, Validation Accuracy: 50.63\n",
            "[56/150]: Training Loss: 1.375196378478004, Training Accuracy: 61.12\n",
            "Validation Loss: 1.9410056468028172, Validation Accuracy: 51.4\n",
            "[57/150]: Training Loss: 1.3586041162081082, Training Accuracy: 61.634\n",
            "Validation Loss: 1.9649552509283563, Validation Accuracy: 50.61\n",
            "[58/150]: Training Loss: 1.3581253530271828, Training Accuracy: 61.412\n",
            "Validation Loss: 1.9388997919240576, Validation Accuracy: 51.27\n",
            "[59/150]: Training Loss: 1.3380669855400729, Training Accuracy: 61.932\n",
            "Validation Loss: 1.9778220661126884, Validation Accuracy: 50.91\n",
            "[60/150]: Training Loss: 1.3257979125622898, Training Accuracy: 62.056\n",
            "Validation Loss: 1.9304483665782175, Validation Accuracy: 51.44\n",
            "[61/150]: Training Loss: 1.316665162896866, Training Accuracy: 62.458\n",
            "Validation Loss: 1.9412351808730204, Validation Accuracy: 51.61\n",
            "[62/150]: Training Loss: 1.2979835793947625, Training Accuracy: 62.832\n",
            "Validation Loss: 1.9522758213577756, Validation Accuracy: 51.6\n",
            "[63/150]: Training Loss: 1.2900130991130838, Training Accuracy: 63.092\n",
            "Validation Loss: 1.9639577113898696, Validation Accuracy: 51.23\n",
            "[64/150]: Training Loss: 1.2804708784955847, Training Accuracy: 63.436\n",
            "Validation Loss: 1.9787959422275518, Validation Accuracy: 51.42\n",
            "[65/150]: Training Loss: 1.255796139959789, Training Accuracy: 63.948\n",
            "Validation Loss: 1.9797948439409778, Validation Accuracy: 51.63\n",
            "[66/150]: Training Loss: 1.25389591042343, Training Accuracy: 64.23\n",
            "Validation Loss: 1.97708031554131, Validation Accuracy: 52.19\n",
            "[67/150]: Training Loss: 1.2357215599330795, Training Accuracy: 64.366\n",
            "Validation Loss: 1.9641305322100402, Validation Accuracy: 52.22\n",
            "[68/150]: Training Loss: 1.2240538022402303, Training Accuracy: 64.862\n",
            "Validation Loss: 1.9815536661512534, Validation Accuracy: 51.47\n",
            "[69/150]: Training Loss: 1.2087419308969736, Training Accuracy: 65.136\n",
            "Validation Loss: 1.979879951021474, Validation Accuracy: 51.77\n",
            "[70/150]: Training Loss: 1.1984577734604516, Training Accuracy: 65.552\n",
            "Validation Loss: 2.005889118856685, Validation Accuracy: 51.82\n",
            "[71/150]: Training Loss: 1.184933677506264, Training Accuracy: 66.026\n",
            "Validation Loss: 1.9805337274150483, Validation Accuracy: 51.89\n",
            "[72/150]: Training Loss: 1.1769923466398282, Training Accuracy: 65.964\n",
            "Validation Loss: 2.0164508561419834, Validation Accuracy: 51.97\n",
            "[73/150]: Training Loss: 1.1639809905720488, Training Accuracy: 66.116\n",
            "Validation Loss: 2.0093113024523306, Validation Accuracy: 51.75\n",
            "[74/150]: Training Loss: 1.1529584921077085, Training Accuracy: 66.55\n",
            "Validation Loss: 2.017468781987573, Validation Accuracy: 51.53\n",
            "[75/150]: Training Loss: 1.1453676276347216, Training Accuracy: 66.758\n",
            "Validation Loss: 2.011715882902692, Validation Accuracy: 51.48\n",
            "[76/150]: Training Loss: 1.1254654065574832, Training Accuracy: 67.396\n",
            "Validation Loss: 2.0016076625532406, Validation Accuracy: 51.93\n",
            "[77/150]: Training Loss: 1.1255306048161537, Training Accuracy: 67.168\n",
            "Validation Loss: 2.037281950567938, Validation Accuracy: 51.54\n",
            "[78/150]: Training Loss: 1.107588133391212, Training Accuracy: 67.898\n",
            "Validation Loss: 2.0207215995545598, Validation Accuracy: 52.25\n",
            "[79/150]: Training Loss: 1.0974091778478354, Training Accuracy: 67.988\n",
            "Validation Loss: 2.0399385941256383, Validation Accuracy: 52.27\n",
            "[80/150]: Training Loss: 1.0841643994726489, Training Accuracy: 68.482\n",
            "Validation Loss: 2.0396120669735467, Validation Accuracy: 51.88\n",
            "[81/150]: Training Loss: 1.086065025128367, Training Accuracy: 68.472\n",
            "Validation Loss: 2.0602660406926634, Validation Accuracy: 52.23\n",
            "[82/150]: Training Loss: 1.068733287741766, Training Accuracy: 68.792\n",
            "Validation Loss: 2.038099098357425, Validation Accuracy: 52.32\n",
            "[83/150]: Training Loss: 1.0567113834116466, Training Accuracy: 69.072\n",
            "Validation Loss: 2.0566319333519907, Validation Accuracy: 52.0\n",
            "[84/150]: Training Loss: 1.0568410671123154, Training Accuracy: 69.164\n",
            "Validation Loss: 2.031417142054078, Validation Accuracy: 52.23\n",
            "[85/150]: Training Loss: 1.0462324290019471, Training Accuracy: 69.518\n",
            "Validation Loss: 2.039376434247205, Validation Accuracy: 52.34\n",
            "[86/150]: Training Loss: 1.0314530159353905, Training Accuracy: 69.866\n",
            "Validation Loss: 2.0698205103540115, Validation Accuracy: 52.02\n",
            "[87/150]: Training Loss: 1.0182559825956363, Training Accuracy: 70.136\n",
            "Validation Loss: 2.063336102825821, Validation Accuracy: 52.83\n",
            "[88/150]: Training Loss: 1.010449574350396, Training Accuracy: 70.25\n",
            "Validation Loss: 2.077486888618226, Validation Accuracy: 52.3\n",
            "[89/150]: Training Loss: 1.0035706778316547, Training Accuracy: 70.786\n",
            "Validation Loss: 2.095621291998845, Validation Accuracy: 52.44\n",
            "[90/150]: Training Loss: 0.9991849294251494, Training Accuracy: 70.812\n",
            "Validation Loss: 2.069785719464539, Validation Accuracy: 52.4\n",
            "[91/150]: Training Loss: 0.993351522995078, Training Accuracy: 70.858\n",
            "Validation Loss: 2.1024031069627993, Validation Accuracy: 52.29\n",
            "[92/150]: Training Loss: 0.9726321048215222, Training Accuracy: 71.618\n",
            "Validation Loss: 2.084312925672835, Validation Accuracy: 52.53\n",
            "[93/150]: Training Loss: 0.97342309279515, Training Accuracy: 71.502\n",
            "Validation Loss: 2.0946866744642803, Validation Accuracy: 52.66\n",
            "[94/150]: Training Loss: 0.963803626920866, Training Accuracy: 71.718\n",
            "Validation Loss: 2.110511908105984, Validation Accuracy: 52.0\n",
            "[95/150]: Training Loss: 0.9580129440635672, Training Accuracy: 71.984\n",
            "Validation Loss: 2.111149025570815, Validation Accuracy: 52.13\n",
            "[96/150]: Training Loss: 0.9513878270869365, Training Accuracy: 72.204\n",
            "Validation Loss: 2.1115560136782894, Validation Accuracy: 52.52\n",
            "[97/150]: Training Loss: 0.938226883673607, Training Accuracy: 72.542\n",
            "Validation Loss: 2.1242388023692333, Validation Accuracy: 52.65\n",
            "[98/150]: Training Loss: 0.938509788811969, Training Accuracy: 72.476\n",
            "Validation Loss: 2.1135271635784467, Validation Accuracy: 52.82\n",
            "[99/150]: Training Loss: 0.9283110121326983, Training Accuracy: 72.674\n",
            "Validation Loss: 2.125285923860635, Validation Accuracy: 52.06\n",
            "[100/150]: Training Loss: 0.9165082442790956, Training Accuracy: 73.184\n",
            "Validation Loss: 2.1202975777304096, Validation Accuracy: 52.38\n",
            "[101/150]: Training Loss: 0.9109463012584335, Training Accuracy: 72.998\n",
            "Validation Loss: 2.136450658937928, Validation Accuracy: 52.42\n",
            "[102/150]: Training Loss: 0.9098046744418571, Training Accuracy: 73.26\n",
            "Validation Loss: 2.1267288725846893, Validation Accuracy: 52.86\n",
            "[103/150]: Training Loss: 0.8908002294237961, Training Accuracy: 73.838\n",
            "Validation Loss: 2.125086438883642, Validation Accuracy: 52.34\n",
            "[104/150]: Training Loss: 0.8947355315432219, Training Accuracy: 73.496\n",
            "Validation Loss: 2.13778414771815, Validation Accuracy: 52.62\n",
            "[105/150]: Training Loss: 0.8788276913830692, Training Accuracy: 74.106\n",
            "Validation Loss: 2.153025217876313, Validation Accuracy: 52.42\n",
            "[106/150]: Training Loss: 0.8798901442524112, Training Accuracy: 74.082\n",
            "Validation Loss: 2.1569059441803367, Validation Accuracy: 52.12\n",
            "[107/150]: Training Loss: 0.8666944346388282, Training Accuracy: 74.51\n",
            "Validation Loss: 2.1608687851839004, Validation Accuracy: 52.57\n",
            "[108/150]: Training Loss: 0.863055142485882, Training Accuracy: 74.528\n",
            "Validation Loss: 2.152739950805713, Validation Accuracy: 52.64\n",
            "[109/150]: Training Loss: 0.8662346141874943, Training Accuracy: 74.474\n",
            "Validation Loss: 2.14941197823567, Validation Accuracy: 52.71\n",
            "[110/150]: Training Loss: 0.8472307874342365, Training Accuracy: 75.102\n",
            "Validation Loss: 2.1724644390640746, Validation Accuracy: 52.69\n",
            "[111/150]: Training Loss: 0.8462071400469221, Training Accuracy: 75.26\n",
            "Validation Loss: 2.166171987345264, Validation Accuracy: 52.5\n",
            "[112/150]: Training Loss: 0.8393054546221442, Training Accuracy: 75.156\n",
            "Validation Loss: 2.16822886315121, Validation Accuracy: 52.79\n",
            "[113/150]: Training Loss: 0.835232794132379, Training Accuracy: 75.426\n",
            "Validation Loss: 2.1755759412316, Validation Accuracy: 52.8\n",
            "[114/150]: Training Loss: 0.8176318519484357, Training Accuracy: 75.594\n",
            "Validation Loss: 2.1797922325741714, Validation Accuracy: 52.63\n",
            "[115/150]: Training Loss: 0.8166115129618998, Training Accuracy: 75.654\n",
            "Validation Loss: 2.1856938577761316, Validation Accuracy: 52.44\n",
            "[116/150]: Training Loss: 0.8185412460733252, Training Accuracy: 75.768\n",
            "Validation Loss: 2.178807595732865, Validation Accuracy: 52.51\n",
            "[117/150]: Training Loss: 0.819738648203023, Training Accuracy: 75.68\n",
            "Validation Loss: 2.196637267519714, Validation Accuracy: 52.53\n",
            "[118/150]: Training Loss: 0.8139445048463924, Training Accuracy: 76.114\n",
            "Validation Loss: 2.1727140124436395, Validation Accuracy: 52.14\n",
            "[119/150]: Training Loss: 0.804041659359432, Training Accuracy: 76.238\n",
            "Validation Loss: 2.189874280789855, Validation Accuracy: 52.54\n",
            "[120/150]: Training Loss: 0.8070289515473349, Training Accuracy: 75.962\n",
            "Validation Loss: 2.1908302922157725, Validation Accuracy: 52.74\n",
            "[121/150]: Training Loss: 0.7972686002626443, Training Accuracy: 76.462\n",
            "Validation Loss: 2.183206063167305, Validation Accuracy: 52.9\n",
            "[122/150]: Training Loss: 0.7931420375090426, Training Accuracy: 76.7\n",
            "Validation Loss: 2.1991693654637428, Validation Accuracy: 52.88\n",
            "[123/150]: Training Loss: 0.7942516611284002, Training Accuracy: 76.382\n",
            "Validation Loss: 2.1899024916302627, Validation Accuracy: 52.96\n",
            "[124/150]: Training Loss: 0.7901588624243236, Training Accuracy: 76.912\n",
            "Validation Loss: 2.1976229795225106, Validation Accuracy: 52.76\n",
            "[125/150]: Training Loss: 0.784064800881059, Training Accuracy: 76.852\n",
            "Validation Loss: 2.197301295152895, Validation Accuracy: 52.94\n",
            "[126/150]: Training Loss: 0.7810554346236427, Training Accuracy: 77.018\n",
            "Validation Loss: 2.1978831883448704, Validation Accuracy: 53.05\n",
            "[127/150]: Training Loss: 0.7694210947855659, Training Accuracy: 77.242\n",
            "Validation Loss: 2.2037578973041216, Validation Accuracy: 52.8\n",
            "[128/150]: Training Loss: 0.771505500425768, Training Accuracy: 77.276\n",
            "Validation Loss: 2.204603326548437, Validation Accuracy: 52.61\n",
            "[129/150]: Training Loss: 0.7755528422039183, Training Accuracy: 77.05\n",
            "Validation Loss: 2.2066474340523885, Validation Accuracy: 52.48\n",
            "[130/150]: Training Loss: 0.7633897851190299, Training Accuracy: 77.462\n",
            "Validation Loss: 2.20657627294018, Validation Accuracy: 52.87\n",
            "[131/150]: Training Loss: 0.7619557766734487, Training Accuracy: 77.74\n",
            "Validation Loss: 2.2119038287241746, Validation Accuracy: 52.87\n",
            "[132/150]: Training Loss: 0.7639070795015301, Training Accuracy: 77.628\n",
            "Validation Loss: 2.214540675946861, Validation Accuracy: 52.93\n",
            "[133/150]: Training Loss: 0.7627752876800039, Training Accuracy: 77.624\n",
            "Validation Loss: 2.2126305232382126, Validation Accuracy: 52.92\n",
            "[134/150]: Training Loss: 0.762916150681503, Training Accuracy: 77.468\n",
            "Validation Loss: 2.213455740813237, Validation Accuracy: 52.87\n",
            "[135/150]: Training Loss: 0.7556408758434798, Training Accuracy: 77.858\n",
            "Validation Loss: 2.2093218823147427, Validation Accuracy: 52.78\n",
            "[136/150]: Training Loss: 0.7546808309567249, Training Accuracy: 77.614\n",
            "Validation Loss: 2.215512813276546, Validation Accuracy: 52.82\n",
            "[137/150]: Training Loss: 0.7569507613130237, Training Accuracy: 77.856\n",
            "Validation Loss: 2.214977786799145, Validation Accuracy: 52.94\n",
            "[138/150]: Training Loss: 0.7538443226414873, Training Accuracy: 77.938\n",
            "Validation Loss: 2.215168529255375, Validation Accuracy: 52.96\n",
            "[139/150]: Training Loss: 0.7538767649084711, Training Accuracy: 77.666\n",
            "Validation Loss: 2.215025094664021, Validation Accuracy: 52.95\n",
            "[140/150]: Training Loss: 0.7476015420216123, Training Accuracy: 77.98\n",
            "Validation Loss: 2.2151690637989407, Validation Accuracy: 53.11\n",
            "[141/150]: Training Loss: 0.7429782649135346, Training Accuracy: 78.256\n",
            "Validation Loss: 2.214695118794775, Validation Accuracy: 52.91\n",
            "[142/150]: Training Loss: 0.7340887488077974, Training Accuracy: 78.538\n",
            "Validation Loss: 2.216404147968171, Validation Accuracy: 53.08\n",
            "[143/150]: Training Loss: 0.7499228092029576, Training Accuracy: 78.16\n",
            "Validation Loss: 2.216663356799229, Validation Accuracy: 52.99\n",
            "[144/150]: Training Loss: 0.739901978646398, Training Accuracy: 78.208\n",
            "Validation Loss: 2.216373413231722, Validation Accuracy: 53.03\n",
            "[145/150]: Training Loss: 0.7356343204560487, Training Accuracy: 78.332\n",
            "Validation Loss: 2.21599667087482, Validation Accuracy: 52.82\n",
            "[146/150]: Training Loss: 0.7417128108575216, Training Accuracy: 78.1\n",
            "Validation Loss: 2.216853774277268, Validation Accuracy: 53.06\n",
            "[147/150]: Training Loss: 0.7406589664385447, Training Accuracy: 78.444\n",
            "Validation Loss: 2.2168655562552675, Validation Accuracy: 52.95\n",
            "[148/150]: Training Loss: 0.7310213162694745, Training Accuracy: 78.62\n",
            "Validation Loss: 2.216719139913085, Validation Accuracy: 52.99\n",
            "[149/150]: Training Loss: 0.7304428781923431, Training Accuracy: 78.478\n",
            "Validation Loss: 2.216782635943905, Validation Accuracy: 53.01\n",
            "[150/150]: Training Loss: 0.7461780087493569, Training Accuracy: 78.148\n",
            "Validation Loss: 2.2168066478838586, Validation Accuracy: 53.01\n",
            "**********************************************************************\n",
            "Test Loss: 2.2168066478838586, Test Accuracy: 53.01\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr><tr><td>Train Accuracy</td><td></td></tr><tr><td>Train Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>53.01</td></tr><tr><td>Test Loss</td><td>2.21681</td></tr><tr><td>Train Accuracy</td><td>78.148</td></tr><tr><td>Train Loss</td><td>0.74618</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">learning_rate=0.0015 weight_decay=0.0004</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB/runs/62vz5e00</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240613_052010-62vz5e00/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "num_epochs = 150\n",
        "lr = 4.8/(2**5 *1e02) # approximately 15e-04\n",
        "wd = 4e-04\n",
        "\n",
        "hyperparameters = {'learning_rate': lr,\n",
        "                    'weight_decay' : wd\n",
        "                  }\n",
        "\n",
        "# Load the model\n",
        "model = LeNet5().to(device)\n",
        "\n",
        "# Optimizer and scheduler setup\n",
        "optimizer = LAMB(model.parameters(), learning_rate=lr, weight_decay=wd)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "# Training\n",
        "run_training(num_epochs, model, original_train_loader, original_test_loader, original_test_loader, optimizer, scheduler, criterion, device, optimizer_name='LAMB', hyperparameters=hyperparameters, is_wandb = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### LAMB Test Large Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 512\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234800-cxzhvadl</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/cxzhvadl' target=\"_blank\">batch_size=512 learning_rate=0.012 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/cxzhvadl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/cxzhvadl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 2.032588768005371, Test Accuracy: 47.49\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>47.49</td></tr><tr><td>Test Loss</td><td>2.03259</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=512 learning_rate=0.012 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/cxzhvadl' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/cxzhvadl</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234800-cxzhvadl/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 1024\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234807-j3op57h9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/j3op57h9' target=\"_blank\">batch_size=1024 learning_rate=0.024 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/j3op57h9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/j3op57h9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 2.2387969970703123, Test Accuracy: 42.42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>42.42</td></tr><tr><td>Test Loss</td><td>2.2388</td></tr><tr><td>Train Accuracy</td><td>42.978</td></tr><tr><td>Train Loss</td><td>2.20884</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=1024 learning_rate=0.024 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/j3op57h9' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/j3op57h9</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234807-j3op57h9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 2048\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234815-qvp88fuq</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/qvp88fuq' target=\"_blank\">batch_size=2048 learning_rate=0.048 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/qvp88fuq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/qvp88fuq</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 2.52529616355896, Test Accuracy: 36.42\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>36.42</td></tr><tr><td>Test Loss</td><td>2.5253</td></tr><tr><td>Train Accuracy</td><td>35.39</td></tr><tr><td>Train Loss</td><td>2.57354</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=2048 learning_rate=0.048 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/qvp88fuq' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/qvp88fuq</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234815-qvp88fuq/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 4096\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234826-8snpsfgb</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/8snpsfgb' target=\"_blank\">batch_size=4096 learning_rate=0.096 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/8snpsfgb' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/8snpsfgb</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 2.9222216606140137, Test Accuracy: 29.16\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>29.16</td></tr><tr><td>Test Loss</td><td>2.92222</td></tr><tr><td>Train Accuracy</td><td>26.796</td></tr><tr><td>Train Loss</td><td>3.01636</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=4096 learning_rate=0.096 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/8snpsfgb' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/8snpsfgb</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234826-8snpsfgb/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 8192\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234838-08ulbgo6</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/08ulbgo6' target=\"_blank\">batch_size=8192 learning_rate=0.192 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/08ulbgo6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/08ulbgo6</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 3.3192431131998696, Test Accuracy: 21.19\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>21.19</td></tr><tr><td>Test Loss</td><td>3.31924</td></tr><tr><td>Train Accuracy</td><td>19.494</td></tr><tr><td>Train Loss</td><td>3.4046</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=8192 learning_rate=0.192 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/08ulbgo6' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/08ulbgo6</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234838-08ulbgo6/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 16384\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234848-9o39fzf2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/9o39fzf2' target=\"_blank\">batch_size=16384 learning_rate=0.384 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/9o39fzf2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/9o39fzf2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 3.6979848543802896, Test Accuracy: 14.82\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>14.82</td></tr><tr><td>Test Loss</td><td>3.69798</td></tr><tr><td>Train Accuracy</td><td>13.586</td></tr><tr><td>Train Loss</td><td>3.75874</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=16384 learning_rate=0.384 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/9o39fzf2' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/9o39fzf2</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234848-9o39fzf2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Batch size: 32768\n",
            "==================================================\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "wandb version 0.18.0 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.17.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/ali/Repos/University/MLDL/mldl/wandb/run-20240912_234858-tuoafh0s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/tuoafh0s' target=\"_blank\">batch_size=32768 learning_rate=0.768 weight_decay=0.0001</a></strong> to <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/tuoafh0s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/tuoafh0s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "**********************************************************************\n",
            "Test Loss: 4.131630261739095, Test Accuracy: 7.73\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td></td></tr><tr><td>Test Loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Test Accuracy</td><td>7.73</td></tr><tr><td>Test Loss</td><td>4.13163</td></tr><tr><td>Train Accuracy</td><td>7.258</td></tr><tr><td>Train Loss</td><td>4.1532</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">batch_size=32768 learning_rate=0.768 weight_decay=0.0001</strong> at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/tuoafh0s' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup/runs/tuoafh0s</a><br/> View project at: <a href='https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup' target=\"_blank\">https://wandb.ai/mldlpolitofari733/cifar100-training-mldl2024-baseline-LAMB_Large_Batches_without_warmup</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240912_234858-tuoafh0s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# without warmup\n",
        "num_epochs = 150\n",
        "wd = 1e-04\n",
        "batch_sizes = [512, 1024, 2048, 4096, 8192, 16384 , 32768]\n",
        "lr = 4.8/(2**5 *1e02) # approximately 15e-04\n",
        "learning_rates = [lr * batch_size / 64.0 for batch_size in batch_sizes] # linear scale-up of learning rate\n",
        "# warmup_ratio = [1/320, 1/160, 1/80, 1/40, 1/20, 1/10, 1/5]\n",
        "\n",
        "for i, batch_size in enumerate(batch_sizes):\n",
        "  print('='*50)\n",
        "  print(f'Batch size: {batch_size}')\n",
        "  print('='*50)\n",
        "\n",
        "  hyperparameters = {\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rates[i],\n",
        "    'weight_decay' : wd\n",
        "  }\n",
        "\n",
        "  if batch_size <= 4096:\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= batch_size)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LAMB(model.parameters(), learning_rate=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LAMB_Large_Batches_without_warmup',\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )\n",
        "  else:\n",
        "    accumulation_steps = batch_size // 4096\n",
        "    # load data\n",
        "    data = CIFAR100Data(batch_size= 4096)\n",
        "    original_train_loader_large_batch, original_test_loader_large_batch = data.train_test()\n",
        "    # Load the model\n",
        "    model = LeNet5().to(device)\n",
        "    # Optimizer and scheduler setup\n",
        "    optimizer = LAMB(model.parameters(), learning_rate=lr, weight_decay=wd)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "\n",
        "    # Training\n",
        "    run_training(\n",
        "        num_epochs,\n",
        "        model,\n",
        "        original_train_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        original_test_loader_large_batch,\n",
        "        optimizer,\n",
        "        scheduler,\n",
        "        criterion,\n",
        "        device,\n",
        "        optimizer_name='LAMB_Large_Batches_without_warmup',\n",
        "        accumulation_steps=accumulation_steps,\n",
        "        hyperparameters=hyperparameters,\n",
        "        is_wandb = True\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Distributed Approaches**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "hRd9SL7iRiKl"
      },
      "outputs": [],
      "source": [
        "# Initialize a model and save its initial parameters\n",
        "initial_model = LeNet5()\n",
        "initial_state_dict = initial_model.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GXZaFXruZI_"
      },
      "source": [
        "### Local SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "I8hvzRbQW32s"
      },
      "outputs": [],
      "source": [
        "class LocalSGDOptimizer(Optimizer):\n",
        "    def __init__(self, global_model, lr=0.01):\n",
        "        self.global_model = global_model\n",
        "        self.lr = lr\n",
        "        params = list(global_model.parameters())\n",
        "        super(LocalSGDOptimizer, self).__init__(params, {'lr': lr})\n",
        "\n",
        "    def step(self, local_models):\n",
        "        # Get global model parameters\n",
        "        global_params = list(self.global_model.parameters())\n",
        "        \n",
        "        # Initialize deltas for each parameter, same size as global parameters\n",
        "        deltas = [torch.zeros_like(param) for param in global_params]\n",
        "        \n",
        "        # Sum up differences between global model and local models\n",
        "        for local_model in local_models:\n",
        "            local_params = list(local_model.parameters())\n",
        "            for i, param in enumerate(local_params):\n",
        "                deltas[i] += (global_params[i] - param)\n",
        "        \n",
        "        # Average the delta over the number of local models\n",
        "        num_models = len(local_models)\n",
        "        for i, delta in enumerate(deltas):\n",
        "            deltas[i] /= self.lr\n",
        "            deltas[i] /= num_models\n",
        "        \n",
        "        # Update global model parameters\n",
        "        with torch.no_grad():\n",
        "            for i, param in enumerate(global_params):\n",
        "                param.copy_(param - self.lr * deltas[i])\n",
        "        \n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "def local_SGD(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, is_wandb=False):\n",
        "      \n",
        "  total_start_time = time.time()\n",
        "\n",
        "  iterations = num_epochs // j\n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  local_models = [LeNet5().to(device) for _ in range(k)]\n",
        "  for model in local_models:\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "  #Initialize optimizers for each chunk\n",
        "  local_optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in local_models]\n",
        "  # Initialize the global model\n",
        "  global_model = LeNet5().to(device)\n",
        "  global_model.load_state_dict(initial_state_dict)\n",
        "  \n",
        "  # Initialize the global optimizer with LocalSGDOptimizer\n",
        "  global_optimizer = LocalSGDOptimizer(global_model, lr)\n",
        "  \n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(global_optimizer, T_max=iterations)\n",
        "  \n",
        "  # Load checkpoint\n",
        "  checkpoint = load_checkpoint('local_sgd', 64, {'k': k, 'j': j})\n",
        "  if checkpoint is not None:\n",
        "      global_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      global_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      \n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn)\n",
        "      print(f'Global Update: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      \n",
        "      return None\n",
        "\n",
        "  # Training\n",
        "  for iteration in range(iterations):\n",
        "    for worker, shard_loader in enumerate(shard_loaders):\n",
        "      train_start_time = time.time()\n",
        "      for loca_step in range(j):\n",
        "        train_loss, train_accuracy = train(local_models[worker], shard_loader, local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "        print(f'Worker {worker+1}, [{loca_step+1:02}/{j:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {worker+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "    \n",
        "    # Synchronize local models with global model\n",
        "    global_optimizer.step(local_models)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Update local models learning rate to global learning rate after scheduler step\n",
        "    for local_optimizer in local_optimizers:\n",
        "        local_optimizer.param_groups[0]['lr'] = global_optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Load global model to local models\n",
        "    for local_model in local_models:\n",
        "      local_model.load_state_dict(global_model.state_dict())\n",
        "    \n",
        "    sync_end_time = time.time()\n",
        "\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    \n",
        "    test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "    \n",
        "    print(f'Global Update {iteration+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "    \n",
        "  \n",
        "  total_end_time = time.time()\n",
        "  \n",
        "  # Save checkpoint\n",
        "  save_checkpoint({\n",
        "              'epoch': num_epochs,\n",
        "              'model_state_dict': global_model.state_dict(),\n",
        "              'optimizer_state_dict': global_optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss': loss_fn\n",
        "              }, 149, 64, 'local_sgd', {'k': k, 'j': j})\n",
        " \n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for local_SGD: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.891312885, Test Accuracy: 56.100\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.937131206, Test Accuracy: 55.350\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.966259042, Test Accuracy: 55.450\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.047621591, Test Accuracy: 53.230\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.210712717, Test Accuracy: 42.830\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.875574264, Test Accuracy: 54.280\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.986871252, Test Accuracy: 52.610\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.156295303, Test Accuracy: 51.480\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.377478916, Test Accuracy: 50.100\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.314803950, Test Accuracy: 43.930\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.944273071, Test Accuracy: 50.760\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.104928839, Test Accuracy: 48.010\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.337245413, Test Accuracy: 46.160\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.830345691, Test Accuracy: 43.520\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.854822108, Test Accuracy: 37.720\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "K = [2, 4, 8]\n",
        "J = [4, 8, 16, 32, 64]\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K: # Number of workers\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    print('='*50)\n",
        "    print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "    print('='*50)\n",
        "    local_SGD(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SlowMo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SlowMoOptimizer(Optimizer):\n",
        "    def __init__(self, global_model, momentum, lr=0.01, beta=0.5, alpha=1.0):\n",
        "        self.global_model = global_model\n",
        "        self.lr = lr\n",
        "        self.beta = beta\n",
        "        self.alpha = alpha\n",
        "        self.momentum = momentum\n",
        "        params = list(global_model.parameters())\n",
        "        super(SlowMoOptimizer, self).__init__(params, {'lr': lr})\n",
        "        \n",
        "    def step(self, local_models):\n",
        "        # Calculate exact average of local models\n",
        "        avg_state_dict = {key: torch.zeros_like(value) for key, value in local_models[0].state_dict().items()}\n",
        "        for model in local_models:\n",
        "            for key, param in model.state_dict().items():\n",
        "                avg_state_dict[key] += param\n",
        "        \n",
        "        # Averaging the models\n",
        "        for key in avg_state_dict:\n",
        "            avg_state_dict[key] /= len(local_models)\n",
        "        \n",
        "        # Perform SlowMo momentum update\n",
        "        for key in self.global_model.state_dict().keys():\n",
        "            self.momentum[key] = self.beta * self.momentum[key] + (1.0 / self.lr) * (self.global_model.state_dict()[key] - avg_state_dict[key])\n",
        "        \n",
        "        # Update global model parameters with outer update\n",
        "        with torch.no_grad():\n",
        "            for key, param in self.global_model.state_dict().items():\n",
        "                param.copy_(param - self.alpha * self.lr * self.momentum[key])\n",
        "\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "def slowmo(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, beta, alpha):\n",
        "\n",
        "  total_start_time = time.time()\n",
        "\n",
        "  iterations = num_epochs // j\n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  local_models = [LeNet5().to(device) for _ in range(k)]\n",
        "  for model in local_models:\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "  #Initialize optimizers for each chunk\n",
        "  local_optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in local_models]\n",
        "  # Initialize the global model\n",
        "  global_model = LeNet5().to(device)\n",
        "  global_model.load_state_dict(initial_state_dict)\n",
        "  \n",
        "  momentum = {key: torch.zeros_like(value) for key, value in global_model.state_dict().items()}\n",
        "  \n",
        "  global_optimizer = SlowMoOptimizer(global_model, momentum , lr, beta, alpha)\n",
        "  \n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(global_optimizer, T_max=iterations)\n",
        "\n",
        "  checkpoint = load_checkpoint('slowmo', 64, {'k': k, 'j': j})\n",
        "  if checkpoint is not None:\n",
        "      global_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      global_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      \n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn)\n",
        "      print(f'Global Update: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      \n",
        "      return None\n",
        "\n",
        "  for iteration in range(iterations):\n",
        "    for worker, shard_loader in enumerate(shard_loaders):\n",
        "      train_start_time = time.time()\n",
        "      for loca_step in range(j):\n",
        "        train_loss, train_accuracy = train(local_models[worker], shard_loader, local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "        print(f'Worker {worker+1}, [{loca_step+1:02}/{j:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {worker+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "\n",
        "    global_optimizer.step(local_models)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for local_optimizer in local_optimizers:\n",
        "        local_optimizer.param_groups[0]['lr'] = global_optimizer.param_groups[0]['lr']    \n",
        "\n",
        "    for local_model in local_models:\n",
        "       local_model.load_state_dict(global_model.state_dict())\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Global Update {iteration+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "    \n",
        "  # Save checkpoint\n",
        "  save_checkpoint({\n",
        "              'epoch': num_epochs,\n",
        "              'model_state_dict': global_model.state_dict(),\n",
        "              'optimizer_state_dict': global_optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss': loss_fn\n",
        "              }, 149, 64, 'slowmo', {'k': k, 'j': j})\n",
        "\n",
        "  total_end_time = time.time()\n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for local_SGD: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.981766467, Test Accuracy: 56.000\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.081315363, Test Accuracy: 54.610\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.200608175, Test Accuracy: 53.200\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.824673044, Test Accuracy: 48.240\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 3.877965771, Test Accuracy: 40.550\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.035068179, Test Accuracy: 53.420\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.146553544, Test Accuracy: 52.300\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.383769921, Test Accuracy: 49.880\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 3.623166016, Test Accuracy: 47.160\n",
            "==================================================\n",
            "Number of Workers:4, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 4.001948534, Test Accuracy: 40.360\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.028979112, Test Accuracy: 50.520\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:8\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.245819785, Test Accuracy: 47.810\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:16\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.663717090, Test Accuracy: 43.500\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:32\n",
            "==================================================\n",
            "Global Update: Test Loss: 4.326718157, Test Accuracy: 40.040\n",
            "==================================================\n",
            "Number of Workers:8, Number of Local Steps:64\n",
            "==================================================\n",
            "Global Update: Test Loss: 4.915232519, Test Accuracy: 33.980\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "beta = 0.4\n",
        "alpha = 1\n",
        "parameters = {'lr': lr, 'wd': wd, 'beta': beta}\n",
        "K = [2, 4, 8]\n",
        "J = [4, 8, 16, 32 , 64]\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Initialize slow model\n",
        "slow_model = LeNet5()\n",
        "slow_model.load_state_dict(initial_state_dict)\n",
        "\n",
        "for k in K:\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    print('='*50)\n",
        "    print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "    print('='*50)\n",
        "    slowmo(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, beta, alpha)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Personal Contribution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SHAT (Asyncronous Approach)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SHAT_PS_Optimizer(Optimizer):\n",
        "    def __init__(self, global_model, lr=0.01):\n",
        "        self.global_model = global_model\n",
        "        self.lr = lr\n",
        "        params = list(global_model.parameters())\n",
        "        super(SHAT_PS_Optimizer, self).__init__(params, {'lr': lr})\n",
        "        \n",
        "    def step(self, gradients_model):\n",
        "        # Update global model parameters with gradients \n",
        "        with torch.no_grad():\n",
        "            for key, param in self.global_model.state_dict().items():\n",
        "                param.copy_(param -  self.lr * gradients_model.state_dict()[key])\n",
        "\n",
        "        return None\n",
        "\n",
        "def generate_computation_latency_sequence(K, each_worker_iteration):\n",
        "    \"\"\"\n",
        "    Simulates a sequence of operations for K workers with random computation latencies.\n",
        "\n",
        "    The function generates a list of operations, each performed by a worker, sorted by\n",
        "    their latencies. Each worker performs exactly t operations, and the latencies are\n",
        "    scaled so that the fastest worker's latency is normalized to 1.\n",
        "\n",
        "    Parameters:\n",
        "    K (int): The number of workers in the simulation.\n",
        "    t (int): The number of operations each computer will perform.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing:\n",
        "        - result (list of dicts): A list of dictionaries where each dictionary represents\n",
        "          an operation performed by a computer. The keys in the dictionary are:\n",
        "              - \"total_iterations\" (int): The total number of iterations performed.\n",
        "              - \"computer\" (int): The ID of the computer performing the operation.\n",
        "              - \"value\" (int): The latency value associated with that operation.\n",
        "        - computation_powers (list of ints): The original random computation latencies for each computer.\n",
        "        - scaled_powers (list of floats): The computation latencies scaled such that the fastest\n",
        "          worker's latency is 1.\n",
        "    \"\"\"\n",
        "    # Generate random computation powers\n",
        "    computation_powers = [5370, 9830]\n",
        "\n",
        "    # Find the minimum computation power\n",
        "    min_power = min(computation_powers)\n",
        "\n",
        "    # Scale the computation powers so that the fastest (smallest value) is equal to 1\n",
        "    scaled_powers = [power / min_power for power in computation_powers]\n",
        "\n",
        "    # Initialize a list to store the dictionaries\n",
        "    result = []\n",
        "\n",
        "    # Store the number of turns taken by each worker\n",
        "    turns_taken = [0] * K\n",
        "    total_number_of_iterations = 0\n",
        "    # Generate the dictionaries until all computers have 15 turns\n",
        "    while any(turn < each_worker_iteration for turn in turns_taken):\n",
        "        total_number_of_iterations += 1\n",
        "        # Generate the next possible dictionaries for each worker\n",
        "        possible_entries = []\n",
        "        for index in range(K):\n",
        "            if turns_taken[index] < each_worker_iteration:  # Only consider computers with less than 15 turns\n",
        "                operation_value = computation_powers[index] * (turns_taken[index] + 1)\n",
        "                possible_entries.append({\"total_iterations\": total_number_of_iterations,\"worker\": index, \"value\": operation_value})\n",
        "\n",
        "        # Sort the possible dictionaries by their operation value\n",
        "        possible_entries.sort(key=lambda x: x[\"value\"])\n",
        "\n",
        "        # Add the dictionary with the smallest value to the result\n",
        "        chosen_entry = possible_entries[0]\n",
        "        result.append(chosen_entry)\n",
        "\n",
        "        # Update the turn count for the chosen worker\n",
        "        chosen_index = chosen_entry[\"worker\"] \n",
        "        turns_taken[chosen_index] += 1\n",
        "\n",
        "    return result, computation_powers, scaled_powers\n",
        "\n",
        "def calculate_gradients_model(global_model, local_model, lr):\n",
        "    gradients_dict = {key: torch.zeros_like(value) for key, value in local_model.state_dict().items()}\n",
        "    \n",
        "    for key, value in local_model.state_dict().items():\n",
        "        gradients_dict[key] += ((global_model.state_dict()[key] - value)/lr)\n",
        "    \n",
        "    return gradients_dict\n",
        "\n",
        "def calculate_s_i(k,ci):\n",
        "    return float(k/ci)\n",
        "\n",
        "def calculate_alpha_i(si, k):\n",
        "    alpha = 1 - (si / math.log(k))\n",
        "    return alpha\n",
        "\n",
        "def updatel_local_model(global_model, local_model, alpha_i):\n",
        "    new_weights = {}\n",
        "    for key, value in local_model.state_dict().items():\n",
        "        new_weights[key] = (1 - alpha_i) * value + alpha_i * global_model.state_dict()[key]\n",
        "    \n",
        "    return new_weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def SHAT_PS(shard_loaders, loss_fn, k, lr, wd, initial_state_dict, num_epochs):  \n",
        "    # SHAT Parameter Server to manage workers\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    # Initialize a model with same value of param for each chunk\n",
        "    local_models = [LeNet5().to(device) for _ in range(k)]\n",
        "    for model in local_models:\n",
        "      model.load_state_dict(initial_state_dict)\n",
        "\n",
        "    # Initialize the global model\n",
        "    global_model = LeNet5().to(device)\n",
        "    global_model.load_state_dict(initial_state_dict)\n",
        "\n",
        "    global_optimizer = SHAT_PS_Optimizer(global_model, lr)\n",
        "  \n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(global_optimizer, T_max=num_epochs)\n",
        "    \n",
        "    checkpoint = load_checkpoint('shat', 64, {'k': k})\n",
        "    if checkpoint is not None:\n",
        "      global_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      global_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      \n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn)\n",
        "      print(f'Global Update: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      \n",
        "      return None\n",
        "    # Generate a sequence of computation latency to simulate the difference of computation latency (Lower computation Latency means higher computation power)\n",
        "    computation_latency_sequence, computation_latency, scaled_computation_latency = generate_computation_latency_sequence(k, num_epochs)\n",
        "\n",
        "    # Print the original and scaled computation latency\n",
        "    print(\"Original Computation Latency:\", computation_latency)\n",
        "    print(\"Scaled Computation Latency:\", scaled_computation_latency)\n",
        "\n",
        "    # print sequence of workers based on their computation latency\n",
        "    print(f'workers simulated orders based on computation latency:{[entry[\"worker\"]+1 for entry in computation_latency_sequence]}')\n",
        "\n",
        "    C = [1 for _ in range(k)] # Staleness counter\n",
        "    local_optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in local_models]\n",
        "    \n",
        "    #This specifies turn of the model\n",
        "    for iteration_index, worker in enumerate([entry['worker'] for entry in computation_latency_sequence]):\n",
        "      iteration_start_time = time.time()\n",
        "      print('*'*50)\n",
        "\n",
        "      train_loss, train_accuracy = train(local_models[worker], shard_loaders[worker], local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "      print(f'Worker {worker+1}, [{iteration_index+1:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "      print('*'*50)\n",
        "      \n",
        "      '''PS server: receive model from the worker and calculate diff model (gradient)'''\n",
        "      gradients_model = LeNet5().to(device)\n",
        "      gradients_model.load_state_dict(calculate_gradients_model(global_model, local_models[worker], lr))\n",
        "      \n",
        "      # Computing the staleness of each worker\n",
        "      for i in C :\n",
        "        if i != worker:\n",
        "          i += 1\n",
        "          \n",
        "      '''PS Server update global model'''\n",
        "      global_optimizer.step(gradients_model)\n",
        "      \n",
        "      '''send updated model to the worker'''\n",
        "      '''calucale the staleness of the worker i  si  logn ,    s  n/ci'''\n",
        "      s_i = calculate_s_i(k,C[worker])\n",
        "      alpha_i = calculate_alpha_i(s_i, k)\n",
        "      '''update worker local model ba w  (1   )w +  w'''\n",
        "      local_models[worker].load_state_dict(updatel_local_model(global_model, local_models[worker], alpha_i))\n",
        "\n",
        "      '''continue outer loop in PS'''\n",
        "      '''ci = 0 ya 1'''\n",
        "      C[worker] = 1\n",
        "      \n",
        "      iteration_end_time = time.time()\n",
        "     \n",
        "      print(f'Time taken for worker {worker+1} : {str(timedelta(seconds=iteration_end_time - iteration_start_time))}')\n",
        "      print('-'*50)\n",
        "      print(f'Iteration: {iteration_index+1:02}/{k*num_epochs:02} - True epochs: {num_epochs}')\n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "      print(f'Global Update {iteration_index+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      print('-'*50)\n",
        "    \n",
        "    # Save checkpoint\n",
        "    save_checkpoint({\n",
        "              'epoch': num_epochs,\n",
        "              'model_state_dict': global_model.state_dict(),\n",
        "              'optimizer_state_dict': global_optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss': loss_fn\n",
        "              }, 149, 64, 'shat', {'k': k})\n",
        "    \n",
        "    total_end_time = time.time()\n",
        "    print('/'*50)\n",
        "    print(f'Total time taken for SHAT: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "    print('/'*50)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.560581903, Test Accuracy: 42.860\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03 \n",
        "K = [2]\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K: # number of workers\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  print('='*50)\n",
        "  print(f'Number of Workers:{k}')\n",
        "  print('='*50)\n",
        "  SHAT_PS(shard_loaders, loss_fn, k, lr, wd, initial_state_dict, num_epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Our Approach 1: Layerwise Masking Approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def freeze_layers(model, layers_to_freeze):\n",
        "    \"\"\"\n",
        "    Freezes the specified layers in the model, skipping non-trainable layers.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model whose layers you want to freeze.\n",
        "    - layers_to_freeze (list of nn.Module): The layers to freeze.\n",
        "    \"\"\"\n",
        "\n",
        "    for idx, layer in enumerate(model.children()):\n",
        "        if idx in layers_to_freeze and any(p.requires_grad for p in layer.parameters()):\n",
        "            for param in layer.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "def build_model_list(model, num_layers_to_freeze):\n",
        "    \"\"\"\n",
        "    Builds a list of models with different combinations of frozen layers.\n",
        "\n",
        "    Parameters:\n",
        "    - model (nn.Module): The model to use as a base.\n",
        "    - num_layers_to_freeze (int): The number of layers to freeze in each model.\n",
        "\n",
        "    Returns:\n",
        "    - list of nn.Module: A list of models with different combinations of frozen layers.\n",
        "    \"\"\"\n",
        "    model_list = []\n",
        "    trainable_layers = [idx for idx, layer in enumerate(model.children()) if any(p.requires_grad for p in layer.parameters())]\n",
        "\n",
        "    # Generate all possible combinations of trainable layers to freeze\n",
        "    layer_combinations = list(combinations(trainable_layers, num_layers_to_freeze))\n",
        "\n",
        "    for layers in layer_combinations:\n",
        "        new_model = copy.deepcopy(model)\n",
        "        freeze_layers(new_model, layers)\n",
        "        model_list.append(new_model)\n",
        "\n",
        "    return model_list\n",
        "\n",
        "def train_select_best_model(model, num_layers_to_freeze, num_epochs, train_loader, test_loader, loss_fn, optimizer, device):\n",
        "    \"\"\"\n",
        "    Trains the model with different combinations of frozen layers and selects the best one based on test accuracy.\n",
        "    \"\"\"\n",
        "    model_list = build_model_list(model, num_layers_to_freeze)\n",
        "    best_accuracy = 0.0\n",
        "    best_layers = []\n",
        "\n",
        "    for candidate_model in model_list:\n",
        "        candidate_model.to(device)\n",
        "        optimizer_copy = copy.deepcopy(optimizer)\n",
        "\n",
        "        # Update only the parameters that require gradients\n",
        "        for param_group in optimizer_copy.param_groups:\n",
        "            param_group['params'] = [param for param in candidate_model.parameters() if param.requires_grad]\n",
        "\n",
        "        candidate_model.train()\n",
        "\n",
        "        for _ in range(num_epochs):\n",
        "            train(candidate_model, train_loader, optimizer_copy, loss_fn)\n",
        "\n",
        "        test_loss, test_accuracy = test(candidate_model, test_loader, loss_fn, is_wandb=False)\n",
        "\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            best_layers = [name for idx, (name, layer) in enumerate(candidate_model.named_children()) \n",
        "                           if not any(p.requires_grad for p in layer.parameters()) and any(p.requires_grad for p in model.get_submodule(name).parameters())]\n",
        "\n",
        "    best_layer_indices = [idx for idx, (name, layer) in enumerate(model.named_children()) if name in best_layers]\n",
        "    freeze_layers(model, best_layer_indices)\n",
        "\n",
        "    return {tuple(best_layers): copy.deepcopy(model)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PerDLMaskOptimizer(Optimizer):\n",
        "    def __init__(self, global_model, lr=0.01):\n",
        "        self.global_model = global_model\n",
        "        self.lr = lr\n",
        "        params = list(global_model.parameters())\n",
        "        super(PerDLMaskOptimizer, self).__init__(params, {'lr': lr})\n",
        "\n",
        "    def expand_mask(self, model, layer_mask):\n",
        "        \"\"\"\n",
        "        Expands the layer-based mask to match the number of parameters.\n",
        "\n",
        "        Args:\n",
        "        - model (nn.Module): The model whose parameters are being masked.\n",
        "        - layer_mask (list of bool): The mask corresponding to each layer (True for trainable, False for frozen).\n",
        "\n",
        "        Returns:\n",
        "        - list of bool: Expanded mask corresponding to each parameter in the model.\n",
        "        \"\"\"\n",
        "        expanded_mask = []\n",
        "        for is_trainable, layer in zip(layer_mask, model.children()):\n",
        "            # Append True/False for each parameter in the layer\n",
        "            expanded_mask.extend([is_trainable] * len(list(layer.parameters())))\n",
        "        return expanded_mask\n",
        "\n",
        "    def step(self, local_models, masks):\n",
        "        \"\"\"\n",
        "        Perform a step of Local SGD optimization using the mask for each worker.\n",
        "\n",
        "        Args:\n",
        "        - local_models (list of nn.Module): The list of local models (from different workers).\n",
        "        - masks (list of list of bool): The mask for each worker indicating whether each layer is trainable or not.\n",
        "        \"\"\"\n",
        "        # Get global model parameters\n",
        "        global_params = list(self.global_model.parameters())\n",
        "        \n",
        "        # Initialize deltas for each parameter, same size as global parameters\n",
        "        deltas = [torch.zeros_like(param) for param in global_params]\n",
        "\n",
        "        # Iterate over local models and accumulate deltas based on the expanded mask\n",
        "        for worker_idx, local_model in enumerate(local_models):\n",
        "            local_params = list(local_model.parameters())\n",
        "            \n",
        "            # Expand the mask to match the number of parameters in the model\n",
        "            expanded_mask = self.expand_mask(local_model, masks[worker_idx])\n",
        "\n",
        "            # Ensure mask length matches local_params length\n",
        "            assert len(expanded_mask) == len(local_params), f\"Expanded mask size {len(expanded_mask)} doesn't match number of parameters {len(local_params)}\"\n",
        "\n",
        "            for i, param in enumerate(local_params):\n",
        "                if expanded_mask[i]:  # Only consider non-frozen parameters\n",
        "                    deltas[i] += (global_params[i] - param)\n",
        "\n",
        "        # Adjust deltas based on the number of workers that updated each layer\n",
        "        for i, delta in enumerate(deltas):\n",
        "            num_active_workers = sum(expanded_mask[i] for expanded_mask in [self.expand_mask(m, masks[w_idx]) for w_idx, m in enumerate(local_models)])  # Count workers with trainable parameters\n",
        "            if num_active_workers > 0:\n",
        "                deltas[i] /= num_active_workers  # Average only over active workers\n",
        "            deltas[i] /= self.lr  # Apply learning rate scaling\n",
        "        \n",
        "        # Update global model parameters\n",
        "        with torch.no_grad():\n",
        "            for i, param in enumerate(global_params):\n",
        "                param.copy_(param - self.lr * deltas[i])\n",
        "        \n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def PerDLMask(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, index_weaker_worker, n_freeze_layer, is_wandb=False, fine_tuning=False):\n",
        "      \n",
        "  total_start_time = time.time()\n",
        "  \n",
        "  iterations = num_epochs // j\n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  local_models = [LeNet5().to(device) for _ in range(k)]\n",
        "  for model in local_models:\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "  #Initialize optimizers for each chunk\n",
        "  local_optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in local_models]\n",
        "\n",
        "  # Initialize the global model\n",
        "  global_model = LeNet5().to(device)\n",
        "  global_model.load_state_dict(initial_state_dict)\n",
        "  \n",
        "  global_optimizer = PerDLMaskOptimizer(global_model, lr)\n",
        "  \n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(global_optimizer, T_max=iterations)\n",
        "  \n",
        "  checkpoint = load_checkpoint('PerDLMask', 64, {'k': k, 'j': j, 'weaker_worker': index_weaker_worker, 'n_freeze_layer': n_freeze_layer, 'fine_tuning': fine_tuning})\n",
        "  if checkpoint is not None:\n",
        "      global_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      global_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      \n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn)\n",
        "      print(f'Global Update: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      \n",
        "      return None\n",
        "  \n",
        "  # select to freeze layers for the weaker worker with lower bais\n",
        "  freeze_model = train_select_best_model(local_models[index_weaker_worker], n_freeze_layer, 5, shard_loaders[index_weaker_worker], original_test_loader, loss_fn, local_optimizers[index_weaker_worker], device)\n",
        "  print(f'The following layers of worker {index_weaker_worker+1} are frozen: {list(freeze_model.keys())[0]}')\n",
        "  local_models[index_weaker_worker] = list(freeze_model.values())[0]\n",
        "  \n",
        "  # Initialize masks for each worker\n",
        "  masks = [[True for _ in model.named_children()] for model in local_models]\n",
        "  # Freeze the layers for the weaker worker in the masks\n",
        "  masks[index_weaker_worker] = [name not in list(freeze_model.keys())[0] for name, layer in list(freeze_model.values())[0].named_children()]\n",
        "\n",
        "  for iteration in range(iterations-1 if fine_tuning else iterations):\n",
        "    for worker, shard_loader in enumerate(shard_loaders):\n",
        "      train_start_time = time.time()\n",
        "      for loca_step in range(j):\n",
        "        train_loss, train_accuracy = train(local_models[worker], shard_loader, local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "        print(f'Worker {worker+1}, [{loca_step+1:02}/{j:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {worker+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "\n",
        "    # Synchronize local models with global model\n",
        "    global_optimizer.step(local_models, masks)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    for local_optimizer in local_optimizers:\n",
        "        local_optimizer.param_groups[0]['lr'] = global_optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "    for local_model in local_models:\n",
        "      local_model.load_state_dict(global_model.state_dict())\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Global Update {iteration+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "    \n",
        "  if fine_tuning:\n",
        "    # Unfreeze all layers for worker 2 (the weaker worker)\n",
        "    for name, layer in local_models[index_weaker_worker].named_children():\n",
        "        for param in layer.parameters():\n",
        "            if name in list(freeze_model.keys())[0]:\n",
        "                param.requires_grad = True\n",
        "    masks = [[True for _ in model.named_children()] for model in local_models]  \n",
        "    \n",
        "    for worker in range(k):\n",
        "        train_start_time = time.time()\n",
        "        for _ in range(j):\n",
        "            train_loss, train_accuracy = train(local_models[worker], shard_loader, local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "            print(f'Worker {worker+1}, [{loca_step+1:02}/{j:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "        total_end_time = time.time()\n",
        "        print(f'Time taken for training worker {worker+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "        print('-'*50)\n",
        "    sync_start_time = time.time()\n",
        "\n",
        "    global_optimizer.step(local_models, masks)\n",
        "    scheduler.step()\n",
        "    for local_optimizer in local_optimizers:\n",
        "        local_optimizer.param_groups[0]['lr'] = global_optimizer.param_groups[0]['lr']\n",
        "\n",
        "\n",
        "    for local_model in local_models:\n",
        "        local_model.load_state_dict(global_model.state_dict())\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Global Update {iteration+1:02}: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "\n",
        "  \n",
        "  # Save checkpoint\n",
        "  save_checkpoint({\n",
        "              'epoch': num_epochs,\n",
        "              'model_state_dict': global_model.state_dict(),\n",
        "              'optimizer_state_dict': global_optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss': loss_fn\n",
        "              }, 149, 64, 'PerDLMask', {'k': k, 'j': j, 'weaker_worker': index_weaker_worker, 'n_freeze_layer': n_freeze_layer, 'fine_tuning': fine_tuning})\n",
        " \n",
        "\n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for local_SGD: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.760830911, Test Accuracy: 48.840\n"
          ]
        }
      ],
      "source": [
        "# Without Fine-tuning\n",
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "K = [2]\n",
        "J = [4]\n",
        "\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K: # Number of workers\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    print('='*50)\n",
        "    print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "    print('='*50)\n",
        "    PerDLMask(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, index_weaker_worker=1, n_freeze_layer=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, Number of Local Steps:4\n",
            "==================================================\n",
            "Global Update: Test Loss: 2.543037563, Test Accuracy: 49.050\n"
          ]
        }
      ],
      "source": [
        "# With Fine-tuning\n",
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "K = [2]\n",
        "J = [4]\n",
        "\n",
        "num_epochs = 150\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K: # Number of workers\n",
        "  shard_loaders = data.iid_shards(num_shards=k)\n",
        "  for j in J:\n",
        "    print('='*50)\n",
        "    print(f'Number of Workers:{k}, Number of Local Steps:{j}')\n",
        "    print('='*50)\n",
        "    PerDLMask(shard_loaders, loss_fn, k, j, lr, wd, initial_state_dict, num_epochs, index_weaker_worker=1, n_freeze_layer=2, fine_tuning=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Our Approach 2: Confidence Interval Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "def update_CI_Acc(accuracies, C_level=0.8):\n",
        "    if len(accuracies) == 1:\n",
        "        return 0.0\n",
        "    mean = np.mean(accuracies)\n",
        "    std_dev = np.std(accuracies, ddof=1)\n",
        "    t_score = stats.t.ppf(1 - (1 - C_level) / 2, len(accuracies) - 1)\n",
        "    CI = t_score * (std_dev / np.sqrt(len(accuracies)))\n",
        "    # Compute relative error\n",
        "    RE = CI / mean\n",
        "    # Compute accuracy\n",
        "    accuracy = 1 - RE\n",
        "\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ConfidenceInetrvalApproach(shard_loaders, loss_fn, k, lr, wd, initial_state_dict, num_epochs, ci_acc_threshold):\n",
        "  total_start_time = time.time()\n",
        "  \n",
        "  # Initialize a model with same value of param for each chunk\n",
        "  local_models = [LeNet5().to(device) for _ in range(k)]\n",
        "  train_accuracy_workers = {i: [] for i in range(k)}\n",
        "  steps_per_worker = {i: 0 for i in range(k)}\n",
        "  accuracy_workers = {i: 0 for i in range(k)}\n",
        "  for model in local_models:\n",
        "    model.load_state_dict(initial_state_dict)\n",
        "\n",
        "  #Initialize optimizers for each chunk\n",
        "  local_optimizers = [torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=wd) for model in local_models]\n",
        "  \n",
        "  # Initialize the global model\n",
        "  global_model = LeNet5().to(device)\n",
        "  global_model.load_state_dict(initial_state_dict)\n",
        "  global_optimizer = LocalSGDOptimizer(global_model, lr=lr)\n",
        "\n",
        "  scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(global_optimizer, T_max=num_epochs)\n",
        "\n",
        "  checkpoint = load_checkpoint('ci-strategy', 64, {'k': k, 'threshold': ci_acc_threshold})\n",
        "  if checkpoint is not None:\n",
        "      global_model.load_state_dict(checkpoint['model_state_dict'])\n",
        "      global_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "      scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "      \n",
        "      test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn)\n",
        "      print(f'Global Update: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "      \n",
        "      return None\n",
        "  \n",
        "  total_epochs = 0\n",
        "  steps_per_worker = {i: 0 for i in range(k)}\n",
        "  while not all(value > num_epochs for value in steps_per_worker.values()): \n",
        "    for worker, shard_loader in enumerate(shard_loaders):\n",
        "      if steps_per_worker[worker] > num_epochs:\n",
        "        continue\n",
        "      train_start_time = time.time()\n",
        "      step_counter = 0\n",
        "      # Train the model\n",
        "      while not accuracy_workers[worker] > ci_acc_threshold:\n",
        "        \n",
        "        train_loss, train_accuracy = train(local_models[worker], shard_loader, local_optimizers[worker], loss_fn, device = device,  is_wandb=False)\n",
        "        train_accuracy_workers[worker].append(train_accuracy)\n",
        "\n",
        "        accuracy_workers[worker] = update_CI_Acc(train_accuracy_workers[worker])\n",
        "        steps_per_worker[worker] += 1\n",
        "        step_counter += 1\n",
        "        print(accuracy_workers[worker])\n",
        "        print(f'Worker {worker+1}, [epoch: {step_counter:02}]: Training Loss: {train_loss:.9f}, Training Accuracy: {train_accuracy:.3f}')\n",
        "        if steps_per_worker[worker] == num_epochs:\n",
        "          break\n",
        "      train_accuracy_workers[worker] = []\n",
        "      accuracy_workers[worker] = 0  \n",
        "      train_end_time = time.time()\n",
        "      print(f'Time taken for training worker {worker+1}: {str(timedelta(seconds=train_end_time - train_start_time))}')\n",
        "      print('-'*50)\n",
        "    sync_start_time = time.time() \n",
        "\n",
        "    # Synchronize local models with global model\n",
        "    global_optimizer.step(local_models)\n",
        "\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Update the local models with the global model\n",
        "    for local_model in local_models:\n",
        "       local_model.load_state_dict(global_model.state_dict())\n",
        "    \n",
        "    # Update the learning rate of the local optimizers with the global optimizer after scheduling\n",
        "    for local_optimizer in local_optimizers:\n",
        "        local_optimizer.param_groups[0]['lr'] = global_optimizer.param_groups[0]['lr']\n",
        "\n",
        "    total_epochs += step_counter\n",
        "    sync_end_time = time.time()\n",
        "    print('*'*50)\n",
        "    print(f'Time taken for synchronization: {str(timedelta(seconds=sync_end_time - sync_start_time))}')\n",
        "    test_loss, test_accuracy = test(global_model,original_test_loader, loss_fn, is_wandb = False)\n",
        "    print(f'Global Model: Test Loss: {test_loss:.9f}, Test Accuracy: {test_accuracy:.3f}')\n",
        "    print('*'*50)\n",
        "  \n",
        "  # Save checkpoint\n",
        "  save_checkpoint({\n",
        "              'epoch': num_epochs,\n",
        "              'model_state_dict': global_model.state_dict(),\n",
        "              'optimizer_state_dict': global_optimizer.state_dict(),\n",
        "              'scheduler_state_dict': scheduler.state_dict(),\n",
        "              'loss': loss_fn\n",
        "              }, 149, 64, 'ci-strategy', {'k': k, 'threshold': ci_acc_threshold}) \n",
        "  \n",
        "  total_end_time = time.time()\n",
        "  print('/'*50)\n",
        "  print(f'Total time taken for Confidence Interval: {str(timedelta(seconds=total_end_time - total_start_time))}')\n",
        "  print('/'*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "==================================================\n",
            "Number of Workers:2, CI Accuracy Threshold:0.8\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.786572354, Test Accuracy: 55.280\n",
            "==================================================\n",
            "Number of Workers:2, CI Accuracy Threshold:0.9\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.758802217, Test Accuracy: 55.350\n",
            "==================================================\n",
            "Number of Workers:2, CI Accuracy Threshold:0.95\n",
            "==================================================\n",
            "Global Update: Test Loss: 1.742772651, Test Accuracy: 54.220\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-02\n",
        "wd = 1e-03\n",
        "K = [2]\n",
        "num_epochs = 150\n",
        "ci_acc_thresholds= [0.8, 0.9, 0.95]\n",
        "data = CIFAR100Data()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for k in K: # Number of workers\n",
        "    for ci_acc_threshold in ci_acc_thresholds:\n",
        "        shard_loaders = data.iid_shards(num_shards=k)\n",
        "        print('='*50)\n",
        "        print(f'Number of Workers:{k}, CI Accuracy Threshold:{ci_acc_threshold}')\n",
        "        print('='*50)\n",
        "        ConfidenceInetrvalApproach(shard_loaders, loss_fn, k, lr, wd, initial_state_dict, num_epochs, ci_acc_threshold)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "BGJAcU7dTxJ1",
        "V2mj0Wd-T73T",
        "ybM87poAtHnl",
        "5fjzE9q4UOPU",
        "SEseiEKFt0mR",
        "taX_5ElNuKxC",
        "aeMWj_f0sbQE",
        "3GXZaFXruZI_"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06d3de2006b14793bd57a5ca89d44e4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68d86018628f420e8d7e516ba5827e35",
            "placeholder": "",
            "style": "IPY_MODEL_8877fd11846246f989e31835e5d3e7ae",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "07dc9b3c563e4615bec4dbd3233bf4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07ff6351429c48c2b835305d3111af40": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5de35a9063345b1a12e212718a02575",
            "placeholder": "",
            "style": "IPY_MODEL_e86e517239b54ca4a6767a300aa7e01d",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "09b762f5ba784066a9408ffcfdea5b2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a9ee7dc8817456aab4af03cbfa4c6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b42ea1995bb410b99e653780dad3916": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4b10bb8bff4d40afa8df981440fe43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d710da02bfe4c8e80d205158d9d64c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ef1563b6ba74b86a7bf7af3fcc3d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fdaf43c468043139e5d72397b118371": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "104402d4cba5477499593d972bc48e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13e7a0db2aa74e35b7d1948224358d76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1574e69b88de479da2aadc2dfdd43261": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a0bbd1e2b14cef8a2f9accf120c1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "175043eb44e44b4f9aefaf51aae6fb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71e710b571d142a3a08cd233590b7171",
            "placeholder": "",
            "style": "IPY_MODEL_2671c3bf3cfd49aa9ad6841c289068cc",
            "value": "0.019 MB of 0.019 MB uploaded\r"
          }
        },
        "17ac4efa9cf148e5be69edbc5b0bdecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "18cb73ac1b224757920e7a8187b3ba4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19ed5f5d4f714246bbdf44513ecc50f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1f9d7ac8fa8a4bcdb76fe2b2cb443f66",
              "IPY_MODEL_71c0cc303cfc44ba8d989d5f8feca119"
            ],
            "layout": "IPY_MODEL_07dc9b3c563e4615bec4dbd3233bf4ba"
          }
        },
        "1b093d744b374154afe2058e4a6de822": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b1acf7a1f5f43739e1fe0894ba48950": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d534596e41340438fc8d083fff6aa8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d74e9350c2c4c61b2e95924ec133012": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f9d7ac8fa8a4bcdb76fe2b2cb443f66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ccc0b32e9a4ceebd6045dff63e6621",
            "placeholder": "",
            "style": "IPY_MODEL_104402d4cba5477499593d972bc48e9d",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "1feabb0772134ace893d71cb905e9b12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b1acf7a1f5f43739e1fe0894ba48950",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d710da02bfe4c8e80d205158d9d64c7",
            "value": 1
          }
        },
        "1fef0782f0804736881f03c2e31c3d64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2402e482be7e484fa98ae3f60f68d95a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2671c3bf3cfd49aa9ad6841c289068cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2991ead42a2a4637b2902ca26837d74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9e0bb90e33ec4e198857c255080ef6f0",
              "IPY_MODEL_77790c4dcd124f73907619689fb8d37c"
            ],
            "layout": "IPY_MODEL_1fef0782f0804736881f03c2e31c3d64"
          }
        },
        "2bc1423c729a4faa9a184ae092eda8ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd5fda76227433aa9332e6e48cd415b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd6480fe59104c7aa15d39bf6ea4a63b",
              "IPY_MODEL_3cb7b5c42e844747ae133750b7d42882"
            ],
            "layout": "IPY_MODEL_b81cc89707e44dedb51081d13a3ba424"
          }
        },
        "2d65b320aaed40cd87b8f78c99c614e7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f39d5f73c7647f1804e4212cb39924d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e7ede02663f4eb0927872bf17858f18",
              "IPY_MODEL_a562d76741f74b10b8095be14da779d1"
            ],
            "layout": "IPY_MODEL_f4e7759ba0f544d8a28a9922e06e890b"
          }
        },
        "30d70d57987c4349b55560e5d9626201": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36ac25551e574241bed4d7e5a4301d95",
              "IPY_MODEL_6898349b9c754ca7be91bea29cabbba5"
            ],
            "layout": "IPY_MODEL_623f947ef06c41569be7fcdda4141174"
          }
        },
        "32c759d7fff64701a6ad61b38ac63187": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67aa8f8c2b244c9a9a3bb11caf491247",
            "placeholder": "",
            "style": "IPY_MODEL_09b762f5ba784066a9408ffcfdea5b2e",
            "value": "Waiting for wandb.init()...\r"
          }
        },
        "33050a2d80c24235aecc36cb34e79684": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a438b911c04f1f96c67b4f7ba7477d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7b6956e7e34db68cd38dee19c798f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d71c8b5d30df474ca6f30976d0a33c71",
            "value": 1
          }
        },
        "3445c5fe76514de0b6b9cc31200c8544": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0748d32c99741d39b18512400e07f30",
            "placeholder": "",
            "style": "IPY_MODEL_dc43eb867d6b446cb0cb8e5debae57e7",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "346856a22f0e45b2be0c14aa7902261f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35d90a90d5854bcaa2bc5f385cdad931": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3606009883cf4212b7e1ed6e4f182845": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a546b812d6403cbf5ed693318a9744": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4a5f301338a4e5185c042a22684ed4a",
            "placeholder": "",
            "style": "IPY_MODEL_48c7de7682f242fd86a234d1607187f4",
            "value": "0.020 MB of 0.020 MB uploaded\r"
          }
        },
        "36ac25551e574241bed4d7e5a4301d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d268f74266044451b230f20756bab2f6",
            "placeholder": "",
            "style": "IPY_MODEL_6896790e80d1450c821918c7ef41e42f",
            "value": "0.027 MB of 0.027 MB uploaded\r"
          }
        },
        "371471be80ca47dbb005c853b7832f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1574e69b88de479da2aadc2dfdd43261",
            "placeholder": "",
            "style": "IPY_MODEL_f523ae2aca8c46878f0a6ddc1f798ef5",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "397b6d4daaf04a1181413adc5e30db0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39aecb8ffe0645fbadccf8b0f8ed2486": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0b3657d30547d7abe702d6c1e7b7c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cb7b5c42e844747ae133750b7d42882": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fdaf43c468043139e5d72397b118371",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f63fffe56ff64f1eb2b6e8f14974f011",
            "value": 1
          }
        },
        "3ee2c346d4d74faa915ef8315e3303c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "403dcd5f10de42ddbb67c8108e3bc34c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4302f47b1ff043aca2523212b015e080": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_371471be80ca47dbb005c853b7832f04",
              "IPY_MODEL_e75a0d8ae24e462aa3075a813aad302d"
            ],
            "layout": "IPY_MODEL_fd2cd8045a5c4387b98d080782289c48"
          }
        },
        "431cf75dd1cc4840b14f678876f45bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a5f3871113994f1eb993c126d793d147",
              "IPY_MODEL_7903555c1e884408b70c9951ecae84ec"
            ],
            "layout": "IPY_MODEL_2d65b320aaed40cd87b8f78c99c614e7"
          }
        },
        "45bdcbbed9ae47ffb24bd2a962345eaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46c9d83bf8af443bb376ed4858ce35f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0b3657d30547d7abe702d6c1e7b7c4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17ac4efa9cf148e5be69edbc5b0bdecf",
            "value": 1
          }
        },
        "48c7de7682f242fd86a234d1607187f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49727de0590f41dca6addf3f4ffe33f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "497de066b1964cd4b931476e0bd50c66": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a4cfb14c56e477cbfef5a652c05fabc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b733fc6800e4a0ab36bba52ff84f1a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e2cc873f917444c833e152f7c2555de",
            "placeholder": "",
            "style": "IPY_MODEL_49727de0590f41dca6addf3f4ffe33f2",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "5055c91b4ed34c1baf249fa25948e84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33050a2d80c24235aecc36cb34e79684",
            "placeholder": "",
            "style": "IPY_MODEL_2bc1423c729a4faa9a184ae092eda8ad",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "50b4ba3147b540abad020ae780353f27": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "557cf2de74314915b7204d9055fa6987": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a345ff7386643eeb7a5b190d69d2e0e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8f4783e2060a4295bb68036a4a7310d9",
            "value": 1
          }
        },
        "5630d5fcb50a46f2887e0cce74a005a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "567cc1542f09433f8cc8b3a39237f198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "584e5a6aada04535b64c40c3ece566e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cf516644d1a4ebf82c7e9dfa13e560b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36a546b812d6403cbf5ed693318a9744",
              "IPY_MODEL_aed05a015df946c7bae33226c3a8ddc6"
            ],
            "layout": "IPY_MODEL_d601ef3ebb6c4b688ac53a65979aa445"
          }
        },
        "5e0116dc735e4ad995a5b1a039c6a55a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76dfea14213f4e66b269b901150c6cba",
            "placeholder": "",
            "style": "IPY_MODEL_d1e4a03094b94c34ac235ffbd0c7fa06",
            "value": "0.030 MB of 0.030 MB uploaded\r"
          }
        },
        "5f3a33bc6a334c9e8c5886caa5f015ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8040d3a83de41319a2a836def914b1b",
            "placeholder": "",
            "style": "IPY_MODEL_0b4b10bb8bff4d40afa8df981440fe43",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "60957598b6c64ab0987d583b788dd674": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623f947ef06c41569be7fcdda4141174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63dd47b50bdc44e88edd97d14585f7ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e0116dc735e4ad995a5b1a039c6a55a",
              "IPY_MODEL_8cf1e952ed294ccdbc3bb2275b5d3efd"
            ],
            "layout": "IPY_MODEL_7421027bfcb34262a1b99d297e49bf8e"
          }
        },
        "64224c777f01418e904dcd30ecd7c5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99929754d3094d03a5f311177ac26cb3",
            "placeholder": "",
            "style": "IPY_MODEL_9ea517158b974c5da17899e3fea4fc3b",
            "value": "0.012 MB of 0.012 MB uploaded\r"
          }
        },
        "67aa8f8c2b244c9a9a3bb11caf491247": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6896790e80d1450c821918c7ef41e42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6898349b9c754ca7be91bea29cabbba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a30700c8bfb449cda98a40d75828f3d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77beee57b67d4bad826f616e5483b87a",
            "value": 1
          }
        },
        "68d86018628f420e8d7e516ba5827e35": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68ff4108835c462b929d0b5c78497555": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696917cb66a74c41b87f9b436f8ce42c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77a9b4df16ba408a941d67a51eed303d",
              "IPY_MODEL_b3b0d42308df44e6b43a06f7424d489d"
            ],
            "layout": "IPY_MODEL_fd23196beb964eb0a631b1fcb3893545"
          }
        },
        "6a345ff7386643eeb7a5b190d69d2e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa92cf922724ac08c45385ff8a58447": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6abbcbe71a314356ba04f8349d1fc127": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3326a99729a416abca13d3122196e64",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1d534596e41340438fc8d083fff6aa8b",
            "value": 1
          }
        },
        "6c30f9a9e6c44d78ad39f43a5f11a6d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e51a8e2e7e6463486d7b11454333941": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e7ede02663f4eb0927872bf17858f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a9ee7dc8817456aab4af03cbfa4c6ed",
            "placeholder": "",
            "style": "IPY_MODEL_567cc1542f09433f8cc8b3a39237f198",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "7064cd1e5d794c258dbeeb63a9ae9f9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71c0cc303cfc44ba8d989d5f8feca119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80fe0a51b14b4e548454d4f83215336c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8e13a8bef6e14973912966984e83cd4c",
            "value": 1
          }
        },
        "71e710b571d142a3a08cd233590b7171": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7421027bfcb34262a1b99d297e49bf8e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76dfea14213f4e66b269b901150c6cba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77790c4dcd124f73907619689fb8d37c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e7a0db2aa74e35b7d1948224358d76",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7064cd1e5d794c258dbeeb63a9ae9f9b",
            "value": 1
          }
        },
        "77a9b4df16ba408a941d67a51eed303d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e51a8e2e7e6463486d7b11454333941",
            "placeholder": "",
            "style": "IPY_MODEL_18cb73ac1b224757920e7a8187b3ba4d",
            "value": "0.020 MB of 0.020 MB uploaded\r"
          }
        },
        "77beee57b67d4bad826f616e5483b87a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "77c702b6d9c04f00b8e624f31a591f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6d67121f0ab4daf96d0bdd2c433259b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3ee2c346d4d74faa915ef8315e3303c8",
            "value": 1
          }
        },
        "7903555c1e884408b70c9951ecae84ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac87babb2f2a4781ab863c3b8f613807",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b3970cfd36ed4450b7c8f958a6499dc4",
            "value": 1
          }
        },
        "7e2cc873f917444c833e152f7c2555de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804c12a3f13840c7bdb2e6df69e62c10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68ff4108835c462b929d0b5c78497555",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a63e1d987556448280ca217f17b60b49",
            "value": 1
          }
        },
        "80fe0a51b14b4e548454d4f83215336c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81408f178c46447f90d36d1d18cdad82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06d3de2006b14793bd57a5ca89d44e4a",
              "IPY_MODEL_804c12a3f13840c7bdb2e6df69e62c10"
            ],
            "layout": "IPY_MODEL_4a4cfb14c56e477cbfef5a652c05fabc"
          }
        },
        "81500a36ef5e4a9e9b36aef01bee3697": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "829bba2a5bb947a0bcf121c527902255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "829eee71e4d74403a22941b15dfcf9bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8587c890f2a847e293a101405d64fc0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_175043eb44e44b4f9aefaf51aae6fb10",
              "IPY_MODEL_db36d0cc7691440a9792ac779e161e62"
            ],
            "layout": "IPY_MODEL_c6a68af25a2847e98201847781419670"
          }
        },
        "8795a05c814c469083b31be62e79289f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8877fd11846246f989e31835e5d3e7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "889653c19d8e43cfb6f56ed46af5b76f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8cf1e952ed294ccdbc3bb2275b5d3efd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e410ff55fc448bbe87c8975a552e88",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f49251ce876f4d9292a4179b48ebb22a",
            "value": 1
          }
        },
        "8dc245e02cac40f1b601fa42a0e6e77a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e13a8bef6e14973912966984e83cd4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8f4783e2060a4295bb68036a4a7310d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "904f899f441149e9b707699a0ebf31b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90b585318084475b9543b3226230d373": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3a33bc6a334c9e8c5886caa5f015ca",
              "IPY_MODEL_46c9d83bf8af443bb376ed4858ce35f7"
            ],
            "layout": "IPY_MODEL_2402e482be7e484fa98ae3f60f68d95a"
          }
        },
        "9387a738135842cf965db860499510f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5630d5fcb50a46f2887e0cce74a005a6",
            "placeholder": "",
            "style": "IPY_MODEL_fed90f96881140119ee97a0d2120b615",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "97c3921b8e454ccdb7b4db95d4440c64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99929754d3094d03a5f311177ac26cb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d88657b39fd4b169d61b1b8d240e6ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e0bb90e33ec4e198857c255080ef6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3606009883cf4212b7e1ed6e4f182845",
            "placeholder": "",
            "style": "IPY_MODEL_39aecb8ffe0645fbadccf8b0f8ed2486",
            "value": "0.021 MB of 0.021 MB uploaded\r"
          }
        },
        "9ea517158b974c5da17899e3fea4fc3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1d013e4d3e942b6b362ab5ade6d1a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a30700c8bfb449cda98a40d75828f3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3ccc0b32e9a4ceebd6045dff63e6621": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a562d76741f74b10b8095be14da779d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dc245e02cac40f1b601fa42a0e6e77a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b093d744b374154afe2058e4a6de822",
            "value": 1
          }
        },
        "a5758bfac16a4388a036005a15812d1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5f3871113994f1eb993c126d793d147": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_346856a22f0e45b2be0c14aa7902261f",
            "placeholder": "",
            "style": "IPY_MODEL_397b6d4daaf04a1181413adc5e30db0c",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "a63e1d987556448280ca217f17b60b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6ba8ab59be54b8ca096631627ee9713": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa6aa819c1fd4776ac47af588aaaaacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64224c777f01418e904dcd30ecd7c5ef",
              "IPY_MODEL_c1dbd12595384bc6a0240aaeb16014dc"
            ],
            "layout": "IPY_MODEL_6aa92cf922724ac08c45385ff8a58447"
          }
        },
        "ab0b891f55f648cdbace9bc4540c51c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab580ef13b18428c994fc4f8b80885b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb268a732bc74b2d81ec3c3a6ecd0362",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2915a147a4246dba7984a90f23c34ae",
            "value": 1
          }
        },
        "ab62d64100a84b1faae744ee0f99501a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50b4ba3147b540abad020ae780353f27",
            "placeholder": "",
            "style": "IPY_MODEL_584e5a6aada04535b64c40c3ece566e8",
            "value": "0.017 MB of 0.017 MB uploaded\r"
          }
        },
        "ac87babb2f2a4781ab863c3b8f613807": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed05a015df946c7bae33226c3a8ddc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_403dcd5f10de42ddbb67c8108e3bc34c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1d013e4d3e942b6b362ab5ade6d1a80",
            "value": 1
          }
        },
        "b0748d32c99741d39b18512400e07f30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3970cfd36ed4450b7c8f958a6499dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3b0d42308df44e6b43a06f7424d489d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ef1563b6ba74b86a7bf7af3fcc3d5d6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_889653c19d8e43cfb6f56ed46af5b76f",
            "value": 1
          }
        },
        "b81cc89707e44dedb51081d13a3ba424": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba6f9560801c461a90a0fd2f8c20d918": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5055c91b4ed34c1baf249fa25948e84f",
              "IPY_MODEL_1feabb0772134ace893d71cb905e9b12"
            ],
            "layout": "IPY_MODEL_fb5f2e328dff44018f41180c2a2ec871"
          }
        },
        "bb2ee36dd3c04926b10b832928d7d0a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcbeb5bacc824f3aacd20e50d38bb70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1dbd12595384bc6a0240aaeb16014dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb2ee36dd3c04926b10b832928d7d0a0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d88657b39fd4b169d61b1b8d240e6ff",
            "value": 1
          }
        },
        "c20d73b37f6a497a8847e2fd20a98d16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a0bbd1e2b14cef8a2f9accf120c1ad",
            "placeholder": "",
            "style": "IPY_MODEL_e181391aa4424c04804ac665abd6f594",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "c59ee0d8b9fb4694ada362115bf965a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab62d64100a84b1faae744ee0f99501a",
              "IPY_MODEL_6abbcbe71a314356ba04f8349d1fc127"
            ],
            "layout": "IPY_MODEL_97c3921b8e454ccdb7b4db95d4440c64"
          }
        },
        "c5bb24dc0f56483b88a0efbfa2a1c8ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5de35a9063345b1a12e212718a02575": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a68af25a2847e98201847781419670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e410ff55fc448bbe87c8975a552e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbe10db0bb8d45609a0f3d59a30c8f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_07ff6351429c48c2b835305d3111af40",
              "IPY_MODEL_ab580ef13b18428c994fc4f8b80885b6"
            ],
            "layout": "IPY_MODEL_497de066b1964cd4b931476e0bd50c66"
          }
        },
        "d1e4a03094b94c34ac235ffbd0c7fa06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d268f74266044451b230f20756bab2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3326a99729a416abca13d3122196e64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d601ef3ebb6c4b688ac53a65979aa445": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d71c8b5d30df474ca6f30976d0a33c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d770fa4de3bd479886dbf8e1f6369543": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c20d73b37f6a497a8847e2fd20a98d16",
              "IPY_MODEL_edd61f4569b54b869669aebf91420508"
            ],
            "layout": "IPY_MODEL_a6ba8ab59be54b8ca096631627ee9713"
          }
        },
        "db36d0cc7691440a9792ac779e161e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45bdcbbed9ae47ffb24bd2a962345eaa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcbeb5bacc824f3aacd20e50d38bb70a",
            "value": 1
          }
        },
        "dc43eb867d6b446cb0cb8e5debae57e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcbb358118e644a2a75d44d8adb6747b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60957598b6c64ab0987d583b788dd674",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4ad17a7648245069c70f2f3fb79105a",
            "value": 1
          }
        },
        "df97494c2f654ffbaceb9ca801ff3113": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1e5353cb6a1427a8b0b9d91d6067ef7",
              "IPY_MODEL_77c702b6d9c04f00b8e624f31a591f01"
            ],
            "layout": "IPY_MODEL_8795a05c814c469083b31be62e79289f"
          }
        },
        "e181391aa4424c04804ac665abd6f594": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1e5353cb6a1427a8b0b9d91d6067ef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_829eee71e4d74403a22941b15dfcf9bc",
            "placeholder": "",
            "style": "IPY_MODEL_ab0b891f55f648cdbace9bc4540c51c6",
            "value": "0.015 MB of 0.015 MB uploaded\r"
          }
        },
        "e4a5f301338a4e5185c042a22684ed4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ad17a7648245069c70f2f3fb79105a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e6a773393e084de9a117fbbf43b7a59e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d67121f0ab4daf96d0bdd2c433259b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75a0d8ae24e462aa3075a813aad302d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b42ea1995bb410b99e653780dad3916",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3ebd9b7bf7a4d24b54ab6673322f74b",
            "value": 1
          }
        },
        "e8040d3a83de41319a2a836def914b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e851c69b66ca4e8a80779a69435b855f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4b733fc6800e4a0ab36bba52ff84f1a5",
              "IPY_MODEL_dcbb358118e644a2a75d44d8adb6747b"
            ],
            "layout": "IPY_MODEL_829bba2a5bb947a0bcf121c527902255"
          }
        },
        "e86e517239b54ca4a6767a300aa7e01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eafc1e77174c4758a3780b481d694ae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c30f9a9e6c44d78ad39f43a5f11a6d0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81500a36ef5e4a9e9b36aef01bee3697",
            "value": 1
          }
        },
        "eb268a732bc74b2d81ec3c3a6ecd0362": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edd61f4569b54b869669aebf91420508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ce66183b2543e7bf19b71d90d1c53e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_904f899f441149e9b707699a0ebf31b5",
            "value": 1
          }
        },
        "f2915a147a4246dba7984a90f23c34ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3ebd9b7bf7a4d24b54ab6673322f74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f49251ce876f4d9292a4179b48ebb22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4e7759ba0f544d8a28a9922e06e890b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f523ae2aca8c46878f0a6ddc1f798ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5fd8db807e144578a2e20762d7369d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_32c759d7fff64701a6ad61b38ac63187",
              "IPY_MODEL_557cf2de74314915b7204d9055fa6987"
            ],
            "layout": "IPY_MODEL_c5bb24dc0f56483b88a0efbfa2a1c8ee"
          }
        },
        "f63fffe56ff64f1eb2b6e8f14974f011": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f76ed5acf91a4edf92950dcb88356f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9387a738135842cf965db860499510f5",
              "IPY_MODEL_33a438b911c04f1f96c67b4f7ba7477d"
            ],
            "layout": "IPY_MODEL_35d90a90d5854bcaa2bc5f385cdad931"
          }
        },
        "f8ce66183b2543e7bf19b71d90d1c53e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9dca98d1b8c402db8fa03f1354a051b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3445c5fe76514de0b6b9cc31200c8544",
              "IPY_MODEL_eafc1e77174c4758a3780b481d694ae0"
            ],
            "layout": "IPY_MODEL_e6a773393e084de9a117fbbf43b7a59e"
          }
        },
        "fb5f2e328dff44018f41180c2a2ec871": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd23196beb964eb0a631b1fcb3893545": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2cd8045a5c4387b98d080782289c48": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6480fe59104c7aa15d39bf6ea4a63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d74e9350c2c4c61b2e95924ec133012",
            "placeholder": "",
            "style": "IPY_MODEL_a5758bfac16a4388a036005a15812d1d",
            "value": "0.017 MB of 0.017 MB uploaded\r"
          }
        },
        "fed90f96881140119ee97a0d2120b615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7b6956e7e34db68cd38dee19c798f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
